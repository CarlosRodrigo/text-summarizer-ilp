<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP881025-0196">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Australian novelist Peter Carey was awarded the coveted Booker Prize for fiction Tuesday night for his love story, ``Oscar and Lucinda.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Australian" lemma="australian" stem="australian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="2" string="novelist" lemma="novelist" stem="novelist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Carey" lemma="Carey" stem="carei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="awarded" lemma="award" stem="award" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="coveted" lemma="coveted" stem="covet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="10" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Tuesday" lemma="Tuesday" stem="tuesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="love" lemma="love" stem="love" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Oscar" lemma="Oscar" stem="oscar" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Lucinda" lemma="Lucinda" stem="lucinda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Australian) (NN novelist) (NNP Peter) (NNP Carey)) (VP (VBD was) (VP (VBN awarded) (NP (NP (DT the) (JJ coveted) (NNP Booker) (NNP Prize)) (PP (IN for) (NP (NN fiction)))) (NP-TMP (NNP Tuesday) (NN night)) (PP (IN for) (NP (NP (PRP$ his) (NN love) (NN story)) (, ,) (`` ``) (NP (NNP Oscar) (CC and) (NNP Lucinda)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the coveted Booker Prize" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="coveted" />
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="2" string="awarded the coveted Booker Prize for fiction Tuesday night for his love story , `` Oscar and Lucinda" type="VP">
          <tokens>
            <token id="6" string="awarded" />
            <token id="7" string="the" />
            <token id="8" string="coveted" />
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
            <token id="11" string="for" />
            <token id="12" string="fiction" />
            <token id="13" string="Tuesday" />
            <token id="14" string="night" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="love" />
            <token id="18" string="story" />
            <token id="19" string="," />
            <token id="20" string="``" />
            <token id="21" string="Oscar" />
            <token id="22" string="and" />
            <token id="23" string="Lucinda" />
          </tokens>
        </chunking>
        <chunking id="3" string="the coveted Booker Prize for fiction" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="coveted" />
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
            <token id="11" string="for" />
            <token id="12" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="4" string="fiction" type="NP">
          <tokens>
            <token id="12" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="his love story , `` Oscar and Lucinda" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="love" />
            <token id="18" string="story" />
            <token id="19" string="," />
            <token id="20" string="``" />
            <token id="21" string="Oscar" />
            <token id="22" string="and" />
            <token id="23" string="Lucinda" />
          </tokens>
        </chunking>
        <chunking id="6" string="Australian novelist Peter Carey" type="NP">
          <tokens>
            <token id="1" string="Australian" />
            <token id="2" string="novelist" />
            <token id="3" string="Peter" />
            <token id="4" string="Carey" />
          </tokens>
        </chunking>
        <chunking id="7" string="was awarded the coveted Booker Prize for fiction Tuesday night for his love story , `` Oscar and Lucinda" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="awarded" />
            <token id="7" string="the" />
            <token id="8" string="coveted" />
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
            <token id="11" string="for" />
            <token id="12" string="fiction" />
            <token id="13" string="Tuesday" />
            <token id="14" string="night" />
            <token id="15" string="for" />
            <token id="16" string="his" />
            <token id="17" string="love" />
            <token id="18" string="story" />
            <token id="19" string="," />
            <token id="20" string="``" />
            <token id="21" string="Oscar" />
            <token id="22" string="and" />
            <token id="23" string="Lucinda" />
          </tokens>
        </chunking>
        <chunking id="8" string="his love story" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="love" />
            <token id="18" string="story" />
          </tokens>
        </chunking>
        <chunking id="9" string="Oscar and Lucinda" type="NP">
          <tokens>
            <token id="21" string="Oscar" />
            <token id="22" string="and" />
            <token id="23" string="Lucinda" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="4">Carey</governor>
          <dependent id="1">Australian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Carey</governor>
          <dependent id="2">novelist</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Carey</governor>
          <dependent id="3">Peter</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">awarded</governor>
          <dependent id="4">Carey</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">awarded</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">awarded</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Prize</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Prize</governor>
          <dependent id="8">coveted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Prize</governor>
          <dependent id="9">Booker</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">awarded</governor>
          <dependent id="10">Prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">fiction</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Prize</governor>
          <dependent id="12">fiction</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">night</governor>
          <dependent id="13">Tuesday</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">awarded</governor>
          <dependent id="14">night</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">story</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">story</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">story</governor>
          <dependent id="17">love</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">awarded</governor>
          <dependent id="18">story</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">story</governor>
          <dependent id="21">Oscar</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">Oscar</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">Oscar</governor>
          <dependent id="23">Lucinda</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Australian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="1" string="Australian" />
          </tokens>
        </entity>
        <entity id="2" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="14" string="night" />
          </tokens>
        </entity>
        <entity id="3" string="Peter Carey" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Peter" />
            <token id="4" string="Carey" />
          </tokens>
        </entity>
        <entity id="4" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
          </tokens>
        </entity>
        <entity id="5" string="Tuesday" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="Tuesday" />
          </tokens>
        </entity>
        <entity id="6" string="Lucinda" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Lucinda" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>A panel of five judges unanimously announced the award of the $26,250 prize after an 80-minute deliberation during a banquet at London&amp;apost;s ancient Guildhall.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="unanimously" lemma="unanimously" stem="unanim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="announced" lemma="announce" stem="announc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="13" string="26,250" lemma="26,250" stem="26,250" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="14" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="80-minute" lemma="80-minute" stem="80-minut" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="deliberation" lemma="deliberation" stem="deliber" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="banquet" lemma="banquet" stem="banquet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="ancient" lemma="ancient" stem="ancient" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Guildhall" lemma="Guildhall" stem="guildhal" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NN panel)) (PP (IN of) (NP (CD five) (NNS judges)))) (ADVP (RB unanimously)) (VP (VBD announced) (NP (NP (DT the) (NN award)) (PP (IN of) (NP (DT the) ($ $) (CD 26,250) (NN prize)))) (PP (IN after) (NP (DT an) (JJ 80-minute) (NN deliberation))) (PP (IN during) (NP (NP (DT a) (NN banquet)) (PP (IN at) (NP (NP (NNP London) (POS 's)) (JJ ancient) (NNP Guildhall)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="five judges" type="NP">
          <tokens>
            <token id="4" string="five" />
            <token id="5" string="judges" />
          </tokens>
        </chunking>
        <chunking id="2" string="an 80-minute deliberation" type="NP">
          <tokens>
            <token id="16" string="an" />
            <token id="17" string="80-minute" />
            <token id="18" string="deliberation" />
          </tokens>
        </chunking>
        <chunking id="3" string="the award of the $ 26,250 prize" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="award" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="$" />
            <token id="13" string="26,250" />
            <token id="14" string="prize" />
          </tokens>
        </chunking>
        <chunking id="4" string="the award" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="award" />
          </tokens>
        </chunking>
        <chunking id="5" string="London 's" type="NP">
          <tokens>
            <token id="23" string="London" />
            <token id="24" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="the $ 26,250 prize" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="$" />
            <token id="13" string="26,250" />
            <token id="14" string="prize" />
          </tokens>
        </chunking>
        <chunking id="7" string="London 's ancient Guildhall" type="NP">
          <tokens>
            <token id="23" string="London" />
            <token id="24" string="'s" />
            <token id="25" string="ancient" />
            <token id="26" string="Guildhall" />
          </tokens>
        </chunking>
        <chunking id="8" string="a banquet at London 's ancient Guildhall" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="banquet" />
            <token id="22" string="at" />
            <token id="23" string="London" />
            <token id="24" string="'s" />
            <token id="25" string="ancient" />
            <token id="26" string="Guildhall" />
          </tokens>
        </chunking>
        <chunking id="9" string="A panel of five judges" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="panel" />
            <token id="3" string="of" />
            <token id="4" string="five" />
            <token id="5" string="judges" />
          </tokens>
        </chunking>
        <chunking id="10" string="A panel" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="panel" />
          </tokens>
        </chunking>
        <chunking id="11" string="a banquet" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="banquet" />
          </tokens>
        </chunking>
        <chunking id="12" string="announced the award of the $ 26,250 prize after an 80-minute deliberation during a banquet at London 's ancient Guildhall" type="VP">
          <tokens>
            <token id="7" string="announced" />
            <token id="8" string="the" />
            <token id="9" string="award" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="$" />
            <token id="13" string="26,250" />
            <token id="14" string="prize" />
            <token id="15" string="after" />
            <token id="16" string="an" />
            <token id="17" string="80-minute" />
            <token id="18" string="deliberation" />
            <token id="19" string="during" />
            <token id="20" string="a" />
            <token id="21" string="banquet" />
            <token id="22" string="at" />
            <token id="23" string="London" />
            <token id="24" string="'s" />
            <token id="25" string="ancient" />
            <token id="26" string="Guildhall" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">panel</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">announced</governor>
          <dependent id="2">panel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">judges</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">judges</governor>
          <dependent id="4">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">panel</governor>
          <dependent id="5">judges</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">announced</governor>
          <dependent id="6">unanimously</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">announced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">award</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">announced</governor>
          <dependent id="9">award</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">prize</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">prize</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">prize</governor>
          <dependent id="12">$</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">prize</governor>
          <dependent id="13">26,250</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">award</governor>
          <dependent id="14">prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">deliberation</governor>
          <dependent id="15">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">deliberation</governor>
          <dependent id="16">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">deliberation</governor>
          <dependent id="17">80-minute</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">announced</governor>
          <dependent id="18">deliberation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">banquet</governor>
          <dependent id="19">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">banquet</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">announced</governor>
          <dependent id="21">banquet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Guildhall</governor>
          <dependent id="22">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">Guildhall</governor>
          <dependent id="23">London</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">London</governor>
          <dependent id="24">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">Guildhall</governor>
          <dependent id="25">ancient</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">banquet</governor>
          <dependent id="26">Guildhall</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 26,250" type="MONEY" score="0.0">
          <tokens>
            <token id="12" string="$" />
            <token id="13" string="26,250" />
          </tokens>
        </entity>
        <entity id="2" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="London" />
          </tokens>
        </entity>
        <entity id="3" string="80-minute" type="DURATION" score="0.0">
          <tokens>
            <token id="17" string="80-minute" />
          </tokens>
        </entity>
        <entity id="4" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The judges made their selection from 102 books published in Britain in the past 12 months and which they read in their homes.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="selection" lemma="selection" stem="select" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="102" lemma="102" stem="102" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="14" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="15" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="16" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="read" lemma="read" stem="read" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="23" string="homes" lemma="home" stem="home" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS judges)) (VP (VBD made) (NP (PRP$ their) (NN selection)) (PP (IN from) (NP (NP (CD 102) (NNS books)) (VP (VBN published) (PP (IN in) (NP (NP (NP (NNP Britain)) (PP (IN in) (NP (DT the) (JJ past) (CD 12) (NNS months)))) (CC and) (SBAR (WHNP (WDT which)) (S (NP (PRP they)) (VP (VBP read) (PP (IN in) (NP (PRP$ their) (NNS homes)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="102 books" type="NP">
          <tokens>
            <token id="7" string="102" />
            <token id="8" string="books" />
          </tokens>
        </chunking>
        <chunking id="2" string="made their selection from 102 books published in Britain in the past 12 months and which they read in their homes" type="VP">
          <tokens>
            <token id="3" string="made" />
            <token id="4" string="their" />
            <token id="5" string="selection" />
            <token id="6" string="from" />
            <token id="7" string="102" />
            <token id="8" string="books" />
            <token id="9" string="published" />
            <token id="10" string="in" />
            <token id="11" string="Britain" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="past" />
            <token id="15" string="12" />
            <token id="16" string="months" />
            <token id="17" string="and" />
            <token id="18" string="which" />
            <token id="19" string="they" />
            <token id="20" string="read" />
            <token id="21" string="in" />
            <token id="22" string="their" />
            <token id="23" string="homes" />
          </tokens>
        </chunking>
        <chunking id="3" string="Britain in the past 12 months" type="NP">
          <tokens>
            <token id="11" string="Britain" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="past" />
            <token id="15" string="12" />
            <token id="16" string="months" />
          </tokens>
        </chunking>
        <chunking id="4" string="published in Britain in the past 12 months and which they read in their homes" type="VP">
          <tokens>
            <token id="9" string="published" />
            <token id="10" string="in" />
            <token id="11" string="Britain" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="past" />
            <token id="15" string="12" />
            <token id="16" string="months" />
            <token id="17" string="and" />
            <token id="18" string="which" />
            <token id="19" string="they" />
            <token id="20" string="read" />
            <token id="21" string="in" />
            <token id="22" string="their" />
            <token id="23" string="homes" />
          </tokens>
        </chunking>
        <chunking id="5" string="Britain" type="NP">
          <tokens>
            <token id="11" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="6" string="their homes" type="NP">
          <tokens>
            <token id="22" string="their" />
            <token id="23" string="homes" />
          </tokens>
        </chunking>
        <chunking id="7" string="102 books published in Britain in the past 12 months and which they read in their homes" type="NP">
          <tokens>
            <token id="7" string="102" />
            <token id="8" string="books" />
            <token id="9" string="published" />
            <token id="10" string="in" />
            <token id="11" string="Britain" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="past" />
            <token id="15" string="12" />
            <token id="16" string="months" />
            <token id="17" string="and" />
            <token id="18" string="which" />
            <token id="19" string="they" />
            <token id="20" string="read" />
            <token id="21" string="in" />
            <token id="22" string="their" />
            <token id="23" string="homes" />
          </tokens>
        </chunking>
        <chunking id="8" string="Britain in the past 12 months and which they read in their homes" type="NP">
          <tokens>
            <token id="11" string="Britain" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="past" />
            <token id="15" string="12" />
            <token id="16" string="months" />
            <token id="17" string="and" />
            <token id="18" string="which" />
            <token id="19" string="they" />
            <token id="20" string="read" />
            <token id="21" string="in" />
            <token id="22" string="their" />
            <token id="23" string="homes" />
          </tokens>
        </chunking>
        <chunking id="9" string="The judges" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="judges" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="19" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="read in their homes" type="VP">
          <tokens>
            <token id="20" string="read" />
            <token id="21" string="in" />
            <token id="22" string="their" />
            <token id="23" string="homes" />
          </tokens>
        </chunking>
        <chunking id="12" string="which they read in their homes" type="SBAR">
          <tokens>
            <token id="18" string="which" />
            <token id="19" string="they" />
            <token id="20" string="read" />
            <token id="21" string="in" />
            <token id="22" string="their" />
            <token id="23" string="homes" />
          </tokens>
        </chunking>
        <chunking id="13" string="their selection" type="NP">
          <tokens>
            <token id="4" string="their" />
            <token id="5" string="selection" />
          </tokens>
        </chunking>
        <chunking id="14" string="the past 12 months" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="past" />
            <token id="15" string="12" />
            <token id="16" string="months" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">judges</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">made</governor>
          <dependent id="2">judges</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">made</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">selection</governor>
          <dependent id="4">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">made</governor>
          <dependent id="5">selection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">books</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">books</governor>
          <dependent id="7">102</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">made</governor>
          <dependent id="8">books</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">books</governor>
          <dependent id="9">published</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Britain</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">published</governor>
          <dependent id="11">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">months</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">months</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">months</governor>
          <dependent id="14">past</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">months</governor>
          <dependent id="15">12</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Britain</governor>
          <dependent id="16">months</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">Britain</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">read</governor>
          <dependent id="18">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">read</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">Britain</governor>
          <dependent id="20">read</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">homes</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">homes</governor>
          <dependent id="22">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">read</governor>
          <dependent id="23">homes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="102" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="102" />
          </tokens>
        </entity>
        <entity id="2" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Britain" />
          </tokens>
        </entity>
        <entity id="3" string="the past 12 months" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="past" />
            <token id="15" string="12" />
            <token id="16" string="months" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Carey, who lives in Sydney with his wife and son, said in a brief speech that like the other five finalists he had been asked to attend with a short speech in his pocket in case he won.</content>
      <tokens>
        <token id="1" string="Carey" lemma="Carey" stem="carei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="lives" lemma="live" stem="live" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Sydney" lemma="Sydney" stem="sydnei" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="brief" lemma="brief" stem="brief" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="speech" lemma="speech" stem="speech" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="finalists" lemma="finalist" stem="finalist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="attend" lemma="attend" stem="attend" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="short" lemma="short" stem="short" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="speech" lemma="speech" stem="speech" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="pocket" lemma="pocket" stem="pocket" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Carey)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ lives) (PP (IN in) (NP (NNP Sydney))) (PP (IN with) (NP (PRP$ his) (NN wife) (CC and) (NN son)))))) (, ,)) (VP (VBD said) (PP (IN in) (NP (DT a) (JJ brief) (NN speech))) (SBAR (WHNP (WDT that)) (S (PP (IN like) (NP (DT the) (JJ other) (CD five) (NNS finalists))) (NP (PRP he)) (VP (VBD had) (VP (VBN been) (VP (VBN asked) (S (VP (TO to) (VP (VB attend) (PP (IN with) (NP (NP (DT a) (JJ short) (NN speech)) (PP (IN in) (NP (PRP$ his) (NN pocket))))) (SBAR (IN in) (NN case) (S (NP (PRP he)) (VP (VBD won))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="lives in Sydney with his wife and son" type="VP">
          <tokens>
            <token id="4" string="lives" />
            <token id="5" string="in" />
            <token id="6" string="Sydney" />
            <token id="7" string="with" />
            <token id="8" string="his" />
            <token id="9" string="wife" />
            <token id="10" string="and" />
            <token id="11" string="son" />
          </tokens>
        </chunking>
        <chunking id="2" string="to attend with a short speech in his pocket in case he won" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="attend" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="short" />
            <token id="33" string="speech" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="pocket" />
            <token id="37" string="in" />
            <token id="38" string="case" />
            <token id="39" string="he" />
            <token id="40" string="won" />
          </tokens>
        </chunking>
        <chunking id="3" string="who lives in Sydney with his wife and son" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="lives" />
            <token id="5" string="in" />
            <token id="6" string="Sydney" />
            <token id="7" string="with" />
            <token id="8" string="his" />
            <token id="9" string="wife" />
            <token id="10" string="and" />
            <token id="11" string="son" />
          </tokens>
        </chunking>
        <chunking id="4" string="his wife and son" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="wife" />
            <token id="10" string="and" />
            <token id="11" string="son" />
          </tokens>
        </chunking>
        <chunking id="5" string="asked to attend with a short speech in his pocket in case he won" type="VP">
          <tokens>
            <token id="27" string="asked" />
            <token id="28" string="to" />
            <token id="29" string="attend" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="short" />
            <token id="33" string="speech" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="pocket" />
            <token id="37" string="in" />
            <token id="38" string="case" />
            <token id="39" string="he" />
            <token id="40" string="won" />
          </tokens>
        </chunking>
        <chunking id="6" string="the other five finalists" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="other" />
            <token id="22" string="five" />
            <token id="23" string="finalists" />
          </tokens>
        </chunking>
        <chunking id="7" string="that like the other five finalists he had been asked to attend with a short speech in his pocket in case he won" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="like" />
            <token id="20" string="the" />
            <token id="21" string="other" />
            <token id="22" string="five" />
            <token id="23" string="finalists" />
            <token id="24" string="he" />
            <token id="25" string="had" />
            <token id="26" string="been" />
            <token id="27" string="asked" />
            <token id="28" string="to" />
            <token id="29" string="attend" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="short" />
            <token id="33" string="speech" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="pocket" />
            <token id="37" string="in" />
            <token id="38" string="case" />
            <token id="39" string="he" />
            <token id="40" string="won" />
          </tokens>
        </chunking>
        <chunking id="8" string="a short speech in his pocket" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="short" />
            <token id="33" string="speech" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="pocket" />
          </tokens>
        </chunking>
        <chunking id="9" string="Carey , who lives in Sydney with his wife and son ," type="NP">
          <tokens>
            <token id="1" string="Carey" />
            <token id="2" string="," />
            <token id="3" string="who" />
            <token id="4" string="lives" />
            <token id="5" string="in" />
            <token id="6" string="Sydney" />
            <token id="7" string="with" />
            <token id="8" string="his" />
            <token id="9" string="wife" />
            <token id="10" string="and" />
            <token id="11" string="son" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="been asked to attend with a short speech in his pocket in case he won" type="VP">
          <tokens>
            <token id="26" string="been" />
            <token id="27" string="asked" />
            <token id="28" string="to" />
            <token id="29" string="attend" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="short" />
            <token id="33" string="speech" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="pocket" />
            <token id="37" string="in" />
            <token id="38" string="case" />
            <token id="39" string="he" />
            <token id="40" string="won" />
          </tokens>
        </chunking>
        <chunking id="11" string="attend with a short speech in his pocket in case he won" type="VP">
          <tokens>
            <token id="29" string="attend" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="short" />
            <token id="33" string="speech" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="pocket" />
            <token id="37" string="in" />
            <token id="38" string="case" />
            <token id="39" string="he" />
            <token id="40" string="won" />
          </tokens>
        </chunking>
        <chunking id="12" string="won" type="VP">
          <tokens>
            <token id="40" string="won" />
          </tokens>
        </chunking>
        <chunking id="13" string="in case he won" type="SBAR">
          <tokens>
            <token id="37" string="in" />
            <token id="38" string="case" />
            <token id="39" string="he" />
            <token id="40" string="won" />
          </tokens>
        </chunking>
        <chunking id="14" string="Sydney" type="NP">
          <tokens>
            <token id="6" string="Sydney" />
          </tokens>
        </chunking>
        <chunking id="15" string="Carey" type="NP">
          <tokens>
            <token id="1" string="Carey" />
          </tokens>
        </chunking>
        <chunking id="16" string="had been asked to attend with a short speech in his pocket in case he won" type="VP">
          <tokens>
            <token id="25" string="had" />
            <token id="26" string="been" />
            <token id="27" string="asked" />
            <token id="28" string="to" />
            <token id="29" string="attend" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="short" />
            <token id="33" string="speech" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="pocket" />
            <token id="37" string="in" />
            <token id="38" string="case" />
            <token id="39" string="he" />
            <token id="40" string="won" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="24" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="a short speech" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="short" />
            <token id="33" string="speech" />
          </tokens>
        </chunking>
        <chunking id="19" string="his pocket" type="NP">
          <tokens>
            <token id="35" string="his" />
            <token id="36" string="pocket" />
          </tokens>
        </chunking>
        <chunking id="20" string="said in a brief speech that like the other five finalists he had been asked to attend with a short speech in his pocket in case he won" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="in" />
            <token id="15" string="a" />
            <token id="16" string="brief" />
            <token id="17" string="speech" />
            <token id="18" string="that" />
            <token id="19" string="like" />
            <token id="20" string="the" />
            <token id="21" string="other" />
            <token id="22" string="five" />
            <token id="23" string="finalists" />
            <token id="24" string="he" />
            <token id="25" string="had" />
            <token id="26" string="been" />
            <token id="27" string="asked" />
            <token id="28" string="to" />
            <token id="29" string="attend" />
            <token id="30" string="with" />
            <token id="31" string="a" />
            <token id="32" string="short" />
            <token id="33" string="speech" />
            <token id="34" string="in" />
            <token id="35" string="his" />
            <token id="36" string="pocket" />
            <token id="37" string="in" />
            <token id="38" string="case" />
            <token id="39" string="he" />
            <token id="40" string="won" />
          </tokens>
        </chunking>
        <chunking id="21" string="a brief speech" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="brief" />
            <token id="17" string="speech" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="1">Carey</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">lives</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Carey</governor>
          <dependent id="4">lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Sydney</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">lives</governor>
          <dependent id="6">Sydney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">wife</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">wife</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">lives</governor>
          <dependent id="9">wife</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">wife</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">wife</governor>
          <dependent id="11">son</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">speech</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">speech</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">speech</governor>
          <dependent id="16">brief</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">said</governor>
          <dependent id="17">speech</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">attend</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">finalists</governor>
          <dependent id="19">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">finalists</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">finalists</governor>
          <dependent id="21">other</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">finalists</governor>
          <dependent id="22">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">asked</governor>
          <dependent id="23">finalists</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">asked</governor>
          <dependent id="24">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">asked</governor>
          <dependent id="25">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">asked</governor>
          <dependent id="26">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="27">asked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">attend</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">asked</governor>
          <dependent id="29">attend</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">speech</governor>
          <dependent id="30">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">speech</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">speech</governor>
          <dependent id="32">short</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">attend</governor>
          <dependent id="33">speech</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">pocket</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">pocket</governor>
          <dependent id="35">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">speech</governor>
          <dependent id="36">pocket</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">won</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="37">in</governor>
          <dependent id="38">case</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">won</governor>
          <dependent id="39">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="29">attend</governor>
          <dependent id="40">won</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sydney" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Sydney" />
          </tokens>
        </entity>
        <entity id="2" string="Carey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Carey" />
          </tokens>
        </entity>
        <entity id="3" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>``If I&amp;apost;d known I was going to win I think I would have taken a bit more trouble with my handwriting,&amp;apost;&amp;apost; he said as he stared down at his notes.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="win" lemma="win" stem="win" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="bit" lemma="bit" stem="bit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="trouble" lemma="trouble" stem="troubl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="handwriting" lemma="handwriting" stem="handwrit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="stared" lemma="stare" stem="stare" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="notes" lemma="note" stem="note" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (IN If) (S (NP (PRP I)) (VP (MD 'd) (VP (VBN known))))) (NP (PRP I)) (VP (VBD was) (VP (VBG going) (S (VP (TO to) (VP (VB win) (SBAR (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP I)) (VP (MD would) (VP (VB have) (VP (VBN taken) (NP (ADVP (NP (DT a) (NN bit)) (RBR more)) (NN trouble)) (PP (IN with) (NP (PRP$ my) (NN handwriting))))))))))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said) (SBAR (IN as) (S (NP (PRP he)) (VP (VBD stared) (PRT (RP down)) (PP (IN at) (NP (PRP$ his) (NNS notes))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his notes" type="NP">
          <tokens>
            <token id="33" string="his" />
            <token id="34" string="notes" />
          </tokens>
        </chunking>
        <chunking id="2" string="would have taken a bit more trouble with my handwriting" type="VP">
          <tokens>
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="taken" />
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
            <token id="21" string="with" />
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="3" string="stared down at his notes" type="VP">
          <tokens>
            <token id="30" string="stared" />
            <token id="31" string="down" />
            <token id="32" string="at" />
            <token id="33" string="his" />
            <token id="34" string="notes" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="was going to win I think I would have taken a bit more trouble with my handwriting" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="going" />
            <token id="9" string="to" />
            <token id="10" string="win" />
            <token id="11" string="I" />
            <token id="12" string="think" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="taken" />
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
            <token id="21" string="with" />
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="6" string="I would have taken a bit more trouble with my handwriting" type="SBAR">
          <tokens>
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="taken" />
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
            <token id="21" string="with" />
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="7" string="think I would have taken a bit more trouble with my handwriting" type="VP">
          <tokens>
            <token id="12" string="think" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="taken" />
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
            <token id="21" string="with" />
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="8" string="a bit" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="bit" />
          </tokens>
        </chunking>
        <chunking id="9" string="I think I would have taken a bit more trouble with my handwriting" type="SBAR">
          <tokens>
            <token id="11" string="I" />
            <token id="12" string="think" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="taken" />
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
            <token id="21" string="with" />
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="10" string="said as he stared down at his notes" type="VP">
          <tokens>
            <token id="27" string="said" />
            <token id="28" string="as" />
            <token id="29" string="he" />
            <token id="30" string="stared" />
            <token id="31" string="down" />
            <token id="32" string="at" />
            <token id="33" string="his" />
            <token id="34" string="notes" />
          </tokens>
        </chunking>
        <chunking id="11" string="my handwriting" type="NP">
          <tokens>
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="12" string="If I 'd known" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="I" />
            <token id="4" string="'d" />
            <token id="5" string="known" />
          </tokens>
        </chunking>
        <chunking id="13" string="'d known" type="VP">
          <tokens>
            <token id="4" string="'d" />
            <token id="5" string="known" />
          </tokens>
        </chunking>
        <chunking id="14" string="a bit more trouble" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="15" string="as he stared down at his notes" type="SBAR">
          <tokens>
            <token id="28" string="as" />
            <token id="29" string="he" />
            <token id="30" string="stared" />
            <token id="31" string="down" />
            <token id="32" string="at" />
            <token id="33" string="his" />
            <token id="34" string="notes" />
          </tokens>
        </chunking>
        <chunking id="16" string="known" type="VP">
          <tokens>
            <token id="5" string="known" />
          </tokens>
        </chunking>
        <chunking id="17" string="have taken a bit more trouble with my handwriting" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="taken" />
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
            <token id="21" string="with" />
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="18" string="going to win I think I would have taken a bit more trouble with my handwriting" type="VP">
          <tokens>
            <token id="8" string="going" />
            <token id="9" string="to" />
            <token id="10" string="win" />
            <token id="11" string="I" />
            <token id="12" string="think" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="taken" />
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
            <token id="21" string="with" />
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="19" string="to win I think I would have taken a bit more trouble with my handwriting" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="win" />
            <token id="11" string="I" />
            <token id="12" string="think" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="taken" />
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
            <token id="21" string="with" />
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="20" string="win I think I would have taken a bit more trouble with my handwriting" type="VP">
          <tokens>
            <token id="10" string="win" />
            <token id="11" string="I" />
            <token id="12" string="think" />
            <token id="13" string="I" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="taken" />
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
            <token id="21" string="with" />
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="21" string="he" type="NP">
          <tokens>
            <token id="26" string="he" />
          </tokens>
        </chunking>
        <chunking id="22" string="taken a bit more trouble with my handwriting" type="VP">
          <tokens>
            <token id="16" string="taken" />
            <token id="17" string="a" />
            <token id="18" string="bit" />
            <token id="19" string="more" />
            <token id="20" string="trouble" />
            <token id="21" string="with" />
            <token id="22" string="my" />
            <token id="23" string="handwriting" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">known</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">known</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">known</governor>
          <dependent id="4">'d</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">going</governor>
          <dependent id="5">known</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">going</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">going</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">said</governor>
          <dependent id="8">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">win</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">going</governor>
          <dependent id="10">win</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">think</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">win</governor>
          <dependent id="12">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">taken</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">taken</governor>
          <dependent id="14">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">taken</governor>
          <dependent id="15">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">think</governor>
          <dependent id="16">taken</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">bit</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="19">more</governor>
          <dependent id="18">bit</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">trouble</governor>
          <dependent id="19">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">taken</governor>
          <dependent id="20">trouble</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">handwriting</governor>
          <dependent id="21">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">handwriting</governor>
          <dependent id="22">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">taken</governor>
          <dependent id="23">handwriting</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">said</governor>
          <dependent id="26">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">said</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">stared</governor>
          <dependent id="28">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">stared</governor>
          <dependent id="29">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="27">said</governor>
          <dependent id="30">stared</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="30">stared</governor>
          <dependent id="31">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">notes</governor>
          <dependent id="32">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">notes</governor>
          <dependent id="33">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">stared</governor>
          <dependent id="34">notes</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>He was unsuccessful in the prize competition in 1985 when his novel, ``Illywhacker,&amp;apost;&amp;apost; was among the final six.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="unsuccessful" lemma="unsuccessful" stem="unsuccess" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="competition" lemma="competition" stem="competit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Illywhacker" lemma="illywhacker" stem="illywhack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD was) (ADJP (JJ unsuccessful) (PP (IN in) (NP (NP (DT the) (NN prize) (NN competition)) (PP (IN in) (NP (CD 1985)))))) (SBAR (WHADVP (WRB when)) (S (NP (NP (PRP$ his) (NN novel)) (, ,) (`` ``) (NP (NN Illywhacker)) (, ,) ('' '')) (VP (VBD was) (PP (IN among) (NP (DT the) (JJ final) (CD six))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the final six" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="final" />
            <token id="22" string="six" />
          </tokens>
        </chunking>
        <chunking id="2" string="when his novel , `` Illywhacker , '' was among the final six" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="his" />
            <token id="12" string="novel" />
            <token id="13" string="," />
            <token id="14" string="``" />
            <token id="15" string="Illywhacker" />
            <token id="16" string="," />
            <token id="17" string="''" />
            <token id="18" string="was" />
            <token id="19" string="among" />
            <token id="20" string="the" />
            <token id="21" string="final" />
            <token id="22" string="six" />
          </tokens>
        </chunking>
        <chunking id="3" string="his novel , `` Illywhacker , ''" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="novel" />
            <token id="13" string="," />
            <token id="14" string="``" />
            <token id="15" string="Illywhacker" />
            <token id="16" string="," />
            <token id="17" string="''" />
          </tokens>
        </chunking>
        <chunking id="4" string="the prize competition in 1985" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="prize" />
            <token id="7" string="competition" />
            <token id="8" string="in" />
            <token id="9" string="1985" />
          </tokens>
        </chunking>
        <chunking id="5" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="6" string="unsuccessful in the prize competition in 1985" type="ADJP">
          <tokens>
            <token id="3" string="unsuccessful" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="prize" />
            <token id="7" string="competition" />
            <token id="8" string="in" />
            <token id="9" string="1985" />
          </tokens>
        </chunking>
        <chunking id="7" string="1985" type="NP">
          <tokens>
            <token id="9" string="1985" />
          </tokens>
        </chunking>
        <chunking id="8" string="the prize competition" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="prize" />
            <token id="7" string="competition" />
          </tokens>
        </chunking>
        <chunking id="9" string="Illywhacker" type="NP">
          <tokens>
            <token id="15" string="Illywhacker" />
          </tokens>
        </chunking>
        <chunking id="10" string="was among the final six" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="among" />
            <token id="20" string="the" />
            <token id="21" string="final" />
            <token id="22" string="six" />
          </tokens>
        </chunking>
        <chunking id="11" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="12" string="was unsuccessful in the prize competition in 1985 when his novel , `` Illywhacker , '' was among the final six" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="unsuccessful" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="prize" />
            <token id="7" string="competition" />
            <token id="8" string="in" />
            <token id="9" string="1985" />
            <token id="10" string="when" />
            <token id="11" string="his" />
            <token id="12" string="novel" />
            <token id="13" string="," />
            <token id="14" string="``" />
            <token id="15" string="Illywhacker" />
            <token id="16" string="," />
            <token id="17" string="''" />
            <token id="18" string="was" />
            <token id="19" string="among" />
            <token id="20" string="the" />
            <token id="21" string="final" />
            <token id="22" string="six" />
          </tokens>
        </chunking>
        <chunking id="13" string="his novel" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="novel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">unsuccessful</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">unsuccessful</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">unsuccessful</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">competition</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">competition</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">competition</governor>
          <dependent id="6">prize</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">unsuccessful</governor>
          <dependent id="7">competition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">1985</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">competition</governor>
          <dependent id="9">1985</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">six</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">novel</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">six</governor>
          <dependent id="12">novel</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">novel</governor>
          <dependent id="15">Illywhacker</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">six</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">six</governor>
          <dependent id="19">among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">six</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">six</governor>
          <dependent id="21">final</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">unsuccessful</governor>
          <dependent id="22">six</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="1985" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="1985" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Carey called the award a ``great honor&amp;apost;&amp;apost; and he thanked the prize sponsors for ``provoking so much passionate discussion about literature _ perhaps there will be more tomorrow.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Carey" lemma="Carey" stem="carei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="honor" lemma="honor" stem="honor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="thanked" lemma="thank" stem="thank" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="sponsors" lemma="sponsor" stem="sponsor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="provoking" lemma="provoke" stem="provok" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="passionate" lemma="passionate" stem="passion" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="discussion" lemma="discussion" stem="discuss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="literature" lemma="literature" stem="literatur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="tomorrow" lemma="tomorrow" stem="tomorrow" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Carey)) (VP (VBD called) (NP (DT the) (NN award)) (NP (DT a) (`` ``) (JJ great) (NN honor) ('' '')))) (CC and) (S (NP (PRP he)) (VP (VBD thanked) (NP (DT the) (NN prize) (NNS sponsors)) (PP (IN for) (`` ``) (S (VP (VBG provoking) (NP (ADJP (RB so) (JJ much)) (JJ passionate) (NN discussion)) (PP (IN about) (NP (NP (NN literature) (NN _)) (ADVP (RB perhaps)) (SBAR (S (NP (EX there)) (VP (MD will) (VP (VB be) (ADVP (RBR more)) (NP-TMP (NN tomorrow))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="will be more tomorrow" type="VP">
          <tokens>
            <token id="28" string="will" />
            <token id="29" string="be" />
            <token id="30" string="more" />
            <token id="31" string="tomorrow" />
          </tokens>
        </chunking>
        <chunking id="2" string="thanked the prize sponsors for `` provoking so much passionate discussion about literature _ perhaps there will be more tomorrow" type="VP">
          <tokens>
            <token id="12" string="thanked" />
            <token id="13" string="the" />
            <token id="14" string="prize" />
            <token id="15" string="sponsors" />
            <token id="16" string="for" />
            <token id="17" string="``" />
            <token id="18" string="provoking" />
            <token id="19" string="so" />
            <token id="20" string="much" />
            <token id="21" string="passionate" />
            <token id="22" string="discussion" />
            <token id="23" string="about" />
            <token id="24" string="literature" />
            <token id="25" string="_" />
            <token id="26" string="perhaps" />
            <token id="27" string="there" />
            <token id="28" string="will" />
            <token id="29" string="be" />
            <token id="30" string="more" />
            <token id="31" string="tomorrow" />
          </tokens>
        </chunking>
        <chunking id="3" string="provoking so much passionate discussion about literature _ perhaps there will be more tomorrow" type="VP">
          <tokens>
            <token id="18" string="provoking" />
            <token id="19" string="so" />
            <token id="20" string="much" />
            <token id="21" string="passionate" />
            <token id="22" string="discussion" />
            <token id="23" string="about" />
            <token id="24" string="literature" />
            <token id="25" string="_" />
            <token id="26" string="perhaps" />
            <token id="27" string="there" />
            <token id="28" string="will" />
            <token id="29" string="be" />
            <token id="30" string="more" />
            <token id="31" string="tomorrow" />
          </tokens>
        </chunking>
        <chunking id="4" string="literature _ perhaps there will be more tomorrow" type="NP">
          <tokens>
            <token id="24" string="literature" />
            <token id="25" string="_" />
            <token id="26" string="perhaps" />
            <token id="27" string="there" />
            <token id="28" string="will" />
            <token id="29" string="be" />
            <token id="30" string="more" />
            <token id="31" string="tomorrow" />
          </tokens>
        </chunking>
        <chunking id="5" string="so much passionate discussion" type="NP">
          <tokens>
            <token id="19" string="so" />
            <token id="20" string="much" />
            <token id="21" string="passionate" />
            <token id="22" string="discussion" />
          </tokens>
        </chunking>
        <chunking id="6" string="be more tomorrow" type="VP">
          <tokens>
            <token id="29" string="be" />
            <token id="30" string="more" />
            <token id="31" string="tomorrow" />
          </tokens>
        </chunking>
        <chunking id="7" string="literature _" type="NP">
          <tokens>
            <token id="24" string="literature" />
            <token id="25" string="_" />
          </tokens>
        </chunking>
        <chunking id="8" string="there" type="NP">
          <tokens>
            <token id="27" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="a `` great honor ''" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="``" />
            <token id="7" string="great" />
            <token id="8" string="honor" />
            <token id="9" string="''" />
          </tokens>
        </chunking>
        <chunking id="10" string="there will be more tomorrow" type="SBAR">
          <tokens>
            <token id="27" string="there" />
            <token id="28" string="will" />
            <token id="29" string="be" />
            <token id="30" string="more" />
            <token id="31" string="tomorrow" />
          </tokens>
        </chunking>
        <chunking id="11" string="the award" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="award" />
          </tokens>
        </chunking>
        <chunking id="12" string="called the award a `` great honor ''" type="VP">
          <tokens>
            <token id="2" string="called" />
            <token id="3" string="the" />
            <token id="4" string="award" />
            <token id="5" string="a" />
            <token id="6" string="``" />
            <token id="7" string="great" />
            <token id="8" string="honor" />
            <token id="9" string="''" />
          </tokens>
        </chunking>
        <chunking id="13" string="Carey" type="NP">
          <tokens>
            <token id="1" string="Carey" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="so much" type="ADJP">
          <tokens>
            <token id="19" string="so" />
            <token id="20" string="much" />
          </tokens>
        </chunking>
        <chunking id="16" string="the prize sponsors" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="prize" />
            <token id="15" string="sponsors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">called</governor>
          <dependent id="1">Carey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">award</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="2">called</governor>
          <dependent id="4">award</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">honor</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">honor</governor>
          <dependent id="7">great</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">called</governor>
          <dependent id="8">honor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">called</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">thanked</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">called</governor>
          <dependent id="12">thanked</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">sponsors</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">sponsors</governor>
          <dependent id="14">prize</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">thanked</governor>
          <dependent id="15">sponsors</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">provoking</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">thanked</governor>
          <dependent id="18">provoking</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">much</governor>
          <dependent id="19">so</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">discussion</governor>
          <dependent id="20">much</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">discussion</governor>
          <dependent id="21">passionate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">provoking</governor>
          <dependent id="22">discussion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">_</governor>
          <dependent id="23">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">_</governor>
          <dependent id="24">literature</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">provoking</governor>
          <dependent id="25">_</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">_</governor>
          <dependent id="26">perhaps</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="29">be</governor>
          <dependent id="27">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">be</governor>
          <dependent id="28">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="25">_</governor>
          <dependent id="29">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">be</governor>
          <dependent id="30">more</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="29">be</governor>
          <dependent id="31">tomorrow</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="tomorrow" type="DATE" score="0.0">
          <tokens>
            <token id="31" string="tomorrow" />
          </tokens>
        </entity>
        <entity id="2" string="Carey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Carey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="false">
      <content>``Everyone who loves good books benefits from this, surely,&amp;apost;&amp;apost; he added.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="loves" lemma="love" stem="love" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="benefits" lemma="benefit" stem="benefit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="surely" lemma="surely" stem="sure" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (NN Everyone)) (SBAR (WHNP (WP who)) (S (VP (VBZ loves) (NP (JJ good) (NNS books) (NNS benefits)) (PP (IN from) (NP (DT this))) (, ,) (ADVP (RB surely)))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD added)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who loves good books benefits from this , surely" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="loves" />
            <token id="5" string="good" />
            <token id="6" string="books" />
            <token id="7" string="benefits" />
            <token id="8" string="from" />
            <token id="9" string="this" />
            <token id="10" string="," />
            <token id="11" string="surely" />
          </tokens>
        </chunking>
        <chunking id="2" string="Everyone" type="NP">
          <tokens>
            <token id="2" string="Everyone" />
          </tokens>
        </chunking>
        <chunking id="3" string="loves good books benefits from this , surely" type="VP">
          <tokens>
            <token id="4" string="loves" />
            <token id="5" string="good" />
            <token id="6" string="books" />
            <token id="7" string="benefits" />
            <token id="8" string="from" />
            <token id="9" string="this" />
            <token id="10" string="," />
            <token id="11" string="surely" />
          </tokens>
        </chunking>
        <chunking id="4" string="Everyone who loves good books benefits from this , surely" type="NP">
          <tokens>
            <token id="2" string="Everyone" />
            <token id="3" string="who" />
            <token id="4" string="loves" />
            <token id="5" string="good" />
            <token id="6" string="books" />
            <token id="7" string="benefits" />
            <token id="8" string="from" />
            <token id="9" string="this" />
            <token id="10" string="," />
            <token id="11" string="surely" />
          </tokens>
        </chunking>
        <chunking id="5" string="added" type="VP">
          <tokens>
            <token id="15" string="added" />
          </tokens>
        </chunking>
        <chunking id="6" string="this" type="NP">
          <tokens>
            <token id="9" string="this" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="good books benefits" type="NP">
          <tokens>
            <token id="5" string="good" />
            <token id="6" string="books" />
            <token id="7" string="benefits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="15">added</governor>
          <dependent id="2">Everyone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">loves</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">Everyone</governor>
          <dependent id="4">loves</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">benefits</governor>
          <dependent id="5">good</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">benefits</governor>
          <dependent id="6">books</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">loves</governor>
          <dependent id="7">benefits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">this</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">loves</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">loves</governor>
          <dependent id="11">surely</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">added</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">added</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>The winning novel is a fitting choice for Australia&amp;apost;s bicentennial year.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="winning" lemma="win" stem="win" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="fitting" lemma="fitting" stem="fit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="choice" lemma="choice" stem="choic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Australia" lemma="Australia" stem="australia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="bicentennial" lemma="bicentennial" stem="bicentenni" pos="JJ" type="Word" isStopWord="false" ner="SET" is_referenced="true" is_refers="false" />
        <token id="12" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (VBG winning) (NN novel)) (VP (VBZ is) (NP (NP (DT a) (JJ fitting) (NN choice)) (PP (IN for) (NP (NP (NNP Australia) (POS 's)) (JJ bicentennial) (NN year))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Australia 's bicentennial year" type="NP">
          <tokens>
            <token id="9" string="Australia" />
            <token id="10" string="'s" />
            <token id="11" string="bicentennial" />
            <token id="12" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="a fitting choice" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="fitting" />
            <token id="7" string="choice" />
          </tokens>
        </chunking>
        <chunking id="3" string="a fitting choice for Australia 's bicentennial year" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="fitting" />
            <token id="7" string="choice" />
            <token id="8" string="for" />
            <token id="9" string="Australia" />
            <token id="10" string="'s" />
            <token id="11" string="bicentennial" />
            <token id="12" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="Australia 's" type="NP">
          <tokens>
            <token id="9" string="Australia" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="is a fitting choice for Australia 's bicentennial year" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="a" />
            <token id="6" string="fitting" />
            <token id="7" string="choice" />
            <token id="8" string="for" />
            <token id="9" string="Australia" />
            <token id="10" string="'s" />
            <token id="11" string="bicentennial" />
            <token id="12" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="The winning novel" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="winning" />
            <token id="3" string="novel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">novel</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">novel</governor>
          <dependent id="2">winning</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">choice</governor>
          <dependent id="3">novel</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">choice</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">choice</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">choice</governor>
          <dependent id="6">fitting</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">choice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">year</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">year</governor>
          <dependent id="9">Australia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Australia</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">year</governor>
          <dependent id="11">bicentennial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">choice</governor>
          <dependent id="12">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Australia" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Australia" />
          </tokens>
        </entity>
        <entity id="2" string="year" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="year" />
          </tokens>
        </entity>
        <entity id="3" string="bicentennial" type="SET" score="0.0">
          <tokens>
            <token id="11" string="bicentennial" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>It tells of a romance between an English gambler and an Australian heiress who meet on a steamship&amp;apost;s maiden voyage to Australia in the mid-19th century.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="tells" lemma="tell" stem="tell" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="romance" lemma="romance" stem="romanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="English" lemma="english" stem="english" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="9" string="gambler" lemma="gambler" stem="gambler" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Australian" lemma="australian" stem="australian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="13" string="heiress" lemma="heiress" stem="heiress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="meet" lemma="meet" stem="meet" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="steamship" lemma="steamship" stem="steamship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="maiden" lemma="maiden" stem="maiden" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="voyage" lemma="voyage" stem="voyag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Australia" lemma="Australia" stem="australia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="mid-19th" lemma="mid-19th" stem="mid-19th" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ tells) (PP (IN of) (NP (NP (NP (DT a) (NN romance)) (PP (IN between) (NP (DT an) (JJ English) (NN gambler)))) (CC and) (NP (NP (DT an) (JJ Australian) (NN heiress)) (SBAR (WHNP (WP who)) (S (VP (VBP meet) (PP (IN on) (NP (NP (DT a) (NN steamship) (POS 's)) (JJ maiden) (NN voyage))) (PP (TO to) (NP (NP (NNP Australia)) (PP (IN in) (NP (DT the) (JJ mid-19th) (NN century)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a steamship 's" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="steamship" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="Australia" type="NP">
          <tokens>
            <token id="23" string="Australia" />
          </tokens>
        </chunking>
        <chunking id="3" string="Australia in the mid-19th century" type="NP">
          <tokens>
            <token id="23" string="Australia" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="mid-19th" />
            <token id="27" string="century" />
          </tokens>
        </chunking>
        <chunking id="4" string="tells of a romance between an English gambler and an Australian heiress who meet on a steamship 's maiden voyage to Australia in the mid-19th century" type="VP">
          <tokens>
            <token id="2" string="tells" />
            <token id="3" string="of" />
            <token id="4" string="a" />
            <token id="5" string="romance" />
            <token id="6" string="between" />
            <token id="7" string="an" />
            <token id="8" string="English" />
            <token id="9" string="gambler" />
            <token id="10" string="and" />
            <token id="11" string="an" />
            <token id="12" string="Australian" />
            <token id="13" string="heiress" />
            <token id="14" string="who" />
            <token id="15" string="meet" />
            <token id="16" string="on" />
            <token id="17" string="a" />
            <token id="18" string="steamship" />
            <token id="19" string="'s" />
            <token id="20" string="maiden" />
            <token id="21" string="voyage" />
            <token id="22" string="to" />
            <token id="23" string="Australia" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="mid-19th" />
            <token id="27" string="century" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="the mid-19th century" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="mid-19th" />
            <token id="27" string="century" />
          </tokens>
        </chunking>
        <chunking id="7" string="an English gambler" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="English" />
            <token id="9" string="gambler" />
          </tokens>
        </chunking>
        <chunking id="8" string="a romance between an English gambler and an Australian heiress who meet on a steamship 's maiden voyage to Australia in the mid-19th century" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="romance" />
            <token id="6" string="between" />
            <token id="7" string="an" />
            <token id="8" string="English" />
            <token id="9" string="gambler" />
            <token id="10" string="and" />
            <token id="11" string="an" />
            <token id="12" string="Australian" />
            <token id="13" string="heiress" />
            <token id="14" string="who" />
            <token id="15" string="meet" />
            <token id="16" string="on" />
            <token id="17" string="a" />
            <token id="18" string="steamship" />
            <token id="19" string="'s" />
            <token id="20" string="maiden" />
            <token id="21" string="voyage" />
            <token id="22" string="to" />
            <token id="23" string="Australia" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="mid-19th" />
            <token id="27" string="century" />
          </tokens>
        </chunking>
        <chunking id="9" string="an Australian heiress" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="Australian" />
            <token id="13" string="heiress" />
          </tokens>
        </chunking>
        <chunking id="10" string="who meet on a steamship 's maiden voyage to Australia in the mid-19th century" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="meet" />
            <token id="16" string="on" />
            <token id="17" string="a" />
            <token id="18" string="steamship" />
            <token id="19" string="'s" />
            <token id="20" string="maiden" />
            <token id="21" string="voyage" />
            <token id="22" string="to" />
            <token id="23" string="Australia" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="mid-19th" />
            <token id="27" string="century" />
          </tokens>
        </chunking>
        <chunking id="11" string="a romance" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="romance" />
          </tokens>
        </chunking>
        <chunking id="12" string="a steamship 's maiden voyage" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="steamship" />
            <token id="19" string="'s" />
            <token id="20" string="maiden" />
            <token id="21" string="voyage" />
          </tokens>
        </chunking>
        <chunking id="13" string="a romance between an English gambler" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="romance" />
            <token id="6" string="between" />
            <token id="7" string="an" />
            <token id="8" string="English" />
            <token id="9" string="gambler" />
          </tokens>
        </chunking>
        <chunking id="14" string="meet on a steamship 's maiden voyage to Australia in the mid-19th century" type="VP">
          <tokens>
            <token id="15" string="meet" />
            <token id="16" string="on" />
            <token id="17" string="a" />
            <token id="18" string="steamship" />
            <token id="19" string="'s" />
            <token id="20" string="maiden" />
            <token id="21" string="voyage" />
            <token id="22" string="to" />
            <token id="23" string="Australia" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="mid-19th" />
            <token id="27" string="century" />
          </tokens>
        </chunking>
        <chunking id="15" string="an Australian heiress who meet on a steamship 's maiden voyage to Australia in the mid-19th century" type="NP">
          <tokens>
            <token id="11" string="an" />
            <token id="12" string="Australian" />
            <token id="13" string="heiress" />
            <token id="14" string="who" />
            <token id="15" string="meet" />
            <token id="16" string="on" />
            <token id="17" string="a" />
            <token id="18" string="steamship" />
            <token id="19" string="'s" />
            <token id="20" string="maiden" />
            <token id="21" string="voyage" />
            <token id="22" string="to" />
            <token id="23" string="Australia" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="mid-19th" />
            <token id="27" string="century" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">tells</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">tells</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">romance</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">romance</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">tells</governor>
          <dependent id="5">romance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">gambler</governor>
          <dependent id="6">between</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">gambler</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">gambler</governor>
          <dependent id="8">English</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">romance</governor>
          <dependent id="9">gambler</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">romance</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">heiress</governor>
          <dependent id="11">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">heiress</governor>
          <dependent id="12">Australian</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">romance</governor>
          <dependent id="13">heiress</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">meet</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">heiress</governor>
          <dependent id="15">meet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">voyage</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">steamship</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">voyage</governor>
          <dependent id="18">steamship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">steamship</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">voyage</governor>
          <dependent id="20">maiden</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">meet</governor>
          <dependent id="21">voyage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Australia</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">meet</governor>
          <dependent id="23">Australia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">century</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">century</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">century</governor>
          <dependent id="26">mid-19th</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">Australia</governor>
          <dependent id="27">century</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Australia" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Australia" />
          </tokens>
        </entity>
        <entity id="2" string="Australian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="Australian" />
          </tokens>
        </entity>
        <entity id="3" string="the mid-19th century" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="mid-19th" />
            <token id="27" string="century" />
          </tokens>
        </entity>
        <entity id="4" string="English" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="English" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>The story weaves in Australian history from its founding in 1788 by British immigrants.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="weaves" lemma="weave" stem="weav" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Australian" lemma="australian" stem="australian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="6" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="founding" lemma="founding" stem="found" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="1788" lemma="1788" stem="1788" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="14" string="immigrants" lemma="immigrant" stem="immigr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN story)) (VP (VBZ weaves) (PP (IN in) (NP (NP (JJ Australian) (NN history)) (PP (IN from) (NP (NP (PRP$ its) (NN founding)) (PP (IN in) (NP (CD 1788))))))) (PP (IN by) (NP (JJ British) (NNS immigrants)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="1788" type="NP">
          <tokens>
            <token id="11" string="1788" />
          </tokens>
        </chunking>
        <chunking id="2" string="Australian history" type="NP">
          <tokens>
            <token id="5" string="Australian" />
            <token id="6" string="history" />
          </tokens>
        </chunking>
        <chunking id="3" string="its founding in 1788" type="NP">
          <tokens>
            <token id="8" string="its" />
            <token id="9" string="founding" />
            <token id="10" string="in" />
            <token id="11" string="1788" />
          </tokens>
        </chunking>
        <chunking id="4" string="weaves in Australian history from its founding in 1788 by British immigrants" type="VP">
          <tokens>
            <token id="3" string="weaves" />
            <token id="4" string="in" />
            <token id="5" string="Australian" />
            <token id="6" string="history" />
            <token id="7" string="from" />
            <token id="8" string="its" />
            <token id="9" string="founding" />
            <token id="10" string="in" />
            <token id="11" string="1788" />
            <token id="12" string="by" />
            <token id="13" string="British" />
            <token id="14" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="5" string="British immigrants" type="NP">
          <tokens>
            <token id="13" string="British" />
            <token id="14" string="immigrants" />
          </tokens>
        </chunking>
        <chunking id="6" string="its founding" type="NP">
          <tokens>
            <token id="8" string="its" />
            <token id="9" string="founding" />
          </tokens>
        </chunking>
        <chunking id="7" string="The story" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="story" />
          </tokens>
        </chunking>
        <chunking id="8" string="Australian history from its founding in 1788" type="NP">
          <tokens>
            <token id="5" string="Australian" />
            <token id="6" string="history" />
            <token id="7" string="from" />
            <token id="8" string="its" />
            <token id="9" string="founding" />
            <token id="10" string="in" />
            <token id="11" string="1788" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">story</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">weaves</governor>
          <dependent id="2">story</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">weaves</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">history</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">history</governor>
          <dependent id="5">Australian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">weaves</governor>
          <dependent id="6">history</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">founding</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">founding</governor>
          <dependent id="8">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">history</governor>
          <dependent id="9">founding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">1788</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">founding</governor>
          <dependent id="11">1788</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">immigrants</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">immigrants</governor>
          <dependent id="13">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">weaves</governor>
          <dependent id="14">immigrants</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1788" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1788" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="13" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="Australian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="5" string="Australian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Panel chairman Michael Foot, a writer and former leader of the opposition Labor Party, said the judges agreed that entries this year had been ``exceptionally strong&amp;apost;&amp;apost; and that choosing the last six novels was extremely difficult.</content>
      <tokens>
        <token id="1" string="Panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="chairman" lemma="chairman" stem="chairman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Michael" lemma="Michael" stem="michael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Foot" lemma="Foot" stem="foot" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="writer" lemma="writer" stem="writer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="opposition" lemma="opposition" stem="opposit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="Labor" lemma="Labor" stem="labor" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="Party" lemma="Party" stem="parti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="agreed" lemma="agree" stem="agre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="entries" lemma="entry" stem="entri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="24" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="25" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="exceptionally" lemma="exceptionally" stem="exception" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="strong" lemma="strong" stem="strong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="choosing" lemma="choose" stem="choos" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="37" string="novels" lemma="novel" stem="novel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="extremely" lemma="extremely" stem="extrem" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="difficult" lemma="difficult" stem="difficult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Panel) (NN chairman) (NNP Michael) (NNP Foot)) (, ,) (NP (NP (DT a) (NX (NX (NN writer)) (CC and) (NX (JJ former) (NN leader)))) (PP (IN of) (NP (DT the) (NN opposition) (NNP Labor) (NNP Party)))) (, ,)) (VP (VBD said) (SBAR (S (NP (DT the) (NNS judges)) (VP (VBD agreed) (SBAR (SBAR (IN that) (S (NP (NNS entries)) (NP-TMP (DT this) (NN year)) (VP (VBD had) (VP (VBN been) (`` ``) (ADJP (RB exceptionally) (JJ strong)) ('' ''))))) (CC and) (SBAR (IN that) (S (S (VP (VBG choosing) (NP (DT the) (JJ last) (CD six) (NNS novels)))) (VP (VBD was) (ADJP (RB extremely) (JJ difficult)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="exceptionally strong" type="ADJP">
          <tokens>
            <token id="28" string="exceptionally" />
            <token id="29" string="strong" />
          </tokens>
        </chunking>
        <chunking id="2" string="Panel chairman Michael Foot" type="NP">
          <tokens>
            <token id="1" string="Panel" />
            <token id="2" string="chairman" />
            <token id="3" string="Michael" />
            <token id="4" string="Foot" />
          </tokens>
        </chunking>
        <chunking id="3" string="that choosing the last six novels was extremely difficult" type="SBAR">
          <tokens>
            <token id="32" string="that" />
            <token id="33" string="choosing" />
            <token id="34" string="the" />
            <token id="35" string="last" />
            <token id="36" string="six" />
            <token id="37" string="novels" />
            <token id="38" string="was" />
            <token id="39" string="extremely" />
            <token id="40" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="4" string="a writer and former leader of the opposition Labor Party" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="writer" />
            <token id="8" string="and" />
            <token id="9" string="former" />
            <token id="10" string="leader" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="opposition" />
            <token id="14" string="Labor" />
            <token id="15" string="Party" />
          </tokens>
        </chunking>
        <chunking id="5" string="choosing the last six novels" type="VP">
          <tokens>
            <token id="33" string="choosing" />
            <token id="34" string="the" />
            <token id="35" string="last" />
            <token id="36" string="six" />
            <token id="37" string="novels" />
          </tokens>
        </chunking>
        <chunking id="6" string="the judges agreed that entries this year had been `` exceptionally strong '' and that choosing the last six novels was extremely difficult" type="SBAR">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="judges" />
            <token id="20" string="agreed" />
            <token id="21" string="that" />
            <token id="22" string="entries" />
            <token id="23" string="this" />
            <token id="24" string="year" />
            <token id="25" string="had" />
            <token id="26" string="been" />
            <token id="27" string="``" />
            <token id="28" string="exceptionally" />
            <token id="29" string="strong" />
            <token id="30" string="''" />
            <token id="31" string="and" />
            <token id="32" string="that" />
            <token id="33" string="choosing" />
            <token id="34" string="the" />
            <token id="35" string="last" />
            <token id="36" string="six" />
            <token id="37" string="novels" />
            <token id="38" string="was" />
            <token id="39" string="extremely" />
            <token id="40" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="7" string="that entries this year had been `` exceptionally strong '' and that choosing the last six novels was extremely difficult" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="entries" />
            <token id="23" string="this" />
            <token id="24" string="year" />
            <token id="25" string="had" />
            <token id="26" string="been" />
            <token id="27" string="``" />
            <token id="28" string="exceptionally" />
            <token id="29" string="strong" />
            <token id="30" string="''" />
            <token id="31" string="and" />
            <token id="32" string="that" />
            <token id="33" string="choosing" />
            <token id="34" string="the" />
            <token id="35" string="last" />
            <token id="36" string="six" />
            <token id="37" string="novels" />
            <token id="38" string="was" />
            <token id="39" string="extremely" />
            <token id="40" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="8" string="was extremely difficult" type="VP">
          <tokens>
            <token id="38" string="was" />
            <token id="39" string="extremely" />
            <token id="40" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="9" string="entries" type="NP">
          <tokens>
            <token id="22" string="entries" />
          </tokens>
        </chunking>
        <chunking id="10" string="had been `` exceptionally strong ''" type="VP">
          <tokens>
            <token id="25" string="had" />
            <token id="26" string="been" />
            <token id="27" string="``" />
            <token id="28" string="exceptionally" />
            <token id="29" string="strong" />
            <token id="30" string="''" />
          </tokens>
        </chunking>
        <chunking id="11" string="the opposition Labor Party" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="opposition" />
            <token id="14" string="Labor" />
            <token id="15" string="Party" />
          </tokens>
        </chunking>
        <chunking id="12" string="a writer and former leader" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="writer" />
            <token id="8" string="and" />
            <token id="9" string="former" />
            <token id="10" string="leader" />
          </tokens>
        </chunking>
        <chunking id="13" string="said the judges agreed that entries this year had been `` exceptionally strong '' and that choosing the last six novels was extremely difficult" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="the" />
            <token id="19" string="judges" />
            <token id="20" string="agreed" />
            <token id="21" string="that" />
            <token id="22" string="entries" />
            <token id="23" string="this" />
            <token id="24" string="year" />
            <token id="25" string="had" />
            <token id="26" string="been" />
            <token id="27" string="``" />
            <token id="28" string="exceptionally" />
            <token id="29" string="strong" />
            <token id="30" string="''" />
            <token id="31" string="and" />
            <token id="32" string="that" />
            <token id="33" string="choosing" />
            <token id="34" string="the" />
            <token id="35" string="last" />
            <token id="36" string="six" />
            <token id="37" string="novels" />
            <token id="38" string="was" />
            <token id="39" string="extremely" />
            <token id="40" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="14" string="that entries this year had been `` exceptionally strong ''" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="entries" />
            <token id="23" string="this" />
            <token id="24" string="year" />
            <token id="25" string="had" />
            <token id="26" string="been" />
            <token id="27" string="``" />
            <token id="28" string="exceptionally" />
            <token id="29" string="strong" />
            <token id="30" string="''" />
          </tokens>
        </chunking>
        <chunking id="15" string="the judges" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="judges" />
          </tokens>
        </chunking>
        <chunking id="16" string="agreed that entries this year had been `` exceptionally strong '' and that choosing the last six novels was extremely difficult" type="VP">
          <tokens>
            <token id="20" string="agreed" />
            <token id="21" string="that" />
            <token id="22" string="entries" />
            <token id="23" string="this" />
            <token id="24" string="year" />
            <token id="25" string="had" />
            <token id="26" string="been" />
            <token id="27" string="``" />
            <token id="28" string="exceptionally" />
            <token id="29" string="strong" />
            <token id="30" string="''" />
            <token id="31" string="and" />
            <token id="32" string="that" />
            <token id="33" string="choosing" />
            <token id="34" string="the" />
            <token id="35" string="last" />
            <token id="36" string="six" />
            <token id="37" string="novels" />
            <token id="38" string="was" />
            <token id="39" string="extremely" />
            <token id="40" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="17" string="been `` exceptionally strong ''" type="VP">
          <tokens>
            <token id="26" string="been" />
            <token id="27" string="``" />
            <token id="28" string="exceptionally" />
            <token id="29" string="strong" />
            <token id="30" string="''" />
          </tokens>
        </chunking>
        <chunking id="18" string="Panel chairman Michael Foot , a writer and former leader of the opposition Labor Party ," type="NP">
          <tokens>
            <token id="1" string="Panel" />
            <token id="2" string="chairman" />
            <token id="3" string="Michael" />
            <token id="4" string="Foot" />
            <token id="5" string="," />
            <token id="6" string="a" />
            <token id="7" string="writer" />
            <token id="8" string="and" />
            <token id="9" string="former" />
            <token id="10" string="leader" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="opposition" />
            <token id="14" string="Labor" />
            <token id="15" string="Party" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="19" string="extremely difficult" type="ADJP">
          <tokens>
            <token id="39" string="extremely" />
            <token id="40" string="difficult" />
          </tokens>
        </chunking>
        <chunking id="20" string="the last six novels" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="last" />
            <token id="36" string="six" />
            <token id="37" string="novels" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Foot</governor>
          <dependent id="1">Panel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Foot</governor>
          <dependent id="2">chairman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Foot</governor>
          <dependent id="3">Michael</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="4">Foot</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">writer</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Foot</governor>
          <dependent id="7">writer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">writer</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">leader</governor>
          <dependent id="9">former</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">writer</governor>
          <dependent id="10">leader</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Party</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Party</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Party</governor>
          <dependent id="13">opposition</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Party</governor>
          <dependent id="14">Labor</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">writer</governor>
          <dependent id="15">Party</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">judges</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">agreed</governor>
          <dependent id="19">judges</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="20">agreed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">strong</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">strong</governor>
          <dependent id="22">entries</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">year</governor>
          <dependent id="23">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="29">strong</governor>
          <dependent id="24">year</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">strong</governor>
          <dependent id="25">had</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="29">strong</governor>
          <dependent id="26">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">strong</governor>
          <dependent id="28">exceptionally</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">agreed</governor>
          <dependent id="29">strong</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">strong</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">difficult</governor>
          <dependent id="32">that</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="40">difficult</governor>
          <dependent id="33">choosing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">novels</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">novels</governor>
          <dependent id="35">last</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="37">novels</governor>
          <dependent id="36">six</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">choosing</governor>
          <dependent id="37">novels</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="40">difficult</governor>
          <dependent id="38">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">difficult</governor>
          <dependent id="39">extremely</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">strong</governor>
          <dependent id="40">difficult</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="36" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="Michael Foot" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Michael" />
            <token id="4" string="Foot" />
          </tokens>
        </entity>
        <entity id="3" string="Labor Party" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Labor" />
            <token id="15" string="Party" />
          </tokens>
        </entity>
        <entity id="4" string="this year" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="this" />
            <token id="24" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``We hope there will be no criticisms but if there are, then people should start reading the books for themselves,&amp;apost;&amp;apost; Foot said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="hope" lemma="hope" stem="hope" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="criticisms" lemma="criticism" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="start" lemma="start" stem="start" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="reading" lemma="read" stem="read" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Foot" lemma="Foot" stem="foot" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP We)) (VP (VBP hope) (SBAR (SBAR (S (NP (EX there)) (VP (MD will) (VP (VB be) (NP (DT no) (NNS criticisms)))))) (CC but) (SBAR (IN if) (S (NP (EX there)) (VP (VBP are))))))) (, ,) (RB then) (S (NP (NNS people)) (VP (MD should) (VP (VB start) (S (VP (VBG reading) (NP (DT the) (NNS books)) (PP (IN for) (NP (PRP themselves))))))))) (, ,) ('' '') (NP (NNP Foot)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there will be no criticisms but if there are" type="SBAR">
          <tokens>
            <token id="4" string="there" />
            <token id="5" string="will" />
            <token id="6" string="be" />
            <token id="7" string="no" />
            <token id="8" string="criticisms" />
            <token id="9" string="but" />
            <token id="10" string="if" />
            <token id="11" string="there" />
            <token id="12" string="are" />
          </tokens>
        </chunking>
        <chunking id="2" string="start reading the books for themselves" type="VP">
          <tokens>
            <token id="17" string="start" />
            <token id="18" string="reading" />
            <token id="19" string="the" />
            <token id="20" string="books" />
            <token id="21" string="for" />
            <token id="22" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="3" string="there will be no criticisms" type="SBAR">
          <tokens>
            <token id="4" string="there" />
            <token id="5" string="will" />
            <token id="6" string="be" />
            <token id="7" string="no" />
            <token id="8" string="criticisms" />
          </tokens>
        </chunking>
        <chunking id="4" string="no criticisms" type="NP">
          <tokens>
            <token id="7" string="no" />
            <token id="8" string="criticisms" />
          </tokens>
        </chunking>
        <chunking id="5" string="people" type="NP">
          <tokens>
            <token id="15" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="Foot" type="NP">
          <tokens>
            <token id="25" string="Foot" />
          </tokens>
        </chunking>
        <chunking id="7" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="8" string="hope there will be no criticisms but if there are" type="VP">
          <tokens>
            <token id="3" string="hope" />
            <token id="4" string="there" />
            <token id="5" string="will" />
            <token id="6" string="be" />
            <token id="7" string="no" />
            <token id="8" string="criticisms" />
            <token id="9" string="but" />
            <token id="10" string="if" />
            <token id="11" string="there" />
            <token id="12" string="are" />
          </tokens>
        </chunking>
        <chunking id="9" string="reading the books for themselves" type="VP">
          <tokens>
            <token id="18" string="reading" />
            <token id="19" string="the" />
            <token id="20" string="books" />
            <token id="21" string="for" />
            <token id="22" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="10" string="be no criticisms" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="no" />
            <token id="8" string="criticisms" />
          </tokens>
        </chunking>
        <chunking id="11" string="there" type="NP">
          <tokens>
            <token id="4" string="there" />
          </tokens>
        </chunking>
        <chunking id="12" string="are" type="VP">
          <tokens>
            <token id="12" string="are" />
          </tokens>
        </chunking>
        <chunking id="13" string="themselves" type="NP">
          <tokens>
            <token id="22" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="14" string="if there are" type="SBAR">
          <tokens>
            <token id="10" string="if" />
            <token id="11" string="there" />
            <token id="12" string="are" />
          </tokens>
        </chunking>
        <chunking id="15" string="should start reading the books for themselves" type="VP">
          <tokens>
            <token id="16" string="should" />
            <token id="17" string="start" />
            <token id="18" string="reading" />
            <token id="19" string="the" />
            <token id="20" string="books" />
            <token id="21" string="for" />
            <token id="22" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="16" string="the books" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="books" />
          </tokens>
        </chunking>
        <chunking id="17" string="will be no criticisms" type="VP">
          <tokens>
            <token id="5" string="will" />
            <token id="6" string="be" />
            <token id="7" string="no" />
            <token id="8" string="criticisms" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="26" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">hope</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">said</governor>
          <dependent id="3">hope</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="8">criticisms</governor>
          <dependent id="4">there</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">criticisms</governor>
          <dependent id="5">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">criticisms</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">criticisms</governor>
          <dependent id="7">no</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">hope</governor>
          <dependent id="8">criticisms</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">criticisms</governor>
          <dependent id="9">but</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">are</governor>
          <dependent id="10">if</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="12">are</governor>
          <dependent id="11">there</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">criticisms</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">start</governor>
          <dependent id="14">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">start</governor>
          <dependent id="15">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">start</governor>
          <dependent id="16">should</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">hope</governor>
          <dependent id="17">start</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">start</governor>
          <dependent id="18">reading</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">books</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">reading</governor>
          <dependent id="20">books</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">themselves</governor>
          <dependent id="21">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">reading</governor>
          <dependent id="22">themselves</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">said</governor>
          <dependent id="25">Foot</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Foot" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Foot" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Carey was the only non-Briton in the final six.</content>
      <tokens>
        <token id="1" string="Carey" lemma="Carey" stem="carei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="non-Briton" lemma="non-briton" stem="non-briton" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Carey)) (VP (VBD was) (NP (NP (DT the) (JJ only) (NN non-Briton)) (PP (IN in) (NP (DT the) (JJ final) (CD six))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the final six" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="final" />
            <token id="9" string="six" />
          </tokens>
        </chunking>
        <chunking id="2" string="the only non-Briton" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="only" />
            <token id="5" string="non-Briton" />
          </tokens>
        </chunking>
        <chunking id="3" string="the only non-Briton in the final six" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="only" />
            <token id="5" string="non-Briton" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="final" />
            <token id="9" string="six" />
          </tokens>
        </chunking>
        <chunking id="4" string="Carey" type="NP">
          <tokens>
            <token id="1" string="Carey" />
          </tokens>
        </chunking>
        <chunking id="5" string="was the only non-Briton in the final six" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="the" />
            <token id="4" string="only" />
            <token id="5" string="non-Briton" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="final" />
            <token id="9" string="six" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">non-Briton</governor>
          <dependent id="1">Carey</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">non-Briton</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">non-Briton</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">non-Briton</governor>
          <dependent id="4">only</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">non-Briton</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">six</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">six</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">six</governor>
          <dependent id="8">final</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">non-Briton</governor>
          <dependent id="9">six</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="non-Briton" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="non-Briton" />
          </tokens>
        </entity>
        <entity id="3" string="Carey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Carey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="false">
      <content>The son of an auto dealer, he was born in Bacchus Marsh, Victoria, and attended Geelong Church of England Grammar School, Melbourne, where the Prince of Wales was also a pupil as an 18-year-old in 1966.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="auto" lemma="auto" stem="auto" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="dealer" lemma="dealer" stem="dealer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Bacchus" lemma="Bacchus" stem="bacchu" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="Marsh" lemma="Marsh" stem="marsh" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Victoria" lemma="Victoria" stem="victoria" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="attended" lemma="attend" stem="attend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Geelong" lemma="Geelong" stem="geelong" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Church" lemma="Church" stem="church" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="England" lemma="England" stem="england" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Grammar" lemma="Grammar" stem="grammar" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="School" lemma="School" stem="school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Melbourne" lemma="Melbourne" stem="melbourn" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Prince" lemma="Prince" stem="princ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="32" string="Wales" lemma="Wales" stem="wale" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="33" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="pupil" lemma="pupil" stem="pupil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="18-year-old" lemma="18-year-old" stem="18-year-old" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="40" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="41" string="1966" lemma="1966" stem="1966" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN son)) (PP (IN of) (NP (DT an) (NN auto) (NN dealer))))) (, ,) (NP (PRP he)) (VP (VP (VBD was) (VP (VBN born) (PP (IN in) (NP (NP (NNP Bacchus) (NNP Marsh)) (, ,) (NP (NNP Victoria)) (, ,))))) (CC and) (VP (VBD attended) (NP (NP (NNP Geelong) (NNP Church)) (PP (IN of) (NP (NP (NNP England) (NNP Grammar) (NNP School)) (, ,) (NP (NNP Melbourne)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NP (DT the) (NNP Prince)) (PP (IN of) (NP (NNP Wales)))) (VP (VBD was) (ADVP (RB also)) (NP (NP (DT a) (NN pupil)) (PP (IN as) (NP (NP (DT an) (JJ 18-year-old)) (PP (IN in) (NP (CD 1966)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Geelong Church of England Grammar School , Melbourne , where the Prince of Wales was also a pupil as an 18-year-old in 1966" type="NP">
          <tokens>
            <token id="19" string="Geelong" />
            <token id="20" string="Church" />
            <token id="21" string="of" />
            <token id="22" string="England" />
            <token id="23" string="Grammar" />
            <token id="24" string="School" />
            <token id="25" string="," />
            <token id="26" string="Melbourne" />
            <token id="27" string="," />
            <token id="28" string="where" />
            <token id="29" string="the" />
            <token id="30" string="Prince" />
            <token id="31" string="of" />
            <token id="32" string="Wales" />
            <token id="33" string="was" />
            <token id="34" string="also" />
            <token id="35" string="a" />
            <token id="36" string="pupil" />
            <token id="37" string="as" />
            <token id="38" string="an" />
            <token id="39" string="18-year-old" />
            <token id="40" string="in" />
            <token id="41" string="1966" />
          </tokens>
        </chunking>
        <chunking id="2" string="The son" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="son" />
          </tokens>
        </chunking>
        <chunking id="3" string="England Grammar School" type="NP">
          <tokens>
            <token id="22" string="England" />
            <token id="23" string="Grammar" />
            <token id="24" string="School" />
          </tokens>
        </chunking>
        <chunking id="4" string="was born in Bacchus Marsh , Victoria ," type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="born" />
            <token id="11" string="in" />
            <token id="12" string="Bacchus" />
            <token id="13" string="Marsh" />
            <token id="14" string="," />
            <token id="15" string="Victoria" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="an auto dealer" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="auto" />
            <token id="6" string="dealer" />
          </tokens>
        </chunking>
        <chunking id="6" string="Victoria" type="NP">
          <tokens>
            <token id="15" string="Victoria" />
          </tokens>
        </chunking>
        <chunking id="7" string="where the Prince of Wales was also a pupil as an 18-year-old in 1966" type="SBAR">
          <tokens>
            <token id="28" string="where" />
            <token id="29" string="the" />
            <token id="30" string="Prince" />
            <token id="31" string="of" />
            <token id="32" string="Wales" />
            <token id="33" string="was" />
            <token id="34" string="also" />
            <token id="35" string="a" />
            <token id="36" string="pupil" />
            <token id="37" string="as" />
            <token id="38" string="an" />
            <token id="39" string="18-year-old" />
            <token id="40" string="in" />
            <token id="41" string="1966" />
          </tokens>
        </chunking>
        <chunking id="8" string="1966" type="NP">
          <tokens>
            <token id="41" string="1966" />
          </tokens>
        </chunking>
        <chunking id="9" string="was born in Bacchus Marsh , Victoria , and attended Geelong Church of England Grammar School , Melbourne , where the Prince of Wales was also a pupil as an 18-year-old in 1966" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="born" />
            <token id="11" string="in" />
            <token id="12" string="Bacchus" />
            <token id="13" string="Marsh" />
            <token id="14" string="," />
            <token id="15" string="Victoria" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="attended" />
            <token id="19" string="Geelong" />
            <token id="20" string="Church" />
            <token id="21" string="of" />
            <token id="22" string="England" />
            <token id="23" string="Grammar" />
            <token id="24" string="School" />
            <token id="25" string="," />
            <token id="26" string="Melbourne" />
            <token id="27" string="," />
            <token id="28" string="where" />
            <token id="29" string="the" />
            <token id="30" string="Prince" />
            <token id="31" string="of" />
            <token id="32" string="Wales" />
            <token id="33" string="was" />
            <token id="34" string="also" />
            <token id="35" string="a" />
            <token id="36" string="pupil" />
            <token id="37" string="as" />
            <token id="38" string="an" />
            <token id="39" string="18-year-old" />
            <token id="40" string="in" />
            <token id="41" string="1966" />
          </tokens>
        </chunking>
        <chunking id="10" string="born in Bacchus Marsh , Victoria ," type="VP">
          <tokens>
            <token id="10" string="born" />
            <token id="11" string="in" />
            <token id="12" string="Bacchus" />
            <token id="13" string="Marsh" />
            <token id="14" string="," />
            <token id="15" string="Victoria" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="Bacchus Marsh , Victoria ," type="NP">
          <tokens>
            <token id="12" string="Bacchus" />
            <token id="13" string="Marsh" />
            <token id="14" string="," />
            <token id="15" string="Victoria" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="Bacchus Marsh" type="NP">
          <tokens>
            <token id="12" string="Bacchus" />
            <token id="13" string="Marsh" />
          </tokens>
        </chunking>
        <chunking id="14" string="England Grammar School , Melbourne , where the Prince of Wales was also a pupil as an 18-year-old in 1966" type="NP">
          <tokens>
            <token id="22" string="England" />
            <token id="23" string="Grammar" />
            <token id="24" string="School" />
            <token id="25" string="," />
            <token id="26" string="Melbourne" />
            <token id="27" string="," />
            <token id="28" string="where" />
            <token id="29" string="the" />
            <token id="30" string="Prince" />
            <token id="31" string="of" />
            <token id="32" string="Wales" />
            <token id="33" string="was" />
            <token id="34" string="also" />
            <token id="35" string="a" />
            <token id="36" string="pupil" />
            <token id="37" string="as" />
            <token id="38" string="an" />
            <token id="39" string="18-year-old" />
            <token id="40" string="in" />
            <token id="41" string="1966" />
          </tokens>
        </chunking>
        <chunking id="15" string="an 18-year-old" type="NP">
          <tokens>
            <token id="38" string="an" />
            <token id="39" string="18-year-old" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Prince of Wales" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Prince" />
            <token id="31" string="of" />
            <token id="32" string="Wales" />
          </tokens>
        </chunking>
        <chunking id="17" string="a pupil as an 18-year-old in 1966" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="pupil" />
            <token id="37" string="as" />
            <token id="38" string="an" />
            <token id="39" string="18-year-old" />
            <token id="40" string="in" />
            <token id="41" string="1966" />
          </tokens>
        </chunking>
        <chunking id="18" string="Geelong Church" type="NP">
          <tokens>
            <token id="19" string="Geelong" />
            <token id="20" string="Church" />
          </tokens>
        </chunking>
        <chunking id="19" string="an 18-year-old in 1966" type="NP">
          <tokens>
            <token id="38" string="an" />
            <token id="39" string="18-year-old" />
            <token id="40" string="in" />
            <token id="41" string="1966" />
          </tokens>
        </chunking>
        <chunking id="20" string="Melbourne" type="NP">
          <tokens>
            <token id="26" string="Melbourne" />
          </tokens>
        </chunking>
        <chunking id="21" string="attended Geelong Church of England Grammar School , Melbourne , where the Prince of Wales was also a pupil as an 18-year-old in 1966" type="VP">
          <tokens>
            <token id="18" string="attended" />
            <token id="19" string="Geelong" />
            <token id="20" string="Church" />
            <token id="21" string="of" />
            <token id="22" string="England" />
            <token id="23" string="Grammar" />
            <token id="24" string="School" />
            <token id="25" string="," />
            <token id="26" string="Melbourne" />
            <token id="27" string="," />
            <token id="28" string="where" />
            <token id="29" string="the" />
            <token id="30" string="Prince" />
            <token id="31" string="of" />
            <token id="32" string="Wales" />
            <token id="33" string="was" />
            <token id="34" string="also" />
            <token id="35" string="a" />
            <token id="36" string="pupil" />
            <token id="37" string="as" />
            <token id="38" string="an" />
            <token id="39" string="18-year-old" />
            <token id="40" string="in" />
            <token id="41" string="1966" />
          </tokens>
        </chunking>
        <chunking id="22" string="a pupil" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="pupil" />
          </tokens>
        </chunking>
        <chunking id="23" string="was also a pupil as an 18-year-old in 1966" type="VP">
          <tokens>
            <token id="33" string="was" />
            <token id="34" string="also" />
            <token id="35" string="a" />
            <token id="36" string="pupil" />
            <token id="37" string="as" />
            <token id="38" string="an" />
            <token id="39" string="18-year-old" />
            <token id="40" string="in" />
            <token id="41" string="1966" />
          </tokens>
        </chunking>
        <chunking id="24" string="Wales" type="NP">
          <tokens>
            <token id="32" string="Wales" />
          </tokens>
        </chunking>
        <chunking id="25" string="the Prince" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="Prince" />
          </tokens>
        </chunking>
        <chunking id="26" string="where" type="WHADVP">
          <tokens>
            <token id="28" string="where" />
          </tokens>
        </chunking>
        <chunking id="27" string="The son of an auto dealer" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="son" />
            <token id="3" string="of" />
            <token id="4" string="an" />
            <token id="5" string="auto" />
            <token id="6" string="dealer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">son</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">born</governor>
          <dependent id="2">son</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">dealer</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">dealer</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">dealer</governor>
          <dependent id="5">auto</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">son</governor>
          <dependent id="6">dealer</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">born</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">born</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">born</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Marsh</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Marsh</governor>
          <dependent id="12">Bacchus</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">born</governor>
          <dependent id="13">Marsh</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Marsh</governor>
          <dependent id="15">Victoria</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">born</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">born</governor>
          <dependent id="18">attended</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Church</governor>
          <dependent id="19">Geelong</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">attended</governor>
          <dependent id="20">Church</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">School</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">School</governor>
          <dependent id="22">England</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">School</governor>
          <dependent id="23">Grammar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Church</governor>
          <dependent id="24">School</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">School</governor>
          <dependent id="26">Melbourne</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">pupil</governor>
          <dependent id="28">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">Prince</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">pupil</governor>
          <dependent id="30">Prince</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Wales</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">Prince</governor>
          <dependent id="32">Wales</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="36">pupil</governor>
          <dependent id="33">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">pupil</governor>
          <dependent id="34">also</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">pupil</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">School</governor>
          <dependent id="36">pupil</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">18-year-old</governor>
          <dependent id="37">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">18-year-old</governor>
          <dependent id="38">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">pupil</governor>
          <dependent id="39">18-year-old</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">1966</governor>
          <dependent id="40">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">18-year-old</governor>
          <dependent id="41">1966</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bacchus Marsh" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Bacchus" />
            <token id="13" string="Marsh" />
          </tokens>
        </entity>
        <entity id="2" string="Geelong Church of England Grammar School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Geelong" />
            <token id="20" string="Church" />
            <token id="21" string="of" />
            <token id="22" string="England" />
            <token id="23" string="Grammar" />
            <token id="24" string="School" />
          </tokens>
        </entity>
        <entity id="3" string="Victoria" type="LOCATION" score="0.0">
          <tokens>
            <token id="15" string="Victoria" />
          </tokens>
        </entity>
        <entity id="4" string="18-year-old in 1966" type="DATE" score="0.0">
          <tokens>
            <token id="39" string="18-year-old" />
            <token id="40" string="in" />
            <token id="41" string="1966" />
          </tokens>
        </entity>
        <entity id="5" string="Prince of Wales" type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="Prince" />
            <token id="31" string="of" />
            <token id="32" string="Wales" />
          </tokens>
        </entity>
        <entity id="6" string="Melbourne" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Melbourne" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Carey was an advertising copywriter before turning to writing books in 1965.</content>
      <tokens>
        <token id="1" string="Carey" lemma="Carey" stem="carei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="advertising" lemma="advertising" stem="advertis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="copywriter" lemma="copywriter" stem="copywrit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="turning" lemma="turn" stem="turn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="writing" lemma="write" stem="write" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="1965" lemma="1965" stem="1965" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Carey)) (VP (VBD was) (NP (DT an) (NN advertising) (NN copywriter)) (PP (IN before) (S (VP (VBG turning) (PP (TO to) (S (VP (VBG writing) (NP (NNS books)) (PP (IN in) (NP (CD 1965)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="books" type="NP">
          <tokens>
            <token id="10" string="books" />
          </tokens>
        </chunking>
        <chunking id="2" string="1965" type="NP">
          <tokens>
            <token id="12" string="1965" />
          </tokens>
        </chunking>
        <chunking id="3" string="an advertising copywriter" type="NP">
          <tokens>
            <token id="3" string="an" />
            <token id="4" string="advertising" />
            <token id="5" string="copywriter" />
          </tokens>
        </chunking>
        <chunking id="4" string="writing books in 1965" type="VP">
          <tokens>
            <token id="9" string="writing" />
            <token id="10" string="books" />
            <token id="11" string="in" />
            <token id="12" string="1965" />
          </tokens>
        </chunking>
        <chunking id="5" string="Carey" type="NP">
          <tokens>
            <token id="1" string="Carey" />
          </tokens>
        </chunking>
        <chunking id="6" string="turning to writing books in 1965" type="VP">
          <tokens>
            <token id="7" string="turning" />
            <token id="8" string="to" />
            <token id="9" string="writing" />
            <token id="10" string="books" />
            <token id="11" string="in" />
            <token id="12" string="1965" />
          </tokens>
        </chunking>
        <chunking id="7" string="was an advertising copywriter before turning to writing books in 1965" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="an" />
            <token id="4" string="advertising" />
            <token id="5" string="copywriter" />
            <token id="6" string="before" />
            <token id="7" string="turning" />
            <token id="8" string="to" />
            <token id="9" string="writing" />
            <token id="10" string="books" />
            <token id="11" string="in" />
            <token id="12" string="1965" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">copywriter</governor>
          <dependent id="1">Carey</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">copywriter</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">copywriter</governor>
          <dependent id="3">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">copywriter</governor>
          <dependent id="4">advertising</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">copywriter</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">turning</governor>
          <dependent id="6">before</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">copywriter</governor>
          <dependent id="7">turning</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">writing</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">turning</governor>
          <dependent id="9">writing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">writing</governor>
          <dependent id="10">books</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">1965</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">writing</governor>
          <dependent id="12">1965</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1965" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1965" />
          </tokens>
        </entity>
        <entity id="2" string="Carey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Carey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>The first Booker Prize was awarded in 1969.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="3" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="4" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="awarded" lemma="award" stem="award" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="1969" lemma="1969" stem="1969" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ first) (NNP Booker) (NNP Prize)) (VP (VBD was) (VP (VBN awarded) (PP (IN in) (NP (CD 1969))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was awarded in 1969" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="awarded" />
            <token id="7" string="in" />
            <token id="8" string="1969" />
          </tokens>
        </chunking>
        <chunking id="2" string="awarded in 1969" type="VP">
          <tokens>
            <token id="6" string="awarded" />
            <token id="7" string="in" />
            <token id="8" string="1969" />
          </tokens>
        </chunking>
        <chunking id="3" string="The first Booker Prize" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="first" />
            <token id="3" string="Booker" />
            <token id="4" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="4" string="1969" type="NP">
          <tokens>
            <token id="8" string="1969" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">Prize</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">Prize</governor>
          <dependent id="2">first</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Prize</governor>
          <dependent id="3">Booker</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">awarded</governor>
          <dependent id="4">Prize</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">awarded</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">awarded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1969</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">awarded</governor>
          <dependent id="8">1969</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="2" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Booker" />
            <token id="4" string="Prize" />
          </tokens>
        </entity>
        <entity id="3" string="1969" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="1969" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>It is administered by Book Trust, an educational charity promoting books, and is sponsored by Booker, an international food and farming business.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="administered" lemma="administer" stem="administ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Book" lemma="Book" stem="book" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="6" string="Trust" lemma="Trust" stem="trust" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="educational" lemma="educational" stem="educ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="charity" lemma="charity" stem="chariti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="promoting" lemma="promote" stem="promot" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="sponsored" lemma="sponsor" stem="sponsor" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="international" lemma="international" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="food" lemma="food" stem="food" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="farming" lemma="farming" stem="farm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VP (VBZ is) (VP (VBN administered) (PP (IN by) (NP (NP (NNP Book) (NNP Trust)) (, ,) (NP (NP (DT an) (JJ educational) (NN charity)) (VP (VBG promoting) (NP (NNS books)))))))) (, ,) (CC and) (VP (VBZ is) (VP (VBN sponsored) (PP (IN by) (NP (NP (NNP Booker)) (, ,) (NP (DT an) (JJ international) (NN food)) (CC and) (NP (NN farming) (NN business))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is administered by Book Trust , an educational charity promoting books" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="administered" />
            <token id="4" string="by" />
            <token id="5" string="Book" />
            <token id="6" string="Trust" />
            <token id="7" string="," />
            <token id="8" string="an" />
            <token id="9" string="educational" />
            <token id="10" string="charity" />
            <token id="11" string="promoting" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="2" string="Booker" type="NP">
          <tokens>
            <token id="18" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="3" string="an educational charity" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="educational" />
            <token id="10" string="charity" />
          </tokens>
        </chunking>
        <chunking id="4" string="is administered by Book Trust , an educational charity promoting books , and is sponsored by Booker , an international food and farming business" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="administered" />
            <token id="4" string="by" />
            <token id="5" string="Book" />
            <token id="6" string="Trust" />
            <token id="7" string="," />
            <token id="8" string="an" />
            <token id="9" string="educational" />
            <token id="10" string="charity" />
            <token id="11" string="promoting" />
            <token id="12" string="books" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="is" />
            <token id="16" string="sponsored" />
            <token id="17" string="by" />
            <token id="18" string="Booker" />
            <token id="19" string="," />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="food" />
            <token id="23" string="and" />
            <token id="24" string="farming" />
            <token id="25" string="business" />
          </tokens>
        </chunking>
        <chunking id="5" string="Book Trust" type="NP">
          <tokens>
            <token id="5" string="Book" />
            <token id="6" string="Trust" />
          </tokens>
        </chunking>
        <chunking id="6" string="promoting books" type="VP">
          <tokens>
            <token id="11" string="promoting" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="is sponsored by Booker , an international food and farming business" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="sponsored" />
            <token id="17" string="by" />
            <token id="18" string="Booker" />
            <token id="19" string="," />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="food" />
            <token id="23" string="and" />
            <token id="24" string="farming" />
            <token id="25" string="business" />
          </tokens>
        </chunking>
        <chunking id="9" string="an educational charity promoting books" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="educational" />
            <token id="10" string="charity" />
            <token id="11" string="promoting" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="10" string="books" type="NP">
          <tokens>
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="11" string="Booker , an international food and farming business" type="NP">
          <tokens>
            <token id="18" string="Booker" />
            <token id="19" string="," />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="food" />
            <token id="23" string="and" />
            <token id="24" string="farming" />
            <token id="25" string="business" />
          </tokens>
        </chunking>
        <chunking id="12" string="an international food" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="food" />
          </tokens>
        </chunking>
        <chunking id="13" string="Book Trust , an educational charity promoting books" type="NP">
          <tokens>
            <token id="5" string="Book" />
            <token id="6" string="Trust" />
            <token id="7" string="," />
            <token id="8" string="an" />
            <token id="9" string="educational" />
            <token id="10" string="charity" />
            <token id="11" string="promoting" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
        <chunking id="14" string="sponsored by Booker , an international food and farming business" type="VP">
          <tokens>
            <token id="16" string="sponsored" />
            <token id="17" string="by" />
            <token id="18" string="Booker" />
            <token id="19" string="," />
            <token id="20" string="an" />
            <token id="21" string="international" />
            <token id="22" string="food" />
            <token id="23" string="and" />
            <token id="24" string="farming" />
            <token id="25" string="business" />
          </tokens>
        </chunking>
        <chunking id="15" string="farming business" type="NP">
          <tokens>
            <token id="24" string="farming" />
            <token id="25" string="business" />
          </tokens>
        </chunking>
        <chunking id="16" string="administered by Book Trust , an educational charity promoting books" type="VP">
          <tokens>
            <token id="3" string="administered" />
            <token id="4" string="by" />
            <token id="5" string="Book" />
            <token id="6" string="Trust" />
            <token id="7" string="," />
            <token id="8" string="an" />
            <token id="9" string="educational" />
            <token id="10" string="charity" />
            <token id="11" string="promoting" />
            <token id="12" string="books" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">administered</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">administered</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">administered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Trust</governor>
          <dependent id="4">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Trust</governor>
          <dependent id="5">Book</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">administered</governor>
          <dependent id="6">Trust</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">charity</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">charity</governor>
          <dependent id="9">educational</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">Trust</governor>
          <dependent id="10">charity</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">charity</governor>
          <dependent id="11">promoting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">promoting</governor>
          <dependent id="12">books</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">administered</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">sponsored</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">administered</governor>
          <dependent id="16">sponsored</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Booker</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">sponsored</governor>
          <dependent id="18">Booker</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">food</governor>
          <dependent id="20">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">food</governor>
          <dependent id="21">international</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">Booker</governor>
          <dependent id="22">food</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">Booker</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">business</governor>
          <dependent id="24">farming</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">Booker</governor>
          <dependent id="25">business</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Booker" />
          </tokens>
        </entity>
        <entity id="2" string="Book Trust" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Book" />
            <token id="6" string="Trust" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="Australian novelist Peter Carey" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-11" string="Carey , who lives in Sydney with his wife and son" id_sentence="4" />
        <mention ids_tokens="1" string="Carey" id_sentence="4" />
        <mention ids_tokens="8" string="his" id_sentence="4" />
        <mention ids_tokens="24" string="he" id_sentence="4" />
        <mention ids_tokens="35" string="his" id_sentence="4" />
        <mention ids_tokens="39" string="he" id_sentence="4" />
        <mention ids_tokens="3" string="I" id_sentence="5" />
        <mention ids_tokens="6" string="I" id_sentence="5" />
        <mention ids_tokens="11" string="I" id_sentence="5" />
        <mention ids_tokens="13" string="I" id_sentence="5" />
        <mention ids_tokens="22" string="my" id_sentence="5" />
        <mention ids_tokens="26" string="he" id_sentence="5" />
        <mention ids_tokens="29" string="he" id_sentence="5" />
        <mention ids_tokens="33" string="his" id_sentence="5" />
        <mention ids_tokens="1" string="He" id_sentence="6" />
        <mention ids_tokens="11" string="his" id_sentence="6" />
        <mention ids_tokens="1" string="Carey" id_sentence="7" />
        <mention ids_tokens="11" string="he" id_sentence="7" />
        <mention ids_tokens="1" string="Carey" id_sentence="14" />
        <mention ids_tokens="3-9" string="the only non-Briton in the final six" id_sentence="14" />
        <mention ids_tokens="1" string="Carey" id_sentence="16" />
        <mention ids_tokens="3-5" string="an advertising copywriter" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="The first Booker Prize" id_sentence="17" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="16-17-18" string="his love story" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-2" string="The story" id_sentence="11" />
        <mention ids_tokens="8" string="its" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="4-5" string="five judges" id_sentence="2" />
      <mentions>
        <mention ids_tokens="1-2" string="The judges" id_sentence="3" />
        <mention ids_tokens="4" string="their" id_sentence="3" />
        <mention ids_tokens="19" string="they" id_sentence="3" />
        <mention ids_tokens="22" string="their" id_sentence="3" />
        <mention ids_tokens="18-19" string="the judges" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13-14" string="the award of the $ 26,250 prize" id_sentence="2" />
      <mentions>
        <mention ids_tokens="3-4" string="the award" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23" string="102 books published in Britain in the past 12 months and which they read in their homes" id_sentence="3" />
      <mentions>
        <mention ids_tokens="19-20" string="the books" id_sentence="13" />
        <mention ids_tokens="10" string="books" id_sentence="16" />
        <mention ids_tokens="12" string="books" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="20-21-22" string="the final six" id_sentence="6" />
      <mentions>
        <mention ids_tokens="36" string="six" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="The winning novel" id_sentence="9" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="9-10-11-12" string="Australia 's bicentennial year" id_sentence="9" />
      <mentions>
        <mention ids_tokens="23-24" string="this year" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="3-4" string="Michael Foot" id_sentence="12" />
      <mentions>
        <mention ids_tokens="25" string="Foot" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="14" type="LIST">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15" string="Panel chairman Michael Foot , a writer and former leader of the opposition Labor Party" id_sentence="12" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="13" />
      </mentions>
    </coreference>
  </coreferences>
</document>
