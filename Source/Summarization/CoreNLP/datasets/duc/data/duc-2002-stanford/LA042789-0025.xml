<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA042789-0025">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Lucille Ball, the leggy showgirl, model and B-grade movie queen whose pumpkin hair and genius for comedy made her an icon of television, died early Wednesday, a week after undergoing emergency heart surgery.</content>
      <tokens>
        <token id="1" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="leggy" lemma="leggy" stem="leggi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="showgirl" lemma="showgirl" stem="showgirl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="model" lemma="model" stem="model" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="B-grade" lemma="b-grade" stem="b-grade" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="queen" lemma="queen" stem="queen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="pumpkin" lemma="pumpkin" stem="pumpkin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="hair" lemma="hair" stem="hair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="genius" lemma="genius" stem="geniu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="comedy" lemma="comedy" stem="comedi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="20" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="icon" lemma="icon" stem="icon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="29" string="Wednesday" lemma="Wednesday" stem="wednesdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="32" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="33" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="undergoing" lemma="undergo" stem="undergo" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="emergency" lemma="emergency" stem="emerg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Lucille) (NNP Ball)) (, ,) (NP (NP (DT the) (JJ leggy) (NN showgirl) (, ,) (NN model) (CC and) (NN B-grade) (NN movie) (NN queen)) (SBAR (WHNP (WP$ whose) (NP (NP (NN pumpkin) (NN hair)) (CC and) (NP (NP (NN genius)) (PP (IN for) (NP (NN comedy)))))) (S (VP (VBD made) (NP (PRP$ her)) (NP (NP (DT an) (NN icon)) (PP (IN of) (NP (NN television)))))))) (, ,)) (VP (VP (VBD died) (NP-TMP (JJ early) (NNP Wednesday))) (, ,) (NP (NP (DT a) (NN week)) (PP (IN after) (S (VP (VBG undergoing) (NP (NN emergency) (NN heart) (NN surgery))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the leggy showgirl , model and B-grade movie queen" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="leggy" />
            <token id="6" string="showgirl" />
            <token id="7" string="," />
            <token id="8" string="model" />
            <token id="9" string="and" />
            <token id="10" string="B-grade" />
            <token id="11" string="movie" />
            <token id="12" string="queen" />
          </tokens>
        </chunking>
        <chunking id="2" string="television" type="NP">
          <tokens>
            <token id="25" string="television" />
          </tokens>
        </chunking>
        <chunking id="3" string="made her an icon of television" type="VP">
          <tokens>
            <token id="20" string="made" />
            <token id="21" string="her" />
            <token id="22" string="an" />
            <token id="23" string="icon" />
            <token id="24" string="of" />
            <token id="25" string="television" />
          </tokens>
        </chunking>
        <chunking id="4" string="comedy" type="NP">
          <tokens>
            <token id="19" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="5" string="an icon" type="NP">
          <tokens>
            <token id="22" string="an" />
            <token id="23" string="icon" />
          </tokens>
        </chunking>
        <chunking id="6" string="the leggy showgirl , model and B-grade movie queen whose pumpkin hair and genius for comedy made her an icon of television" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="leggy" />
            <token id="6" string="showgirl" />
            <token id="7" string="," />
            <token id="8" string="model" />
            <token id="9" string="and" />
            <token id="10" string="B-grade" />
            <token id="11" string="movie" />
            <token id="12" string="queen" />
            <token id="13" string="whose" />
            <token id="14" string="pumpkin" />
            <token id="15" string="hair" />
            <token id="16" string="and" />
            <token id="17" string="genius" />
            <token id="18" string="for" />
            <token id="19" string="comedy" />
            <token id="20" string="made" />
            <token id="21" string="her" />
            <token id="22" string="an" />
            <token id="23" string="icon" />
            <token id="24" string="of" />
            <token id="25" string="television" />
          </tokens>
        </chunking>
        <chunking id="7" string="genius" type="NP">
          <tokens>
            <token id="17" string="genius" />
          </tokens>
        </chunking>
        <chunking id="8" string="emergency heart surgery" type="NP">
          <tokens>
            <token id="35" string="emergency" />
            <token id="36" string="heart" />
            <token id="37" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="9" string="pumpkin hair" type="NP">
          <tokens>
            <token id="14" string="pumpkin" />
            <token id="15" string="hair" />
          </tokens>
        </chunking>
        <chunking id="10" string="Lucille Ball , the leggy showgirl , model and B-grade movie queen whose pumpkin hair and genius for comedy made her an icon of television ," type="NP">
          <tokens>
            <token id="1" string="Lucille" />
            <token id="2" string="Ball" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="leggy" />
            <token id="6" string="showgirl" />
            <token id="7" string="," />
            <token id="8" string="model" />
            <token id="9" string="and" />
            <token id="10" string="B-grade" />
            <token id="11" string="movie" />
            <token id="12" string="queen" />
            <token id="13" string="whose" />
            <token id="14" string="pumpkin" />
            <token id="15" string="hair" />
            <token id="16" string="and" />
            <token id="17" string="genius" />
            <token id="18" string="for" />
            <token id="19" string="comedy" />
            <token id="20" string="made" />
            <token id="21" string="her" />
            <token id="22" string="an" />
            <token id="23" string="icon" />
            <token id="24" string="of" />
            <token id="25" string="television" />
            <token id="26" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="an icon of television" type="NP">
          <tokens>
            <token id="22" string="an" />
            <token id="23" string="icon" />
            <token id="24" string="of" />
            <token id="25" string="television" />
          </tokens>
        </chunking>
        <chunking id="12" string="a week" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="week" />
          </tokens>
        </chunking>
        <chunking id="13" string="a week after undergoing emergency heart surgery" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="week" />
            <token id="33" string="after" />
            <token id="34" string="undergoing" />
            <token id="35" string="emergency" />
            <token id="36" string="heart" />
            <token id="37" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="14" string="pumpkin hair and genius for comedy" type="NP">
          <tokens>
            <token id="14" string="pumpkin" />
            <token id="15" string="hair" />
            <token id="16" string="and" />
            <token id="17" string="genius" />
            <token id="18" string="for" />
            <token id="19" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="15" string="her" type="NP">
          <tokens>
            <token id="21" string="her" />
          </tokens>
        </chunking>
        <chunking id="16" string="died early Wednesday" type="VP">
          <tokens>
            <token id="27" string="died" />
            <token id="28" string="early" />
            <token id="29" string="Wednesday" />
          </tokens>
        </chunking>
        <chunking id="17" string="died early Wednesday , a week after undergoing emergency heart surgery" type="VP">
          <tokens>
            <token id="27" string="died" />
            <token id="28" string="early" />
            <token id="29" string="Wednesday" />
            <token id="30" string="," />
            <token id="31" string="a" />
            <token id="32" string="week" />
            <token id="33" string="after" />
            <token id="34" string="undergoing" />
            <token id="35" string="emergency" />
            <token id="36" string="heart" />
            <token id="37" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="18" string="whose pumpkin hair and genius for comedy made her an icon of television" type="SBAR">
          <tokens>
            <token id="13" string="whose" />
            <token id="14" string="pumpkin" />
            <token id="15" string="hair" />
            <token id="16" string="and" />
            <token id="17" string="genius" />
            <token id="18" string="for" />
            <token id="19" string="comedy" />
            <token id="20" string="made" />
            <token id="21" string="her" />
            <token id="22" string="an" />
            <token id="23" string="icon" />
            <token id="24" string="of" />
            <token id="25" string="television" />
          </tokens>
        </chunking>
        <chunking id="19" string="undergoing emergency heart surgery" type="VP">
          <tokens>
            <token id="34" string="undergoing" />
            <token id="35" string="emergency" />
            <token id="36" string="heart" />
            <token id="37" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="20" string="genius for comedy" type="NP">
          <tokens>
            <token id="17" string="genius" />
            <token id="18" string="for" />
            <token id="19" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="21" string="Lucille Ball" type="NP">
          <tokens>
            <token id="1" string="Lucille" />
            <token id="2" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ball</governor>
          <dependent id="1">Lucille</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">died</governor>
          <dependent id="2">Ball</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">queen</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">queen</governor>
          <dependent id="5">leggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">queen</governor>
          <dependent id="6">showgirl</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">showgirl</governor>
          <dependent id="8">model</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">showgirl</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">showgirl</governor>
          <dependent id="10">B-grade</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">queen</governor>
          <dependent id="11">movie</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Ball</governor>
          <dependent id="12">queen</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">hair</governor>
          <dependent id="13">whose</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">hair</governor>
          <dependent id="14">pumpkin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">made</governor>
          <dependent id="15">hair</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">hair</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">hair</governor>
          <dependent id="17">genius</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">comedy</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">genius</governor>
          <dependent id="19">comedy</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">queen</governor>
          <dependent id="20">made</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">made</governor>
          <dependent id="21">her</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">icon</governor>
          <dependent id="22">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">made</governor>
          <dependent id="23">icon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">television</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">icon</governor>
          <dependent id="25">television</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">died</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">Wednesday</governor>
          <dependent id="28">early</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="27">died</governor>
          <dependent id="29">Wednesday</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">week</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">died</governor>
          <dependent id="32">week</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">undergoing</governor>
          <dependent id="33">after</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="32">week</governor>
          <dependent id="34">undergoing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">surgery</governor>
          <dependent id="35">emergency</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">surgery</governor>
          <dependent id="36">heart</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">undergoing</governor>
          <dependent id="37">surgery</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="a week" type="DURATION" score="0.0">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="week" />
          </tokens>
        </entity>
        <entity id="2" string="early Wednesday" type="DATE" score="0.0">
          <tokens>
            <token id="28" string="early" />
            <token id="29" string="Wednesday" />
          </tokens>
        </entity>
        <entity id="3" string="Lucille Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lucille" />
            <token id="2" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The co-creator and star of &amp;quot;I Love Lucy,&amp;quot; a product of TV&amp;apost;s Golden Age that continues via syndication to be viewed by millions around the world, was 77 and died at Cedars-Sinai Medical Center of a ruptured abdominal aorta.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="co-creator" lemma="co-creator" stem="co-creat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="star" lemma="star" stem="star" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="product" lemma="product" stem="product" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="TV" lemma="tv" stem="tv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Golden" lemma="Golden" stem="golden" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="18" string="Age" lemma="Age" stem="age" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="continues" lemma="continue" stem="continu" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="via" lemma="via" stem="via" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="syndication" lemma="syndication" stem="syndic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="viewed" lemma="view" stem="view" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="millions" lemma="million" stem="million" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="77" lemma="77" stem="77" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="34" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="Cedars-Sinai" lemma="Cedars-Sinai" stem="cedars-sinai" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="38" string="Medical" lemma="Medical" stem="medic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="39" string="Center" lemma="Center" stem="center" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="40" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="ruptured" lemma="rupture" stem="ruptur" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="abdominal" lemma="abdominal" stem="abdomin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="aorta" lemma="aorta" stem="aorta" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NP (DT The) (NN co-creator) (CC and) (NN star)) (PP (IN of) (`` ``) (NP (PRP I)))) (NP (NNP Love) (NNP Lucy))) (, ,) ('' '') (NP (NP (DT a) (NN product)) (PP (IN of) (NP (NP (NN TV) (POS 's)) (NNP Golden) (NNP Age))) (SBAR (WHNP (IN that)) (S (VP (VBZ continues) (PP (IN via) (NP (NN syndication))) (S (VP (TO to) (VP (VB be) (VP (VBN viewed) (PP (IN by) (NP (NP (NNS millions)) (PP (IN around) (NP (DT the) (NN world))))))))))))) (, ,)) (VP (VP (VBD was) (NP (CD 77))) (CC and) (VP (VBD died) (PP (IN at) (NP (NP (NNP Cedars-Sinai) (NNP Medical) (NNP Center)) (PP (IN of) (NP (DT a) (VBN ruptured) (JJ abdominal) (NN aorta))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="continues via syndication to be viewed by millions around the world" type="VP">
          <tokens>
            <token id="20" string="continues" />
            <token id="21" string="via" />
            <token id="22" string="syndication" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="viewed" />
            <token id="26" string="by" />
            <token id="27" string="millions" />
            <token id="28" string="around" />
            <token id="29" string="the" />
            <token id="30" string="world" />
          </tokens>
        </chunking>
        <chunking id="2" string="viewed by millions around the world" type="VP">
          <tokens>
            <token id="25" string="viewed" />
            <token id="26" string="by" />
            <token id="27" string="millions" />
            <token id="28" string="around" />
            <token id="29" string="the" />
            <token id="30" string="world" />
          </tokens>
        </chunking>
        <chunking id="3" string="a product of TV 's Golden Age that continues via syndication to be viewed by millions around the world" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="product" />
            <token id="14" string="of" />
            <token id="15" string="TV" />
            <token id="16" string="'s" />
            <token id="17" string="Golden" />
            <token id="18" string="Age" />
            <token id="19" string="that" />
            <token id="20" string="continues" />
            <token id="21" string="via" />
            <token id="22" string="syndication" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="viewed" />
            <token id="26" string="by" />
            <token id="27" string="millions" />
            <token id="28" string="around" />
            <token id="29" string="the" />
            <token id="30" string="world" />
          </tokens>
        </chunking>
        <chunking id="4" string="TV 's Golden Age" type="NP">
          <tokens>
            <token id="15" string="TV" />
            <token id="16" string="'s" />
            <token id="17" string="Golden" />
            <token id="18" string="Age" />
          </tokens>
        </chunking>
        <chunking id="5" string="a ruptured abdominal aorta" type="NP">
          <tokens>
            <token id="41" string="a" />
            <token id="42" string="ruptured" />
            <token id="43" string="abdominal" />
            <token id="44" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="6" string="to be viewed by millions around the world" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="viewed" />
            <token id="26" string="by" />
            <token id="27" string="millions" />
            <token id="28" string="around" />
            <token id="29" string="the" />
            <token id="30" string="world" />
          </tokens>
        </chunking>
        <chunking id="7" string="was 77" type="VP">
          <tokens>
            <token id="32" string="was" />
            <token id="33" string="77" />
          </tokens>
        </chunking>
        <chunking id="8" string="The co-creator and star of `` I Love Lucy" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="co-creator" />
            <token id="3" string="and" />
            <token id="4" string="star" />
            <token id="5" string="of" />
            <token id="6" string="&quot;" />
            <token id="7" string="I" />
            <token id="8" string="Love" />
            <token id="9" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="9" string="that continues via syndication to be viewed by millions around the world" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="continues" />
            <token id="21" string="via" />
            <token id="22" string="syndication" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="viewed" />
            <token id="26" string="by" />
            <token id="27" string="millions" />
            <token id="28" string="around" />
            <token id="29" string="the" />
            <token id="30" string="world" />
          </tokens>
        </chunking>
        <chunking id="10" string="millions around the world" type="NP">
          <tokens>
            <token id="27" string="millions" />
            <token id="28" string="around" />
            <token id="29" string="the" />
            <token id="30" string="world" />
          </tokens>
        </chunking>
        <chunking id="11" string="was 77 and died at Cedars-Sinai Medical Center of a ruptured abdominal aorta" type="VP">
          <tokens>
            <token id="32" string="was" />
            <token id="33" string="77" />
            <token id="34" string="and" />
            <token id="35" string="died" />
            <token id="36" string="at" />
            <token id="37" string="Cedars-Sinai" />
            <token id="38" string="Medical" />
            <token id="39" string="Center" />
            <token id="40" string="of" />
            <token id="41" string="a" />
            <token id="42" string="ruptured" />
            <token id="43" string="abdominal" />
            <token id="44" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="12" string="millions" type="NP">
          <tokens>
            <token id="27" string="millions" />
          </tokens>
        </chunking>
        <chunking id="13" string="Cedars-Sinai Medical Center of a ruptured abdominal aorta" type="NP">
          <tokens>
            <token id="37" string="Cedars-Sinai" />
            <token id="38" string="Medical" />
            <token id="39" string="Center" />
            <token id="40" string="of" />
            <token id="41" string="a" />
            <token id="42" string="ruptured" />
            <token id="43" string="abdominal" />
            <token id="44" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="14" string="Love Lucy" type="NP">
          <tokens>
            <token id="8" string="Love" />
            <token id="9" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="15" string="The co-creator and star of `` I" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="co-creator" />
            <token id="3" string="and" />
            <token id="4" string="star" />
            <token id="5" string="of" />
            <token id="6" string="&quot;" />
            <token id="7" string="I" />
          </tokens>
        </chunking>
        <chunking id="16" string="The co-creator and star of `` I Love Lucy , '' a product of TV 's Golden Age that continues via syndication to be viewed by millions around the world ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="co-creator" />
            <token id="3" string="and" />
            <token id="4" string="star" />
            <token id="5" string="of" />
            <token id="6" string="&quot;" />
            <token id="7" string="I" />
            <token id="8" string="Love" />
            <token id="9" string="Lucy" />
            <token id="10" string="," />
            <token id="11" string="&quot;" />
            <token id="12" string="a" />
            <token id="13" string="product" />
            <token id="14" string="of" />
            <token id="15" string="TV" />
            <token id="16" string="'s" />
            <token id="17" string="Golden" />
            <token id="18" string="Age" />
            <token id="19" string="that" />
            <token id="20" string="continues" />
            <token id="21" string="via" />
            <token id="22" string="syndication" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="viewed" />
            <token id="26" string="by" />
            <token id="27" string="millions" />
            <token id="28" string="around" />
            <token id="29" string="the" />
            <token id="30" string="world" />
            <token id="31" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="syndication" type="NP">
          <tokens>
            <token id="22" string="syndication" />
          </tokens>
        </chunking>
        <chunking id="18" string="be viewed by millions around the world" type="VP">
          <tokens>
            <token id="24" string="be" />
            <token id="25" string="viewed" />
            <token id="26" string="by" />
            <token id="27" string="millions" />
            <token id="28" string="around" />
            <token id="29" string="the" />
            <token id="30" string="world" />
          </tokens>
        </chunking>
        <chunking id="19" string="I" type="NP">
          <tokens>
            <token id="7" string="I" />
          </tokens>
        </chunking>
        <chunking id="20" string="the world" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="world" />
          </tokens>
        </chunking>
        <chunking id="21" string="died at Cedars-Sinai Medical Center of a ruptured abdominal aorta" type="VP">
          <tokens>
            <token id="35" string="died" />
            <token id="36" string="at" />
            <token id="37" string="Cedars-Sinai" />
            <token id="38" string="Medical" />
            <token id="39" string="Center" />
            <token id="40" string="of" />
            <token id="41" string="a" />
            <token id="42" string="ruptured" />
            <token id="43" string="abdominal" />
            <token id="44" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="22" string="a product" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="product" />
          </tokens>
        </chunking>
        <chunking id="23" string="TV 's" type="NP">
          <tokens>
            <token id="15" string="TV" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="24" string="The co-creator and star" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="co-creator" />
            <token id="3" string="and" />
            <token id="4" string="star" />
          </tokens>
        </chunking>
        <chunking id="25" string="Cedars-Sinai Medical Center" type="NP">
          <tokens>
            <token id="37" string="Cedars-Sinai" />
            <token id="38" string="Medical" />
            <token id="39" string="Center" />
          </tokens>
        </chunking>
        <chunking id="26" string="77" type="NP">
          <tokens>
            <token id="33" string="77" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">co-creator</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">77</governor>
          <dependent id="2">co-creator</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">co-creator</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">co-creator</governor>
          <dependent id="4">star</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">I</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">co-creator</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Lucy</governor>
          <dependent id="8">Love</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">co-creator</governor>
          <dependent id="9">Lucy</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">product</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">co-creator</governor>
          <dependent id="13">product</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Age</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">Age</governor>
          <dependent id="15">TV</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">TV</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Age</governor>
          <dependent id="17">Golden</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">product</governor>
          <dependent id="18">Age</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">continues</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">product</governor>
          <dependent id="20">continues</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">syndication</governor>
          <dependent id="21">via</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">continues</governor>
          <dependent id="22">syndication</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">viewed</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">viewed</governor>
          <dependent id="24">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">continues</governor>
          <dependent id="25">viewed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">millions</governor>
          <dependent id="26">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">viewed</governor>
          <dependent id="27">millions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">world</governor>
          <dependent id="28">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">world</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">millions</governor>
          <dependent id="30">world</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="33">77</governor>
          <dependent id="32">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="33">77</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">77</governor>
          <dependent id="34">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">77</governor>
          <dependent id="35">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">Center</governor>
          <dependent id="36">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Center</governor>
          <dependent id="37">Cedars-Sinai</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Center</governor>
          <dependent id="38">Medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">died</governor>
          <dependent id="39">Center</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">aorta</governor>
          <dependent id="40">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">aorta</governor>
          <dependent id="41">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">aorta</governor>
          <dependent id="42">ruptured</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">aorta</governor>
          <dependent id="43">abdominal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">Center</governor>
          <dependent id="44">aorta</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Golden Age" type="MISC" score="0.0">
          <tokens>
            <token id="17" string="Golden" />
            <token id="18" string="Age" />
          </tokens>
        </entity>
        <entity id="2" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Lucy" />
          </tokens>
        </entity>
        <entity id="3" string="Cedars-Sinai Medical Center" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="37" string="Cedars-Sinai" />
            <token id="38" string="Medical" />
            <token id="39" string="Center" />
          </tokens>
        </entity>
        <entity id="4" string="77" type="NUMBER" score="0.0">
          <tokens>
            <token id="33" string="77" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Known simply as &amp;quot;Lucy&amp;quot; to four decades of smitten television fans, she had undergone surgery at Cedars-Sinai on April 18 to replace part of her aorta and aortic valve and had recovered from the 6 1/2-hour operation to a point where she was eating and even walking around her hospital room.</content>
      <tokens>
        <token id="1" string="Known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="9" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="smitten" lemma="smitten" stem="smitten" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="undergone" lemma="undergo" stem="undergon" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Cedars-Sinai" lemma="Cedars-Sinai" stem="cedars-sinai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="18" lemma="18" stem="18" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="replace" lemma="replace" stem="replac" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="aorta" lemma="aorta" stem="aorta" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="aortic" lemma="aortic" stem="aortic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="valve" lemma="valve" stem="valv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="recovered" lemma="recover" stem="recov" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="6 1/2" lemma="61/2" stem="6 1/2" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="39" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="40" string="hour" lemma="hour" stem="hour" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="41" string="operation" lemma="operation" stem="oper" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="42" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="eating" lemma="eat" stem="eat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="walking" lemma="walk" stem="walk" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Known) (ADVP (RB simply)) (PP (IN as) (NP (`` ``) (NP (NNP Lucy)) ('' '') (PP (TO to) (NP (NP (CD four) (NNS decades)) (PP (IN of) (NP (JJ smitten) (NN television) (NNS fans))))))))) (, ,) (NP (PRP she)) (VP (VP (VBD had) (VP (VBN undergone) (NP (NN surgery)) (PP (IN at) (NP (NNP Cedars-Sinai))) (PP (IN on) (NP (NNP April) (CD 18))) (S (VP (TO to) (VP (VB replace) (NP (NP (NN part)) (PP (IN of) (NP (NP (PRP$ her) (NN aorta)) (CC and) (NP (JJ aortic) (NN valve)))))))))) (CC and) (VP (VBD had) (VP (VBN recovered) (PP (IN from) (NP (DT the) (CD 61/2))))) (: -) (VP (NP (NN hour) (NN operation)) (PP (TO to) (NP (DT a) (NN point)))) (SBAR (WHADVP (WRB where)) (S (NP (PRP she)) (VP (VBD was) (VP (VP (VBG eating)) (CC and) (VP (ADVP (RB even)) (VBG walking) (PP (IN around) (NP (PRP$ her) (NN hospital) (NN room))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="four decades of smitten television fans" type="NP">
          <tokens>
            <token id="8" string="four" />
            <token id="9" string="decades" />
            <token id="10" string="of" />
            <token id="11" string="smitten" />
            <token id="12" string="television" />
            <token id="13" string="fans" />
          </tokens>
        </chunking>
        <chunking id="2" string="aortic valve" type="NP">
          <tokens>
            <token id="31" string="aortic" />
            <token id="32" string="valve" />
          </tokens>
        </chunking>
        <chunking id="3" string="a point" type="NP">
          <tokens>
            <token id="43" string="a" />
            <token id="44" string="point" />
          </tokens>
        </chunking>
        <chunking id="4" string="even walking around her hospital room" type="VP">
          <tokens>
            <token id="50" string="even" />
            <token id="51" string="walking" />
            <token id="52" string="around" />
            <token id="53" string="her" />
            <token id="54" string="hospital" />
            <token id="55" string="room" />
          </tokens>
        </chunking>
        <chunking id="5" string="she" type="NP">
          <tokens>
            <token id="15" string="she" />
          </tokens>
        </chunking>
        <chunking id="6" string="eating" type="VP">
          <tokens>
            <token id="48" string="eating" />
          </tokens>
        </chunking>
        <chunking id="7" string="to replace part of her aorta and aortic valve" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="replace" />
            <token id="26" string="part" />
            <token id="27" string="of" />
            <token id="28" string="her" />
            <token id="29" string="aorta" />
            <token id="30" string="and" />
            <token id="31" string="aortic" />
            <token id="32" string="valve" />
          </tokens>
        </chunking>
        <chunking id="8" string="her aorta and aortic valve" type="NP">
          <tokens>
            <token id="28" string="her" />
            <token id="29" string="aorta" />
            <token id="30" string="and" />
            <token id="31" string="aortic" />
            <token id="32" string="valve" />
          </tokens>
        </chunking>
        <chunking id="9" string="replace part of her aorta and aortic valve" type="VP">
          <tokens>
            <token id="25" string="replace" />
            <token id="26" string="part" />
            <token id="27" string="of" />
            <token id="28" string="her" />
            <token id="29" string="aorta" />
            <token id="30" string="and" />
            <token id="31" string="aortic" />
            <token id="32" string="valve" />
          </tokens>
        </chunking>
        <chunking id="10" string="her aorta" type="NP">
          <tokens>
            <token id="28" string="her" />
            <token id="29" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="11" string="`` Lucy '' to four decades of smitten television fans" type="NP">
          <tokens>
            <token id="4" string="&quot;" />
            <token id="5" string="Lucy" />
            <token id="6" string="&quot;" />
            <token id="7" string="to" />
            <token id="8" string="four" />
            <token id="9" string="decades" />
            <token id="10" string="of" />
            <token id="11" string="smitten" />
            <token id="12" string="television" />
            <token id="13" string="fans" />
          </tokens>
        </chunking>
        <chunking id="12" string="part of her aorta and aortic valve" type="NP">
          <tokens>
            <token id="26" string="part" />
            <token id="27" string="of" />
            <token id="28" string="her" />
            <token id="29" string="aorta" />
            <token id="30" string="and" />
            <token id="31" string="aortic" />
            <token id="32" string="valve" />
          </tokens>
        </chunking>
        <chunking id="13" string="eating and even walking around her hospital room" type="VP">
          <tokens>
            <token id="48" string="eating" />
            <token id="49" string="and" />
            <token id="50" string="even" />
            <token id="51" string="walking" />
            <token id="52" string="around" />
            <token id="53" string="her" />
            <token id="54" string="hospital" />
            <token id="55" string="room" />
          </tokens>
        </chunking>
        <chunking id="14" string="Lucy" type="NP">
          <tokens>
            <token id="5" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="15" string="had undergone surgery at Cedars-Sinai on April 18 to replace part of her aorta and aortic valve and had recovered from the 61/2 - hour operation to a point where she was eating and even walking around her hospital room" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="undergone" />
            <token id="18" string="surgery" />
            <token id="19" string="at" />
            <token id="20" string="Cedars-Sinai" />
            <token id="21" string="on" />
            <token id="22" string="April" />
            <token id="23" string="18" />
            <token id="24" string="to" />
            <token id="25" string="replace" />
            <token id="26" string="part" />
            <token id="27" string="of" />
            <token id="28" string="her" />
            <token id="29" string="aorta" />
            <token id="30" string="and" />
            <token id="31" string="aortic" />
            <token id="32" string="valve" />
            <token id="33" string="and" />
            <token id="34" string="had" />
            <token id="35" string="recovered" />
            <token id="36" string="from" />
            <token id="37" string="the" />
            <token id="38" string="6 1/2" />
            <token id="39" string="-" />
            <token id="40" string="hour" />
            <token id="41" string="operation" />
            <token id="42" string="to" />
            <token id="43" string="a" />
            <token id="44" string="point" />
            <token id="45" string="where" />
            <token id="46" string="she" />
            <token id="47" string="was" />
            <token id="48" string="eating" />
            <token id="49" string="and" />
            <token id="50" string="even" />
            <token id="51" string="walking" />
            <token id="52" string="around" />
            <token id="53" string="her" />
            <token id="54" string="hospital" />
            <token id="55" string="room" />
          </tokens>
        </chunking>
        <chunking id="16" string="undergone surgery at Cedars-Sinai on April 18 to replace part of her aorta and aortic valve" type="VP">
          <tokens>
            <token id="17" string="undergone" />
            <token id="18" string="surgery" />
            <token id="19" string="at" />
            <token id="20" string="Cedars-Sinai" />
            <token id="21" string="on" />
            <token id="22" string="April" />
            <token id="23" string="18" />
            <token id="24" string="to" />
            <token id="25" string="replace" />
            <token id="26" string="part" />
            <token id="27" string="of" />
            <token id="28" string="her" />
            <token id="29" string="aorta" />
            <token id="30" string="and" />
            <token id="31" string="aortic" />
            <token id="32" string="valve" />
          </tokens>
        </chunking>
        <chunking id="17" string="had recovered from the 61/2" type="VP">
          <tokens>
            <token id="34" string="had" />
            <token id="35" string="recovered" />
            <token id="36" string="from" />
            <token id="37" string="the" />
            <token id="38" string="6 1/2" />
          </tokens>
        </chunking>
        <chunking id="18" string="recovered from the 61/2" type="VP">
          <tokens>
            <token id="35" string="recovered" />
            <token id="36" string="from" />
            <token id="37" string="the" />
            <token id="38" string="6 1/2" />
          </tokens>
        </chunking>
        <chunking id="19" string="surgery" type="NP">
          <tokens>
            <token id="18" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="20" string="Known simply as `` Lucy '' to four decades of smitten television fans" type="VP">
          <tokens>
            <token id="1" string="Known" />
            <token id="2" string="simply" />
            <token id="3" string="as" />
            <token id="4" string="&quot;" />
            <token id="5" string="Lucy" />
            <token id="6" string="&quot;" />
            <token id="7" string="to" />
            <token id="8" string="four" />
            <token id="9" string="decades" />
            <token id="10" string="of" />
            <token id="11" string="smitten" />
            <token id="12" string="television" />
            <token id="13" string="fans" />
          </tokens>
        </chunking>
        <chunking id="21" string="hour operation to a point" type="VP">
          <tokens>
            <token id="40" string="hour" />
            <token id="41" string="operation" />
            <token id="42" string="to" />
            <token id="43" string="a" />
            <token id="44" string="point" />
          </tokens>
        </chunking>
        <chunking id="22" string="her hospital room" type="NP">
          <tokens>
            <token id="53" string="her" />
            <token id="54" string="hospital" />
            <token id="55" string="room" />
          </tokens>
        </chunking>
        <chunking id="23" string="Cedars-Sinai" type="NP">
          <tokens>
            <token id="20" string="Cedars-Sinai" />
          </tokens>
        </chunking>
        <chunking id="24" string="part" type="NP">
          <tokens>
            <token id="26" string="part" />
          </tokens>
        </chunking>
        <chunking id="25" string="April 18" type="NP">
          <tokens>
            <token id="22" string="April" />
            <token id="23" string="18" />
          </tokens>
        </chunking>
        <chunking id="26" string="smitten television fans" type="NP">
          <tokens>
            <token id="11" string="smitten" />
            <token id="12" string="television" />
            <token id="13" string="fans" />
          </tokens>
        </chunking>
        <chunking id="27" string="had undergone surgery at Cedars-Sinai on April 18 to replace part of her aorta and aortic valve" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="undergone" />
            <token id="18" string="surgery" />
            <token id="19" string="at" />
            <token id="20" string="Cedars-Sinai" />
            <token id="21" string="on" />
            <token id="22" string="April" />
            <token id="23" string="18" />
            <token id="24" string="to" />
            <token id="25" string="replace" />
            <token id="26" string="part" />
            <token id="27" string="of" />
            <token id="28" string="her" />
            <token id="29" string="aorta" />
            <token id="30" string="and" />
            <token id="31" string="aortic" />
            <token id="32" string="valve" />
          </tokens>
        </chunking>
        <chunking id="28" string="hour operation" type="NP">
          <tokens>
            <token id="40" string="hour" />
            <token id="41" string="operation" />
          </tokens>
        </chunking>
        <chunking id="29" string="where she was eating and even walking around her hospital room" type="SBAR">
          <tokens>
            <token id="45" string="where" />
            <token id="46" string="she" />
            <token id="47" string="was" />
            <token id="48" string="eating" />
            <token id="49" string="and" />
            <token id="50" string="even" />
            <token id="51" string="walking" />
            <token id="52" string="around" />
            <token id="53" string="her" />
            <token id="54" string="hospital" />
            <token id="55" string="room" />
          </tokens>
        </chunking>
        <chunking id="30" string="four decades" type="NP">
          <tokens>
            <token id="8" string="four" />
            <token id="9" string="decades" />
          </tokens>
        </chunking>
        <chunking id="31" string="the 61/2" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="6 1/2" />
          </tokens>
        </chunking>
        <chunking id="32" string="where" type="WHADVP">
          <tokens>
            <token id="45" string="where" />
          </tokens>
        </chunking>
        <chunking id="33" string="was eating and even walking around her hospital room" type="VP">
          <tokens>
            <token id="47" string="was" />
            <token id="48" string="eating" />
            <token id="49" string="and" />
            <token id="50" string="even" />
            <token id="51" string="walking" />
            <token id="52" string="around" />
            <token id="53" string="her" />
            <token id="54" string="hospital" />
            <token id="55" string="room" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="17">undergone</governor>
          <dependent id="1">Known</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="1">Known</governor>
          <dependent id="2">simply</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Lucy</governor>
          <dependent id="3">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Known</governor>
          <dependent id="5">Lucy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">decades</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">decades</governor>
          <dependent id="8">four</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Lucy</governor>
          <dependent id="9">decades</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">fans</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">fans</governor>
          <dependent id="11">smitten</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">fans</governor>
          <dependent id="12">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">decades</governor>
          <dependent id="13">fans</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">undergone</governor>
          <dependent id="15">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">undergone</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">undergone</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">undergone</governor>
          <dependent id="18">surgery</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Cedars-Sinai</governor>
          <dependent id="19">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">undergone</governor>
          <dependent id="20">Cedars-Sinai</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">April</governor>
          <dependent id="21">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">undergone</governor>
          <dependent id="22">April</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">April</governor>
          <dependent id="23">18</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">replace</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">undergone</governor>
          <dependent id="25">replace</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">replace</governor>
          <dependent id="26">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">aorta</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">aorta</governor>
          <dependent id="28">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">part</governor>
          <dependent id="29">aorta</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">aorta</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">valve</governor>
          <dependent id="31">aortic</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">aorta</governor>
          <dependent id="32">valve</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">undergone</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="35">recovered</governor>
          <dependent id="34">had</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">undergone</governor>
          <dependent id="35">recovered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">61/2</governor>
          <dependent id="36">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">61/2</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">recovered</governor>
          <dependent id="38">61/2</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">operation</governor>
          <dependent id="40">hour</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">undergone</governor>
          <dependent id="41">operation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">point</governor>
          <dependent id="42">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">point</governor>
          <dependent id="43">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">operation</governor>
          <dependent id="44">point</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="48">eating</governor>
          <dependent id="45">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="48">eating</governor>
          <dependent id="46">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="48">eating</governor>
          <dependent id="47">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">undergone</governor>
          <dependent id="48">eating</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="48">eating</governor>
          <dependent id="49">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="51">walking</governor>
          <dependent id="50">even</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="48">eating</governor>
          <dependent id="51">walking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">room</governor>
          <dependent id="52">around</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="55">room</governor>
          <dependent id="53">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="55">room</governor>
          <dependent id="54">hospital</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="51">walking</governor>
          <dependent id="55">room</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="four decades" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="four" />
            <token id="9" string="decades" />
          </tokens>
        </entity>
        <entity id="2" string="6 1/2 - hour" type="DURATION" score="0.0">
          <tokens>
            <token id="38" string="6 1/2" />
            <token id="39" string="-" />
            <token id="40" string="hour" />
          </tokens>
        </entity>
        <entity id="3" string="Cedars-Sinai" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Cedars-Sinai" />
          </tokens>
        </entity>
        <entity id="4" string="April 18" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="April" />
            <token id="23" string="18" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Hospital spokesman Ronald Wise said the rupture occurred in a portion of the aorta, the main heart artery, far from where the operation was performed.</content>
      <tokens>
        <token id="1" string="Hospital" lemma="Hospital" stem="hospit" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="spokesman" lemma="spokesman" stem="spokesman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="Ronald" lemma="Ronald" stem="ronald" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Wise" lemma="Wise" stem="wise" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="rupture" lemma="rupture" stem="ruptur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="occurred" lemma="occur" stem="occur" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="portion" lemma="portion" stem="portion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="aorta" lemma="aorta" stem="aorta" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="main" lemma="main" stem="main" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="artery" lemma="artery" stem="arteri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="operation" lemma="operation" stem="oper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="performed" lemma="perform" stem="perform" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Hospital) (NN spokesman) (NNP Ronald) (NNP Wise)) (VP (VBD said) (SBAR (S (NP (DT the) (NN rupture)) (VP (VBD occurred) (PP (IN in) (NP (NP (DT a) (NN portion)) (PP (IN of) (NP (NP (DT the) (NN aorta)) (, ,) (NP (DT the) (JJ main) (NN heart) (NN artery)))) (, ,) (ADVP (RB far) (PP (IN from) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (NN operation)) (VP (VBD was) (VP (VBN performed))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a portion of the aorta , the main heart artery , far from where the operation was performed" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="portion" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="aorta" />
            <token id="15" string="," />
            <token id="16" string="the" />
            <token id="17" string="main" />
            <token id="18" string="heart" />
            <token id="19" string="artery" />
            <token id="20" string="," />
            <token id="21" string="far" />
            <token id="22" string="from" />
            <token id="23" string="where" />
            <token id="24" string="the" />
            <token id="25" string="operation" />
            <token id="26" string="was" />
            <token id="27" string="performed" />
          </tokens>
        </chunking>
        <chunking id="2" string="the aorta , the main heart artery" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="aorta" />
            <token id="15" string="," />
            <token id="16" string="the" />
            <token id="17" string="main" />
            <token id="18" string="heart" />
            <token id="19" string="artery" />
          </tokens>
        </chunking>
        <chunking id="3" string="was performed" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="performed" />
          </tokens>
        </chunking>
        <chunking id="4" string="occurred in a portion of the aorta , the main heart artery , far from where the operation was performed" type="VP">
          <tokens>
            <token id="8" string="occurred" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="portion" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="aorta" />
            <token id="15" string="," />
            <token id="16" string="the" />
            <token id="17" string="main" />
            <token id="18" string="heart" />
            <token id="19" string="artery" />
            <token id="20" string="," />
            <token id="21" string="far" />
            <token id="22" string="from" />
            <token id="23" string="where" />
            <token id="24" string="the" />
            <token id="25" string="operation" />
            <token id="26" string="was" />
            <token id="27" string="performed" />
          </tokens>
        </chunking>
        <chunking id="5" string="Hospital spokesman Ronald Wise" type="NP">
          <tokens>
            <token id="1" string="Hospital" />
            <token id="2" string="spokesman" />
            <token id="3" string="Ronald" />
            <token id="4" string="Wise" />
          </tokens>
        </chunking>
        <chunking id="6" string="performed" type="VP">
          <tokens>
            <token id="27" string="performed" />
          </tokens>
        </chunking>
        <chunking id="7" string="a portion" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="portion" />
          </tokens>
        </chunking>
        <chunking id="8" string="said the rupture occurred in a portion of the aorta , the main heart artery , far from where the operation was performed" type="VP">
          <tokens>
            <token id="5" string="said" />
            <token id="6" string="the" />
            <token id="7" string="rupture" />
            <token id="8" string="occurred" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="portion" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="aorta" />
            <token id="15" string="," />
            <token id="16" string="the" />
            <token id="17" string="main" />
            <token id="18" string="heart" />
            <token id="19" string="artery" />
            <token id="20" string="," />
            <token id="21" string="far" />
            <token id="22" string="from" />
            <token id="23" string="where" />
            <token id="24" string="the" />
            <token id="25" string="operation" />
            <token id="26" string="was" />
            <token id="27" string="performed" />
          </tokens>
        </chunking>
        <chunking id="9" string="the main heart artery" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="main" />
            <token id="18" string="heart" />
            <token id="19" string="artery" />
          </tokens>
        </chunking>
        <chunking id="10" string="the rupture occurred in a portion of the aorta , the main heart artery , far from where the operation was performed" type="SBAR">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="rupture" />
            <token id="8" string="occurred" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="portion" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="aorta" />
            <token id="15" string="," />
            <token id="16" string="the" />
            <token id="17" string="main" />
            <token id="18" string="heart" />
            <token id="19" string="artery" />
            <token id="20" string="," />
            <token id="21" string="far" />
            <token id="22" string="from" />
            <token id="23" string="where" />
            <token id="24" string="the" />
            <token id="25" string="operation" />
            <token id="26" string="was" />
            <token id="27" string="performed" />
          </tokens>
        </chunking>
        <chunking id="11" string="the aorta" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="aorta" />
          </tokens>
        </chunking>
        <chunking id="12" string="the operation" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="operation" />
          </tokens>
        </chunking>
        <chunking id="13" string="the rupture" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="rupture" />
          </tokens>
        </chunking>
        <chunking id="14" string="where the operation was performed" type="SBAR">
          <tokens>
            <token id="23" string="where" />
            <token id="24" string="the" />
            <token id="25" string="operation" />
            <token id="26" string="was" />
            <token id="27" string="performed" />
          </tokens>
        </chunking>
        <chunking id="15" string="where" type="WHADVP">
          <tokens>
            <token id="23" string="where" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Wise</governor>
          <dependent id="1">Hospital</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Wise</governor>
          <dependent id="2">spokesman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Wise</governor>
          <dependent id="3">Ronald</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">said</governor>
          <dependent id="4">Wise</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">rupture</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">occurred</governor>
          <dependent id="7">rupture</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">said</governor>
          <dependent id="8">occurred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">portion</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">portion</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">occurred</governor>
          <dependent id="11">portion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">aorta</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">aorta</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">portion</governor>
          <dependent id="14">aorta</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">artery</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">artery</governor>
          <dependent id="17">main</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">artery</governor>
          <dependent id="18">heart</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">aorta</governor>
          <dependent id="19">artery</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">portion</governor>
          <dependent id="21">far</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">performed</governor>
          <dependent id="22">from</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">performed</governor>
          <dependent id="23">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">operation</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">performed</governor>
          <dependent id="25">operation</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">performed</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">far</governor>
          <dependent id="27">performed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ronald Wise" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Ronald" />
            <token id="4" string="Wise" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>She suffered a complete heart failure at 5 a.m., and 47 minutes of resuscitation efforts proved fruitless, Wise said.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="suffered" lemma="suffer" stem="suffer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="complete" lemma="complete" stem="complet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="6" string="failure" lemma="failure" stem="failur" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="5" lemma="5" stem="5" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="9" string="a.m." lemma="a.m." stem="a.m." pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="47" lemma="47" stem="47" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="resuscitation" lemma="resuscitation" stem="resuscit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="efforts" lemma="effort" stem="effort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="proved" lemma="prove" stem="prove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="fruitless" lemma="fruitless" stem="fruitless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Wise" lemma="Wise" stem="wise" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (NP (PRP She)) (VP (VBD suffered) (NP (DT a) (JJ complete) (NN heart) (NN failure)) (PP (IN at) (NP (CD 5) (RB a.m.))))) (, ,) (CC and) (S (NP (NP (CD 47) (NNS minutes)) (PP (IN of) (NP (NN resuscitation) (NNS efforts)))) (VP (VBD proved) (ADJP (JJ fruitless))))) (, ,) (NP (NNP Wise)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="suffered a complete heart failure at 5 a.m." type="VP">
          <tokens>
            <token id="2" string="suffered" />
            <token id="3" string="a" />
            <token id="4" string="complete" />
            <token id="5" string="heart" />
            <token id="6" string="failure" />
            <token id="7" string="at" />
            <token id="8" string="5" />
            <token id="9" string="a.m." />
          </tokens>
        </chunking>
        <chunking id="2" string="proved fruitless" type="VP">
          <tokens>
            <token id="17" string="proved" />
            <token id="18" string="fruitless" />
          </tokens>
        </chunking>
        <chunking id="3" string="resuscitation efforts" type="NP">
          <tokens>
            <token id="15" string="resuscitation" />
            <token id="16" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="4" string="5 a.m." type="NP">
          <tokens>
            <token id="8" string="5" />
            <token id="9" string="a.m." />
          </tokens>
        </chunking>
        <chunking id="5" string="fruitless" type="ADJP">
          <tokens>
            <token id="18" string="fruitless" />
          </tokens>
        </chunking>
        <chunking id="6" string="Wise" type="NP">
          <tokens>
            <token id="20" string="Wise" />
          </tokens>
        </chunking>
        <chunking id="7" string="47 minutes" type="NP">
          <tokens>
            <token id="12" string="47" />
            <token id="13" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="8" string="a complete heart failure" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="complete" />
            <token id="5" string="heart" />
            <token id="6" string="failure" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="11" string="47 minutes of resuscitation efforts" type="NP">
          <tokens>
            <token id="12" string="47" />
            <token id="13" string="minutes" />
            <token id="14" string="of" />
            <token id="15" string="resuscitation" />
            <token id="16" string="efforts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">suffered</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="2">suffered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">failure</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">failure</governor>
          <dependent id="4">complete</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">failure</governor>
          <dependent id="5">heart</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">suffered</governor>
          <dependent id="6">failure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">5</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">suffered</governor>
          <dependent id="8">5</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">5</governor>
          <dependent id="9">a.m.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">suffered</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">minutes</governor>
          <dependent id="12">47</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">proved</governor>
          <dependent id="13">minutes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">efforts</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">efforts</governor>
          <dependent id="15">resuscitation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">minutes</governor>
          <dependent id="16">efforts</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">suffered</governor>
          <dependent id="17">proved</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">proved</governor>
          <dependent id="18">fruitless</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">Wise</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="5 a.m." type="TIME" score="0.0">
          <tokens>
            <token id="8" string="5" />
            <token id="9" string="a.m." />
          </tokens>
        </entity>
        <entity id="2" string="Wise" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Wise" />
          </tokens>
        </entity>
        <entity id="3" string="47 minutes" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="47" />
            <token id="13" string="minutes" />
          </tokens>
        </entity>
        <entity id="4" string="heart failure" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="5" string="heart" />
            <token id="6" string="failure" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>&amp;quot;There was nothing to indicate this would happen,&amp;quot; Wise said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="indicate" lemma="indicate" stem="indic" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Wise" lemma="Wise" stem="wise" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (VBD was) (ADJP (NN nothing) (S (VP (TO to) (VP (VB indicate) (SBAR (S (NP (DT this)) (VP (MD would) (VP (VB happen))))))))))) (, ,) ('' '') (NP (NNP Wise)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="nothing to indicate this would happen" type="ADJP">
          <tokens>
            <token id="4" string="nothing" />
            <token id="5" string="to" />
            <token id="6" string="indicate" />
            <token id="7" string="this" />
            <token id="8" string="would" />
            <token id="9" string="happen" />
          </tokens>
        </chunking>
        <chunking id="2" string="indicate this would happen" type="VP">
          <tokens>
            <token id="6" string="indicate" />
            <token id="7" string="this" />
            <token id="8" string="would" />
            <token id="9" string="happen" />
          </tokens>
        </chunking>
        <chunking id="3" string="would happen" type="VP">
          <tokens>
            <token id="8" string="would" />
            <token id="9" string="happen" />
          </tokens>
        </chunking>
        <chunking id="4" string="to indicate this would happen" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="indicate" />
            <token id="7" string="this" />
            <token id="8" string="would" />
            <token id="9" string="happen" />
          </tokens>
        </chunking>
        <chunking id="5" string="happen" type="VP">
          <tokens>
            <token id="9" string="happen" />
          </tokens>
        </chunking>
        <chunking id="6" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="7" string="this would happen" type="SBAR">
          <tokens>
            <token id="7" string="this" />
            <token id="8" string="would" />
            <token id="9" string="happen" />
          </tokens>
        </chunking>
        <chunking id="8" string="was nothing to indicate this would happen" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="nothing" />
            <token id="5" string="to" />
            <token id="6" string="indicate" />
            <token id="7" string="this" />
            <token id="8" string="would" />
            <token id="9" string="happen" />
          </tokens>
        </chunking>
        <chunking id="9" string="Wise" type="NP">
          <tokens>
            <token id="12" string="Wise" />
          </tokens>
        </chunking>
        <chunking id="10" string="this" type="NP">
          <tokens>
            <token id="7" string="this" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="13" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">was</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">was</governor>
          <dependent id="4">nothing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">indicate</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">nothing</governor>
          <dependent id="6">indicate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">happen</governor>
          <dependent id="7">this</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">happen</governor>
          <dependent id="8">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">indicate</governor>
          <dependent id="9">happen</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">Wise</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wise" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Wise" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>&amp;quot;The heart itself apparently was not involved in Miss Ball&amp;apost;s sudden death.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="apparently" lemma="apparently" stem="appar" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="sudden" lemma="sudden" stem="sudden" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (`` ``) (NP (DT The) (NN heart) (SBAR (S (NP (PRP itself)) (ADVP (RB apparently)) (VP (VBD was) (RB not) (VP (VBN involved) (PP (IN in) (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (JJ sudden) (NN death)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="itself" type="NP">
          <tokens>
            <token id="4" string="itself" />
          </tokens>
        </chunking>
        <chunking id="2" string="The heart itself apparently was not involved in Miss Ball 's sudden death" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="heart" />
            <token id="4" string="itself" />
            <token id="5" string="apparently" />
            <token id="6" string="was" />
            <token id="7" string="not" />
            <token id="8" string="involved" />
            <token id="9" string="in" />
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="'s" />
            <token id="13" string="sudden" />
            <token id="14" string="death" />
          </tokens>
        </chunking>
        <chunking id="3" string="was not involved in Miss Ball 's sudden death" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="not" />
            <token id="8" string="involved" />
            <token id="9" string="in" />
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="'s" />
            <token id="13" string="sudden" />
            <token id="14" string="death" />
          </tokens>
        </chunking>
        <chunking id="4" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="itself apparently was not involved in Miss Ball 's sudden death" type="SBAR">
          <tokens>
            <token id="4" string="itself" />
            <token id="5" string="apparently" />
            <token id="6" string="was" />
            <token id="7" string="not" />
            <token id="8" string="involved" />
            <token id="9" string="in" />
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="'s" />
            <token id="13" string="sudden" />
            <token id="14" string="death" />
          </tokens>
        </chunking>
        <chunking id="6" string="Miss Ball 's sudden death" type="NP">
          <tokens>
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="'s" />
            <token id="13" string="sudden" />
            <token id="14" string="death" />
          </tokens>
        </chunking>
        <chunking id="7" string="involved in Miss Ball 's sudden death" type="VP">
          <tokens>
            <token id="8" string="involved" />
            <token id="9" string="in" />
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="'s" />
            <token id="13" string="sudden" />
            <token id="14" string="death" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">heart</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">heart</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">involved</governor>
          <dependent id="4">itself</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">involved</governor>
          <dependent id="5">apparently</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">involved</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">involved</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">heart</governor>
          <dependent id="8">involved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">death</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Ball</governor>
          <dependent id="10">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">death</governor>
          <dependent id="11">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Ball</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">death</governor>
          <dependent id="13">sudden</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">involved</governor>
          <dependent id="14">death</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Since last week&amp;apost;s surgery, fans had flooded the hospital with thousands of get-well cards, sent via telegram and even facsimile machine.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="surgery" lemma="surgery" stem="surgeri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="flooded" lemma="flood" stem="flood" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="thousands" lemma="thousand" stem="thousand" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="get-well" lemma="get-well" stem="get-wel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="cards" lemma="card" stem="card" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="via" lemma="via" stem="via" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="telegram" lemma="telegram" stem="telegram" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="facsimile" lemma="facsimile" stem="facsimil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="machine" lemma="machine" stem="machin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Since) (NP (NP-TMP (JJ last) (NN week) (POS 's)) (NN surgery))) (, ,) (NP (NNS fans)) (VP (VBD had) (VP (VBN flooded) (NP (NP (DT the) (NN hospital)) (PP (IN with) (NP (NP (NNS thousands)) (PP (IN of) (NP (JJ get-well) (NNS cards))))) (, ,) (RRC (RRC (VP (VBN sent) (PP (IN via) (NP (NN telegram))))) (CC and) (RRC (ADVP (RB even)) (NP (JJ facsimile) (NN machine))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fans" type="NP">
          <tokens>
            <token id="7" string="fans" />
          </tokens>
        </chunking>
        <chunking id="2" string="last week 's surgery" type="NP">
          <tokens>
            <token id="2" string="last" />
            <token id="3" string="week" />
            <token id="4" string="'s" />
            <token id="5" string="surgery" />
          </tokens>
        </chunking>
        <chunking id="3" string="facsimile machine" type="NP">
          <tokens>
            <token id="23" string="facsimile" />
            <token id="24" string="machine" />
          </tokens>
        </chunking>
        <chunking id="4" string="sent via telegram" type="VP">
          <tokens>
            <token id="18" string="sent" />
            <token id="19" string="via" />
            <token id="20" string="telegram" />
          </tokens>
        </chunking>
        <chunking id="5" string="get-well cards" type="NP">
          <tokens>
            <token id="15" string="get-well" />
            <token id="16" string="cards" />
          </tokens>
        </chunking>
        <chunking id="6" string="telegram" type="NP">
          <tokens>
            <token id="20" string="telegram" />
          </tokens>
        </chunking>
        <chunking id="7" string="thousands" type="NP">
          <tokens>
            <token id="13" string="thousands" />
          </tokens>
        </chunking>
        <chunking id="8" string="had flooded the hospital with thousands of get-well cards , sent via telegram and even facsimile machine" type="VP">
          <tokens>
            <token id="8" string="had" />
            <token id="9" string="flooded" />
            <token id="10" string="the" />
            <token id="11" string="hospital" />
            <token id="12" string="with" />
            <token id="13" string="thousands" />
            <token id="14" string="of" />
            <token id="15" string="get-well" />
            <token id="16" string="cards" />
            <token id="17" string="," />
            <token id="18" string="sent" />
            <token id="19" string="via" />
            <token id="20" string="telegram" />
            <token id="21" string="and" />
            <token id="22" string="even" />
            <token id="23" string="facsimile" />
            <token id="24" string="machine" />
          </tokens>
        </chunking>
        <chunking id="9" string="flooded the hospital with thousands of get-well cards , sent via telegram and even facsimile machine" type="VP">
          <tokens>
            <token id="9" string="flooded" />
            <token id="10" string="the" />
            <token id="11" string="hospital" />
            <token id="12" string="with" />
            <token id="13" string="thousands" />
            <token id="14" string="of" />
            <token id="15" string="get-well" />
            <token id="16" string="cards" />
            <token id="17" string="," />
            <token id="18" string="sent" />
            <token id="19" string="via" />
            <token id="20" string="telegram" />
            <token id="21" string="and" />
            <token id="22" string="even" />
            <token id="23" string="facsimile" />
            <token id="24" string="machine" />
          </tokens>
        </chunking>
        <chunking id="10" string="the hospital with thousands of get-well cards , sent via telegram and even facsimile machine" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="hospital" />
            <token id="12" string="with" />
            <token id="13" string="thousands" />
            <token id="14" string="of" />
            <token id="15" string="get-well" />
            <token id="16" string="cards" />
            <token id="17" string="," />
            <token id="18" string="sent" />
            <token id="19" string="via" />
            <token id="20" string="telegram" />
            <token id="21" string="and" />
            <token id="22" string="even" />
            <token id="23" string="facsimile" />
            <token id="24" string="machine" />
          </tokens>
        </chunking>
        <chunking id="11" string="the hospital" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="12" string="thousands of get-well cards" type="NP">
          <tokens>
            <token id="13" string="thousands" />
            <token id="14" string="of" />
            <token id="15" string="get-well" />
            <token id="16" string="cards" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">surgery</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">week</governor>
          <dependent id="2">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">surgery</governor>
          <dependent id="3">week</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">week</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">flooded</governor>
          <dependent id="5">surgery</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">flooded</governor>
          <dependent id="7">fans</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">flooded</governor>
          <dependent id="8">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">flooded</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">hospital</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">flooded</governor>
          <dependent id="11">hospital</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">thousands</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">hospital</governor>
          <dependent id="13">thousands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">cards</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">cards</governor>
          <dependent id="15">get-well</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">thousands</governor>
          <dependent id="16">cards</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">hospital</governor>
          <dependent id="18">sent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">telegram</governor>
          <dependent id="19">via</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">sent</governor>
          <dependent id="20">telegram</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">sent</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">machine</governor>
          <dependent id="22">even</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">machine</governor>
          <dependent id="23">facsimile</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">sent</governor>
          <dependent id="24">machine</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="last week" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="last" />
            <token id="3" string="week" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Hospital officials said it was the largest outpouring they had ever seen.</content>
      <tokens>
        <token id="1" string="Hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="largest" lemma="largest" stem="largest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="outpouring" lemma="outpour" stem="outpour" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Hospital) (NNS officials)) (VP (VBD said) (SBAR (S (NP (PRP it)) (VP (VBD was) (NP (NP (DT the) (JJS largest)) (VP (VBG outpouring) (SBAR (S (NP (PRP they)) (VP (VBD had) (ADVP (RB ever)) (VP (VBN seen))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="9" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="it was the largest outpouring they had ever seen" type="SBAR">
          <tokens>
            <token id="4" string="it" />
            <token id="5" string="was" />
            <token id="6" string="the" />
            <token id="7" string="largest" />
            <token id="8" string="outpouring" />
            <token id="9" string="they" />
            <token id="10" string="had" />
            <token id="11" string="ever" />
            <token id="12" string="seen" />
          </tokens>
        </chunking>
        <chunking id="3" string="Hospital officials" type="NP">
          <tokens>
            <token id="1" string="Hospital" />
            <token id="2" string="officials" />
          </tokens>
        </chunking>
        <chunking id="4" string="the largest" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="largest" />
          </tokens>
        </chunking>
        <chunking id="5" string="had ever seen" type="VP">
          <tokens>
            <token id="10" string="had" />
            <token id="11" string="ever" />
            <token id="12" string="seen" />
          </tokens>
        </chunking>
        <chunking id="6" string="they had ever seen" type="SBAR">
          <tokens>
            <token id="9" string="they" />
            <token id="10" string="had" />
            <token id="11" string="ever" />
            <token id="12" string="seen" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="outpouring they had ever seen" type="VP">
          <tokens>
            <token id="8" string="outpouring" />
            <token id="9" string="they" />
            <token id="10" string="had" />
            <token id="11" string="ever" />
            <token id="12" string="seen" />
          </tokens>
        </chunking>
        <chunking id="9" string="the largest outpouring they had ever seen" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="largest" />
            <token id="8" string="outpouring" />
            <token id="9" string="they" />
            <token id="10" string="had" />
            <token id="11" string="ever" />
            <token id="12" string="seen" />
          </tokens>
        </chunking>
        <chunking id="10" string="said it was the largest outpouring they had ever seen" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="it" />
            <token id="5" string="was" />
            <token id="6" string="the" />
            <token id="7" string="largest" />
            <token id="8" string="outpouring" />
            <token id="9" string="they" />
            <token id="10" string="had" />
            <token id="11" string="ever" />
            <token id="12" string="seen" />
          </tokens>
        </chunking>
        <chunking id="11" string="was the largest outpouring they had ever seen" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="the" />
            <token id="7" string="largest" />
            <token id="8" string="outpouring" />
            <token id="9" string="they" />
            <token id="10" string="had" />
            <token id="11" string="ever" />
            <token id="12" string="seen" />
          </tokens>
        </chunking>
        <chunking id="12" string="seen" type="VP">
          <tokens>
            <token id="12" string="seen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">officials</governor>
          <dependent id="1">Hospital</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">largest</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">largest</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">largest</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="7">largest</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">largest</governor>
          <dependent id="8">outpouring</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">seen</governor>
          <dependent id="9">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">seen</governor>
          <dependent id="10">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">seen</governor>
          <dependent id="11">ever</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">outpouring</governor>
          <dependent id="12">seen</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Miss Ball was a tough-talking woman who had used her stardom and show business savvy to become, with her then-husband, the late Desi Arnaz, head of one of Hollywood&amp;apost;s major studios, Desilu.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="tough-talking" lemma="tough-talking" stem="tough-talk" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="woman" lemma="woman" stem="woman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="stardom" lemma="stardom" stem="stardom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="savvy" lemma="savvy" stem="savvi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="then-husband" lemma="then-husband" stem="then-husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="24" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="25" string="Desi" lemma="Desi" stem="desi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="26" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="28" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="32" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="33" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="34" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="35" string="studios" lemma="studio" stem="studio" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="37" string="Desilu" lemma="Desilu" stem="desilu" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Miss) (NNP Ball)) (VP (VBD was) (NP (NP (DT a) (JJ tough-talking) (NN woman)) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN used) (NP (PRP$ her) (NN stardom) (CC and) (NN show) (NN business) (NN savvy)) (S (VP (TO to) (VP (VB become)))) (, ,) (PP (IN with) (NP (NP (PRP$ her) (NN then-husband)) (, ,) (NP (NP (DT the) (JJ late) (NNP Desi) (NNP Arnaz)) (, ,) (NP (NP (NN head)) (PP (IN of) (NP (CD one))) (PP (IN of) (NP (NP (NNP Hollywood) (POS 's)) (JJ major) (NNS studios)))) (, ,) (NP (NNP Desilu))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a tough-talking woman" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="tough-talking" />
            <token id="6" string="woman" />
          </tokens>
        </chunking>
        <chunking id="2" string="the late Desi Arnaz , head of one of Hollywood 's major studios , Desilu" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="Desi" />
            <token id="26" string="Arnaz" />
            <token id="27" string="," />
            <token id="28" string="head" />
            <token id="29" string="of" />
            <token id="30" string="one" />
            <token id="31" string="of" />
            <token id="32" string="Hollywood" />
            <token id="33" string="'s" />
            <token id="34" string="major" />
            <token id="35" string="studios" />
            <token id="36" string="," />
            <token id="37" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="30" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="her then-husband , the late Desi Arnaz , head of one of Hollywood 's major studios , Desilu" type="NP">
          <tokens>
            <token id="20" string="her" />
            <token id="21" string="then-husband" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="Desi" />
            <token id="26" string="Arnaz" />
            <token id="27" string="," />
            <token id="28" string="head" />
            <token id="29" string="of" />
            <token id="30" string="one" />
            <token id="31" string="of" />
            <token id="32" string="Hollywood" />
            <token id="33" string="'s" />
            <token id="34" string="major" />
            <token id="35" string="studios" />
            <token id="36" string="," />
            <token id="37" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="5" string="had used her stardom and show business savvy to become , with her then-husband , the late Desi Arnaz , head of one of Hollywood 's major studios , Desilu" type="VP">
          <tokens>
            <token id="8" string="had" />
            <token id="9" string="used" />
            <token id="10" string="her" />
            <token id="11" string="stardom" />
            <token id="12" string="and" />
            <token id="13" string="show" />
            <token id="14" string="business" />
            <token id="15" string="savvy" />
            <token id="16" string="to" />
            <token id="17" string="become" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="her" />
            <token id="21" string="then-husband" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="Desi" />
            <token id="26" string="Arnaz" />
            <token id="27" string="," />
            <token id="28" string="head" />
            <token id="29" string="of" />
            <token id="30" string="one" />
            <token id="31" string="of" />
            <token id="32" string="Hollywood" />
            <token id="33" string="'s" />
            <token id="34" string="major" />
            <token id="35" string="studios" />
            <token id="36" string="," />
            <token id="37" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="6" string="the late Desi Arnaz" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="Desi" />
            <token id="26" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="7" string="a tough-talking woman who had used her stardom and show business savvy to become , with her then-husband , the late Desi Arnaz , head of one of Hollywood 's major studios , Desilu" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="tough-talking" />
            <token id="6" string="woman" />
            <token id="7" string="who" />
            <token id="8" string="had" />
            <token id="9" string="used" />
            <token id="10" string="her" />
            <token id="11" string="stardom" />
            <token id="12" string="and" />
            <token id="13" string="show" />
            <token id="14" string="business" />
            <token id="15" string="savvy" />
            <token id="16" string="to" />
            <token id="17" string="become" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="her" />
            <token id="21" string="then-husband" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="Desi" />
            <token id="26" string="Arnaz" />
            <token id="27" string="," />
            <token id="28" string="head" />
            <token id="29" string="of" />
            <token id="30" string="one" />
            <token id="31" string="of" />
            <token id="32" string="Hollywood" />
            <token id="33" string="'s" />
            <token id="34" string="major" />
            <token id="35" string="studios" />
            <token id="36" string="," />
            <token id="37" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="8" string="who had used her stardom and show business savvy to become , with her then-husband , the late Desi Arnaz , head of one of Hollywood 's major studios , Desilu" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="had" />
            <token id="9" string="used" />
            <token id="10" string="her" />
            <token id="11" string="stardom" />
            <token id="12" string="and" />
            <token id="13" string="show" />
            <token id="14" string="business" />
            <token id="15" string="savvy" />
            <token id="16" string="to" />
            <token id="17" string="become" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="her" />
            <token id="21" string="then-husband" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="Desi" />
            <token id="26" string="Arnaz" />
            <token id="27" string="," />
            <token id="28" string="head" />
            <token id="29" string="of" />
            <token id="30" string="one" />
            <token id="31" string="of" />
            <token id="32" string="Hollywood" />
            <token id="33" string="'s" />
            <token id="34" string="major" />
            <token id="35" string="studios" />
            <token id="36" string="," />
            <token id="37" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="9" string="to become" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="become" />
          </tokens>
        </chunking>
        <chunking id="10" string="Hollywood 's" type="NP">
          <tokens>
            <token id="32" string="Hollywood" />
            <token id="33" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="head" type="NP">
          <tokens>
            <token id="28" string="head" />
          </tokens>
        </chunking>
        <chunking id="12" string="used her stardom and show business savvy to become , with her then-husband , the late Desi Arnaz , head of one of Hollywood 's major studios , Desilu" type="VP">
          <tokens>
            <token id="9" string="used" />
            <token id="10" string="her" />
            <token id="11" string="stardom" />
            <token id="12" string="and" />
            <token id="13" string="show" />
            <token id="14" string="business" />
            <token id="15" string="savvy" />
            <token id="16" string="to" />
            <token id="17" string="become" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="her" />
            <token id="21" string="then-husband" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="Desi" />
            <token id="26" string="Arnaz" />
            <token id="27" string="," />
            <token id="28" string="head" />
            <token id="29" string="of" />
            <token id="30" string="one" />
            <token id="31" string="of" />
            <token id="32" string="Hollywood" />
            <token id="33" string="'s" />
            <token id="34" string="major" />
            <token id="35" string="studios" />
            <token id="36" string="," />
            <token id="37" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="13" string="Desilu" type="NP">
          <tokens>
            <token id="37" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="14" string="her then-husband" type="NP">
          <tokens>
            <token id="20" string="her" />
            <token id="21" string="then-husband" />
          </tokens>
        </chunking>
        <chunking id="15" string="was a tough-talking woman who had used her stardom and show business savvy to become , with her then-husband , the late Desi Arnaz , head of one of Hollywood 's major studios , Desilu" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="tough-talking" />
            <token id="6" string="woman" />
            <token id="7" string="who" />
            <token id="8" string="had" />
            <token id="9" string="used" />
            <token id="10" string="her" />
            <token id="11" string="stardom" />
            <token id="12" string="and" />
            <token id="13" string="show" />
            <token id="14" string="business" />
            <token id="15" string="savvy" />
            <token id="16" string="to" />
            <token id="17" string="become" />
            <token id="18" string="," />
            <token id="19" string="with" />
            <token id="20" string="her" />
            <token id="21" string="then-husband" />
            <token id="22" string="," />
            <token id="23" string="the" />
            <token id="24" string="late" />
            <token id="25" string="Desi" />
            <token id="26" string="Arnaz" />
            <token id="27" string="," />
            <token id="28" string="head" />
            <token id="29" string="of" />
            <token id="30" string="one" />
            <token id="31" string="of" />
            <token id="32" string="Hollywood" />
            <token id="33" string="'s" />
            <token id="34" string="major" />
            <token id="35" string="studios" />
            <token id="36" string="," />
            <token id="37" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="16" string="head of one of Hollywood 's major studios" type="NP">
          <tokens>
            <token id="28" string="head" />
            <token id="29" string="of" />
            <token id="30" string="one" />
            <token id="31" string="of" />
            <token id="32" string="Hollywood" />
            <token id="33" string="'s" />
            <token id="34" string="major" />
            <token id="35" string="studios" />
          </tokens>
        </chunking>
        <chunking id="17" string="her stardom and show business savvy" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="stardom" />
            <token id="12" string="and" />
            <token id="13" string="show" />
            <token id="14" string="business" />
            <token id="15" string="savvy" />
          </tokens>
        </chunking>
        <chunking id="18" string="become" type="VP">
          <tokens>
            <token id="17" string="become" />
          </tokens>
        </chunking>
        <chunking id="19" string="Miss Ball" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="20" string="Hollywood 's major studios" type="NP">
          <tokens>
            <token id="32" string="Hollywood" />
            <token id="33" string="'s" />
            <token id="34" string="major" />
            <token id="35" string="studios" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ball</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">woman</governor>
          <dependent id="2">Ball</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">woman</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">woman</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">woman</governor>
          <dependent id="5">tough-talking</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">woman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">used</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">used</governor>
          <dependent id="8">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">woman</governor>
          <dependent id="9">used</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">stardom</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">used</governor>
          <dependent id="11">stardom</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">stardom</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">savvy</governor>
          <dependent id="13">show</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">savvy</governor>
          <dependent id="14">business</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">stardom</governor>
          <dependent id="15">savvy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">become</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">used</governor>
          <dependent id="17">become</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">then-husband</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">then-husband</governor>
          <dependent id="20">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">used</governor>
          <dependent id="21">then-husband</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">Arnaz</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">Arnaz</governor>
          <dependent id="24">late</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Arnaz</governor>
          <dependent id="25">Desi</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="21">then-husband</governor>
          <dependent id="26">Arnaz</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="26">Arnaz</governor>
          <dependent id="28">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">one</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">head</governor>
          <dependent id="30">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">studios</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">studios</governor>
          <dependent id="32">Hollywood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Hollywood</governor>
          <dependent id="33">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">studios</governor>
          <dependent id="34">major</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">head</governor>
          <dependent id="35">studios</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="26">Arnaz</governor>
          <dependent id="37">Desilu</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="32" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="2" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ball" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="30" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="Desi Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Desi" />
            <token id="26" string="Arnaz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Despite her business acumen, she remained the unquestioned queen of television comedy.</content>
      <tokens>
        <token id="1" string="Despite" lemma="despite" stem="despit" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="acumen" lemma="acumen" stem="acumen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="remained" lemma="remain" stem="remain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="unquestioned" lemma="unquestioned" stem="unquest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="queen" lemma="queen" stem="queen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="comedy" lemma="comedy" stem="comedi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Despite) (NP (PRP$ her) (NN business) (NNS acumen))) (, ,) (NP (PRP she)) (VP (VBD remained) (NP (NP (DT the) (JJ unquestioned) (NN queen)) (PP (IN of) (NP (NN television) (NN comedy))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the unquestioned queen of television comedy" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="unquestioned" />
            <token id="10" string="queen" />
            <token id="11" string="of" />
            <token id="12" string="television" />
            <token id="13" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="2" string="television comedy" type="NP">
          <tokens>
            <token id="12" string="television" />
            <token id="13" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="3" string="her business acumen" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="business" />
            <token id="4" string="acumen" />
          </tokens>
        </chunking>
        <chunking id="4" string="the unquestioned queen" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="unquestioned" />
            <token id="10" string="queen" />
          </tokens>
        </chunking>
        <chunking id="5" string="remained the unquestioned queen of television comedy" type="VP">
          <tokens>
            <token id="7" string="remained" />
            <token id="8" string="the" />
            <token id="9" string="unquestioned" />
            <token id="10" string="queen" />
            <token id="11" string="of" />
            <token id="12" string="television" />
            <token id="13" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="6" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">acumen</governor>
          <dependent id="1">Despite</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">acumen</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">acumen</governor>
          <dependent id="3">business</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">remained</governor>
          <dependent id="4">acumen</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">remained</governor>
          <dependent id="6">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">remained</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">queen</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">queen</governor>
          <dependent id="9">unquestioned</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">remained</governor>
          <dependent id="10">queen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">comedy</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">comedy</governor>
          <dependent id="12">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">queen</governor>
          <dependent id="13">comedy</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>From her star-struck childhood through her struggles as a wisecracking movie actress in the 1930s and &amp;apost;40s to the television career that made her a legend, Miss Ball&amp;apost;s life was in the best show business tradition of rags to riches.</content>
      <tokens>
        <token id="1" string="From" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="star-struck" lemma="star-struck" stem="star-struck" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="childhood" lemma="childhood" stem="childhood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="struggles" lemma="struggle" stem="struggl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="wisecracking" lemma="wisecracking" stem="wisecrack" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="actress" lemma="actress" stem="actress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="1930s" lemma="1930" stem="1930" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="'40s" lemma="'40" stem="'40" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="career" lemma="career" stem="career" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="legend" lemma="legend" stem="legend" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="tradition" lemma="tradition" stem="tradit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="rags" lemma="rag" stem="rag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="riches" lemma="riches" stem="rich" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN From) (NP (NP (PRP$ her) (JJ star-struck) (NN childhood)) (PP (PP (IN through) (NP (PRP$ her) (NNS struggles))) (PP (IN as) (NP (NP (DT a) (JJ wisecracking) (NN movie) (NN actress)) (PP (IN in) (NP (DT the) (NNS 1930s) (CC and) (NNS '40s))))) (PP (TO to) (NP (NP (DT the) (NN television) (NN career)) (SBAR (WHNP (WDT that)) (S (VP (VBD made) (S (NP (PRP her)) (NP (DT a) (NN legend))))))))))) (, ,) (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (NN life)) (VP (VBD was) (PP (IN in) (NP (NP (DT the) (JJS best) (NN show) (NN business) (NN tradition)) (PP (IN of) (NP (NP (NNS rags)) (PP (TO to) (NP (NNS riches)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the best show business tradition of rags to riches" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="best" />
            <token id="36" string="show" />
            <token id="37" string="business" />
            <token id="38" string="tradition" />
            <token id="39" string="of" />
            <token id="40" string="rags" />
            <token id="41" string="to" />
            <token id="42" string="riches" />
          </tokens>
        </chunking>
        <chunking id="2" string="her star-struck childhood through her struggles as a wisecracking movie actress in the 1930s and '40s to the television career that made her a legend" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="star-struck" />
            <token id="4" string="childhood" />
            <token id="5" string="through" />
            <token id="6" string="her" />
            <token id="7" string="struggles" />
            <token id="8" string="as" />
            <token id="9" string="a" />
            <token id="10" string="wisecracking" />
            <token id="11" string="movie" />
            <token id="12" string="actress" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="1930s" />
            <token id="16" string="and" />
            <token id="17" string="'40s" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="television" />
            <token id="21" string="career" />
            <token id="22" string="that" />
            <token id="23" string="made" />
            <token id="24" string="her" />
            <token id="25" string="a" />
            <token id="26" string="legend" />
          </tokens>
        </chunking>
        <chunking id="3" string="the best show business tradition" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="best" />
            <token id="36" string="show" />
            <token id="37" string="business" />
            <token id="38" string="tradition" />
          </tokens>
        </chunking>
        <chunking id="4" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="28" string="Miss" />
            <token id="29" string="Ball" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="Miss Ball 's life" type="NP">
          <tokens>
            <token id="28" string="Miss" />
            <token id="29" string="Ball" />
            <token id="30" string="'s" />
            <token id="31" string="life" />
          </tokens>
        </chunking>
        <chunking id="6" string="her struggles" type="NP">
          <tokens>
            <token id="6" string="her" />
            <token id="7" string="struggles" />
          </tokens>
        </chunking>
        <chunking id="7" string="a wisecracking movie actress" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="wisecracking" />
            <token id="11" string="movie" />
            <token id="12" string="actress" />
          </tokens>
        </chunking>
        <chunking id="8" string="was in the best show business tradition of rags to riches" type="VP">
          <tokens>
            <token id="32" string="was" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="best" />
            <token id="36" string="show" />
            <token id="37" string="business" />
            <token id="38" string="tradition" />
            <token id="39" string="of" />
            <token id="40" string="rags" />
            <token id="41" string="to" />
            <token id="42" string="riches" />
          </tokens>
        </chunking>
        <chunking id="9" string="a legend" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="legend" />
          </tokens>
        </chunking>
        <chunking id="10" string="rags" type="NP">
          <tokens>
            <token id="40" string="rags" />
          </tokens>
        </chunking>
        <chunking id="11" string="rags to riches" type="NP">
          <tokens>
            <token id="40" string="rags" />
            <token id="41" string="to" />
            <token id="42" string="riches" />
          </tokens>
        </chunking>
        <chunking id="12" string="that made her a legend" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="made" />
            <token id="24" string="her" />
            <token id="25" string="a" />
            <token id="26" string="legend" />
          </tokens>
        </chunking>
        <chunking id="13" string="a wisecracking movie actress in the 1930s and '40s" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="wisecracking" />
            <token id="11" string="movie" />
            <token id="12" string="actress" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="1930s" />
            <token id="16" string="and" />
            <token id="17" string="'40s" />
          </tokens>
        </chunking>
        <chunking id="14" string="the television career" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="television" />
            <token id="21" string="career" />
          </tokens>
        </chunking>
        <chunking id="15" string="her" type="NP">
          <tokens>
            <token id="24" string="her" />
          </tokens>
        </chunking>
        <chunking id="16" string="her star-struck childhood" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="star-struck" />
            <token id="4" string="childhood" />
          </tokens>
        </chunking>
        <chunking id="17" string="the television career that made her a legend" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="television" />
            <token id="21" string="career" />
            <token id="22" string="that" />
            <token id="23" string="made" />
            <token id="24" string="her" />
            <token id="25" string="a" />
            <token id="26" string="legend" />
          </tokens>
        </chunking>
        <chunking id="18" string="riches" type="NP">
          <tokens>
            <token id="42" string="riches" />
          </tokens>
        </chunking>
        <chunking id="19" string="the 1930s and '40s" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="1930s" />
            <token id="16" string="and" />
            <token id="17" string="'40s" />
          </tokens>
        </chunking>
        <chunking id="20" string="made her a legend" type="VP">
          <tokens>
            <token id="23" string="made" />
            <token id="24" string="her" />
            <token id="25" string="a" />
            <token id="26" string="legend" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">childhood</governor>
          <dependent id="1">From</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">childhood</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">childhood</governor>
          <dependent id="3">star-struck</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">tradition</governor>
          <dependent id="4">childhood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">struggles</governor>
          <dependent id="5">through</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">struggles</governor>
          <dependent id="6">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">childhood</governor>
          <dependent id="7">struggles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">actress</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">actress</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">actress</governor>
          <dependent id="10">wisecracking</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">actress</governor>
          <dependent id="11">movie</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">struggles</governor>
          <dependent id="12">actress</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">1930s</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">1930s</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">actress</governor>
          <dependent id="15">1930s</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">1930s</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">1930s</governor>
          <dependent id="17">'40s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">career</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">career</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">career</governor>
          <dependent id="20">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">struggles</governor>
          <dependent id="21">career</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">made</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">career</governor>
          <dependent id="23">made</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">legend</governor>
          <dependent id="24">her</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">legend</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">made</governor>
          <dependent id="26">legend</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Ball</governor>
          <dependent id="28">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">life</governor>
          <dependent id="29">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Ball</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">tradition</governor>
          <dependent id="31">life</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="38">tradition</governor>
          <dependent id="32">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">tradition</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">tradition</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">tradition</governor>
          <dependent id="35">best</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">tradition</governor>
          <dependent id="36">show</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">tradition</governor>
          <dependent id="37">business</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="38">tradition</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">rags</governor>
          <dependent id="39">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">tradition</governor>
          <dependent id="40">rags</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">riches</governor>
          <dependent id="41">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">rags</governor>
          <dependent id="42">riches</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="the 1930s" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="1930s" />
          </tokens>
        </entity>
        <entity id="3" string="'40s" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="'40s" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Almost humbly, she liked to say she owed her enormous success, not so much to talent, but to a magical combination of guts and good supporting players.</content>
      <tokens>
        <token id="1" string="Almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="humbly" lemma="humbly" stem="humbli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="liked" lemma="like" stem="like" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="owed" lemma="owe" stem="ow" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="enormous" lemma="enormous" stem="enorm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="success" lemma="success" stem="success" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="talent" lemma="talent" stem="talent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="magical" lemma="magical" stem="magic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="combination" lemma="combination" stem="combin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="guts" lemma="gut" stem="gut" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="supporting" lemma="support" stem="support" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="players" lemma="player" stem="player" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Almost) (ADVP (RB humbly))) (, ,) (NP (PRP she)) (VP (VBD liked) (S (VP (TO to) (VP (VB say) (SBAR (S (NP (PRP she)) (VP (VBD owed) (NP (NP (PRP$ her) (JJ enormous) (NN success)) (, ,) (UCP (RB not) (ADJP (RB so) (JJ much) (PP (TO to) (NP (NN talent)))) (, ,) (CC but) (PP (TO to) (NP (NP (DT a) (JJ magical) (NN combination)) (PP (IN of) (NP (NP (NNS guts)) (CC and) (NP (JJ good) (VBG supporting) (NNS players))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="say she owed her enormous success , not so much to talent , but to a magical combination of guts and good supporting players" type="VP">
          <tokens>
            <token id="7" string="say" />
            <token id="8" string="she" />
            <token id="9" string="owed" />
            <token id="10" string="her" />
            <token id="11" string="enormous" />
            <token id="12" string="success" />
            <token id="13" string="," />
            <token id="14" string="not" />
            <token id="15" string="so" />
            <token id="16" string="much" />
            <token id="17" string="to" />
            <token id="18" string="talent" />
            <token id="19" string="," />
            <token id="20" string="but" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="magical" />
            <token id="24" string="combination" />
            <token id="25" string="of" />
            <token id="26" string="guts" />
            <token id="27" string="and" />
            <token id="28" string="good" />
            <token id="29" string="supporting" />
            <token id="30" string="players" />
          </tokens>
        </chunking>
        <chunking id="2" string="her enormous success , not so much to talent , but to a magical combination of guts and good supporting players" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="enormous" />
            <token id="12" string="success" />
            <token id="13" string="," />
            <token id="14" string="not" />
            <token id="15" string="so" />
            <token id="16" string="much" />
            <token id="17" string="to" />
            <token id="18" string="talent" />
            <token id="19" string="," />
            <token id="20" string="but" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="magical" />
            <token id="24" string="combination" />
            <token id="25" string="of" />
            <token id="26" string="guts" />
            <token id="27" string="and" />
            <token id="28" string="good" />
            <token id="29" string="supporting" />
            <token id="30" string="players" />
          </tokens>
        </chunking>
        <chunking id="3" string="good supporting players" type="NP">
          <tokens>
            <token id="28" string="good" />
            <token id="29" string="supporting" />
            <token id="30" string="players" />
          </tokens>
        </chunking>
        <chunking id="4" string="to say she owed her enormous success , not so much to talent , but to a magical combination of guts and good supporting players" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="say" />
            <token id="8" string="she" />
            <token id="9" string="owed" />
            <token id="10" string="her" />
            <token id="11" string="enormous" />
            <token id="12" string="success" />
            <token id="13" string="," />
            <token id="14" string="not" />
            <token id="15" string="so" />
            <token id="16" string="much" />
            <token id="17" string="to" />
            <token id="18" string="talent" />
            <token id="19" string="," />
            <token id="20" string="but" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="magical" />
            <token id="24" string="combination" />
            <token id="25" string="of" />
            <token id="26" string="guts" />
            <token id="27" string="and" />
            <token id="28" string="good" />
            <token id="29" string="supporting" />
            <token id="30" string="players" />
          </tokens>
        </chunking>
        <chunking id="5" string="owed her enormous success , not so much to talent , but to a magical combination of guts and good supporting players" type="VP">
          <tokens>
            <token id="9" string="owed" />
            <token id="10" string="her" />
            <token id="11" string="enormous" />
            <token id="12" string="success" />
            <token id="13" string="," />
            <token id="14" string="not" />
            <token id="15" string="so" />
            <token id="16" string="much" />
            <token id="17" string="to" />
            <token id="18" string="talent" />
            <token id="19" string="," />
            <token id="20" string="but" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="magical" />
            <token id="24" string="combination" />
            <token id="25" string="of" />
            <token id="26" string="guts" />
            <token id="27" string="and" />
            <token id="28" string="good" />
            <token id="29" string="supporting" />
            <token id="30" string="players" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="her enormous success" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="enormous" />
            <token id="12" string="success" />
          </tokens>
        </chunking>
        <chunking id="8" string="talent" type="NP">
          <tokens>
            <token id="18" string="talent" />
          </tokens>
        </chunking>
        <chunking id="9" string="guts and good supporting players" type="NP">
          <tokens>
            <token id="26" string="guts" />
            <token id="27" string="and" />
            <token id="28" string="good" />
            <token id="29" string="supporting" />
            <token id="30" string="players" />
          </tokens>
        </chunking>
        <chunking id="10" string="she owed her enormous success , not so much to talent , but to a magical combination of guts and good supporting players" type="SBAR">
          <tokens>
            <token id="8" string="she" />
            <token id="9" string="owed" />
            <token id="10" string="her" />
            <token id="11" string="enormous" />
            <token id="12" string="success" />
            <token id="13" string="," />
            <token id="14" string="not" />
            <token id="15" string="so" />
            <token id="16" string="much" />
            <token id="17" string="to" />
            <token id="18" string="talent" />
            <token id="19" string="," />
            <token id="20" string="but" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="magical" />
            <token id="24" string="combination" />
            <token id="25" string="of" />
            <token id="26" string="guts" />
            <token id="27" string="and" />
            <token id="28" string="good" />
            <token id="29" string="supporting" />
            <token id="30" string="players" />
          </tokens>
        </chunking>
        <chunking id="11" string="liked to say she owed her enormous success , not so much to talent , but to a magical combination of guts and good supporting players" type="VP">
          <tokens>
            <token id="5" string="liked" />
            <token id="6" string="to" />
            <token id="7" string="say" />
            <token id="8" string="she" />
            <token id="9" string="owed" />
            <token id="10" string="her" />
            <token id="11" string="enormous" />
            <token id="12" string="success" />
            <token id="13" string="," />
            <token id="14" string="not" />
            <token id="15" string="so" />
            <token id="16" string="much" />
            <token id="17" string="to" />
            <token id="18" string="talent" />
            <token id="19" string="," />
            <token id="20" string="but" />
            <token id="21" string="to" />
            <token id="22" string="a" />
            <token id="23" string="magical" />
            <token id="24" string="combination" />
            <token id="25" string="of" />
            <token id="26" string="guts" />
            <token id="27" string="and" />
            <token id="28" string="good" />
            <token id="29" string="supporting" />
            <token id="30" string="players" />
          </tokens>
        </chunking>
        <chunking id="12" string="a magical combination of guts and good supporting players" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="magical" />
            <token id="24" string="combination" />
            <token id="25" string="of" />
            <token id="26" string="guts" />
            <token id="27" string="and" />
            <token id="28" string="good" />
            <token id="29" string="supporting" />
            <token id="30" string="players" />
          </tokens>
        </chunking>
        <chunking id="13" string="a magical combination" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="magical" />
            <token id="24" string="combination" />
          </tokens>
        </chunking>
        <chunking id="14" string="so much to talent" type="ADJP">
          <tokens>
            <token id="15" string="so" />
            <token id="16" string="much" />
            <token id="17" string="to" />
            <token id="18" string="talent" />
          </tokens>
        </chunking>
        <chunking id="15" string="guts" type="NP">
          <tokens>
            <token id="26" string="guts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">liked</governor>
          <dependent id="1">Almost</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="1">Almost</governor>
          <dependent id="2">humbly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">liked</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">liked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">say</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">liked</governor>
          <dependent id="7">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">owed</governor>
          <dependent id="8">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">say</governor>
          <dependent id="9">owed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">success</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">success</governor>
          <dependent id="11">enormous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">owed</governor>
          <dependent id="12">success</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">success</governor>
          <dependent id="14">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">much</governor>
          <dependent id="15">so</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">not</governor>
          <dependent id="16">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">talent</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">much</governor>
          <dependent id="18">talent</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">not</governor>
          <dependent id="20">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">combination</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">combination</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">combination</governor>
          <dependent id="23">magical</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">not</governor>
          <dependent id="24">combination</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">guts</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">combination</governor>
          <dependent id="26">guts</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">guts</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">players</governor>
          <dependent id="28">good</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">players</governor>
          <dependent id="29">supporting</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">guts</governor>
          <dependent id="30">players</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Her greatest achievements, she always would add, were not any milestones in her career but ranked somewhere under the birth of her two children, Lucie in 1951 and Desi Jr., two years later.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="greatest" lemma="greatest" stem="greatest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="achievements" lemma="achievement" stem="achiev" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="add" lemma="add" stem="add" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="milestones" lemma="milestone" stem="mileston" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="career" lemma="career" stem="career" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="ranked" lemma="rank" stem="rank" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="somewhere" lemma="somewhere" stem="somewher" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="birth" lemma="birth" stem="birth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="25" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="26" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Lucie" lemma="Lucie" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="1951" lemma="1951" stem="1951" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Desi" lemma="Desi" stem="desi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="33" string="Jr." lemma="Jr." stem="jr." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="36" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="37" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Her) (JJS greatest) (NNS achievements)) (PRN (, ,) (S (NP (PRP she)) (ADVP (RB always)) (VP (MD would) (VP (VB add)))) (, ,)) (VP (VP (VBD were) (NP (NP (RB not) (DT any) (NNS milestones)) (PP (IN in) (NP (PRP$ her) (NN career))))) (CC but) (VP (VBD ranked) (ADVP (RB somewhere)) (PP (IN under) (NP (NP (NP (DT the) (NN birth)) (PP (IN of) (NP (PRP$ her) (CD two) (NNS children)))) (, ,) (NP (NP (NNP Lucie)) (PP (IN in) (NP (CD 1951)))) (CC and) (NP (NP (NNP Desi) (NNP Jr.)) (, ,) (ADVP (NP (CD two) (NNS years)) (RB later))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the birth of her two children , Lucie in 1951 and Desi Jr. , two years later" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="birth" />
            <token id="23" string="of" />
            <token id="24" string="her" />
            <token id="25" string="two" />
            <token id="26" string="children" />
            <token id="27" string="," />
            <token id="28" string="Lucie" />
            <token id="29" string="in" />
            <token id="30" string="1951" />
            <token id="31" string="and" />
            <token id="32" string="Desi" />
            <token id="33" string="Jr." />
            <token id="34" string="," />
            <token id="35" string="two" />
            <token id="36" string="years" />
            <token id="37" string="later" />
          </tokens>
        </chunking>
        <chunking id="2" string="add" type="VP">
          <tokens>
            <token id="8" string="add" />
          </tokens>
        </chunking>
        <chunking id="3" string="Desi Jr." type="NP">
          <tokens>
            <token id="32" string="Desi" />
            <token id="33" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="4" string="Her greatest achievements" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="greatest" />
            <token id="3" string="achievements" />
          </tokens>
        </chunking>
        <chunking id="5" string="Desi Jr. , two years later" type="NP">
          <tokens>
            <token id="32" string="Desi" />
            <token id="33" string="Jr." />
            <token id="34" string="," />
            <token id="35" string="two" />
            <token id="36" string="years" />
            <token id="37" string="later" />
          </tokens>
        </chunking>
        <chunking id="6" string="her two children" type="NP">
          <tokens>
            <token id="24" string="her" />
            <token id="25" string="two" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="were not any milestones in her career but ranked somewhere under the birth of her two children , Lucie in 1951 and Desi Jr. , two years later" type="VP">
          <tokens>
            <token id="10" string="were" />
            <token id="11" string="not" />
            <token id="12" string="any" />
            <token id="13" string="milestones" />
            <token id="14" string="in" />
            <token id="15" string="her" />
            <token id="16" string="career" />
            <token id="17" string="but" />
            <token id="18" string="ranked" />
            <token id="19" string="somewhere" />
            <token id="20" string="under" />
            <token id="21" string="the" />
            <token id="22" string="birth" />
            <token id="23" string="of" />
            <token id="24" string="her" />
            <token id="25" string="two" />
            <token id="26" string="children" />
            <token id="27" string="," />
            <token id="28" string="Lucie" />
            <token id="29" string="in" />
            <token id="30" string="1951" />
            <token id="31" string="and" />
            <token id="32" string="Desi" />
            <token id="33" string="Jr." />
            <token id="34" string="," />
            <token id="35" string="two" />
            <token id="36" string="years" />
            <token id="37" string="later" />
          </tokens>
        </chunking>
        <chunking id="8" string="ranked somewhere under the birth of her two children , Lucie in 1951 and Desi Jr. , two years later" type="VP">
          <tokens>
            <token id="18" string="ranked" />
            <token id="19" string="somewhere" />
            <token id="20" string="under" />
            <token id="21" string="the" />
            <token id="22" string="birth" />
            <token id="23" string="of" />
            <token id="24" string="her" />
            <token id="25" string="two" />
            <token id="26" string="children" />
            <token id="27" string="," />
            <token id="28" string="Lucie" />
            <token id="29" string="in" />
            <token id="30" string="1951" />
            <token id="31" string="and" />
            <token id="32" string="Desi" />
            <token id="33" string="Jr." />
            <token id="34" string="," />
            <token id="35" string="two" />
            <token id="36" string="years" />
            <token id="37" string="later" />
          </tokens>
        </chunking>
        <chunking id="9" string="the birth" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="birth" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="Lucie" type="NP">
          <tokens>
            <token id="28" string="Lucie" />
          </tokens>
        </chunking>
        <chunking id="12" string="would add" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="add" />
          </tokens>
        </chunking>
        <chunking id="13" string="the birth of her two children" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="birth" />
            <token id="23" string="of" />
            <token id="24" string="her" />
            <token id="25" string="two" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="14" string="1951" type="NP">
          <tokens>
            <token id="30" string="1951" />
          </tokens>
        </chunking>
        <chunking id="15" string="two years" type="NP">
          <tokens>
            <token id="35" string="two" />
            <token id="36" string="years" />
          </tokens>
        </chunking>
        <chunking id="16" string="were not any milestones in her career" type="VP">
          <tokens>
            <token id="10" string="were" />
            <token id="11" string="not" />
            <token id="12" string="any" />
            <token id="13" string="milestones" />
            <token id="14" string="in" />
            <token id="15" string="her" />
            <token id="16" string="career" />
          </tokens>
        </chunking>
        <chunking id="17" string="her career" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="career" />
          </tokens>
        </chunking>
        <chunking id="18" string="not any milestones" type="NP">
          <tokens>
            <token id="11" string="not" />
            <token id="12" string="any" />
            <token id="13" string="milestones" />
          </tokens>
        </chunking>
        <chunking id="19" string="Lucie in 1951" type="NP">
          <tokens>
            <token id="28" string="Lucie" />
            <token id="29" string="in" />
            <token id="30" string="1951" />
          </tokens>
        </chunking>
        <chunking id="20" string="not any milestones in her career" type="NP">
          <tokens>
            <token id="11" string="not" />
            <token id="12" string="any" />
            <token id="13" string="milestones" />
            <token id="14" string="in" />
            <token id="15" string="her" />
            <token id="16" string="career" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">achievements</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">achievements</governor>
          <dependent id="2">greatest</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">milestones</governor>
          <dependent id="3">achievements</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">add</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">add</governor>
          <dependent id="6">always</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">add</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="13">milestones</governor>
          <dependent id="8">add</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">milestones</governor>
          <dependent id="10">were</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">milestones</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">milestones</governor>
          <dependent id="12">any</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">milestones</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">career</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">career</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">milestones</governor>
          <dependent id="16">career</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">milestones</governor>
          <dependent id="17">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">milestones</governor>
          <dependent id="18">ranked</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">ranked</governor>
          <dependent id="19">somewhere</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">birth</governor>
          <dependent id="20">under</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">birth</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">ranked</governor>
          <dependent id="22">birth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">children</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">children</governor>
          <dependent id="24">her</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">children</governor>
          <dependent id="25">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">birth</governor>
          <dependent id="26">children</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">birth</governor>
          <dependent id="28">Lucie</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">1951</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">Lucie</governor>
          <dependent id="30">1951</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">birth</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Jr.</governor>
          <dependent id="32">Desi</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">birth</governor>
          <dependent id="33">Jr.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="36">years</governor>
          <dependent id="35">two</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="37">later</governor>
          <dependent id="36">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">Jr.</governor>
          <dependent id="37">later</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucie" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Lucie" />
          </tokens>
        </entity>
        <entity id="2" string="1951" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="1951" />
          </tokens>
        </entity>
        <entity id="3" string="Desi Jr." type="PERSON" score="0.0">
          <tokens>
            <token id="32" string="Desi" />
            <token id="33" string="Jr." />
          </tokens>
        </entity>
        <entity id="4" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="25" string="two" />
          </tokens>
        </entity>
        <entity id="5" string="two years later" type="DATE" score="0.0">
          <tokens>
            <token id="35" string="two" />
            <token id="36" string="years" />
            <token id="37" string="later" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>&amp;quot;I am not funny,&amp;quot; Ball told an interviewer for Rolling Stone magazine in 1983.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="funny" lemma="funny" stem="funni" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="interviewer" lemma="interviewer" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Rolling" lemma="Rolling" stem="roll" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="Stone" lemma="Stone" stem="stone" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP am) (RB not) (ADJP (JJ funny)))) (, ,) ('' '') (NP (NNP Ball)) (VP (VBD told) (NP (DT an) (NN interviewer)) (PP (IN for) (NP (NNP Rolling) (NNP Stone) (NN magazine))) (PP (IN in) (NP (CD 1983)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ball" type="NP">
          <tokens>
            <token id="8" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="2" string="am not funny" type="VP">
          <tokens>
            <token id="3" string="am" />
            <token id="4" string="not" />
            <token id="5" string="funny" />
          </tokens>
        </chunking>
        <chunking id="3" string="an interviewer" type="NP">
          <tokens>
            <token id="10" string="an" />
            <token id="11" string="interviewer" />
          </tokens>
        </chunking>
        <chunking id="4" string="Rolling Stone magazine" type="NP">
          <tokens>
            <token id="13" string="Rolling" />
            <token id="14" string="Stone" />
            <token id="15" string="magazine" />
          </tokens>
        </chunking>
        <chunking id="5" string="1983" type="NP">
          <tokens>
            <token id="17" string="1983" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="funny" type="ADJP">
          <tokens>
            <token id="5" string="funny" />
          </tokens>
        </chunking>
        <chunking id="8" string="told an interviewer for Rolling Stone magazine in 1983" type="VP">
          <tokens>
            <token id="9" string="told" />
            <token id="10" string="an" />
            <token id="11" string="interviewer" />
            <token id="12" string="for" />
            <token id="13" string="Rolling" />
            <token id="14" string="Stone" />
            <token id="15" string="magazine" />
            <token id="16" string="in" />
            <token id="17" string="1983" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">funny</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">funny</governor>
          <dependent id="3">am</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">funny</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">told</governor>
          <dependent id="5">funny</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">told</governor>
          <dependent id="8">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">interviewer</governor>
          <dependent id="10">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">told</governor>
          <dependent id="11">interviewer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">magazine</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">magazine</governor>
          <dependent id="13">Rolling</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">magazine</governor>
          <dependent id="14">Stone</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">told</governor>
          <dependent id="15">magazine</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">1983</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">told</governor>
          <dependent id="17">1983</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Rolling Stone" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Rolling" />
            <token id="14" string="Stone" />
          </tokens>
        </entity>
        <entity id="3" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="1983" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>&amp;quot;My writers were funny.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="writers" lemma="writer" stem="writer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="funny" lemma="funny" stem="funni" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP$ My) (NNS writers)) (VP (VBD were) (ADJP (JJ funny))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were funny" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="funny" />
          </tokens>
        </chunking>
        <chunking id="2" string="My writers" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="writers" />
          </tokens>
        </chunking>
        <chunking id="3" string="funny" type="ADJP">
          <tokens>
            <token id="5" string="funny" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">writers</governor>
          <dependent id="2">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">funny</governor>
          <dependent id="3">writers</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">funny</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">funny</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>My directors were funny.</content>
      <tokens>
        <token id="1" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="directors" lemma="director" stem="director" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="funny" lemma="funny" stem="funni" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ My) (NNS directors)) (VP (VBD were) (ADJP (JJ funny))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were funny" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="funny" />
          </tokens>
        </chunking>
        <chunking id="2" string="My directors" type="NP">
          <tokens>
            <token id="1" string="My" />
            <token id="2" string="directors" />
          </tokens>
        </chunking>
        <chunking id="3" string="funny" type="ADJP">
          <tokens>
            <token id="4" string="funny" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">directors</governor>
          <dependent id="1">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">funny</governor>
          <dependent id="2">directors</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">funny</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">funny</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="false">
      <content>The situations were funny. . . .</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="situations" lemma="situation" stem="situat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="funny" lemma="funny" stem="funni" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS situations)) (VP (VBD were) (ADJP (JJ funny))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were funny" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="funny" />
          </tokens>
        </chunking>
        <chunking id="2" string="The situations" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="situations" />
          </tokens>
        </chunking>
        <chunking id="3" string="funny" type="ADJP">
          <tokens>
            <token id="4" string="funny" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">situations</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">funny</governor>
          <dependent id="2">situations</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">funny</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">funny</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>What I am is brave.</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="brave" lemma="brave" stem="brave" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHNP (WP What)) (S (NP (PRP I)) (VP (VBP am) (VP (VBZ is))))) (VP (VBP brave)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="What I am is" type="SBAR">
          <tokens>
            <token id="1" string="What" />
            <token id="2" string="I" />
            <token id="3" string="am" />
            <token id="4" string="is" />
          </tokens>
        </chunking>
        <chunking id="2" string="am is" type="VP">
          <tokens>
            <token id="3" string="am" />
            <token id="4" string="is" />
          </tokens>
        </chunking>
        <chunking id="3" string="brave" type="VP">
          <tokens>
            <token id="5" string="brave" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="is" type="VP">
          <tokens>
            <token id="4" string="is" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dobj">
          <governor id="4">is</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">is</governor>
          <dependent id="3">am</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="5">brave</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">brave</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>I have never been scared.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="scared" lemma="scare" stem="scare" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP have) (ADVP (RB never)) (VP (VBN been) (ADJP (VBN scared)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="scared" type="ADJP">
          <tokens>
            <token id="5" string="scared" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="have never been scared" type="VP">
          <tokens>
            <token id="2" string="have" />
            <token id="3" string="never" />
            <token id="4" string="been" />
            <token id="5" string="scared" />
          </tokens>
        </chunking>
        <chunking id="4" string="been scared" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="scared" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">scared</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">scared</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">scared</governor>
          <dependent id="3">never</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">scared</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">scared</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Not when I did movies, certainly not when I was a model and not when I did &amp;quot;I Love Lucy.&amp;quot;</content>
      <tokens>
        <token id="1" string="Not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="movies" lemma="movie" stem="movi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="certainly" lemma="certainly" stem="certainli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="model" lemma="model" stem="model" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (RB Not) (WHADVP (WRB when)) (S (NP (PRP I)) (VP (VBD did) (NP (NNS movies)) (, ,) (SBAR (SBAR (WHADVP (ADVP (RB certainly) (RB not)) (WRB when)) (S (NP (PRP I)) (VP (VBD was) (NP (DT a) (NN model))))) (CC and) (SBAR (WHADVP (RB not) (WRB when))))))) (NP (PRP I)) (VP (VBD did) (S (NP (`` ``) (PRP I)) (NP (NNP Love) (NNP Lucy)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a model" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="model" />
          </tokens>
        </chunking>
        <chunking id="2" string="certainly not when I was a model and not when" type="SBAR">
          <tokens>
            <token id="7" string="certainly" />
            <token id="8" string="not" />
            <token id="9" string="when" />
            <token id="10" string="I" />
            <token id="11" string="was" />
            <token id="12" string="a" />
            <token id="13" string="model" />
            <token id="14" string="and" />
            <token id="15" string="not" />
            <token id="16" string="when" />
          </tokens>
        </chunking>
        <chunking id="3" string="was a model" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="a" />
            <token id="13" string="model" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` I" type="NP">
          <tokens>
            <token id="19" string="&quot;" />
            <token id="20" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="not when" type="SBAR">
          <tokens>
            <token id="15" string="not" />
            <token id="16" string="when" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="did movies , certainly not when I was a model and not when" type="VP">
          <tokens>
            <token id="4" string="did" />
            <token id="5" string="movies" />
            <token id="6" string="," />
            <token id="7" string="certainly" />
            <token id="8" string="not" />
            <token id="9" string="when" />
            <token id="10" string="I" />
            <token id="11" string="was" />
            <token id="12" string="a" />
            <token id="13" string="model" />
            <token id="14" string="and" />
            <token id="15" string="not" />
            <token id="16" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="2" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="movies" type="NP">
          <tokens>
            <token id="5" string="movies" />
          </tokens>
        </chunking>
        <chunking id="10" string="Not when I did movies , certainly not when I was a model and not when" type="SBAR">
          <tokens>
            <token id="1" string="Not" />
            <token id="2" string="when" />
            <token id="3" string="I" />
            <token id="4" string="did" />
            <token id="5" string="movies" />
            <token id="6" string="," />
            <token id="7" string="certainly" />
            <token id="8" string="not" />
            <token id="9" string="when" />
            <token id="10" string="I" />
            <token id="11" string="was" />
            <token id="12" string="a" />
            <token id="13" string="model" />
            <token id="14" string="and" />
            <token id="15" string="not" />
            <token id="16" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="certainly not when I was a model" type="SBAR">
          <tokens>
            <token id="7" string="certainly" />
            <token id="8" string="not" />
            <token id="9" string="when" />
            <token id="10" string="I" />
            <token id="11" string="was" />
            <token id="12" string="a" />
            <token id="13" string="model" />
          </tokens>
        </chunking>
        <chunking id="12" string="certainly not when" type="WHADVP">
          <tokens>
            <token id="7" string="certainly" />
            <token id="8" string="not" />
            <token id="9" string="when" />
          </tokens>
        </chunking>
        <chunking id="13" string="did `` I Love Lucy" type="VP">
          <tokens>
            <token id="18" string="did" />
            <token id="19" string="&quot;" />
            <token id="20" string="I" />
            <token id="21" string="Love" />
            <token id="22" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="14" string="Love Lucy" type="NP">
          <tokens>
            <token id="21" string="Love" />
            <token id="22" string="Lucy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="4">did</governor>
          <dependent id="1">Not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">did</governor>
          <dependent id="2">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">did</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">did</governor>
          <dependent id="4">did</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">did</governor>
          <dependent id="5">movies</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">not</governor>
          <dependent id="7">certainly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">when</governor>
          <dependent id="8">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">model</governor>
          <dependent id="9">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">model</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">model</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">model</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">did</governor>
          <dependent id="13">model</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">model</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">when</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">model</governor>
          <dependent id="16">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">did</governor>
          <dependent id="17">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">did</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">Lucy</governor>
          <dependent id="20">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Lucy</governor>
          <dependent id="21">Love</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">did</governor>
          <dependent id="22">Lucy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>It was &amp;quot;I Love Lucy,&amp;quot; which premiered on CBS on Oct. 15, 1951, that earned Miss Ball her niche in television history.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="premiered" lemma="premiere" stem="premier" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="CBS" lemma="CBS" stem="cbs" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="15" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="17" string="1951" lemma="1951" stem="1951" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="earned" lemma="earn" stem="earn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="niche" lemma="niche" stem="nich" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (`` ``) (NP (NP (PRP I)) (NP (NP (NNP Love) (NNP Lucy)) (, ,) ('' '') (SBAR (WHNP (WDT which)) (S (VP (VBD premiered) (PP (IN on) (NP (NNP CBS))) (PP (IN on) (NP (NNP Oct.) (CD 15) (, ,) (CD 1951)))))) (, ,) (SBAR (WHNP (WDT that)) (S (VP (VBD earned) (NP (NNP Miss) (NNP Ball)) (NP (NP (PRP$ her) (NN niche)) (PP (IN in) (NP (NN television) (NN history)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her niche in television history" type="NP">
          <tokens>
            <token id="23" string="her" />
            <token id="24" string="niche" />
            <token id="25" string="in" />
            <token id="26" string="television" />
            <token id="27" string="history" />
          </tokens>
        </chunking>
        <chunking id="2" string="Love Lucy , '' which premiered on CBS on Oct. 15 , 1951 , that earned Miss Ball her niche in television history" type="NP">
          <tokens>
            <token id="5" string="Love" />
            <token id="6" string="Lucy" />
            <token id="7" string="," />
            <token id="8" string="&quot;" />
            <token id="9" string="which" />
            <token id="10" string="premiered" />
            <token id="11" string="on" />
            <token id="12" string="CBS" />
            <token id="13" string="on" />
            <token id="14" string="Oct." />
            <token id="15" string="15" />
            <token id="16" string="," />
            <token id="17" string="1951" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="earned" />
            <token id="21" string="Miss" />
            <token id="22" string="Ball" />
            <token id="23" string="her" />
            <token id="24" string="niche" />
            <token id="25" string="in" />
            <token id="26" string="television" />
            <token id="27" string="history" />
          </tokens>
        </chunking>
        <chunking id="3" string="I Love Lucy , '' which premiered on CBS on Oct. 15 , 1951 , that earned Miss Ball her niche in television history" type="NP">
          <tokens>
            <token id="4" string="I" />
            <token id="5" string="Love" />
            <token id="6" string="Lucy" />
            <token id="7" string="," />
            <token id="8" string="&quot;" />
            <token id="9" string="which" />
            <token id="10" string="premiered" />
            <token id="11" string="on" />
            <token id="12" string="CBS" />
            <token id="13" string="on" />
            <token id="14" string="Oct." />
            <token id="15" string="15" />
            <token id="16" string="," />
            <token id="17" string="1951" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="earned" />
            <token id="21" string="Miss" />
            <token id="22" string="Ball" />
            <token id="23" string="her" />
            <token id="24" string="niche" />
            <token id="25" string="in" />
            <token id="26" string="television" />
            <token id="27" string="history" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="4" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="was `` I Love Lucy , '' which premiered on CBS on Oct. 15 , 1951 , that earned Miss Ball her niche in television history" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="&quot;" />
            <token id="4" string="I" />
            <token id="5" string="Love" />
            <token id="6" string="Lucy" />
            <token id="7" string="," />
            <token id="8" string="&quot;" />
            <token id="9" string="which" />
            <token id="10" string="premiered" />
            <token id="11" string="on" />
            <token id="12" string="CBS" />
            <token id="13" string="on" />
            <token id="14" string="Oct." />
            <token id="15" string="15" />
            <token id="16" string="," />
            <token id="17" string="1951" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="earned" />
            <token id="21" string="Miss" />
            <token id="22" string="Ball" />
            <token id="23" string="her" />
            <token id="24" string="niche" />
            <token id="25" string="in" />
            <token id="26" string="television" />
            <token id="27" string="history" />
          </tokens>
        </chunking>
        <chunking id="7" string="earned Miss Ball her niche in television history" type="VP">
          <tokens>
            <token id="20" string="earned" />
            <token id="21" string="Miss" />
            <token id="22" string="Ball" />
            <token id="23" string="her" />
            <token id="24" string="niche" />
            <token id="25" string="in" />
            <token id="26" string="television" />
            <token id="27" string="history" />
          </tokens>
        </chunking>
        <chunking id="8" string="Oct. 15 , 1951" type="NP">
          <tokens>
            <token id="14" string="Oct." />
            <token id="15" string="15" />
            <token id="16" string="," />
            <token id="17" string="1951" />
          </tokens>
        </chunking>
        <chunking id="9" string="CBS" type="NP">
          <tokens>
            <token id="12" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="10" string="that earned Miss Ball her niche in television history" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="earned" />
            <token id="21" string="Miss" />
            <token id="22" string="Ball" />
            <token id="23" string="her" />
            <token id="24" string="niche" />
            <token id="25" string="in" />
            <token id="26" string="television" />
            <token id="27" string="history" />
          </tokens>
        </chunking>
        <chunking id="11" string="television history" type="NP">
          <tokens>
            <token id="26" string="television" />
            <token id="27" string="history" />
          </tokens>
        </chunking>
        <chunking id="12" string="which premiered on CBS on Oct. 15 , 1951" type="SBAR">
          <tokens>
            <token id="9" string="which" />
            <token id="10" string="premiered" />
            <token id="11" string="on" />
            <token id="12" string="CBS" />
            <token id="13" string="on" />
            <token id="14" string="Oct." />
            <token id="15" string="15" />
            <token id="16" string="," />
            <token id="17" string="1951" />
          </tokens>
        </chunking>
        <chunking id="13" string="premiered on CBS on Oct. 15 , 1951" type="VP">
          <tokens>
            <token id="10" string="premiered" />
            <token id="11" string="on" />
            <token id="12" string="CBS" />
            <token id="13" string="on" />
            <token id="14" string="Oct." />
            <token id="15" string="15" />
            <token id="16" string="," />
            <token id="17" string="1951" />
          </tokens>
        </chunking>
        <chunking id="14" string="her niche" type="NP">
          <tokens>
            <token id="23" string="her" />
            <token id="24" string="niche" />
          </tokens>
        </chunking>
        <chunking id="15" string="Love Lucy" type="NP">
          <tokens>
            <token id="5" string="Love" />
            <token id="6" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="16" string="Miss Ball" type="NP">
          <tokens>
            <token id="21" string="Miss" />
            <token id="22" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">I</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">I</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Lucy</governor>
          <dependent id="5">Love</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">I</governor>
          <dependent id="6">Lucy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">premiered</governor>
          <dependent id="9">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">Lucy</governor>
          <dependent id="10">premiered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">CBS</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">premiered</governor>
          <dependent id="12">CBS</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Oct.</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">premiered</governor>
          <dependent id="14">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">Oct.</governor>
          <dependent id="15">15</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">Oct.</governor>
          <dependent id="17">1951</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">earned</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">Lucy</governor>
          <dependent id="20">earned</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Ball</governor>
          <dependent id="21">Miss</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="20">earned</governor>
          <dependent id="22">Ball</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">niche</governor>
          <dependent id="23">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">earned</governor>
          <dependent id="24">niche</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">history</governor>
          <dependent id="25">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">history</governor>
          <dependent id="26">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">niche</governor>
          <dependent id="27">history</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oct. 15 , 1951" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="Oct." />
            <token id="15" string="15" />
            <token id="16" string="," />
            <token id="17" string="1951" />
          </tokens>
        </entity>
        <entity id="2" string="CBS" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="CBS" />
          </tokens>
        </entity>
        <entity id="3" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>The 30-minute comedy starred Miss Ball and the Cuban-born Arnaz as the wacky Lucy Ricardo and her conga-playing husband Ricky.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="30-minute" lemma="30-minute" stem="30-minut" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="comedy" lemma="comedy" stem="comedi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="starred" lemma="star" stem="star" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="Cuban-born" lemma="cuban-born" stem="cuban-born" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="10" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="wacky" lemma="wacky" stem="wacki" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Ricardo" lemma="Ricardo" stem="ricardo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="conga-playing" lemma="conga-playing" stem="conga-plai" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="Ricky" lemma="Ricky" stem="ricki" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ 30-minute) (NN comedy)) (VP (VBD starred) (NP (NP (NNP Miss) (NNP Ball)) (CC and) (NP (DT the) (JJ Cuban-born) (NNP Arnaz))) (PP (IN as) (NP (NP (DT the) (JJ wacky) (NNP Lucy) (NNP Ricardo)) (CC and) (NP (NP (PRP$ her) (JJ conga-playing) (NN husband)) (NP (NNP Ricky)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the wacky Lucy Ricardo and her conga-playing husband Ricky" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="wacky" />
            <token id="14" string="Lucy" />
            <token id="15" string="Ricardo" />
            <token id="16" string="and" />
            <token id="17" string="her" />
            <token id="18" string="conga-playing" />
            <token id="19" string="husband" />
            <token id="20" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="2" string="her conga-playing husband" type="NP">
          <tokens>
            <token id="17" string="her" />
            <token id="18" string="conga-playing" />
            <token id="19" string="husband" />
          </tokens>
        </chunking>
        <chunking id="3" string="The 30-minute comedy" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="30-minute" />
            <token id="3" string="comedy" />
          </tokens>
        </chunking>
        <chunking id="4" string="starred Miss Ball and the Cuban-born Arnaz as the wacky Lucy Ricardo and her conga-playing husband Ricky" type="VP">
          <tokens>
            <token id="4" string="starred" />
            <token id="5" string="Miss" />
            <token id="6" string="Ball" />
            <token id="7" string="and" />
            <token id="8" string="the" />
            <token id="9" string="Cuban-born" />
            <token id="10" string="Arnaz" />
            <token id="11" string="as" />
            <token id="12" string="the" />
            <token id="13" string="wacky" />
            <token id="14" string="Lucy" />
            <token id="15" string="Ricardo" />
            <token id="16" string="and" />
            <token id="17" string="her" />
            <token id="18" string="conga-playing" />
            <token id="19" string="husband" />
            <token id="20" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="5" string="Miss Ball and the Cuban-born Arnaz" type="NP">
          <tokens>
            <token id="5" string="Miss" />
            <token id="6" string="Ball" />
            <token id="7" string="and" />
            <token id="8" string="the" />
            <token id="9" string="Cuban-born" />
            <token id="10" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="6" string="the wacky Lucy Ricardo" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="wacky" />
            <token id="14" string="Lucy" />
            <token id="15" string="Ricardo" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Cuban-born Arnaz" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="Cuban-born" />
            <token id="10" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="8" string="her conga-playing husband Ricky" type="NP">
          <tokens>
            <token id="17" string="her" />
            <token id="18" string="conga-playing" />
            <token id="19" string="husband" />
            <token id="20" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ricky" type="NP">
          <tokens>
            <token id="20" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="10" string="Miss Ball" type="NP">
          <tokens>
            <token id="5" string="Miss" />
            <token id="6" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">comedy</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">comedy</governor>
          <dependent id="2">30-minute</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">starred</governor>
          <dependent id="3">comedy</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">starred</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Ball</governor>
          <dependent id="5">Miss</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">starred</governor>
          <dependent id="6">Ball</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Ball</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Arnaz</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Arnaz</governor>
          <dependent id="9">Cuban-born</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Ball</governor>
          <dependent id="10">Arnaz</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Ricardo</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Ricardo</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Ricardo</governor>
          <dependent id="13">wacky</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Ricardo</governor>
          <dependent id="14">Lucy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">starred</governor>
          <dependent id="15">Ricardo</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">Ricardo</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">husband</governor>
          <dependent id="17">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">husband</governor>
          <dependent id="18">conga-playing</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">Ricardo</governor>
          <dependent id="19">husband</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="19">husband</governor>
          <dependent id="20">Ricky</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy Ricardo" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lucy" />
            <token id="15" string="Ricardo" />
          </tokens>
        </entity>
        <entity id="2" string="Cuban-born" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Cuban-born" />
          </tokens>
        </entity>
        <entity id="3" string="Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Arnaz" />
          </tokens>
        </entity>
        <entity id="4" string="30-minute" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="30-minute" />
          </tokens>
        </entity>
        <entity id="5" string="Ricky" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Ricky" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>The show was a weekly dash into absurdity that boasted the biggest television audience of its time -- of almost any time.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="weekly" lemma="weekly" stem="weekli" pos="JJ" type="Word" isStopWord="false" ner="SET" is_referenced="true" is_refers="false" />
        <token id="6" string="dash" lemma="dash" stem="dash" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="absurdity" lemma="absurdity" stem="absurd" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="boasted" lemma="boast" stem="boast" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="biggest" lemma="biggest" stem="biggest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="audience" lemma="audience" stem="audienc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN show)) (VP (VBD was) (NP (DT a) (JJ weekly) (NN dash)) (PP (IN into) (NP (NP (NN absurdity)) (SBAR (WHNP (WDT that)) (S (VP (VBD boasted) (NP (NP (NP (DT the) (JJS biggest) (NN television) (NN audience)) (PP (IN of) (NP (PRP$ its) (NN time)))) (: --) (PP (IN of) (NP (RB almost) (DT any) (NN time)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="absurdity that boasted the biggest television audience of its time -- of almost any time" type="NP">
          <tokens>
            <token id="8" string="absurdity" />
            <token id="9" string="that" />
            <token id="10" string="boasted" />
            <token id="11" string="the" />
            <token id="12" string="biggest" />
            <token id="13" string="television" />
            <token id="14" string="audience" />
            <token id="15" string="of" />
            <token id="16" string="its" />
            <token id="17" string="time" />
            <token id="18" string="--" />
            <token id="19" string="of" />
            <token id="20" string="almost" />
            <token id="21" string="any" />
            <token id="22" string="time" />
          </tokens>
        </chunking>
        <chunking id="2" string="that boasted the biggest television audience of its time -- of almost any time" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="boasted" />
            <token id="11" string="the" />
            <token id="12" string="biggest" />
            <token id="13" string="television" />
            <token id="14" string="audience" />
            <token id="15" string="of" />
            <token id="16" string="its" />
            <token id="17" string="time" />
            <token id="18" string="--" />
            <token id="19" string="of" />
            <token id="20" string="almost" />
            <token id="21" string="any" />
            <token id="22" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="the biggest television audience of its time -- of almost any time" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="biggest" />
            <token id="13" string="television" />
            <token id="14" string="audience" />
            <token id="15" string="of" />
            <token id="16" string="its" />
            <token id="17" string="time" />
            <token id="18" string="--" />
            <token id="19" string="of" />
            <token id="20" string="almost" />
            <token id="21" string="any" />
            <token id="22" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="its time" type="NP">
          <tokens>
            <token id="16" string="its" />
            <token id="17" string="time" />
          </tokens>
        </chunking>
        <chunking id="5" string="absurdity" type="NP">
          <tokens>
            <token id="8" string="absurdity" />
          </tokens>
        </chunking>
        <chunking id="6" string="The show" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="show" />
          </tokens>
        </chunking>
        <chunking id="7" string="boasted the biggest television audience of its time -- of almost any time" type="VP">
          <tokens>
            <token id="10" string="boasted" />
            <token id="11" string="the" />
            <token id="12" string="biggest" />
            <token id="13" string="television" />
            <token id="14" string="audience" />
            <token id="15" string="of" />
            <token id="16" string="its" />
            <token id="17" string="time" />
            <token id="18" string="--" />
            <token id="19" string="of" />
            <token id="20" string="almost" />
            <token id="21" string="any" />
            <token id="22" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="the biggest television audience of its time" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="biggest" />
            <token id="13" string="television" />
            <token id="14" string="audience" />
            <token id="15" string="of" />
            <token id="16" string="its" />
            <token id="17" string="time" />
          </tokens>
        </chunking>
        <chunking id="9" string="the biggest television audience" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="biggest" />
            <token id="13" string="television" />
            <token id="14" string="audience" />
          </tokens>
        </chunking>
        <chunking id="10" string="was a weekly dash into absurdity that boasted the biggest television audience of its time -- of almost any time" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="weekly" />
            <token id="6" string="dash" />
            <token id="7" string="into" />
            <token id="8" string="absurdity" />
            <token id="9" string="that" />
            <token id="10" string="boasted" />
            <token id="11" string="the" />
            <token id="12" string="biggest" />
            <token id="13" string="television" />
            <token id="14" string="audience" />
            <token id="15" string="of" />
            <token id="16" string="its" />
            <token id="17" string="time" />
            <token id="18" string="--" />
            <token id="19" string="of" />
            <token id="20" string="almost" />
            <token id="21" string="any" />
            <token id="22" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="almost any time" type="NP">
          <tokens>
            <token id="20" string="almost" />
            <token id="21" string="any" />
            <token id="22" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="a weekly dash" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="weekly" />
            <token id="6" string="dash" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">show</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">dash</governor>
          <dependent id="2">show</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">dash</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">dash</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">dash</governor>
          <dependent id="5">weekly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">dash</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">absurdity</governor>
          <dependent id="7">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">dash</governor>
          <dependent id="8">absurdity</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">boasted</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">absurdity</governor>
          <dependent id="10">boasted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">audience</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">audience</governor>
          <dependent id="12">biggest</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">audience</governor>
          <dependent id="13">television</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">boasted</governor>
          <dependent id="14">audience</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">time</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">time</governor>
          <dependent id="16">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">audience</governor>
          <dependent id="17">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">time</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">time</governor>
          <dependent id="20">almost</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">time</governor>
          <dependent id="21">any</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">audience</governor>
          <dependent id="22">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="weekly" type="SET" score="0.0">
          <tokens>
            <token id="5" string="weekly" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Stopped the Nation In creating the show, Miss Ball and Arnaz -- who died in 1986 -- set a pattern of television that was to be repeated in decades to come.</content>
      <tokens>
        <token id="1" string="Stopped" lemma="stop" stem="stop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Nation" lemma="Nation" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="4" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="5" string="creating" lemma="create" stem="creat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="pattern" lemma="pattern" stem="pattern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="repeated" lemma="repeat" stem="repeat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Stopped) (S (NP (DT the) (NNP Nation)) (PP (IN In) (S (VP (VBG creating) (NP (DT the) (NN show)))))))) (, ,) (NP (NP (NNP Miss) (NNP Ball) (CC and) (NNP Arnaz)) (PRN (: --) (SBAR (WHNP (WP who)) (S (VP (VBD died) (PP (IN in) (NP (CD 1986)))))) (: --))) (VP (VBD set) (NP (NP (DT a) (NN pattern)) (PP (IN of) (NP (NN television))) (SBAR (WHNP (WDT that)) (S (VP (VBD was) (S (VP (TO to) (VP (VB be) (VP (VBN repeated) (PP (IN in) (NP (NNS decades))) (S (VP (TO to) (VP (VB come))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who died in 1986" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="died" />
            <token id="16" string="in" />
            <token id="17" string="1986" />
          </tokens>
        </chunking>
        <chunking id="2" string="set a pattern of television that was to be repeated in decades to come" type="VP">
          <tokens>
            <token id="19" string="set" />
            <token id="20" string="a" />
            <token id="21" string="pattern" />
            <token id="22" string="of" />
            <token id="23" string="television" />
            <token id="24" string="that" />
            <token id="25" string="was" />
            <token id="26" string="to" />
            <token id="27" string="be" />
            <token id="28" string="repeated" />
            <token id="29" string="in" />
            <token id="30" string="decades" />
            <token id="31" string="to" />
            <token id="32" string="come" />
          </tokens>
        </chunking>
        <chunking id="3" string="television" type="NP">
          <tokens>
            <token id="23" string="television" />
          </tokens>
        </chunking>
        <chunking id="4" string="Miss Ball and Arnaz" type="NP">
          <tokens>
            <token id="9" string="Miss" />
            <token id="10" string="Ball" />
            <token id="11" string="and" />
            <token id="12" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="5" string="a pattern of television that was to be repeated in decades to come" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="pattern" />
            <token id="22" string="of" />
            <token id="23" string="television" />
            <token id="24" string="that" />
            <token id="25" string="was" />
            <token id="26" string="to" />
            <token id="27" string="be" />
            <token id="28" string="repeated" />
            <token id="29" string="in" />
            <token id="30" string="decades" />
            <token id="31" string="to" />
            <token id="32" string="come" />
          </tokens>
        </chunking>
        <chunking id="6" string="to come" type="VP">
          <tokens>
            <token id="31" string="to" />
            <token id="32" string="come" />
          </tokens>
        </chunking>
        <chunking id="7" string="Miss Ball and Arnaz -- who died in 1986 --" type="NP">
          <tokens>
            <token id="9" string="Miss" />
            <token id="10" string="Ball" />
            <token id="11" string="and" />
            <token id="12" string="Arnaz" />
            <token id="13" string="--" />
            <token id="14" string="who" />
            <token id="15" string="died" />
            <token id="16" string="in" />
            <token id="17" string="1986" />
            <token id="18" string="--" />
          </tokens>
        </chunking>
        <chunking id="8" string="the show" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="show" />
          </tokens>
        </chunking>
        <chunking id="9" string="that was to be repeated in decades to come" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="was" />
            <token id="26" string="to" />
            <token id="27" string="be" />
            <token id="28" string="repeated" />
            <token id="29" string="in" />
            <token id="30" string="decades" />
            <token id="31" string="to" />
            <token id="32" string="come" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Nation" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="Nation" />
          </tokens>
        </chunking>
        <chunking id="11" string="died in 1986" type="VP">
          <tokens>
            <token id="15" string="died" />
            <token id="16" string="in" />
            <token id="17" string="1986" />
          </tokens>
        </chunking>
        <chunking id="12" string="come" type="VP">
          <tokens>
            <token id="32" string="come" />
          </tokens>
        </chunking>
        <chunking id="13" string="creating the show" type="VP">
          <tokens>
            <token id="5" string="creating" />
            <token id="6" string="the" />
            <token id="7" string="show" />
          </tokens>
        </chunking>
        <chunking id="14" string="1986" type="NP">
          <tokens>
            <token id="17" string="1986" />
          </tokens>
        </chunking>
        <chunking id="15" string="to be repeated in decades to come" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="be" />
            <token id="28" string="repeated" />
            <token id="29" string="in" />
            <token id="30" string="decades" />
            <token id="31" string="to" />
            <token id="32" string="come" />
          </tokens>
        </chunking>
        <chunking id="16" string="Stopped the Nation In creating the show" type="VP">
          <tokens>
            <token id="1" string="Stopped" />
            <token id="2" string="the" />
            <token id="3" string="Nation" />
            <token id="4" string="In" />
            <token id="5" string="creating" />
            <token id="6" string="the" />
            <token id="7" string="show" />
          </tokens>
        </chunking>
        <chunking id="17" string="was to be repeated in decades to come" type="VP">
          <tokens>
            <token id="25" string="was" />
            <token id="26" string="to" />
            <token id="27" string="be" />
            <token id="28" string="repeated" />
            <token id="29" string="in" />
            <token id="30" string="decades" />
            <token id="31" string="to" />
            <token id="32" string="come" />
          </tokens>
        </chunking>
        <chunking id="18" string="decades" type="NP">
          <tokens>
            <token id="30" string="decades" />
          </tokens>
        </chunking>
        <chunking id="19" string="a pattern" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="pattern" />
          </tokens>
        </chunking>
        <chunking id="20" string="be repeated in decades to come" type="VP">
          <tokens>
            <token id="27" string="be" />
            <token id="28" string="repeated" />
            <token id="29" string="in" />
            <token id="30" string="decades" />
            <token id="31" string="to" />
            <token id="32" string="come" />
          </tokens>
        </chunking>
        <chunking id="21" string="repeated in decades to come" type="VP">
          <tokens>
            <token id="28" string="repeated" />
            <token id="29" string="in" />
            <token id="30" string="decades" />
            <token id="31" string="to" />
            <token id="32" string="come" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="19">set</governor>
          <dependent id="1">Stopped</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">Nation</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="1">Stopped</governor>
          <dependent id="3">Nation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">creating</governor>
          <dependent id="4">In</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">Nation</governor>
          <dependent id="5">creating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">show</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">creating</governor>
          <dependent id="7">show</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Ball</governor>
          <dependent id="9">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">set</governor>
          <dependent id="10">Ball</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">Ball</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Ball</governor>
          <dependent id="12">Arnaz</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">died</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">Ball</governor>
          <dependent id="15">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">1986</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">died</governor>
          <dependent id="17">1986</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">set</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">pattern</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">set</governor>
          <dependent id="21">pattern</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">television</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">pattern</governor>
          <dependent id="23">television</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">was</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">pattern</governor>
          <dependent id="25">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">repeated</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">repeated</governor>
          <dependent id="27">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">was</governor>
          <dependent id="28">repeated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">decades</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">repeated</governor>
          <dependent id="30">decades</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">come</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">repeated</governor>
          <dependent id="32">come</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1986" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="1986" />
          </tokens>
        </entity>
        <entity id="2" string="Nation In" type="MISC" score="0.0">
          <tokens>
            <token id="3" string="Nation" />
            <token id="4" string="In" />
          </tokens>
        </entity>
        <entity id="3" string="decades" type="DURATION" score="0.0">
          <tokens>
            <token id="30" string="decades" />
          </tokens>
        </entity>
        <entity id="4" string="Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Arnaz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>They filmed the programs in front of a live audience and in doing so, invented the popular and financially rewarding rerun.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="filmed" lemma="film" stem="film" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="programs" lemma="program" stem="program" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="front" lemma="front" stem="front" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="live" lemma="live" stem="live" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="audience" lemma="audience" stem="audienc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="invented" lemma="invent" stem="invent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="popular" lemma="popular" stem="popular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="financially" lemma="financially" stem="financi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="rewarding" lemma="rewarding" stem="reward" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="rerun" lemma="rerun" stem="rerun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (PRP They)) (VP (VBD filmed) (NP (DT the) (NNS programs)) (PP (PP (IN in) (NP (NP (NN front)) (PP (IN of) (NP (DT a) (JJ live) (NN audience))))) (CC and) (PP (IN in) (S (VP (VBG doing) (ADVP (RB so)))))))) (, ,) (VP (VBD invented)) (NP (DT the) (ADJP (ADJP (JJ popular)) (CC and) (ADJP (RB financially) (JJ rewarding))) (NN rerun)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="a live audience" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="live" />
            <token id="10" string="audience" />
          </tokens>
        </chunking>
        <chunking id="3" string="popular and financially rewarding" type="ADJP">
          <tokens>
            <token id="18" string="popular" />
            <token id="19" string="and" />
            <token id="20" string="financially" />
            <token id="21" string="rewarding" />
          </tokens>
        </chunking>
        <chunking id="4" string="front of a live audience" type="NP">
          <tokens>
            <token id="6" string="front" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="live" />
            <token id="10" string="audience" />
          </tokens>
        </chunking>
        <chunking id="5" string="financially rewarding" type="ADJP">
          <tokens>
            <token id="20" string="financially" />
            <token id="21" string="rewarding" />
          </tokens>
        </chunking>
        <chunking id="6" string="doing so" type="VP">
          <tokens>
            <token id="13" string="doing" />
            <token id="14" string="so" />
          </tokens>
        </chunking>
        <chunking id="7" string="filmed the programs in front of a live audience and in doing so" type="VP">
          <tokens>
            <token id="2" string="filmed" />
            <token id="3" string="the" />
            <token id="4" string="programs" />
            <token id="5" string="in" />
            <token id="6" string="front" />
            <token id="7" string="of" />
            <token id="8" string="a" />
            <token id="9" string="live" />
            <token id="10" string="audience" />
            <token id="11" string="and" />
            <token id="12" string="in" />
            <token id="13" string="doing" />
            <token id="14" string="so" />
          </tokens>
        </chunking>
        <chunking id="8" string="front" type="NP">
          <tokens>
            <token id="6" string="front" />
          </tokens>
        </chunking>
        <chunking id="9" string="the popular and financially rewarding rerun" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="popular" />
            <token id="19" string="and" />
            <token id="20" string="financially" />
            <token id="21" string="rewarding" />
            <token id="22" string="rerun" />
          </tokens>
        </chunking>
        <chunking id="10" string="popular" type="ADJP">
          <tokens>
            <token id="18" string="popular" />
          </tokens>
        </chunking>
        <chunking id="11" string="the programs" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="programs" />
          </tokens>
        </chunking>
        <chunking id="12" string="invented" type="VP">
          <tokens>
            <token id="16" string="invented" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">filmed</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">invented</governor>
          <dependent id="2">filmed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">programs</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">filmed</governor>
          <dependent id="4">programs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">audience</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="5">in</governor>
          <dependent id="6">front</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="5">in</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">audience</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">audience</governor>
          <dependent id="9">live</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">filmed</governor>
          <dependent id="10">audience</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">audience</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">doing</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">audience</governor>
          <dependent id="13">doing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">doing</governor>
          <dependent id="14">so</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">invented</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">rerun</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">rerun</governor>
          <dependent id="18">popular</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">popular</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">rewarding</governor>
          <dependent id="20">financially</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">popular</governor>
          <dependent id="21">rewarding</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">invented</governor>
          <dependent id="22">rerun</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>The show was so popular during the 1950s that it literally stopped the nation every Monday night from 9 p.m. to 9:30 p.m.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="popular" lemma="popular" stem="popular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="1950s" lemma="1950" stem="1950" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="literally" lemma="literally" stem="liter" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="stopped" lemma="stop" stem="stop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="16" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="18" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="20" string="p.m." lemma="p.m." stem="p.m." pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="9:30" lemma="9:30" stem="9:30" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="23" string="p.m" lemma="p.m." stem="p.m" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN show)) (VP (VBD was) (ADJP (RB so) (JJ popular) (PP (IN during) (NP (DT the) (NNS 1950s)))) (SBAR (IN that) (S (NP (PRP it)) (ADVP (RB literally)) (VP (VBD stopped) (NP (DT the) (NN nation)) (PP (NP (DT every) (NNP Monday) (NN night)) (IN from) (NP (CD 9) (NN p.m.))) (PP (TO to) (NP (CD 9:30))) (NP-TMP (NN p.m.)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was so popular during the 1950s that it literally stopped the nation every Monday night from 9 p.m. to 9:30 p.m." type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="so" />
            <token id="5" string="popular" />
            <token id="6" string="during" />
            <token id="7" string="the" />
            <token id="8" string="1950s" />
            <token id="9" string="that" />
            <token id="10" string="it" />
            <token id="11" string="literally" />
            <token id="12" string="stopped" />
            <token id="13" string="the" />
            <token id="14" string="nation" />
            <token id="15" string="every" />
            <token id="16" string="Monday" />
            <token id="17" string="night" />
            <token id="18" string="from" />
            <token id="19" string="9" />
            <token id="20" string="p.m." />
            <token id="21" string="to" />
            <token id="22" string="9:30" />
            <token id="23" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="2" string="the nation" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="nation" />
          </tokens>
        </chunking>
        <chunking id="3" string="The show" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="show" />
          </tokens>
        </chunking>
        <chunking id="4" string="9:30" type="NP">
          <tokens>
            <token id="22" string="9:30" />
          </tokens>
        </chunking>
        <chunking id="5" string="that it literally stopped the nation every Monday night from 9 p.m. to 9:30 p.m." type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="it" />
            <token id="11" string="literally" />
            <token id="12" string="stopped" />
            <token id="13" string="the" />
            <token id="14" string="nation" />
            <token id="15" string="every" />
            <token id="16" string="Monday" />
            <token id="17" string="night" />
            <token id="18" string="from" />
            <token id="19" string="9" />
            <token id="20" string="p.m." />
            <token id="21" string="to" />
            <token id="22" string="9:30" />
            <token id="23" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="6" string="so popular during the 1950s" type="ADJP">
          <tokens>
            <token id="4" string="so" />
            <token id="5" string="popular" />
            <token id="6" string="during" />
            <token id="7" string="the" />
            <token id="8" string="1950s" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 1950s" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="1950s" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="stopped the nation every Monday night from 9 p.m. to 9:30 p.m." type="VP">
          <tokens>
            <token id="12" string="stopped" />
            <token id="13" string="the" />
            <token id="14" string="nation" />
            <token id="15" string="every" />
            <token id="16" string="Monday" />
            <token id="17" string="night" />
            <token id="18" string="from" />
            <token id="19" string="9" />
            <token id="20" string="p.m." />
            <token id="21" string="to" />
            <token id="22" string="9:30" />
            <token id="23" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="10" string="every Monday night" type="NP">
          <tokens>
            <token id="15" string="every" />
            <token id="16" string="Monday" />
            <token id="17" string="night" />
          </tokens>
        </chunking>
        <chunking id="11" string="9 p.m." type="NP">
          <tokens>
            <token id="19" string="9" />
            <token id="20" string="p.m." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">show</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">popular</governor>
          <dependent id="2">show</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">popular</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">popular</governor>
          <dependent id="4">so</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">popular</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1950s</governor>
          <dependent id="6">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">1950s</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">popular</governor>
          <dependent id="8">1950s</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">stopped</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">stopped</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">stopped</governor>
          <dependent id="11">literally</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">popular</governor>
          <dependent id="12">stopped</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">nation</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">stopped</governor>
          <dependent id="14">nation</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">night</governor>
          <dependent id="15">every</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">night</governor>
          <dependent id="16">Monday</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">stopped</governor>
          <dependent id="17">night</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">night</governor>
          <dependent id="18">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">p.m.</governor>
          <dependent id="19">9</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">night</governor>
          <dependent id="20">p.m.</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">9:30</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">stopped</governor>
          <dependent id="22">9:30</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">stopped</governor>
          <dependent id="23">p.m.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="9:30 p.m" type="TIME" score="0.0">
          <tokens>
            <token id="22" string="9:30" />
            <token id="23" string="p.m" />
          </tokens>
        </entity>
        <entity id="2" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="17" string="night" />
          </tokens>
        </entity>
        <entity id="3" string="the 1950s" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="1950s" />
          </tokens>
        </entity>
        <entity id="4" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="Monday" />
          </tokens>
        </entity>
        <entity id="5" string="every" type="SET" score="0.0">
          <tokens>
            <token id="15" string="every" />
          </tokens>
        </entity>
        <entity id="6" string="9 p.m." type="TIME" score="0.0">
          <tokens>
            <token id="19" string="9" />
            <token id="20" string="p.m." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>In fact, nighttime shoppers became so scarce in Chicago that the mammoth Marshall Field department store posted a sign that read: &amp;quot;We Love Lucy, too, so from now on we will be open Thursday night instead of Monday.&amp;quot;</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="nighttime" lemma="nighttime" stem="nighttim" pos="JJ" type="Word" isStopWord="false" ner="TIME" is_referenced="true" is_refers="false" />
        <token id="5" string="shoppers" lemma="shopper" stem="shopper" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="scarce" lemma="scarce" stem="scarc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Chicago" lemma="Chicago" stem="chicago" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="mammoth" lemma="mammoth" stem="mammoth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Marshall" lemma="Marshall" stem="marshal" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Field" lemma="Field" stem="field" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="store" lemma="store" stem="store" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="posted" lemma="post" stem="post" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="sign" lemma="sign" stem="sign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="read" lemma="read" stem="read" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="34" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="open" lemma="open" stem="open" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="40" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="41" string="instead" lemma="instead" stem="instead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="Monday" lemma="Monday" stem="mondai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN In) (NP (NN fact))) (, ,) (NP (JJ nighttime) (NNS shoppers)) (VP (VBD became) (ADJP (RB so) (JJ scarce)) (PP (IN in) (NP (NNP Chicago))) (SBAR (IN that) (S (NP (DT the) (JJ mammoth) (NNP Marshall) (NNP Field) (NN department) (NN store)) (VP (VBD posted) (NP (DT a) (NN sign)) (SBAR (IN that) (FRAG (NP (NN read))))))))) (: :) (`` ``) (S (NP (PRP We)) (ADVP (ADVP (NP (NP (NNP Love) (NNP Lucy)) (PRN (, ,) (ADVP (RB too)) (, ,))) (RB so) (PP (IN from) (ADVP (RB now)))) (PP (IN on) (NP (PRP we)))) (VP (MD will) (VP (VB be) (NP (NP (ADJP (JJ open) (NP-TMP (NNP Thursday))) (NN night)) (PP (RB instead) (IN of) (NP (NNP Monday))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="read" type="NP">
          <tokens>
            <token id="22" string="read" />
          </tokens>
        </chunking>
        <chunking id="2" string="became so scarce in Chicago that the mammoth Marshall Field department store posted a sign that read" type="VP">
          <tokens>
            <token id="6" string="became" />
            <token id="7" string="so" />
            <token id="8" string="scarce" />
            <token id="9" string="in" />
            <token id="10" string="Chicago" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="mammoth" />
            <token id="14" string="Marshall" />
            <token id="15" string="Field" />
            <token id="16" string="department" />
            <token id="17" string="store" />
            <token id="18" string="posted" />
            <token id="19" string="a" />
            <token id="20" string="sign" />
            <token id="21" string="that" />
            <token id="22" string="read" />
          </tokens>
        </chunking>
        <chunking id="3" string="open Thursday" type="ADJP">
          <tokens>
            <token id="38" string="open" />
            <token id="39" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="4" string="so scarce" type="ADJP">
          <tokens>
            <token id="7" string="so" />
            <token id="8" string="scarce" />
          </tokens>
        </chunking>
        <chunking id="5" string="fact" type="NP">
          <tokens>
            <token id="2" string="fact" />
          </tokens>
        </chunking>
        <chunking id="6" string="be open Thursday night instead of Monday" type="VP">
          <tokens>
            <token id="37" string="be" />
            <token id="38" string="open" />
            <token id="39" string="Thursday" />
            <token id="40" string="night" />
            <token id="41" string="instead" />
            <token id="42" string="of" />
            <token id="43" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="7" string="a sign" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="sign" />
          </tokens>
        </chunking>
        <chunking id="8" string="Love Lucy , too ," type="NP">
          <tokens>
            <token id="26" string="Love" />
            <token id="27" string="Lucy" />
            <token id="28" string="," />
            <token id="29" string="too" />
            <token id="30" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="Chicago" type="NP">
          <tokens>
            <token id="10" string="Chicago" />
          </tokens>
        </chunking>
        <chunking id="10" string="posted a sign that read" type="VP">
          <tokens>
            <token id="18" string="posted" />
            <token id="19" string="a" />
            <token id="20" string="sign" />
            <token id="21" string="that" />
            <token id="22" string="read" />
          </tokens>
        </chunking>
        <chunking id="11" string="that the mammoth Marshall Field department store posted a sign that read" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="mammoth" />
            <token id="14" string="Marshall" />
            <token id="15" string="Field" />
            <token id="16" string="department" />
            <token id="17" string="store" />
            <token id="18" string="posted" />
            <token id="19" string="a" />
            <token id="20" string="sign" />
            <token id="21" string="that" />
            <token id="22" string="read" />
          </tokens>
        </chunking>
        <chunking id="12" string="that read" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="read" />
          </tokens>
        </chunking>
        <chunking id="13" string="We" type="NP">
          <tokens>
            <token id="25" string="We" />
          </tokens>
        </chunking>
        <chunking id="14" string="we" type="NP">
          <tokens>
            <token id="35" string="we" />
          </tokens>
        </chunking>
        <chunking id="15" string="nighttime shoppers" type="NP">
          <tokens>
            <token id="4" string="nighttime" />
            <token id="5" string="shoppers" />
          </tokens>
        </chunking>
        <chunking id="16" string="the mammoth Marshall Field department store" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="mammoth" />
            <token id="14" string="Marshall" />
            <token id="15" string="Field" />
            <token id="16" string="department" />
            <token id="17" string="store" />
          </tokens>
        </chunking>
        <chunking id="17" string="open Thursday night" type="NP">
          <tokens>
            <token id="38" string="open" />
            <token id="39" string="Thursday" />
            <token id="40" string="night" />
          </tokens>
        </chunking>
        <chunking id="18" string="will be open Thursday night instead of Monday" type="VP">
          <tokens>
            <token id="36" string="will" />
            <token id="37" string="be" />
            <token id="38" string="open" />
            <token id="39" string="Thursday" />
            <token id="40" string="night" />
            <token id="41" string="instead" />
            <token id="42" string="of" />
            <token id="43" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="19" string="open Thursday night instead of Monday" type="NP">
          <tokens>
            <token id="38" string="open" />
            <token id="39" string="Thursday" />
            <token id="40" string="night" />
            <token id="41" string="instead" />
            <token id="42" string="of" />
            <token id="43" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="20" string="Monday" type="NP">
          <tokens>
            <token id="43" string="Monday" />
          </tokens>
        </chunking>
        <chunking id="21" string="Love Lucy" type="NP">
          <tokens>
            <token id="26" string="Love" />
            <token id="27" string="Lucy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">fact</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">became</governor>
          <dependent id="2">fact</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">shoppers</governor>
          <dependent id="4">nighttime</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">became</governor>
          <dependent id="5">shoppers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">became</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">scarce</governor>
          <dependent id="7">so</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">became</governor>
          <dependent id="8">scarce</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Chicago</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">became</governor>
          <dependent id="10">Chicago</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">posted</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">store</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">store</governor>
          <dependent id="13">mammoth</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">store</governor>
          <dependent id="14">Marshall</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">store</governor>
          <dependent id="15">Field</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">store</governor>
          <dependent id="16">department</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">posted</governor>
          <dependent id="17">store</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">became</governor>
          <dependent id="18">posted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">sign</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">posted</governor>
          <dependent id="20">sign</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">read</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">posted</governor>
          <dependent id="22">read</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">night</governor>
          <dependent id="25">We</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Lucy</governor>
          <dependent id="26">Love</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="31">so</governor>
          <dependent id="27">Lucy</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">Lucy</governor>
          <dependent id="29">too</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">night</governor>
          <dependent id="31">so</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">now</governor>
          <dependent id="32">from</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">so</governor>
          <dependent id="33">now</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">we</governor>
          <dependent id="34">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">so</governor>
          <dependent id="35">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">night</governor>
          <dependent id="36">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="40">night</governor>
          <dependent id="37">be</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">night</governor>
          <dependent id="38">open</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="38">open</governor>
          <dependent id="39">Thursday</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">became</governor>
          <dependent id="40">night</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">Monday</governor>
          <dependent id="41">instead</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="41">instead</governor>
          <dependent id="42">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">night</governor>
          <dependent id="43">Monday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="nighttime" type="TIME" score="0.0">
          <tokens>
            <token id="4" string="nighttime" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="33" string="now" />
          </tokens>
        </entity>
        <entity id="3" string="Chicago" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Chicago" />
          </tokens>
        </entity>
        <entity id="4" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="39" string="Thursday" />
          </tokens>
        </entity>
        <entity id="5" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="40" string="night" />
          </tokens>
        </entity>
        <entity id="6" string="Marshall Field" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Marshall" />
            <token id="15" string="Field" />
          </tokens>
        </entity>
        <entity id="7" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Lucy" />
          </tokens>
        </entity>
        <entity id="8" string="Monday" type="DATE" score="0.0">
          <tokens>
            <token id="43" string="Monday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>When presidential candidate Adlai E. Stevenson interrupted the show once for a political message, he was flooded with angry mail.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="presidential" lemma="presidential" stem="presidenti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="candidate" lemma="candidate" stem="candid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Adlai" lemma="Adlai" stem="adlai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="E." lemma="E." stem="e." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Stevenson" lemma="Stevenson" stem="stevenson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="interrupted" lemma="interrupt" stem="interrupt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="message" lemma="message" stem="messag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="flooded" lemma="flood" stem="flood" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="angry" lemma="angry" stem="angri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="mail" lemma="mail" stem="mail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (JJ presidential) (NN candidate) (NNP Adlai) (NNP E.) (NNP Stevenson)) (VP (VBD interrupted) (NP (DT the) (NN show)) (ADVP (RB once)) (PP (IN for) (NP (DT a) (JJ political) (NN message)))))) (, ,) (NP (PRP he)) (VP (VBD was) (VP (VBN flooded) (PP (IN with) (NP (JJ angry) (NN mail))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="2" string="a political message" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="political" />
            <token id="14" string="message" />
          </tokens>
        </chunking>
        <chunking id="3" string="When presidential candidate Adlai E. Stevenson interrupted the show once for a political message" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="presidential" />
            <token id="3" string="candidate" />
            <token id="4" string="Adlai" />
            <token id="5" string="E." />
            <token id="6" string="Stevenson" />
            <token id="7" string="interrupted" />
            <token id="8" string="the" />
            <token id="9" string="show" />
            <token id="10" string="once" />
            <token id="11" string="for" />
            <token id="12" string="a" />
            <token id="13" string="political" />
            <token id="14" string="message" />
          </tokens>
        </chunking>
        <chunking id="4" string="interrupted the show once for a political message" type="VP">
          <tokens>
            <token id="7" string="interrupted" />
            <token id="8" string="the" />
            <token id="9" string="show" />
            <token id="10" string="once" />
            <token id="11" string="for" />
            <token id="12" string="a" />
            <token id="13" string="political" />
            <token id="14" string="message" />
          </tokens>
        </chunking>
        <chunking id="5" string="the show" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="show" />
          </tokens>
        </chunking>
        <chunking id="6" string="was flooded with angry mail" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="flooded" />
            <token id="19" string="with" />
            <token id="20" string="angry" />
            <token id="21" string="mail" />
          </tokens>
        </chunking>
        <chunking id="7" string="presidential candidate Adlai E. Stevenson" type="NP">
          <tokens>
            <token id="2" string="presidential" />
            <token id="3" string="candidate" />
            <token id="4" string="Adlai" />
            <token id="5" string="E." />
            <token id="6" string="Stevenson" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="flooded with angry mail" type="VP">
          <tokens>
            <token id="18" string="flooded" />
            <token id="19" string="with" />
            <token id="20" string="angry" />
            <token id="21" string="mail" />
          </tokens>
        </chunking>
        <chunking id="10" string="angry mail" type="NP">
          <tokens>
            <token id="20" string="angry" />
            <token id="21" string="mail" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">interrupted</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">Stevenson</governor>
          <dependent id="2">presidential</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Stevenson</governor>
          <dependent id="3">candidate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Stevenson</governor>
          <dependent id="4">Adlai</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Stevenson</governor>
          <dependent id="5">E.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">interrupted</governor>
          <dependent id="6">Stevenson</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">flooded</governor>
          <dependent id="7">interrupted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">show</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">interrupted</governor>
          <dependent id="9">show</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">interrupted</governor>
          <dependent id="10">once</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">message</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">message</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">message</governor>
          <dependent id="13">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">interrupted</governor>
          <dependent id="14">message</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">flooded</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">flooded</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">flooded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">mail</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">mail</governor>
          <dependent id="20">angry</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">flooded</governor>
          <dependent id="21">mail</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Adlai E. Stevenson" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Adlai" />
            <token id="5" string="E." />
            <token id="6" string="Stevenson" />
          </tokens>
        </entity>
        <entity id="2" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="once" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Even a charge that Miss Ball was a Communist, made by the House Un-American Activities Committee in 1952, failed to dent her popularity.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="charge" lemma="charge" stem="charg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Communist" lemma="communist" stem="communist" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Un-American" lemma="Un-American" stem="un-american" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="Activities" lemma="Activities" stem="activiti" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="Committee" lemma="Committee" stem="committe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="1952" lemma="1952" stem="1952" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="failed" lemma="fail" stem="fail" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="dent" lemma="dent" stem="dent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="popularity" lemma="popularity" stem="popular" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (RB Even) (DT a) (NN charge)) (SBAR (WHNP (WDT that)) (S (NP (NNP Miss) (NNP Ball)) (VP (VBD was) (NP (DT a) (JJ Communist)))))) (, ,) (VP (VBN made) (PP (IN by) (NP (DT the) (NNP House) (NNP Un-American) (NNPS Activities) (NNP Committee))) (PP (IN in) (NP (CD 1952)))) (, ,)) (VP (VBD failed) (PP (TO to) (NP (NN dent) (PRP$ her) (NN popularity)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Even a charge" type="NP">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="a" />
            <token id="3" string="charge" />
          </tokens>
        </chunking>
        <chunking id="2" string="the House Un-American Activities Committee" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="House" />
            <token id="15" string="Un-American" />
            <token id="16" string="Activities" />
            <token id="17" string="Committee" />
          </tokens>
        </chunking>
        <chunking id="3" string="1952" type="NP">
          <tokens>
            <token id="19" string="1952" />
          </tokens>
        </chunking>
        <chunking id="4" string="Even a charge that Miss Ball was a Communist , made by the House Un-American Activities Committee in 1952 ," type="NP">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="a" />
            <token id="3" string="charge" />
            <token id="4" string="that" />
            <token id="5" string="Miss" />
            <token id="6" string="Ball" />
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="Communist" />
            <token id="10" string="," />
            <token id="11" string="made" />
            <token id="12" string="by" />
            <token id="13" string="the" />
            <token id="14" string="House" />
            <token id="15" string="Un-American" />
            <token id="16" string="Activities" />
            <token id="17" string="Committee" />
            <token id="18" string="in" />
            <token id="19" string="1952" />
            <token id="20" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="Even a charge that Miss Ball was a Communist" type="NP">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="a" />
            <token id="3" string="charge" />
            <token id="4" string="that" />
            <token id="5" string="Miss" />
            <token id="6" string="Ball" />
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="Communist" />
          </tokens>
        </chunking>
        <chunking id="6" string="that Miss Ball was a Communist" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="Miss" />
            <token id="6" string="Ball" />
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="Communist" />
          </tokens>
        </chunking>
        <chunking id="7" string="made by the House Un-American Activities Committee in 1952" type="VP">
          <tokens>
            <token id="11" string="made" />
            <token id="12" string="by" />
            <token id="13" string="the" />
            <token id="14" string="House" />
            <token id="15" string="Un-American" />
            <token id="16" string="Activities" />
            <token id="17" string="Committee" />
            <token id="18" string="in" />
            <token id="19" string="1952" />
          </tokens>
        </chunking>
        <chunking id="8" string="dent her popularity" type="NP">
          <tokens>
            <token id="23" string="dent" />
            <token id="24" string="her" />
            <token id="25" string="popularity" />
          </tokens>
        </chunking>
        <chunking id="9" string="a Communist" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="Communist" />
          </tokens>
        </chunking>
        <chunking id="10" string="was a Communist" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="Communist" />
          </tokens>
        </chunking>
        <chunking id="11" string="failed to dent her popularity" type="VP">
          <tokens>
            <token id="21" string="failed" />
            <token id="22" string="to" />
            <token id="23" string="dent" />
            <token id="24" string="her" />
            <token id="25" string="popularity" />
          </tokens>
        </chunking>
        <chunking id="12" string="Miss Ball" type="NP">
          <tokens>
            <token id="5" string="Miss" />
            <token id="6" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">charge</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">charge</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">failed</governor>
          <dependent id="3">charge</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">Communist</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Ball</governor>
          <dependent id="5">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">Communist</governor>
          <dependent id="6">Ball</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">Communist</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Communist</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">charge</governor>
          <dependent id="9">Communist</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">charge</governor>
          <dependent id="11">made</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Committee</governor>
          <dependent id="12">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">Committee</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Committee</governor>
          <dependent id="14">House</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Committee</governor>
          <dependent id="15">Un-American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Committee</governor>
          <dependent id="16">Activities</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">made</governor>
          <dependent id="17">Committee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">1952</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">made</governor>
          <dependent id="19">1952</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">failed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">popularity</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">popularity</governor>
          <dependent id="23">dent</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">popularity</governor>
          <dependent id="24">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">failed</governor>
          <dependent id="25">popularity</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Communist" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="9" string="Communist" />
          </tokens>
        </entity>
        <entity id="3" string="1952" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="1952" />
          </tokens>
        </entity>
        <entity id="4" string="House Un-American Activities Committee" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="House" />
            <token id="15" string="Un-American" />
            <token id="16" string="Activities" />
            <token id="17" string="Committee" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>The charges, based on her registering to vote as a Communist in 1936, were dropped when Miss Ball explained she had done so only to please her ailing grandfather.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="registering" lemma="register" stem="regist" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="vote" lemma="vote" stem="vote" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Communist" lemma="communist" stem="communist" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="1936" lemma="1936" stem="1936" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="dropped" lemma="drop" stem="drop" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="explained" lemma="explain" stem="explain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="please" lemma="please" stem="pleas" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="ailing" lemma="ailing" stem="ail" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="grandfather" lemma="grandfather" stem="grandfath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNS charges)) (, ,) (VP (VBN based) (PP (IN on) (S (NP (PRP$ her)) (VP (VBG registering) (S (VP (TO to) (VP (VB vote) (PP (IN as) (NP (NP (DT a) (JJ Communist)) (PP (IN in) (NP (CD 1936)))))))))))) (, ,)) (VP (VBD were) (VP (VBN dropped) (SBAR (WHADVP (WRB when)) (S (NP (NNP Miss) (NNP Ball)) (VP (VBD explained) (SBAR (S (NP (PRP she)) (VP (VBD had) (VP (VBN done) (ADVP (RB so) (RB only)) (S (VP (TO to) (VP (VB please) (NP (PRP$ her) (JJ ailing) (NN grandfather)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her ailing grandfather" type="NP">
          <tokens>
            <token id="29" string="her" />
            <token id="30" string="ailing" />
            <token id="31" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="2" string="explained she had done so only to please her ailing grandfather" type="VP">
          <tokens>
            <token id="21" string="explained" />
            <token id="22" string="she" />
            <token id="23" string="had" />
            <token id="24" string="done" />
            <token id="25" string="so" />
            <token id="26" string="only" />
            <token id="27" string="to" />
            <token id="28" string="please" />
            <token id="29" string="her" />
            <token id="30" string="ailing" />
            <token id="31" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="3" string="to vote as a Communist in 1936" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="vote" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="Communist" />
            <token id="13" string="in" />
            <token id="14" string="1936" />
          </tokens>
        </chunking>
        <chunking id="4" string="The charges , based on her registering to vote as a Communist in 1936 ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="charges" />
            <token id="3" string="," />
            <token id="4" string="based" />
            <token id="5" string="on" />
            <token id="6" string="her" />
            <token id="7" string="registering" />
            <token id="8" string="to" />
            <token id="9" string="vote" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="Communist" />
            <token id="13" string="in" />
            <token id="14" string="1936" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="a Communist" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="Communist" />
          </tokens>
        </chunking>
        <chunking id="6" string="she had done so only to please her ailing grandfather" type="SBAR">
          <tokens>
            <token id="22" string="she" />
            <token id="23" string="had" />
            <token id="24" string="done" />
            <token id="25" string="so" />
            <token id="26" string="only" />
            <token id="27" string="to" />
            <token id="28" string="please" />
            <token id="29" string="her" />
            <token id="30" string="ailing" />
            <token id="31" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="7" string="a Communist in 1936" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="Communist" />
            <token id="13" string="in" />
            <token id="14" string="1936" />
          </tokens>
        </chunking>
        <chunking id="8" string="when Miss Ball explained she had done so only to please her ailing grandfather" type="SBAR">
          <tokens>
            <token id="18" string="when" />
            <token id="19" string="Miss" />
            <token id="20" string="Ball" />
            <token id="21" string="explained" />
            <token id="22" string="she" />
            <token id="23" string="had" />
            <token id="24" string="done" />
            <token id="25" string="so" />
            <token id="26" string="only" />
            <token id="27" string="to" />
            <token id="28" string="please" />
            <token id="29" string="her" />
            <token id="30" string="ailing" />
            <token id="31" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="9" string="dropped when Miss Ball explained she had done so only to please her ailing grandfather" type="VP">
          <tokens>
            <token id="17" string="dropped" />
            <token id="18" string="when" />
            <token id="19" string="Miss" />
            <token id="20" string="Ball" />
            <token id="21" string="explained" />
            <token id="22" string="she" />
            <token id="23" string="had" />
            <token id="24" string="done" />
            <token id="25" string="so" />
            <token id="26" string="only" />
            <token id="27" string="to" />
            <token id="28" string="please" />
            <token id="29" string="her" />
            <token id="30" string="ailing" />
            <token id="31" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="10" string="please her ailing grandfather" type="VP">
          <tokens>
            <token id="28" string="please" />
            <token id="29" string="her" />
            <token id="30" string="ailing" />
            <token id="31" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="11" string="based on her registering to vote as a Communist in 1936" type="VP">
          <tokens>
            <token id="4" string="based" />
            <token id="5" string="on" />
            <token id="6" string="her" />
            <token id="7" string="registering" />
            <token id="8" string="to" />
            <token id="9" string="vote" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="Communist" />
            <token id="13" string="in" />
            <token id="14" string="1936" />
          </tokens>
        </chunking>
        <chunking id="12" string="to please her ailing grandfather" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="please" />
            <token id="29" string="her" />
            <token id="30" string="ailing" />
            <token id="31" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="13" string="when" type="WHADVP">
          <tokens>
            <token id="18" string="when" />
          </tokens>
        </chunking>
        <chunking id="14" string="she" type="NP">
          <tokens>
            <token id="22" string="she" />
          </tokens>
        </chunking>
        <chunking id="15" string="registering to vote as a Communist in 1936" type="VP">
          <tokens>
            <token id="7" string="registering" />
            <token id="8" string="to" />
            <token id="9" string="vote" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="Communist" />
            <token id="13" string="in" />
            <token id="14" string="1936" />
          </tokens>
        </chunking>
        <chunking id="16" string="had done so only to please her ailing grandfather" type="VP">
          <tokens>
            <token id="23" string="had" />
            <token id="24" string="done" />
            <token id="25" string="so" />
            <token id="26" string="only" />
            <token id="27" string="to" />
            <token id="28" string="please" />
            <token id="29" string="her" />
            <token id="30" string="ailing" />
            <token id="31" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="17" string="her" type="NP">
          <tokens>
            <token id="6" string="her" />
          </tokens>
        </chunking>
        <chunking id="18" string="vote as a Communist in 1936" type="VP">
          <tokens>
            <token id="9" string="vote" />
            <token id="10" string="as" />
            <token id="11" string="a" />
            <token id="12" string="Communist" />
            <token id="13" string="in" />
            <token id="14" string="1936" />
          </tokens>
        </chunking>
        <chunking id="19" string="done so only to please her ailing grandfather" type="VP">
          <tokens>
            <token id="24" string="done" />
            <token id="25" string="so" />
            <token id="26" string="only" />
            <token id="27" string="to" />
            <token id="28" string="please" />
            <token id="29" string="her" />
            <token id="30" string="ailing" />
            <token id="31" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="20" string="were dropped when Miss Ball explained she had done so only to please her ailing grandfather" type="VP">
          <tokens>
            <token id="16" string="were" />
            <token id="17" string="dropped" />
            <token id="18" string="when" />
            <token id="19" string="Miss" />
            <token id="20" string="Ball" />
            <token id="21" string="explained" />
            <token id="22" string="she" />
            <token id="23" string="had" />
            <token id="24" string="done" />
            <token id="25" string="so" />
            <token id="26" string="only" />
            <token id="27" string="to" />
            <token id="28" string="please" />
            <token id="29" string="her" />
            <token id="30" string="ailing" />
            <token id="31" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="21" string="The charges" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="charges" />
          </tokens>
        </chunking>
        <chunking id="22" string="1936" type="NP">
          <tokens>
            <token id="14" string="1936" />
          </tokens>
        </chunking>
        <chunking id="23" string="Miss Ball" type="NP">
          <tokens>
            <token id="19" string="Miss" />
            <token id="20" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">charges</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">dropped</governor>
          <dependent id="2">charges</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">charges</governor>
          <dependent id="4">based</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">registering</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">registering</governor>
          <dependent id="6">her</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">based</governor>
          <dependent id="7">registering</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">vote</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">registering</governor>
          <dependent id="9">vote</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Communist</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Communist</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">vote</governor>
          <dependent id="12">Communist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">1936</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">Communist</governor>
          <dependent id="14">1936</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">dropped</governor>
          <dependent id="16">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">dropped</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">explained</governor>
          <dependent id="18">when</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Ball</governor>
          <dependent id="19">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">explained</governor>
          <dependent id="20">Ball</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">dropped</governor>
          <dependent id="21">explained</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">done</governor>
          <dependent id="22">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">done</governor>
          <dependent id="23">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">explained</governor>
          <dependent id="24">done</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">only</governor>
          <dependent id="25">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">done</governor>
          <dependent id="26">only</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">please</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">done</governor>
          <dependent id="28">please</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">grandfather</governor>
          <dependent id="29">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">grandfather</governor>
          <dependent id="30">ailing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">please</governor>
          <dependent id="31">grandfather</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Communist" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="12" string="Communist" />
          </tokens>
        </entity>
        <entity id="2" string="1936" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="1936" />
          </tokens>
        </entity>
        <entity id="3" string="Miss Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Miss" />
            <token id="20" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="false">
      <content>Millions of sympathetic fans and a pragmatic CBS understood.</content>
      <tokens>
        <token id="1" string="Millions" lemma="million" stem="million" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="sympathetic" lemma="sympathetic" stem="sympathet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="pragmatic" lemma="pragmatic" stem="pragmat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="CBS" lemma="CBS" stem="cbs" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="understood" lemma="understand" stem="understood" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Millions)) (PP (IN of) (NP (NP (JJ sympathetic) (NNS fans)) (CC and) (NP (DT a) (JJ pragmatic) (NNP CBS))))) (VP (VBN understood)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sympathetic fans and a pragmatic CBS" type="NP">
          <tokens>
            <token id="3" string="sympathetic" />
            <token id="4" string="fans" />
            <token id="5" string="and" />
            <token id="6" string="a" />
            <token id="7" string="pragmatic" />
            <token id="8" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="2" string="a pragmatic CBS" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="pragmatic" />
            <token id="8" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="3" string="Millions" type="NP">
          <tokens>
            <token id="1" string="Millions" />
          </tokens>
        </chunking>
        <chunking id="4" string="Millions of sympathetic fans and a pragmatic CBS" type="NP">
          <tokens>
            <token id="1" string="Millions" />
            <token id="2" string="of" />
            <token id="3" string="sympathetic" />
            <token id="4" string="fans" />
            <token id="5" string="and" />
            <token id="6" string="a" />
            <token id="7" string="pragmatic" />
            <token id="8" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="5" string="sympathetic fans" type="NP">
          <tokens>
            <token id="3" string="sympathetic" />
            <token id="4" string="fans" />
          </tokens>
        </chunking>
        <chunking id="6" string="understood" type="VP">
          <tokens>
            <token id="9" string="understood" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="9">understood</governor>
          <dependent id="1">Millions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">fans</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">fans</governor>
          <dependent id="3">sympathetic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Millions</governor>
          <dependent id="4">fans</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">fans</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">CBS</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">CBS</governor>
          <dependent id="7">pragmatic</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">fans</governor>
          <dependent id="8">CBS</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">understood</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CBS" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="CBS" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>A phenomenal 40 million viewers watched the antics each week as Lucy would always try to outwit Ricky.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="phenomenal" lemma="phenomenal" stem="phenomen" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="viewers" lemma="viewer" stem="viewer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="watched" lemma="watch" stem="watch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="antics" lemma="antic" stem="antic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" ner="SET" is_referenced="true" is_refers="false" />
        <token id="10" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="true" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="try" lemma="try" stem="try" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="outwit" lemma="outwit" stem="outwit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Ricky" lemma="Ricky" stem="ricki" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (JJ phenomenal) (QP (CD 40) (CD million))) (NNS viewers)) (VP (VBD watched) (NP (DT the) (NNS antics)) (NP-TMP (DT each) (NN week)) (SBAR (IN as) (S (NP (NNP Lucy)) (VP (MD would) (ADVP (RB always)) (VP (VB try) (S (VP (TO to) (VP (VB outwit) (NP (NNP Ricky)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="try to outwit Ricky" type="VP">
          <tokens>
            <token id="15" string="try" />
            <token id="16" string="to" />
            <token id="17" string="outwit" />
            <token id="18" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="2" string="A phenomenal 40 million viewers" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="phenomenal" />
            <token id="3" string="40" />
            <token id="4" string="million" />
            <token id="5" string="viewers" />
          </tokens>
        </chunking>
        <chunking id="3" string="would always try to outwit Ricky" type="VP">
          <tokens>
            <token id="13" string="would" />
            <token id="14" string="always" />
            <token id="15" string="try" />
            <token id="16" string="to" />
            <token id="17" string="outwit" />
            <token id="18" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="4" string="A phenomenal 40 million" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="phenomenal" />
            <token id="3" string="40" />
            <token id="4" string="million" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lucy" type="NP">
          <tokens>
            <token id="12" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="6" string="to outwit Ricky" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="outwit" />
            <token id="18" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="7" string="as Lucy would always try to outwit Ricky" type="SBAR">
          <tokens>
            <token id="11" string="as" />
            <token id="12" string="Lucy" />
            <token id="13" string="would" />
            <token id="14" string="always" />
            <token id="15" string="try" />
            <token id="16" string="to" />
            <token id="17" string="outwit" />
            <token id="18" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="8" string="the antics" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="antics" />
          </tokens>
        </chunking>
        <chunking id="9" string="outwit Ricky" type="VP">
          <tokens>
            <token id="17" string="outwit" />
            <token id="18" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="10" string="watched the antics each week as Lucy would always try to outwit Ricky" type="VP">
          <tokens>
            <token id="6" string="watched" />
            <token id="7" string="the" />
            <token id="8" string="antics" />
            <token id="9" string="each" />
            <token id="10" string="week" />
            <token id="11" string="as" />
            <token id="12" string="Lucy" />
            <token id="13" string="would" />
            <token id="14" string="always" />
            <token id="15" string="try" />
            <token id="16" string="to" />
            <token id="17" string="outwit" />
            <token id="18" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ricky" type="NP">
          <tokens>
            <token id="18" string="Ricky" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">million</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">million</governor>
          <dependent id="2">phenomenal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">million</governor>
          <dependent id="3">40</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">viewers</governor>
          <dependent id="4">million</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">watched</governor>
          <dependent id="5">viewers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">watched</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">antics</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">watched</governor>
          <dependent id="8">antics</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">week</governor>
          <dependent id="9">each</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">watched</governor>
          <dependent id="10">week</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">try</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">try</governor>
          <dependent id="12">Lucy</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">try</governor>
          <dependent id="13">would</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">try</governor>
          <dependent id="14">always</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">watched</governor>
          <dependent id="15">try</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">outwit</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">try</governor>
          <dependent id="17">outwit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">outwit</governor>
          <dependent id="18">Ricky</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="40 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="40" />
            <token id="4" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Lucy" />
          </tokens>
        </entity>
        <entity id="3" string="Ricky" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Ricky" />
          </tokens>
        </entity>
        <entity id="4" string="each week" type="SET" score="0.0">
          <tokens>
            <token id="9" string="each" />
            <token id="10" string="week" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>With their best friends and landlords, Fred and Ethel Mertz, played by veterans William Frawley and Vivian Vance as the perfect foils, the Ricardos found themselves mired in situations that frequently were rowdy and always ridiculous.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="landlords" lemma="landlord" stem="landlord" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Fred" lemma="Fred" stem="fred" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Ethel" lemma="Ethel" stem="ethel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Mertz" lemma="Mertz" stem="mertz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="played" lemma="play" stem="plai" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="veterans" lemma="veteran" stem="veteran" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Frawley" lemma="Frawley" stem="frawlei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Vivian" lemma="Vivian" stem="vivian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="Vance" lemma="Vance" stem="vanc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="perfect" lemma="perfect" stem="perfect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="foils" lemma="foil" stem="foil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Ricardos" lemma="Ricardos" stem="ricardo" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="28" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="mired" lemma="mire" stem="mire" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="situations" lemma="situation" stem="situat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="frequently" lemma="frequently" stem="frequent" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="rowdy" lemma="rowdy" stem="rowdi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="ridiculous" lemma="ridiculous" stem="ridicul" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN With) (NP (PRP$ their) (JJS best) (NNS friends) (CC and) (NNS landlords))) (, ,) (NP (NP (NNP Fred)) (CC and) (NP (NNP Ethel) (NNP Mertz))) (, ,) (S (VP (VBN played) (PP (IN by) (NP (NP (NNS veterans) (NNP William) (NNP Frawley) (CC and) (NNP Vivian) (NNP Vance)) (PP (IN as) (NP (DT the) (JJ perfect) (NNS foils))))))) (, ,) (NP (DT the) (NNP Ricardos)) (VP (VBD found) (SBAR (S (NP (PRP themselves)) (VP (VBN mired) (PP (IN in) (NP (NP (NNS situations)) (SBAR (WHNP (WDT that)) (S (ADVP (RB frequently)) (VP (VBD were) (ADJP (ADJP (JJ rowdy)) (CC and) (ADJP (RB always) (JJ ridiculous)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="veterans William Frawley and Vivian Vance as the perfect foils" type="NP">
          <tokens>
            <token id="15" string="veterans" />
            <token id="16" string="William" />
            <token id="17" string="Frawley" />
            <token id="18" string="and" />
            <token id="19" string="Vivian" />
            <token id="20" string="Vance" />
            <token id="21" string="as" />
            <token id="22" string="the" />
            <token id="23" string="perfect" />
            <token id="24" string="foils" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Ricardos" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="Ricardos" />
          </tokens>
        </chunking>
        <chunking id="3" string="mired in situations that frequently were rowdy and always ridiculous" type="VP">
          <tokens>
            <token id="30" string="mired" />
            <token id="31" string="in" />
            <token id="32" string="situations" />
            <token id="33" string="that" />
            <token id="34" string="frequently" />
            <token id="35" string="were" />
            <token id="36" string="rowdy" />
            <token id="37" string="and" />
            <token id="38" string="always" />
            <token id="39" string="ridiculous" />
          </tokens>
        </chunking>
        <chunking id="4" string="found themselves mired in situations that frequently were rowdy and always ridiculous" type="VP">
          <tokens>
            <token id="28" string="found" />
            <token id="29" string="themselves" />
            <token id="30" string="mired" />
            <token id="31" string="in" />
            <token id="32" string="situations" />
            <token id="33" string="that" />
            <token id="34" string="frequently" />
            <token id="35" string="were" />
            <token id="36" string="rowdy" />
            <token id="37" string="and" />
            <token id="38" string="always" />
            <token id="39" string="ridiculous" />
          </tokens>
        </chunking>
        <chunking id="5" string="always ridiculous" type="ADJP">
          <tokens>
            <token id="38" string="always" />
            <token id="39" string="ridiculous" />
          </tokens>
        </chunking>
        <chunking id="6" string="their best friends and landlords" type="NP">
          <tokens>
            <token id="2" string="their" />
            <token id="3" string="best" />
            <token id="4" string="friends" />
            <token id="5" string="and" />
            <token id="6" string="landlords" />
          </tokens>
        </chunking>
        <chunking id="7" string="were rowdy and always ridiculous" type="VP">
          <tokens>
            <token id="35" string="were" />
            <token id="36" string="rowdy" />
            <token id="37" string="and" />
            <token id="38" string="always" />
            <token id="39" string="ridiculous" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ethel Mertz" type="NP">
          <tokens>
            <token id="10" string="Ethel" />
            <token id="11" string="Mertz" />
          </tokens>
        </chunking>
        <chunking id="9" string="Fred" type="NP">
          <tokens>
            <token id="8" string="Fred" />
          </tokens>
        </chunking>
        <chunking id="10" string="veterans William Frawley and Vivian Vance" type="NP">
          <tokens>
            <token id="15" string="veterans" />
            <token id="16" string="William" />
            <token id="17" string="Frawley" />
            <token id="18" string="and" />
            <token id="19" string="Vivian" />
            <token id="20" string="Vance" />
          </tokens>
        </chunking>
        <chunking id="11" string="situations that frequently were rowdy and always ridiculous" type="NP">
          <tokens>
            <token id="32" string="situations" />
            <token id="33" string="that" />
            <token id="34" string="frequently" />
            <token id="35" string="were" />
            <token id="36" string="rowdy" />
            <token id="37" string="and" />
            <token id="38" string="always" />
            <token id="39" string="ridiculous" />
          </tokens>
        </chunking>
        <chunking id="12" string="Fred and Ethel Mertz" type="NP">
          <tokens>
            <token id="8" string="Fred" />
            <token id="9" string="and" />
            <token id="10" string="Ethel" />
            <token id="11" string="Mertz" />
          </tokens>
        </chunking>
        <chunking id="13" string="themselves" type="NP">
          <tokens>
            <token id="29" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="14" string="rowdy" type="ADJP">
          <tokens>
            <token id="36" string="rowdy" />
          </tokens>
        </chunking>
        <chunking id="15" string="themselves mired in situations that frequently were rowdy and always ridiculous" type="SBAR">
          <tokens>
            <token id="29" string="themselves" />
            <token id="30" string="mired" />
            <token id="31" string="in" />
            <token id="32" string="situations" />
            <token id="33" string="that" />
            <token id="34" string="frequently" />
            <token id="35" string="were" />
            <token id="36" string="rowdy" />
            <token id="37" string="and" />
            <token id="38" string="always" />
            <token id="39" string="ridiculous" />
          </tokens>
        </chunking>
        <chunking id="16" string="rowdy and always ridiculous" type="ADJP">
          <tokens>
            <token id="36" string="rowdy" />
            <token id="37" string="and" />
            <token id="38" string="always" />
            <token id="39" string="ridiculous" />
          </tokens>
        </chunking>
        <chunking id="17" string="the perfect foils" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="perfect" />
            <token id="24" string="foils" />
          </tokens>
        </chunking>
        <chunking id="18" string="that frequently were rowdy and always ridiculous" type="SBAR">
          <tokens>
            <token id="33" string="that" />
            <token id="34" string="frequently" />
            <token id="35" string="were" />
            <token id="36" string="rowdy" />
            <token id="37" string="and" />
            <token id="38" string="always" />
            <token id="39" string="ridiculous" />
          </tokens>
        </chunking>
        <chunking id="19" string="played by veterans William Frawley and Vivian Vance as the perfect foils" type="VP">
          <tokens>
            <token id="13" string="played" />
            <token id="14" string="by" />
            <token id="15" string="veterans" />
            <token id="16" string="William" />
            <token id="17" string="Frawley" />
            <token id="18" string="and" />
            <token id="19" string="Vivian" />
            <token id="20" string="Vance" />
            <token id="21" string="as" />
            <token id="22" string="the" />
            <token id="23" string="perfect" />
            <token id="24" string="foils" />
          </tokens>
        </chunking>
        <chunking id="20" string="situations" type="NP">
          <tokens>
            <token id="32" string="situations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">friends</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">friends</governor>
          <dependent id="2">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">friends</governor>
          <dependent id="3">best</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">found</governor>
          <dependent id="4">friends</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">friends</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">friends</governor>
          <dependent id="6">landlords</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">found</governor>
          <dependent id="8">Fred</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Fred</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Mertz</governor>
          <dependent id="10">Ethel</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Fred</governor>
          <dependent id="11">Mertz</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">found</governor>
          <dependent id="13">played</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Frawley</governor>
          <dependent id="14">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Frawley</governor>
          <dependent id="15">veterans</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Frawley</governor>
          <dependent id="16">William</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">played</governor>
          <dependent id="17">Frawley</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">Frawley</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Vance</governor>
          <dependent id="19">Vivian</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">Frawley</governor>
          <dependent id="20">Vance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">foils</governor>
          <dependent id="21">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">foils</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">foils</governor>
          <dependent id="23">perfect</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">Frawley</governor>
          <dependent id="24">foils</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Ricardos</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">found</governor>
          <dependent id="27">Ricardos</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">found</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">mired</governor>
          <dependent id="29">themselves</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">found</governor>
          <dependent id="30">mired</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">situations</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">mired</governor>
          <dependent id="32">situations</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">rowdy</governor>
          <dependent id="33">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">rowdy</governor>
          <dependent id="34">frequently</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="36">rowdy</governor>
          <dependent id="35">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="32">situations</governor>
          <dependent id="36">rowdy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="36">rowdy</governor>
          <dependent id="37">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="39">ridiculous</governor>
          <dependent id="38">always</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">rowdy</governor>
          <dependent id="39">ridiculous</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ricardos" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="27" string="Ricardos" />
          </tokens>
        </entity>
        <entity id="2" string="William Frawley" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="William" />
            <token id="17" string="Frawley" />
          </tokens>
        </entity>
        <entity id="3" string="Ethel Mertz" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Ethel" />
            <token id="11" string="Mertz" />
          </tokens>
        </entity>
        <entity id="4" string="Fred" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Fred" />
          </tokens>
        </entity>
        <entity id="5" string="Vivian Vance" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Vivian" />
            <token id="20" string="Vance" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>A generation of Americans grew to recap their favorite Lucy episodes, plot twist by crazy twist.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="generation" lemma="generation" stem="gener" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="5" string="grew" lemma="grow" stem="grew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="recap" lemma="recap" stem="recap" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="favorite" lemma="favorite" stem="favorit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="episodes" lemma="episode" stem="episod" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="plot" lemma="plot" stem="plot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="twist" lemma="twist" stem="twist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="crazy" lemma="crazy" stem="crazi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="twist" lemma="twist" stem="twist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (NN generation)) (PP (IN of) (NP (NNPS Americans)))) (VP (VBD grew) (S (VP (TO to) (VP (VB recap) (NP (PRP$ their) (JJ favorite) (NNP Lucy) (NNS episodes) (, ,) (NN plot) (NN twist)) (PP (IN by) (NP (JJ crazy) (NN twist))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Americans" type="NP">
          <tokens>
            <token id="4" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="2" string="grew to recap their favorite Lucy episodes , plot twist by crazy twist" type="VP">
          <tokens>
            <token id="5" string="grew" />
            <token id="6" string="to" />
            <token id="7" string="recap" />
            <token id="8" string="their" />
            <token id="9" string="favorite" />
            <token id="10" string="Lucy" />
            <token id="11" string="episodes" />
            <token id="12" string="," />
            <token id="13" string="plot" />
            <token id="14" string="twist" />
            <token id="15" string="by" />
            <token id="16" string="crazy" />
            <token id="17" string="twist" />
          </tokens>
        </chunking>
        <chunking id="3" string="A generation of Americans" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="generation" />
            <token id="3" string="of" />
            <token id="4" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="4" string="to recap their favorite Lucy episodes , plot twist by crazy twist" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="recap" />
            <token id="8" string="their" />
            <token id="9" string="favorite" />
            <token id="10" string="Lucy" />
            <token id="11" string="episodes" />
            <token id="12" string="," />
            <token id="13" string="plot" />
            <token id="14" string="twist" />
            <token id="15" string="by" />
            <token id="16" string="crazy" />
            <token id="17" string="twist" />
          </tokens>
        </chunking>
        <chunking id="5" string="their favorite Lucy episodes , plot twist" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="favorite" />
            <token id="10" string="Lucy" />
            <token id="11" string="episodes" />
            <token id="12" string="," />
            <token id="13" string="plot" />
            <token id="14" string="twist" />
          </tokens>
        </chunking>
        <chunking id="6" string="recap their favorite Lucy episodes , plot twist by crazy twist" type="VP">
          <tokens>
            <token id="7" string="recap" />
            <token id="8" string="their" />
            <token id="9" string="favorite" />
            <token id="10" string="Lucy" />
            <token id="11" string="episodes" />
            <token id="12" string="," />
            <token id="13" string="plot" />
            <token id="14" string="twist" />
            <token id="15" string="by" />
            <token id="16" string="crazy" />
            <token id="17" string="twist" />
          </tokens>
        </chunking>
        <chunking id="7" string="crazy twist" type="NP">
          <tokens>
            <token id="16" string="crazy" />
            <token id="17" string="twist" />
          </tokens>
        </chunking>
        <chunking id="8" string="A generation" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="generation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">generation</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">grew</governor>
          <dependent id="2">generation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Americans</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">generation</governor>
          <dependent id="4">Americans</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">grew</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">recap</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">grew</governor>
          <dependent id="7">recap</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">twist</governor>
          <dependent id="8">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">twist</governor>
          <dependent id="9">favorite</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">twist</governor>
          <dependent id="10">Lucy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">twist</governor>
          <dependent id="11">episodes</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">twist</governor>
          <dependent id="13">plot</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">recap</governor>
          <dependent id="14">twist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">twist</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">twist</governor>
          <dependent id="16">crazy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">recap</governor>
          <dependent id="17">twist</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Americans" />
          </tokens>
        </entity>
        <entity id="2" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>There was the time Lucy schemed her way onto Ricky&amp;apost;s television show to do a commercial for a vegetable drink with a high alcoholic content and got hilariously tipsy during the many retakes.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="schemed" lemma="scheme" stem="scheme" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="onto" lemma="onto" stem="onto" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Ricky" lemma="Ricky" stem="ricki" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="commercial" lemma="commercial" stem="commerci" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="vegetable" lemma="vegetable" stem="veget" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="drink" lemma="drink" stem="drink" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="alcoholic" lemma="alcoholic" stem="alcohol" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="content" lemma="content" stem="content" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="hilariously" lemma="hilariously" stem="hilari" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="tipsy" lemma="tipsy" stem="tipsi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="retakes" lemma="retake" stem="retak" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBD was) (NP (NP (DT the) (NN time)) (SBAR (S (NP (NNP Lucy)) (VP (VP (VBD schemed) (NP (PRP$ her) (NN way)) (PP (IN onto) (NP (NP (NNP Ricky) (POS 's)) (NN television) (NN show))) (S (VP (TO to) (VP (VB do) (NP (DT a) (JJ commercial)) (PP (IN for) (NP (NP (DT a) (NN vegetable) (NN drink)) (PP (IN with) (NP (DT a) (JJ high) (JJ alcoholic) (NN content))))))))) (CC and) (VP (VBD got) (ADJP (RB hilariously) (JJ tipsy)) (PP (IN during) (NP (DT the) (JJ many) (NNS retakes))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="schemed her way onto Ricky 's television show to do a commercial for a vegetable drink with a high alcoholic content" type="VP">
          <tokens>
            <token id="6" string="schemed" />
            <token id="7" string="her" />
            <token id="8" string="way" />
            <token id="9" string="onto" />
            <token id="10" string="Ricky" />
            <token id="11" string="'s" />
            <token id="12" string="television" />
            <token id="13" string="show" />
            <token id="14" string="to" />
            <token id="15" string="do" />
            <token id="16" string="a" />
            <token id="17" string="commercial" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="vegetable" />
            <token id="21" string="drink" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="high" />
            <token id="25" string="alcoholic" />
            <token id="26" string="content" />
          </tokens>
        </chunking>
        <chunking id="2" string="the time Lucy schemed her way onto Ricky 's television show to do a commercial for a vegetable drink with a high alcoholic content and got hilariously tipsy during the many retakes" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="time" />
            <token id="5" string="Lucy" />
            <token id="6" string="schemed" />
            <token id="7" string="her" />
            <token id="8" string="way" />
            <token id="9" string="onto" />
            <token id="10" string="Ricky" />
            <token id="11" string="'s" />
            <token id="12" string="television" />
            <token id="13" string="show" />
            <token id="14" string="to" />
            <token id="15" string="do" />
            <token id="16" string="a" />
            <token id="17" string="commercial" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="vegetable" />
            <token id="21" string="drink" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="high" />
            <token id="25" string="alcoholic" />
            <token id="26" string="content" />
            <token id="27" string="and" />
            <token id="28" string="got" />
            <token id="29" string="hilariously" />
            <token id="30" string="tipsy" />
            <token id="31" string="during" />
            <token id="32" string="the" />
            <token id="33" string="many" />
            <token id="34" string="retakes" />
          </tokens>
        </chunking>
        <chunking id="3" string="schemed her way onto Ricky 's television show to do a commercial for a vegetable drink with a high alcoholic content and got hilariously tipsy during the many retakes" type="VP">
          <tokens>
            <token id="6" string="schemed" />
            <token id="7" string="her" />
            <token id="8" string="way" />
            <token id="9" string="onto" />
            <token id="10" string="Ricky" />
            <token id="11" string="'s" />
            <token id="12" string="television" />
            <token id="13" string="show" />
            <token id="14" string="to" />
            <token id="15" string="do" />
            <token id="16" string="a" />
            <token id="17" string="commercial" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="vegetable" />
            <token id="21" string="drink" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="high" />
            <token id="25" string="alcoholic" />
            <token id="26" string="content" />
            <token id="27" string="and" />
            <token id="28" string="got" />
            <token id="29" string="hilariously" />
            <token id="30" string="tipsy" />
            <token id="31" string="during" />
            <token id="32" string="the" />
            <token id="33" string="many" />
            <token id="34" string="retakes" />
          </tokens>
        </chunking>
        <chunking id="4" string="the many retakes" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="many" />
            <token id="34" string="retakes" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ricky 's television show" type="NP">
          <tokens>
            <token id="10" string="Ricky" />
            <token id="11" string="'s" />
            <token id="12" string="television" />
            <token id="13" string="show" />
          </tokens>
        </chunking>
        <chunking id="6" string="a commercial" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="commercial" />
          </tokens>
        </chunking>
        <chunking id="7" string="a high alcoholic content" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="high" />
            <token id="25" string="alcoholic" />
            <token id="26" string="content" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ricky 's" type="NP">
          <tokens>
            <token id="10" string="Ricky" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="a vegetable drink with a high alcoholic content" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="vegetable" />
            <token id="21" string="drink" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="high" />
            <token id="25" string="alcoholic" />
            <token id="26" string="content" />
          </tokens>
        </chunking>
        <chunking id="10" string="a vegetable drink" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="vegetable" />
            <token id="21" string="drink" />
          </tokens>
        </chunking>
        <chunking id="11" string="Lucy schemed her way onto Ricky 's television show to do a commercial for a vegetable drink with a high alcoholic content and got hilariously tipsy during the many retakes" type="SBAR">
          <tokens>
            <token id="5" string="Lucy" />
            <token id="6" string="schemed" />
            <token id="7" string="her" />
            <token id="8" string="way" />
            <token id="9" string="onto" />
            <token id="10" string="Ricky" />
            <token id="11" string="'s" />
            <token id="12" string="television" />
            <token id="13" string="show" />
            <token id="14" string="to" />
            <token id="15" string="do" />
            <token id="16" string="a" />
            <token id="17" string="commercial" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="vegetable" />
            <token id="21" string="drink" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="high" />
            <token id="25" string="alcoholic" />
            <token id="26" string="content" />
            <token id="27" string="and" />
            <token id="28" string="got" />
            <token id="29" string="hilariously" />
            <token id="30" string="tipsy" />
            <token id="31" string="during" />
            <token id="32" string="the" />
            <token id="33" string="many" />
            <token id="34" string="retakes" />
          </tokens>
        </chunking>
        <chunking id="12" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="13" string="hilariously tipsy" type="ADJP">
          <tokens>
            <token id="29" string="hilariously" />
            <token id="30" string="tipsy" />
          </tokens>
        </chunking>
        <chunking id="14" string="got hilariously tipsy during the many retakes" type="VP">
          <tokens>
            <token id="28" string="got" />
            <token id="29" string="hilariously" />
            <token id="30" string="tipsy" />
            <token id="31" string="during" />
            <token id="32" string="the" />
            <token id="33" string="many" />
            <token id="34" string="retakes" />
          </tokens>
        </chunking>
        <chunking id="15" string="the time" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="time" />
          </tokens>
        </chunking>
        <chunking id="16" string="was the time Lucy schemed her way onto Ricky 's television show to do a commercial for a vegetable drink with a high alcoholic content and got hilariously tipsy during the many retakes" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="the" />
            <token id="4" string="time" />
            <token id="5" string="Lucy" />
            <token id="6" string="schemed" />
            <token id="7" string="her" />
            <token id="8" string="way" />
            <token id="9" string="onto" />
            <token id="10" string="Ricky" />
            <token id="11" string="'s" />
            <token id="12" string="television" />
            <token id="13" string="show" />
            <token id="14" string="to" />
            <token id="15" string="do" />
            <token id="16" string="a" />
            <token id="17" string="commercial" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="vegetable" />
            <token id="21" string="drink" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="high" />
            <token id="25" string="alcoholic" />
            <token id="26" string="content" />
            <token id="27" string="and" />
            <token id="28" string="got" />
            <token id="29" string="hilariously" />
            <token id="30" string="tipsy" />
            <token id="31" string="during" />
            <token id="32" string="the" />
            <token id="33" string="many" />
            <token id="34" string="retakes" />
          </tokens>
        </chunking>
        <chunking id="17" string="Lucy" type="NP">
          <tokens>
            <token id="5" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="18" string="her way" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="way" />
          </tokens>
        </chunking>
        <chunking id="19" string="do a commercial for a vegetable drink with a high alcoholic content" type="VP">
          <tokens>
            <token id="15" string="do" />
            <token id="16" string="a" />
            <token id="17" string="commercial" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="vegetable" />
            <token id="21" string="drink" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="high" />
            <token id="25" string="alcoholic" />
            <token id="26" string="content" />
          </tokens>
        </chunking>
        <chunking id="20" string="to do a commercial for a vegetable drink with a high alcoholic content" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="do" />
            <token id="16" string="a" />
            <token id="17" string="commercial" />
            <token id="18" string="for" />
            <token id="19" string="a" />
            <token id="20" string="vegetable" />
            <token id="21" string="drink" />
            <token id="22" string="with" />
            <token id="23" string="a" />
            <token id="24" string="high" />
            <token id="25" string="alcoholic" />
            <token id="26" string="content" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">was</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">time</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">was</governor>
          <dependent id="4">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">schemed</governor>
          <dependent id="5">Lucy</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">time</governor>
          <dependent id="6">schemed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">way</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">schemed</governor>
          <dependent id="8">way</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">show</governor>
          <dependent id="9">onto</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">show</governor>
          <dependent id="10">Ricky</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Ricky</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">show</governor>
          <dependent id="12">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">schemed</governor>
          <dependent id="13">show</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">do</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">schemed</governor>
          <dependent id="15">do</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">commercial</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">do</governor>
          <dependent id="17">commercial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">drink</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">drink</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">drink</governor>
          <dependent id="20">vegetable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">do</governor>
          <dependent id="21">drink</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">content</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">content</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">content</governor>
          <dependent id="24">high</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">content</governor>
          <dependent id="25">alcoholic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">drink</governor>
          <dependent id="26">content</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">schemed</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">schemed</governor>
          <dependent id="28">got</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">tipsy</governor>
          <dependent id="29">hilariously</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">got</governor>
          <dependent id="30">tipsy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">retakes</governor>
          <dependent id="31">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">retakes</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">retakes</governor>
          <dependent id="33">many</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">got</governor>
          <dependent id="34">retakes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Lucy" />
          </tokens>
        </entity>
        <entity id="2" string="Ricky" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Ricky" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Then there was the time she threw in two packages of yeast while baking homemade bread and ended up pinned against the wall of her Manhattan kitchen by a monster loaf.</content>
      <tokens>
        <token id="1" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="threw" lemma="throw" stem="threw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="10" string="packages" lemma="package" stem="packag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="yeast" lemma="yeast" stem="yeast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="baking" lemma="bake" stem="bake" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="homemade" lemma="homemade" stem="homemad" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="bread" lemma="bread" stem="bread" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="ended" lemma="end" stem="end" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="pinned" lemma="pin" stem="pin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="wall" lemma="wall" stem="wall" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="Manhattan" lemma="Manhattan" stem="manhattan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="kitchen" lemma="kitchen" stem="kitchen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="monster" lemma="monster" stem="monster" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="loaf" lemma="loaf" stem="loaf" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Then) (NP (EX there)) (VP (VBD was) (NP (NP (DT the) (NN time)) (SBAR (S (NP (PRP she)) (VP (VP (VBD threw) (PP (IN in) (NP (NP (CD two) (NNS packages)) (PP (IN of) (NP (NN yeast))))) (PP (IN while) (NP (VBG baking) (NN homemade) (NN bread)))) (CC and) (VP (VBD ended) (PRT (RP up)) (S (VP (VBN pinned) (PP (IN against) (NP (NP (DT the) (NN wall)) (PP (IN of) (NP (PRP$ her) (NNP Manhattan) (NN kitchen))))) (PP (IN by) (NP (DT a) (NN monster) (NN loaf))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="ended up pinned against the wall of her Manhattan kitchen by a monster loaf" type="VP">
          <tokens>
            <token id="18" string="ended" />
            <token id="19" string="up" />
            <token id="20" string="pinned" />
            <token id="21" string="against" />
            <token id="22" string="the" />
            <token id="23" string="wall" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="Manhattan" />
            <token id="27" string="kitchen" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="monster" />
            <token id="31" string="loaf" />
          </tokens>
        </chunking>
        <chunking id="2" string="the time she threw in two packages of yeast while baking homemade bread and ended up pinned against the wall of her Manhattan kitchen by a monster loaf" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="time" />
            <token id="6" string="she" />
            <token id="7" string="threw" />
            <token id="8" string="in" />
            <token id="9" string="two" />
            <token id="10" string="packages" />
            <token id="11" string="of" />
            <token id="12" string="yeast" />
            <token id="13" string="while" />
            <token id="14" string="baking" />
            <token id="15" string="homemade" />
            <token id="16" string="bread" />
            <token id="17" string="and" />
            <token id="18" string="ended" />
            <token id="19" string="up" />
            <token id="20" string="pinned" />
            <token id="21" string="against" />
            <token id="22" string="the" />
            <token id="23" string="wall" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="Manhattan" />
            <token id="27" string="kitchen" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="monster" />
            <token id="31" string="loaf" />
          </tokens>
        </chunking>
        <chunking id="3" string="she threw in two packages of yeast while baking homemade bread and ended up pinned against the wall of her Manhattan kitchen by a monster loaf" type="SBAR">
          <tokens>
            <token id="6" string="she" />
            <token id="7" string="threw" />
            <token id="8" string="in" />
            <token id="9" string="two" />
            <token id="10" string="packages" />
            <token id="11" string="of" />
            <token id="12" string="yeast" />
            <token id="13" string="while" />
            <token id="14" string="baking" />
            <token id="15" string="homemade" />
            <token id="16" string="bread" />
            <token id="17" string="and" />
            <token id="18" string="ended" />
            <token id="19" string="up" />
            <token id="20" string="pinned" />
            <token id="21" string="against" />
            <token id="22" string="the" />
            <token id="23" string="wall" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="Manhattan" />
            <token id="27" string="kitchen" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="monster" />
            <token id="31" string="loaf" />
          </tokens>
        </chunking>
        <chunking id="4" string="two packages of yeast" type="NP">
          <tokens>
            <token id="9" string="two" />
            <token id="10" string="packages" />
            <token id="11" string="of" />
            <token id="12" string="yeast" />
          </tokens>
        </chunking>
        <chunking id="5" string="yeast" type="NP">
          <tokens>
            <token id="12" string="yeast" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="6" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="her Manhattan kitchen" type="NP">
          <tokens>
            <token id="25" string="her" />
            <token id="26" string="Manhattan" />
            <token id="27" string="kitchen" />
          </tokens>
        </chunking>
        <chunking id="8" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="a monster loaf" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="monster" />
            <token id="31" string="loaf" />
          </tokens>
        </chunking>
        <chunking id="10" string="two packages" type="NP">
          <tokens>
            <token id="9" string="two" />
            <token id="10" string="packages" />
          </tokens>
        </chunking>
        <chunking id="11" string="pinned against the wall of her Manhattan kitchen by a monster loaf" type="VP">
          <tokens>
            <token id="20" string="pinned" />
            <token id="21" string="against" />
            <token id="22" string="the" />
            <token id="23" string="wall" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="Manhattan" />
            <token id="27" string="kitchen" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="monster" />
            <token id="31" string="loaf" />
          </tokens>
        </chunking>
        <chunking id="12" string="threw in two packages of yeast while baking homemade bread and ended up pinned against the wall of her Manhattan kitchen by a monster loaf" type="VP">
          <tokens>
            <token id="7" string="threw" />
            <token id="8" string="in" />
            <token id="9" string="two" />
            <token id="10" string="packages" />
            <token id="11" string="of" />
            <token id="12" string="yeast" />
            <token id="13" string="while" />
            <token id="14" string="baking" />
            <token id="15" string="homemade" />
            <token id="16" string="bread" />
            <token id="17" string="and" />
            <token id="18" string="ended" />
            <token id="19" string="up" />
            <token id="20" string="pinned" />
            <token id="21" string="against" />
            <token id="22" string="the" />
            <token id="23" string="wall" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="Manhattan" />
            <token id="27" string="kitchen" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="monster" />
            <token id="31" string="loaf" />
          </tokens>
        </chunking>
        <chunking id="13" string="baking homemade bread" type="NP">
          <tokens>
            <token id="14" string="baking" />
            <token id="15" string="homemade" />
            <token id="16" string="bread" />
          </tokens>
        </chunking>
        <chunking id="14" string="was the time she threw in two packages of yeast while baking homemade bread and ended up pinned against the wall of her Manhattan kitchen by a monster loaf" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="time" />
            <token id="6" string="she" />
            <token id="7" string="threw" />
            <token id="8" string="in" />
            <token id="9" string="two" />
            <token id="10" string="packages" />
            <token id="11" string="of" />
            <token id="12" string="yeast" />
            <token id="13" string="while" />
            <token id="14" string="baking" />
            <token id="15" string="homemade" />
            <token id="16" string="bread" />
            <token id="17" string="and" />
            <token id="18" string="ended" />
            <token id="19" string="up" />
            <token id="20" string="pinned" />
            <token id="21" string="against" />
            <token id="22" string="the" />
            <token id="23" string="wall" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="Manhattan" />
            <token id="27" string="kitchen" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="monster" />
            <token id="31" string="loaf" />
          </tokens>
        </chunking>
        <chunking id="15" string="the time" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="time" />
          </tokens>
        </chunking>
        <chunking id="16" string="the wall" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="wall" />
          </tokens>
        </chunking>
        <chunking id="17" string="threw in two packages of yeast while baking homemade bread" type="VP">
          <tokens>
            <token id="7" string="threw" />
            <token id="8" string="in" />
            <token id="9" string="two" />
            <token id="10" string="packages" />
            <token id="11" string="of" />
            <token id="12" string="yeast" />
            <token id="13" string="while" />
            <token id="14" string="baking" />
            <token id="15" string="homemade" />
            <token id="16" string="bread" />
          </tokens>
        </chunking>
        <chunking id="18" string="the wall of her Manhattan kitchen" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="wall" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="Manhattan" />
            <token id="27" string="kitchen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">was</governor>
          <dependent id="1">Then</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">was</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">time</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">was</governor>
          <dependent id="5">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">threw</governor>
          <dependent id="6">she</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">time</governor>
          <dependent id="7">threw</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">packages</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">packages</governor>
          <dependent id="9">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">threw</governor>
          <dependent id="10">packages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">yeast</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">packages</governor>
          <dependent id="12">yeast</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">bread</governor>
          <dependent id="13">while</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">bread</governor>
          <dependent id="14">baking</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">bread</governor>
          <dependent id="15">homemade</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">threw</governor>
          <dependent id="16">bread</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">threw</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">threw</governor>
          <dependent id="18">ended</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="18">ended</governor>
          <dependent id="19">up</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">ended</governor>
          <dependent id="20">pinned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">wall</governor>
          <dependent id="21">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">wall</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">pinned</governor>
          <dependent id="23">wall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">kitchen</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">kitchen</governor>
          <dependent id="25">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">kitchen</governor>
          <dependent id="26">Manhattan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">wall</governor>
          <dependent id="27">kitchen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">loaf</governor>
          <dependent id="28">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">loaf</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">loaf</governor>
          <dependent id="30">monster</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">pinned</governor>
          <dependent id="31">loaf</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Manhattan" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Manhattan" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>And there was the time Lucy and Ethel, trying to impress their New York friends with the ultimate souvenir from a trip to Hollywood, pried loose the cement block containing John Wayne&amp;apost;s footprints from in front of Grauman&amp;apost;s Chinese Theater.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="Ethel" lemma="Ethel" stem="ethel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="impress" lemma="impress" stem="impress" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="15" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="16" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="ultimate" lemma="ultimate" stem="ultim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="souvenir" lemma="souvenir" stem="souvenir" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="trip" lemma="trip" stem="trip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="pried" lemma="pry" stem="pri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="loose" lemma="loose" stem="loos" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="cement" lemma="cement" stem="cement" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="31" string="block" lemma="block" stem="block" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="32" string="containing" lemma="contain" stem="contain" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="33" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="34" string="Wayne" lemma="Wayne" stem="wayn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="35" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="36" string="footprints" lemma="footprint" stem="footprint" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="37" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="39" string="front" lemma="front" stem="front" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="40" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="41" string="Grauman" lemma="Grauman" stem="grauman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="42" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="43" string="Chinese" lemma="chinese" stem="chines" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="true" />
        <token id="44" string="Theater" lemma="Theater" stem="theater" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (EX there)) (VP (VBD was) (NP (NP (DT the) (NN time)) (SBAR (S (NP (NP (NNP Lucy) (CC and) (NNP Ethel)) (, ,) (VP (VBG trying) (S (VP (TO to) (VP (VB impress) (NP (PRP$ their) (NNP New) (NNP York) (NNS friends)) (PP (IN with) (NP (NP (DT the) (JJ ultimate) (NN souvenir)) (PP (IN from) (NP (DT a) (NN trip))))) (PP (TO to) (NP (NNP Hollywood))))))) (, ,)) (VP (VBD pried) (ADVP (RB loose)) (NP (NP (DT the) (NN cement) (NN block)) (VP (VBG containing) (NP (NP (NNP John) (NNP Wayne) (POS 's)) (NNS footprints)) (PP (IN from) (IN in) (NP (NP (NN front)) (PP (IN of) (NP (NP (NNP Grauman) (POS 's)) (JJ Chinese) (NNP Theater)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the time Lucy and Ethel , trying to impress their New York friends with the ultimate souvenir from a trip to Hollywood , pried loose the cement block containing John Wayne 's footprints from in front of Grauman 's Chinese Theater" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="time" />
            <token id="6" string="Lucy" />
            <token id="7" string="and" />
            <token id="8" string="Ethel" />
            <token id="9" string="," />
            <token id="10" string="trying" />
            <token id="11" string="to" />
            <token id="12" string="impress" />
            <token id="13" string="their" />
            <token id="14" string="New" />
            <token id="15" string="York" />
            <token id="16" string="friends" />
            <token id="17" string="with" />
            <token id="18" string="the" />
            <token id="19" string="ultimate" />
            <token id="20" string="souvenir" />
            <token id="21" string="from" />
            <token id="22" string="a" />
            <token id="23" string="trip" />
            <token id="24" string="to" />
            <token id="25" string="Hollywood" />
            <token id="26" string="," />
            <token id="27" string="pried" />
            <token id="28" string="loose" />
            <token id="29" string="the" />
            <token id="30" string="cement" />
            <token id="31" string="block" />
            <token id="32" string="containing" />
            <token id="33" string="John" />
            <token id="34" string="Wayne" />
            <token id="35" string="'s" />
            <token id="36" string="footprints" />
            <token id="37" string="from" />
            <token id="38" string="in" />
            <token id="39" string="front" />
            <token id="40" string="of" />
            <token id="41" string="Grauman" />
            <token id="42" string="'s" />
            <token id="43" string="Chinese" />
            <token id="44" string="Theater" />
          </tokens>
        </chunking>
        <chunking id="2" string="Lucy and Ethel , trying to impress their New York friends with the ultimate souvenir from a trip to Hollywood ," type="NP">
          <tokens>
            <token id="6" string="Lucy" />
            <token id="7" string="and" />
            <token id="8" string="Ethel" />
            <token id="9" string="," />
            <token id="10" string="trying" />
            <token id="11" string="to" />
            <token id="12" string="impress" />
            <token id="13" string="their" />
            <token id="14" string="New" />
            <token id="15" string="York" />
            <token id="16" string="friends" />
            <token id="17" string="with" />
            <token id="18" string="the" />
            <token id="19" string="ultimate" />
            <token id="20" string="souvenir" />
            <token id="21" string="from" />
            <token id="22" string="a" />
            <token id="23" string="trip" />
            <token id="24" string="to" />
            <token id="25" string="Hollywood" />
            <token id="26" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="was the time Lucy and Ethel , trying to impress their New York friends with the ultimate souvenir from a trip to Hollywood , pried loose the cement block containing John Wayne 's footprints from in front of Grauman 's Chinese Theater" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="time" />
            <token id="6" string="Lucy" />
            <token id="7" string="and" />
            <token id="8" string="Ethel" />
            <token id="9" string="," />
            <token id="10" string="trying" />
            <token id="11" string="to" />
            <token id="12" string="impress" />
            <token id="13" string="their" />
            <token id="14" string="New" />
            <token id="15" string="York" />
            <token id="16" string="friends" />
            <token id="17" string="with" />
            <token id="18" string="the" />
            <token id="19" string="ultimate" />
            <token id="20" string="souvenir" />
            <token id="21" string="from" />
            <token id="22" string="a" />
            <token id="23" string="trip" />
            <token id="24" string="to" />
            <token id="25" string="Hollywood" />
            <token id="26" string="," />
            <token id="27" string="pried" />
            <token id="28" string="loose" />
            <token id="29" string="the" />
            <token id="30" string="cement" />
            <token id="31" string="block" />
            <token id="32" string="containing" />
            <token id="33" string="John" />
            <token id="34" string="Wayne" />
            <token id="35" string="'s" />
            <token id="36" string="footprints" />
            <token id="37" string="from" />
            <token id="38" string="in" />
            <token id="39" string="front" />
            <token id="40" string="of" />
            <token id="41" string="Grauman" />
            <token id="42" string="'s" />
            <token id="43" string="Chinese" />
            <token id="44" string="Theater" />
          </tokens>
        </chunking>
        <chunking id="4" string="the ultimate souvenir" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="ultimate" />
            <token id="20" string="souvenir" />
          </tokens>
        </chunking>
        <chunking id="5" string="the cement block" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="cement" />
            <token id="31" string="block" />
          </tokens>
        </chunking>
        <chunking id="6" string="Grauman 's Chinese Theater" type="NP">
          <tokens>
            <token id="41" string="Grauman" />
            <token id="42" string="'s" />
            <token id="43" string="Chinese" />
            <token id="44" string="Theater" />
          </tokens>
        </chunking>
        <chunking id="7" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="8" string="Hollywood" type="NP">
          <tokens>
            <token id="25" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="9" string="to impress their New York friends with the ultimate souvenir from a trip to Hollywood" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="impress" />
            <token id="13" string="their" />
            <token id="14" string="New" />
            <token id="15" string="York" />
            <token id="16" string="friends" />
            <token id="17" string="with" />
            <token id="18" string="the" />
            <token id="19" string="ultimate" />
            <token id="20" string="souvenir" />
            <token id="21" string="from" />
            <token id="22" string="a" />
            <token id="23" string="trip" />
            <token id="24" string="to" />
            <token id="25" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="10" string="the time" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="John Wayne 's footprints" type="NP">
          <tokens>
            <token id="33" string="John" />
            <token id="34" string="Wayne" />
            <token id="35" string="'s" />
            <token id="36" string="footprints" />
          </tokens>
        </chunking>
        <chunking id="12" string="Lucy and Ethel , trying to impress their New York friends with the ultimate souvenir from a trip to Hollywood , pried loose the cement block containing John Wayne 's footprints from in front of Grauman 's Chinese Theater" type="SBAR">
          <tokens>
            <token id="6" string="Lucy" />
            <token id="7" string="and" />
            <token id="8" string="Ethel" />
            <token id="9" string="," />
            <token id="10" string="trying" />
            <token id="11" string="to" />
            <token id="12" string="impress" />
            <token id="13" string="their" />
            <token id="14" string="New" />
            <token id="15" string="York" />
            <token id="16" string="friends" />
            <token id="17" string="with" />
            <token id="18" string="the" />
            <token id="19" string="ultimate" />
            <token id="20" string="souvenir" />
            <token id="21" string="from" />
            <token id="22" string="a" />
            <token id="23" string="trip" />
            <token id="24" string="to" />
            <token id="25" string="Hollywood" />
            <token id="26" string="," />
            <token id="27" string="pried" />
            <token id="28" string="loose" />
            <token id="29" string="the" />
            <token id="30" string="cement" />
            <token id="31" string="block" />
            <token id="32" string="containing" />
            <token id="33" string="John" />
            <token id="34" string="Wayne" />
            <token id="35" string="'s" />
            <token id="36" string="footprints" />
            <token id="37" string="from" />
            <token id="38" string="in" />
            <token id="39" string="front" />
            <token id="40" string="of" />
            <token id="41" string="Grauman" />
            <token id="42" string="'s" />
            <token id="43" string="Chinese" />
            <token id="44" string="Theater" />
          </tokens>
        </chunking>
        <chunking id="13" string="Lucy and Ethel" type="NP">
          <tokens>
            <token id="6" string="Lucy" />
            <token id="7" string="and" />
            <token id="8" string="Ethel" />
          </tokens>
        </chunking>
        <chunking id="14" string="front" type="NP">
          <tokens>
            <token id="39" string="front" />
          </tokens>
        </chunking>
        <chunking id="15" string="a trip" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="trip" />
          </tokens>
        </chunking>
        <chunking id="16" string="pried loose the cement block containing John Wayne 's footprints from in front of Grauman 's Chinese Theater" type="VP">
          <tokens>
            <token id="27" string="pried" />
            <token id="28" string="loose" />
            <token id="29" string="the" />
            <token id="30" string="cement" />
            <token id="31" string="block" />
            <token id="32" string="containing" />
            <token id="33" string="John" />
            <token id="34" string="Wayne" />
            <token id="35" string="'s" />
            <token id="36" string="footprints" />
            <token id="37" string="from" />
            <token id="38" string="in" />
            <token id="39" string="front" />
            <token id="40" string="of" />
            <token id="41" string="Grauman" />
            <token id="42" string="'s" />
            <token id="43" string="Chinese" />
            <token id="44" string="Theater" />
          </tokens>
        </chunking>
        <chunking id="17" string="trying to impress their New York friends with the ultimate souvenir from a trip to Hollywood" type="VP">
          <tokens>
            <token id="10" string="trying" />
            <token id="11" string="to" />
            <token id="12" string="impress" />
            <token id="13" string="their" />
            <token id="14" string="New" />
            <token id="15" string="York" />
            <token id="16" string="friends" />
            <token id="17" string="with" />
            <token id="18" string="the" />
            <token id="19" string="ultimate" />
            <token id="20" string="souvenir" />
            <token id="21" string="from" />
            <token id="22" string="a" />
            <token id="23" string="trip" />
            <token id="24" string="to" />
            <token id="25" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="18" string="the cement block containing John Wayne 's footprints from in front of Grauman 's Chinese Theater" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="cement" />
            <token id="31" string="block" />
            <token id="32" string="containing" />
            <token id="33" string="John" />
            <token id="34" string="Wayne" />
            <token id="35" string="'s" />
            <token id="36" string="footprints" />
            <token id="37" string="from" />
            <token id="38" string="in" />
            <token id="39" string="front" />
            <token id="40" string="of" />
            <token id="41" string="Grauman" />
            <token id="42" string="'s" />
            <token id="43" string="Chinese" />
            <token id="44" string="Theater" />
          </tokens>
        </chunking>
        <chunking id="19" string="John Wayne 's" type="NP">
          <tokens>
            <token id="33" string="John" />
            <token id="34" string="Wayne" />
            <token id="35" string="'s" />
          </tokens>
        </chunking>
        <chunking id="20" string="the ultimate souvenir from a trip" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="ultimate" />
            <token id="20" string="souvenir" />
            <token id="21" string="from" />
            <token id="22" string="a" />
            <token id="23" string="trip" />
          </tokens>
        </chunking>
        <chunking id="21" string="containing John Wayne 's footprints from in front of Grauman 's Chinese Theater" type="VP">
          <tokens>
            <token id="32" string="containing" />
            <token id="33" string="John" />
            <token id="34" string="Wayne" />
            <token id="35" string="'s" />
            <token id="36" string="footprints" />
            <token id="37" string="from" />
            <token id="38" string="in" />
            <token id="39" string="front" />
            <token id="40" string="of" />
            <token id="41" string="Grauman" />
            <token id="42" string="'s" />
            <token id="43" string="Chinese" />
            <token id="44" string="Theater" />
          </tokens>
        </chunking>
        <chunking id="22" string="impress their New York friends with the ultimate souvenir from a trip to Hollywood" type="VP">
          <tokens>
            <token id="12" string="impress" />
            <token id="13" string="their" />
            <token id="14" string="New" />
            <token id="15" string="York" />
            <token id="16" string="friends" />
            <token id="17" string="with" />
            <token id="18" string="the" />
            <token id="19" string="ultimate" />
            <token id="20" string="souvenir" />
            <token id="21" string="from" />
            <token id="22" string="a" />
            <token id="23" string="trip" />
            <token id="24" string="to" />
            <token id="25" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="23" string="front of Grauman 's Chinese Theater" type="NP">
          <tokens>
            <token id="39" string="front" />
            <token id="40" string="of" />
            <token id="41" string="Grauman" />
            <token id="42" string="'s" />
            <token id="43" string="Chinese" />
            <token id="44" string="Theater" />
          </tokens>
        </chunking>
        <chunking id="24" string="their New York friends" type="NP">
          <tokens>
            <token id="13" string="their" />
            <token id="14" string="New" />
            <token id="15" string="York" />
            <token id="16" string="friends" />
          </tokens>
        </chunking>
        <chunking id="25" string="Grauman 's" type="NP">
          <tokens>
            <token id="41" string="Grauman" />
            <token id="42" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">was</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">was</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">time</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">was</governor>
          <dependent id="5">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">pried</governor>
          <dependent id="6">Lucy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">Lucy</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">Lucy</governor>
          <dependent id="8">Ethel</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">Lucy</governor>
          <dependent id="10">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">impress</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">trying</governor>
          <dependent id="12">impress</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">friends</governor>
          <dependent id="13">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">friends</governor>
          <dependent id="14">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">friends</governor>
          <dependent id="15">York</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">impress</governor>
          <dependent id="16">friends</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">souvenir</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">souvenir</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">souvenir</governor>
          <dependent id="19">ultimate</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">impress</governor>
          <dependent id="20">souvenir</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">trip</governor>
          <dependent id="21">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">trip</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">souvenir</governor>
          <dependent id="23">trip</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Hollywood</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">impress</governor>
          <dependent id="25">Hollywood</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">time</governor>
          <dependent id="27">pried</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">pried</governor>
          <dependent id="28">loose</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">block</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">block</governor>
          <dependent id="30">cement</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">pried</governor>
          <dependent id="31">block</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="31">block</governor>
          <dependent id="32">containing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Wayne</governor>
          <dependent id="33">John</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">footprints</governor>
          <dependent id="34">Wayne</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Wayne</governor>
          <dependent id="35">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">containing</governor>
          <dependent id="36">footprints</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">Theater</governor>
          <dependent id="37">from</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">Theater</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="38">in</governor>
          <dependent id="39">front</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="38">in</governor>
          <dependent id="40">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="44">Theater</governor>
          <dependent id="41">Grauman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">Grauman</governor>
          <dependent id="42">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="44">Theater</governor>
          <dependent id="43">Chinese</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">containing</governor>
          <dependent id="44">Theater</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="New" />
            <token id="15" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="3" string="John Wayne" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="John" />
            <token id="34" string="Wayne" />
          </tokens>
        </entity>
        <entity id="4" string="Chinese" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="43" string="Chinese" />
          </tokens>
        </entity>
        <entity id="5" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Lucy" />
          </tokens>
        </entity>
        <entity id="6" string="Grauman" type="PERSON" score="0.0">
          <tokens>
            <token id="41" string="Grauman" />
          </tokens>
        </entity>
        <entity id="7" string="Ethel" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Ethel" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Of course, the block broke.</content>
      <tokens>
        <token id="1" string="Of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="block" lemma="block" stem="block" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="broke" lemma="break" stem="broke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Of) (NP (NN course))) (, ,) (NP (DT the) (NN block)) (VP (VBD broke)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="broke" type="VP">
          <tokens>
            <token id="6" string="broke" />
          </tokens>
        </chunking>
        <chunking id="2" string="course" type="NP">
          <tokens>
            <token id="2" string="course" />
          </tokens>
        </chunking>
        <chunking id="3" string="the block" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="block" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">course</governor>
          <dependent id="1">Of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">broke</governor>
          <dependent id="2">course</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">block</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">broke</governor>
          <dependent id="5">block</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">broke</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>Week after week, Lucy would find herself trapped in a vat of laundry starch, locked in a meat freezer, or lost on a subway with a loving cup stuck on her head.</content>
      <tokens>
        <token id="1" string="Week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="2" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="herself" lemma="herself" stem="herself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="trapped" lemma="trap" stem="trap" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="vat" lemma="vat" stem="vat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="laundry" lemma="laundry" stem="laundri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="starch" lemma="starch" stem="starch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="locked" lemma="lock" stem="lock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="meat" lemma="meat" stem="meat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="freezer" lemma="freezer" stem="freezer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="lost" lemma="lose" stem="lost" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="subway" lemma="subway" stem="subwai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="loving" lemma="loving" stem="love" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="cup" lemma="cup" stem="cup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="stuck" lemma="stick" stem="stuck" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (NN Week)) (PP (IN after) (NP (NN week))) (, ,) (NP (NNP Lucy)) (VP (MD would) (VP (VB find) (S (NP (PRP herself)) (VP (VP (VBN trapped) (PP (IN in) (NP (NP (DT a) (NN vat)) (PP (IN of) (NP (NN laundry) (NN starch))) (, ,) (VP (VBN locked) (PP (IN in) (NP (DT a) (NN meat) (NN freezer)))) (, ,)))) (CC or) (VP (VBN lost) (PP (IN on) (NP (DT a) (NN subway))) (PP (IN with) (NP (NP (DT a) (JJ loving) (NN cup)) (VP (VBD stuck) (PP (IN on) (NP (PRP$ her) (NN head))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="trapped in a vat of laundry starch , locked in a meat freezer , or lost on a subway with a loving cup stuck on her head" type="VP">
          <tokens>
            <token id="9" string="trapped" />
            <token id="10" string="in" />
            <token id="11" string="a" />
            <token id="12" string="vat" />
            <token id="13" string="of" />
            <token id="14" string="laundry" />
            <token id="15" string="starch" />
            <token id="16" string="," />
            <token id="17" string="locked" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="meat" />
            <token id="21" string="freezer" />
            <token id="22" string="," />
            <token id="23" string="or" />
            <token id="24" string="lost" />
            <token id="25" string="on" />
            <token id="26" string="a" />
            <token id="27" string="subway" />
            <token id="28" string="with" />
            <token id="29" string="a" />
            <token id="30" string="loving" />
            <token id="31" string="cup" />
            <token id="32" string="stuck" />
            <token id="33" string="on" />
            <token id="34" string="her" />
            <token id="35" string="head" />
          </tokens>
        </chunking>
        <chunking id="2" string="laundry starch" type="NP">
          <tokens>
            <token id="14" string="laundry" />
            <token id="15" string="starch" />
          </tokens>
        </chunking>
        <chunking id="3" string="her head" type="NP">
          <tokens>
            <token id="34" string="her" />
            <token id="35" string="head" />
          </tokens>
        </chunking>
        <chunking id="4" string="a meat freezer" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="meat" />
            <token id="21" string="freezer" />
          </tokens>
        </chunking>
        <chunking id="5" string="week" type="NP">
          <tokens>
            <token id="3" string="week" />
          </tokens>
        </chunking>
        <chunking id="6" string="would find herself trapped in a vat of laundry starch , locked in a meat freezer , or lost on a subway with a loving cup stuck on her head" type="VP">
          <tokens>
            <token id="6" string="would" />
            <token id="7" string="find" />
            <token id="8" string="herself" />
            <token id="9" string="trapped" />
            <token id="10" string="in" />
            <token id="11" string="a" />
            <token id="12" string="vat" />
            <token id="13" string="of" />
            <token id="14" string="laundry" />
            <token id="15" string="starch" />
            <token id="16" string="," />
            <token id="17" string="locked" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="meat" />
            <token id="21" string="freezer" />
            <token id="22" string="," />
            <token id="23" string="or" />
            <token id="24" string="lost" />
            <token id="25" string="on" />
            <token id="26" string="a" />
            <token id="27" string="subway" />
            <token id="28" string="with" />
            <token id="29" string="a" />
            <token id="30" string="loving" />
            <token id="31" string="cup" />
            <token id="32" string="stuck" />
            <token id="33" string="on" />
            <token id="34" string="her" />
            <token id="35" string="head" />
          </tokens>
        </chunking>
        <chunking id="7" string="a loving cup stuck on her head" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="loving" />
            <token id="31" string="cup" />
            <token id="32" string="stuck" />
            <token id="33" string="on" />
            <token id="34" string="her" />
            <token id="35" string="head" />
          </tokens>
        </chunking>
        <chunking id="8" string="locked in a meat freezer" type="VP">
          <tokens>
            <token id="17" string="locked" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="meat" />
            <token id="21" string="freezer" />
          </tokens>
        </chunking>
        <chunking id="9" string="a vat" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="vat" />
          </tokens>
        </chunking>
        <chunking id="10" string="lost on a subway with a loving cup stuck on her head" type="VP">
          <tokens>
            <token id="24" string="lost" />
            <token id="25" string="on" />
            <token id="26" string="a" />
            <token id="27" string="subway" />
            <token id="28" string="with" />
            <token id="29" string="a" />
            <token id="30" string="loving" />
            <token id="31" string="cup" />
            <token id="32" string="stuck" />
            <token id="33" string="on" />
            <token id="34" string="her" />
            <token id="35" string="head" />
          </tokens>
        </chunking>
        <chunking id="11" string="find herself trapped in a vat of laundry starch , locked in a meat freezer , or lost on a subway with a loving cup stuck on her head" type="VP">
          <tokens>
            <token id="7" string="find" />
            <token id="8" string="herself" />
            <token id="9" string="trapped" />
            <token id="10" string="in" />
            <token id="11" string="a" />
            <token id="12" string="vat" />
            <token id="13" string="of" />
            <token id="14" string="laundry" />
            <token id="15" string="starch" />
            <token id="16" string="," />
            <token id="17" string="locked" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="meat" />
            <token id="21" string="freezer" />
            <token id="22" string="," />
            <token id="23" string="or" />
            <token id="24" string="lost" />
            <token id="25" string="on" />
            <token id="26" string="a" />
            <token id="27" string="subway" />
            <token id="28" string="with" />
            <token id="29" string="a" />
            <token id="30" string="loving" />
            <token id="31" string="cup" />
            <token id="32" string="stuck" />
            <token id="33" string="on" />
            <token id="34" string="her" />
            <token id="35" string="head" />
          </tokens>
        </chunking>
        <chunking id="12" string="a subway" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="subway" />
          </tokens>
        </chunking>
        <chunking id="13" string="Lucy" type="NP">
          <tokens>
            <token id="5" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="14" string="stuck on her head" type="VP">
          <tokens>
            <token id="32" string="stuck" />
            <token id="33" string="on" />
            <token id="34" string="her" />
            <token id="35" string="head" />
          </tokens>
        </chunking>
        <chunking id="15" string="trapped in a vat of laundry starch , locked in a meat freezer ," type="VP">
          <tokens>
            <token id="9" string="trapped" />
            <token id="10" string="in" />
            <token id="11" string="a" />
            <token id="12" string="vat" />
            <token id="13" string="of" />
            <token id="14" string="laundry" />
            <token id="15" string="starch" />
            <token id="16" string="," />
            <token id="17" string="locked" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="meat" />
            <token id="21" string="freezer" />
            <token id="22" string="," />
          </tokens>
        </chunking>
        <chunking id="16" string="a loving cup" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="loving" />
            <token id="31" string="cup" />
          </tokens>
        </chunking>
        <chunking id="17" string="herself" type="NP">
          <tokens>
            <token id="8" string="herself" />
          </tokens>
        </chunking>
        <chunking id="18" string="a vat of laundry starch , locked in a meat freezer ," type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="vat" />
            <token id="13" string="of" />
            <token id="14" string="laundry" />
            <token id="15" string="starch" />
            <token id="16" string="," />
            <token id="17" string="locked" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="meat" />
            <token id="21" string="freezer" />
            <token id="22" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:tmod">
          <governor id="7">find</governor>
          <dependent id="1">Week</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">week</governor>
          <dependent id="2">after</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">find</governor>
          <dependent id="3">week</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">find</governor>
          <dependent id="5">Lucy</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">find</governor>
          <dependent id="6">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">find</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">trapped</governor>
          <dependent id="8">herself</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">find</governor>
          <dependent id="9">trapped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">vat</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">vat</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">trapped</governor>
          <dependent id="12">vat</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">starch</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">starch</governor>
          <dependent id="14">laundry</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">vat</governor>
          <dependent id="15">starch</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">vat</governor>
          <dependent id="17">locked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">freezer</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">freezer</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">freezer</governor>
          <dependent id="20">meat</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">locked</governor>
          <dependent id="21">freezer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">trapped</governor>
          <dependent id="23">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">trapped</governor>
          <dependent id="24">lost</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">subway</governor>
          <dependent id="25">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">subway</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">lost</governor>
          <dependent id="27">subway</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">cup</governor>
          <dependent id="28">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">cup</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">cup</governor>
          <dependent id="30">loving</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">lost</governor>
          <dependent id="31">cup</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="31">cup</governor>
          <dependent id="32">stuck</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">head</governor>
          <dependent id="33">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">head</governor>
          <dependent id="34">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">stuck</governor>
          <dependent id="35">head</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="week" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="week" />
          </tokens>
        </entity>
        <entity id="2" string="Week" type="DURATION" score="0.0">
          <tokens>
            <token id="1" string="Week" />
          </tokens>
        </entity>
        <entity id="3" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Her turmoils permanently positioned her in the hearts of most Americans, including the critics.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="turmoils" lemma="turmoil" stem="turmoil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="permanently" lemma="permanently" stem="perman" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="positioned" lemma="position" stem="posit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="hearts" lemma="heart" stem="heart" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Americans" lemma="Americans" stem="american" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Her) (NNS turmoils)) (ADVP (RB permanently)) (VP (VBD positioned) (NP (PRP her)) (PP (IN in) (NP (NP (DT the) (NNS hearts)) (PP (IN of) (NP (NP (NP (JJS most)) (NNPS Americans)) (, ,) (PP (VBG including) (NP (DT the) (NNS critics)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="most" type="NP">
          <tokens>
            <token id="10" string="most" />
          </tokens>
        </chunking>
        <chunking id="2" string="the critics" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="critics" />
          </tokens>
        </chunking>
        <chunking id="3" string="her" type="NP">
          <tokens>
            <token id="5" string="her" />
          </tokens>
        </chunking>
        <chunking id="4" string="Her turmoils" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="turmoils" />
          </tokens>
        </chunking>
        <chunking id="5" string="the hearts of most Americans , including the critics" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="hearts" />
            <token id="9" string="of" />
            <token id="10" string="most" />
            <token id="11" string="Americans" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="the" />
            <token id="15" string="critics" />
          </tokens>
        </chunking>
        <chunking id="6" string="most Americans , including the critics" type="NP">
          <tokens>
            <token id="10" string="most" />
            <token id="11" string="Americans" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="the" />
            <token id="15" string="critics" />
          </tokens>
        </chunking>
        <chunking id="7" string="most Americans" type="NP">
          <tokens>
            <token id="10" string="most" />
            <token id="11" string="Americans" />
          </tokens>
        </chunking>
        <chunking id="8" string="the hearts" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="hearts" />
          </tokens>
        </chunking>
        <chunking id="9" string="positioned her in the hearts of most Americans , including the critics" type="VP">
          <tokens>
            <token id="4" string="positioned" />
            <token id="5" string="her" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="hearts" />
            <token id="9" string="of" />
            <token id="10" string="most" />
            <token id="11" string="Americans" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="the" />
            <token id="15" string="critics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">turmoils</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">positioned</governor>
          <dependent id="2">turmoils</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">positioned</governor>
          <dependent id="3">permanently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">positioned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">positioned</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">hearts</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">hearts</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">positioned</governor>
          <dependent id="8">hearts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Americans</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Americans</governor>
          <dependent id="10">most</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">hearts</governor>
          <dependent id="11">Americans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">critics</governor>
          <dependent id="13">including</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">critics</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Americans</governor>
          <dependent id="15">critics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Americans" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="Americans" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>&amp;quot;An extraordinary discipline and intuitive understanding of farce give &amp;apost;I Love Lucy&amp;apost; an engaging lilt,&amp;quot; wrote New York Times critic Jack Gould.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="An" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="extraordinary" lemma="extraordinary" stem="extraordinari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="discipline" lemma="discipline" stem="disciplin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="intuitive" lemma="intuitive" stem="intuit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="understanding" lemma="understanding" stem="understand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="farce" lemma="farce" stem="farc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="give" lemma="give" stem="give" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="engaging" lemma="engaging" stem="engag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="lilt" lemma="lilt" stem="lilt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="23" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="24" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="25" string="critic" lemma="critic" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="Jack" lemma="Jack" stem="jack" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="27" string="Gould" lemma="Gould" stem="gould" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NP (DT An) (JJ extraordinary) (NN discipline) (CC and) (JJ intuitive) (NN understanding)) (PP (IN of) (NP (NN farce)))) (VP (VBP give) ('' ') (NP (PRP I)) (PP (NP (NNP Love)) (NP (NP (NNP Lucy) (POS ')) (NP (DT an) (JJ engaging) (NN lilt)))))) (, ,) ('' '') (VP (VBD wrote)) (NP (NNP New) (NNP York) (NNP Times) (NN critic) (NNP Jack) (NNP Gould)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="An extraordinary discipline and intuitive understanding" type="NP">
          <tokens>
            <token id="2" string="An" />
            <token id="3" string="extraordinary" />
            <token id="4" string="discipline" />
            <token id="5" string="and" />
            <token id="6" string="intuitive" />
            <token id="7" string="understanding" />
          </tokens>
        </chunking>
        <chunking id="2" string="Lucy ' an engaging lilt" type="NP">
          <tokens>
            <token id="14" string="Lucy" />
            <token id="15" string="'" />
            <token id="16" string="an" />
            <token id="17" string="engaging" />
            <token id="18" string="lilt" />
          </tokens>
        </chunking>
        <chunking id="3" string="farce" type="NP">
          <tokens>
            <token id="9" string="farce" />
          </tokens>
        </chunking>
        <chunking id="4" string="New York Times critic Jack Gould" type="NP">
          <tokens>
            <token id="22" string="New" />
            <token id="23" string="York" />
            <token id="24" string="Times" />
            <token id="25" string="critic" />
            <token id="26" string="Jack" />
            <token id="27" string="Gould" />
          </tokens>
        </chunking>
        <chunking id="5" string="An extraordinary discipline and intuitive understanding of farce" type="NP">
          <tokens>
            <token id="2" string="An" />
            <token id="3" string="extraordinary" />
            <token id="4" string="discipline" />
            <token id="5" string="and" />
            <token id="6" string="intuitive" />
            <token id="7" string="understanding" />
            <token id="8" string="of" />
            <token id="9" string="farce" />
          </tokens>
        </chunking>
        <chunking id="6" string="Love" type="NP">
          <tokens>
            <token id="13" string="Love" />
          </tokens>
        </chunking>
        <chunking id="7" string="wrote" type="VP">
          <tokens>
            <token id="21" string="wrote" />
          </tokens>
        </chunking>
        <chunking id="8" string="give ' I Love Lucy ' an engaging lilt" type="VP">
          <tokens>
            <token id="10" string="give" />
            <token id="11" string="'" />
            <token id="12" string="I" />
            <token id="13" string="Love" />
            <token id="14" string="Lucy" />
            <token id="15" string="'" />
            <token id="16" string="an" />
            <token id="17" string="engaging" />
            <token id="18" string="lilt" />
          </tokens>
        </chunking>
        <chunking id="9" string="I" type="NP">
          <tokens>
            <token id="12" string="I" />
          </tokens>
        </chunking>
        <chunking id="10" string="Lucy '" type="NP">
          <tokens>
            <token id="14" string="Lucy" />
            <token id="15" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="an engaging lilt" type="NP">
          <tokens>
            <token id="16" string="an" />
            <token id="17" string="engaging" />
            <token id="18" string="lilt" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">discipline</governor>
          <dependent id="2">An</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">discipline</governor>
          <dependent id="3">extraordinary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">give</governor>
          <dependent id="4">discipline</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">discipline</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">understanding</governor>
          <dependent id="6">intuitive</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">discipline</governor>
          <dependent id="7">understanding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">farce</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">discipline</governor>
          <dependent id="9">farce</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">wrote</governor>
          <dependent id="10">give</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">give</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">give</governor>
          <dependent id="13">Love</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">Love</governor>
          <dependent id="14">Lucy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Lucy</governor>
          <dependent id="15">'</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">lilt</governor>
          <dependent id="16">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">lilt</governor>
          <dependent id="17">engaging</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">Lucy</governor>
          <dependent id="18">lilt</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">wrote</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Gould</governor>
          <dependent id="22">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Gould</governor>
          <dependent id="23">York</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Gould</governor>
          <dependent id="24">Times</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Gould</governor>
          <dependent id="25">critic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Gould</governor>
          <dependent id="26">Jack</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">wrote</governor>
          <dependent id="27">Gould</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York Times" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="New" />
            <token id="23" string="York" />
            <token id="24" string="Times" />
          </tokens>
        </entity>
        <entity id="2" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lucy" />
          </tokens>
        </entity>
        <entity id="3" string="Jack Gould" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Jack" />
            <token id="27" string="Gould" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>In its Lucy cover story, Time magazine said: &amp;quot;This is the sort of cheerful rowdiness that has been rare. . . .</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="cover" lemma="cover" stem="cover" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Time" lemma="Time" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="sort" lemma="sort" stem="sort" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="cheerful" lemma="cheerful" stem="cheer" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="rowdiness" lemma="rowdiness" stem="rowdi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="rare" lemma="rare" stem="rare" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (PRP$ its) (NNP Lucy) (NN cover) (NN story))) (, ,) (NP (NNP Time) (NN magazine)) (VP (VBD said) (: :) (`` ``) (S (NP (DT This)) (VP (VBZ is) (NP (NP (DT the) (NN sort)) (PP (IN of) (NP (JJ cheerful) (NN rowdiness))) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN been) (ADJP (JJ rare)))))))))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that has been rare" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="been" />
            <token id="22" string="rare" />
          </tokens>
        </chunking>
        <chunking id="2" string="Time magazine" type="NP">
          <tokens>
            <token id="7" string="Time" />
            <token id="8" string="magazine" />
          </tokens>
        </chunking>
        <chunking id="3" string="is the sort of cheerful rowdiness that has been rare" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="the" />
            <token id="15" string="sort" />
            <token id="16" string="of" />
            <token id="17" string="cheerful" />
            <token id="18" string="rowdiness" />
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="been" />
            <token id="22" string="rare" />
          </tokens>
        </chunking>
        <chunking id="4" string="rare" type="ADJP">
          <tokens>
            <token id="22" string="rare" />
          </tokens>
        </chunking>
        <chunking id="5" string="cheerful rowdiness" type="NP">
          <tokens>
            <token id="17" string="cheerful" />
            <token id="18" string="rowdiness" />
          </tokens>
        </chunking>
        <chunking id="6" string="This" type="NP">
          <tokens>
            <token id="12" string="This" />
          </tokens>
        </chunking>
        <chunking id="7" string="its Lucy cover story" type="NP">
          <tokens>
            <token id="2" string="its" />
            <token id="3" string="Lucy" />
            <token id="4" string="cover" />
            <token id="5" string="story" />
          </tokens>
        </chunking>
        <chunking id="8" string="the sort" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="sort" />
          </tokens>
        </chunking>
        <chunking id="9" string="been rare" type="VP">
          <tokens>
            <token id="21" string="been" />
            <token id="22" string="rare" />
          </tokens>
        </chunking>
        <chunking id="10" string="said : `` This is the sort of cheerful rowdiness that has been rare" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string=":" />
            <token id="11" string="&quot;" />
            <token id="12" string="This" />
            <token id="13" string="is" />
            <token id="14" string="the" />
            <token id="15" string="sort" />
            <token id="16" string="of" />
            <token id="17" string="cheerful" />
            <token id="18" string="rowdiness" />
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="been" />
            <token id="22" string="rare" />
          </tokens>
        </chunking>
        <chunking id="11" string="the sort of cheerful rowdiness that has been rare" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="sort" />
            <token id="16" string="of" />
            <token id="17" string="cheerful" />
            <token id="18" string="rowdiness" />
            <token id="19" string="that" />
            <token id="20" string="has" />
            <token id="21" string="been" />
            <token id="22" string="rare" />
          </tokens>
        </chunking>
        <chunking id="12" string="has been rare" type="VP">
          <tokens>
            <token id="20" string="has" />
            <token id="21" string="been" />
            <token id="22" string="rare" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">story</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">story</governor>
          <dependent id="2">its</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">story</governor>
          <dependent id="3">Lucy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">story</governor>
          <dependent id="4">cover</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">said</governor>
          <dependent id="5">story</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">magazine</governor>
          <dependent id="7">Time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="8">magazine</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">sort</governor>
          <dependent id="12">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">sort</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">sort</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="15">sort</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">rowdiness</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">rowdiness</governor>
          <dependent id="17">cheerful</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">sort</governor>
          <dependent id="18">rowdiness</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">rare</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">rare</governor>
          <dependent id="20">has</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">rare</governor>
          <dependent id="21">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">sort</governor>
          <dependent id="22">rare</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Time magazine" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Time" />
            <token id="8" string="magazine" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Lucille submits enthusiastically to being hit with pies; falls over furniture. . . .</content>
      <tokens>
        <token id="1" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="submits" lemma="submit" stem="submit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="enthusiastically" lemma="enthusiastically" stem="enthusiast" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="hit" lemma="hit" stem="hit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="pies" lemma="pie" stem="pi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="falls" lemma="fall" stem="fall" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="furniture" lemma="furniture" stem="furnitur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lucille)) (VP (VBZ submits) (ADVP (RB enthusiastically)) (PP (TO to) (S (VP (VBG being) (VP (VBN hit) (PP (IN with) (NP (NP (NNS pies)) (: ;) (SBAR (S (VP (VBZ falls) (PP (IN over) (NP (NN furniture)))))) (: ...)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lucille" type="NP">
          <tokens>
            <token id="1" string="Lucille" />
          </tokens>
        </chunking>
        <chunking id="2" string="pies" type="NP">
          <tokens>
            <token id="8" string="pies" />
          </tokens>
        </chunking>
        <chunking id="3" string="being hit with pies ; falls over furniture ..." type="VP">
          <tokens>
            <token id="5" string="being" />
            <token id="6" string="hit" />
            <token id="7" string="with" />
            <token id="8" string="pies" />
            <token id="9" string=";" />
            <token id="10" string="falls" />
            <token id="11" string="over" />
            <token id="12" string="furniture" />
            <token id="13" string=". . ." />
          </tokens>
        </chunking>
        <chunking id="4" string="furniture" type="NP">
          <tokens>
            <token id="12" string="furniture" />
          </tokens>
        </chunking>
        <chunking id="5" string="hit with pies ; falls over furniture ..." type="VP">
          <tokens>
            <token id="6" string="hit" />
            <token id="7" string="with" />
            <token id="8" string="pies" />
            <token id="9" string=";" />
            <token id="10" string="falls" />
            <token id="11" string="over" />
            <token id="12" string="furniture" />
            <token id="13" string=". . ." />
          </tokens>
        </chunking>
        <chunking id="6" string="pies ; falls over furniture ..." type="NP">
          <tokens>
            <token id="8" string="pies" />
            <token id="9" string=";" />
            <token id="10" string="falls" />
            <token id="11" string="over" />
            <token id="12" string="furniture" />
            <token id="13" string=". . ." />
          </tokens>
        </chunking>
        <chunking id="7" string="submits enthusiastically to being hit with pies ; falls over furniture ..." type="VP">
          <tokens>
            <token id="2" string="submits" />
            <token id="3" string="enthusiastically" />
            <token id="4" string="to" />
            <token id="5" string="being" />
            <token id="6" string="hit" />
            <token id="7" string="with" />
            <token id="8" string="pies" />
            <token id="9" string=";" />
            <token id="10" string="falls" />
            <token id="11" string="over" />
            <token id="12" string="furniture" />
            <token id="13" string=". . ." />
          </tokens>
        </chunking>
        <chunking id="8" string="falls over furniture" type="SBAR">
          <tokens>
            <token id="10" string="falls" />
            <token id="11" string="over" />
            <token id="12" string="furniture" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">submits</governor>
          <dependent id="1">Lucille</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">submits</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">submits</governor>
          <dependent id="3">enthusiastically</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">hit</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">hit</governor>
          <dependent id="5">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">submits</governor>
          <dependent id="6">hit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">pies</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">hit</governor>
          <dependent id="8">pies</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">pies</governor>
          <dependent id="10">falls</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">furniture</governor>
          <dependent id="11">over</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">falls</governor>
          <dependent id="12">furniture</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucille" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lucille" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="false">
      <content>Tricked out as a ballerina or a Hindu maharani or a toothless hillbilly, she takes her assorted lumps and pratfalls with unflagging zest and good humor.&amp;quot;</content>
      <tokens>
        <token id="1" string="Tricked" lemma="trick" stem="trick" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="ballerina" lemma="ballerina" stem="ballerina" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Hindu" lemma="hindu" stem="hindu" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="9" string="maharani" lemma="maharanus" stem="maharani" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="toothless" lemma="toothless" stem="toothless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="hillbilly" lemma="hillbilly" stem="hillbilli" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="assorted" lemma="assorted" stem="assort" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="lumps" lemma="lump" stem="lump" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="pratfalls" lemma="pratfall" stem="pratfal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="unflagging" lemma="unflagging" stem="unflag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="zest" lemma="zest" stem="zest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="humor" lemma="humor" stem="humor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Tricked) (PRT (RP out)) (PP (IN as) (NP (NP (DT a) (NN ballerina)) (CC or) (NP (NP (DT a) (NN Hindu) (NNS maharani)) (CC or) (NP (DT a) (JJ toothless) (NN hillbilly))))))) (, ,) (NP (PRP she)) (VP (VBZ takes) (NP (PRP$ her) (JJ assorted) (NNS lumps) (CC and) (NNS pratfalls)) (PP (IN with) (NP (NP (JJ unflagging) (NN zest)) (CC and) (NP (JJ good) (NN humor))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Tricked out as a ballerina or a Hindu maharani or a toothless hillbilly" type="VP">
          <tokens>
            <token id="1" string="Tricked" />
            <token id="2" string="out" />
            <token id="3" string="as" />
            <token id="4" string="a" />
            <token id="5" string="ballerina" />
            <token id="6" string="or" />
            <token id="7" string="a" />
            <token id="8" string="Hindu" />
            <token id="9" string="maharani" />
            <token id="10" string="or" />
            <token id="11" string="a" />
            <token id="12" string="toothless" />
            <token id="13" string="hillbilly" />
          </tokens>
        </chunking>
        <chunking id="2" string="takes her assorted lumps and pratfalls with unflagging zest and good humor" type="VP">
          <tokens>
            <token id="16" string="takes" />
            <token id="17" string="her" />
            <token id="18" string="assorted" />
            <token id="19" string="lumps" />
            <token id="20" string="and" />
            <token id="21" string="pratfalls" />
            <token id="22" string="with" />
            <token id="23" string="unflagging" />
            <token id="24" string="zest" />
            <token id="25" string="and" />
            <token id="26" string="good" />
            <token id="27" string="humor" />
          </tokens>
        </chunking>
        <chunking id="3" string="unflagging zest" type="NP">
          <tokens>
            <token id="23" string="unflagging" />
            <token id="24" string="zest" />
          </tokens>
        </chunking>
        <chunking id="4" string="good humor" type="NP">
          <tokens>
            <token id="26" string="good" />
            <token id="27" string="humor" />
          </tokens>
        </chunking>
        <chunking id="5" string="a ballerina or a Hindu maharani or a toothless hillbilly" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="ballerina" />
            <token id="6" string="or" />
            <token id="7" string="a" />
            <token id="8" string="Hindu" />
            <token id="9" string="maharani" />
            <token id="10" string="or" />
            <token id="11" string="a" />
            <token id="12" string="toothless" />
            <token id="13" string="hillbilly" />
          </tokens>
        </chunking>
        <chunking id="6" string="a ballerina" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="ballerina" />
          </tokens>
        </chunking>
        <chunking id="7" string="a Hindu maharani or a toothless hillbilly" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="Hindu" />
            <token id="9" string="maharani" />
            <token id="10" string="or" />
            <token id="11" string="a" />
            <token id="12" string="toothless" />
            <token id="13" string="hillbilly" />
          </tokens>
        </chunking>
        <chunking id="8" string="a Hindu maharani" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="Hindu" />
            <token id="9" string="maharani" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="15" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="unflagging zest and good humor" type="NP">
          <tokens>
            <token id="23" string="unflagging" />
            <token id="24" string="zest" />
            <token id="25" string="and" />
            <token id="26" string="good" />
            <token id="27" string="humor" />
          </tokens>
        </chunking>
        <chunking id="11" string="a toothless hillbilly" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="toothless" />
            <token id="13" string="hillbilly" />
          </tokens>
        </chunking>
        <chunking id="12" string="her assorted lumps and pratfalls" type="NP">
          <tokens>
            <token id="17" string="her" />
            <token id="18" string="assorted" />
            <token id="19" string="lumps" />
            <token id="20" string="and" />
            <token id="21" string="pratfalls" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="16">takes</governor>
          <dependent id="1">Tricked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="1">Tricked</governor>
          <dependent id="2">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">ballerina</governor>
          <dependent id="3">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">ballerina</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Tricked</governor>
          <dependent id="5">ballerina</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">ballerina</governor>
          <dependent id="6">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">maharani</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">maharani</governor>
          <dependent id="8">Hindu</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">ballerina</governor>
          <dependent id="9">maharani</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">maharani</governor>
          <dependent id="10">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">hillbilly</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">hillbilly</governor>
          <dependent id="12">toothless</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">maharani</governor>
          <dependent id="13">hillbilly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">takes</governor>
          <dependent id="15">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">takes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">lumps</governor>
          <dependent id="17">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">lumps</governor>
          <dependent id="18">assorted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">takes</governor>
          <dependent id="19">lumps</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">lumps</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">lumps</governor>
          <dependent id="21">pratfalls</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">zest</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">zest</governor>
          <dependent id="23">unflagging</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">takes</governor>
          <dependent id="24">zest</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">zest</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">humor</governor>
          <dependent id="26">good</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">zest</governor>
          <dependent id="27">humor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hindu" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="8" string="Hindu" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>In a 1981 interview in The Times, even Miss Ball admitted, &amp;quot;I love Lucy.&amp;quot;</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="1981" lemma="1981" stem="1981" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="admitted" lemma="admit" stem="admit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="love" lemma="love" stem="love" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT a) (CD 1981) (NN interview)) (PP (IN in) (NP (DT The) (NNP Times))))) (, ,) (SBAR (RB even) (S (NP (NNP Miss) (NNP Ball)) (VP (VBD admitted)))) (, ,) (`` ``) (NP (PRP I)) (VP (VBP love) (NP (NNP Lucy))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="admitted" type="VP">
          <tokens>
            <token id="12" string="admitted" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Times" type="NP">
          <tokens>
            <token id="6" string="The" />
            <token id="7" string="Times" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="15" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="a 1981 interview in The Times" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="1981" />
            <token id="4" string="interview" />
            <token id="5" string="in" />
            <token id="6" string="The" />
            <token id="7" string="Times" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lucy" type="NP">
          <tokens>
            <token id="17" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="6" string="love Lucy" type="VP">
          <tokens>
            <token id="16" string="love" />
            <token id="17" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="7" string="even Miss Ball admitted" type="SBAR">
          <tokens>
            <token id="9" string="even" />
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="admitted" />
          </tokens>
        </chunking>
        <chunking id="8" string="a 1981 interview" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="1981" />
            <token id="4" string="interview" />
          </tokens>
        </chunking>
        <chunking id="9" string="Miss Ball" type="NP">
          <tokens>
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">interview</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">interview</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">interview</governor>
          <dependent id="3">1981</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">love</governor>
          <dependent id="4">interview</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Times</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Times</governor>
          <dependent id="6">The</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">interview</governor>
          <dependent id="7">Times</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">admitted</governor>
          <dependent id="9">even</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Ball</governor>
          <dependent id="10">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">admitted</governor>
          <dependent id="11">Ball</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">love</governor>
          <dependent id="12">admitted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">love</governor>
          <dependent id="15">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">love</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">love</governor>
          <dependent id="17">Lucy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="1981" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="1981" />
          </tokens>
        </entity>
        <entity id="3" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>&amp;quot;There were two key qualities to her,&amp;quot; the comedienne said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="5" string="key" lemma="key" stem="kei" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="qualities" lemma="quality" stem="qualiti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="comedienne" lemma="comedienne" stem="comedienn" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (EX There)) (VP (VBD were) (NP (NP (CD two) (JJ key) (NNS qualities)) (PP (TO to) (NP (PRP her)))))) (, ,) ('' '') (NP (DT the) (NN comedienne)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="two key qualities" type="NP">
          <tokens>
            <token id="4" string="two" />
            <token id="5" string="key" />
            <token id="6" string="qualities" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="her" type="NP">
          <tokens>
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="4" string="two key qualities to her" type="NP">
          <tokens>
            <token id="4" string="two" />
            <token id="5" string="key" />
            <token id="6" string="qualities" />
            <token id="7" string="to" />
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="5" string="were two key qualities to her" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="two" />
            <token id="5" string="key" />
            <token id="6" string="qualities" />
            <token id="7" string="to" />
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="6" string="the comedienne" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="comedienne" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="13" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">were</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">qualities</governor>
          <dependent id="4">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">qualities</governor>
          <dependent id="5">key</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">were</governor>
          <dependent id="6">qualities</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">her</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">qualities</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">comedienne</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">comedienne</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>&amp;quot;She was always in financial trouble -- if she wanted a fur collar, a ratty little fur collar, she had to figure out a way to make some extra money to get it. . . .</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="financial" lemma="financial" stem="financi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="trouble" lemma="trouble" stem="troubl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="fur" lemma="fur" stem="fur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="collar" lemma="collar" stem="collar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="ratty" lemma="ratty" stem="ratti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="fur" lemma="fur" stem="fur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="collar" lemma="collar" stem="collar" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="figure" lemma="figure" stem="figur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="extra" lemma="extra" stem="extra" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="money" lemma="money" stem="monei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP She)) (VP (VBD was) (ADVP (RB always)) (PP (IN in) (NP (JJ financial) (NN trouble))))) (: --) (S (SBAR (IN if) (S (NP (PRP she)) (VP (VBD wanted) (NP (NP (DT a) (NN fur) (NN collar)) (, ,) (NP (DT a) (JJ ratty) (JJ little) (NN fur) (NN collar)))))) (, ,) (NP (PRP she)) (VP (VBD had) (S (VP (TO to) (VP (VB figure) (PRT (RP out)) (NP (DT a) (NN way) (S (VP (TO to) (VP (VB make) (NP (DT some) (JJ extra) (NN money))))))))) (S (VP (TO to) (VP (VB get) (NP (PRP it))))))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a fur collar" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="fur" />
            <token id="14" string="collar" />
          </tokens>
        </chunking>
        <chunking id="2" string="if she wanted a fur collar , a ratty little fur collar" type="SBAR">
          <tokens>
            <token id="9" string="if" />
            <token id="10" string="she" />
            <token id="11" string="wanted" />
            <token id="12" string="a" />
            <token id="13" string="fur" />
            <token id="14" string="collar" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="ratty" />
            <token id="18" string="little" />
            <token id="19" string="fur" />
            <token id="20" string="collar" />
          </tokens>
        </chunking>
        <chunking id="3" string="a way to make some extra money" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="way" />
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="some" />
            <token id="32" string="extra" />
            <token id="33" string="money" />
          </tokens>
        </chunking>
        <chunking id="4" string="to get it" type="VP">
          <tokens>
            <token id="34" string="to" />
            <token id="35" string="get" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="was always in financial trouble" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="always" />
            <token id="5" string="in" />
            <token id="6" string="financial" />
            <token id="7" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="7" string="to make some extra money" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="some" />
            <token id="32" string="extra" />
            <token id="33" string="money" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="10" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="had to figure out a way to make some extra money to get it" type="VP">
          <tokens>
            <token id="23" string="had" />
            <token id="24" string="to" />
            <token id="25" string="figure" />
            <token id="26" string="out" />
            <token id="27" string="a" />
            <token id="28" string="way" />
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="some" />
            <token id="32" string="extra" />
            <token id="33" string="money" />
            <token id="34" string="to" />
            <token id="35" string="get" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="to figure out a way to make some extra money" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="figure" />
            <token id="26" string="out" />
            <token id="27" string="a" />
            <token id="28" string="way" />
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="some" />
            <token id="32" string="extra" />
            <token id="33" string="money" />
          </tokens>
        </chunking>
        <chunking id="12" string="figure out a way to make some extra money" type="VP">
          <tokens>
            <token id="25" string="figure" />
            <token id="26" string="out" />
            <token id="27" string="a" />
            <token id="28" string="way" />
            <token id="29" string="to" />
            <token id="30" string="make" />
            <token id="31" string="some" />
            <token id="32" string="extra" />
            <token id="33" string="money" />
          </tokens>
        </chunking>
        <chunking id="13" string="wanted a fur collar , a ratty little fur collar" type="VP">
          <tokens>
            <token id="11" string="wanted" />
            <token id="12" string="a" />
            <token id="13" string="fur" />
            <token id="14" string="collar" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="ratty" />
            <token id="18" string="little" />
            <token id="19" string="fur" />
            <token id="20" string="collar" />
          </tokens>
        </chunking>
        <chunking id="14" string="a ratty little fur collar" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="ratty" />
            <token id="18" string="little" />
            <token id="19" string="fur" />
            <token id="20" string="collar" />
          </tokens>
        </chunking>
        <chunking id="15" string="get it" type="VP">
          <tokens>
            <token id="35" string="get" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="16" string="financial trouble" type="NP">
          <tokens>
            <token id="6" string="financial" />
            <token id="7" string="trouble" />
          </tokens>
        </chunking>
        <chunking id="17" string="make some extra money" type="VP">
          <tokens>
            <token id="30" string="make" />
            <token id="31" string="some" />
            <token id="32" string="extra" />
            <token id="33" string="money" />
          </tokens>
        </chunking>
        <chunking id="18" string="some extra money" type="NP">
          <tokens>
            <token id="31" string="some" />
            <token id="32" string="extra" />
            <token id="33" string="money" />
          </tokens>
        </chunking>
        <chunking id="19" string="a fur collar , a ratty little fur collar" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="fur" />
            <token id="14" string="collar" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="ratty" />
            <token id="18" string="little" />
            <token id="19" string="fur" />
            <token id="20" string="collar" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">trouble</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">trouble</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">trouble</governor>
          <dependent id="4">always</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">trouble</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">trouble</governor>
          <dependent id="6">financial</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">trouble</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">wanted</governor>
          <dependent id="9">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">wanted</governor>
          <dependent id="10">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">had</governor>
          <dependent id="11">wanted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">collar</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">collar</governor>
          <dependent id="13">fur</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">wanted</governor>
          <dependent id="14">collar</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">collar</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">collar</governor>
          <dependent id="17">ratty</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">collar</governor>
          <dependent id="18">little</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">collar</governor>
          <dependent id="19">fur</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">collar</governor>
          <dependent id="20">collar</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">had</governor>
          <dependent id="22">she</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">trouble</governor>
          <dependent id="23">had</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">figure</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">had</governor>
          <dependent id="25">figure</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="25">figure</governor>
          <dependent id="26">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">way</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">figure</governor>
          <dependent id="28">way</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">make</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="28">way</governor>
          <dependent id="30">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">money</governor>
          <dependent id="31">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">money</governor>
          <dependent id="32">extra</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">make</governor>
          <dependent id="33">money</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">get</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">had</governor>
          <dependent id="35">get</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">get</governor>
          <dependent id="36">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>God, that&amp;apost;s universal.</content>
      <tokens>
        <token id="1" string="God" lemma="God" stem="god" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="universal" lemma="universal" stem="univers" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP God)) (, ,) (NP (DT that)) (VP (VBZ 's) (ADJP (JJ universal))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="3" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s universal" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="universal" />
          </tokens>
        </chunking>
        <chunking id="3" string="God" type="NP">
          <tokens>
            <token id="1" string="God" />
          </tokens>
        </chunking>
        <chunking id="4" string="universal" type="ADJP">
          <tokens>
            <token id="5" string="universal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">universal</governor>
          <dependent id="1">God</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">universal</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">universal</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">universal</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>And she always had a domineering figure over her. . . .</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="domineering" lemma="domineering" stem="domin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="figure" lemma="figure" stem="figur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (PRP she)) (ADVP (RB always)) (VP (VBD had) (NP (NP (DT a) (JJ domineering) (NN figure)) (PP (IN over) (NP (PRP$ her))))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a domineering figure over her" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="domineering" />
            <token id="7" string="figure" />
            <token id="8" string="over" />
            <token id="9" string="her" />
          </tokens>
        </chunking>
        <chunking id="2" string="her" type="NP">
          <tokens>
            <token id="9" string="her" />
          </tokens>
        </chunking>
        <chunking id="3" string="had a domineering figure over her" type="VP">
          <tokens>
            <token id="4" string="had" />
            <token id="5" string="a" />
            <token id="6" string="domineering" />
            <token id="7" string="figure" />
            <token id="8" string="over" />
            <token id="9" string="her" />
          </tokens>
        </chunking>
        <chunking id="4" string="a domineering figure" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="domineering" />
            <token id="7" string="figure" />
          </tokens>
        </chunking>
        <chunking id="5" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">had</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">had</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">had</governor>
          <dependent id="3">always</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">figure</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">figure</governor>
          <dependent id="6">domineering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">had</governor>
          <dependent id="7">figure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">her</governor>
          <dependent id="8">over</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">figure</governor>
          <dependent id="9">her</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>Lucy was forever knocking somebody&amp;apost;s top hat off.&amp;quot;</content>
      <tokens>
        <token id="1" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="forever" lemma="forever" stem="forev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="knocking" lemma="knock" stem="knock" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="somebody" lemma="somebody" stem="somebodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="top" lemma="top" stem="top" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="hat" lemma="hat" stem="hat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="off" lemma="off" stem="off" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lucy)) (VP (VBD was) (ADVP (RB forever)) (VP (VBG knocking) (NP (NP (NN somebody) (POS 's)) (JJ top) (NN hat)) (ADVP (RB off)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="knocking somebody 's top hat off" type="VP">
          <tokens>
            <token id="4" string="knocking" />
            <token id="5" string="somebody" />
            <token id="6" string="'s" />
            <token id="7" string="top" />
            <token id="8" string="hat" />
            <token id="9" string="off" />
          </tokens>
        </chunking>
        <chunking id="2" string="somebody 's" type="NP">
          <tokens>
            <token id="5" string="somebody" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="was forever knocking somebody 's top hat off" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="forever" />
            <token id="4" string="knocking" />
            <token id="5" string="somebody" />
            <token id="6" string="'s" />
            <token id="7" string="top" />
            <token id="8" string="hat" />
            <token id="9" string="off" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lucy" type="NP">
          <tokens>
            <token id="1" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="5" string="somebody 's top hat" type="NP">
          <tokens>
            <token id="5" string="somebody" />
            <token id="6" string="'s" />
            <token id="7" string="top" />
            <token id="8" string="hat" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">knocking</governor>
          <dependent id="1">Lucy</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">knocking</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">knocking</governor>
          <dependent id="3">forever</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">knocking</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">hat</governor>
          <dependent id="5">somebody</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">somebody</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">hat</governor>
          <dependent id="7">top</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">knocking</governor>
          <dependent id="8">hat</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">knocking</governor>
          <dependent id="9">off</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>Miss Ball&amp;apost;s personal favorite episodes were filmed when she was pregnant with Desi Jr.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="2" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="favorite" lemma="favorite" stem="favorit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="episodes" lemma="episode" stem="episod" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="filmed" lemma="film" stem="film" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="pregnant" lemma="pregnant" stem="pregnant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Desi" lemma="Desi" stem="desi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Jr" lemma="Jr." stem="jr" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (JJ personal) (JJ favorite) (NNS episodes)) (VP (VBD were) (VP (VBN filmed) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD was) (ADJP (JJ pregnant) (PP (IN with) (NP (NNP Desi) (NNP Jr.))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Desi Jr." type="NP">
          <tokens>
            <token id="14" string="Desi" />
            <token id="15" string="Jr" />
          </tokens>
        </chunking>
        <chunking id="2" string="were filmed when she was pregnant with Desi Jr." type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="filmed" />
            <token id="9" string="when" />
            <token id="10" string="she" />
            <token id="11" string="was" />
            <token id="12" string="pregnant" />
            <token id="13" string="with" />
            <token id="14" string="Desi" />
            <token id="15" string="Jr" />
          </tokens>
        </chunking>
        <chunking id="3" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="filmed when she was pregnant with Desi Jr." type="VP">
          <tokens>
            <token id="8" string="filmed" />
            <token id="9" string="when" />
            <token id="10" string="she" />
            <token id="11" string="was" />
            <token id="12" string="pregnant" />
            <token id="13" string="with" />
            <token id="14" string="Desi" />
            <token id="15" string="Jr" />
          </tokens>
        </chunking>
        <chunking id="5" string="when she was pregnant with Desi Jr." type="SBAR">
          <tokens>
            <token id="9" string="when" />
            <token id="10" string="she" />
            <token id="11" string="was" />
            <token id="12" string="pregnant" />
            <token id="13" string="with" />
            <token id="14" string="Desi" />
            <token id="15" string="Jr" />
          </tokens>
        </chunking>
        <chunking id="6" string="was pregnant with Desi Jr." type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="pregnant" />
            <token id="13" string="with" />
            <token id="14" string="Desi" />
            <token id="15" string="Jr" />
          </tokens>
        </chunking>
        <chunking id="7" string="pregnant with Desi Jr." type="ADJP">
          <tokens>
            <token id="12" string="pregnant" />
            <token id="13" string="with" />
            <token id="14" string="Desi" />
            <token id="15" string="Jr" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="9" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="10" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="Miss Ball 's personal favorite episodes" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
            <token id="3" string="'s" />
            <token id="4" string="personal" />
            <token id="5" string="favorite" />
            <token id="6" string="episodes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ball</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">episodes</governor>
          <dependent id="2">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Ball</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">episodes</governor>
          <dependent id="4">personal</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">episodes</governor>
          <dependent id="5">favorite</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">filmed</governor>
          <dependent id="6">episodes</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">filmed</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">filmed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">pregnant</governor>
          <dependent id="9">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">pregnant</governor>
          <dependent id="10">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">pregnant</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">filmed</governor>
          <dependent id="12">pregnant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Jr.</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Jr.</governor>
          <dependent id="14">Desi</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">pregnant</governor>
          <dependent id="15">Jr.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Desi Jr" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Desi" />
            <token id="15" string="Jr" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>An amazing 44 million viewers, 90% of the television audience, gleefully watched on Jan. 19, 1953, when she gave birth on film to the show&amp;apost;s little Ricky.</content>
      <tokens>
        <token id="1" string="An" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="amazing" lemma="amazing" stem="amaz" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="44" lemma="44" stem="44" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="viewers" lemma="viewer" stem="viewer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="90" lemma="90" stem="90" pos="CD" type="Number" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="8" string="%" lemma="%" stem="%" pos="NN" type="Symbol" isStopWord="true" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="audience" lemma="audience" stem="audienc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="gleefully" lemma="gleefully" stem="gleefulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="watched" lemma="watch" stem="watch" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="19" lemma="19" stem="19" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="1953" lemma="1953" stem="1953" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="birth" lemma="birth" stem="birth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="31" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="32" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="Ricky" lemma="Ricky" stem="ricki" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT An) (JJ amazing) (QP (CD 44) (CD million)) (NNS viewers)) (, ,) (NP (NP (CD 90) (NN %)) (PP (IN of) (NP (DT the) (NN television) (NN audience)))) (, ,)) (VP (ADVP (RB gleefully)) (VBN watched) (PP (IN on) (NP (NP (NNP Jan.) (CD 19) (, ,) (CD 1953)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD gave) (NP (NN birth)) (PP (IN on) (NP (NN film))) (PP (TO to) (NP (NP (DT the) (NN show) (POS 's)) (JJ little) (NNP Ricky))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="90 %" type="NP">
          <tokens>
            <token id="7" string="90" />
            <token id="8" string="%" />
          </tokens>
        </chunking>
        <chunking id="2" string="An amazing 44 million viewers , 90 % of the television audience ," type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="amazing" />
            <token id="3" string="44" />
            <token id="4" string="million" />
            <token id="5" string="viewers" />
            <token id="6" string="," />
            <token id="7" string="90" />
            <token id="8" string="%" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="television" />
            <token id="12" string="audience" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="gleefully watched on Jan. 19 , 1953 , when she gave birth on film to the show 's little Ricky" type="VP">
          <tokens>
            <token id="14" string="gleefully" />
            <token id="15" string="watched" />
            <token id="16" string="on" />
            <token id="17" string="Jan." />
            <token id="18" string="19" />
            <token id="19" string="," />
            <token id="20" string="1953" />
            <token id="21" string="," />
            <token id="22" string="when" />
            <token id="23" string="she" />
            <token id="24" string="gave" />
            <token id="25" string="birth" />
            <token id="26" string="on" />
            <token id="27" string="film" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="show" />
            <token id="31" string="'s" />
            <token id="32" string="little" />
            <token id="33" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="4" string="birth" type="NP">
          <tokens>
            <token id="25" string="birth" />
          </tokens>
        </chunking>
        <chunking id="5" string="film" type="NP">
          <tokens>
            <token id="27" string="film" />
          </tokens>
        </chunking>
        <chunking id="6" string="the show 's" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="show" />
            <token id="31" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="22" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="23" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="90 % of the television audience" type="NP">
          <tokens>
            <token id="7" string="90" />
            <token id="8" string="%" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="television" />
            <token id="12" string="audience" />
          </tokens>
        </chunking>
        <chunking id="10" string="Jan. 19 , 1953 , when she gave birth on film to the show 's little Ricky" type="NP">
          <tokens>
            <token id="17" string="Jan." />
            <token id="18" string="19" />
            <token id="19" string="," />
            <token id="20" string="1953" />
            <token id="21" string="," />
            <token id="22" string="when" />
            <token id="23" string="she" />
            <token id="24" string="gave" />
            <token id="25" string="birth" />
            <token id="26" string="on" />
            <token id="27" string="film" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="show" />
            <token id="31" string="'s" />
            <token id="32" string="little" />
            <token id="33" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="11" string="Jan. 19 , 1953" type="NP">
          <tokens>
            <token id="17" string="Jan." />
            <token id="18" string="19" />
            <token id="19" string="," />
            <token id="20" string="1953" />
          </tokens>
        </chunking>
        <chunking id="12" string="when she gave birth on film to the show 's little Ricky" type="SBAR">
          <tokens>
            <token id="22" string="when" />
            <token id="23" string="she" />
            <token id="24" string="gave" />
            <token id="25" string="birth" />
            <token id="26" string="on" />
            <token id="27" string="film" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="show" />
            <token id="31" string="'s" />
            <token id="32" string="little" />
            <token id="33" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="13" string="the show 's little Ricky" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="show" />
            <token id="31" string="'s" />
            <token id="32" string="little" />
            <token id="33" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="14" string="the television audience" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="television" />
            <token id="12" string="audience" />
          </tokens>
        </chunking>
        <chunking id="15" string="An amazing 44 million viewers" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="amazing" />
            <token id="3" string="44" />
            <token id="4" string="million" />
            <token id="5" string="viewers" />
          </tokens>
        </chunking>
        <chunking id="16" string="gave birth on film to the show 's little Ricky" type="VP">
          <tokens>
            <token id="24" string="gave" />
            <token id="25" string="birth" />
            <token id="26" string="on" />
            <token id="27" string="film" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="show" />
            <token id="31" string="'s" />
            <token id="32" string="little" />
            <token id="33" string="Ricky" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">viewers</governor>
          <dependent id="1">An</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">viewers</governor>
          <dependent id="2">amazing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">million</governor>
          <dependent id="3">44</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">viewers</governor>
          <dependent id="4">million</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">watched</governor>
          <dependent id="5">viewers</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">%</governor>
          <dependent id="7">90</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">viewers</governor>
          <dependent id="8">%</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">audience</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">audience</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">audience</governor>
          <dependent id="11">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">%</governor>
          <dependent id="12">audience</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">watched</governor>
          <dependent id="14">gleefully</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">watched</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Jan.</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">watched</governor>
          <dependent id="17">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">Jan.</governor>
          <dependent id="18">19</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">Jan.</governor>
          <dependent id="20">1953</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">gave</governor>
          <dependent id="22">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">gave</governor>
          <dependent id="23">she</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">Jan.</governor>
          <dependent id="24">gave</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">gave</governor>
          <dependent id="25">birth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">film</governor>
          <dependent id="26">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">gave</governor>
          <dependent id="27">film</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Ricky</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">show</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">Ricky</governor>
          <dependent id="30">show</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">show</governor>
          <dependent id="31">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">Ricky</governor>
          <dependent id="32">little</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">gave</governor>
          <dependent id="33">Ricky</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="90 %" type="PERCENT" score="0.0">
          <tokens>
            <token id="7" string="90" />
            <token id="8" string="%" />
          </tokens>
        </entity>
        <entity id="2" string="44 million" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="44" />
            <token id="4" string="million" />
          </tokens>
        </entity>
        <entity id="3" string="Jan. 19 , 1953" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="Jan." />
            <token id="18" string="19" />
            <token id="19" string="," />
            <token id="20" string="1953" />
          </tokens>
        </entity>
        <entity id="4" string="Ricky" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Ricky" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>To the unabashed delight of a nation, it was the same night she had given birth in real life.</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="unabashed" lemma="unabashed" stem="unabash" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="delight" lemma="delight" stem="delight" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="night" lemma="night" stem="night" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="14" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="birth" lemma="birth" stem="birth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (TO To) (NP (NP (DT the) (JJ unabashed) (NN delight)) (PP (IN of) (NP (DT a) (NN nation))))) (, ,) (NP (PRP it)) (VP (VBD was) (NP (NP (DT the) (JJ same) (NN night)) (SBAR (S (NP (PRP she)) (VP (VBD had) (VP (VBN given) (NP (NP (NN birth)) (PP (IN in) (NP (JJ real) (NN life)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the unabashed delight of a nation" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="unabashed" />
            <token id="4" string="delight" />
            <token id="5" string="of" />
            <token id="6" string="a" />
            <token id="7" string="nation" />
          </tokens>
        </chunking>
        <chunking id="2" string="had given birth in real life" type="VP">
          <tokens>
            <token id="15" string="had" />
            <token id="16" string="given" />
            <token id="17" string="birth" />
            <token id="18" string="in" />
            <token id="19" string="real" />
            <token id="20" string="life" />
          </tokens>
        </chunking>
        <chunking id="3" string="birth" type="NP">
          <tokens>
            <token id="17" string="birth" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="the same night" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="same" />
            <token id="13" string="night" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="14" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="given birth in real life" type="VP">
          <tokens>
            <token id="16" string="given" />
            <token id="17" string="birth" />
            <token id="18" string="in" />
            <token id="19" string="real" />
            <token id="20" string="life" />
          </tokens>
        </chunking>
        <chunking id="8" string="real life" type="NP">
          <tokens>
            <token id="19" string="real" />
            <token id="20" string="life" />
          </tokens>
        </chunking>
        <chunking id="9" string="the same night she had given birth in real life" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="same" />
            <token id="13" string="night" />
            <token id="14" string="she" />
            <token id="15" string="had" />
            <token id="16" string="given" />
            <token id="17" string="birth" />
            <token id="18" string="in" />
            <token id="19" string="real" />
            <token id="20" string="life" />
          </tokens>
        </chunking>
        <chunking id="10" string="she had given birth in real life" type="SBAR">
          <tokens>
            <token id="14" string="she" />
            <token id="15" string="had" />
            <token id="16" string="given" />
            <token id="17" string="birth" />
            <token id="18" string="in" />
            <token id="19" string="real" />
            <token id="20" string="life" />
          </tokens>
        </chunking>
        <chunking id="11" string="was the same night she had given birth in real life" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="the" />
            <token id="12" string="same" />
            <token id="13" string="night" />
            <token id="14" string="she" />
            <token id="15" string="had" />
            <token id="16" string="given" />
            <token id="17" string="birth" />
            <token id="18" string="in" />
            <token id="19" string="real" />
            <token id="20" string="life" />
          </tokens>
        </chunking>
        <chunking id="12" string="a nation" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="nation" />
          </tokens>
        </chunking>
        <chunking id="13" string="birth in real life" type="NP">
          <tokens>
            <token id="17" string="birth" />
            <token id="18" string="in" />
            <token id="19" string="real" />
            <token id="20" string="life" />
          </tokens>
        </chunking>
        <chunking id="14" string="the unabashed delight" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="unabashed" />
            <token id="4" string="delight" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">delight</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">delight</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">delight</governor>
          <dependent id="3">unabashed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">night</governor>
          <dependent id="4">delight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">nation</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">nation</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">delight</governor>
          <dependent id="7">nation</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">night</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">night</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">night</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">night</governor>
          <dependent id="12">same</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">night</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">given</governor>
          <dependent id="14">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">given</governor>
          <dependent id="15">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">night</governor>
          <dependent id="16">given</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">given</governor>
          <dependent id="17">birth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">life</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">life</governor>
          <dependent id="19">real</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">birth</governor>
          <dependent id="20">life</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="night" type="TIME" score="0.0">
          <tokens>
            <token id="13" string="night" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>&amp;quot;I was so damned happy -- just floating on a cloud -- and I think the way I felt came across on the film,&amp;quot; she said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="damned" lemma="damned" stem="damn" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="happy" lemma="happy" stem="happi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="floating" lemma="float" stem="float" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="cloud" lemma="cloud" stem="cloud" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="across" lemma="across" stem="across" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP I)) (VP (VBD was) (ADJP (RB so) (RB damned) (JJ happy)) (PRN (: --) (NP (NP (RB just) (VBG floating)) (PP (IN on) (NP (DT a) (NN cloud)))) (: --)))) (CC and) (S (NP (PRP I)) (VP (VBP think) (NP (NP (DT the) (NN way)) (SBAR (S (NP (PRP I)) (VP (VBD felt) (SBAR (S (VP (VBD came) (PP (IN across) (PP (IN on) (NP (DT the) (NN film)))))))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was so damned happy -- just floating on a cloud --" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="so" />
            <token id="5" string="damned" />
            <token id="6" string="happy" />
            <token id="7" string="--" />
            <token id="8" string="just" />
            <token id="9" string="floating" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="cloud" />
            <token id="13" string="--" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="a cloud" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="cloud" />
          </tokens>
        </chunking>
        <chunking id="4" string="think the way I felt came across on the film" type="VP">
          <tokens>
            <token id="16" string="think" />
            <token id="17" string="the" />
            <token id="18" string="way" />
            <token id="19" string="I" />
            <token id="20" string="felt" />
            <token id="21" string="came" />
            <token id="22" string="across" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="film" />
          </tokens>
        </chunking>
        <chunking id="5" string="just floating" type="NP">
          <tokens>
            <token id="8" string="just" />
            <token id="9" string="floating" />
          </tokens>
        </chunking>
        <chunking id="6" string="the way I felt came across on the film" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="way" />
            <token id="19" string="I" />
            <token id="20" string="felt" />
            <token id="21" string="came" />
            <token id="22" string="across" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="film" />
          </tokens>
        </chunking>
        <chunking id="7" string="the film" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="film" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="28" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="felt came across on the film" type="VP">
          <tokens>
            <token id="20" string="felt" />
            <token id="21" string="came" />
            <token id="22" string="across" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="film" />
          </tokens>
        </chunking>
        <chunking id="10" string="just floating on a cloud" type="NP">
          <tokens>
            <token id="8" string="just" />
            <token id="9" string="floating" />
            <token id="10" string="on" />
            <token id="11" string="a" />
            <token id="12" string="cloud" />
          </tokens>
        </chunking>
        <chunking id="11" string="the way" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="way" />
          </tokens>
        </chunking>
        <chunking id="12" string="came across on the film" type="SBAR">
          <tokens>
            <token id="21" string="came" />
            <token id="22" string="across" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="film" />
          </tokens>
        </chunking>
        <chunking id="13" string="I felt came across on the film" type="SBAR">
          <tokens>
            <token id="19" string="I" />
            <token id="20" string="felt" />
            <token id="21" string="came" />
            <token id="22" string="across" />
            <token id="23" string="on" />
            <token id="24" string="the" />
            <token id="25" string="film" />
          </tokens>
        </chunking>
        <chunking id="14" string="so damned happy" type="ADJP">
          <tokens>
            <token id="4" string="so" />
            <token id="5" string="damned" />
            <token id="6" string="happy" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="29" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">happy</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">happy</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">happy</governor>
          <dependent id="4">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">happy</governor>
          <dependent id="5">damned</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="6">happy</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">happy</governor>
          <dependent id="8">just</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">just</governor>
          <dependent id="9">floating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">cloud</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">cloud</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">just</governor>
          <dependent id="12">cloud</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">happy</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">think</governor>
          <dependent id="15">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">happy</governor>
          <dependent id="16">think</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">way</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">think</governor>
          <dependent id="18">way</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">felt</governor>
          <dependent id="19">I</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">way</governor>
          <dependent id="20">felt</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">felt</governor>
          <dependent id="21">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">film</governor>
          <dependent id="22">across</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">film</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">film</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">came</governor>
          <dependent id="25">film</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="28">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>&amp;quot;I loved doing all those pregnant shows.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="loved" lemma="love" stem="love" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="pregnant" lemma="pregnant" stem="pregnant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="shows" lemma="show" stem="show" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD loved) (S (VP (VBG doing) (NP (PDT all) (DT those) (JJ pregnant) (NNS shows))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="all those pregnant shows" type="NP">
          <tokens>
            <token id="5" string="all" />
            <token id="6" string="those" />
            <token id="7" string="pregnant" />
            <token id="8" string="shows" />
          </tokens>
        </chunking>
        <chunking id="2" string="loved doing all those pregnant shows" type="VP">
          <tokens>
            <token id="3" string="loved" />
            <token id="4" string="doing" />
            <token id="5" string="all" />
            <token id="6" string="those" />
            <token id="7" string="pregnant" />
            <token id="8" string="shows" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="doing all those pregnant shows" type="VP">
          <tokens>
            <token id="4" string="doing" />
            <token id="5" string="all" />
            <token id="6" string="those" />
            <token id="7" string="pregnant" />
            <token id="8" string="shows" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">loved</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">loved</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">loved</governor>
          <dependent id="4">doing</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="8">shows</governor>
          <dependent id="5">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">shows</governor>
          <dependent id="6">those</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">shows</governor>
          <dependent id="7">pregnant</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">doing</governor>
          <dependent id="8">shows</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>Astoundingly, or so it seems in retrospect, early reviews of Miss Ball&amp;apost;s talents gave little hint of what was to come.</content>
      <tokens>
        <token id="1" string="Astoundingly" lemma="astoundingly" stem="astoundingli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="retrospect" lemma="retrospect" stem="retrospect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="reviews" lemma="review" stem="review" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="14" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="talents" lemma="talent" stem="talent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="hint" lemma="hint" stem="hint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Astoundingly)) (PRN (, ,) (CC or) (S (ADVP (IN so)) (NP (PRP it)) (VP (VBZ seems) (PP (IN in) (NP (NN retrospect))))) (, ,)) (NP (NP (JJ early) (NNS reviews)) (PP (IN of) (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (NNS talents)))) (VP (VBD gave) (NP (NP (JJ little) (NN hint)) (PP (IN of) (SBAR (WHNP (WP what)) (S (VP (VBD was) (S (VP (TO to) (VP (VB come)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="early reviews of Miss Ball 's talents" type="NP">
          <tokens>
            <token id="10" string="early" />
            <token id="11" string="reviews" />
            <token id="12" string="of" />
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
            <token id="16" string="talents" />
          </tokens>
        </chunking>
        <chunking id="2" string="little hint" type="NP">
          <tokens>
            <token id="18" string="little" />
            <token id="19" string="hint" />
          </tokens>
        </chunking>
        <chunking id="3" string="was to come" type="VP">
          <tokens>
            <token id="22" string="was" />
            <token id="23" string="to" />
            <token id="24" string="come" />
          </tokens>
        </chunking>
        <chunking id="4" string="to come" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="come" />
          </tokens>
        </chunking>
        <chunking id="5" string="gave little hint of what was to come" type="VP">
          <tokens>
            <token id="17" string="gave" />
            <token id="18" string="little" />
            <token id="19" string="hint" />
            <token id="20" string="of" />
            <token id="21" string="what" />
            <token id="22" string="was" />
            <token id="23" string="to" />
            <token id="24" string="come" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="little hint of what was to come" type="NP">
          <tokens>
            <token id="18" string="little" />
            <token id="19" string="hint" />
            <token id="20" string="of" />
            <token id="21" string="what" />
            <token id="22" string="was" />
            <token id="23" string="to" />
            <token id="24" string="come" />
          </tokens>
        </chunking>
        <chunking id="9" string="come" type="VP">
          <tokens>
            <token id="24" string="come" />
          </tokens>
        </chunking>
        <chunking id="10" string="seems in retrospect" type="VP">
          <tokens>
            <token id="6" string="seems" />
            <token id="7" string="in" />
            <token id="8" string="retrospect" />
          </tokens>
        </chunking>
        <chunking id="11" string="retrospect" type="NP">
          <tokens>
            <token id="8" string="retrospect" />
          </tokens>
        </chunking>
        <chunking id="12" string="Miss Ball 's talents" type="NP">
          <tokens>
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
            <token id="15" string="'s" />
            <token id="16" string="talents" />
          </tokens>
        </chunking>
        <chunking id="13" string="what was to come" type="SBAR">
          <tokens>
            <token id="21" string="what" />
            <token id="22" string="was" />
            <token id="23" string="to" />
            <token id="24" string="come" />
          </tokens>
        </chunking>
        <chunking id="14" string="early reviews" type="NP">
          <tokens>
            <token id="10" string="early" />
            <token id="11" string="reviews" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="17">gave</governor>
          <dependent id="1">Astoundingly</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">seems</governor>
          <dependent id="3">or</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">seems</governor>
          <dependent id="4">so</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">seems</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="17">gave</governor>
          <dependent id="6">seems</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">retrospect</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">seems</governor>
          <dependent id="8">retrospect</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">reviews</governor>
          <dependent id="10">early</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">gave</governor>
          <dependent id="11">reviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">talents</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Ball</governor>
          <dependent id="13">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">talents</governor>
          <dependent id="14">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Ball</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">reviews</governor>
          <dependent id="16">talents</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">gave</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">hint</governor>
          <dependent id="18">little</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">gave</governor>
          <dependent id="19">hint</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">was</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">was</governor>
          <dependent id="21">what</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="19">hint</governor>
          <dependent id="22">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">come</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">was</governor>
          <dependent id="24">come</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Miss Ball" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Miss" />
            <token id="14" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>In fact, when she was a plucky 15-year-old looking for that first break on Broadway, Miss Ball was told by a drama teacher to give up.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="plucky" lemma="plucky" stem="plucki" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="15-year-old" lemma="15-year-old" stem="15-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="looking" lemma="look" stem="look" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="14" string="break" lemma="break" stem="break" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Broadway" lemma="Broadway" stem="broadwai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="told" lemma="tell" stem="told" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="drama" lemma="drama" stem="drama" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="teacher" lemma="teacher" stem="teacher" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NN fact))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD was) (ADJP (DT a) (JJ plucky) (JJ 15-year-old)) (S (VP (VBG looking) (PP (IN for) (NP (NP (DT that) (JJ first) (NN break)) (PP (IN on) (NP (NNP Broadway)))))))))) (, ,) (NP (NNP Miss) (NNP Ball)) (VP (VBD was) (VP (VBN told) (PP (IN by) (NP (DT a) (NN drama) (NN teacher))) (S (VP (TO to) (VP (VB give) (PRT (RP up))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fact" type="NP">
          <tokens>
            <token id="2" string="fact" />
          </tokens>
        </chunking>
        <chunking id="2" string="was a plucky 15-year-old looking for that first break on Broadway" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="a" />
            <token id="8" string="plucky" />
            <token id="9" string="15-year-old" />
            <token id="10" string="looking" />
            <token id="11" string="for" />
            <token id="12" string="that" />
            <token id="13" string="first" />
            <token id="14" string="break" />
            <token id="15" string="on" />
            <token id="16" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="3" string="Broadway" type="NP">
          <tokens>
            <token id="16" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="4" string="that first break on Broadway" type="NP">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="first" />
            <token id="14" string="break" />
            <token id="15" string="on" />
            <token id="16" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="5" string="a plucky 15-year-old" type="ADJP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="plucky" />
            <token id="9" string="15-year-old" />
          </tokens>
        </chunking>
        <chunking id="6" string="when" type="WHADVP">
          <tokens>
            <token id="4" string="when" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="looking for that first break on Broadway" type="VP">
          <tokens>
            <token id="10" string="looking" />
            <token id="11" string="for" />
            <token id="12" string="that" />
            <token id="13" string="first" />
            <token id="14" string="break" />
            <token id="15" string="on" />
            <token id="16" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="9" string="was told by a drama teacher to give up" type="VP">
          <tokens>
            <token id="20" string="was" />
            <token id="21" string="told" />
            <token id="22" string="by" />
            <token id="23" string="a" />
            <token id="24" string="drama" />
            <token id="25" string="teacher" />
            <token id="26" string="to" />
            <token id="27" string="give" />
            <token id="28" string="up" />
          </tokens>
        </chunking>
        <chunking id="10" string="a drama teacher" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="drama" />
            <token id="25" string="teacher" />
          </tokens>
        </chunking>
        <chunking id="11" string="to give up" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="give" />
            <token id="28" string="up" />
          </tokens>
        </chunking>
        <chunking id="12" string="give up" type="VP">
          <tokens>
            <token id="27" string="give" />
            <token id="28" string="up" />
          </tokens>
        </chunking>
        <chunking id="13" string="that first break" type="NP">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="first" />
            <token id="14" string="break" />
          </tokens>
        </chunking>
        <chunking id="14" string="told by a drama teacher to give up" type="VP">
          <tokens>
            <token id="21" string="told" />
            <token id="22" string="by" />
            <token id="23" string="a" />
            <token id="24" string="drama" />
            <token id="25" string="teacher" />
            <token id="26" string="to" />
            <token id="27" string="give" />
            <token id="28" string="up" />
          </tokens>
        </chunking>
        <chunking id="15" string="when she was a plucky 15-year-old looking for that first break on Broadway" type="SBAR">
          <tokens>
            <token id="4" string="when" />
            <token id="5" string="she" />
            <token id="6" string="was" />
            <token id="7" string="a" />
            <token id="8" string="plucky" />
            <token id="9" string="15-year-old" />
            <token id="10" string="looking" />
            <token id="11" string="for" />
            <token id="12" string="that" />
            <token id="13" string="first" />
            <token id="14" string="break" />
            <token id="15" string="on" />
            <token id="16" string="Broadway" />
          </tokens>
        </chunking>
        <chunking id="16" string="Miss Ball" type="NP">
          <tokens>
            <token id="18" string="Miss" />
            <token id="19" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">fact</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">told</governor>
          <dependent id="2">fact</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">15-year-old</governor>
          <dependent id="4">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">15-year-old</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">15-year-old</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">15-year-old</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">15-year-old</governor>
          <dependent id="8">plucky</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">told</governor>
          <dependent id="9">15-year-old</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">15-year-old</governor>
          <dependent id="10">looking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">break</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">break</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">break</governor>
          <dependent id="13">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">looking</governor>
          <dependent id="14">break</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Broadway</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">break</governor>
          <dependent id="16">Broadway</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Ball</governor>
          <dependent id="18">Miss</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">told</governor>
          <dependent id="19">Ball</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">told</governor>
          <dependent id="20">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">told</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">teacher</governor>
          <dependent id="22">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">teacher</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">teacher</governor>
          <dependent id="24">drama</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">told</governor>
          <dependent id="25">teacher</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">give</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">told</governor>
          <dependent id="27">give</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="27">give</governor>
          <dependent id="28">up</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="13" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="15-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="15-year-old" />
          </tokens>
        </entity>
        <entity id="3" string="Broadway" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Broadway" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="59" has_coreference="false">
      <content>Luckily, the turquoise-eyed teen-ager ignored the advice.</content>
      <tokens>
        <token id="1" string="Luckily" lemma="luckily" stem="luckili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="turquoise-eyed" lemma="turquoise-eyed" stem="turquoise-ei" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="teen-ager" lemma="teen-ager" stem="teen-ag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="ignored" lemma="ignore" stem="ignor" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="advice" lemma="advice" stem="advic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Luckily)) (, ,) (NP (DT the) (JJ turquoise-eyed) (NN teen-ager)) (VP (VBD ignored) (NP (DT the) (NN advice))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the advice" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="advice" />
          </tokens>
        </chunking>
        <chunking id="2" string="ignored the advice" type="VP">
          <tokens>
            <token id="6" string="ignored" />
            <token id="7" string="the" />
            <token id="8" string="advice" />
          </tokens>
        </chunking>
        <chunking id="3" string="the turquoise-eyed teen-ager" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="turquoise-eyed" />
            <token id="5" string="teen-ager" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">ignored</governor>
          <dependent id="1">Luckily</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">teen-ager</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">teen-ager</governor>
          <dependent id="4">turquoise-eyed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">ignored</governor>
          <dependent id="5">teen-ager</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">ignored</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">advice</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">ignored</governor>
          <dependent id="8">advice</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="60" has_coreference="true">
      <content>Born to an electrician father and pianist mother on Aug. 6, 1911, in a suburb of Jamestown, N.Y., Miss Ball had set her sights on stardom almost from the first.</content>
      <tokens>
        <token id="1" string="Born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="electrician" lemma="electrician" stem="electrician" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="pianist" lemma="pianist" stem="pianist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Aug." lemma="Aug." stem="aug." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="6" lemma="6" stem="6" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="1911" lemma="1911" stem="1911" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="suburb" lemma="suburb" stem="suburb" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Jamestown" lemma="Jamestown" stem="jamestown" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="N.Y." lemma="N.Y." stem="n.y." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="24" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="25" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="set" lemma="set" stem="set" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="sights" lemma="sight" stem="sight" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="stardom" lemma="stardom" stem="stardom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Born) (PP (TO to) (NP (DT an) (NN electrician) (NN father) (CC and) (NN pianist) (NN mother))) (PP (IN on) (NP (NP (NNP Aug.) (CD 6) (, ,) (CD 1911) (, ,)) (PP (IN in) (NP (NP (DT a) (NN suburb)) (PP (IN of) (NP (NNP Jamestown) (, ,) (NNP N.Y.))))))))) (, ,) (NP (NNP Miss) (NNP Ball)) (VP (VBD had) (VP (VBN set) (NP (PRP$ her) (NNS sights)) (PP (IN on) (NP (NP (NN stardom) (RB almost)) (PP (IN from) (NP (DT the) (JJ first))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Born to an electrician father and pianist mother on Aug. 6 , 1911 , in a suburb of Jamestown , N.Y." type="VP">
          <tokens>
            <token id="1" string="Born" />
            <token id="2" string="to" />
            <token id="3" string="an" />
            <token id="4" string="electrician" />
            <token id="5" string="father" />
            <token id="6" string="and" />
            <token id="7" string="pianist" />
            <token id="8" string="mother" />
            <token id="9" string="on" />
            <token id="10" string="Aug." />
            <token id="11" string="6" />
            <token id="12" string="," />
            <token id="13" string="1911" />
            <token id="14" string="," />
            <token id="15" string="in" />
            <token id="16" string="a" />
            <token id="17" string="suburb" />
            <token id="18" string="of" />
            <token id="19" string="Jamestown" />
            <token id="20" string="," />
            <token id="21" string="N.Y." />
          </tokens>
        </chunking>
        <chunking id="2" string="an electrician father and pianist mother" type="NP">
          <tokens>
            <token id="3" string="an" />
            <token id="4" string="electrician" />
            <token id="5" string="father" />
            <token id="6" string="and" />
            <token id="7" string="pianist" />
            <token id="8" string="mother" />
          </tokens>
        </chunking>
        <chunking id="3" string="stardom almost" type="NP">
          <tokens>
            <token id="30" string="stardom" />
            <token id="31" string="almost" />
          </tokens>
        </chunking>
        <chunking id="4" string="set her sights on stardom almost from the first" type="VP">
          <tokens>
            <token id="26" string="set" />
            <token id="27" string="her" />
            <token id="28" string="sights" />
            <token id="29" string="on" />
            <token id="30" string="stardom" />
            <token id="31" string="almost" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="first" />
          </tokens>
        </chunking>
        <chunking id="5" string="stardom almost from the first" type="NP">
          <tokens>
            <token id="30" string="stardom" />
            <token id="31" string="almost" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="first" />
          </tokens>
        </chunking>
        <chunking id="6" string="had set her sights on stardom almost from the first" type="VP">
          <tokens>
            <token id="25" string="had" />
            <token id="26" string="set" />
            <token id="27" string="her" />
            <token id="28" string="sights" />
            <token id="29" string="on" />
            <token id="30" string="stardom" />
            <token id="31" string="almost" />
            <token id="32" string="from" />
            <token id="33" string="the" />
            <token id="34" string="first" />
          </tokens>
        </chunking>
        <chunking id="7" string="a suburb" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="suburb" />
          </tokens>
        </chunking>
        <chunking id="8" string="a suburb of Jamestown , N.Y." type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="suburb" />
            <token id="18" string="of" />
            <token id="19" string="Jamestown" />
            <token id="20" string="," />
            <token id="21" string="N.Y." />
          </tokens>
        </chunking>
        <chunking id="9" string="her sights" type="NP">
          <tokens>
            <token id="27" string="her" />
            <token id="28" string="sights" />
          </tokens>
        </chunking>
        <chunking id="10" string="Aug. 6 , 1911 , in a suburb of Jamestown , N.Y." type="NP">
          <tokens>
            <token id="10" string="Aug." />
            <token id="11" string="6" />
            <token id="12" string="," />
            <token id="13" string="1911" />
            <token id="14" string="," />
            <token id="15" string="in" />
            <token id="16" string="a" />
            <token id="17" string="suburb" />
            <token id="18" string="of" />
            <token id="19" string="Jamestown" />
            <token id="20" string="," />
            <token id="21" string="N.Y." />
          </tokens>
        </chunking>
        <chunking id="11" string="Jamestown , N.Y." type="NP">
          <tokens>
            <token id="19" string="Jamestown" />
            <token id="20" string="," />
            <token id="21" string="N.Y." />
          </tokens>
        </chunking>
        <chunking id="12" string="the first" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="first" />
          </tokens>
        </chunking>
        <chunking id="13" string="Aug. 6 , 1911 ," type="NP">
          <tokens>
            <token id="10" string="Aug." />
            <token id="11" string="6" />
            <token id="12" string="," />
            <token id="13" string="1911" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="Miss Ball" type="NP">
          <tokens>
            <token id="23" string="Miss" />
            <token id="24" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="26">set</governor>
          <dependent id="1">Born</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">father</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">father</governor>
          <dependent id="3">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">father</governor>
          <dependent id="4">electrician</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Born</governor>
          <dependent id="5">father</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">father</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">mother</governor>
          <dependent id="7">pianist</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">father</governor>
          <dependent id="8">mother</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Aug.</governor>
          <dependent id="9">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Born</governor>
          <dependent id="10">Aug.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">Aug.</governor>
          <dependent id="11">6</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">Aug.</governor>
          <dependent id="13">1911</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">suburb</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">suburb</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Aug.</governor>
          <dependent id="17">suburb</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">N.Y.</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">N.Y.</governor>
          <dependent id="19">Jamestown</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">suburb</governor>
          <dependent id="21">N.Y.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Ball</governor>
          <dependent id="23">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">set</governor>
          <dependent id="24">Ball</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">set</governor>
          <dependent id="25">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">set</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">sights</governor>
          <dependent id="27">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">set</governor>
          <dependent id="28">sights</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">stardom</governor>
          <dependent id="29">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">set</governor>
          <dependent id="30">stardom</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">stardom</governor>
          <dependent id="31">almost</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">first</governor>
          <dependent id="32">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">first</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">stardom</governor>
          <dependent id="34">first</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jamestown" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Jamestown" />
          </tokens>
        </entity>
        <entity id="2" string="N.Y." type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="N.Y." />
          </tokens>
        </entity>
        <entity id="3" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="34" string="first" />
          </tokens>
        </entity>
        <entity id="4" string="Aug. 6 , 1911" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="Aug." />
            <token id="11" string="6" />
            <token id="12" string="," />
            <token id="13" string="1911" />
          </tokens>
        </entity>
        <entity id="5" string="Miss Ball" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Miss" />
            <token id="24" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="61" has_coreference="true">
      <content>By 5, the brown-haired little girl was taking music lessons.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="5" lemma="5" stem="5" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="brown-haired" lemma="brown-haired" stem="brown-hair" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="girl" lemma="girl" stem="girl" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="lessons" lemma="lesson" stem="lesson" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (CD 5))) (, ,) (NP (DT the) (JJ brown-haired) (JJ little) (NN girl)) (VP (VBD was) (VP (VBG taking) (NP (NN music) (NNS lessons)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="5" type="NP">
          <tokens>
            <token id="2" string="5" />
          </tokens>
        </chunking>
        <chunking id="2" string="music lessons" type="NP">
          <tokens>
            <token id="10" string="music" />
            <token id="11" string="lessons" />
          </tokens>
        </chunking>
        <chunking id="3" string="taking music lessons" type="VP">
          <tokens>
            <token id="9" string="taking" />
            <token id="10" string="music" />
            <token id="11" string="lessons" />
          </tokens>
        </chunking>
        <chunking id="4" string="the brown-haired little girl" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="brown-haired" />
            <token id="6" string="little" />
            <token id="7" string="girl" />
          </tokens>
        </chunking>
        <chunking id="5" string="was taking music lessons" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="taking" />
            <token id="10" string="music" />
            <token id="11" string="lessons" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">5</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">taking</governor>
          <dependent id="2">5</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">girl</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">girl</governor>
          <dependent id="5">brown-haired</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">girl</governor>
          <dependent id="6">little</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">taking</governor>
          <dependent id="7">girl</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">taking</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">taking</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">lessons</governor>
          <dependent id="10">music</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">taking</governor>
          <dependent id="11">lessons</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="5" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="5" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="62" has_coreference="true">
      <content>Each spring that followed she would head toward New York City, walking until someone found her and returned her to her home.</content>
      <tokens>
        <token id="1" string="Each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" ner="SET" is_referenced="false" is_refers="false" />
        <token id="2" string="spring" lemma="spring" stem="spring" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="followed" lemma="follow" stem="follow" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="head" lemma="head" stem="head" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="walking" lemma="walk" stem="walk" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="returned" lemma="return" stem="return" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Each) (NN spring)) (SBAR (WHNP (WDT that)) (S (VP (VBD followed) (SBAR (S (NP (PRP she)) (VP (MD would) (VP (VB head) (PP (IN toward) (NP (NNP New) (NNP York) (NNP City))) (, ,) (S (VP (VBG walking) (PP (IN until) (NP (NN someone))))))))))))) (VP (VP (VBD found) (NP (PRP her))) (CC and) (VP (VBD returned) (NP (PRP her)) (PP (TO to) (NP (PRP$ her) (NN home))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her home" type="NP">
          <tokens>
            <token id="22" string="her" />
            <token id="23" string="home" />
          </tokens>
        </chunking>
        <chunking id="2" string="Each spring" type="NP">
          <tokens>
            <token id="1" string="Each" />
            <token id="2" string="spring" />
          </tokens>
        </chunking>
        <chunking id="3" string="returned her to her home" type="VP">
          <tokens>
            <token id="19" string="returned" />
            <token id="20" string="her" />
            <token id="21" string="to" />
            <token id="22" string="her" />
            <token id="23" string="home" />
          </tokens>
        </chunking>
        <chunking id="4" string="walking until someone" type="VP">
          <tokens>
            <token id="13" string="walking" />
            <token id="14" string="until" />
            <token id="15" string="someone" />
          </tokens>
        </chunking>
        <chunking id="5" string="would head toward New York City , walking until someone" type="VP">
          <tokens>
            <token id="6" string="would" />
            <token id="7" string="head" />
            <token id="8" string="toward" />
            <token id="9" string="New" />
            <token id="10" string="York" />
            <token id="11" string="City" />
            <token id="12" string="," />
            <token id="13" string="walking" />
            <token id="14" string="until" />
            <token id="15" string="someone" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="found her" type="VP">
          <tokens>
            <token id="16" string="found" />
            <token id="17" string="her" />
          </tokens>
        </chunking>
        <chunking id="8" string="she would head toward New York City , walking until someone" type="SBAR">
          <tokens>
            <token id="5" string="she" />
            <token id="6" string="would" />
            <token id="7" string="head" />
            <token id="8" string="toward" />
            <token id="9" string="New" />
            <token id="10" string="York" />
            <token id="11" string="City" />
            <token id="12" string="," />
            <token id="13" string="walking" />
            <token id="14" string="until" />
            <token id="15" string="someone" />
          </tokens>
        </chunking>
        <chunking id="9" string="Each spring that followed she would head toward New York City , walking until someone" type="NP">
          <tokens>
            <token id="1" string="Each" />
            <token id="2" string="spring" />
            <token id="3" string="that" />
            <token id="4" string="followed" />
            <token id="5" string="she" />
            <token id="6" string="would" />
            <token id="7" string="head" />
            <token id="8" string="toward" />
            <token id="9" string="New" />
            <token id="10" string="York" />
            <token id="11" string="City" />
            <token id="12" string="," />
            <token id="13" string="walking" />
            <token id="14" string="until" />
            <token id="15" string="someone" />
          </tokens>
        </chunking>
        <chunking id="10" string="her" type="NP">
          <tokens>
            <token id="17" string="her" />
          </tokens>
        </chunking>
        <chunking id="11" string="head toward New York City , walking until someone" type="VP">
          <tokens>
            <token id="7" string="head" />
            <token id="8" string="toward" />
            <token id="9" string="New" />
            <token id="10" string="York" />
            <token id="11" string="City" />
            <token id="12" string="," />
            <token id="13" string="walking" />
            <token id="14" string="until" />
            <token id="15" string="someone" />
          </tokens>
        </chunking>
        <chunking id="12" string="New York City" type="NP">
          <tokens>
            <token id="9" string="New" />
            <token id="10" string="York" />
            <token id="11" string="City" />
          </tokens>
        </chunking>
        <chunking id="13" string="someone" type="NP">
          <tokens>
            <token id="15" string="someone" />
          </tokens>
        </chunking>
        <chunking id="14" string="found her and returned her to her home" type="VP">
          <tokens>
            <token id="16" string="found" />
            <token id="17" string="her" />
            <token id="18" string="and" />
            <token id="19" string="returned" />
            <token id="20" string="her" />
            <token id="21" string="to" />
            <token id="22" string="her" />
            <token id="23" string="home" />
          </tokens>
        </chunking>
        <chunking id="15" string="followed she would head toward New York City , walking until someone" type="VP">
          <tokens>
            <token id="4" string="followed" />
            <token id="5" string="she" />
            <token id="6" string="would" />
            <token id="7" string="head" />
            <token id="8" string="toward" />
            <token id="9" string="New" />
            <token id="10" string="York" />
            <token id="11" string="City" />
            <token id="12" string="," />
            <token id="13" string="walking" />
            <token id="14" string="until" />
            <token id="15" string="someone" />
          </tokens>
        </chunking>
        <chunking id="16" string="that followed she would head toward New York City , walking until someone" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="followed" />
            <token id="5" string="she" />
            <token id="6" string="would" />
            <token id="7" string="head" />
            <token id="8" string="toward" />
            <token id="9" string="New" />
            <token id="10" string="York" />
            <token id="11" string="City" />
            <token id="12" string="," />
            <token id="13" string="walking" />
            <token id="14" string="until" />
            <token id="15" string="someone" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">spring</governor>
          <dependent id="1">Each</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">found</governor>
          <dependent id="2">spring</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">followed</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">spring</governor>
          <dependent id="4">followed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">head</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">head</governor>
          <dependent id="6">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">followed</governor>
          <dependent id="7">head</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">City</governor>
          <dependent id="8">toward</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">City</governor>
          <dependent id="9">New</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">City</governor>
          <dependent id="10">York</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">head</governor>
          <dependent id="11">City</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">head</governor>
          <dependent id="13">walking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">someone</governor>
          <dependent id="14">until</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">walking</governor>
          <dependent id="15">someone</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">found</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">found</governor>
          <dependent id="17">her</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">found</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">found</governor>
          <dependent id="19">returned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">returned</governor>
          <dependent id="20">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">home</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">home</governor>
          <dependent id="22">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">returned</governor>
          <dependent id="23">home</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Each" type="SET" score="0.0">
          <tokens>
            <token id="1" string="Each" />
          </tokens>
        </entity>
        <entity id="2" string="spring" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="spring" />
          </tokens>
        </entity>
        <entity id="3" string="New York City" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="New" />
            <token id="10" string="York" />
            <token id="11" string="City" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="63" has_coreference="true">
      <content>Leaving school at 15, Miss Ball finally made it to New York and the John Murray Anderson dramatic school.</content>
      <tokens>
        <token id="1" string="Leaving" lemma="leave" stem="leav" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="finally" lemma="finally" stem="final" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Murray" lemma="Murray" stem="murrai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Anderson" lemma="Anderson" stem="anderson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="dramatic" lemma="dramatic" stem="dramat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Leaving) (NP (NN school)) (PP (IN at) (NP (CD 15))))) (, ,) (NP (NNP Miss) (NNP Ball)) (ADVP (RB finally)) (VP (VBD made) (NP (PRP it)) (PP (TO to) (NP (NP (NNP New) (NNP York)) (CC and) (NP (DT the) (NNP John) (NNP Murray) (NNP Anderson) (JJ dramatic) (NN school))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="12" string="New" />
            <token id="13" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="school" type="NP">
          <tokens>
            <token id="2" string="school" />
          </tokens>
        </chunking>
        <chunking id="3" string="15" type="NP">
          <tokens>
            <token id="4" string="15" />
          </tokens>
        </chunking>
        <chunking id="4" string="New York and the John Murray Anderson dramatic school" type="NP">
          <tokens>
            <token id="12" string="New" />
            <token id="13" string="York" />
            <token id="14" string="and" />
            <token id="15" string="the" />
            <token id="16" string="John" />
            <token id="17" string="Murray" />
            <token id="18" string="Anderson" />
            <token id="19" string="dramatic" />
            <token id="20" string="school" />
          </tokens>
        </chunking>
        <chunking id="5" string="the John Murray Anderson dramatic school" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="John" />
            <token id="17" string="Murray" />
            <token id="18" string="Anderson" />
            <token id="19" string="dramatic" />
            <token id="20" string="school" />
          </tokens>
        </chunking>
        <chunking id="6" string="Leaving school at 15" type="VP">
          <tokens>
            <token id="1" string="Leaving" />
            <token id="2" string="school" />
            <token id="3" string="at" />
            <token id="4" string="15" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="made it to New York and the John Murray Anderson dramatic school" type="VP">
          <tokens>
            <token id="9" string="made" />
            <token id="10" string="it" />
            <token id="11" string="to" />
            <token id="12" string="New" />
            <token id="13" string="York" />
            <token id="14" string="and" />
            <token id="15" string="the" />
            <token id="16" string="John" />
            <token id="17" string="Murray" />
            <token id="18" string="Anderson" />
            <token id="19" string="dramatic" />
            <token id="20" string="school" />
          </tokens>
        </chunking>
        <chunking id="9" string="Miss Ball" type="NP">
          <tokens>
            <token id="6" string="Miss" />
            <token id="7" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="9">made</governor>
          <dependent id="1">Leaving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Leaving</governor>
          <dependent id="2">school</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">15</governor>
          <dependent id="3">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Leaving</governor>
          <dependent id="4">15</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Ball</governor>
          <dependent id="6">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">made</governor>
          <dependent id="7">Ball</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">made</governor>
          <dependent id="8">finally</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">made</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">made</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">York</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">York</governor>
          <dependent id="12">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">made</governor>
          <dependent id="13">York</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">York</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">school</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">school</governor>
          <dependent id="16">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">school</governor>
          <dependent id="17">Murray</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">school</governor>
          <dependent id="18">Anderson</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">school</governor>
          <dependent id="19">dramatic</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">York</governor>
          <dependent id="20">school</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="New" />
            <token id="13" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="15" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="15" />
          </tokens>
        </entity>
        <entity id="3" string="John Murray Anderson" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="John" />
            <token id="17" string="Murray" />
            <token id="18" string="Anderson" />
          </tokens>
        </entity>
        <entity id="4" string="Miss Ball" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Miss" />
            <token id="7" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="64" has_coreference="true">
      <content>There was a brief stint in a Ziegfeld Follies road show and some short-lived appearances in a handful of Broadway chorus lines.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="brief" lemma="brief" stem="brief" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="stint" lemma="stint" stem="stint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Ziegfeld" lemma="Ziegfeld" stem="ziegfeld" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Follies" lemma="Follies" stem="folli" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="road" lemma="road" stem="road" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="short-lived" lemma="short-lived" stem="short-liv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="appearances" lemma="appearance" stem="appear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="handful" lemma="handful" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Broadway" lemma="Broadway" stem="broadwai" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="21" string="chorus" lemma="chorus" stem="choru" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="lines" lemma="line" stem="line" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBD was) (NP (NP (NP (DT a) (JJ brief) (NN stint)) (PP (IN in) (NP (DT a) (NNP Ziegfeld) (NNPS Follies) (NN road) (NN show)))) (CC and) (NP (NP (DT some) (JJ short-lived) (NNS appearances)) (PP (IN in) (NP (NP (DT a) (NN handful)) (PP (IN of) (NP (NNP Broadway) (NN chorus) (NNS lines)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a handful" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="handful" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="a brief stint in a Ziegfeld Follies road show and some short-lived appearances in a handful of Broadway chorus lines" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="brief" />
            <token id="5" string="stint" />
            <token id="6" string="in" />
            <token id="7" string="a" />
            <token id="8" string="Ziegfeld" />
            <token id="9" string="Follies" />
            <token id="10" string="road" />
            <token id="11" string="show" />
            <token id="12" string="and" />
            <token id="13" string="some" />
            <token id="14" string="short-lived" />
            <token id="15" string="appearances" />
            <token id="16" string="in" />
            <token id="17" string="a" />
            <token id="18" string="handful" />
            <token id="19" string="of" />
            <token id="20" string="Broadway" />
            <token id="21" string="chorus" />
            <token id="22" string="lines" />
          </tokens>
        </chunking>
        <chunking id="4" string="a brief stint in a Ziegfeld Follies road show" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="brief" />
            <token id="5" string="stint" />
            <token id="6" string="in" />
            <token id="7" string="a" />
            <token id="8" string="Ziegfeld" />
            <token id="9" string="Follies" />
            <token id="10" string="road" />
            <token id="11" string="show" />
          </tokens>
        </chunking>
        <chunking id="5" string="a Ziegfeld Follies road show" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="Ziegfeld" />
            <token id="9" string="Follies" />
            <token id="10" string="road" />
            <token id="11" string="show" />
          </tokens>
        </chunking>
        <chunking id="6" string="some short-lived appearances in a handful of Broadway chorus lines" type="NP">
          <tokens>
            <token id="13" string="some" />
            <token id="14" string="short-lived" />
            <token id="15" string="appearances" />
            <token id="16" string="in" />
            <token id="17" string="a" />
            <token id="18" string="handful" />
            <token id="19" string="of" />
            <token id="20" string="Broadway" />
            <token id="21" string="chorus" />
            <token id="22" string="lines" />
          </tokens>
        </chunking>
        <chunking id="7" string="a handful of Broadway chorus lines" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="handful" />
            <token id="19" string="of" />
            <token id="20" string="Broadway" />
            <token id="21" string="chorus" />
            <token id="22" string="lines" />
          </tokens>
        </chunking>
        <chunking id="8" string="some short-lived appearances" type="NP">
          <tokens>
            <token id="13" string="some" />
            <token id="14" string="short-lived" />
            <token id="15" string="appearances" />
          </tokens>
        </chunking>
        <chunking id="9" string="was a brief stint in a Ziegfeld Follies road show and some short-lived appearances in a handful of Broadway chorus lines" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="a" />
            <token id="4" string="brief" />
            <token id="5" string="stint" />
            <token id="6" string="in" />
            <token id="7" string="a" />
            <token id="8" string="Ziegfeld" />
            <token id="9" string="Follies" />
            <token id="10" string="road" />
            <token id="11" string="show" />
            <token id="12" string="and" />
            <token id="13" string="some" />
            <token id="14" string="short-lived" />
            <token id="15" string="appearances" />
            <token id="16" string="in" />
            <token id="17" string="a" />
            <token id="18" string="handful" />
            <token id="19" string="of" />
            <token id="20" string="Broadway" />
            <token id="21" string="chorus" />
            <token id="22" string="lines" />
          </tokens>
        </chunking>
        <chunking id="10" string="a brief stint" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="brief" />
            <token id="5" string="stint" />
          </tokens>
        </chunking>
        <chunking id="11" string="Broadway chorus lines" type="NP">
          <tokens>
            <token id="20" string="Broadway" />
            <token id="21" string="chorus" />
            <token id="22" string="lines" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">was</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">stint</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">stint</governor>
          <dependent id="4">brief</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">was</governor>
          <dependent id="5">stint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">show</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">show</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">show</governor>
          <dependent id="8">Ziegfeld</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">show</governor>
          <dependent id="9">Follies</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">show</governor>
          <dependent id="10">road</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">stint</governor>
          <dependent id="11">show</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">stint</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">appearances</governor>
          <dependent id="13">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">appearances</governor>
          <dependent id="14">short-lived</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">stint</governor>
          <dependent id="15">appearances</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">handful</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">handful</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">appearances</governor>
          <dependent id="18">handful</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">lines</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">lines</governor>
          <dependent id="20">Broadway</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">lines</governor>
          <dependent id="21">chorus</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">handful</governor>
          <dependent id="22">lines</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ziegfeld Follies" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Ziegfeld" />
            <token id="9" string="Follies" />
          </tokens>
        </entity>
        <entity id="2" string="Broadway" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Broadway" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="65" has_coreference="true">
      <content>Changing her name to Diane Belmont (&amp;quot;I always loved the name Diane and I was driving past the Belmont race track, and the names seemed to fit together&amp;quot;) she turned to modeling.</content>
      <tokens>
        <token id="1" string="Changing" lemma="change" stem="chang" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="name" lemma="name" stem="name" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Diane" lemma="Diane" stem="dian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="Belmont" lemma="Belmont" stem="belmont" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="loved" lemma="love" stem="love" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="name" lemma="name" stem="name" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Diane" lemma="Diane" stem="dian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="driving" lemma="drive" stem="drive" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="past" lemma="past" stem="past" pos="IN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Belmont" lemma="Belmont" stem="belmont" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="track" lemma="track" stem="track" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="names" lemma="name" stem="name" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="fit" lemma="fit" stem="fit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="turned" lemma="turn" stem="turn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="modeling" lemma="modeling" stem="model" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Changing) (NP (PRP$ her) (NN name)) (PP (TO to) (NP (NP (NNP Diane) (NNP Belmont)) (PRN (-LRB- -LRB-) (`` ``) (S (NP (PRP I)) (ADVP (RB always)) (VP (VBD loved) (SBAR (S (S (NP (DT the) (NN name)) (NP (NNP Diane))) (CC and) (S (S (NP (PRP I)) (VP (VBD was) (VP (VBG driving) (PP (IN past) (NP (DT the) (NNP Belmont) (NN race) (NN track)))))) (, ,) (CC and) (S (NP (DT the) (NNS names)) (VP (VBD seemed) (S (VP (TO to) (VP (VB fit) (ADVP (RB together)))))))))))) ('' '') (-RRB- -RRB-)))))) (NP (PRP she)) (VP (VBD turned) (PP (TO to) (NP (NN modeling)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Diane Belmont -LRB- `` I always loved the name Diane and I was driving past the Belmont race track , and the names seemed to fit together '' -RRB-" type="NP">
          <tokens>
            <token id="5" string="Diane" />
            <token id="6" string="Belmont" />
            <token id="7" string="(" />
            <token id="8" string="&quot;" />
            <token id="9" string="I" />
            <token id="10" string="always" />
            <token id="11" string="loved" />
            <token id="12" string="the" />
            <token id="13" string="name" />
            <token id="14" string="Diane" />
            <token id="15" string="and" />
            <token id="16" string="I" />
            <token id="17" string="was" />
            <token id="18" string="driving" />
            <token id="19" string="past" />
            <token id="20" string="the" />
            <token id="21" string="Belmont" />
            <token id="22" string="race" />
            <token id="23" string="track" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="the" />
            <token id="27" string="names" />
            <token id="28" string="seemed" />
            <token id="29" string="to" />
            <token id="30" string="fit" />
            <token id="31" string="together" />
            <token id="32" string="&quot;" />
            <token id="33" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="loved the name Diane and I was driving past the Belmont race track , and the names seemed to fit together" type="VP">
          <tokens>
            <token id="11" string="loved" />
            <token id="12" string="the" />
            <token id="13" string="name" />
            <token id="14" string="Diane" />
            <token id="15" string="and" />
            <token id="16" string="I" />
            <token id="17" string="was" />
            <token id="18" string="driving" />
            <token id="19" string="past" />
            <token id="20" string="the" />
            <token id="21" string="Belmont" />
            <token id="22" string="race" />
            <token id="23" string="track" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="the" />
            <token id="27" string="names" />
            <token id="28" string="seemed" />
            <token id="29" string="to" />
            <token id="30" string="fit" />
            <token id="31" string="together" />
          </tokens>
        </chunking>
        <chunking id="3" string="was driving past the Belmont race track" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="driving" />
            <token id="19" string="past" />
            <token id="20" string="the" />
            <token id="21" string="Belmont" />
            <token id="22" string="race" />
            <token id="23" string="track" />
          </tokens>
        </chunking>
        <chunking id="4" string="modeling" type="NP">
          <tokens>
            <token id="37" string="modeling" />
          </tokens>
        </chunking>
        <chunking id="5" string="Diane Belmont" type="NP">
          <tokens>
            <token id="5" string="Diane" />
            <token id="6" string="Belmont" />
          </tokens>
        </chunking>
        <chunking id="6" string="driving past the Belmont race track" type="VP">
          <tokens>
            <token id="18" string="driving" />
            <token id="19" string="past" />
            <token id="20" string="the" />
            <token id="21" string="Belmont" />
            <token id="22" string="race" />
            <token id="23" string="track" />
          </tokens>
        </chunking>
        <chunking id="7" string="the name Diane and I was driving past the Belmont race track , and the names seemed to fit together" type="SBAR">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="name" />
            <token id="14" string="Diane" />
            <token id="15" string="and" />
            <token id="16" string="I" />
            <token id="17" string="was" />
            <token id="18" string="driving" />
            <token id="19" string="past" />
            <token id="20" string="the" />
            <token id="21" string="Belmont" />
            <token id="22" string="race" />
            <token id="23" string="track" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="the" />
            <token id="27" string="names" />
            <token id="28" string="seemed" />
            <token id="29" string="to" />
            <token id="30" string="fit" />
            <token id="31" string="together" />
          </tokens>
        </chunking>
        <chunking id="8" string="fit together" type="VP">
          <tokens>
            <token id="30" string="fit" />
            <token id="31" string="together" />
          </tokens>
        </chunking>
        <chunking id="9" string="turned to modeling" type="VP">
          <tokens>
            <token id="35" string="turned" />
            <token id="36" string="to" />
            <token id="37" string="modeling" />
          </tokens>
        </chunking>
        <chunking id="10" string="I" type="NP">
          <tokens>
            <token id="9" string="I" />
          </tokens>
        </chunking>
        <chunking id="11" string="to fit together" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="fit" />
            <token id="31" string="together" />
          </tokens>
        </chunking>
        <chunking id="12" string="she" type="NP">
          <tokens>
            <token id="34" string="she" />
          </tokens>
        </chunking>
        <chunking id="13" string="the names" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="names" />
          </tokens>
        </chunking>
        <chunking id="14" string="the name" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="name" />
          </tokens>
        </chunking>
        <chunking id="15" string="seemed to fit together" type="VP">
          <tokens>
            <token id="28" string="seemed" />
            <token id="29" string="to" />
            <token id="30" string="fit" />
            <token id="31" string="together" />
          </tokens>
        </chunking>
        <chunking id="16" string="her name" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="name" />
          </tokens>
        </chunking>
        <chunking id="17" string="Diane" type="NP">
          <tokens>
            <token id="14" string="Diane" />
          </tokens>
        </chunking>
        <chunking id="18" string="the Belmont race track" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Belmont" />
            <token id="22" string="race" />
            <token id="23" string="track" />
          </tokens>
        </chunking>
        <chunking id="19" string="Changing her name to Diane Belmont -LRB- `` I always loved the name Diane and I was driving past the Belmont race track , and the names seemed to fit together '' -RRB-" type="VP">
          <tokens>
            <token id="1" string="Changing" />
            <token id="2" string="her" />
            <token id="3" string="name" />
            <token id="4" string="to" />
            <token id="5" string="Diane" />
            <token id="6" string="Belmont" />
            <token id="7" string="(" />
            <token id="8" string="&quot;" />
            <token id="9" string="I" />
            <token id="10" string="always" />
            <token id="11" string="loved" />
            <token id="12" string="the" />
            <token id="13" string="name" />
            <token id="14" string="Diane" />
            <token id="15" string="and" />
            <token id="16" string="I" />
            <token id="17" string="was" />
            <token id="18" string="driving" />
            <token id="19" string="past" />
            <token id="20" string="the" />
            <token id="21" string="Belmont" />
            <token id="22" string="race" />
            <token id="23" string="track" />
            <token id="24" string="," />
            <token id="25" string="and" />
            <token id="26" string="the" />
            <token id="27" string="names" />
            <token id="28" string="seemed" />
            <token id="29" string="to" />
            <token id="30" string="fit" />
            <token id="31" string="together" />
            <token id="32" string="&quot;" />
            <token id="33" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="35">turned</governor>
          <dependent id="1">Changing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">name</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Changing</governor>
          <dependent id="3">name</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Belmont</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Belmont</governor>
          <dependent id="5">Diane</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Changing</governor>
          <dependent id="6">Belmont</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">loved</governor>
          <dependent id="9">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">loved</governor>
          <dependent id="10">always</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">Belmont</governor>
          <dependent id="11">loved</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">name</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">Diane</governor>
          <dependent id="13">name</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">loved</governor>
          <dependent id="14">Diane</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">Diane</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">driving</governor>
          <dependent id="16">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">driving</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">Diane</governor>
          <dependent id="18">driving</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">track</governor>
          <dependent id="19">past</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">track</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">track</governor>
          <dependent id="21">Belmont</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">track</governor>
          <dependent id="22">race</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">driving</governor>
          <dependent id="23">track</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">driving</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">names</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">seemed</governor>
          <dependent id="27">names</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">driving</governor>
          <dependent id="28">seemed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">fit</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">seemed</governor>
          <dependent id="30">fit</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">fit</governor>
          <dependent id="31">together</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">turned</governor>
          <dependent id="34">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="35">turned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">modeling</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">turned</governor>
          <dependent id="37">modeling</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Diane Belmont" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Diane" />
            <token id="6" string="Belmont" />
          </tokens>
        </entity>
        <entity id="2" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="past" />
          </tokens>
        </entity>
        <entity id="3" string="Belmont" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Belmont" />
          </tokens>
        </entity>
        <entity id="4" string="Diane" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Diane" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="66" has_coreference="true">
      <content>At various times a dress model and a hat model, Miss Ball, with long legs peeking out the bottom of a oversized cigarette pack, ultimately became a &amp;quot;Chesterfield girl.&amp;quot;</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="various" lemma="various" stem="variou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="dress" lemma="dress" stem="dress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="model" lemma="model" stem="model" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="hat" lemma="hat" stem="hat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="model" lemma="model" stem="model" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="13" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="legs" lemma="leg" stem="leg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="peeking" lemma="peek" stem="peek" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="bottom" lemma="bottom" stem="bottom" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="oversized" lemma="oversized" stem="overs" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="cigarette" lemma="cigarette" stem="cigarett" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="pack" lemma="pack" stem="pack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="ultimately" lemma="ultimately" stem="ultim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Chesterfield" lemma="Chesterfield" stem="chesterfield" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="girl" lemma="girl" stem="girl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (JJ various) (NNS times))) (PRN (S (NP (NP (DT a) (NN dress) (NN model)) (CC and) (NP (NP (NP (DT a) (NN hat) (NN model)) (, ,) (NP (NNP Miss) (NNP Ball)) (, ,)) (PP (IN with) (NP (JJ long) (NNS legs))))) (VP (VBG peeking) (PRT (RP out)) (NP (NP (DT the) (NN bottom)) (PP (IN of) (NP (DT a) (JJ oversized) (NN cigarette) (NN pack)))))) (, ,)) (ADVP (RB ultimately)) (VP (VBD became) (S (NP (DT a) (`` ``) (NNP Chesterfield) (NN girl)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a oversized cigarette pack" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="oversized" />
            <token id="25" string="cigarette" />
            <token id="26" string="pack" />
          </tokens>
        </chunking>
        <chunking id="2" string="became a `` Chesterfield girl" type="VP">
          <tokens>
            <token id="29" string="became" />
            <token id="30" string="a" />
            <token id="31" string="&quot;" />
            <token id="32" string="Chesterfield" />
            <token id="33" string="girl" />
          </tokens>
        </chunking>
        <chunking id="3" string="a dress model" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="dress" />
            <token id="6" string="model" />
          </tokens>
        </chunking>
        <chunking id="4" string="peeking out the bottom of a oversized cigarette pack" type="VP">
          <tokens>
            <token id="18" string="peeking" />
            <token id="19" string="out" />
            <token id="20" string="the" />
            <token id="21" string="bottom" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="oversized" />
            <token id="25" string="cigarette" />
            <token id="26" string="pack" />
          </tokens>
        </chunking>
        <chunking id="5" string="various times" type="NP">
          <tokens>
            <token id="2" string="various" />
            <token id="3" string="times" />
          </tokens>
        </chunking>
        <chunking id="6" string="a hat model , Miss Ball ," type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="hat" />
            <token id="10" string="model" />
            <token id="11" string="," />
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="long legs" type="NP">
          <tokens>
            <token id="16" string="long" />
            <token id="17" string="legs" />
          </tokens>
        </chunking>
        <chunking id="8" string="a hat model" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="hat" />
            <token id="10" string="model" />
          </tokens>
        </chunking>
        <chunking id="9" string="a hat model , Miss Ball , with long legs" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="hat" />
            <token id="10" string="model" />
            <token id="11" string="," />
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
            <token id="14" string="," />
            <token id="15" string="with" />
            <token id="16" string="long" />
            <token id="17" string="legs" />
          </tokens>
        </chunking>
        <chunking id="10" string="the bottom of a oversized cigarette pack" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="bottom" />
            <token id="22" string="of" />
            <token id="23" string="a" />
            <token id="24" string="oversized" />
            <token id="25" string="cigarette" />
            <token id="26" string="pack" />
          </tokens>
        </chunking>
        <chunking id="11" string="a `` Chesterfield girl" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="&quot;" />
            <token id="32" string="Chesterfield" />
            <token id="33" string="girl" />
          </tokens>
        </chunking>
        <chunking id="12" string="the bottom" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="bottom" />
          </tokens>
        </chunking>
        <chunking id="13" string="a dress model and a hat model , Miss Ball , with long legs" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="dress" />
            <token id="6" string="model" />
            <token id="7" string="and" />
            <token id="8" string="a" />
            <token id="9" string="hat" />
            <token id="10" string="model" />
            <token id="11" string="," />
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
            <token id="14" string="," />
            <token id="15" string="with" />
            <token id="16" string="long" />
            <token id="17" string="legs" />
          </tokens>
        </chunking>
        <chunking id="14" string="Miss Ball" type="NP">
          <tokens>
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">times</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">times</governor>
          <dependent id="2">various</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">became</governor>
          <dependent id="3">times</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">model</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">model</governor>
          <dependent id="5">dress</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">peeking</governor>
          <dependent id="6">model</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">model</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">model</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">model</governor>
          <dependent id="9">hat</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">model</governor>
          <dependent id="10">model</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Ball</governor>
          <dependent id="12">Miss</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">model</governor>
          <dependent id="13">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">legs</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">legs</governor>
          <dependent id="16">long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">model</governor>
          <dependent id="17">legs</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="29">became</governor>
          <dependent id="18">peeking</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="18">peeking</governor>
          <dependent id="19">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">bottom</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">peeking</governor>
          <dependent id="21">bottom</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">pack</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">pack</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">pack</governor>
          <dependent id="24">oversized</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">pack</governor>
          <dependent id="25">cigarette</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">bottom</governor>
          <dependent id="26">pack</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">became</governor>
          <dependent id="28">ultimately</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">became</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">girl</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">girl</governor>
          <dependent id="32">Chesterfield</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">became</governor>
          <dependent id="33">girl</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Miss Ball" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="67" has_coreference="true">
      <content>America grew to know her on billboards, magazine ads and on posters in its drugstore windows.</content>
      <tokens>
        <token id="1" string="America" lemma="America" stem="america" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="2" string="grew" lemma="grow" stem="grew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="billboards" lemma="billboard" stem="billboard" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="ads" lemma="ad" stem="ad" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="posters" lemma="poster" stem="poster" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="drugstore" lemma="drugstore" stem="drugstor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="windows" lemma="window" stem="window" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP America)) (VP (VBD grew) (S (VP (TO to) (VP (VB know) (NP (PRP$ her)) (PP (PP (IN on) (NP (NP (NNS billboards)) (, ,) (NP (NN magazine) (NNS ads)))) (CC and) (PP (IN on) (NP (NP (NNS posters)) (PP (IN in) (NP (PRP$ its) (NN drugstore) (NNS windows)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="grew to know her on billboards , magazine ads and on posters in its drugstore windows" type="VP">
          <tokens>
            <token id="2" string="grew" />
            <token id="3" string="to" />
            <token id="4" string="know" />
            <token id="5" string="her" />
            <token id="6" string="on" />
            <token id="7" string="billboards" />
            <token id="8" string="," />
            <token id="9" string="magazine" />
            <token id="10" string="ads" />
            <token id="11" string="and" />
            <token id="12" string="on" />
            <token id="13" string="posters" />
            <token id="14" string="in" />
            <token id="15" string="its" />
            <token id="16" string="drugstore" />
            <token id="17" string="windows" />
          </tokens>
        </chunking>
        <chunking id="2" string="billboards" type="NP">
          <tokens>
            <token id="7" string="billboards" />
          </tokens>
        </chunking>
        <chunking id="3" string="its drugstore windows" type="NP">
          <tokens>
            <token id="15" string="its" />
            <token id="16" string="drugstore" />
            <token id="17" string="windows" />
          </tokens>
        </chunking>
        <chunking id="4" string="America" type="NP">
          <tokens>
            <token id="1" string="America" />
          </tokens>
        </chunking>
        <chunking id="5" string="magazine ads" type="NP">
          <tokens>
            <token id="9" string="magazine" />
            <token id="10" string="ads" />
          </tokens>
        </chunking>
        <chunking id="6" string="posters in its drugstore windows" type="NP">
          <tokens>
            <token id="13" string="posters" />
            <token id="14" string="in" />
            <token id="15" string="its" />
            <token id="16" string="drugstore" />
            <token id="17" string="windows" />
          </tokens>
        </chunking>
        <chunking id="7" string="her" type="NP">
          <tokens>
            <token id="5" string="her" />
          </tokens>
        </chunking>
        <chunking id="8" string="know her on billboards , magazine ads and on posters in its drugstore windows" type="VP">
          <tokens>
            <token id="4" string="know" />
            <token id="5" string="her" />
            <token id="6" string="on" />
            <token id="7" string="billboards" />
            <token id="8" string="," />
            <token id="9" string="magazine" />
            <token id="10" string="ads" />
            <token id="11" string="and" />
            <token id="12" string="on" />
            <token id="13" string="posters" />
            <token id="14" string="in" />
            <token id="15" string="its" />
            <token id="16" string="drugstore" />
            <token id="17" string="windows" />
          </tokens>
        </chunking>
        <chunking id="9" string="to know her on billboards , magazine ads and on posters in its drugstore windows" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="know" />
            <token id="5" string="her" />
            <token id="6" string="on" />
            <token id="7" string="billboards" />
            <token id="8" string="," />
            <token id="9" string="magazine" />
            <token id="10" string="ads" />
            <token id="11" string="and" />
            <token id="12" string="on" />
            <token id="13" string="posters" />
            <token id="14" string="in" />
            <token id="15" string="its" />
            <token id="16" string="drugstore" />
            <token id="17" string="windows" />
          </tokens>
        </chunking>
        <chunking id="10" string="posters" type="NP">
          <tokens>
            <token id="13" string="posters" />
          </tokens>
        </chunking>
        <chunking id="11" string="billboards , magazine ads" type="NP">
          <tokens>
            <token id="7" string="billboards" />
            <token id="8" string="," />
            <token id="9" string="magazine" />
            <token id="10" string="ads" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">grew</governor>
          <dependent id="1">America</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">grew</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">know</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">grew</governor>
          <dependent id="4">know</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">know</governor>
          <dependent id="4">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">know</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">billboards</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">know</governor>
          <dependent id="7">billboards</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">ads</governor>
          <dependent id="9">magazine</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">billboards</governor>
          <dependent id="10">ads</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">know</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">posters</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">know</governor>
          <dependent id="13">posters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">windows</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">windows</governor>
          <dependent id="15">its</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">windows</governor>
          <dependent id="16">drugstore</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">posters</governor>
          <dependent id="17">windows</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="America" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="America" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="68" has_coreference="true">
      <content>Then in 1933, she headed to Hollywood.</content>
      <tokens>
        <token id="1" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="1933" lemma="1933" stem="1933" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="headed" lemma="head" stem="head" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Then) (PP (IN in) (NP (CD 1933))) (, ,) (NP (PRP she)) (VP (VBD headed) (PP (TO to) (NP (NNP Hollywood)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="1933" type="NP">
          <tokens>
            <token id="3" string="1933" />
          </tokens>
        </chunking>
        <chunking id="2" string="Hollywood" type="NP">
          <tokens>
            <token id="8" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="3" string="headed to Hollywood" type="VP">
          <tokens>
            <token id="6" string="headed" />
            <token id="7" string="to" />
            <token id="8" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="4" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">headed</governor>
          <dependent id="1">Then</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">1933</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">headed</governor>
          <dependent id="3">1933</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">headed</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">headed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Hollywood</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">headed</governor>
          <dependent id="8">Hollywood</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1933" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="1933" />
          </tokens>
        </entity>
        <entity id="2" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Hollywood" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="69" has_coreference="true">
      <content>Her curly hair bleached a Jean Harlow platinum, Miss Ball was hired to work for six weeks in the chorus of Samuel Goldwyn&amp;apost;s &amp;quot;Roman Scandals.&amp;quot;</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="curly" lemma="curly" stem="curli" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="hair" lemma="hair" stem="hair" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="bleached" lemma="bleached" stem="bleach" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="Jean" lemma="Jean" stem="jean" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Harlow" lemma="Harlow" stem="harlow" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="platinum" lemma="platinum" stem="platinum" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="11" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="hired" lemma="hire" stem="hire" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="chorus" lemma="chorus" stem="choru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Samuel" lemma="Samuel" stem="samuel" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="Goldwyn" lemma="Goldwyn" stem="goldwyn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Roman" lemma="Roman" stem="roman" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="28" string="Scandals" lemma="Scandals" stem="scandal" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ Her) (JJ curly) (NN hair)) (ADJP (JJ bleached) (NP-TMP (NP (DT a) (NNP Jean) (NNP Harlow) (NN platinum)) (, ,) (NP (NNP Miss) (NNP Ball))))) (VP (VBD was) (VP (VBN hired) (S (VP (TO to) (VP (VB work) (PP (IN for) (NP (NP (CD six) (NNS weeks)) (PP (IN in) (NP (NP (DT the) (NN chorus)) (PP (IN of) (NP (NP (NNP Samuel) (NNP Goldwyn) (POS 's)) (`` ``) (NNP Roman) (NNP Scandals)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="bleached a Jean Harlow platinum , Miss Ball" type="ADJP">
          <tokens>
            <token id="4" string="bleached" />
            <token id="5" string="a" />
            <token id="6" string="Jean" />
            <token id="7" string="Harlow" />
            <token id="8" string="platinum" />
            <token id="9" string="," />
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="2" string="six weeks in the chorus of Samuel Goldwyn 's `` Roman Scandals" type="NP">
          <tokens>
            <token id="17" string="six" />
            <token id="18" string="weeks" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="chorus" />
            <token id="22" string="of" />
            <token id="23" string="Samuel" />
            <token id="24" string="Goldwyn" />
            <token id="25" string="'s" />
            <token id="26" string="&quot;" />
            <token id="27" string="Roman" />
            <token id="28" string="Scandals" />
          </tokens>
        </chunking>
        <chunking id="3" string="to work for six weeks in the chorus of Samuel Goldwyn 's `` Roman Scandals" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="work" />
            <token id="16" string="for" />
            <token id="17" string="six" />
            <token id="18" string="weeks" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="chorus" />
            <token id="22" string="of" />
            <token id="23" string="Samuel" />
            <token id="24" string="Goldwyn" />
            <token id="25" string="'s" />
            <token id="26" string="&quot;" />
            <token id="27" string="Roman" />
            <token id="28" string="Scandals" />
          </tokens>
        </chunking>
        <chunking id="4" string="was hired to work for six weeks in the chorus of Samuel Goldwyn 's `` Roman Scandals" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="hired" />
            <token id="14" string="to" />
            <token id="15" string="work" />
            <token id="16" string="for" />
            <token id="17" string="six" />
            <token id="18" string="weeks" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="chorus" />
            <token id="22" string="of" />
            <token id="23" string="Samuel" />
            <token id="24" string="Goldwyn" />
            <token id="25" string="'s" />
            <token id="26" string="&quot;" />
            <token id="27" string="Roman" />
            <token id="28" string="Scandals" />
          </tokens>
        </chunking>
        <chunking id="5" string="Samuel Goldwyn 's `` Roman Scandals" type="NP">
          <tokens>
            <token id="23" string="Samuel" />
            <token id="24" string="Goldwyn" />
            <token id="25" string="'s" />
            <token id="26" string="&quot;" />
            <token id="27" string="Roman" />
            <token id="28" string="Scandals" />
          </tokens>
        </chunking>
        <chunking id="6" string="work for six weeks in the chorus of Samuel Goldwyn 's `` Roman Scandals" type="VP">
          <tokens>
            <token id="15" string="work" />
            <token id="16" string="for" />
            <token id="17" string="six" />
            <token id="18" string="weeks" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="chorus" />
            <token id="22" string="of" />
            <token id="23" string="Samuel" />
            <token id="24" string="Goldwyn" />
            <token id="25" string="'s" />
            <token id="26" string="&quot;" />
            <token id="27" string="Roman" />
            <token id="28" string="Scandals" />
          </tokens>
        </chunking>
        <chunking id="7" string="hired to work for six weeks in the chorus of Samuel Goldwyn 's `` Roman Scandals" type="VP">
          <tokens>
            <token id="13" string="hired" />
            <token id="14" string="to" />
            <token id="15" string="work" />
            <token id="16" string="for" />
            <token id="17" string="six" />
            <token id="18" string="weeks" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="chorus" />
            <token id="22" string="of" />
            <token id="23" string="Samuel" />
            <token id="24" string="Goldwyn" />
            <token id="25" string="'s" />
            <token id="26" string="&quot;" />
            <token id="27" string="Roman" />
            <token id="28" string="Scandals" />
          </tokens>
        </chunking>
        <chunking id="8" string="Her curly hair bleached a Jean Harlow platinum , Miss Ball" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="curly" />
            <token id="3" string="hair" />
            <token id="4" string="bleached" />
            <token id="5" string="a" />
            <token id="6" string="Jean" />
            <token id="7" string="Harlow" />
            <token id="8" string="platinum" />
            <token id="9" string="," />
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="9" string="Her curly hair" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="curly" />
            <token id="3" string="hair" />
          </tokens>
        </chunking>
        <chunking id="10" string="a Jean Harlow platinum" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="Jean" />
            <token id="7" string="Harlow" />
            <token id="8" string="platinum" />
          </tokens>
        </chunking>
        <chunking id="11" string="the chorus of Samuel Goldwyn 's `` Roman Scandals" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="chorus" />
            <token id="22" string="of" />
            <token id="23" string="Samuel" />
            <token id="24" string="Goldwyn" />
            <token id="25" string="'s" />
            <token id="26" string="&quot;" />
            <token id="27" string="Roman" />
            <token id="28" string="Scandals" />
          </tokens>
        </chunking>
        <chunking id="12" string="the chorus" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="chorus" />
          </tokens>
        </chunking>
        <chunking id="13" string="six weeks" type="NP">
          <tokens>
            <token id="17" string="six" />
            <token id="18" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="14" string="Samuel Goldwyn 's" type="NP">
          <tokens>
            <token id="23" string="Samuel" />
            <token id="24" string="Goldwyn" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="Miss Ball" type="NP">
          <tokens>
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">hair</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">hair</governor>
          <dependent id="2">curly</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">hired</governor>
          <dependent id="3">hair</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">hair</governor>
          <dependent id="4">bleached</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">platinum</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">platinum</governor>
          <dependent id="6">Jean</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">platinum</governor>
          <dependent id="7">Harlow</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">bleached</governor>
          <dependent id="8">platinum</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Ball</governor>
          <dependent id="10">Miss</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">platinum</governor>
          <dependent id="11">Ball</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">hired</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">hired</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">work</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">hired</governor>
          <dependent id="15">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">weeks</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">weeks</governor>
          <dependent id="17">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">work</governor>
          <dependent id="18">weeks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">chorus</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">chorus</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">weeks</governor>
          <dependent id="21">chorus</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Scandals</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Goldwyn</governor>
          <dependent id="23">Samuel</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">Scandals</governor>
          <dependent id="24">Goldwyn</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Goldwyn</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Scandals</governor>
          <dependent id="27">Roman</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">chorus</governor>
          <dependent id="28">Scandals</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Samuel Goldwyn" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Samuel" />
            <token id="24" string="Goldwyn" />
          </tokens>
        </entity>
        <entity id="2" string="Jean Harlow" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Jean" />
            <token id="7" string="Harlow" />
          </tokens>
        </entity>
        <entity id="3" string="Roman" type="MISC" score="0.0">
          <tokens>
            <token id="27" string="Roman" />
          </tokens>
        </entity>
        <entity id="4" string="six weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="17" string="six" />
            <token id="18" string="weeks" />
          </tokens>
        </entity>
        <entity id="5" string="Miss Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="70" has_coreference="true">
      <content>Bit part after bit part stretched her stay to six months and she became a Hollywood fixture, taking second billing in the years that followed to everyone from The Three Stooges and Buster Keaton to Katharine Hepburn and Spencer Tracy.</content>
      <tokens>
        <token id="1" string="Bit" lemma="bit" stem="bit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="bit" lemma="bit" stem="bit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="stretched" lemma="stretch" stem="stretch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="stay" lemma="stay" stem="stai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="fixture" lemma="fixture" stem="fixtur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="taking" lemma="take" stem="take" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="21" string="billing" lemma="billing" stem="bill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="24" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="25" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="followed" lemma="follow" stem="follow" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="Three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="32" string="Stooges" lemma="stooge" stem="stoog" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="Buster" lemma="Buster" stem="buster" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="35" string="Keaton" lemma="Keaton" stem="keaton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="Katharine" lemma="Katharine" stem="katharin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="38" string="Hepburn" lemma="Hepburn" stem="hepburn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="39" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="Spencer" lemma="Spencer" stem="spencer" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="41" string="Tracy" lemma="Tracy" stem="traci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NN Bit) (NN part)) (PP (IN after) (NP (NN bit) (NN part)))) (VP (VBD stretched) (NP (PRP$ her) (NN stay)) (PP (TO to) (NP (CD six) (NNS months))))) (CC and) (S (NP (PRP she)) (VP (VBD became) (NP (DT a) (NNP Hollywood) (NN fixture)) (, ,) (S (VP (VBG taking) (NP (JJ second) (NN billing)) (PP (IN in) (NP (NP (DT the) (NNS years)) (SBAR (WHNP (WDT that)) (S (VP (VBD followed) (PP (TO to) (NP (NN everyone))) (PP (IN from) (NP (NP (DT The) (CD Three) (NNS Stooges)) (CC and) (NP (NNP Buster) (NNP Keaton)))) (PP (TO to) (NP (NP (NNP Katharine) (NNP Hepburn)) (CC and) (NP (NNP Spencer) (NNP Tracy))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Bit part" type="NP">
          <tokens>
            <token id="1" string="Bit" />
            <token id="2" string="part" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Three Stooges and Buster Keaton" type="NP">
          <tokens>
            <token id="30" string="The" />
            <token id="31" string="Three" />
            <token id="32" string="Stooges" />
            <token id="33" string="and" />
            <token id="34" string="Buster" />
            <token id="35" string="Keaton" />
          </tokens>
        </chunking>
        <chunking id="3" string="stretched her stay to six months" type="VP">
          <tokens>
            <token id="6" string="stretched" />
            <token id="7" string="her" />
            <token id="8" string="stay" />
            <token id="9" string="to" />
            <token id="10" string="six" />
            <token id="11" string="months" />
          </tokens>
        </chunking>
        <chunking id="4" string="Katharine Hepburn" type="NP">
          <tokens>
            <token id="37" string="Katharine" />
            <token id="38" string="Hepburn" />
          </tokens>
        </chunking>
        <chunking id="5" string="Spencer Tracy" type="NP">
          <tokens>
            <token id="40" string="Spencer" />
            <token id="41" string="Tracy" />
          </tokens>
        </chunking>
        <chunking id="6" string="six months" type="NP">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="months" />
          </tokens>
        </chunking>
        <chunking id="7" string="taking second billing in the years that followed to everyone from The Three Stooges and Buster Keaton to Katharine Hepburn and Spencer Tracy" type="VP">
          <tokens>
            <token id="19" string="taking" />
            <token id="20" string="second" />
            <token id="21" string="billing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="years" />
            <token id="25" string="that" />
            <token id="26" string="followed" />
            <token id="27" string="to" />
            <token id="28" string="everyone" />
            <token id="29" string="from" />
            <token id="30" string="The" />
            <token id="31" string="Three" />
            <token id="32" string="Stooges" />
            <token id="33" string="and" />
            <token id="34" string="Buster" />
            <token id="35" string="Keaton" />
            <token id="36" string="to" />
            <token id="37" string="Katharine" />
            <token id="38" string="Hepburn" />
            <token id="39" string="and" />
            <token id="40" string="Spencer" />
            <token id="41" string="Tracy" />
          </tokens>
        </chunking>
        <chunking id="8" string="the years" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="years" />
          </tokens>
        </chunking>
        <chunking id="9" string="everyone" type="NP">
          <tokens>
            <token id="28" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="10" string="Buster Keaton" type="NP">
          <tokens>
            <token id="34" string="Buster" />
            <token id="35" string="Keaton" />
          </tokens>
        </chunking>
        <chunking id="11" string="Bit part after bit part" type="NP">
          <tokens>
            <token id="1" string="Bit" />
            <token id="2" string="part" />
            <token id="3" string="after" />
            <token id="4" string="bit" />
            <token id="5" string="part" />
          </tokens>
        </chunking>
        <chunking id="12" string="she" type="NP">
          <tokens>
            <token id="13" string="she" />
          </tokens>
        </chunking>
        <chunking id="13" string="bit part" type="NP">
          <tokens>
            <token id="4" string="bit" />
            <token id="5" string="part" />
          </tokens>
        </chunking>
        <chunking id="14" string="became a Hollywood fixture , taking second billing in the years that followed to everyone from The Three Stooges and Buster Keaton to Katharine Hepburn and Spencer Tracy" type="VP">
          <tokens>
            <token id="14" string="became" />
            <token id="15" string="a" />
            <token id="16" string="Hollywood" />
            <token id="17" string="fixture" />
            <token id="18" string="," />
            <token id="19" string="taking" />
            <token id="20" string="second" />
            <token id="21" string="billing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="years" />
            <token id="25" string="that" />
            <token id="26" string="followed" />
            <token id="27" string="to" />
            <token id="28" string="everyone" />
            <token id="29" string="from" />
            <token id="30" string="The" />
            <token id="31" string="Three" />
            <token id="32" string="Stooges" />
            <token id="33" string="and" />
            <token id="34" string="Buster" />
            <token id="35" string="Keaton" />
            <token id="36" string="to" />
            <token id="37" string="Katharine" />
            <token id="38" string="Hepburn" />
            <token id="39" string="and" />
            <token id="40" string="Spencer" />
            <token id="41" string="Tracy" />
          </tokens>
        </chunking>
        <chunking id="15" string="that followed to everyone from The Three Stooges and Buster Keaton to Katharine Hepburn and Spencer Tracy" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="followed" />
            <token id="27" string="to" />
            <token id="28" string="everyone" />
            <token id="29" string="from" />
            <token id="30" string="The" />
            <token id="31" string="Three" />
            <token id="32" string="Stooges" />
            <token id="33" string="and" />
            <token id="34" string="Buster" />
            <token id="35" string="Keaton" />
            <token id="36" string="to" />
            <token id="37" string="Katharine" />
            <token id="38" string="Hepburn" />
            <token id="39" string="and" />
            <token id="40" string="Spencer" />
            <token id="41" string="Tracy" />
          </tokens>
        </chunking>
        <chunking id="16" string="her stay" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="stay" />
          </tokens>
        </chunking>
        <chunking id="17" string="The Three Stooges" type="NP">
          <tokens>
            <token id="30" string="The" />
            <token id="31" string="Three" />
            <token id="32" string="Stooges" />
          </tokens>
        </chunking>
        <chunking id="18" string="Katharine Hepburn and Spencer Tracy" type="NP">
          <tokens>
            <token id="37" string="Katharine" />
            <token id="38" string="Hepburn" />
            <token id="39" string="and" />
            <token id="40" string="Spencer" />
            <token id="41" string="Tracy" />
          </tokens>
        </chunking>
        <chunking id="19" string="a Hollywood fixture" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="Hollywood" />
            <token id="17" string="fixture" />
          </tokens>
        </chunking>
        <chunking id="20" string="second billing" type="NP">
          <tokens>
            <token id="20" string="second" />
            <token id="21" string="billing" />
          </tokens>
        </chunking>
        <chunking id="21" string="the years that followed to everyone from The Three Stooges and Buster Keaton to Katharine Hepburn and Spencer Tracy" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="years" />
            <token id="25" string="that" />
            <token id="26" string="followed" />
            <token id="27" string="to" />
            <token id="28" string="everyone" />
            <token id="29" string="from" />
            <token id="30" string="The" />
            <token id="31" string="Three" />
            <token id="32" string="Stooges" />
            <token id="33" string="and" />
            <token id="34" string="Buster" />
            <token id="35" string="Keaton" />
            <token id="36" string="to" />
            <token id="37" string="Katharine" />
            <token id="38" string="Hepburn" />
            <token id="39" string="and" />
            <token id="40" string="Spencer" />
            <token id="41" string="Tracy" />
          </tokens>
        </chunking>
        <chunking id="22" string="followed to everyone from The Three Stooges and Buster Keaton to Katharine Hepburn and Spencer Tracy" type="VP">
          <tokens>
            <token id="26" string="followed" />
            <token id="27" string="to" />
            <token id="28" string="everyone" />
            <token id="29" string="from" />
            <token id="30" string="The" />
            <token id="31" string="Three" />
            <token id="32" string="Stooges" />
            <token id="33" string="and" />
            <token id="34" string="Buster" />
            <token id="35" string="Keaton" />
            <token id="36" string="to" />
            <token id="37" string="Katharine" />
            <token id="38" string="Hepburn" />
            <token id="39" string="and" />
            <token id="40" string="Spencer" />
            <token id="41" string="Tracy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">part</governor>
          <dependent id="1">Bit</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">stretched</governor>
          <dependent id="2">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">part</governor>
          <dependent id="3">after</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">part</governor>
          <dependent id="4">bit</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">part</governor>
          <dependent id="5">part</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">stretched</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">stay</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">stretched</governor>
          <dependent id="8">stay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">months</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">months</governor>
          <dependent id="10">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">stretched</governor>
          <dependent id="11">months</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">stretched</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">became</governor>
          <dependent id="13">she</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">stretched</governor>
          <dependent id="14">became</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">fixture</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">fixture</governor>
          <dependent id="16">Hollywood</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">became</governor>
          <dependent id="17">fixture</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">became</governor>
          <dependent id="19">taking</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">billing</governor>
          <dependent id="20">second</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">taking</governor>
          <dependent id="21">billing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">years</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">years</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">taking</governor>
          <dependent id="24">years</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">followed</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">years</governor>
          <dependent id="26">followed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">everyone</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">followed</governor>
          <dependent id="28">everyone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Stooges</governor>
          <dependent id="29">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">Stooges</governor>
          <dependent id="30">The</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="32">Stooges</governor>
          <dependent id="31">Three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">followed</governor>
          <dependent id="32">Stooges</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">Stooges</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Keaton</governor>
          <dependent id="34">Buster</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">Stooges</governor>
          <dependent id="35">Keaton</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">Hepburn</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="38">Hepburn</governor>
          <dependent id="37">Katharine</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">followed</governor>
          <dependent id="38">Hepburn</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="38">Hepburn</governor>
          <dependent id="39">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">Tracy</governor>
          <dependent id="40">Spencer</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="38">Hepburn</governor>
          <dependent id="41">Tracy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="2" string="Katharine Hepburn" type="PERSON" score="0.0">
          <tokens>
            <token id="37" string="Katharine" />
            <token id="38" string="Hepburn" />
          </tokens>
        </entity>
        <entity id="3" string="Spencer Tracy" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="Spencer" />
            <token id="41" string="Tracy" />
          </tokens>
        </entity>
        <entity id="4" string="six months" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="months" />
          </tokens>
        </entity>
        <entity id="5" string="the years" type="DURATION" score="0.0">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="years" />
          </tokens>
        </entity>
        <entity id="6" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="20" string="second" />
          </tokens>
        </entity>
        <entity id="7" string="Buster Keaton" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Buster" />
            <token id="35" string="Keaton" />
          </tokens>
        </entity>
        <entity id="8" string="Three" type="NUMBER" score="0.0">
          <tokens>
            <token id="31" string="Three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="71" has_coreference="true">
      <content>Along the way, she dyed her hair a fiery red and was given the unofficial title of &amp;quot;Queen of the Bs.&amp;quot;</content>
      <tokens>
        <token id="1" string="Along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="dyed" lemma="dye" stem="dy" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="hair" lemma="hair" stem="hair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="fiery" lemma="fiery" stem="fieri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="red" lemma="red" stem="red" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="unofficial" lemma="unofficial" stem="unoffici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="title" lemma="title" stem="titl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Queen" lemma="Queen" stem="queen" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Bs" lemma="b" stem="b" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Along) (NP (DT the) (NN way))) (, ,) (NP (PRP she)) (VP (VP (VBD dyed) (NP (PRP$ her) (NN hair)) (NP (DT a) (JJ fiery) (JJ red))) (CC and) (VP (VBD was) (VP (VBN given) (NP (NP (DT the) (JJ unofficial) (NN title)) (PP (IN of) (`` ``) (NP (NP (NNP Queen)) (PP (IN of) (NP (DT the) (NNS Bs))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the unofficial title of `` Queen of the Bs" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="unofficial" />
            <token id="17" string="title" />
            <token id="18" string="of" />
            <token id="19" string="&quot;" />
            <token id="20" string="Queen" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Bs" />
          </tokens>
        </chunking>
        <chunking id="2" string="Queen" type="NP">
          <tokens>
            <token id="20" string="Queen" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Bs" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Bs" />
          </tokens>
        </chunking>
        <chunking id="4" string="her hair" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="hair" />
          </tokens>
        </chunking>
        <chunking id="5" string="dyed her hair a fiery red and was given the unofficial title of `` Queen of the Bs" type="VP">
          <tokens>
            <token id="6" string="dyed" />
            <token id="7" string="her" />
            <token id="8" string="hair" />
            <token id="9" string="a" />
            <token id="10" string="fiery" />
            <token id="11" string="red" />
            <token id="12" string="and" />
            <token id="13" string="was" />
            <token id="14" string="given" />
            <token id="15" string="the" />
            <token id="16" string="unofficial" />
            <token id="17" string="title" />
            <token id="18" string="of" />
            <token id="19" string="&quot;" />
            <token id="20" string="Queen" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Bs" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="the way" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="way" />
          </tokens>
        </chunking>
        <chunking id="8" string="a fiery red" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="fiery" />
            <token id="11" string="red" />
          </tokens>
        </chunking>
        <chunking id="9" string="Queen of the Bs" type="NP">
          <tokens>
            <token id="20" string="Queen" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Bs" />
          </tokens>
        </chunking>
        <chunking id="10" string="given the unofficial title of `` Queen of the Bs" type="VP">
          <tokens>
            <token id="14" string="given" />
            <token id="15" string="the" />
            <token id="16" string="unofficial" />
            <token id="17" string="title" />
            <token id="18" string="of" />
            <token id="19" string="&quot;" />
            <token id="20" string="Queen" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Bs" />
          </tokens>
        </chunking>
        <chunking id="11" string="dyed her hair a fiery red" type="VP">
          <tokens>
            <token id="6" string="dyed" />
            <token id="7" string="her" />
            <token id="8" string="hair" />
            <token id="9" string="a" />
            <token id="10" string="fiery" />
            <token id="11" string="red" />
          </tokens>
        </chunking>
        <chunking id="12" string="the unofficial title" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="unofficial" />
            <token id="17" string="title" />
          </tokens>
        </chunking>
        <chunking id="13" string="was given the unofficial title of `` Queen of the Bs" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="given" />
            <token id="15" string="the" />
            <token id="16" string="unofficial" />
            <token id="17" string="title" />
            <token id="18" string="of" />
            <token id="19" string="&quot;" />
            <token id="20" string="Queen" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Bs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">way</governor>
          <dependent id="1">Along</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">way</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">dyed</governor>
          <dependent id="3">way</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">dyed</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">dyed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">hair</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">dyed</governor>
          <dependent id="8">hair</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">red</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">red</governor>
          <dependent id="10">fiery</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">dyed</governor>
          <dependent id="11">red</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">dyed</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">given</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">dyed</governor>
          <dependent id="14">given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">title</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">title</governor>
          <dependent id="16">unofficial</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">given</governor>
          <dependent id="17">title</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Queen</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">title</governor>
          <dependent id="20">Queen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Bs</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Bs</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Queen</governor>
          <dependent id="23">Bs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Queen" type="TITLE" score="0.0">
          <tokens>
            <token id="20" string="Queen" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="72" has_coreference="true">
      <content>Reviewers noted her &amp;quot;pert presence&amp;quot; and talent for &amp;quot;rubber-faced slapstick clowning.&amp;quot;</content>
      <tokens>
        <token id="1" string="Reviewers" lemma="reviewer" stem="review" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="noted" lemma="note" stem="note" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="pert" lemma="pert" stem="pert" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="presence" lemma="presence" stem="presenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="talent" lemma="talent" stem="talent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="rubber-faced" lemma="rubber-faced" stem="rubber-fac" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="slapstick" lemma="slapstick" stem="slapstick" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="clowning" lemma="clowning" stem="clown" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Reviewers)) (VP (VBD noted) (S (NP (PRP her)) (NP (NP (`` ``) (JJ pert) (NN presence) ('' '')) (CC and) (NP (NN talent)))) (PP (IN for) (`` ``) (NP (JJ rubber-faced) (NN slapstick) (NN clowning)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="talent" type="NP">
          <tokens>
            <token id="9" string="talent" />
          </tokens>
        </chunking>
        <chunking id="2" string="rubber-faced slapstick clowning" type="NP">
          <tokens>
            <token id="12" string="rubber-faced" />
            <token id="13" string="slapstick" />
            <token id="14" string="clowning" />
          </tokens>
        </chunking>
        <chunking id="3" string="noted her `` pert presence '' and talent for `` rubber-faced slapstick clowning" type="VP">
          <tokens>
            <token id="2" string="noted" />
            <token id="3" string="her" />
            <token id="4" string="&quot;" />
            <token id="5" string="pert" />
            <token id="6" string="presence" />
            <token id="7" string="&quot;" />
            <token id="8" string="and" />
            <token id="9" string="talent" />
            <token id="10" string="for" />
            <token id="11" string="&quot;" />
            <token id="12" string="rubber-faced" />
            <token id="13" string="slapstick" />
            <token id="14" string="clowning" />
          </tokens>
        </chunking>
        <chunking id="4" string="her" type="NP">
          <tokens>
            <token id="3" string="her" />
          </tokens>
        </chunking>
        <chunking id="5" string="Reviewers" type="NP">
          <tokens>
            <token id="1" string="Reviewers" />
          </tokens>
        </chunking>
        <chunking id="6" string="`` pert presence '' and talent" type="NP">
          <tokens>
            <token id="4" string="&quot;" />
            <token id="5" string="pert" />
            <token id="6" string="presence" />
            <token id="7" string="&quot;" />
            <token id="8" string="and" />
            <token id="9" string="talent" />
          </tokens>
        </chunking>
        <chunking id="7" string="`` pert presence ''" type="NP">
          <tokens>
            <token id="4" string="&quot;" />
            <token id="5" string="pert" />
            <token id="6" string="presence" />
            <token id="7" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">noted</governor>
          <dependent id="1">Reviewers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">noted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">presence</governor>
          <dependent id="3">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">presence</governor>
          <dependent id="5">pert</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">noted</governor>
          <dependent id="6">presence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">presence</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">presence</governor>
          <dependent id="9">talent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">clowning</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">clowning</governor>
          <dependent id="12">rubber-faced</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">clowning</governor>
          <dependent id="13">slapstick</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">noted</governor>
          <dependent id="14">clowning</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="73" has_coreference="true">
      <content>She was described in one newspaper as a &amp;quot;slangy, breezy wisecracking gal with a bebop rhythm to her walk.&amp;quot;</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="described" lemma="describe" stem="describ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="newspaper" lemma="newspaper" stem="newspap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="slangy" lemma="slangy" stem="slangi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="breezy" lemma="breezy" stem="breezi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="wisecracking" lemma="wisecracking" stem="wisecrack" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="gal" lemma="gal" stem="gal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="bebop" lemma="bebop" stem="bebop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="rhythm" lemma="rhythm" stem="rhythm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="walk" lemma="walk" stem="walk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD was) (VP (VBN described) (PP (IN in) (NP (NP (CD one) (NN newspaper)) (PP (IN as) (NP (NP (DT a) (`` ``) (JJ slangy) (, ,) (JJ breezy) (JJ wisecracking) (NN gal)) (PP (IN with) (NP (DT a) (NN bebop) (NN rhythm))))))) (PP (TO to) (NP (PRP$ her) (NN walk))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a bebop rhythm" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="bebop" />
            <token id="18" string="rhythm" />
          </tokens>
        </chunking>
        <chunking id="2" string="her walk" type="NP">
          <tokens>
            <token id="20" string="her" />
            <token id="21" string="walk" />
          </tokens>
        </chunking>
        <chunking id="3" string="described in one newspaper as a `` slangy , breezy wisecracking gal with a bebop rhythm to her walk" type="VP">
          <tokens>
            <token id="3" string="described" />
            <token id="4" string="in" />
            <token id="5" string="one" />
            <token id="6" string="newspaper" />
            <token id="7" string="as" />
            <token id="8" string="a" />
            <token id="9" string="&quot;" />
            <token id="10" string="slangy" />
            <token id="11" string="," />
            <token id="12" string="breezy" />
            <token id="13" string="wisecracking" />
            <token id="14" string="gal" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="bebop" />
            <token id="18" string="rhythm" />
            <token id="19" string="to" />
            <token id="20" string="her" />
            <token id="21" string="walk" />
          </tokens>
        </chunking>
        <chunking id="4" string="a `` slangy , breezy wisecracking gal with a bebop rhythm" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="&quot;" />
            <token id="10" string="slangy" />
            <token id="11" string="," />
            <token id="12" string="breezy" />
            <token id="13" string="wisecracking" />
            <token id="14" string="gal" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="bebop" />
            <token id="18" string="rhythm" />
          </tokens>
        </chunking>
        <chunking id="5" string="one newspaper" type="NP">
          <tokens>
            <token id="5" string="one" />
            <token id="6" string="newspaper" />
          </tokens>
        </chunking>
        <chunking id="6" string="a `` slangy , breezy wisecracking gal" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="&quot;" />
            <token id="10" string="slangy" />
            <token id="11" string="," />
            <token id="12" string="breezy" />
            <token id="13" string="wisecracking" />
            <token id="14" string="gal" />
          </tokens>
        </chunking>
        <chunking id="7" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="8" string="was described in one newspaper as a `` slangy , breezy wisecracking gal with a bebop rhythm to her walk" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="described" />
            <token id="4" string="in" />
            <token id="5" string="one" />
            <token id="6" string="newspaper" />
            <token id="7" string="as" />
            <token id="8" string="a" />
            <token id="9" string="&quot;" />
            <token id="10" string="slangy" />
            <token id="11" string="," />
            <token id="12" string="breezy" />
            <token id="13" string="wisecracking" />
            <token id="14" string="gal" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="bebop" />
            <token id="18" string="rhythm" />
            <token id="19" string="to" />
            <token id="20" string="her" />
            <token id="21" string="walk" />
          </tokens>
        </chunking>
        <chunking id="9" string="one newspaper as a `` slangy , breezy wisecracking gal with a bebop rhythm" type="NP">
          <tokens>
            <token id="5" string="one" />
            <token id="6" string="newspaper" />
            <token id="7" string="as" />
            <token id="8" string="a" />
            <token id="9" string="&quot;" />
            <token id="10" string="slangy" />
            <token id="11" string="," />
            <token id="12" string="breezy" />
            <token id="13" string="wisecracking" />
            <token id="14" string="gal" />
            <token id="15" string="with" />
            <token id="16" string="a" />
            <token id="17" string="bebop" />
            <token id="18" string="rhythm" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">described</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">described</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">described</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">newspaper</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">newspaper</governor>
          <dependent id="5">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">described</governor>
          <dependent id="6">newspaper</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">gal</governor>
          <dependent id="7">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">gal</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">gal</governor>
          <dependent id="10">slangy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">gal</governor>
          <dependent id="12">breezy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">gal</governor>
          <dependent id="13">wisecracking</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">newspaper</governor>
          <dependent id="14">gal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">rhythm</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">rhythm</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">rhythm</governor>
          <dependent id="17">bebop</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">gal</governor>
          <dependent id="18">rhythm</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">walk</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">walk</governor>
          <dependent id="20">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">described</governor>
          <dependent id="21">walk</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="74" has_coreference="true">
      <content>Said another, &amp;quot;Pretty Lucille Ball . . . was born for the parts Ginger Rogers sweats over.&amp;quot;</content>
      <tokens>
        <token id="1" string="Said" lemma="Said" stem="said" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Pretty" lemma="Pretty" stem="pretti" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="parts" lemma="part" stem="part" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Ginger" lemma="Ginger" stem="ginger" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Rogers" lemma="Rogers" stem="roger" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="sweats" lemma="sweat" stem="sweat" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Said)) (NP (DT another))) (, ,) (`` ``) (NP (NNP Pretty) (NNP Lucille) (NNP Ball)) (: ...)) (VP (VBD was) (VP (VBN born) (PP (IN for) (NP (DT the) (NNS parts)) (NP-TMP (NP (NNP Ginger) (NNP Rogers) (NNS sweats)) (IN over))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Said another , `` Pretty Lucille Ball ..." type="NP">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="another" />
            <token id="3" string="," />
            <token id="4" string="&quot;" />
            <token id="5" string="Pretty" />
            <token id="6" string="Lucille" />
            <token id="7" string="Ball" />
            <token id="8" string=". . ." />
          </tokens>
        </chunking>
        <chunking id="2" string="was born for the parts Ginger Rogers sweats over" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="born" />
            <token id="11" string="for" />
            <token id="12" string="the" />
            <token id="13" string="parts" />
            <token id="14" string="Ginger" />
            <token id="15" string="Rogers" />
            <token id="16" string="sweats" />
            <token id="17" string="over" />
          </tokens>
        </chunking>
        <chunking id="3" string="born for the parts Ginger Rogers sweats over" type="VP">
          <tokens>
            <token id="10" string="born" />
            <token id="11" string="for" />
            <token id="12" string="the" />
            <token id="13" string="parts" />
            <token id="14" string="Ginger" />
            <token id="15" string="Rogers" />
            <token id="16" string="sweats" />
            <token id="17" string="over" />
          </tokens>
        </chunking>
        <chunking id="4" string="the parts" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="parts" />
          </tokens>
        </chunking>
        <chunking id="5" string="another" type="NP">
          <tokens>
            <token id="2" string="another" />
          </tokens>
        </chunking>
        <chunking id="6" string="Pretty Lucille Ball" type="NP">
          <tokens>
            <token id="5" string="Pretty" />
            <token id="6" string="Lucille" />
            <token id="7" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="7" string="Said another" type="NP">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="another" />
          </tokens>
        </chunking>
        <chunking id="8" string="Said" type="NP">
          <tokens>
            <token id="1" string="Said" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ginger Rogers sweats" type="NP">
          <tokens>
            <token id="14" string="Ginger" />
            <token id="15" string="Rogers" />
            <token id="16" string="sweats" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="10">born</governor>
          <dependent id="1">Said</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Said</governor>
          <dependent id="2">another</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Ball</governor>
          <dependent id="5">Pretty</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Ball</governor>
          <dependent id="6">Lucille</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Said</governor>
          <dependent id="7">Ball</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">born</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">born</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">parts</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">parts</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">born</governor>
          <dependent id="13">parts</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">sweats</governor>
          <dependent id="14">Ginger</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">sweats</governor>
          <dependent id="15">Rogers</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">parts</governor>
          <dependent id="16">sweats</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">sweats</governor>
          <dependent id="17">over</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucille Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Lucille" />
            <token id="7" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="75" has_coreference="true">
      <content>Playing the ingenue lead in the 1940 musical &amp;quot;Too Many Girls,&amp;quot; Miss Ball met rumba singer Arnaz, cast as a Cuban football player.</content>
      <tokens>
        <token id="1" string="Playing" lemma="play" stem="plai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="ingenue" lemma="ingenue" stem="ingenu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="lead" lemma="lead" stem="lead" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="1940" lemma="1940" stem="1940" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="musical" lemma="musical" stem="music" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Girls" lemma="girl" stem="girl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="met" lemma="meet" stem="met" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="rumba" lemma="rumba" stem="rumba" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="singer" lemma="singer" stem="singer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="cast" lemma="cast" stem="cast" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Cuban" lemma="cuban" stem="cuban" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="26" string="football" lemma="football" stem="footbal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="player" lemma="player" stem="player" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Playing) (NP (DT the) (NN ingenue) (NN lead)) (PP (IN in) (NP (DT the) (CD 1940))) (NP-TMP (NP (JJ musical)) (NP (`` ``) (RB Too) (JJ Many) (NNS Girls))))) (PRN (, ,) ('' '') (S (NP (NNP Miss) (NNP Ball)) (VP (VBD met) (S (NP (NN rumba) (NN singer)) (NP (NNP Arnaz))))) (, ,)) (VP (VBD cast) (PP (IN as) (NP (DT a) (JJ Cuban) (NN football) (NN player)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the 1940" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="1940" />
          </tokens>
        </chunking>
        <chunking id="2" string="cast as a Cuban football player" type="VP">
          <tokens>
            <token id="22" string="cast" />
            <token id="23" string="as" />
            <token id="24" string="a" />
            <token id="25" string="Cuban" />
            <token id="26" string="football" />
            <token id="27" string="player" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` Too Many Girls" type="NP">
          <tokens>
            <token id="9" string="&quot;" />
            <token id="10" string="Too" />
            <token id="11" string="Many" />
            <token id="12" string="Girls" />
          </tokens>
        </chunking>
        <chunking id="4" string="a Cuban football player" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="Cuban" />
            <token id="26" string="football" />
            <token id="27" string="player" />
          </tokens>
        </chunking>
        <chunking id="5" string="met rumba singer Arnaz" type="VP">
          <tokens>
            <token id="17" string="met" />
            <token id="18" string="rumba" />
            <token id="19" string="singer" />
            <token id="20" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="6" string="rumba singer" type="NP">
          <tokens>
            <token id="18" string="rumba" />
            <token id="19" string="singer" />
          </tokens>
        </chunking>
        <chunking id="7" string="the ingenue lead" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="ingenue" />
            <token id="4" string="lead" />
          </tokens>
        </chunking>
        <chunking id="8" string="musical" type="NP">
          <tokens>
            <token id="8" string="musical" />
          </tokens>
        </chunking>
        <chunking id="9" string="Arnaz" type="NP">
          <tokens>
            <token id="20" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="10" string="Playing the ingenue lead in the 1940 musical `` Too Many Girls" type="VP">
          <tokens>
            <token id="1" string="Playing" />
            <token id="2" string="the" />
            <token id="3" string="ingenue" />
            <token id="4" string="lead" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="1940" />
            <token id="8" string="musical" />
            <token id="9" string="&quot;" />
            <token id="10" string="Too" />
            <token id="11" string="Many" />
            <token id="12" string="Girls" />
          </tokens>
        </chunking>
        <chunking id="11" string="Miss Ball" type="NP">
          <tokens>
            <token id="15" string="Miss" />
            <token id="16" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="csubj">
          <governor id="22">cast</governor>
          <dependent id="1">Playing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">lead</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">lead</governor>
          <dependent id="3">ingenue</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Playing</governor>
          <dependent id="4">lead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">1940</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">1940</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Playing</governor>
          <dependent id="7">1940</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">Playing</governor>
          <dependent id="8">musical</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">Girls</governor>
          <dependent id="10">Too</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">Girls</governor>
          <dependent id="11">Many</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">musical</governor>
          <dependent id="12">Girls</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Ball</governor>
          <dependent id="15">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">met</governor>
          <dependent id="16">Ball</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="22">cast</governor>
          <dependent id="17">met</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">singer</governor>
          <dependent id="18">rumba</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">Arnaz</governor>
          <dependent id="19">singer</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">met</governor>
          <dependent id="20">Arnaz</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">cast</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">player</governor>
          <dependent id="23">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">player</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">player</governor>
          <dependent id="25">Cuban</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">player</governor>
          <dependent id="26">football</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">cast</governor>
          <dependent id="27">player</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="1940" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="1940" />
          </tokens>
        </entity>
        <entity id="3" string="Cuban" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="25" string="Cuban" />
          </tokens>
        </entity>
        <entity id="4" string="Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Arnaz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="76" has_coreference="true">
      <content>She later told an interviewer, &amp;quot;It was, at least for me, true love from the start.&amp;quot;</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="interviewer" lemma="interviewer" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="least" lemma="least" stem="least" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="love" lemma="love" stem="love" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="start" lemma="start" stem="start" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (ADVP (RB later)) (VP (VBD told) (NP (DT an) (NN interviewer)) (, ,) (`` ``) (S (NP (PRP It)) (VP (VBD was) (, ,) (PP (ADVP (IN at) (JJS least)) (IN for) (NP (PRP me))) (, ,) (NP (NP (JJ true) (NN love)) (PP (IN from) (NP (DT the) (NN start))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="true love from the start" type="NP">
          <tokens>
            <token id="16" string="true" />
            <token id="17" string="love" />
            <token id="18" string="from" />
            <token id="19" string="the" />
            <token id="20" string="start" />
          </tokens>
        </chunking>
        <chunking id="2" string="told an interviewer , `` It was , at least for me , true love from the start" type="VP">
          <tokens>
            <token id="3" string="told" />
            <token id="4" string="an" />
            <token id="5" string="interviewer" />
            <token id="6" string="," />
            <token id="7" string="&quot;" />
            <token id="8" string="It" />
            <token id="9" string="was" />
            <token id="10" string="," />
            <token id="11" string="at" />
            <token id="12" string="least" />
            <token id="13" string="for" />
            <token id="14" string="me" />
            <token id="15" string="," />
            <token id="16" string="true" />
            <token id="17" string="love" />
            <token id="18" string="from" />
            <token id="19" string="the" />
            <token id="20" string="start" />
          </tokens>
        </chunking>
        <chunking id="3" string="an interviewer" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="interviewer" />
          </tokens>
        </chunking>
        <chunking id="4" string="true love" type="NP">
          <tokens>
            <token id="16" string="true" />
            <token id="17" string="love" />
          </tokens>
        </chunking>
        <chunking id="5" string="the start" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="start" />
          </tokens>
        </chunking>
        <chunking id="6" string="me" type="NP">
          <tokens>
            <token id="14" string="me" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="8" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="was , at least for me , true love from the start" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="," />
            <token id="11" string="at" />
            <token id="12" string="least" />
            <token id="13" string="for" />
            <token id="14" string="me" />
            <token id="15" string="," />
            <token id="16" string="true" />
            <token id="17" string="love" />
            <token id="18" string="from" />
            <token id="19" string="the" />
            <token id="20" string="start" />
          </tokens>
        </chunking>
        <chunking id="9" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">told</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">told</governor>
          <dependent id="2">later</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">interviewer</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">told</governor>
          <dependent id="5">interviewer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">love</governor>
          <dependent id="8">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">love</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">me</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="11">at</governor>
          <dependent id="12">least</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">me</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">love</governor>
          <dependent id="14">me</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">love</governor>
          <dependent id="16">true</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">told</governor>
          <dependent id="17">love</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">start</governor>
          <dependent id="18">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">start</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">love</governor>
          <dependent id="20">start</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="77" has_coreference="true">
      <content>Exchanging vows seven months later, the pair began what was for the most part a troubled marriage.</content>
      <tokens>
        <token id="1" string="Exchanging" lemma="exchange" stem="exchang" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="vows" lemma="vow" stem="vow" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="pair" lemma="pair" stem="pair" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="troubled" lemma="troubled" stem="troubl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Exchanging) (VP (VBZ vows)))) (NP-TMP (CD seven) (NNS months) (RB later)) (, ,) (NP (DT the) (NN pair)) (VP (VBD began) (SBAR (WHNP (WP what)) (S (VP (VBD was) (PP (IN for) (NP (NP (DT the) (JJS most) (NN part)) (NP (DT a) (JJ troubled) (NN marriage)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Exchanging vows" type="VP">
          <tokens>
            <token id="1" string="Exchanging" />
            <token id="2" string="vows" />
          </tokens>
        </chunking>
        <chunking id="2" string="vows" type="VP">
          <tokens>
            <token id="2" string="vows" />
          </tokens>
        </chunking>
        <chunking id="3" string="a troubled marriage" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="troubled" />
            <token id="18" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="4" string="began what was for the most part a troubled marriage" type="VP">
          <tokens>
            <token id="9" string="began" />
            <token id="10" string="what" />
            <token id="11" string="was" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="part" />
            <token id="16" string="a" />
            <token id="17" string="troubled" />
            <token id="18" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="5" string="what was for the most part a troubled marriage" type="SBAR">
          <tokens>
            <token id="10" string="what" />
            <token id="11" string="was" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="part" />
            <token id="16" string="a" />
            <token id="17" string="troubled" />
            <token id="18" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="6" string="the pair" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="pair" />
          </tokens>
        </chunking>
        <chunking id="7" string="was for the most part a troubled marriage" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="part" />
            <token id="16" string="a" />
            <token id="17" string="troubled" />
            <token id="18" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="8" string="the most part a troubled marriage" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="part" />
            <token id="16" string="a" />
            <token id="17" string="troubled" />
            <token id="18" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="9" string="the most part" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="part" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="9">began</governor>
          <dependent id="1">Exchanging</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Exchanging</governor>
          <dependent id="2">vows</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">months</governor>
          <dependent id="3">seven</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">began</governor>
          <dependent id="4">months</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">months</governor>
          <dependent id="5">later</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">pair</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">began</governor>
          <dependent id="8">pair</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">began</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">part</governor>
          <dependent id="10">what</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">part</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">part</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">part</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">part</governor>
          <dependent id="14">most</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">began</governor>
          <dependent id="15">part</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">marriage</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">marriage</governor>
          <dependent id="17">troubled</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">part</governor>
          <dependent id="18">marriage</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="seven months later" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="seven" />
            <token id="4" string="months" />
            <token id="5" string="later" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="78" has_coreference="true">
      <content>All but three of their first 11 years of marriage were spent apart.</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="7" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="spent" lemma="spend" stem="spent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="apart" lemma="apart" stem="apart" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (QP (DT All) (CC but) (CD three))) (PP (IN of) (NP (NP (PRP$ their) (JJ first) (CD 11) (NNS years)) (PP (IN of) (NP (NN marriage)))))) (VP (VBD were) (VP (VBN spent) (ADVP (RB apart)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="All but three" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="but" />
            <token id="3" string="three" />
          </tokens>
        </chunking>
        <chunking id="2" string="were spent apart" type="VP">
          <tokens>
            <token id="11" string="were" />
            <token id="12" string="spent" />
            <token id="13" string="apart" />
          </tokens>
        </chunking>
        <chunking id="3" string="marriage" type="NP">
          <tokens>
            <token id="10" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="4" string="their first 11 years of marriage" type="NP">
          <tokens>
            <token id="5" string="their" />
            <token id="6" string="first" />
            <token id="7" string="11" />
            <token id="8" string="years" />
            <token id="9" string="of" />
            <token id="10" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="5" string="All but three of their first 11 years of marriage" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="but" />
            <token id="3" string="three" />
            <token id="4" string="of" />
            <token id="5" string="their" />
            <token id="6" string="first" />
            <token id="7" string="11" />
            <token id="8" string="years" />
            <token id="9" string="of" />
            <token id="10" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="6" string="spent apart" type="VP">
          <tokens>
            <token id="12" string="spent" />
            <token id="13" string="apart" />
          </tokens>
        </chunking>
        <chunking id="7" string="their first 11 years" type="NP">
          <tokens>
            <token id="5" string="their" />
            <token id="6" string="first" />
            <token id="7" string="11" />
            <token id="8" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="3">three</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">All</governor>
          <dependent id="2">but</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">spent</governor>
          <dependent id="3">three</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">years</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">years</governor>
          <dependent id="5">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">years</governor>
          <dependent id="6">first</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">years</governor>
          <dependent id="7">11</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">three</governor>
          <dependent id="8">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">marriage</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">years</governor>
          <dependent id="10">marriage</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">spent</governor>
          <dependent id="11">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">spent</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">spent</governor>
          <dependent id="13">apart</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="6" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="11 years" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="11" />
            <token id="8" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="79" has_coreference="true">
      <content>With Arnaz traveling the country with his band and Miss Ball committed to Hollywood sound stages, the pair spent almost $30,000 on telegrams and long-distance telephone calls.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="traveling" lemma="travel" stem="travel" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="band" lemma="band" stem="band" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="committed" lemma="commit" stem="commit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="sound" lemma="sound" stem="sound" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="stages" lemma="stage" stem="stage" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="pair" lemma="pair" stem="pair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="spent" lemma="spend" stem="spent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="23" string="30,000" lemma="30,000" stem="30,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="telegrams" lemma="telegram" stem="telegram" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="long-distance" lemma="long-distance" stem="long-dist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="telephone" lemma="telephone" stem="telephon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="calls" lemma="call" stem="call" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN With) (S (S (NP (NNP Arnaz)) (VP (VBG traveling) (NP (DT the) (NN country)) (PP (IN with) (NP (PRP$ his) (NN band))))) (CC and) (S (NP (NNP Miss) (NNP Ball)) (VP (VBD committed) (PP (TO to) (NP (NNP Hollywood) (JJ sound) (NNS stages))))))) (, ,) (NP (DT the) (NN pair)) (VP (VBD spent) (NP (QP (RB almost) ($ $) (CD 30,000))) (PP (IN on) (NP (NP (NNS telegrams)) (CC and) (NP (JJ long-distance) (NN telephone) (NNS calls))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="telegrams" type="NP">
          <tokens>
            <token id="25" string="telegrams" />
          </tokens>
        </chunking>
        <chunking id="2" string="Hollywood sound stages" type="NP">
          <tokens>
            <token id="14" string="Hollywood" />
            <token id="15" string="sound" />
            <token id="16" string="stages" />
          </tokens>
        </chunking>
        <chunking id="3" string="almost $ 30,000" type="NP">
          <tokens>
            <token id="21" string="almost" />
            <token id="22" string="$" />
            <token id="23" string="30,000" />
          </tokens>
        </chunking>
        <chunking id="4" string="the pair" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="pair" />
          </tokens>
        </chunking>
        <chunking id="5" string="With Arnaz traveling the country with his band and Miss Ball committed to Hollywood sound stages" type="SBAR">
          <tokens>
            <token id="1" string="With" />
            <token id="2" string="Arnaz" />
            <token id="3" string="traveling" />
            <token id="4" string="the" />
            <token id="5" string="country" />
            <token id="6" string="with" />
            <token id="7" string="his" />
            <token id="8" string="band" />
            <token id="9" string="and" />
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
            <token id="12" string="committed" />
            <token id="13" string="to" />
            <token id="14" string="Hollywood" />
            <token id="15" string="sound" />
            <token id="16" string="stages" />
          </tokens>
        </chunking>
        <chunking id="6" string="telegrams and long-distance telephone calls" type="NP">
          <tokens>
            <token id="25" string="telegrams" />
            <token id="26" string="and" />
            <token id="27" string="long-distance" />
            <token id="28" string="telephone" />
            <token id="29" string="calls" />
          </tokens>
        </chunking>
        <chunking id="7" string="long-distance telephone calls" type="NP">
          <tokens>
            <token id="27" string="long-distance" />
            <token id="28" string="telephone" />
            <token id="29" string="calls" />
          </tokens>
        </chunking>
        <chunking id="8" string="his band" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="band" />
          </tokens>
        </chunking>
        <chunking id="9" string="the country" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="country" />
          </tokens>
        </chunking>
        <chunking id="10" string="traveling the country with his band" type="VP">
          <tokens>
            <token id="3" string="traveling" />
            <token id="4" string="the" />
            <token id="5" string="country" />
            <token id="6" string="with" />
            <token id="7" string="his" />
            <token id="8" string="band" />
          </tokens>
        </chunking>
        <chunking id="11" string="Arnaz" type="NP">
          <tokens>
            <token id="2" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="12" string="committed to Hollywood sound stages" type="VP">
          <tokens>
            <token id="12" string="committed" />
            <token id="13" string="to" />
            <token id="14" string="Hollywood" />
            <token id="15" string="sound" />
            <token id="16" string="stages" />
          </tokens>
        </chunking>
        <chunking id="13" string="Miss Ball" type="NP">
          <tokens>
            <token id="10" string="Miss" />
            <token id="11" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="14" string="spent almost $ 30,000 on telegrams and long-distance telephone calls" type="VP">
          <tokens>
            <token id="20" string="spent" />
            <token id="21" string="almost" />
            <token id="22" string="$" />
            <token id="23" string="30,000" />
            <token id="24" string="on" />
            <token id="25" string="telegrams" />
            <token id="26" string="and" />
            <token id="27" string="long-distance" />
            <token id="28" string="telephone" />
            <token id="29" string="calls" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">traveling</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">traveling</governor>
          <dependent id="2">Arnaz</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">spent</governor>
          <dependent id="3">traveling</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">country</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">traveling</governor>
          <dependent id="5">country</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">band</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">band</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">traveling</governor>
          <dependent id="8">band</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">traveling</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Ball</governor>
          <dependent id="10">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">committed</governor>
          <dependent id="11">Ball</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">traveling</governor>
          <dependent id="12">committed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">stages</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">stages</governor>
          <dependent id="14">Hollywood</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">stages</governor>
          <dependent id="15">sound</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">committed</governor>
          <dependent id="16">stages</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">pair</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">spent</governor>
          <dependent id="19">pair</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">spent</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">$</governor>
          <dependent id="21">almost</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">spent</governor>
          <dependent id="22">$</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">$</governor>
          <dependent id="23">30,000</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">telegrams</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">spent</governor>
          <dependent id="25">telegrams</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">telegrams</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">calls</governor>
          <dependent id="27">long-distance</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">calls</governor>
          <dependent id="28">telephone</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">telegrams</governor>
          <dependent id="29">calls</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="2" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Ball" />
          </tokens>
        </entity>
        <entity id="3" string="Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Arnaz" />
          </tokens>
        </entity>
        <entity id="4" string="$ 30,000" type="MONEY" score="0.0">
          <tokens>
            <token id="22" string="$" />
            <token id="23" string="30,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="80" has_coreference="true">
      <content>&amp;quot;We would end up talking on the phone -- no, fighting on the phone,&amp;quot; Miss Ball told interviewers.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="end" lemma="end" stem="end" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="talking" lemma="talk" stem="talk" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="phone" lemma="phone" stem="phone" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="fighting" lemma="fight" stem="fight" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="phone" lemma="phone" stem="phone" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="interviewers" lemma="interviewer" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP We)) (VP (MD would) (VP (VB end) (PRT (RP up)) (S (VP (VP (VBG talking) (PP (IN on) (NP (NP (DT the) (NN phone)) (: --) (NP (DT no))))) (, ,) (VP (VBG fighting) (PP (IN on) (NP (DT the) (NN phone))))))))) (, ,) ('' '') (NP (NNP Miss) (NNP Ball)) (VP (VBD told) (NP (NNS interviewers))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="no" type="NP">
          <tokens>
            <token id="11" string="no" />
          </tokens>
        </chunking>
        <chunking id="2" string="the phone -- no" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="phone" />
            <token id="10" string="--" />
            <token id="11" string="no" />
          </tokens>
        </chunking>
        <chunking id="3" string="end up talking on the phone -- no , fighting on the phone" type="VP">
          <tokens>
            <token id="4" string="end" />
            <token id="5" string="up" />
            <token id="6" string="talking" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="phone" />
            <token id="10" string="--" />
            <token id="11" string="no" />
            <token id="12" string="," />
            <token id="13" string="fighting" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="phone" />
          </tokens>
        </chunking>
        <chunking id="4" string="interviewers" type="NP">
          <tokens>
            <token id="22" string="interviewers" />
          </tokens>
        </chunking>
        <chunking id="5" string="talking on the phone -- no" type="VP">
          <tokens>
            <token id="6" string="talking" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="phone" />
            <token id="10" string="--" />
            <token id="11" string="no" />
          </tokens>
        </chunking>
        <chunking id="6" string="the phone" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="phone" />
          </tokens>
        </chunking>
        <chunking id="7" string="talking on the phone -- no , fighting on the phone" type="VP">
          <tokens>
            <token id="6" string="talking" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="phone" />
            <token id="10" string="--" />
            <token id="11" string="no" />
            <token id="12" string="," />
            <token id="13" string="fighting" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="phone" />
          </tokens>
        </chunking>
        <chunking id="8" string="would end up talking on the phone -- no , fighting on the phone" type="VP">
          <tokens>
            <token id="3" string="would" />
            <token id="4" string="end" />
            <token id="5" string="up" />
            <token id="6" string="talking" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="phone" />
            <token id="10" string="--" />
            <token id="11" string="no" />
            <token id="12" string="," />
            <token id="13" string="fighting" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="phone" />
          </tokens>
        </chunking>
        <chunking id="9" string="told interviewers" type="VP">
          <tokens>
            <token id="21" string="told" />
            <token id="22" string="interviewers" />
          </tokens>
        </chunking>
        <chunking id="10" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="11" string="fighting on the phone" type="VP">
          <tokens>
            <token id="13" string="fighting" />
            <token id="14" string="on" />
            <token id="15" string="the" />
            <token id="16" string="phone" />
          </tokens>
        </chunking>
        <chunking id="12" string="Miss Ball" type="NP">
          <tokens>
            <token id="19" string="Miss" />
            <token id="20" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">end</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">end</governor>
          <dependent id="3">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">told</governor>
          <dependent id="4">end</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="4">end</governor>
          <dependent id="5">up</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">end</governor>
          <dependent id="6">talking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">phone</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">phone</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">talking</governor>
          <dependent id="9">phone</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">phone</governor>
          <dependent id="11">no</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">talking</governor>
          <dependent id="13">fighting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">phone</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">phone</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">fighting</governor>
          <dependent id="16">phone</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Ball</governor>
          <dependent id="19">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">told</governor>
          <dependent id="20">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">told</governor>
          <dependent id="22">interviewers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="81" has_coreference="true">
      <content>&amp;quot;You can&amp;apost;t have a marriage over the phone.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="phone" lemma="phone" stem="phone" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP You)) (VP (MD ca) (RB n't) (VP (VB have) (NP (NP (DT a) (NN marriage)) (PP (IN over) (NP (DT the) (NN phone)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have a marriage over the phone" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="a" />
            <token id="7" string="marriage" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="phone" />
          </tokens>
        </chunking>
        <chunking id="2" string="ca n't have a marriage over the phone" type="VP">
          <tokens>
            <token id="3" string="ca" />
            <token id="4" string="n't" />
            <token id="5" string="have" />
            <token id="6" string="a" />
            <token id="7" string="marriage" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="phone" />
          </tokens>
        </chunking>
        <chunking id="3" string="a marriage" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="4" string="the phone" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="phone" />
          </tokens>
        </chunking>
        <chunking id="5" string="You" type="NP">
          <tokens>
            <token id="2" string="You" />
          </tokens>
        </chunking>
        <chunking id="6" string="a marriage over the phone" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="marriage" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="phone" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">have</governor>
          <dependent id="2">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">have</governor>
          <dependent id="3">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">have</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">marriage</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">have</governor>
          <dependent id="7">marriage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">phone</governor>
          <dependent id="8">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">phone</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">marriage</governor>
          <dependent id="10">phone</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="82" has_coreference="true">
      <content>You can&amp;apost;t have children over the phone.</content>
      <tokens>
        <token id="1" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="phone" lemma="phone" stem="phone" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP You)) (VP (MD ca) (RB n't) (VP (VB have) (NP (NP (NNS children)) (PP (IN over) (NP (DT the) (NN phone)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have children over the phone" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="children" />
            <token id="6" string="over" />
            <token id="7" string="the" />
            <token id="8" string="phone" />
          </tokens>
        </chunking>
        <chunking id="2" string="children" type="NP">
          <tokens>
            <token id="5" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="the phone" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="phone" />
          </tokens>
        </chunking>
        <chunking id="4" string="ca n't have children over the phone" type="VP">
          <tokens>
            <token id="2" string="ca" />
            <token id="3" string="n't" />
            <token id="4" string="have" />
            <token id="5" string="children" />
            <token id="6" string="over" />
            <token id="7" string="the" />
            <token id="8" string="phone" />
          </tokens>
        </chunking>
        <chunking id="5" string="You" type="NP">
          <tokens>
            <token id="1" string="You" />
          </tokens>
        </chunking>
        <chunking id="6" string="children over the phone" type="NP">
          <tokens>
            <token id="5" string="children" />
            <token id="6" string="over" />
            <token id="7" string="the" />
            <token id="8" string="phone" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">have</governor>
          <dependent id="1">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">have</governor>
          <dependent id="2">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">have</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">have</governor>
          <dependent id="5">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">phone</governor>
          <dependent id="6">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">phone</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">children</governor>
          <dependent id="8">phone</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="83" has_coreference="false">
      <content>It became obvious that something had to be done.&amp;quot;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="obvious" lemma="obvious" stem="obviou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD became) (ADJP (JJ obvious)) (SBAR (IN that) (S (NP (NN something)) (VP (VBD had) (S (VP (TO to) (VP (VB be) (VP (VBN done))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="be done" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="done" />
          </tokens>
        </chunking>
        <chunking id="2" string="obvious" type="ADJP">
          <tokens>
            <token id="3" string="obvious" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="became obvious that something had to be done" type="VP">
          <tokens>
            <token id="2" string="became" />
            <token id="3" string="obvious" />
            <token id="4" string="that" />
            <token id="5" string="something" />
            <token id="6" string="had" />
            <token id="7" string="to" />
            <token id="8" string="be" />
            <token id="9" string="done" />
          </tokens>
        </chunking>
        <chunking id="5" string="that something had to be done" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="something" />
            <token id="6" string="had" />
            <token id="7" string="to" />
            <token id="8" string="be" />
            <token id="9" string="done" />
          </tokens>
        </chunking>
        <chunking id="6" string="something" type="NP">
          <tokens>
            <token id="5" string="something" />
          </tokens>
        </chunking>
        <chunking id="7" string="to be done" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="be" />
            <token id="9" string="done" />
          </tokens>
        </chunking>
        <chunking id="8" string="done" type="VP">
          <tokens>
            <token id="9" string="done" />
          </tokens>
        </chunking>
        <chunking id="9" string="had to be done" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="to" />
            <token id="8" string="be" />
            <token id="9" string="done" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">became</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">became</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">became</governor>
          <dependent id="3">obvious</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">had</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">had</governor>
          <dependent id="5">something</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">became</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">done</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">done</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">had</governor>
          <dependent id="9">done</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="84" has_coreference="true">
      <content>What was done to salvage the marriage was &amp;quot;I Love Lucy.&amp;quot;</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="salvage" lemma="salvage" stem="salvag" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHNP (WP What)) (S (VP (VBD was) (VP (VBN done) (S (VP (TO to) (VP (VB salvage) (NP (DT the) (NN marriage))))))))) (VP (VBD was) (`` ``) (NP (NP (PRP I)) (NP (NNP Love) (NNP Lucy)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="What was done to salvage the marriage" type="SBAR">
          <tokens>
            <token id="1" string="What" />
            <token id="2" string="was" />
            <token id="3" string="done" />
            <token id="4" string="to" />
            <token id="5" string="salvage" />
            <token id="6" string="the" />
            <token id="7" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="2" string="was `` I Love Lucy" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="&quot;" />
            <token id="10" string="I" />
            <token id="11" string="Love" />
            <token id="12" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="3" string="salvage the marriage" type="VP">
          <tokens>
            <token id="5" string="salvage" />
            <token id="6" string="the" />
            <token id="7" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="4" string="the marriage" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="10" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="was done to salvage the marriage" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="done" />
            <token id="4" string="to" />
            <token id="5" string="salvage" />
            <token id="6" string="the" />
            <token id="7" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="7" string="I Love Lucy" type="NP">
          <tokens>
            <token id="10" string="I" />
            <token id="11" string="Love" />
            <token id="12" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="8" string="to salvage the marriage" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="salvage" />
            <token id="6" string="the" />
            <token id="7" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="9" string="done to salvage the marriage" type="VP">
          <tokens>
            <token id="3" string="done" />
            <token id="4" string="to" />
            <token id="5" string="salvage" />
            <token id="6" string="the" />
            <token id="7" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="10" string="Love Lucy" type="NP">
          <tokens>
            <token id="11" string="Love" />
            <token id="12" string="Lucy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">done</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">done</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="10">I</governor>
          <dependent id="3">done</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">salvage</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">done</governor>
          <dependent id="5">salvage</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">marriage</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">salvage</governor>
          <dependent id="7">marriage</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">I</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Lucy</governor>
          <dependent id="11">Love</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">I</governor>
          <dependent id="12">Lucy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="85" has_coreference="true">
      <content>Since CBS was stubbornly opposed to the idea of the heavily accented Arnaz playing the husband, the determined Arnazes created their own Desilu company and took a stage version of their show on the road to gauge public opinion.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="CBS" lemma="CBS" stem="cbs" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="stubbornly" lemma="stubbornly" stem="stubbornli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="opposed" lemma="oppose" stem="oppos" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="idea" lemma="idea" stem="idea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="heavily" lemma="heavily" stem="heavili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="accented" lemma="accented" stem="accent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="playing" lemma="play" stem="plai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="determined" lemma="determine" stem="determin" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="Arnazes" lemma="arnaze" stem="arnaze" pos="NNS" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="created" lemma="create" stem="creat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Desilu" lemma="desilu" stem="desilu" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="25" string="company" lemma="company" stem="compani" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="stage" lemma="stage" stem="stage" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="version" lemma="version" stem="version" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="road" lemma="road" stem="road" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="gauge" lemma="gauge" stem="gaug" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Since) (S (NP (NNP CBS)) (VP (VBD was) (VP (ADVP (RB stubbornly)) (VBN opposed) (PP (TO to) (NP (NP (DT the) (NN idea)) (PP (IN of) (NP (DT the) (ADJP (RB heavily) (JJ accented)) (NNP Arnaz))))) (S (VP (VBG playing) (NP (DT the) (NN husband)))))))) (, ,) (NP (DT the) (ADJP (VBN determined)) (NNS Arnazes)) (VP (VP (VBD created) (NP (PRP$ their) (JJ own) (NN Desilu) (NN company))) (CC and) (VP (VBD took) (NP (NP (DT a) (NN stage) (NN version)) (PP (IN of) (NP (PRP$ their) (NN show)))) (PP (IN on) (NP (DT the) (NN road) (S (VP (TO to) (VP (VB gauge) (NP (JJ public) (NN opinion))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the heavily accented Arnaz" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="heavily" />
            <token id="12" string="accented" />
            <token id="13" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="2" string="the husband" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="husband" />
          </tokens>
        </chunking>
        <chunking id="3" string="created their own Desilu company and took a stage version of their show on the road to gauge public opinion" type="VP">
          <tokens>
            <token id="21" string="created" />
            <token id="22" string="their" />
            <token id="23" string="own" />
            <token id="24" string="Desilu" />
            <token id="25" string="company" />
            <token id="26" string="and" />
            <token id="27" string="took" />
            <token id="28" string="a" />
            <token id="29" string="stage" />
            <token id="30" string="version" />
            <token id="31" string="of" />
            <token id="32" string="their" />
            <token id="33" string="show" />
            <token id="34" string="on" />
            <token id="35" string="the" />
            <token id="36" string="road" />
            <token id="37" string="to" />
            <token id="38" string="gauge" />
            <token id="39" string="public" />
            <token id="40" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="4" string="gauge public opinion" type="VP">
          <tokens>
            <token id="38" string="gauge" />
            <token id="39" string="public" />
            <token id="40" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="5" string="the determined Arnazes" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="determined" />
            <token id="20" string="Arnazes" />
          </tokens>
        </chunking>
        <chunking id="6" string="Since CBS was stubbornly opposed to the idea of the heavily accented Arnaz playing the husband" type="SBAR">
          <tokens>
            <token id="1" string="Since" />
            <token id="2" string="CBS" />
            <token id="3" string="was" />
            <token id="4" string="stubbornly" />
            <token id="5" string="opposed" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="idea" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="heavily" />
            <token id="12" string="accented" />
            <token id="13" string="Arnaz" />
            <token id="14" string="playing" />
            <token id="15" string="the" />
            <token id="16" string="husband" />
          </tokens>
        </chunking>
        <chunking id="7" string="heavily accented" type="ADJP">
          <tokens>
            <token id="11" string="heavily" />
            <token id="12" string="accented" />
          </tokens>
        </chunking>
        <chunking id="8" string="a stage version" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="stage" />
            <token id="30" string="version" />
          </tokens>
        </chunking>
        <chunking id="9" string="CBS" type="NP">
          <tokens>
            <token id="2" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="10" string="their own Desilu company" type="NP">
          <tokens>
            <token id="22" string="their" />
            <token id="23" string="own" />
            <token id="24" string="Desilu" />
            <token id="25" string="company" />
          </tokens>
        </chunking>
        <chunking id="11" string="playing the husband" type="VP">
          <tokens>
            <token id="14" string="playing" />
            <token id="15" string="the" />
            <token id="16" string="husband" />
          </tokens>
        </chunking>
        <chunking id="12" string="created their own Desilu company" type="VP">
          <tokens>
            <token id="21" string="created" />
            <token id="22" string="their" />
            <token id="23" string="own" />
            <token id="24" string="Desilu" />
            <token id="25" string="company" />
          </tokens>
        </chunking>
        <chunking id="13" string="stubbornly opposed to the idea of the heavily accented Arnaz playing the husband" type="VP">
          <tokens>
            <token id="4" string="stubbornly" />
            <token id="5" string="opposed" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="idea" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="heavily" />
            <token id="12" string="accented" />
            <token id="13" string="Arnaz" />
            <token id="14" string="playing" />
            <token id="15" string="the" />
            <token id="16" string="husband" />
          </tokens>
        </chunking>
        <chunking id="14" string="determined" type="ADJP">
          <tokens>
            <token id="19" string="determined" />
          </tokens>
        </chunking>
        <chunking id="15" string="their show" type="NP">
          <tokens>
            <token id="32" string="their" />
            <token id="33" string="show" />
          </tokens>
        </chunking>
        <chunking id="16" string="the road to gauge public opinion" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="road" />
            <token id="37" string="to" />
            <token id="38" string="gauge" />
            <token id="39" string="public" />
            <token id="40" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="17" string="to gauge public opinion" type="VP">
          <tokens>
            <token id="37" string="to" />
            <token id="38" string="gauge" />
            <token id="39" string="public" />
            <token id="40" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="18" string="the idea of the heavily accented Arnaz" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="idea" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="heavily" />
            <token id="12" string="accented" />
            <token id="13" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="19" string="a stage version of their show" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="stage" />
            <token id="30" string="version" />
            <token id="31" string="of" />
            <token id="32" string="their" />
            <token id="33" string="show" />
          </tokens>
        </chunking>
        <chunking id="20" string="public opinion" type="NP">
          <tokens>
            <token id="39" string="public" />
            <token id="40" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="21" string="the idea" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="idea" />
          </tokens>
        </chunking>
        <chunking id="22" string="took a stage version of their show on the road to gauge public opinion" type="VP">
          <tokens>
            <token id="27" string="took" />
            <token id="28" string="a" />
            <token id="29" string="stage" />
            <token id="30" string="version" />
            <token id="31" string="of" />
            <token id="32" string="their" />
            <token id="33" string="show" />
            <token id="34" string="on" />
            <token id="35" string="the" />
            <token id="36" string="road" />
            <token id="37" string="to" />
            <token id="38" string="gauge" />
            <token id="39" string="public" />
            <token id="40" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="23" string="was stubbornly opposed to the idea of the heavily accented Arnaz playing the husband" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="stubbornly" />
            <token id="5" string="opposed" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="idea" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="heavily" />
            <token id="12" string="accented" />
            <token id="13" string="Arnaz" />
            <token id="14" string="playing" />
            <token id="15" string="the" />
            <token id="16" string="husband" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">opposed</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">opposed</governor>
          <dependent id="2">CBS</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">opposed</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">opposed</governor>
          <dependent id="4">stubbornly</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">created</governor>
          <dependent id="5">opposed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">idea</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">idea</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">opposed</governor>
          <dependent id="8">idea</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Arnaz</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Arnaz</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">accented</governor>
          <dependent id="11">heavily</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">Arnaz</governor>
          <dependent id="12">accented</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">idea</governor>
          <dependent id="13">Arnaz</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">opposed</governor>
          <dependent id="14">playing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">husband</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">playing</governor>
          <dependent id="16">husband</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Arnazes</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">Arnazes</governor>
          <dependent id="19">determined</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">created</governor>
          <dependent id="20">Arnazes</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">created</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">company</governor>
          <dependent id="22">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">company</governor>
          <dependent id="23">own</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">company</governor>
          <dependent id="24">Desilu</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">created</governor>
          <dependent id="25">company</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">created</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">created</governor>
          <dependent id="27">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">version</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">version</governor>
          <dependent id="29">stage</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">took</governor>
          <dependent id="30">version</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">show</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">show</governor>
          <dependent id="32">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">version</governor>
          <dependent id="33">show</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">road</governor>
          <dependent id="34">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">road</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">took</governor>
          <dependent id="36">road</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">gauge</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="36">road</governor>
          <dependent id="38">gauge</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">opinion</governor>
          <dependent id="39">public</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">gauge</governor>
          <dependent id="40">opinion</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Desilu" type="MISC" score="0.0">
          <tokens>
            <token id="24" string="Desilu" />
          </tokens>
        </entity>
        <entity id="2" string="CBS" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="CBS" />
          </tokens>
        </entity>
        <entity id="3" string="Arnazes" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Arnazes" />
          </tokens>
        </entity>
        <entity id="4" string="Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Arnaz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="86" has_coreference="true">
      <content>It was a smash, and television executives reluctantly gave &amp;quot;I Love Lucy&amp;quot; a time slot.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="smash" lemma="smash" stem="smash" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="executives" lemma="executive" stem="execut" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="reluctantly" lemma="reluctantly" stem="reluctantli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="slot" lemma="slot" stem="slot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBD was) (NP (DT a) (NN smash)))) (, ,) (CC and) (S (NP (NN television) (NNS executives)) (ADVP (RB reluctantly)) (VP (VBD gave) (NP (`` ``) (NP (PRP I)) (PP (NNP Love) (NP (NNP Lucy))) ('' '') (NP (DT a) (NN time) (NN slot))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was a smash" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="a" />
            <token id="4" string="smash" />
          </tokens>
        </chunking>
        <chunking id="2" string="a smash" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="smash" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` I Love Lucy '' a time slot" type="NP">
          <tokens>
            <token id="11" string="&quot;" />
            <token id="12" string="I" />
            <token id="13" string="Love" />
            <token id="14" string="Lucy" />
            <token id="15" string="&quot;" />
            <token id="16" string="a" />
            <token id="17" string="time" />
            <token id="18" string="slot" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="12" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lucy" type="NP">
          <tokens>
            <token id="14" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="7" string="gave `` I Love Lucy '' a time slot" type="VP">
          <tokens>
            <token id="10" string="gave" />
            <token id="11" string="&quot;" />
            <token id="12" string="I" />
            <token id="13" string="Love" />
            <token id="14" string="Lucy" />
            <token id="15" string="&quot;" />
            <token id="16" string="a" />
            <token id="17" string="time" />
            <token id="18" string="slot" />
          </tokens>
        </chunking>
        <chunking id="8" string="television executives" type="NP">
          <tokens>
            <token id="7" string="television" />
            <token id="8" string="executives" />
          </tokens>
        </chunking>
        <chunking id="9" string="a time slot" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="time" />
            <token id="18" string="slot" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">smash</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">smash</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">smash</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">smash</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">smash</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">executives</governor>
          <dependent id="7">television</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">gave</governor>
          <dependent id="8">executives</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">gave</governor>
          <dependent id="9">reluctantly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">smash</governor>
          <dependent id="10">gave</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">gave</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">Lucy</governor>
          <dependent id="13">Love</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">I</governor>
          <dependent id="14">Lucy</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">slot</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">slot</governor>
          <dependent id="17">time</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">I</governor>
          <dependent id="18">slot</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="87" has_coreference="true">
      <content>&amp;quot;I wanted our characters to have problems,&amp;quot; Miss Ball said of her concept for the show.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="characters" lemma="character" stem="charact" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="16" string="concept" lemma="concept" stem="concept" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD wanted) (NP (PRP$ our) (NNS characters)) (S (VP (TO to) (VP (VB have) (NP (NNS problems))))))) (, ,) ('' '') (NP (NNP Miss) (NNP Ball)) (VP (VBD said) (PP (IN of) (NP (PRP$ her) (NN concept))) (PP (IN for) (NP (DT the) (NN show)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said of her concept for the show" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="of" />
            <token id="15" string="her" />
            <token id="16" string="concept" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="show" />
          </tokens>
        </chunking>
        <chunking id="2" string="wanted our characters to have problems" type="VP">
          <tokens>
            <token id="3" string="wanted" />
            <token id="4" string="our" />
            <token id="5" string="characters" />
            <token id="6" string="to" />
            <token id="7" string="have" />
            <token id="8" string="problems" />
          </tokens>
        </chunking>
        <chunking id="3" string="our characters" type="NP">
          <tokens>
            <token id="4" string="our" />
            <token id="5" string="characters" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="problems" type="NP">
          <tokens>
            <token id="8" string="problems" />
          </tokens>
        </chunking>
        <chunking id="6" string="the show" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="show" />
          </tokens>
        </chunking>
        <chunking id="7" string="to have problems" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="have" />
            <token id="8" string="problems" />
          </tokens>
        </chunking>
        <chunking id="8" string="have problems" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="problems" />
          </tokens>
        </chunking>
        <chunking id="9" string="her concept" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="concept" />
          </tokens>
        </chunking>
        <chunking id="10" string="Miss Ball" type="NP">
          <tokens>
            <token id="11" string="Miss" />
            <token id="12" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">wanted</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="3">wanted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">characters</governor>
          <dependent id="4">our</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">wanted</governor>
          <dependent id="5">characters</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">have</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">wanted</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="8">problems</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Ball</governor>
          <dependent id="11">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">concept</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">concept</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">said</governor>
          <dependent id="16">concept</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">show</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">show</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">said</governor>
          <dependent id="19">show</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="88" has_coreference="true">
      <content>&amp;quot;I wanted to be an average housewife.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="average" lemma="average" stem="averag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="housewife" lemma="housewife" stem="housewif" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD wanted) (S (VP (TO to) (VP (VB be) (NP (DT an) (JJ average) (NN housewife)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to be an average housewife" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="be" />
            <token id="6" string="an" />
            <token id="7" string="average" />
            <token id="8" string="housewife" />
          </tokens>
        </chunking>
        <chunking id="2" string="be an average housewife" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="an" />
            <token id="7" string="average" />
            <token id="8" string="housewife" />
          </tokens>
        </chunking>
        <chunking id="3" string="wanted to be an average housewife" type="VP">
          <tokens>
            <token id="3" string="wanted" />
            <token id="4" string="to" />
            <token id="5" string="be" />
            <token id="6" string="an" />
            <token id="7" string="average" />
            <token id="8" string="housewife" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="an average housewife" type="NP">
          <tokens>
            <token id="6" string="an" />
            <token id="7" string="average" />
            <token id="8" string="housewife" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">wanted</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">housewife</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">housewife</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">housewife</governor>
          <dependent id="6">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">housewife</governor>
          <dependent id="7">average</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">wanted</governor>
          <dependent id="8">housewife</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="89" has_coreference="false">
      <content>A very nosy but very average housewife.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="nosy" lemma="nosy" stem="nosi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="average" lemma="average" stem="averag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="housewife" lemma="housewife" stem="housewif" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (DT A) (ADJP (ADJP (RB very) (JJ nosy)) (CC but) (ADJP (RB very) (JJ average))) (NN housewife)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="very nosy" type="ADJP">
          <tokens>
            <token id="2" string="very" />
            <token id="3" string="nosy" />
          </tokens>
        </chunking>
        <chunking id="2" string="A very nosy but very average housewife" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="very" />
            <token id="3" string="nosy" />
            <token id="4" string="but" />
            <token id="5" string="very" />
            <token id="6" string="average" />
            <token id="7" string="housewife" />
          </tokens>
        </chunking>
        <chunking id="3" string="very nosy but very average" type="ADJP">
          <tokens>
            <token id="2" string="very" />
            <token id="3" string="nosy" />
            <token id="4" string="but" />
            <token id="5" string="very" />
            <token id="6" string="average" />
          </tokens>
        </chunking>
        <chunking id="4" string="very average" type="ADJP">
          <tokens>
            <token id="5" string="very" />
            <token id="6" string="average" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="7">housewife</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">nosy</governor>
          <dependent id="2">very</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">housewife</governor>
          <dependent id="3">nosy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">nosy</governor>
          <dependent id="4">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">average</governor>
          <dependent id="5">very</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">nosy</governor>
          <dependent id="6">average</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">housewife</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="90" has_coreference="true">
      <content>And I wanted my husband to love me.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="love" lemma="love" stem="love" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (PRP I)) (VP (VBD wanted) (NP (PRP$ my) (NN husband) (S (VP (TO to) (VP (VB love) (NP (PRP me))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="my husband to love me" type="NP">
          <tokens>
            <token id="4" string="my" />
            <token id="5" string="husband" />
            <token id="6" string="to" />
            <token id="7" string="love" />
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="to love me" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="love" />
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="me" type="NP">
          <tokens>
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="wanted my husband to love me" type="VP">
          <tokens>
            <token id="3" string="wanted" />
            <token id="4" string="my" />
            <token id="5" string="husband" />
            <token id="6" string="to" />
            <token id="7" string="love" />
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="6" string="love me" type="VP">
          <tokens>
            <token id="7" string="love" />
            <token id="8" string="me" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">wanted</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">wanted</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">wanted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">husband</governor>
          <dependent id="4">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">wanted</governor>
          <dependent id="5">husband</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">love</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">husband</governor>
          <dependent id="7">love</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">love</governor>
          <dependent id="8">me</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="91" has_coreference="true">
      <content>&amp;quot;CBS thought we were out of our minds to want to do it on film.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="CBS" lemma="CBS" stem="cbs" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="minds" lemma="mind" stem="mind" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="want" lemma="want" stem="want" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP CBS)) (VP (VBD thought) (SBAR (S (NP (PRP we)) (VP (VBD were) (ADVP (IN out) (PP (IN of) (NP (PRP$ our) (NNS minds)))) (S (VP (TO to) (VP (VB want) (S (VP (TO to) (VP (VB do) (NP (PRP it)) (PP (IN on) (NP (NN film))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="CBS" type="NP">
          <tokens>
            <token id="2" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="2" string="to want to do it on film" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="it" />
            <token id="15" string="on" />
            <token id="16" string="film" />
          </tokens>
        </chunking>
        <chunking id="3" string="our minds" type="NP">
          <tokens>
            <token id="8" string="our" />
            <token id="9" string="minds" />
          </tokens>
        </chunking>
        <chunking id="4" string="want to do it on film" type="VP">
          <tokens>
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="it" />
            <token id="15" string="on" />
            <token id="16" string="film" />
          </tokens>
        </chunking>
        <chunking id="5" string="were out of our minds to want to do it on film" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="out" />
            <token id="7" string="of" />
            <token id="8" string="our" />
            <token id="9" string="minds" />
            <token id="10" string="to" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="it" />
            <token id="15" string="on" />
            <token id="16" string="film" />
          </tokens>
        </chunking>
        <chunking id="6" string="do it on film" type="VP">
          <tokens>
            <token id="13" string="do" />
            <token id="14" string="it" />
            <token id="15" string="on" />
            <token id="16" string="film" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="thought we were out of our minds to want to do it on film" type="VP">
          <tokens>
            <token id="3" string="thought" />
            <token id="4" string="we" />
            <token id="5" string="were" />
            <token id="6" string="out" />
            <token id="7" string="of" />
            <token id="8" string="our" />
            <token id="9" string="minds" />
            <token id="10" string="to" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="it" />
            <token id="15" string="on" />
            <token id="16" string="film" />
          </tokens>
        </chunking>
        <chunking id="9" string="to do it on film" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="it" />
            <token id="15" string="on" />
            <token id="16" string="film" />
          </tokens>
        </chunking>
        <chunking id="10" string="film" type="NP">
          <tokens>
            <token id="16" string="film" />
          </tokens>
        </chunking>
        <chunking id="11" string="we were out of our minds to want to do it on film" type="SBAR">
          <tokens>
            <token id="4" string="we" />
            <token id="5" string="were" />
            <token id="6" string="out" />
            <token id="7" string="of" />
            <token id="8" string="our" />
            <token id="9" string="minds" />
            <token id="10" string="to" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="do" />
            <token id="14" string="it" />
            <token id="15" string="on" />
            <token id="16" string="film" />
          </tokens>
        </chunking>
        <chunking id="12" string="we" type="NP">
          <tokens>
            <token id="4" string="we" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">thought</governor>
          <dependent id="2">CBS</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">thought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">were</governor>
          <dependent id="4">we</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">thought</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">minds</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="6">out</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">minds</governor>
          <dependent id="8">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">were</governor>
          <dependent id="9">minds</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">want</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">were</governor>
          <dependent id="11">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">do</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">want</governor>
          <dependent id="13">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">do</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">film</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">do</governor>
          <dependent id="16">film</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CBS" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="CBS" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="92" has_coreference="true">
      <content>The episodes were filmed before a live audience by Academy Award-winning cinematographer Karl Freund, famous for his work on such films as &amp;quot;The Good Earth&amp;quot; and Garbo&amp;apost;s &amp;quot;Camille.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="episodes" lemma="episode" stem="episod" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="filmed" lemma="film" stem="film" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="live" lemma="live" stem="live" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="audience" lemma="audience" stem="audienc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Academy" lemma="Academy" stem="academi" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="Award-winning" lemma="award-winning" stem="award-win" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="12" string="cinematographer" lemma="cinematographer" stem="cinematograph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Karl" lemma="Karl" stem="karl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="Freund" lemma="Freund" stem="freund" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="famous" lemma="famous" stem="famou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="films" lemma="film" stem="film" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="26" string="Good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="27" string="Earth" lemma="Earth" stem="earth" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Garbo" lemma="Garbo" stem="garbo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="Camille" lemma="Camille" stem="camil" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS episodes)) (VP (VBD were) (VP (VBN filmed) (PP (IN before) (NP (DT a) (JJ live) (NN audience))) (PP (IN by) (NP (NP (NNP Academy) (JJ Award-winning) (NN cinematographer) (NNP Karl) (NNP Freund)) (, ,) (ADJP (JJ famous) (PP (IN for) (NP (NP (PRP$ his) (NN work)) (PP (IN on) (NP (NP (JJ such) (NNS films)) (PP (IN as) (`` ``) (NP (DT The) (JJ Good) (NNP Earth)) ('' ''))) (CC and) (NP (NP (NNP Garbo) (POS 's)) (`` ``) (NNP Camille)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a live audience" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="live" />
            <token id="8" string="audience" />
          </tokens>
        </chunking>
        <chunking id="2" string="his work on such films as `` The Good Earth '' and Garbo 's `` Camille" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="work" />
            <token id="20" string="on" />
            <token id="21" string="such" />
            <token id="22" string="films" />
            <token id="23" string="as" />
            <token id="24" string="&quot;" />
            <token id="25" string="The" />
            <token id="26" string="Good" />
            <token id="27" string="Earth" />
            <token id="28" string="&quot;" />
            <token id="29" string="and" />
            <token id="30" string="Garbo" />
            <token id="31" string="'s" />
            <token id="32" string="&quot;" />
            <token id="33" string="Camille" />
          </tokens>
        </chunking>
        <chunking id="3" string="The episodes" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="episodes" />
          </tokens>
        </chunking>
        <chunking id="4" string="were filmed before a live audience by Academy Award-winning cinematographer Karl Freund , famous for his work on such films as `` The Good Earth '' and Garbo 's `` Camille" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="filmed" />
            <token id="5" string="before" />
            <token id="6" string="a" />
            <token id="7" string="live" />
            <token id="8" string="audience" />
            <token id="9" string="by" />
            <token id="10" string="Academy" />
            <token id="11" string="Award-winning" />
            <token id="12" string="cinematographer" />
            <token id="13" string="Karl" />
            <token id="14" string="Freund" />
            <token id="15" string="," />
            <token id="16" string="famous" />
            <token id="17" string="for" />
            <token id="18" string="his" />
            <token id="19" string="work" />
            <token id="20" string="on" />
            <token id="21" string="such" />
            <token id="22" string="films" />
            <token id="23" string="as" />
            <token id="24" string="&quot;" />
            <token id="25" string="The" />
            <token id="26" string="Good" />
            <token id="27" string="Earth" />
            <token id="28" string="&quot;" />
            <token id="29" string="and" />
            <token id="30" string="Garbo" />
            <token id="31" string="'s" />
            <token id="32" string="&quot;" />
            <token id="33" string="Camille" />
          </tokens>
        </chunking>
        <chunking id="5" string="filmed before a live audience by Academy Award-winning cinematographer Karl Freund , famous for his work on such films as `` The Good Earth '' and Garbo 's `` Camille" type="VP">
          <tokens>
            <token id="4" string="filmed" />
            <token id="5" string="before" />
            <token id="6" string="a" />
            <token id="7" string="live" />
            <token id="8" string="audience" />
            <token id="9" string="by" />
            <token id="10" string="Academy" />
            <token id="11" string="Award-winning" />
            <token id="12" string="cinematographer" />
            <token id="13" string="Karl" />
            <token id="14" string="Freund" />
            <token id="15" string="," />
            <token id="16" string="famous" />
            <token id="17" string="for" />
            <token id="18" string="his" />
            <token id="19" string="work" />
            <token id="20" string="on" />
            <token id="21" string="such" />
            <token id="22" string="films" />
            <token id="23" string="as" />
            <token id="24" string="&quot;" />
            <token id="25" string="The" />
            <token id="26" string="Good" />
            <token id="27" string="Earth" />
            <token id="28" string="&quot;" />
            <token id="29" string="and" />
            <token id="30" string="Garbo" />
            <token id="31" string="'s" />
            <token id="32" string="&quot;" />
            <token id="33" string="Camille" />
          </tokens>
        </chunking>
        <chunking id="6" string="The Good Earth" type="NP">
          <tokens>
            <token id="25" string="The" />
            <token id="26" string="Good" />
            <token id="27" string="Earth" />
          </tokens>
        </chunking>
        <chunking id="7" string="such films as `` The Good Earth ''" type="NP">
          <tokens>
            <token id="21" string="such" />
            <token id="22" string="films" />
            <token id="23" string="as" />
            <token id="24" string="&quot;" />
            <token id="25" string="The" />
            <token id="26" string="Good" />
            <token id="27" string="Earth" />
            <token id="28" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="8" string="famous for his work on such films as `` The Good Earth '' and Garbo 's `` Camille" type="ADJP">
          <tokens>
            <token id="16" string="famous" />
            <token id="17" string="for" />
            <token id="18" string="his" />
            <token id="19" string="work" />
            <token id="20" string="on" />
            <token id="21" string="such" />
            <token id="22" string="films" />
            <token id="23" string="as" />
            <token id="24" string="&quot;" />
            <token id="25" string="The" />
            <token id="26" string="Good" />
            <token id="27" string="Earth" />
            <token id="28" string="&quot;" />
            <token id="29" string="and" />
            <token id="30" string="Garbo" />
            <token id="31" string="'s" />
            <token id="32" string="&quot;" />
            <token id="33" string="Camille" />
          </tokens>
        </chunking>
        <chunking id="9" string="Garbo 's `` Camille" type="NP">
          <tokens>
            <token id="30" string="Garbo" />
            <token id="31" string="'s" />
            <token id="32" string="&quot;" />
            <token id="33" string="Camille" />
          </tokens>
        </chunking>
        <chunking id="10" string="Academy Award-winning cinematographer Karl Freund , famous for his work on such films as `` The Good Earth '' and Garbo 's `` Camille" type="NP">
          <tokens>
            <token id="10" string="Academy" />
            <token id="11" string="Award-winning" />
            <token id="12" string="cinematographer" />
            <token id="13" string="Karl" />
            <token id="14" string="Freund" />
            <token id="15" string="," />
            <token id="16" string="famous" />
            <token id="17" string="for" />
            <token id="18" string="his" />
            <token id="19" string="work" />
            <token id="20" string="on" />
            <token id="21" string="such" />
            <token id="22" string="films" />
            <token id="23" string="as" />
            <token id="24" string="&quot;" />
            <token id="25" string="The" />
            <token id="26" string="Good" />
            <token id="27" string="Earth" />
            <token id="28" string="&quot;" />
            <token id="29" string="and" />
            <token id="30" string="Garbo" />
            <token id="31" string="'s" />
            <token id="32" string="&quot;" />
            <token id="33" string="Camille" />
          </tokens>
        </chunking>
        <chunking id="11" string="Garbo 's" type="NP">
          <tokens>
            <token id="30" string="Garbo" />
            <token id="31" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="Academy Award-winning cinematographer Karl Freund" type="NP">
          <tokens>
            <token id="10" string="Academy" />
            <token id="11" string="Award-winning" />
            <token id="12" string="cinematographer" />
            <token id="13" string="Karl" />
            <token id="14" string="Freund" />
          </tokens>
        </chunking>
        <chunking id="13" string="his work" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="work" />
          </tokens>
        </chunking>
        <chunking id="14" string="such films" type="NP">
          <tokens>
            <token id="21" string="such" />
            <token id="22" string="films" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">episodes</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">filmed</governor>
          <dependent id="2">episodes</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">filmed</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">filmed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">audience</governor>
          <dependent id="5">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">audience</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">audience</governor>
          <dependent id="7">live</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">filmed</governor>
          <dependent id="8">audience</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Freund</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Freund</governor>
          <dependent id="10">Academy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">Freund</governor>
          <dependent id="11">Award-winning</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Freund</governor>
          <dependent id="12">cinematographer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Freund</governor>
          <dependent id="13">Karl</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">filmed</governor>
          <dependent id="14">Freund</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">Freund</governor>
          <dependent id="16">famous</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">work</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">work</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">famous</governor>
          <dependent id="19">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">films</governor>
          <dependent id="20">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">films</governor>
          <dependent id="21">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">work</governor>
          <dependent id="22">films</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Earth</governor>
          <dependent id="23">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Earth</governor>
          <dependent id="25">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">Earth</governor>
          <dependent id="26">Good</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">films</governor>
          <dependent id="27">Earth</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">films</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">Camille</governor>
          <dependent id="30">Garbo</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Garbo</governor>
          <dependent id="31">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">films</governor>
          <dependent id="33">Camille</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Garbo" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Garbo" />
          </tokens>
        </entity>
        <entity id="2" string="Academy Award-winning" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="Academy" />
            <token id="11" string="Award-winning" />
          </tokens>
        </entity>
        <entity id="3" string="Karl Freund" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Karl" />
            <token id="14" string="Freund" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="93" has_coreference="true">
      <content>When the Arnazes negotiated to keep the films &amp;quot;to show our kids someday,&amp;quot; few in the industry predicted what would happen.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Arnazes" lemma="Arnazes" stem="arnaze" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="negotiated" lemma="negotiate" stem="negoti" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="keep" lemma="keep" stem="keep" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="films" lemma="film" stem="film" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="show" lemma="show" stem="show" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="kids" lemma="kid" stem="kid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="someday" lemma="someday" stem="somedai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="predicted" lemma="predict" stem="predict" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (DT the) (NNPS Arnazes)) (VP (VBD negotiated) (S (VP (TO to) (VP (VB keep) (NP (DT the) (NNS films)) (`` ``) (S (VP (TO to) (VP (VB show) (NP (PRP$ our) (NNS kids)) (ADVP (RB someday))))))))))) (, ,) ('' '') (NP (NP (JJ few)) (PP (IN in) (NP (DT the) (NN industry)))) (VP (VBD predicted) (SBAR (WHNP (WP what)) (S (VP (MD would) (VP (VB happen)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="When the Arnazes negotiated to keep the films `` to show our kids someday" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="the" />
            <token id="3" string="Arnazes" />
            <token id="4" string="negotiated" />
            <token id="5" string="to" />
            <token id="6" string="keep" />
            <token id="7" string="the" />
            <token id="8" string="films" />
            <token id="9" string="&quot;" />
            <token id="10" string="to" />
            <token id="11" string="show" />
            <token id="12" string="our" />
            <token id="13" string="kids" />
            <token id="14" string="someday" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Arnazes" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="Arnazes" />
          </tokens>
        </chunking>
        <chunking id="3" string="what would happen" type="SBAR">
          <tokens>
            <token id="22" string="what" />
            <token id="23" string="would" />
            <token id="24" string="happen" />
          </tokens>
        </chunking>
        <chunking id="4" string="would happen" type="VP">
          <tokens>
            <token id="23" string="would" />
            <token id="24" string="happen" />
          </tokens>
        </chunking>
        <chunking id="5" string="happen" type="VP">
          <tokens>
            <token id="24" string="happen" />
          </tokens>
        </chunking>
        <chunking id="6" string="the films" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="films" />
          </tokens>
        </chunking>
        <chunking id="7" string="to show our kids someday" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="show" />
            <token id="12" string="our" />
            <token id="13" string="kids" />
            <token id="14" string="someday" />
          </tokens>
        </chunking>
        <chunking id="8" string="to keep the films `` to show our kids someday" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="keep" />
            <token id="7" string="the" />
            <token id="8" string="films" />
            <token id="9" string="&quot;" />
            <token id="10" string="to" />
            <token id="11" string="show" />
            <token id="12" string="our" />
            <token id="13" string="kids" />
            <token id="14" string="someday" />
          </tokens>
        </chunking>
        <chunking id="9" string="few in the industry" type="NP">
          <tokens>
            <token id="17" string="few" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="industry" />
          </tokens>
        </chunking>
        <chunking id="10" string="the industry" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="industry" />
          </tokens>
        </chunking>
        <chunking id="11" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="12" string="predicted what would happen" type="VP">
          <tokens>
            <token id="21" string="predicted" />
            <token id="22" string="what" />
            <token id="23" string="would" />
            <token id="24" string="happen" />
          </tokens>
        </chunking>
        <chunking id="13" string="few" type="NP">
          <tokens>
            <token id="17" string="few" />
          </tokens>
        </chunking>
        <chunking id="14" string="keep the films `` to show our kids someday" type="VP">
          <tokens>
            <token id="6" string="keep" />
            <token id="7" string="the" />
            <token id="8" string="films" />
            <token id="9" string="&quot;" />
            <token id="10" string="to" />
            <token id="11" string="show" />
            <token id="12" string="our" />
            <token id="13" string="kids" />
            <token id="14" string="someday" />
          </tokens>
        </chunking>
        <chunking id="15" string="our kids" type="NP">
          <tokens>
            <token id="12" string="our" />
            <token id="13" string="kids" />
          </tokens>
        </chunking>
        <chunking id="16" string="negotiated to keep the films `` to show our kids someday" type="VP">
          <tokens>
            <token id="4" string="negotiated" />
            <token id="5" string="to" />
            <token id="6" string="keep" />
            <token id="7" string="the" />
            <token id="8" string="films" />
            <token id="9" string="&quot;" />
            <token id="10" string="to" />
            <token id="11" string="show" />
            <token id="12" string="our" />
            <token id="13" string="kids" />
            <token id="14" string="someday" />
          </tokens>
        </chunking>
        <chunking id="17" string="show our kids someday" type="VP">
          <tokens>
            <token id="11" string="show" />
            <token id="12" string="our" />
            <token id="13" string="kids" />
            <token id="14" string="someday" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">negotiated</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">Arnazes</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">negotiated</governor>
          <dependent id="3">Arnazes</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">predicted</governor>
          <dependent id="4">negotiated</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">keep</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">negotiated</governor>
          <dependent id="6">keep</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">films</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">keep</governor>
          <dependent id="8">films</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">show</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">keep</governor>
          <dependent id="11">show</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">kids</governor>
          <dependent id="12">our</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">show</governor>
          <dependent id="13">kids</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">show</governor>
          <dependent id="14">someday</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">predicted</governor>
          <dependent id="17">few</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">industry</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">industry</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">few</governor>
          <dependent id="20">industry</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">predicted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">happen</governor>
          <dependent id="22">what</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">happen</governor>
          <dependent id="23">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">predicted</governor>
          <dependent id="24">happen</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="94" has_coreference="true">
      <content>&amp;quot;I remember (someone) saying, &amp;apost;These films may be worth something someday,&amp;apost; &amp;quot; Miss Ball told The Times.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="remember" lemma="remember" stem="rememb" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="These" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="films" lemma="film" stem="film" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="worth" lemma="worth" stem="worth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="someday" lemma="someday" stem="somedai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="24" string="Times" lemma="Times" stem="time" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP remember) (NP (NP (-LRB- -LRB-) (NN someone) (-RRB- -RRB-)) (VP (VBG saying) (, ,) (`` `) (S (NP (DT These) (NNS films)) (VP (MD may) (VP (VB be) (NP (JJ worth) (NN something)) (ADVP (RB someday))))))))) (, ,) ('' ') ('' '') (NP (NNP Miss) (NNP Ball)) (VP (VBD told) (NP (DT The) (NNPS Times))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="-LRB- someone -RRB- saying , ` These films may be worth something someday" type="NP">
          <tokens>
            <token id="4" string="(" />
            <token id="5" string="someone" />
            <token id="6" string=")" />
            <token id="7" string="saying" />
            <token id="8" string="," />
            <token id="9" string="'" />
            <token id="10" string="These" />
            <token id="11" string="films" />
            <token id="12" string="may" />
            <token id="13" string="be" />
            <token id="14" string="worth" />
            <token id="15" string="something" />
            <token id="16" string="someday" />
          </tokens>
        </chunking>
        <chunking id="2" string="be worth something someday" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="worth" />
            <token id="15" string="something" />
            <token id="16" string="someday" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Times" type="NP">
          <tokens>
            <token id="23" string="The" />
            <token id="24" string="Times" />
          </tokens>
        </chunking>
        <chunking id="4" string="These films" type="NP">
          <tokens>
            <token id="10" string="These" />
            <token id="11" string="films" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="-LRB- someone -RRB-" type="NP">
          <tokens>
            <token id="4" string="(" />
            <token id="5" string="someone" />
            <token id="6" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="saying , ` These films may be worth something someday" type="VP">
          <tokens>
            <token id="7" string="saying" />
            <token id="8" string="," />
            <token id="9" string="'" />
            <token id="10" string="These" />
            <token id="11" string="films" />
            <token id="12" string="may" />
            <token id="13" string="be" />
            <token id="14" string="worth" />
            <token id="15" string="something" />
            <token id="16" string="someday" />
          </tokens>
        </chunking>
        <chunking id="8" string="worth something" type="NP">
          <tokens>
            <token id="14" string="worth" />
            <token id="15" string="something" />
          </tokens>
        </chunking>
        <chunking id="9" string="told The Times" type="VP">
          <tokens>
            <token id="22" string="told" />
            <token id="23" string="The" />
            <token id="24" string="Times" />
          </tokens>
        </chunking>
        <chunking id="10" string="may be worth something someday" type="VP">
          <tokens>
            <token id="12" string="may" />
            <token id="13" string="be" />
            <token id="14" string="worth" />
            <token id="15" string="something" />
            <token id="16" string="someday" />
          </tokens>
        </chunking>
        <chunking id="11" string="remember -LRB- someone -RRB- saying , ` These films may be worth something someday" type="VP">
          <tokens>
            <token id="3" string="remember" />
            <token id="4" string="(" />
            <token id="5" string="someone" />
            <token id="6" string=")" />
            <token id="7" string="saying" />
            <token id="8" string="," />
            <token id="9" string="'" />
            <token id="10" string="These" />
            <token id="11" string="films" />
            <token id="12" string="may" />
            <token id="13" string="be" />
            <token id="14" string="worth" />
            <token id="15" string="something" />
            <token id="16" string="someday" />
          </tokens>
        </chunking>
        <chunking id="12" string="Miss Ball" type="NP">
          <tokens>
            <token id="20" string="Miss" />
            <token id="21" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">remember</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">told</governor>
          <dependent id="3">remember</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">remember</governor>
          <dependent id="5">someone</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">someone</governor>
          <dependent id="7">saying</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">films</governor>
          <dependent id="10">These</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">something</governor>
          <dependent id="11">films</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">something</governor>
          <dependent id="12">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">something</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">something</governor>
          <dependent id="14">worth</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">saying</governor>
          <dependent id="15">something</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">something</governor>
          <dependent id="16">someday</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Ball</governor>
          <dependent id="20">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">told</governor>
          <dependent id="21">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">Times</governor>
          <dependent id="23">The</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">told</governor>
          <dependent id="24">Times</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="The Times" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="23" string="The" />
            <token id="24" string="Times" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="95" has_coreference="true">
      <content>&amp;quot;You should hang onto them.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="hang" lemma="hang" stem="hang" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="onto" lemma="onto" stem="onto" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP You)) (VP (MD should) (VP (VB hang) (PP (IN onto) (NP (PRP them))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="hang onto them" type="VP">
          <tokens>
            <token id="4" string="hang" />
            <token id="5" string="onto" />
            <token id="6" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="should hang onto them" type="VP">
          <tokens>
            <token id="3" string="should" />
            <token id="4" string="hang" />
            <token id="5" string="onto" />
            <token id="6" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="them" type="NP">
          <tokens>
            <token id="6" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="You" type="NP">
          <tokens>
            <token id="2" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">hang</governor>
          <dependent id="2">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">hang</governor>
          <dependent id="3">should</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">hang</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">them</governor>
          <dependent id="5">onto</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">hang</governor>
          <dependent id="6">them</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="96" has_coreference="true">
      <content>If Desi had that in mind, I never knew it.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Desi" lemma="desus" stem="desi" pos="NNS" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="mind" lemma="mind" stem="mind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (NNS Desi)) (VP (VBD had) (ADVP (IN that) (PP (IN in) (NP (NN mind))))))) (, ,) (NP (PRP I)) (ADVP (RB never)) (VP (VBD knew) (NP (PRP it))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="knew it" type="VP">
          <tokens>
            <token id="10" string="knew" />
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="mind" type="NP">
          <tokens>
            <token id="6" string="mind" />
          </tokens>
        </chunking>
        <chunking id="3" string="If Desi had that in mind" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="Desi" />
            <token id="3" string="had" />
            <token id="4" string="that" />
            <token id="5" string="in" />
            <token id="6" string="mind" />
          </tokens>
        </chunking>
        <chunking id="4" string="Desi" type="NP">
          <tokens>
            <token id="2" string="Desi" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="8" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="had that in mind" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="that" />
            <token id="5" string="in" />
            <token id="6" string="mind" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">had</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">had</governor>
          <dependent id="2">Desi</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">knew</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">had</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">mind</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">that</governor>
          <dependent id="6">mind</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">knew</governor>
          <dependent id="8">I</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">knew</governor>
          <dependent id="9">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">knew</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">knew</governor>
          <dependent id="11">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Desi" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Desi" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="97" has_coreference="true">
      <content>Maybe he knew he was creating the rerun but he never told me about it.</content>
      <tokens>
        <token id="1" string="Maybe" lemma="maybe" stem="mayb" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="creating" lemma="create" stem="creat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="rerun" lemma="rerun" stem="rerun" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Maybe)) (NP (PRP he)) (VP (VBD knew) (SBAR (S (NP (PRP he)) (VP (VBD was) (VP (VBG creating) (NP (DT the) (NN rerun)))))))) (CC but) (S (NP (PRP he)) (ADVP (RB never)) (VP (VBD told) (NP (PRP me)) (PP (IN about) (NP (PRP it))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="told me about it" type="VP">
          <tokens>
            <token id="12" string="told" />
            <token id="13" string="me" />
            <token id="14" string="about" />
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="knew he was creating the rerun" type="VP">
          <tokens>
            <token id="3" string="knew" />
            <token id="4" string="he" />
            <token id="5" string="was" />
            <token id="6" string="creating" />
            <token id="7" string="the" />
            <token id="8" string="rerun" />
          </tokens>
        </chunking>
        <chunking id="3" string="creating the rerun" type="VP">
          <tokens>
            <token id="6" string="creating" />
            <token id="7" string="the" />
            <token id="8" string="rerun" />
          </tokens>
        </chunking>
        <chunking id="4" string="me" type="NP">
          <tokens>
            <token id="13" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="the rerun" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="rerun" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="was creating the rerun" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="creating" />
            <token id="7" string="the" />
            <token id="8" string="rerun" />
          </tokens>
        </chunking>
        <chunking id="9" string="he was creating the rerun" type="SBAR">
          <tokens>
            <token id="4" string="he" />
            <token id="5" string="was" />
            <token id="6" string="creating" />
            <token id="7" string="the" />
            <token id="8" string="rerun" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">knew</governor>
          <dependent id="1">Maybe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">knew</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">knew</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">creating</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">creating</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">knew</governor>
          <dependent id="6">creating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">rerun</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">creating</governor>
          <dependent id="8">rerun</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">knew</governor>
          <dependent id="9">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">told</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">told</governor>
          <dependent id="11">never</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">knew</governor>
          <dependent id="12">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">told</governor>
          <dependent id="13">me</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">it</governor>
          <dependent id="14">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">told</governor>
          <dependent id="15">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="98" has_coreference="true">
      <content>All I knew was I was 40 years old and was having my first baby and I didn&amp;apost;t want to do these shows and let them disappear into the air.</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="8" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="9" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="15" string="baby" lemma="baby" stem="babi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="want" lemma="want" stem="want" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="shows" lemma="show" stem="show" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="disappear" lemma="disappear" stem="disappear" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="air" lemma="air" stem="air" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT All)) (SBAR (S (NP (PRP I)) (VP (VBD knew))))) (VP (VP (VBD was) (SBAR (S (NP (PRP I)) (VP (VBD was) (ADJP (NP (CD 40) (NNS years)) (JJ old)))))) (CC and) (VP (VBD was) (VP (VBG having) (NP (PRP$ my) (JJ first) (NN baby)))))) (CC and) (S (NP (PRP I)) (VP (VBD did) (RB n't) (VP (VP (VB want) (S (VP (TO to) (VP (VB do) (NP (DT these) (NNS shows)))))) (CC and) (VP (VB let) (S (NP (PRP them)) (VP (VB disappear) (PP (IN into) (NP (DT the) (NN air))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="All" type="NP">
          <tokens>
            <token id="1" string="All" />
          </tokens>
        </chunking>
        <chunking id="2" string="I was 40 years old" type="SBAR">
          <tokens>
            <token id="5" string="I" />
            <token id="6" string="was" />
            <token id="7" string="40" />
            <token id="8" string="years" />
            <token id="9" string="old" />
          </tokens>
        </chunking>
        <chunking id="3" string="want to do these shows" type="VP">
          <tokens>
            <token id="20" string="want" />
            <token id="21" string="to" />
            <token id="22" string="do" />
            <token id="23" string="these" />
            <token id="24" string="shows" />
          </tokens>
        </chunking>
        <chunking id="4" string="let them disappear into the air" type="VP">
          <tokens>
            <token id="26" string="let" />
            <token id="27" string="them" />
            <token id="28" string="disappear" />
            <token id="29" string="into" />
            <token id="30" string="the" />
            <token id="31" string="air" />
          </tokens>
        </chunking>
        <chunking id="5" string="knew" type="VP">
          <tokens>
            <token id="3" string="knew" />
          </tokens>
        </chunking>
        <chunking id="6" string="40 years old" type="ADJP">
          <tokens>
            <token id="7" string="40" />
            <token id="8" string="years" />
            <token id="9" string="old" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="to do these shows" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="do" />
            <token id="23" string="these" />
            <token id="24" string="shows" />
          </tokens>
        </chunking>
        <chunking id="9" string="40 years" type="NP">
          <tokens>
            <token id="7" string="40" />
            <token id="8" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="was having my first baby" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="having" />
            <token id="13" string="my" />
            <token id="14" string="first" />
            <token id="15" string="baby" />
          </tokens>
        </chunking>
        <chunking id="11" string="these shows" type="NP">
          <tokens>
            <token id="23" string="these" />
            <token id="24" string="shows" />
          </tokens>
        </chunking>
        <chunking id="12" string="I knew" type="SBAR">
          <tokens>
            <token id="2" string="I" />
            <token id="3" string="knew" />
          </tokens>
        </chunking>
        <chunking id="13" string="them" type="NP">
          <tokens>
            <token id="27" string="them" />
          </tokens>
        </chunking>
        <chunking id="14" string="disappear into the air" type="VP">
          <tokens>
            <token id="28" string="disappear" />
            <token id="29" string="into" />
            <token id="30" string="the" />
            <token id="31" string="air" />
          </tokens>
        </chunking>
        <chunking id="15" string="the air" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="air" />
          </tokens>
        </chunking>
        <chunking id="16" string="did n't want to do these shows and let them disappear into the air" type="VP">
          <tokens>
            <token id="18" string="did" />
            <token id="19" string="n't" />
            <token id="20" string="want" />
            <token id="21" string="to" />
            <token id="22" string="do" />
            <token id="23" string="these" />
            <token id="24" string="shows" />
            <token id="25" string="and" />
            <token id="26" string="let" />
            <token id="27" string="them" />
            <token id="28" string="disappear" />
            <token id="29" string="into" />
            <token id="30" string="the" />
            <token id="31" string="air" />
          </tokens>
        </chunking>
        <chunking id="17" string="having my first baby" type="VP">
          <tokens>
            <token id="12" string="having" />
            <token id="13" string="my" />
            <token id="14" string="first" />
            <token id="15" string="baby" />
          </tokens>
        </chunking>
        <chunking id="18" string="was I was 40 years old" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="I" />
            <token id="6" string="was" />
            <token id="7" string="40" />
            <token id="8" string="years" />
            <token id="9" string="old" />
          </tokens>
        </chunking>
        <chunking id="19" string="my first baby" type="NP">
          <tokens>
            <token id="13" string="my" />
            <token id="14" string="first" />
            <token id="15" string="baby" />
          </tokens>
        </chunking>
        <chunking id="20" string="do these shows" type="VP">
          <tokens>
            <token id="22" string="do" />
            <token id="23" string="these" />
            <token id="24" string="shows" />
          </tokens>
        </chunking>
        <chunking id="21" string="was I was 40 years old and was having my first baby" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="I" />
            <token id="6" string="was" />
            <token id="7" string="40" />
            <token id="8" string="years" />
            <token id="9" string="old" />
            <token id="10" string="and" />
            <token id="11" string="was" />
            <token id="12" string="having" />
            <token id="13" string="my" />
            <token id="14" string="first" />
            <token id="15" string="baby" />
          </tokens>
        </chunking>
        <chunking id="22" string="All I knew" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="I" />
            <token id="3" string="knew" />
          </tokens>
        </chunking>
        <chunking id="23" string="was 40 years old" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="40" />
            <token id="8" string="years" />
            <token id="9" string="old" />
          </tokens>
        </chunking>
        <chunking id="24" string="want to do these shows and let them disappear into the air" type="VP">
          <tokens>
            <token id="20" string="want" />
            <token id="21" string="to" />
            <token id="22" string="do" />
            <token id="23" string="these" />
            <token id="24" string="shows" />
            <token id="25" string="and" />
            <token id="26" string="let" />
            <token id="27" string="them" />
            <token id="28" string="disappear" />
            <token id="29" string="into" />
            <token id="30" string="the" />
            <token id="31" string="air" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">was</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">knew</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">All</governor>
          <dependent id="3">knew</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">old</governor>
          <dependent id="5">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">old</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">years</governor>
          <dependent id="7">40</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="9">old</governor>
          <dependent id="8">years</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">was</governor>
          <dependent id="9">old</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">was</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">having</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">was</governor>
          <dependent id="12">having</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">baby</governor>
          <dependent id="13">my</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">baby</governor>
          <dependent id="14">first</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">having</governor>
          <dependent id="15">baby</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">was</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">want</governor>
          <dependent id="17">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">want</governor>
          <dependent id="18">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">want</governor>
          <dependent id="19">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">was</governor>
          <dependent id="20">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">do</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">want</governor>
          <dependent id="22">do</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">shows</governor>
          <dependent id="23">these</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">do</governor>
          <dependent id="24">shows</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">want</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">want</governor>
          <dependent id="26">let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">disappear</governor>
          <dependent id="27">them</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">let</governor>
          <dependent id="28">disappear</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">air</governor>
          <dependent id="29">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">air</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">disappear</governor>
          <dependent id="31">air</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="14" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="40 years old" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="40" />
            <token id="8" string="years" />
            <token id="9" string="old" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="99" has_coreference="true">
      <content>I felt we could save the films for home movies. . . .&amp;quot; Instead, in the years since the original 153 &amp;quot;I Love Lucy&amp;quot; episodes were telecast, they have been shown and reshown in virtually every country around the globe, earning an estimated $50 million to $100 million.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="save" lemma="save" stem="save" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="films" lemma="film" stem="film" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="movies" lemma="movie" stem="movi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string=". . . ." lemma="..." stem=". . . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Instead" lemma="instead" stem="instead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="17" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="18" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="original" lemma="original" stem="origin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="153" lemma="153" stem="153" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="22" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="episodes" lemma="episode" stem="episod" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="telecast" lemma="telecast" stem="telecast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="shown" lemma="show" stem="shown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="reshown" lemma="reshown" stem="reshown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="virtually" lemma="virtually" stem="virtual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="globe" lemma="globe" stem="globe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="earning" lemma="earn" stem="earn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="estimated" lemma="estimate" stem="estim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="49" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="50" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="51" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="53" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="54" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="55" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBD felt) (SBAR (S (NP (PRP we)) (VP (MD could) (VP (VB save) (NP (DT the) (NNS films)) (PP (IN for) (NP (NN home) (NNS movies))))))))) (: ...) ('' '') (S (ADVP (RB Instead)) (, ,) (PP (IN in) (NP (NP (DT the) (NNS years)) (PP (IN since) (NP (DT the) (JJ original) (CD 153))) (`` ``) (NP (NP (PRP I)) (SBAR (S (NP (NNP Love) (NNP Lucy) ('' '') (NNS episodes)) (VP (VBD were) (NP (NN telecast)))))))) (, ,) (NP (PRP they)) (VP (VBP have) (VP (VBN been) (VP (VBN shown) (CC and) (VBN reshown) (PP (IN in) (NP (NP (RB virtually) (DT every) (NN country)) (PP (IN around) (NP (DT the) (NN globe))))) (, ,) (S (VP (VBG earning) (NP (DT an) (VBN estimated) (QP ($ $) (CD 50) (CD million) (TO to) ($ $) (CD 100) (CD million))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the years" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="were telecast" type="VP">
          <tokens>
            <token id="28" string="were" />
            <token id="29" string="telecast" />
          </tokens>
        </chunking>
        <chunking id="3" string="Love Lucy '' episodes" type="NP">
          <tokens>
            <token id="24" string="Love" />
            <token id="25" string="Lucy" />
            <token id="26" string="&quot;" />
            <token id="27" string="episodes" />
          </tokens>
        </chunking>
        <chunking id="4" string="an estimated $ 50 million to $ 100 million" type="NP">
          <tokens>
            <token id="46" string="an" />
            <token id="47" string="estimated" />
            <token id="48" string="$" />
            <token id="49" string="50" />
            <token id="50" string="million" />
            <token id="51" string="to" />
            <token id="52" string="$" />
            <token id="53" string="100" />
            <token id="54" string="million" />
          </tokens>
        </chunking>
        <chunking id="5" string="shown and reshown in virtually every country around the globe , earning an estimated $ 50 million to $ 100 million" type="VP">
          <tokens>
            <token id="34" string="shown" />
            <token id="35" string="and" />
            <token id="36" string="reshown" />
            <token id="37" string="in" />
            <token id="38" string="virtually" />
            <token id="39" string="every" />
            <token id="40" string="country" />
            <token id="41" string="around" />
            <token id="42" string="the" />
            <token id="43" string="globe" />
            <token id="44" string="," />
            <token id="45" string="earning" />
            <token id="46" string="an" />
            <token id="47" string="estimated" />
            <token id="48" string="$" />
            <token id="49" string="50" />
            <token id="50" string="million" />
            <token id="51" string="to" />
            <token id="52" string="$" />
            <token id="53" string="100" />
            <token id="54" string="million" />
          </tokens>
        </chunking>
        <chunking id="6" string="could save the films for home movies" type="VP">
          <tokens>
            <token id="4" string="could" />
            <token id="5" string="save" />
            <token id="6" string="the" />
            <token id="7" string="films" />
            <token id="8" string="for" />
            <token id="9" string="home" />
            <token id="10" string="movies" />
          </tokens>
        </chunking>
        <chunking id="7" string="felt we could save the films for home movies" type="VP">
          <tokens>
            <token id="2" string="felt" />
            <token id="3" string="we" />
            <token id="4" string="could" />
            <token id="5" string="save" />
            <token id="6" string="the" />
            <token id="7" string="films" />
            <token id="8" string="for" />
            <token id="9" string="home" />
            <token id="10" string="movies" />
          </tokens>
        </chunking>
        <chunking id="8" string="save the films for home movies" type="VP">
          <tokens>
            <token id="5" string="save" />
            <token id="6" string="the" />
            <token id="7" string="films" />
            <token id="8" string="for" />
            <token id="9" string="home" />
            <token id="10" string="movies" />
          </tokens>
        </chunking>
        <chunking id="9" string="I Love Lucy '' episodes were telecast" type="NP">
          <tokens>
            <token id="23" string="I" />
            <token id="24" string="Love" />
            <token id="25" string="Lucy" />
            <token id="26" string="&quot;" />
            <token id="27" string="episodes" />
            <token id="28" string="were" />
            <token id="29" string="telecast" />
          </tokens>
        </chunking>
        <chunking id="10" string="home movies" type="NP">
          <tokens>
            <token id="9" string="home" />
            <token id="10" string="movies" />
          </tokens>
        </chunking>
        <chunking id="11" string="the globe" type="NP">
          <tokens>
            <token id="42" string="the" />
            <token id="43" string="globe" />
          </tokens>
        </chunking>
        <chunking id="12" string="the years since the original 153 `` I Love Lucy '' episodes were telecast" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="years" />
            <token id="18" string="since" />
            <token id="19" string="the" />
            <token id="20" string="original" />
            <token id="21" string="153" />
            <token id="22" string="&quot;" />
            <token id="23" string="I" />
            <token id="24" string="Love" />
            <token id="25" string="Lucy" />
            <token id="26" string="&quot;" />
            <token id="27" string="episodes" />
            <token id="28" string="were" />
            <token id="29" string="telecast" />
          </tokens>
        </chunking>
        <chunking id="13" string="we could save the films for home movies" type="SBAR">
          <tokens>
            <token id="3" string="we" />
            <token id="4" string="could" />
            <token id="5" string="save" />
            <token id="6" string="the" />
            <token id="7" string="films" />
            <token id="8" string="for" />
            <token id="9" string="home" />
            <token id="10" string="movies" />
          </tokens>
        </chunking>
        <chunking id="14" string="the original 153" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="original" />
            <token id="21" string="153" />
          </tokens>
        </chunking>
        <chunking id="15" string="been shown and reshown in virtually every country around the globe , earning an estimated $ 50 million to $ 100 million" type="VP">
          <tokens>
            <token id="33" string="been" />
            <token id="34" string="shown" />
            <token id="35" string="and" />
            <token id="36" string="reshown" />
            <token id="37" string="in" />
            <token id="38" string="virtually" />
            <token id="39" string="every" />
            <token id="40" string="country" />
            <token id="41" string="around" />
            <token id="42" string="the" />
            <token id="43" string="globe" />
            <token id="44" string="," />
            <token id="45" string="earning" />
            <token id="46" string="an" />
            <token id="47" string="estimated" />
            <token id="48" string="$" />
            <token id="49" string="50" />
            <token id="50" string="million" />
            <token id="51" string="to" />
            <token id="52" string="$" />
            <token id="53" string="100" />
            <token id="54" string="million" />
          </tokens>
        </chunking>
        <chunking id="16" string="the films" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="films" />
          </tokens>
        </chunking>
        <chunking id="17" string="virtually every country around the globe" type="NP">
          <tokens>
            <token id="38" string="virtually" />
            <token id="39" string="every" />
            <token id="40" string="country" />
            <token id="41" string="around" />
            <token id="42" string="the" />
            <token id="43" string="globe" />
          </tokens>
        </chunking>
        <chunking id="18" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="19" string="Love Lucy '' episodes were telecast" type="SBAR">
          <tokens>
            <token id="24" string="Love" />
            <token id="25" string="Lucy" />
            <token id="26" string="&quot;" />
            <token id="27" string="episodes" />
            <token id="28" string="were" />
            <token id="29" string="telecast" />
          </tokens>
        </chunking>
        <chunking id="20" string="we" type="NP">
          <tokens>
            <token id="3" string="we" />
          </tokens>
        </chunking>
        <chunking id="21" string="telecast" type="NP">
          <tokens>
            <token id="29" string="telecast" />
          </tokens>
        </chunking>
        <chunking id="22" string="earning an estimated $ 50 million to $ 100 million" type="VP">
          <tokens>
            <token id="45" string="earning" />
            <token id="46" string="an" />
            <token id="47" string="estimated" />
            <token id="48" string="$" />
            <token id="49" string="50" />
            <token id="50" string="million" />
            <token id="51" string="to" />
            <token id="52" string="$" />
            <token id="53" string="100" />
            <token id="54" string="million" />
          </tokens>
        </chunking>
        <chunking id="23" string="virtually every country" type="NP">
          <tokens>
            <token id="38" string="virtually" />
            <token id="39" string="every" />
            <token id="40" string="country" />
          </tokens>
        </chunking>
        <chunking id="24" string="they" type="NP">
          <tokens>
            <token id="31" string="they" />
          </tokens>
        </chunking>
        <chunking id="25" string="have been shown and reshown in virtually every country around the globe , earning an estimated $ 50 million to $ 100 million" type="VP">
          <tokens>
            <token id="32" string="have" />
            <token id="33" string="been" />
            <token id="34" string="shown" />
            <token id="35" string="and" />
            <token id="36" string="reshown" />
            <token id="37" string="in" />
            <token id="38" string="virtually" />
            <token id="39" string="every" />
            <token id="40" string="country" />
            <token id="41" string="around" />
            <token id="42" string="the" />
            <token id="43" string="globe" />
            <token id="44" string="," />
            <token id="45" string="earning" />
            <token id="46" string="an" />
            <token id="47" string="estimated" />
            <token id="48" string="$" />
            <token id="49" string="50" />
            <token id="50" string="million" />
            <token id="51" string="to" />
            <token id="52" string="$" />
            <token id="53" string="100" />
            <token id="54" string="million" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">felt</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">felt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">save</governor>
          <dependent id="3">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">save</governor>
          <dependent id="4">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">felt</governor>
          <dependent id="5">save</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">films</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">save</governor>
          <dependent id="7">films</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">movies</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">movies</governor>
          <dependent id="9">home</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">save</governor>
          <dependent id="10">movies</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">shown</governor>
          <dependent id="13">Instead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">years</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">years</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">shown</governor>
          <dependent id="17">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">153</governor>
          <dependent id="18">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">153</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">153</governor>
          <dependent id="20">original</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">years</governor>
          <dependent id="21">153</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">years</governor>
          <dependent id="23">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">episodes</governor>
          <dependent id="24">Love</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">episodes</governor>
          <dependent id="25">Lucy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">telecast</governor>
          <dependent id="27">episodes</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="29">telecast</governor>
          <dependent id="28">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">I</governor>
          <dependent id="29">telecast</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="34">shown</governor>
          <dependent id="31">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">shown</governor>
          <dependent id="32">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="34">shown</governor>
          <dependent id="33">been</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">felt</governor>
          <dependent id="34">shown</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="34">shown</governor>
          <dependent id="35">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">shown</governor>
          <dependent id="36">reshown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">country</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">country</governor>
          <dependent id="38">virtually</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">country</governor>
          <dependent id="39">every</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">shown</governor>
          <dependent id="40">country</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">globe</governor>
          <dependent id="41">around</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">globe</governor>
          <dependent id="42">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">country</governor>
          <dependent id="43">globe</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="34">shown</governor>
          <dependent id="45">earning</dependent>
        </dependency>
        <dependency type="det">
          <governor id="52">$</governor>
          <dependent id="46">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="52">$</governor>
          <dependent id="47">estimated</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="52">$</governor>
          <dependent id="48">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">$</governor>
          <dependent id="49">50</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">$</governor>
          <dependent id="50">million</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="52">$</governor>
          <dependent id="51">to</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="45">earning</governor>
          <dependent id="52">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="54">million</governor>
          <dependent id="53">100</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="52">$</governor>
          <dependent id="54">million</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 100 million" type="MONEY" score="0.0">
          <tokens>
            <token id="52" string="$" />
            <token id="53" string="100" />
            <token id="54" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="the years" type="DURATION" score="0.0">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="years" />
          </tokens>
        </entity>
        <entity id="3" string="$ 50 million" type="MONEY" score="0.0">
          <tokens>
            <token id="48" string="$" />
            <token id="49" string="50" />
            <token id="50" string="million" />
          </tokens>
        </entity>
        <entity id="4" string="153" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="153" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="100" has_coreference="true">
      <content>Miss Ball&amp;apost;s face was one of the most recognized on Earth.</content>
      <tokens>
        <token id="1" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="recognized" lemma="recognize" stem="recogn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Earth" lemma="Earth" stem="earth" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Miss) (NNP Ball) (POS 's)) (NN face)) (VP (VBD was) (NP (NP (CD one)) (PP (IN of) (NP (NP (DT the) (RBS most)) (VP (VBN recognized) (PP (IN on) (NP (NNP Earth)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the most" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="most" />
          </tokens>
        </chunking>
        <chunking id="2" string="Earth" type="NP">
          <tokens>
            <token id="12" string="Earth" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="recognized on Earth" type="VP">
          <tokens>
            <token id="10" string="recognized" />
            <token id="11" string="on" />
            <token id="12" string="Earth" />
          </tokens>
        </chunking>
        <chunking id="5" string="Miss Ball 's face" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
            <token id="3" string="'s" />
            <token id="4" string="face" />
          </tokens>
        </chunking>
        <chunking id="6" string="the most recognized on Earth" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="recognized" />
            <token id="11" string="on" />
            <token id="12" string="Earth" />
          </tokens>
        </chunking>
        <chunking id="7" string="was one of the most recognized on Earth" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="recognized" />
            <token id="11" string="on" />
            <token id="12" string="Earth" />
          </tokens>
        </chunking>
        <chunking id="8" string="one of the most recognized on Earth" type="NP">
          <tokens>
            <token id="6" string="one" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="recognized" />
            <token id="11" string="on" />
            <token id="12" string="Earth" />
          </tokens>
        </chunking>
        <chunking id="9" string="Miss Ball 's" type="NP">
          <tokens>
            <token id="1" string="Miss" />
            <token id="2" string="Ball" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ball</governor>
          <dependent id="1">Miss</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">face</governor>
          <dependent id="2">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Ball</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">one</governor>
          <dependent id="4">face</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">one</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">the</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">one</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">the</governor>
          <dependent id="9">most</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">the</governor>
          <dependent id="10">recognized</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Earth</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">recognized</governor>
          <dependent id="12">Earth</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Earth" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Earth" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="101" has_coreference="true">
      <content>But all of it was not enough to save her troubled marriage.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="enough" lemma="enough" stem="enough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="save" lemma="save" stem="save" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="troubled" lemma="troubled" stem="troubl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (DT all)) (PP (IN of) (NP (PRP it)))) (VP (VBD was) (RB not) (ADJP (JJ enough) (S (VP (TO to) (VP (VB save) (NP (PRP$ her) (JJ troubled) (NN marriage))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all of it" type="NP">
          <tokens>
            <token id="2" string="all" />
            <token id="3" string="of" />
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="all" type="NP">
          <tokens>
            <token id="2" string="all" />
          </tokens>
        </chunking>
        <chunking id="3" string="her troubled marriage" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="troubled" />
            <token id="12" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="was not enough to save her troubled marriage" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="not" />
            <token id="7" string="enough" />
            <token id="8" string="to" />
            <token id="9" string="save" />
            <token id="10" string="her" />
            <token id="11" string="troubled" />
            <token id="12" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="6" string="save her troubled marriage" type="VP">
          <tokens>
            <token id="9" string="save" />
            <token id="10" string="her" />
            <token id="11" string="troubled" />
            <token id="12" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="7" string="enough to save her troubled marriage" type="ADJP">
          <tokens>
            <token id="7" string="enough" />
            <token id="8" string="to" />
            <token id="9" string="save" />
            <token id="10" string="her" />
            <token id="11" string="troubled" />
            <token id="12" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="8" string="to save her troubled marriage" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="save" />
            <token id="10" string="her" />
            <token id="11" string="troubled" />
            <token id="12" string="marriage" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">enough</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">enough</governor>
          <dependent id="2">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">it</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">all</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">enough</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">enough</governor>
          <dependent id="6">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">enough</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">save</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">enough</governor>
          <dependent id="9">save</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">marriage</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">marriage</governor>
          <dependent id="11">troubled</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">save</governor>
          <dependent id="12">marriage</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="102" has_coreference="true">
      <content>To the horror of their television fans, Miss Ball and Arnaz were divorced in 1960.</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="horror" lemma="horror" stem="horror" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="divorced" lemma="divorce" stem="divorc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="1960" lemma="1960" stem="1960" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (TO To) (NP (NP (DT the) (NN horror)) (PP (IN of) (NP (PRP$ their) (NN television) (NNS fans))))) (, ,) (NP (NNP Miss) (NNP Ball) (CC and) (NNP Arnaz)) (VP (VBD were) (VP (VBN divorced) (PP (IN in) (NP (CD 1960))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="their television fans" type="NP">
          <tokens>
            <token id="5" string="their" />
            <token id="6" string="television" />
            <token id="7" string="fans" />
          </tokens>
        </chunking>
        <chunking id="2" string="divorced in 1960" type="VP">
          <tokens>
            <token id="14" string="divorced" />
            <token id="15" string="in" />
            <token id="16" string="1960" />
          </tokens>
        </chunking>
        <chunking id="3" string="the horror" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="horror" />
          </tokens>
        </chunking>
        <chunking id="4" string="the horror of their television fans" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="horror" />
            <token id="4" string="of" />
            <token id="5" string="their" />
            <token id="6" string="television" />
            <token id="7" string="fans" />
          </tokens>
        </chunking>
        <chunking id="5" string="Miss Ball and Arnaz" type="NP">
          <tokens>
            <token id="9" string="Miss" />
            <token id="10" string="Ball" />
            <token id="11" string="and" />
            <token id="12" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="6" string="1960" type="NP">
          <tokens>
            <token id="16" string="1960" />
          </tokens>
        </chunking>
        <chunking id="7" string="were divorced in 1960" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="divorced" />
            <token id="15" string="in" />
            <token id="16" string="1960" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">horror</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">horror</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">divorced</governor>
          <dependent id="3">horror</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">fans</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">fans</governor>
          <dependent id="5">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">fans</governor>
          <dependent id="6">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">horror</governor>
          <dependent id="7">fans</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Ball</governor>
          <dependent id="9">Miss</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">divorced</governor>
          <dependent id="10">Ball</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">Ball</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Ball</governor>
          <dependent id="12">Arnaz</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">divorced</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">divorced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">1960</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">divorced</governor>
          <dependent id="16">1960</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1960" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="1960" />
          </tokens>
        </entity>
        <entity id="2" string="Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Arnaz" />
          </tokens>
        </entity>
        <entity id="3" string="Miss Ball" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Miss" />
            <token id="10" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="103" has_coreference="true">
      <content>&amp;quot;He (Arnaz) was like Jekyll and Hyde,&amp;quot; she said years later.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Jekyll" lemma="Jekyll" stem="jekyl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Hyde" lemma="Hyde" stem="hyde" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="16" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP He)) (PRN (-LRB- -LRB-) (NP (NNP Arnaz)) (-RRB- -RRB-)) (VP (VBD was) (PP (IN like) (NP (NNP Jekyll) (CC and) (NNP Hyde))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said) (NP (NNS years)) (ADVP (RB later))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was like Jekyll and Hyde" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="like" />
            <token id="8" string="Jekyll" />
            <token id="9" string="and" />
            <token id="10" string="Hyde" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jekyll and Hyde" type="NP">
          <tokens>
            <token id="8" string="Jekyll" />
            <token id="9" string="and" />
            <token id="10" string="Hyde" />
          </tokens>
        </chunking>
        <chunking id="3" string="said years later" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="years" />
            <token id="16" string="later" />
          </tokens>
        </chunking>
        <chunking id="4" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="5" string="Arnaz" type="NP">
          <tokens>
            <token id="4" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="6" string="years" type="NP">
          <tokens>
            <token id="15" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="13" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">Jekyll</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">Jekyll</governor>
          <dependent id="4">Arnaz</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">Jekyll</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Jekyll</governor>
          <dependent id="7">like</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="8">Jekyll</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Jekyll</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Jekyll</governor>
          <dependent id="10">Hyde</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="14">said</governor>
          <dependent id="15">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">said</governor>
          <dependent id="16">later</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jekyll" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Jekyll" />
          </tokens>
        </entity>
        <entity id="2" string="Hyde" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Hyde" />
          </tokens>
        </entity>
        <entity id="3" string="Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Arnaz" />
          </tokens>
        </entity>
        <entity id="4" string="years later" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="years" />
            <token id="16" string="later" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="104" has_coreference="true">
      <content>&amp;quot;He drank and he gambled and he went around with other women.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="drank" lemma="drink" stem="drank" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="gambled" lemma="gamble" stem="gambl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="around" lemma="around" stem="around" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP He)) (VP (VBD drank))) (CC and) (S (S (NP (PRP he)) (VP (VBD gambled))) (CC and) (S (NP (PRP he)) (VP (VBD went) (ADVP (RB around)) (PP (IN with) (NP (JJ other) (NNS women)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="went around with other women" type="VP">
          <tokens>
            <token id="9" string="went" />
            <token id="10" string="around" />
            <token id="11" string="with" />
            <token id="12" string="other" />
            <token id="13" string="women" />
          </tokens>
        </chunking>
        <chunking id="2" string="drank" type="VP">
          <tokens>
            <token id="3" string="drank" />
          </tokens>
        </chunking>
        <chunking id="3" string="other women" type="NP">
          <tokens>
            <token id="12" string="other" />
            <token id="13" string="women" />
          </tokens>
        </chunking>
        <chunking id="4" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="gambled" type="VP">
          <tokens>
            <token id="6" string="gambled" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">drank</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">drank</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">drank</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">gambled</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">drank</governor>
          <dependent id="6">gambled</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">gambled</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">went</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">gambled</governor>
          <dependent id="9">went</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">went</governor>
          <dependent id="10">around</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">women</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">women</governor>
          <dependent id="12">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">went</governor>
          <dependent id="13">women</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="105" has_coreference="true">
      <content>It was always the same: booze and broads.&amp;quot;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="booze" lemma="booze" stem="booz" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="broads" lemma="broad" stem="broad" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (ADVP (RB always)) (NP (NP (DT the) (JJ same)) (: :) (NP (NP (NN booze)) (CC and) (NP (NNS broads))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="booze and broads" type="NP">
          <tokens>
            <token id="7" string="booze" />
            <token id="8" string="and" />
            <token id="9" string="broads" />
          </tokens>
        </chunking>
        <chunking id="2" string="the same : booze and broads" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="same" />
            <token id="6" string=":" />
            <token id="7" string="booze" />
            <token id="8" string="and" />
            <token id="9" string="broads" />
          </tokens>
        </chunking>
        <chunking id="3" string="booze" type="NP">
          <tokens>
            <token id="7" string="booze" />
          </tokens>
        </chunking>
        <chunking id="4" string="broads" type="NP">
          <tokens>
            <token id="9" string="broads" />
          </tokens>
        </chunking>
        <chunking id="5" string="the same" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="same" />
          </tokens>
        </chunking>
        <chunking id="6" string="was always the same : booze and broads" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="always" />
            <token id="4" string="the" />
            <token id="5" string="same" />
            <token id="6" string=":" />
            <token id="7" string="booze" />
            <token id="8" string="and" />
            <token id="9" string="broads" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">same</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">same</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">same</governor>
          <dependent id="3">always</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">same</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">same</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">same</governor>
          <dependent id="7">booze</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">booze</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">booze</governor>
          <dependent id="9">broads</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="106" has_coreference="true">
      <content>Breaking with the past, Miss Ball left Hollywood for New York and a starring role in the musical &amp;quot;Wildcat.&amp;quot;</content>
      <tokens>
        <token id="1" string="Breaking" lemma="break" stem="break" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="past" lemma="past" stem="past" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="9" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="starring" lemma="star" stem="star" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="musical" lemma="musical" stem="music" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Wildcat" lemma="wildcat" stem="wildcat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Breaking) (PP (IN with) (NP (DT the) (NN past))))) (, ,) (NP (NNP Miss) (NNP Ball)) (VP (VBD left) (NP (NP (NNP Hollywood)) (PP (IN for) (NP (NP (NNP New) (NNP York)) (CC and) (NP (NP (DT a) (VBG starring) (NN role)) (PP (IN in) (NP (DT the) (JJ musical) (`` ``) (NN Wildcat)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Hollywood" type="NP">
          <tokens>
            <token id="9" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="2" string="New York" type="NP">
          <tokens>
            <token id="11" string="New" />
            <token id="12" string="York" />
          </tokens>
        </chunking>
        <chunking id="3" string="the past" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="past" />
          </tokens>
        </chunking>
        <chunking id="4" string="Breaking with the past" type="VP">
          <tokens>
            <token id="1" string="Breaking" />
            <token id="2" string="with" />
            <token id="3" string="the" />
            <token id="4" string="past" />
          </tokens>
        </chunking>
        <chunking id="5" string="left Hollywood for New York and a starring role in the musical `` Wildcat" type="VP">
          <tokens>
            <token id="8" string="left" />
            <token id="9" string="Hollywood" />
            <token id="10" string="for" />
            <token id="11" string="New" />
            <token id="12" string="York" />
            <token id="13" string="and" />
            <token id="14" string="a" />
            <token id="15" string="starring" />
            <token id="16" string="role" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="musical" />
            <token id="20" string="&quot;" />
            <token id="21" string="Wildcat" />
          </tokens>
        </chunking>
        <chunking id="6" string="Hollywood for New York and a starring role in the musical `` Wildcat" type="NP">
          <tokens>
            <token id="9" string="Hollywood" />
            <token id="10" string="for" />
            <token id="11" string="New" />
            <token id="12" string="York" />
            <token id="13" string="and" />
            <token id="14" string="a" />
            <token id="15" string="starring" />
            <token id="16" string="role" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="musical" />
            <token id="20" string="&quot;" />
            <token id="21" string="Wildcat" />
          </tokens>
        </chunking>
        <chunking id="7" string="a starring role" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="starring" />
            <token id="16" string="role" />
          </tokens>
        </chunking>
        <chunking id="8" string="the musical `` Wildcat" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="musical" />
            <token id="20" string="&quot;" />
            <token id="21" string="Wildcat" />
          </tokens>
        </chunking>
        <chunking id="9" string="New York and a starring role in the musical `` Wildcat" type="NP">
          <tokens>
            <token id="11" string="New" />
            <token id="12" string="York" />
            <token id="13" string="and" />
            <token id="14" string="a" />
            <token id="15" string="starring" />
            <token id="16" string="role" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="musical" />
            <token id="20" string="&quot;" />
            <token id="21" string="Wildcat" />
          </tokens>
        </chunking>
        <chunking id="10" string="a starring role in the musical `` Wildcat" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="starring" />
            <token id="16" string="role" />
            <token id="17" string="in" />
            <token id="18" string="the" />
            <token id="19" string="musical" />
            <token id="20" string="&quot;" />
            <token id="21" string="Wildcat" />
          </tokens>
        </chunking>
        <chunking id="11" string="Miss Ball" type="NP">
          <tokens>
            <token id="6" string="Miss" />
            <token id="7" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="8">left</governor>
          <dependent id="1">Breaking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">past</governor>
          <dependent id="2">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">past</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Breaking</governor>
          <dependent id="4">past</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Ball</governor>
          <dependent id="6">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">left</governor>
          <dependent id="7">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">left</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">left</governor>
          <dependent id="9">Hollywood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">York</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">York</governor>
          <dependent id="11">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Hollywood</governor>
          <dependent id="12">York</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">York</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">role</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">role</governor>
          <dependent id="15">starring</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">York</governor>
          <dependent id="16">role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Wildcat</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Wildcat</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Wildcat</governor>
          <dependent id="19">musical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">role</governor>
          <dependent id="21">Wildcat</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="2" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="New" />
            <token id="12" string="York" />
          </tokens>
        </entity>
        <entity id="3" string="the past" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="past" />
          </tokens>
        </entity>
        <entity id="4" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="8" string="left" />
          </tokens>
        </entity>
        <entity id="5" string="Miss Ball" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Miss" />
            <token id="7" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="107" has_coreference="true">
      <content>The 1960 production floundered after only a few performances but during her stay in the East, she met stand-up comedian Gary Morton.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1960" lemma="1960" stem="1960" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="production" lemma="production" stem="product" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="floundered" lemma="flounder" stem="flounder" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="performances" lemma="performance" stem="perform" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="stay" lemma="stay" stem="stai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="met" lemma="meet" stem="met" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="stand-up" lemma="stand-up" stem="stand-up" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="comedian" lemma="comedian" stem="comedian" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="Gary" lemma="Gary" stem="gari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Morton" lemma="Morton" stem="morton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (CD 1960) (NN production)) (VP (VBD floundered) (PP (IN after) (NP (QP (RB only) (DT a) (JJ few)) (NNS performances))) (PP (CC but) (IN during) (NP (NP (PRP$ her) (NN stay)) (PP (IN in) (NP (DT the) (NNP East))))))) (, ,) (NP (PRP she)) (VP (VBD met) (NP (JJ stand-up) (NN comedian) (NNP Gary) (NNP Morton))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her stay" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="stay" />
          </tokens>
        </chunking>
        <chunking id="2" string="stand-up comedian Gary Morton" type="NP">
          <tokens>
            <token id="20" string="stand-up" />
            <token id="21" string="comedian" />
            <token id="22" string="Gary" />
            <token id="23" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="3" string="The 1960 production" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="1960" />
            <token id="3" string="production" />
          </tokens>
        </chunking>
        <chunking id="4" string="floundered after only a few performances but during her stay in the East" type="VP">
          <tokens>
            <token id="4" string="floundered" />
            <token id="5" string="after" />
            <token id="6" string="only" />
            <token id="7" string="a" />
            <token id="8" string="few" />
            <token id="9" string="performances" />
            <token id="10" string="but" />
            <token id="11" string="during" />
            <token id="12" string="her" />
            <token id="13" string="stay" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="East" />
          </tokens>
        </chunking>
        <chunking id="5" string="the East" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="East" />
          </tokens>
        </chunking>
        <chunking id="6" string="only a few performances" type="NP">
          <tokens>
            <token id="6" string="only" />
            <token id="7" string="a" />
            <token id="8" string="few" />
            <token id="9" string="performances" />
          </tokens>
        </chunking>
        <chunking id="7" string="her stay in the East" type="NP">
          <tokens>
            <token id="12" string="her" />
            <token id="13" string="stay" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="East" />
          </tokens>
        </chunking>
        <chunking id="8" string="met stand-up comedian Gary Morton" type="VP">
          <tokens>
            <token id="19" string="met" />
            <token id="20" string="stand-up" />
            <token id="21" string="comedian" />
            <token id="22" string="Gary" />
            <token id="23" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="18" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">production</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">production</governor>
          <dependent id="2">1960</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">floundered</governor>
          <dependent id="3">production</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">met</governor>
          <dependent id="4">floundered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">performances</governor>
          <dependent id="5">after</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">few</governor>
          <dependent id="6">only</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">few</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">performances</governor>
          <dependent id="8">few</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">floundered</governor>
          <dependent id="9">performances</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">stay</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">stay</governor>
          <dependent id="11">during</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">stay</governor>
          <dependent id="12">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">floundered</governor>
          <dependent id="13">stay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">East</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">East</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">stay</governor>
          <dependent id="16">East</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">met</governor>
          <dependent id="18">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">met</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">Morton</governor>
          <dependent id="20">stand-up</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Morton</governor>
          <dependent id="21">comedian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Morton</governor>
          <dependent id="22">Gary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">met</governor>
          <dependent id="23">Morton</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1960" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1960" />
          </tokens>
        </entity>
        <entity id="2" string="Gary Morton" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Gary" />
            <token id="23" string="Morton" />
          </tokens>
        </entity>
        <entity id="3" string="East" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="East" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="108" has_coreference="true">
      <content>They married in 1961.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="married" lemma="marry" stem="marri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="1961" lemma="1961" stem="1961" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD married) (PP (IN in) (NP (CD 1961)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="1961" type="NP">
          <tokens>
            <token id="4" string="1961" />
          </tokens>
        </chunking>
        <chunking id="3" string="married in 1961" type="VP">
          <tokens>
            <token id="2" string="married" />
            <token id="3" string="in" />
            <token id="4" string="1961" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">married</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">married</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">1961</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">married</governor>
          <dependent id="4">1961</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1961" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1961" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="109" has_coreference="true">
      <content>Meanwhile, Arnaz and Miss Ball had sold their &amp;quot;I Love Lucy&amp;quot; films to CBS for $6 million and she bought her ex-husband&amp;apost;s interest in Desilu, becoming in effect, the first woman to head a major studio.</content>
      <tokens>
        <token id="1" string="Meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="sold" lemma="sell" stem="sold" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="films" lemma="film" stem="film" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="CBS" lemma="CBS" stem="cbs" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="20" string="6" lemma="6" stem="6" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="21" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="bought" lemma="buy" stem="bought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="ex-husband" lemma="ex-husband" stem="ex-husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Desilu" lemma="Desilu" stem="desilu" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="becoming" lemma="become" stem="becom" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="true" />
        <token id="38" string="woman" lemma="woman" stem="woman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="head" lemma="head" stem="head" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="studio" lemma="studio" stem="studio" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Meanwhile)) (, ,) (S (NP (NNP Arnaz) (CC and) (NNP Miss) (NNP Ball)) (VP (VBD had) (VP (VBN sold) (NP (PRP$ their) (`` ``) (NX (NP (PRP I)) (PP (NP (NNP Love) (NNP Lucy) ('' '') (NNS films)) (PP (TO to) (NP (NNP CBS)))))) (PP (IN for) (NP (QP ($ $) (CD 6) (CD million))))))) (CC and) (S (NP (PRP she)) (VP (VBD bought) (NP (NP (PRP$ her) (NN ex-husband) (POS 's)) (NN interest)) (PP (IN in) (NP (NNP Desilu))) (, ,) (S (VP (VBG becoming) (PP (IN in) (NP (NP (NN effect)) (, ,) (NP (DT the) (JJ first) (NN woman)))) (S (VP (TO to) (VP (VB head) (NP (DT a) (JJ major) (NN studio))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="$ 6 million" type="NP">
          <tokens>
            <token id="19" string="$" />
            <token id="20" string="6" />
            <token id="21" string="million" />
          </tokens>
        </chunking>
        <chunking id="2" string="head a major studio" type="VP">
          <tokens>
            <token id="40" string="head" />
            <token id="41" string="a" />
            <token id="42" string="major" />
            <token id="43" string="studio" />
          </tokens>
        </chunking>
        <chunking id="3" string="had sold their `` I Love Lucy '' films to CBS for $ 6 million" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="sold" />
            <token id="9" string="their" />
            <token id="10" string="&quot;" />
            <token id="11" string="I" />
            <token id="12" string="Love" />
            <token id="13" string="Lucy" />
            <token id="14" string="&quot;" />
            <token id="15" string="films" />
            <token id="16" string="to" />
            <token id="17" string="CBS" />
            <token id="18" string="for" />
            <token id="19" string="$" />
            <token id="20" string="6" />
            <token id="21" string="million" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="to head a major studio" type="VP">
          <tokens>
            <token id="39" string="to" />
            <token id="40" string="head" />
            <token id="41" string="a" />
            <token id="42" string="major" />
            <token id="43" string="studio" />
          </tokens>
        </chunking>
        <chunking id="6" string="becoming in effect , the first woman to head a major studio" type="VP">
          <tokens>
            <token id="32" string="becoming" />
            <token id="33" string="in" />
            <token id="34" string="effect" />
            <token id="35" string="," />
            <token id="36" string="the" />
            <token id="37" string="first" />
            <token id="38" string="woman" />
            <token id="39" string="to" />
            <token id="40" string="head" />
            <token id="41" string="a" />
            <token id="42" string="major" />
            <token id="43" string="studio" />
          </tokens>
        </chunking>
        <chunking id="7" string="her ex-husband 's interest" type="NP">
          <tokens>
            <token id="25" string="her" />
            <token id="26" string="ex-husband" />
            <token id="27" string="'s" />
            <token id="28" string="interest" />
          </tokens>
        </chunking>
        <chunking id="8" string="Arnaz and Miss Ball" type="NP">
          <tokens>
            <token id="3" string="Arnaz" />
            <token id="4" string="and" />
            <token id="5" string="Miss" />
            <token id="6" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="23" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="her ex-husband 's" type="NP">
          <tokens>
            <token id="25" string="her" />
            <token id="26" string="ex-husband" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="effect , the first woman" type="NP">
          <tokens>
            <token id="34" string="effect" />
            <token id="35" string="," />
            <token id="36" string="the" />
            <token id="37" string="first" />
            <token id="38" string="woman" />
          </tokens>
        </chunking>
        <chunking id="12" string="Desilu" type="NP">
          <tokens>
            <token id="30" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="13" string="Love Lucy '' films" type="NP">
          <tokens>
            <token id="12" string="Love" />
            <token id="13" string="Lucy" />
            <token id="14" string="&quot;" />
            <token id="15" string="films" />
          </tokens>
        </chunking>
        <chunking id="14" string="CBS" type="NP">
          <tokens>
            <token id="17" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="15" string="sold their `` I Love Lucy '' films to CBS for $ 6 million" type="VP">
          <tokens>
            <token id="8" string="sold" />
            <token id="9" string="their" />
            <token id="10" string="&quot;" />
            <token id="11" string="I" />
            <token id="12" string="Love" />
            <token id="13" string="Lucy" />
            <token id="14" string="&quot;" />
            <token id="15" string="films" />
            <token id="16" string="to" />
            <token id="17" string="CBS" />
            <token id="18" string="for" />
            <token id="19" string="$" />
            <token id="20" string="6" />
            <token id="21" string="million" />
          </tokens>
        </chunking>
        <chunking id="16" string="a major studio" type="NP">
          <tokens>
            <token id="41" string="a" />
            <token id="42" string="major" />
            <token id="43" string="studio" />
          </tokens>
        </chunking>
        <chunking id="17" string="effect" type="NP">
          <tokens>
            <token id="34" string="effect" />
          </tokens>
        </chunking>
        <chunking id="18" string="bought her ex-husband 's interest in Desilu , becoming in effect , the first woman to head a major studio" type="VP">
          <tokens>
            <token id="24" string="bought" />
            <token id="25" string="her" />
            <token id="26" string="ex-husband" />
            <token id="27" string="'s" />
            <token id="28" string="interest" />
            <token id="29" string="in" />
            <token id="30" string="Desilu" />
            <token id="31" string="," />
            <token id="32" string="becoming" />
            <token id="33" string="in" />
            <token id="34" string="effect" />
            <token id="35" string="," />
            <token id="36" string="the" />
            <token id="37" string="first" />
            <token id="38" string="woman" />
            <token id="39" string="to" />
            <token id="40" string="head" />
            <token id="41" string="a" />
            <token id="42" string="major" />
            <token id="43" string="studio" />
          </tokens>
        </chunking>
        <chunking id="19" string="the first woman" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="first" />
            <token id="38" string="woman" />
          </tokens>
        </chunking>
        <chunking id="20" string="their `` I Love Lucy '' films to CBS" type="NP">
          <tokens>
            <token id="9" string="their" />
            <token id="10" string="&quot;" />
            <token id="11" string="I" />
            <token id="12" string="Love" />
            <token id="13" string="Lucy" />
            <token id="14" string="&quot;" />
            <token id="15" string="films" />
            <token id="16" string="to" />
            <token id="17" string="CBS" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">sold</governor>
          <dependent id="1">Meanwhile</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Ball</governor>
          <dependent id="3">Arnaz</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">Arnaz</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Arnaz</governor>
          <dependent id="5">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">sold</governor>
          <dependent id="6">Ball</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">sold</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">sold</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">I</governor>
          <dependent id="9">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">sold</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">films</governor>
          <dependent id="12">Love</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">films</governor>
          <dependent id="13">Lucy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">I</governor>
          <dependent id="15">films</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">CBS</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">films</governor>
          <dependent id="17">CBS</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">$</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">sold</governor>
          <dependent id="19">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">million</governor>
          <dependent id="20">6</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">$</governor>
          <dependent id="21">million</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">sold</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">bought</governor>
          <dependent id="23">she</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">sold</governor>
          <dependent id="24">bought</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">ex-husband</governor>
          <dependent id="25">her</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">interest</governor>
          <dependent id="26">ex-husband</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">ex-husband</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">bought</governor>
          <dependent id="28">interest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Desilu</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">bought</governor>
          <dependent id="30">Desilu</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">bought</governor>
          <dependent id="32">becoming</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">effect</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">becoming</governor>
          <dependent id="34">effect</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">woman</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">woman</governor>
          <dependent id="37">first</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">effect</governor>
          <dependent id="38">woman</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">head</governor>
          <dependent id="39">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="32">becoming</governor>
          <dependent id="40">head</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">studio</governor>
          <dependent id="41">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">studio</governor>
          <dependent id="42">major</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">head</governor>
          <dependent id="43">studio</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 6 million" type="MONEY" score="0.0">
          <tokens>
            <token id="19" string="$" />
            <token id="20" string="6" />
            <token id="21" string="million" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="37" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="CBS" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="CBS" />
          </tokens>
        </entity>
        <entity id="4" string="Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Arnaz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="110" has_coreference="true">
      <content>It was by then home to 18 shows, including such hits as &amp;quot;The Untouchables&amp;quot; and &amp;quot;The Ann Sothern Show.&amp;quot;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="18" lemma="18" stem="18" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string="shows" lemma="show" stem="show" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="hits" lemma="hit" stem="hit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Untouchables" lemma="Untouchables" stem="untouchabl" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Sothern" lemma="Sothern" stem="sothern" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Show" lemma="Show" stem="show" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (PP (IN by) (NP (RB then))) (ADVP (NN home) (PP (TO to) (NP (CD 18) (NNS shows)))) (, ,) (PP (VBG including) (NP (NP (JJ such) (NNS hits)) (PP (IN as) (NP (`` ``) (NP (DT The) (NNPS Untouchables)) ('' '') (CC and) (`` ``) (NP (DT The) (NNP Ann) (NNP Sothern) (NNP Show))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="such hits" type="NP">
          <tokens>
            <token id="11" string="such" />
            <token id="12" string="hits" />
          </tokens>
        </chunking>
        <chunking id="2" string="`` The Untouchables '' and `` The Ann Sothern Show" type="NP">
          <tokens>
            <token id="14" string="&quot;" />
            <token id="15" string="The" />
            <token id="16" string="Untouchables" />
            <token id="17" string="&quot;" />
            <token id="18" string="and" />
            <token id="19" string="&quot;" />
            <token id="20" string="The" />
            <token id="21" string="Ann" />
            <token id="22" string="Sothern" />
            <token id="23" string="Show" />
          </tokens>
        </chunking>
        <chunking id="3" string="The Ann Sothern Show" type="NP">
          <tokens>
            <token id="20" string="The" />
            <token id="21" string="Ann" />
            <token id="22" string="Sothern" />
            <token id="23" string="Show" />
          </tokens>
        </chunking>
        <chunking id="4" string="The Untouchables" type="NP">
          <tokens>
            <token id="15" string="The" />
            <token id="16" string="Untouchables" />
          </tokens>
        </chunking>
        <chunking id="5" string="such hits as `` The Untouchables '' and `` The Ann Sothern Show" type="NP">
          <tokens>
            <token id="11" string="such" />
            <token id="12" string="hits" />
            <token id="13" string="as" />
            <token id="14" string="&quot;" />
            <token id="15" string="The" />
            <token id="16" string="Untouchables" />
            <token id="17" string="&quot;" />
            <token id="18" string="and" />
            <token id="19" string="&quot;" />
            <token id="20" string="The" />
            <token id="21" string="Ann" />
            <token id="22" string="Sothern" />
            <token id="23" string="Show" />
          </tokens>
        </chunking>
        <chunking id="6" string="was by then home to 18 shows , including such hits as `` The Untouchables '' and `` The Ann Sothern Show" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="by" />
            <token id="4" string="then" />
            <token id="5" string="home" />
            <token id="6" string="to" />
            <token id="7" string="18" />
            <token id="8" string="shows" />
            <token id="9" string="," />
            <token id="10" string="including" />
            <token id="11" string="such" />
            <token id="12" string="hits" />
            <token id="13" string="as" />
            <token id="14" string="&quot;" />
            <token id="15" string="The" />
            <token id="16" string="Untouchables" />
            <token id="17" string="&quot;" />
            <token id="18" string="and" />
            <token id="19" string="&quot;" />
            <token id="20" string="The" />
            <token id="21" string="Ann" />
            <token id="22" string="Sothern" />
            <token id="23" string="Show" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="then" type="NP">
          <tokens>
            <token id="4" string="then" />
          </tokens>
        </chunking>
        <chunking id="9" string="18 shows" type="NP">
          <tokens>
            <token id="7" string="18" />
            <token id="8" string="shows" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">then</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">then</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">then</governor>
          <dependent id="3">by</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">then</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">then</governor>
          <dependent id="5">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">shows</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">shows</governor>
          <dependent id="7">18</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">home</governor>
          <dependent id="8">shows</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">hits</governor>
          <dependent id="10">including</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">hits</governor>
          <dependent id="11">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">then</governor>
          <dependent id="12">hits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Untouchables</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Untouchables</governor>
          <dependent id="15">The</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">hits</governor>
          <dependent id="16">Untouchables</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">Untouchables</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Show</governor>
          <dependent id="20">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Show</governor>
          <dependent id="21">Ann</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Show</governor>
          <dependent id="22">Sothern</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">Untouchables</governor>
          <dependent id="23">Show</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="18" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="18" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="111" has_coreference="true">
      <content>Friend Bob Hope called her business sense &amp;quot;startling.&amp;quot;</content>
      <tokens>
        <token id="1" string="Friend" lemma="friend" stem="friend" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Bob" lemma="Bob" stem="bob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Hope" lemma="Hope" stem="hope" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="startling" lemma="startling" stem="startl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Friend) (NNP Bob) (NNP Hope)) (VP (VBD called) (S (NP (PRP$ her) (NN business) (NN sense)) (`` ``) (ADJP (JJ startling)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Friend Bob Hope" type="NP">
          <tokens>
            <token id="1" string="Friend" />
            <token id="2" string="Bob" />
            <token id="3" string="Hope" />
          </tokens>
        </chunking>
        <chunking id="2" string="called her business sense `` startling" type="VP">
          <tokens>
            <token id="4" string="called" />
            <token id="5" string="her" />
            <token id="6" string="business" />
            <token id="7" string="sense" />
            <token id="8" string="&quot;" />
            <token id="9" string="startling" />
          </tokens>
        </chunking>
        <chunking id="3" string="her business sense" type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="business" />
            <token id="7" string="sense" />
          </tokens>
        </chunking>
        <chunking id="4" string="startling" type="ADJP">
          <tokens>
            <token id="9" string="startling" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Hope</governor>
          <dependent id="1">Friend</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Hope</governor>
          <dependent id="2">Bob</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">called</governor>
          <dependent id="3">Hope</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">called</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">sense</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">sense</governor>
          <dependent id="6">business</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">startling</governor>
          <dependent id="7">sense</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">called</governor>
          <dependent id="9">startling</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bob Hope" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Bob" />
            <token id="3" string="Hope" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="112" has_coreference="true">
      <content>&amp;quot;I never wanted to be an executive, but when my marriage to Desi broke up after 19 years, I couldn&amp;apost;t just walk away from my obligations and say &amp;apost;forget it,&amp;apost; &amp;quot; Miss Ball explained.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="executive" lemma="executive" stem="execut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Desi" lemma="desi" stem="desi" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="broke" lemma="break" stem="broke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="19" lemma="19" stem="19" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="20" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="walk" lemma="walk" stem="walk" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="obligations" lemma="obligation" stem="oblig" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="forget" lemma="forget" stem="forget" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="41" string="explained" lemma="explain" stem="explain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP I)) (ADVP (RB never)) (VP (VBD wanted) (S (VP (TO to) (VP (VB be) (NP (DT an) (NN executive))))))) (, ,) (CC but) (S (SBAR (WHADVP (WRB when)) (S (NP (NP (PRP$ my) (NN marriage)) (PP (TO to) (NP (NN Desi)))) (VP (VBD broke) (PRT (RP up)) (PP (IN after) (NP (CD 19) (NNS years)))))) (, ,) (NP (PRP I)) (VP (MD could) (RB n't) (ADVP (RB just)) (VP (VB walk) (UCP (PP (ADVP (RB away)) (IN from) (NP (PRP$ my) (NNS obligations))) (CC and) (S (VP (VBP say) (`` `) (S (VP (VB forget) (NP (PRP it))))))))))) (, ,) ('' ') ('' '') (NP (NNP Miss) (NNP Ball)) (VP (VBD explained)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="could n't just walk away from my obligations and say ` forget it" type="VP">
          <tokens>
            <token id="23" string="could" />
            <token id="24" string="n't" />
            <token id="25" string="just" />
            <token id="26" string="walk" />
            <token id="27" string="away" />
            <token id="28" string="from" />
            <token id="29" string="my" />
            <token id="30" string="obligations" />
            <token id="31" string="and" />
            <token id="32" string="say" />
            <token id="33" string="'" />
            <token id="34" string="forget" />
            <token id="35" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="forget it" type="VP">
          <tokens>
            <token id="34" string="forget" />
            <token id="35" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="be an executive" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="an" />
            <token id="8" string="executive" />
          </tokens>
        </chunking>
        <chunking id="5" string="say ` forget it" type="VP">
          <tokens>
            <token id="32" string="say" />
            <token id="33" string="'" />
            <token id="34" string="forget" />
            <token id="35" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="35" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="walk away from my obligations and say ` forget it" type="VP">
          <tokens>
            <token id="26" string="walk" />
            <token id="27" string="away" />
            <token id="28" string="from" />
            <token id="29" string="my" />
            <token id="30" string="obligations" />
            <token id="31" string="and" />
            <token id="32" string="say" />
            <token id="33" string="'" />
            <token id="34" string="forget" />
            <token id="35" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="19 years" type="NP">
          <tokens>
            <token id="19" string="19" />
            <token id="20" string="years" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="11" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="my obligations" type="NP">
          <tokens>
            <token id="29" string="my" />
            <token id="30" string="obligations" />
          </tokens>
        </chunking>
        <chunking id="11" string="an executive" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="executive" />
          </tokens>
        </chunking>
        <chunking id="12" string="explained" type="VP">
          <tokens>
            <token id="41" string="explained" />
          </tokens>
        </chunking>
        <chunking id="13" string="wanted to be an executive" type="VP">
          <tokens>
            <token id="4" string="wanted" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="an" />
            <token id="8" string="executive" />
          </tokens>
        </chunking>
        <chunking id="14" string="my marriage to Desi" type="NP">
          <tokens>
            <token id="12" string="my" />
            <token id="13" string="marriage" />
            <token id="14" string="to" />
            <token id="15" string="Desi" />
          </tokens>
        </chunking>
        <chunking id="15" string="to be an executive" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="an" />
            <token id="8" string="executive" />
          </tokens>
        </chunking>
        <chunking id="16" string="Desi" type="NP">
          <tokens>
            <token id="15" string="Desi" />
          </tokens>
        </chunking>
        <chunking id="17" string="my marriage" type="NP">
          <tokens>
            <token id="12" string="my" />
            <token id="13" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="18" string="when my marriage to Desi broke up after 19 years" type="SBAR">
          <tokens>
            <token id="11" string="when" />
            <token id="12" string="my" />
            <token id="13" string="marriage" />
            <token id="14" string="to" />
            <token id="15" string="Desi" />
            <token id="16" string="broke" />
            <token id="17" string="up" />
            <token id="18" string="after" />
            <token id="19" string="19" />
            <token id="20" string="years" />
          </tokens>
        </chunking>
        <chunking id="19" string="broke up after 19 years" type="VP">
          <tokens>
            <token id="16" string="broke" />
            <token id="17" string="up" />
            <token id="18" string="after" />
            <token id="19" string="19" />
            <token id="20" string="years" />
          </tokens>
        </chunking>
        <chunking id="20" string="Miss Ball" type="NP">
          <tokens>
            <token id="39" string="Miss" />
            <token id="40" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">wanted</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">wanted</governor>
          <dependent id="3">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="41">explained</governor>
          <dependent id="4">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">executive</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">executive</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">executive</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">wanted</governor>
          <dependent id="8">executive</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">wanted</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">broke</governor>
          <dependent id="11">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">marriage</governor>
          <dependent id="12">my</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">broke</governor>
          <dependent id="13">marriage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Desi</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">marriage</governor>
          <dependent id="15">Desi</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="26">walk</governor>
          <dependent id="16">broke</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">broke</governor>
          <dependent id="17">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">years</governor>
          <dependent id="18">after</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">years</governor>
          <dependent id="19">19</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">broke</governor>
          <dependent id="20">years</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">walk</governor>
          <dependent id="22">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">walk</governor>
          <dependent id="23">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">walk</governor>
          <dependent id="24">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">walk</governor>
          <dependent id="25">just</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">wanted</governor>
          <dependent id="26">walk</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">obligations</governor>
          <dependent id="27">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">obligations</governor>
          <dependent id="28">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">obligations</governor>
          <dependent id="29">my</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="26">walk</governor>
          <dependent id="30">obligations</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">obligations</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">obligations</governor>
          <dependent id="32">say</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">say</governor>
          <dependent id="34">forget</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">forget</governor>
          <dependent id="35">it</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">Ball</governor>
          <dependent id="39">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="41">explained</governor>
          <dependent id="40">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="41">explained</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Desi" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Desi" />
          </tokens>
        </entity>
        <entity id="3" string="19 years" type="DURATION" score="0.0">
          <tokens>
            <token id="19" string="19" />
            <token id="20" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="113" has_coreference="true">
      <content>&amp;quot;We were an institution.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="institution" lemma="institution" stem="institut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP We)) (VP (VBD were) (NP (DT an) (NN institution))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an institution" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="institution" />
          </tokens>
        </chunking>
        <chunking id="2" string="were an institution" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="an" />
            <token id="5" string="institution" />
          </tokens>
        </chunking>
        <chunking id="3" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">institution</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">institution</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">institution</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">institution</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="114" has_coreference="true">
      <content>Life takes guts.</content>
      <tokens>
        <token id="1" string="Life" lemma="Life" stem="life" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="guts" lemma="gut" stem="gut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Life)) (VP (VBZ takes) (NP (NNS guts))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="takes guts" type="VP">
          <tokens>
            <token id="2" string="takes" />
            <token id="3" string="guts" />
          </tokens>
        </chunking>
        <chunking id="2" string="guts" type="NP">
          <tokens>
            <token id="3" string="guts" />
          </tokens>
        </chunking>
        <chunking id="3" string="Life" type="NP">
          <tokens>
            <token id="1" string="Life" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">takes</governor>
          <dependent id="1">Life</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">takes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">takes</governor>
          <dependent id="3">guts</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="115" has_coreference="false">
      <content>If you don&amp;apost;t take chances, you&amp;apost;ll never bathe again because you might get dirty again.&amp;quot;</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="chances" lemma="chance" stem="chanc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="bathe" lemma="bathe" stem="bath" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="dirty" lemma="dirty" stem="dirti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (PRP you)) (VP (VBP do) (RB n't) (VP (VB take) (NP (NNS chances)))))) (, ,) (NP (PRP you)) (VP (MD 'll) (ADVP (RB never)) (VP (VB bathe) (ADVP (RB again)) (SBAR (IN because) (S (NP (PRP you)) (VP (MD might) (VP (VB get) (ADJP (JJ dirty)) (ADVP (RB again)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="do n't take chances" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="take" />
            <token id="6" string="chances" />
          </tokens>
        </chunking>
        <chunking id="2" string="because you might get dirty again" type="SBAR">
          <tokens>
            <token id="13" string="because" />
            <token id="14" string="you" />
            <token id="15" string="might" />
            <token id="16" string="get" />
            <token id="17" string="dirty" />
            <token id="18" string="again" />
          </tokens>
        </chunking>
        <chunking id="3" string="might get dirty again" type="VP">
          <tokens>
            <token id="15" string="might" />
            <token id="16" string="get" />
            <token id="17" string="dirty" />
            <token id="18" string="again" />
          </tokens>
        </chunking>
        <chunking id="4" string="get dirty again" type="VP">
          <tokens>
            <token id="16" string="get" />
            <token id="17" string="dirty" />
            <token id="18" string="again" />
          </tokens>
        </chunking>
        <chunking id="5" string="If you do n't take chances" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="you" />
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="take" />
            <token id="6" string="chances" />
          </tokens>
        </chunking>
        <chunking id="6" string="dirty" type="ADJP">
          <tokens>
            <token id="17" string="dirty" />
          </tokens>
        </chunking>
        <chunking id="7" string="chances" type="NP">
          <tokens>
            <token id="6" string="chances" />
          </tokens>
        </chunking>
        <chunking id="8" string="'ll never bathe again because you might get dirty again" type="VP">
          <tokens>
            <token id="9" string="'ll" />
            <token id="10" string="never" />
            <token id="11" string="bathe" />
            <token id="12" string="again" />
            <token id="13" string="because" />
            <token id="14" string="you" />
            <token id="15" string="might" />
            <token id="16" string="get" />
            <token id="17" string="dirty" />
            <token id="18" string="again" />
          </tokens>
        </chunking>
        <chunking id="9" string="bathe again because you might get dirty again" type="VP">
          <tokens>
            <token id="11" string="bathe" />
            <token id="12" string="again" />
            <token id="13" string="because" />
            <token id="14" string="you" />
            <token id="15" string="might" />
            <token id="16" string="get" />
            <token id="17" string="dirty" />
            <token id="18" string="again" />
          </tokens>
        </chunking>
        <chunking id="10" string="take chances" type="VP">
          <tokens>
            <token id="5" string="take" />
            <token id="6" string="chances" />
          </tokens>
        </chunking>
        <chunking id="11" string="you" type="NP">
          <tokens>
            <token id="2" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">take</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">take</governor>
          <dependent id="2">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">take</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">take</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">bathe</governor>
          <dependent id="5">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">take</governor>
          <dependent id="6">chances</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">bathe</governor>
          <dependent id="8">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">bathe</governor>
          <dependent id="9">'ll</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">bathe</governor>
          <dependent id="10">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">bathe</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">bathe</governor>
          <dependent id="12">again</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">get</governor>
          <dependent id="13">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">get</governor>
          <dependent id="14">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">get</governor>
          <dependent id="15">might</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">bathe</governor>
          <dependent id="16">get</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">get</governor>
          <dependent id="17">dirty</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">get</governor>
          <dependent id="18">again</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="116" has_coreference="true">
      <content>Husband Morton said Miss Ball was blessed with an &amp;quot;innate business sense.&amp;quot;</content>
      <tokens>
        <token id="1" string="Husband" lemma="Husband" stem="husband" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Morton" lemma="Morton" stem="morton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="blessed" lemma="bless" stem="bless" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="innate" lemma="innate" stem="innat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="sense" lemma="sense" stem="sens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Husband) (NNP Morton)) (VP (VBD said) (SBAR (S (NP (NNP Miss) (NNP Ball)) (VP (VBD was) (VP (VBN blessed) (PP (IN with) (NP (DT an) (`` ``) (JJ innate) (NN business) (NN sense)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="blessed with an `` innate business sense" type="VP">
          <tokens>
            <token id="7" string="blessed" />
            <token id="8" string="with" />
            <token id="9" string="an" />
            <token id="10" string="&quot;" />
            <token id="11" string="innate" />
            <token id="12" string="business" />
            <token id="13" string="sense" />
          </tokens>
        </chunking>
        <chunking id="2" string="an `` innate business sense" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="&quot;" />
            <token id="11" string="innate" />
            <token id="12" string="business" />
            <token id="13" string="sense" />
          </tokens>
        </chunking>
        <chunking id="3" string="was blessed with an `` innate business sense" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="blessed" />
            <token id="8" string="with" />
            <token id="9" string="an" />
            <token id="10" string="&quot;" />
            <token id="11" string="innate" />
            <token id="12" string="business" />
            <token id="13" string="sense" />
          </tokens>
        </chunking>
        <chunking id="4" string="said Miss Ball was blessed with an `` innate business sense" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="Miss" />
            <token id="5" string="Ball" />
            <token id="6" string="was" />
            <token id="7" string="blessed" />
            <token id="8" string="with" />
            <token id="9" string="an" />
            <token id="10" string="&quot;" />
            <token id="11" string="innate" />
            <token id="12" string="business" />
            <token id="13" string="sense" />
          </tokens>
        </chunking>
        <chunking id="5" string="Husband Morton" type="NP">
          <tokens>
            <token id="1" string="Husband" />
            <token id="2" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="6" string="Miss Ball was blessed with an `` innate business sense" type="SBAR">
          <tokens>
            <token id="4" string="Miss" />
            <token id="5" string="Ball" />
            <token id="6" string="was" />
            <token id="7" string="blessed" />
            <token id="8" string="with" />
            <token id="9" string="an" />
            <token id="10" string="&quot;" />
            <token id="11" string="innate" />
            <token id="12" string="business" />
            <token id="13" string="sense" />
          </tokens>
        </chunking>
        <chunking id="7" string="Miss Ball" type="NP">
          <tokens>
            <token id="4" string="Miss" />
            <token id="5" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Morton</governor>
          <dependent id="1">Husband</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">Morton</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Ball</governor>
          <dependent id="4">Miss</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">blessed</governor>
          <dependent id="5">Ball</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">blessed</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="7">blessed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">sense</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">sense</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">sense</governor>
          <dependent id="11">innate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">sense</governor>
          <dependent id="12">business</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">blessed</governor>
          <dependent id="13">sense</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Morton" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Morton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="117" has_coreference="true">
      <content>&amp;quot;When she was running Desilu,&amp;quot; he said, &amp;quot;she made decisions affecting the future of the company that often amazed board members, not because they were coming from a woman but because time usually proved her judgment to be correct.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Desilu" lemma="Desilu" stem="desilu" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="decisions" lemma="decision" stem="decis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="affecting" lemma="affect" stem="affect" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="future" lemma="future" stem="futur" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="company" lemma="company" stem="compani" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="amazed" lemma="amaze" stem="amaz" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="board" lemma="board" stem="board" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="members" lemma="member" stem="member" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="woman" lemma="woman" stem="woman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="39" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="proved" lemma="prove" stem="prove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="judgment" lemma="judgment" stem="judgment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="correct" lemma="correct" stem="correct" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (WHADVP (WRB When)) (S (NP (PRP she)) (VP (VBD was) (VP (VBG running) (NP (NNP Desilu)))))) (PRN (, ,) ('' '') (S (NP (PRP he)) (VP (VBD said))) (, ,)) (`` ``) (NP (PRP she)) (VP (VBD made) (NP (NNS decisions)) (S (VP (VBG affecting) (NP (NP (DT the) (NN future)) (PP (IN of) (NP (NP (DT the) (NN company)) (SBAR (SBAR (WHNP (WDT that)) (S (ADVP (RB often)) (VP (VBD amazed) (NP (NN board) (NNS members)) (, ,) (SBAR (RB not) (IN because) (S (NP (PRP they)) (VP (VBD were) (VP (VBG coming) (PP (IN from) (NP (DT a) (NN woman)))))))))) (CC but) (SBAR (IN because) (S (NP (NN time)) (ADVP (RB usually)) (VP (VBD proved) (NP (PRP$ her) (NN judgment) (S (VP (TO to) (VP (VB be) (ADJP (JJ correct)))))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="her judgment to be correct" type="NP">
          <tokens>
            <token id="41" string="her" />
            <token id="42" string="judgment" />
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="2" string="board members" type="NP">
          <tokens>
            <token id="25" string="board" />
            <token id="26" string="members" />
          </tokens>
        </chunking>
        <chunking id="3" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
        <chunking id="4" string="When" type="WHADVP">
          <tokens>
            <token id="2" string="When" />
          </tokens>
        </chunking>
        <chunking id="5" string="Desilu" type="NP">
          <tokens>
            <token id="6" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="6" string="running Desilu" type="VP">
          <tokens>
            <token id="5" string="running" />
            <token id="6" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="7" string="affecting the future of the company that often amazed board members , not because they were coming from a woman but because time usually proved her judgment to be correct" type="VP">
          <tokens>
            <token id="16" string="affecting" />
            <token id="17" string="the" />
            <token id="18" string="future" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="company" />
            <token id="22" string="that" />
            <token id="23" string="often" />
            <token id="24" string="amazed" />
            <token id="25" string="board" />
            <token id="26" string="members" />
            <token id="27" string="," />
            <token id="28" string="not" />
            <token id="29" string="because" />
            <token id="30" string="they" />
            <token id="31" string="were" />
            <token id="32" string="coming" />
            <token id="33" string="from" />
            <token id="34" string="a" />
            <token id="35" string="woman" />
            <token id="36" string="but" />
            <token id="37" string="because" />
            <token id="38" string="time" />
            <token id="39" string="usually" />
            <token id="40" string="proved" />
            <token id="41" string="her" />
            <token id="42" string="judgment" />
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="8" string="the future" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="future" />
          </tokens>
        </chunking>
        <chunking id="9" string="the company that often amazed board members , not because they were coming from a woman but because time usually proved her judgment to be correct" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="company" />
            <token id="22" string="that" />
            <token id="23" string="often" />
            <token id="24" string="amazed" />
            <token id="25" string="board" />
            <token id="26" string="members" />
            <token id="27" string="," />
            <token id="28" string="not" />
            <token id="29" string="because" />
            <token id="30" string="they" />
            <token id="31" string="were" />
            <token id="32" string="coming" />
            <token id="33" string="from" />
            <token id="34" string="a" />
            <token id="35" string="woman" />
            <token id="36" string="but" />
            <token id="37" string="because" />
            <token id="38" string="time" />
            <token id="39" string="usually" />
            <token id="40" string="proved" />
            <token id="41" string="her" />
            <token id="42" string="judgment" />
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="10" string="time" type="NP">
          <tokens>
            <token id="38" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="When she was running Desilu" type="SBAR">
          <tokens>
            <token id="2" string="When" />
            <token id="3" string="she" />
            <token id="4" string="was" />
            <token id="5" string="running" />
            <token id="6" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="to be correct" type="VP">
          <tokens>
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="14" string="be correct" type="VP">
          <tokens>
            <token id="44" string="be" />
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="15" string="proved her judgment to be correct" type="VP">
          <tokens>
            <token id="40" string="proved" />
            <token id="41" string="her" />
            <token id="42" string="judgment" />
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="16" string="that often amazed board members , not because they were coming from a woman but because time usually proved her judgment to be correct" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="often" />
            <token id="24" string="amazed" />
            <token id="25" string="board" />
            <token id="26" string="members" />
            <token id="27" string="," />
            <token id="28" string="not" />
            <token id="29" string="because" />
            <token id="30" string="they" />
            <token id="31" string="were" />
            <token id="32" string="coming" />
            <token id="33" string="from" />
            <token id="34" string="a" />
            <token id="35" string="woman" />
            <token id="36" string="but" />
            <token id="37" string="because" />
            <token id="38" string="time" />
            <token id="39" string="usually" />
            <token id="40" string="proved" />
            <token id="41" string="her" />
            <token id="42" string="judgment" />
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="17" string="was running Desilu" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="running" />
            <token id="6" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="18" string="coming from a woman" type="VP">
          <tokens>
            <token id="32" string="coming" />
            <token id="33" string="from" />
            <token id="34" string="a" />
            <token id="35" string="woman" />
          </tokens>
        </chunking>
        <chunking id="19" string="correct" type="ADJP">
          <tokens>
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="20" string="the future of the company that often amazed board members , not because they were coming from a woman but because time usually proved her judgment to be correct" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="future" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="company" />
            <token id="22" string="that" />
            <token id="23" string="often" />
            <token id="24" string="amazed" />
            <token id="25" string="board" />
            <token id="26" string="members" />
            <token id="27" string="," />
            <token id="28" string="not" />
            <token id="29" string="because" />
            <token id="30" string="they" />
            <token id="31" string="were" />
            <token id="32" string="coming" />
            <token id="33" string="from" />
            <token id="34" string="a" />
            <token id="35" string="woman" />
            <token id="36" string="but" />
            <token id="37" string="because" />
            <token id="38" string="time" />
            <token id="39" string="usually" />
            <token id="40" string="proved" />
            <token id="41" string="her" />
            <token id="42" string="judgment" />
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="21" string="because time usually proved her judgment to be correct" type="SBAR">
          <tokens>
            <token id="37" string="because" />
            <token id="38" string="time" />
            <token id="39" string="usually" />
            <token id="40" string="proved" />
            <token id="41" string="her" />
            <token id="42" string="judgment" />
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="22" string="the company" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="company" />
          </tokens>
        </chunking>
        <chunking id="23" string="they" type="NP">
          <tokens>
            <token id="30" string="they" />
          </tokens>
        </chunking>
        <chunking id="24" string="that often amazed board members , not because they were coming from a woman" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="often" />
            <token id="24" string="amazed" />
            <token id="25" string="board" />
            <token id="26" string="members" />
            <token id="27" string="," />
            <token id="28" string="not" />
            <token id="29" string="because" />
            <token id="30" string="they" />
            <token id="31" string="were" />
            <token id="32" string="coming" />
            <token id="33" string="from" />
            <token id="34" string="a" />
            <token id="35" string="woman" />
          </tokens>
        </chunking>
        <chunking id="25" string="made decisions affecting the future of the company that often amazed board members , not because they were coming from a woman but because time usually proved her judgment to be correct" type="VP">
          <tokens>
            <token id="14" string="made" />
            <token id="15" string="decisions" />
            <token id="16" string="affecting" />
            <token id="17" string="the" />
            <token id="18" string="future" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="company" />
            <token id="22" string="that" />
            <token id="23" string="often" />
            <token id="24" string="amazed" />
            <token id="25" string="board" />
            <token id="26" string="members" />
            <token id="27" string="," />
            <token id="28" string="not" />
            <token id="29" string="because" />
            <token id="30" string="they" />
            <token id="31" string="were" />
            <token id="32" string="coming" />
            <token id="33" string="from" />
            <token id="34" string="a" />
            <token id="35" string="woman" />
            <token id="36" string="but" />
            <token id="37" string="because" />
            <token id="38" string="time" />
            <token id="39" string="usually" />
            <token id="40" string="proved" />
            <token id="41" string="her" />
            <token id="42" string="judgment" />
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="correct" />
          </tokens>
        </chunking>
        <chunking id="26" string="were coming from a woman" type="VP">
          <tokens>
            <token id="31" string="were" />
            <token id="32" string="coming" />
            <token id="33" string="from" />
            <token id="34" string="a" />
            <token id="35" string="woman" />
          </tokens>
        </chunking>
        <chunking id="27" string="a woman" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="woman" />
          </tokens>
        </chunking>
        <chunking id="28" string="decisions" type="NP">
          <tokens>
            <token id="15" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="29" string="said" type="VP">
          <tokens>
            <token id="10" string="said" />
          </tokens>
        </chunking>
        <chunking id="30" string="not because they were coming from a woman" type="SBAR">
          <tokens>
            <token id="28" string="not" />
            <token id="29" string="because" />
            <token id="30" string="they" />
            <token id="31" string="were" />
            <token id="32" string="coming" />
            <token id="33" string="from" />
            <token id="34" string="a" />
            <token id="35" string="woman" />
          </tokens>
        </chunking>
        <chunking id="31" string="amazed board members , not because they were coming from a woman" type="VP">
          <tokens>
            <token id="24" string="amazed" />
            <token id="25" string="board" />
            <token id="26" string="members" />
            <token id="27" string="," />
            <token id="28" string="not" />
            <token id="29" string="because" />
            <token id="30" string="they" />
            <token id="31" string="were" />
            <token id="32" string="coming" />
            <token id="33" string="from" />
            <token id="34" string="a" />
            <token id="35" string="woman" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">running</governor>
          <dependent id="2">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">running</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">running</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">made</governor>
          <dependent id="5">running</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">running</governor>
          <dependent id="6">Desilu</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="14">made</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">made</governor>
          <dependent id="13">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">made</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">made</governor>
          <dependent id="15">decisions</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">made</governor>
          <dependent id="16">affecting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">future</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">affecting</governor>
          <dependent id="18">future</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">company</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">company</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">future</governor>
          <dependent id="21">company</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">amazed</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">amazed</governor>
          <dependent id="23">often</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">company</governor>
          <dependent id="24">amazed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">members</governor>
          <dependent id="25">board</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">amazed</governor>
          <dependent id="26">members</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="32">coming</governor>
          <dependent id="28">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">coming</governor>
          <dependent id="29">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">coming</governor>
          <dependent id="30">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="32">coming</governor>
          <dependent id="31">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">amazed</governor>
          <dependent id="32">coming</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">woman</governor>
          <dependent id="33">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">woman</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">coming</governor>
          <dependent id="35">woman</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">amazed</governor>
          <dependent id="36">but</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">proved</governor>
          <dependent id="37">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">proved</governor>
          <dependent id="38">time</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">proved</governor>
          <dependent id="39">usually</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">amazed</governor>
          <dependent id="40">proved</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="42">judgment</governor>
          <dependent id="41">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">proved</governor>
          <dependent id="42">judgment</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="45">correct</governor>
          <dependent id="43">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="45">correct</governor>
          <dependent id="44">be</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="42">judgment</governor>
          <dependent id="45">correct</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the future" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="future" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="118" has_coreference="true">
      <content>Among the shows Miss Ball tutored to success was her own &amp;quot;The Lucy Show,&amp;quot; a series without Arnaz but with the same madcap clowning that kept her fans delighted.</content>
      <tokens>
        <token id="1" string="Among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="shows" lemma="show" stem="show" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="tutored" lemma="tutor" stem="tutor" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="success" lemma="success" stem="success" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="Show" lemma="Show" stem="show" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="series" lemma="series" stem="seri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="madcap" lemma="madcap" stem="madcap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="clowning" lemma="clowning" stem="clown" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="kept" lemma="keep" stem="kept" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="delighted" lemma="delighted" stem="delight" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Among) (NP (DT the) (NNS shows))) (NP (NNP Miss) (NNP Ball)) (VP (VBD tutored) (PP (TO to) (NP (NP (NN success)) (SBAR (S (VP (VBD was) (NP (PRP$ her) (JJ own))))))) (NP (`` ``) (NP (DT The) (NNP Lucy) (NNP Show)) (, ,) ('' '') (NP (NP (DT a) (NN series)) (PP (PP (IN without) (NP (NNP Arnaz))) (CC but) (PP (IN with) (NP (DT the) (JJ same) (NN madcap) (NN clowning)))) (SBAR (WHNP (WDT that)) (S (VP (VBD kept) (S (NP (PRP her) (NNS fans)) (ADJP (JJ delighted))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her fans" type="NP">
          <tokens>
            <token id="30" string="her" />
            <token id="31" string="fans" />
          </tokens>
        </chunking>
        <chunking id="2" string="her own" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="own" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` The Lucy Show , '' a series without Arnaz but with the same madcap clowning that kept her fans delighted" type="NP">
          <tokens>
            <token id="12" string="&quot;" />
            <token id="13" string="The" />
            <token id="14" string="Lucy" />
            <token id="15" string="Show" />
            <token id="16" string="," />
            <token id="17" string="&quot;" />
            <token id="18" string="a" />
            <token id="19" string="series" />
            <token id="20" string="without" />
            <token id="21" string="Arnaz" />
            <token id="22" string="but" />
            <token id="23" string="with" />
            <token id="24" string="the" />
            <token id="25" string="same" />
            <token id="26" string="madcap" />
            <token id="27" string="clowning" />
            <token id="28" string="that" />
            <token id="29" string="kept" />
            <token id="30" string="her" />
            <token id="31" string="fans" />
            <token id="32" string="delighted" />
          </tokens>
        </chunking>
        <chunking id="4" string="a series" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="series" />
          </tokens>
        </chunking>
        <chunking id="5" string="that kept her fans delighted" type="SBAR">
          <tokens>
            <token id="28" string="that" />
            <token id="29" string="kept" />
            <token id="30" string="her" />
            <token id="31" string="fans" />
            <token id="32" string="delighted" />
          </tokens>
        </chunking>
        <chunking id="6" string="delighted" type="ADJP">
          <tokens>
            <token id="32" string="delighted" />
          </tokens>
        </chunking>
        <chunking id="7" string="the shows" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="shows" />
          </tokens>
        </chunking>
        <chunking id="8" string="kept her fans delighted" type="VP">
          <tokens>
            <token id="29" string="kept" />
            <token id="30" string="her" />
            <token id="31" string="fans" />
            <token id="32" string="delighted" />
          </tokens>
        </chunking>
        <chunking id="9" string="success was her own" type="NP">
          <tokens>
            <token id="8" string="success" />
            <token id="9" string="was" />
            <token id="10" string="her" />
            <token id="11" string="own" />
          </tokens>
        </chunking>
        <chunking id="10" string="success" type="NP">
          <tokens>
            <token id="8" string="success" />
          </tokens>
        </chunking>
        <chunking id="11" string="The Lucy Show" type="NP">
          <tokens>
            <token id="13" string="The" />
            <token id="14" string="Lucy" />
            <token id="15" string="Show" />
          </tokens>
        </chunking>
        <chunking id="12" string="a series without Arnaz but with the same madcap clowning that kept her fans delighted" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="series" />
            <token id="20" string="without" />
            <token id="21" string="Arnaz" />
            <token id="22" string="but" />
            <token id="23" string="with" />
            <token id="24" string="the" />
            <token id="25" string="same" />
            <token id="26" string="madcap" />
            <token id="27" string="clowning" />
            <token id="28" string="that" />
            <token id="29" string="kept" />
            <token id="30" string="her" />
            <token id="31" string="fans" />
            <token id="32" string="delighted" />
          </tokens>
        </chunking>
        <chunking id="13" string="Arnaz" type="NP">
          <tokens>
            <token id="21" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="14" string="was her own" type="SBAR">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="her" />
            <token id="11" string="own" />
          </tokens>
        </chunking>
        <chunking id="15" string="the same madcap clowning" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="same" />
            <token id="26" string="madcap" />
            <token id="27" string="clowning" />
          </tokens>
        </chunking>
        <chunking id="16" string="Miss Ball" type="NP">
          <tokens>
            <token id="4" string="Miss" />
            <token id="5" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="17" string="tutored to success was her own `` The Lucy Show , '' a series without Arnaz but with the same madcap clowning that kept her fans delighted" type="VP">
          <tokens>
            <token id="6" string="tutored" />
            <token id="7" string="to" />
            <token id="8" string="success" />
            <token id="9" string="was" />
            <token id="10" string="her" />
            <token id="11" string="own" />
            <token id="12" string="&quot;" />
            <token id="13" string="The" />
            <token id="14" string="Lucy" />
            <token id="15" string="Show" />
            <token id="16" string="," />
            <token id="17" string="&quot;" />
            <token id="18" string="a" />
            <token id="19" string="series" />
            <token id="20" string="without" />
            <token id="21" string="Arnaz" />
            <token id="22" string="but" />
            <token id="23" string="with" />
            <token id="24" string="the" />
            <token id="25" string="same" />
            <token id="26" string="madcap" />
            <token id="27" string="clowning" />
            <token id="28" string="that" />
            <token id="29" string="kept" />
            <token id="30" string="her" />
            <token id="31" string="fans" />
            <token id="32" string="delighted" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">shows</governor>
          <dependent id="1">Among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">shows</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">tutored</governor>
          <dependent id="3">shows</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Ball</governor>
          <dependent id="4">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">tutored</governor>
          <dependent id="5">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">tutored</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">success</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">tutored</governor>
          <dependent id="8">success</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">own</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">own</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">success</governor>
          <dependent id="11">own</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Show</governor>
          <dependent id="13">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Show</governor>
          <dependent id="14">Lucy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">tutored</governor>
          <dependent id="15">Show</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">series</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">Show</governor>
          <dependent id="19">series</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">series</governor>
          <dependent id="19">series</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Arnaz</governor>
          <dependent id="20">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">series</governor>
          <dependent id="21">Arnaz</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">series</governor>
          <dependent id="22">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">clowning</governor>
          <dependent id="23">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">clowning</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">clowning</governor>
          <dependent id="25">same</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">clowning</governor>
          <dependent id="26">madcap</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">series</governor>
          <dependent id="27">clowning</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">kept</governor>
          <dependent id="28">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">series</governor>
          <dependent id="29">kept</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="31">fans</governor>
          <dependent id="30">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">delighted</governor>
          <dependent id="31">fans</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">kept</governor>
          <dependent id="32">delighted</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Arnaz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="119" has_coreference="true">
      <content>Among the guest stars attracted by the madness were Elizabeth Taylor and Richard Burton, the most glittering couple of the day.</content>
      <tokens>
        <token id="1" string="Among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="guest" lemma="guest" stem="guest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="stars" lemma="star" stem="star" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="attracted" lemma="attract" stem="attract" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="madness" lemma="madness" stem="mad" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Elizabeth" lemma="Elizabeth" stem="elizabeth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Taylor" lemma="Taylor" stem="taylor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Richard" lemma="Richard" stem="richard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="Burton" lemma="Burton" stem="burton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="glittering" lemma="glittering" stem="glitter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="couple" lemma="couple" stem="coupl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (PP (IN Among) (NP (NP (DT the) (NN guest)) (SBAR (S (VP (VBZ stars) (VP (VBN attracted) (PP (IN by) (NP (DT the) (NN madness))))))))) (VP (VBD were)) (NP (NP (NNP Elizabeth) (NNP Taylor) (CC and) (NNP Richard) (NNP Burton)) (, ,) (NP (NP (DT the) (ADJP (RBS most) (JJ glittering)) (NN couple)) (PP (IN of) (NP (DT the) (NN day))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the guest stars attracted by the madness" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="guest" />
            <token id="4" string="stars" />
            <token id="5" string="attracted" />
            <token id="6" string="by" />
            <token id="7" string="the" />
            <token id="8" string="madness" />
          </tokens>
        </chunking>
        <chunking id="2" string="attracted by the madness" type="VP">
          <tokens>
            <token id="5" string="attracted" />
            <token id="6" string="by" />
            <token id="7" string="the" />
            <token id="8" string="madness" />
          </tokens>
        </chunking>
        <chunking id="3" string="most glittering" type="ADJP">
          <tokens>
            <token id="17" string="most" />
            <token id="18" string="glittering" />
          </tokens>
        </chunking>
        <chunking id="4" string="the day" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="day" />
          </tokens>
        </chunking>
        <chunking id="5" string="the guest" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="guest" />
          </tokens>
        </chunking>
        <chunking id="6" string="were" type="VP">
          <tokens>
            <token id="9" string="were" />
          </tokens>
        </chunking>
        <chunking id="7" string="the most glittering couple" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="most" />
            <token id="18" string="glittering" />
            <token id="19" string="couple" />
          </tokens>
        </chunking>
        <chunking id="8" string="the madness" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="madness" />
          </tokens>
        </chunking>
        <chunking id="9" string="Elizabeth Taylor and Richard Burton , the most glittering couple of the day" type="NP">
          <tokens>
            <token id="10" string="Elizabeth" />
            <token id="11" string="Taylor" />
            <token id="12" string="and" />
            <token id="13" string="Richard" />
            <token id="14" string="Burton" />
            <token id="15" string="," />
            <token id="16" string="the" />
            <token id="17" string="most" />
            <token id="18" string="glittering" />
            <token id="19" string="couple" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="day" />
          </tokens>
        </chunking>
        <chunking id="10" string="stars attracted by the madness" type="SBAR">
          <tokens>
            <token id="4" string="stars" />
            <token id="5" string="attracted" />
            <token id="6" string="by" />
            <token id="7" string="the" />
            <token id="8" string="madness" />
          </tokens>
        </chunking>
        <chunking id="11" string="the most glittering couple of the day" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="most" />
            <token id="18" string="glittering" />
            <token id="19" string="couple" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="day" />
          </tokens>
        </chunking>
        <chunking id="12" string="Elizabeth Taylor and Richard Burton" type="NP">
          <tokens>
            <token id="10" string="Elizabeth" />
            <token id="11" string="Taylor" />
            <token id="12" string="and" />
            <token id="13" string="Richard" />
            <token id="14" string="Burton" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">guest</governor>
          <dependent id="1">Among</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">guest</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">were</governor>
          <dependent id="3">guest</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">guest</governor>
          <dependent id="4">stars</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">stars</governor>
          <dependent id="5">attracted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">madness</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">madness</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">attracted</governor>
          <dependent id="8">madness</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Taylor</governor>
          <dependent id="10">Elizabeth</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">were</governor>
          <dependent id="11">Taylor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">Taylor</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Burton</governor>
          <dependent id="13">Richard</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">Taylor</governor>
          <dependent id="14">Burton</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">couple</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">glittering</governor>
          <dependent id="17">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">couple</governor>
          <dependent id="18">glittering</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">Taylor</governor>
          <dependent id="19">couple</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">day</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">day</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">couple</governor>
          <dependent id="22">day</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the day" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="day" />
          </tokens>
        </entity>
        <entity id="2" string="Elizabeth Taylor" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Elizabeth" />
            <token id="11" string="Taylor" />
          </tokens>
        </entity>
        <entity id="3" string="Richard Burton" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Richard" />
            <token id="14" string="Burton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="120" has_coreference="true">
      <content>In 1967, with Desilu churning out a gold mine of televisions hits, &amp;quot;Star Trek&amp;quot; and &amp;quot;Mission: Impossible&amp;quot; among them, an exhausted Miss Ball decided that she had had enough.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1967" lemma="1967" stem="1967" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Desilu" lemma="desilu" stem="desilu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="churning" lemma="churn" stem="churn" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="gold" lemma="gold" stem="gold" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="mine" lemma="mine" stem="mine" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="televisions" lemma="television" stem="televis" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="hits" lemma="hit" stem="hit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="Star" lemma="Star" stem="star" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="Trek" lemma="Trek" stem="trek" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Mission" lemma="Mission" stem="mission" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="22" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="23" string="Impossible" lemma="impossible" stem="impossibl" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="24" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="exhausted" lemma="exhaust" stem="exhaust" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="32" string="decided" lemma="decide" stem="decid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="enough" lemma="enough" stem="enough" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1967))) (, ,) (PP (IN with) (NP (NP (NN Desilu)) (VP (VBG churning) (PRT (RP out)) (NP (NP (DT a) (NN gold) (NN mine)) (PP (IN of) (NP (NP (NNS televisions) (NNS hits)) (, ,) (`` ``) (NP (NNP Star) (NNP Trek)) ('' '') (CC and) (`` ``) (NP (NNP Mission)) (: :) (NP (JJ Impossible)) ('' '') (PP (IN among) (NP (PRP them))))))))) (, ,) (NP (DT an) (VBN exhausted) (NNP Miss) (NNP Ball)) (VP (VBD decided) (SBAR (IN that) (S (NP (PRP she)) (VP (VBD had) (VP (VBN had) (NP-TMP (RB enough))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="churning out a gold mine of televisions hits , `` Star Trek '' and `` Mission : Impossible '' among them" type="VP">
          <tokens>
            <token id="6" string="churning" />
            <token id="7" string="out" />
            <token id="8" string="a" />
            <token id="9" string="gold" />
            <token id="10" string="mine" />
            <token id="11" string="of" />
            <token id="12" string="televisions" />
            <token id="13" string="hits" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="Star" />
            <token id="17" string="Trek" />
            <token id="18" string="&quot;" />
            <token id="19" string="and" />
            <token id="20" string="&quot;" />
            <token id="21" string="Mission" />
            <token id="22" string=":" />
            <token id="23" string="Impossible" />
            <token id="24" string="&quot;" />
            <token id="25" string="among" />
            <token id="26" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="them" type="NP">
          <tokens>
            <token id="26" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="she" type="NP">
          <tokens>
            <token id="34" string="she" />
          </tokens>
        </chunking>
        <chunking id="4" string="had had enough" type="VP">
          <tokens>
            <token id="35" string="had" />
            <token id="36" string="had" />
            <token id="37" string="enough" />
          </tokens>
        </chunking>
        <chunking id="5" string="a gold mine" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="gold" />
            <token id="10" string="mine" />
          </tokens>
        </chunking>
        <chunking id="6" string="Desilu" type="NP">
          <tokens>
            <token id="5" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="7" string="televisions hits" type="NP">
          <tokens>
            <token id="12" string="televisions" />
            <token id="13" string="hits" />
          </tokens>
        </chunking>
        <chunking id="8" string="televisions hits , `` Star Trek '' and `` Mission : Impossible '' among them" type="NP">
          <tokens>
            <token id="12" string="televisions" />
            <token id="13" string="hits" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="Star" />
            <token id="17" string="Trek" />
            <token id="18" string="&quot;" />
            <token id="19" string="and" />
            <token id="20" string="&quot;" />
            <token id="21" string="Mission" />
            <token id="22" string=":" />
            <token id="23" string="Impossible" />
            <token id="24" string="&quot;" />
            <token id="25" string="among" />
            <token id="26" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="Desilu churning out a gold mine of televisions hits , `` Star Trek '' and `` Mission : Impossible '' among them" type="NP">
          <tokens>
            <token id="5" string="Desilu" />
            <token id="6" string="churning" />
            <token id="7" string="out" />
            <token id="8" string="a" />
            <token id="9" string="gold" />
            <token id="10" string="mine" />
            <token id="11" string="of" />
            <token id="12" string="televisions" />
            <token id="13" string="hits" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="Star" />
            <token id="17" string="Trek" />
            <token id="18" string="&quot;" />
            <token id="19" string="and" />
            <token id="20" string="&quot;" />
            <token id="21" string="Mission" />
            <token id="22" string=":" />
            <token id="23" string="Impossible" />
            <token id="24" string="&quot;" />
            <token id="25" string="among" />
            <token id="26" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="decided that she had had enough" type="VP">
          <tokens>
            <token id="32" string="decided" />
            <token id="33" string="that" />
            <token id="34" string="she" />
            <token id="35" string="had" />
            <token id="36" string="had" />
            <token id="37" string="enough" />
          </tokens>
        </chunking>
        <chunking id="11" string="had enough" type="VP">
          <tokens>
            <token id="36" string="had" />
            <token id="37" string="enough" />
          </tokens>
        </chunking>
        <chunking id="12" string="Star Trek" type="NP">
          <tokens>
            <token id="16" string="Star" />
            <token id="17" string="Trek" />
          </tokens>
        </chunking>
        <chunking id="13" string="an exhausted Miss Ball" type="NP">
          <tokens>
            <token id="28" string="an" />
            <token id="29" string="exhausted" />
            <token id="30" string="Miss" />
            <token id="31" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="14" string="Impossible" type="NP">
          <tokens>
            <token id="23" string="Impossible" />
          </tokens>
        </chunking>
        <chunking id="15" string="a gold mine of televisions hits , `` Star Trek '' and `` Mission : Impossible '' among them" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="gold" />
            <token id="10" string="mine" />
            <token id="11" string="of" />
            <token id="12" string="televisions" />
            <token id="13" string="hits" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="Star" />
            <token id="17" string="Trek" />
            <token id="18" string="&quot;" />
            <token id="19" string="and" />
            <token id="20" string="&quot;" />
            <token id="21" string="Mission" />
            <token id="22" string=":" />
            <token id="23" string="Impossible" />
            <token id="24" string="&quot;" />
            <token id="25" string="among" />
            <token id="26" string="them" />
          </tokens>
        </chunking>
        <chunking id="16" string="Mission" type="NP">
          <tokens>
            <token id="21" string="Mission" />
          </tokens>
        </chunking>
        <chunking id="17" string="that she had had enough" type="SBAR">
          <tokens>
            <token id="33" string="that" />
            <token id="34" string="she" />
            <token id="35" string="had" />
            <token id="36" string="had" />
            <token id="37" string="enough" />
          </tokens>
        </chunking>
        <chunking id="18" string="1967" type="NP">
          <tokens>
            <token id="2" string="1967" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1967</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">decided</governor>
          <dependent id="2">1967</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Desilu</governor>
          <dependent id="4">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">decided</governor>
          <dependent id="5">Desilu</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">Desilu</governor>
          <dependent id="6">churning</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">churning</governor>
          <dependent id="7">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">mine</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">mine</governor>
          <dependent id="9">gold</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">churning</governor>
          <dependent id="10">mine</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">mine</governor>
          <dependent id="10">mine</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">hits</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">hits</governor>
          <dependent id="12">televisions</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">mine</governor>
          <dependent id="13">hits</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Trek</governor>
          <dependent id="16">Star</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">hits</governor>
          <dependent id="17">Trek</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">mine</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">hits</governor>
          <dependent id="21">Mission</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">hits</governor>
          <dependent id="23">Impossible</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">them</governor>
          <dependent id="25">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">mine</governor>
          <dependent id="26">them</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Ball</governor>
          <dependent id="28">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">Ball</governor>
          <dependent id="29">exhausted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Ball</governor>
          <dependent id="30">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">decided</governor>
          <dependent id="31">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="32">decided</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">had</governor>
          <dependent id="33">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">had</governor>
          <dependent id="34">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">had</governor>
          <dependent id="35">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="32">decided</governor>
          <dependent id="36">had</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="36">had</governor>
          <dependent id="37">enough</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Mission : Impossible" type="MISC" score="0.0">
          <tokens>
            <token id="21" string="Mission" />
            <token id="22" string=":" />
            <token id="23" string="Impossible" />
          </tokens>
        </entity>
        <entity id="3" string="1967" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1967" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="121" has_coreference="false">
      <content>Gulf &amp;amp;amp; Western Industries bought the property for a reported $17 million.</content>
      <tokens>
        <token id="1" string="Gulf" lemma="Gulf" stem="gulf" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="&amp;amp;" lemma="&amp;" stem="&amp;amp;" pos="CC" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Western" lemma="Western" stem="western" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="Industries" lemma="Industries" stem="industri" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="bought" lemma="buy" stem="bought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="property" lemma="property" stem="properti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="reported" lemma="report" stem="report" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="12" string="17" lemma="17" stem="17" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="13" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Gulf) (CC &amp;) (NNP Western) (NNP Industries)) (VP (VBD bought) (NP (NP (DT the) (NN property)) (PP (IN for) (NP (DT a) (VBN reported) (QP ($ $) (CD 17) (CD million)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a reported $ 17 million" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="reported" />
            <token id="11" string="$" />
            <token id="12" string="17" />
            <token id="13" string="million" />
          </tokens>
        </chunking>
        <chunking id="2" string="bought the property for a reported $ 17 million" type="VP">
          <tokens>
            <token id="5" string="bought" />
            <token id="6" string="the" />
            <token id="7" string="property" />
            <token id="8" string="for" />
            <token id="9" string="a" />
            <token id="10" string="reported" />
            <token id="11" string="$" />
            <token id="12" string="17" />
            <token id="13" string="million" />
          </tokens>
        </chunking>
        <chunking id="3" string="Gulf &amp; Western Industries" type="NP">
          <tokens>
            <token id="1" string="Gulf" />
            <token id="2" string="&amp;amp;" />
            <token id="3" string="Western" />
            <token id="4" string="Industries" />
          </tokens>
        </chunking>
        <chunking id="4" string="the property for a reported $ 17 million" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="property" />
            <token id="8" string="for" />
            <token id="9" string="a" />
            <token id="10" string="reported" />
            <token id="11" string="$" />
            <token id="12" string="17" />
            <token id="13" string="million" />
          </tokens>
        </chunking>
        <chunking id="5" string="the property" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="property" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Industries</governor>
          <dependent id="1">Gulf</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Gulf</governor>
          <dependent id="2">&amp;</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Gulf</governor>
          <dependent id="3">Western</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">bought</governor>
          <dependent id="4">Industries</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">bought</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">property</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">bought</governor>
          <dependent id="7">property</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">$</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">$</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">$</governor>
          <dependent id="10">reported</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">property</governor>
          <dependent id="11">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">million</governor>
          <dependent id="12">17</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">$</governor>
          <dependent id="13">million</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gulf &amp;amp; Western Industries" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Gulf" />
            <token id="2" string="&amp;amp;" />
            <token id="3" string="Western" />
            <token id="4" string="Industries" />
          </tokens>
        </entity>
        <entity id="2" string="$ 17 million" type="MONEY" score="0.0">
          <tokens>
            <token id="11" string="$" />
            <token id="12" string="17" />
            <token id="13" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="122" has_coreference="true">
      <content>In place of Desilu, Miss Ball, along with Morton, launched the much smaller Lucille Ball Productions Inc. and in 1968, began filming &amp;quot;Here&amp;apost;s Lucy,&amp;quot; a series featuring Desi Jr. and Lucie.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Desilu" lemma="Desilu" stem="desilu" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="7" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Morton" lemma="Morton" stem="morton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="launched" lemma="launch" stem="launch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="smaller" lemma="smaller" stem="smaller" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="Productions" lemma="Productions" stem="product" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Inc." lemma="Inc." stem="inc." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="1968" lemma="1968" stem="1968" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="filming" lemma="film" stem="film" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="34" string="series" lemma="series" stem="seri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="35" string="featuring" lemma="feature" stem="featur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="Desi" lemma="Desi" stem="desi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="37" string="Jr." lemma="Jr." stem="jr." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="38" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="Lucie" lemma="Lucie" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (NN place)) (PP (IN of) (NP (NNP Desilu))))) (, ,) (NP (NNP Miss) (NNP Ball)) (, ,) (PP (IN along) (PP (IN with) (NP (NNP Morton)))) (, ,) (VP (VBD launched) (NP (NP (DT the) (JJ much) (JJR smaller)) (SBAR (WHNP (NP (NNP Lucille) (NNP Ball) (NNP Productions) (NNP Inc.)) (PRN (CC and) (PP (IN in) (NP (CD 1968))))) (, ,) (S (VP (VBD began) (S (VP (VBG filming) (`` ``) (NP (RB Here)))))))) (S (NP (POS 's)))) (NP (NP (NP (NNP Lucy)) (PRN (, ,) ('' '') (S (NP (DT a) (NN series)) (VP (VBG featuring) (NP (NNP Desi) (NNP Jr.)))))) (CC and) (NP (NNP Lucie))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="place of Desilu" type="NP">
          <tokens>
            <token id="2" string="place" />
            <token id="3" string="of" />
            <token id="4" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="2" string="Lucille Ball Productions Inc." type="NP">
          <tokens>
            <token id="17" string="Lucille" />
            <token id="18" string="Ball" />
            <token id="19" string="Productions" />
            <token id="20" string="Inc." />
          </tokens>
        </chunking>
        <chunking id="3" string="Desi Jr." type="NP">
          <tokens>
            <token id="36" string="Desi" />
            <token id="37" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="4" string="began filming `` Here" type="VP">
          <tokens>
            <token id="25" string="began" />
            <token id="26" string="filming" />
            <token id="27" string="&quot;" />
            <token id="28" string="Here" />
          </tokens>
        </chunking>
        <chunking id="5" string="filming `` Here" type="VP">
          <tokens>
            <token id="26" string="filming" />
            <token id="27" string="&quot;" />
            <token id="28" string="Here" />
          </tokens>
        </chunking>
        <chunking id="6" string="featuring Desi Jr." type="VP">
          <tokens>
            <token id="35" string="featuring" />
            <token id="36" string="Desi" />
            <token id="37" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="7" string="launched the much smaller Lucille Ball Productions Inc. and in 1968 , began filming `` Here 's" type="VP">
          <tokens>
            <token id="13" string="launched" />
            <token id="14" string="the" />
            <token id="15" string="much" />
            <token id="16" string="smaller" />
            <token id="17" string="Lucille" />
            <token id="18" string="Ball" />
            <token id="19" string="Productions" />
            <token id="20" string="Inc." />
            <token id="21" string="and" />
            <token id="22" string="in" />
            <token id="23" string="1968" />
            <token id="24" string="," />
            <token id="25" string="began" />
            <token id="26" string="filming" />
            <token id="27" string="&quot;" />
            <token id="28" string="Here" />
            <token id="29" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="Lucille Ball Productions Inc. and in 1968 , began filming `` Here" type="SBAR">
          <tokens>
            <token id="17" string="Lucille" />
            <token id="18" string="Ball" />
            <token id="19" string="Productions" />
            <token id="20" string="Inc." />
            <token id="21" string="and" />
            <token id="22" string="in" />
            <token id="23" string="1968" />
            <token id="24" string="," />
            <token id="25" string="began" />
            <token id="26" string="filming" />
            <token id="27" string="&quot;" />
            <token id="28" string="Here" />
          </tokens>
        </chunking>
        <chunking id="9" string="'s" type="NP">
          <tokens>
            <token id="29" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="Here" type="NP">
          <tokens>
            <token id="28" string="Here" />
          </tokens>
        </chunking>
        <chunking id="11" string="a series" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="series" />
          </tokens>
        </chunking>
        <chunking id="12" string="Lucie" type="NP">
          <tokens>
            <token id="39" string="Lucie" />
          </tokens>
        </chunking>
        <chunking id="13" string="Desilu" type="NP">
          <tokens>
            <token id="4" string="Desilu" />
          </tokens>
        </chunking>
        <chunking id="14" string="Morton" type="NP">
          <tokens>
            <token id="11" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="15" string="Lucy , '' a series featuring Desi Jr. and Lucie" type="NP">
          <tokens>
            <token id="30" string="Lucy" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="a" />
            <token id="34" string="series" />
            <token id="35" string="featuring" />
            <token id="36" string="Desi" />
            <token id="37" string="Jr." />
            <token id="38" string="and" />
            <token id="39" string="Lucie" />
          </tokens>
        </chunking>
        <chunking id="16" string="Lucy , '' a series featuring Desi Jr." type="NP">
          <tokens>
            <token id="30" string="Lucy" />
            <token id="31" string="," />
            <token id="32" string="&quot;" />
            <token id="33" string="a" />
            <token id="34" string="series" />
            <token id="35" string="featuring" />
            <token id="36" string="Desi" />
            <token id="37" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="17" string="the much smaller" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="much" />
            <token id="16" string="smaller" />
          </tokens>
        </chunking>
        <chunking id="18" string="place" type="NP">
          <tokens>
            <token id="2" string="place" />
          </tokens>
        </chunking>
        <chunking id="19" string="the much smaller Lucille Ball Productions Inc. and in 1968 , began filming `` Here" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="much" />
            <token id="16" string="smaller" />
            <token id="17" string="Lucille" />
            <token id="18" string="Ball" />
            <token id="19" string="Productions" />
            <token id="20" string="Inc." />
            <token id="21" string="and" />
            <token id="22" string="in" />
            <token id="23" string="1968" />
            <token id="24" string="," />
            <token id="25" string="began" />
            <token id="26" string="filming" />
            <token id="27" string="&quot;" />
            <token id="28" string="Here" />
          </tokens>
        </chunking>
        <chunking id="20" string="Lucy" type="NP">
          <tokens>
            <token id="30" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="21" string="1968" type="NP">
          <tokens>
            <token id="23" string="1968" />
          </tokens>
        </chunking>
        <chunking id="22" string="Miss Ball" type="NP">
          <tokens>
            <token id="6" string="Miss" />
            <token id="7" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">Desilu</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">In</governor>
          <dependent id="2">place</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">In</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">launched</governor>
          <dependent id="4">Desilu</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Ball</governor>
          <dependent id="6">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">launched</governor>
          <dependent id="7">Ball</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Morton</governor>
          <dependent id="9">along</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="9">along</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">launched</governor>
          <dependent id="11">Morton</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">launched</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">smaller</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">smaller</governor>
          <dependent id="15">much</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">launched</governor>
          <dependent id="16">smaller</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Inc.</governor>
          <dependent id="17">Lucille</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Inc.</governor>
          <dependent id="18">Ball</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Inc.</governor>
          <dependent id="19">Productions</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">began</governor>
          <dependent id="20">Inc.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">1968</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">1968</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">Inc.</governor>
          <dependent id="23">1968</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">smaller</governor>
          <dependent id="25">began</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">began</governor>
          <dependent id="26">filming</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">filming</governor>
          <dependent id="28">Here</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">launched</governor>
          <dependent id="29">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">launched</governor>
          <dependent id="30">Lucy</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">series</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">featuring</governor>
          <dependent id="34">series</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="30">Lucy</governor>
          <dependent id="35">featuring</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Jr.</governor>
          <dependent id="36">Desi</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">featuring</governor>
          <dependent id="37">Jr.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">Lucy</governor>
          <dependent id="38">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">Lucy</governor>
          <dependent id="39">Lucie</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucie" type="PERSON" score="0.0">
          <tokens>
            <token id="39" string="Lucie" />
          </tokens>
        </entity>
        <entity id="2" string="Morton" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Morton" />
          </tokens>
        </entity>
        <entity id="3" string="Lucille Ball Productions Inc." type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Lucille" />
            <token id="18" string="Ball" />
            <token id="19" string="Productions" />
            <token id="20" string="Inc." />
          </tokens>
        </entity>
        <entity id="4" string="Desi Jr." type="PERSON" score="0.0">
          <tokens>
            <token id="36" string="Desi" />
            <token id="37" string="Jr." />
          </tokens>
        </entity>
        <entity id="5" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Lucy" />
          </tokens>
        </entity>
        <entity id="6" string="1968" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="1968" />
          </tokens>
        </entity>
        <entity id="7" string="Miss Ball" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="Miss" />
            <token id="7" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="123" has_coreference="true">
      <content>&amp;quot;My life started when my children were born,&amp;quot; Miss Ball said at the time.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP$ My) (NN life)) (VP (VBD started) (SBAR (WHADVP (WRB when)) (S (NP (PRP$ my) (NNS children)) (VP (VBD were) (VP (VBN born))))))) (, ,) ('' '') (NP (NNP Miss) (NNP Ball)) (VP (VBD said) (PP (IN at) (NP (DT the) (NN time)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="My life" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="were born" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="born" />
          </tokens>
        </chunking>
        <chunking id="3" string="said at the time" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="at" />
            <token id="16" string="the" />
            <token id="17" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="started when my children were born" type="VP">
          <tokens>
            <token id="4" string="started" />
            <token id="5" string="when" />
            <token id="6" string="my" />
            <token id="7" string="children" />
            <token id="8" string="were" />
            <token id="9" string="born" />
          </tokens>
        </chunking>
        <chunking id="5" string="when my children were born" type="SBAR">
          <tokens>
            <token id="5" string="when" />
            <token id="6" string="my" />
            <token id="7" string="children" />
            <token id="8" string="were" />
            <token id="9" string="born" />
          </tokens>
        </chunking>
        <chunking id="6" string="born" type="VP">
          <tokens>
            <token id="9" string="born" />
          </tokens>
        </chunking>
        <chunking id="7" string="the time" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="my children" type="NP">
          <tokens>
            <token id="6" string="my" />
            <token id="7" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="5" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="Miss Ball" type="NP">
          <tokens>
            <token id="12" string="Miss" />
            <token id="13" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">life</governor>
          <dependent id="2">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">started</governor>
          <dependent id="3">life</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="4">started</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">born</governor>
          <dependent id="5">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">children</governor>
          <dependent id="6">my</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">born</governor>
          <dependent id="7">children</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">born</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">started</governor>
          <dependent id="9">born</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Ball</governor>
          <dependent id="12">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">time</governor>
          <dependent id="15">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">time</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">said</governor>
          <dependent id="17">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="time" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="time" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="124" has_coreference="true">
      <content>&amp;quot;I couldn&amp;apost;t wait to work with them. . . .</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="wait" lemma="wait" stem="wait" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (MD could) (RB n't) (VP (VB wait) (S (VP (TO to) (VP (VB work) (PP (IN with) (NP (PRP them)))))))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could n't wait to work with them" type="VP">
          <tokens>
            <token id="3" string="could" />
            <token id="4" string="n't" />
            <token id="5" string="wait" />
            <token id="6" string="to" />
            <token id="7" string="work" />
            <token id="8" string="with" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="to work with them" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="work" />
            <token id="8" string="with" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="wait to work with them" type="VP">
          <tokens>
            <token id="5" string="wait" />
            <token id="6" string="to" />
            <token id="7" string="work" />
            <token id="8" string="with" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="them" type="NP">
          <tokens>
            <token id="9" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="work with them" type="VP">
          <tokens>
            <token id="7" string="work" />
            <token id="8" string="with" />
            <token id="9" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">wait</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">wait</governor>
          <dependent id="3">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">wait</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">wait</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">work</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">wait</governor>
          <dependent id="7">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">them</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">work</governor>
          <dependent id="9">them</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="125" has_coreference="true">
      <content>Even when they moved out of the house, they were still home at the studio.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="moved" lemma="move" stem="move" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="out" lemma="out" stem="out" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="studio" lemma="studio" stem="studio" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (RB Even) (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBD moved) (ADVP (RB out)) (PP (IN of) (NP (DT the) (NN house)))))) (, ,) (NP (PRP they)) (VP (VBD were) (ADVP (RB still)) (NP (NP (NN home)) (PP (IN at) (NP (DT the) (NN studio))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="Even when they moved out of the house" type="SBAR">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="when" />
            <token id="3" string="they" />
            <token id="4" string="moved" />
            <token id="5" string="out" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="house" />
          </tokens>
        </chunking>
        <chunking id="3" string="moved out of the house" type="VP">
          <tokens>
            <token id="4" string="moved" />
            <token id="5" string="out" />
            <token id="6" string="of" />
            <token id="7" string="the" />
            <token id="8" string="house" />
          </tokens>
        </chunking>
        <chunking id="4" string="home at the studio" type="NP">
          <tokens>
            <token id="13" string="home" />
            <token id="14" string="at" />
            <token id="15" string="the" />
            <token id="16" string="studio" />
          </tokens>
        </chunking>
        <chunking id="5" string="were still home at the studio" type="VP">
          <tokens>
            <token id="11" string="were" />
            <token id="12" string="still" />
            <token id="13" string="home" />
            <token id="14" string="at" />
            <token id="15" string="the" />
            <token id="16" string="studio" />
          </tokens>
        </chunking>
        <chunking id="6" string="the house" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="house" />
          </tokens>
        </chunking>
        <chunking id="7" string="the studio" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="studio" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="2" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="home" type="NP">
          <tokens>
            <token id="13" string="home" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">moved</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">moved</governor>
          <dependent id="2">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">moved</governor>
          <dependent id="3">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">home</governor>
          <dependent id="4">moved</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">moved</governor>
          <dependent id="5">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">house</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">house</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">moved</governor>
          <dependent id="8">house</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">home</governor>
          <dependent id="10">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">home</governor>
          <dependent id="11">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">home</governor>
          <dependent id="12">still</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">studio</governor>
          <dependent id="14">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">studio</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">home</governor>
          <dependent id="16">studio</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="126" has_coreference="true">
      <content>I liked that.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="liked" lemma="like" stem="like" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD liked) (ADVP (IN that))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="liked that" type="VP">
          <tokens>
            <token id="2" string="liked" />
            <token id="3" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">liked</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">liked</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">liked</governor>
          <dependent id="3">that</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="127" has_coreference="true">
      <content>The series aired through 1974.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="series" lemma="series" stem="seri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="aired" lemma="air" stem="air" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="1974" lemma="1974" stem="1974" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN series)) (VP (VBD aired) (PP (IN through) (NP (CD 1974)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The series" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="series" />
          </tokens>
        </chunking>
        <chunking id="2" string="1974" type="NP">
          <tokens>
            <token id="5" string="1974" />
          </tokens>
        </chunking>
        <chunking id="3" string="aired through 1974" type="VP">
          <tokens>
            <token id="3" string="aired" />
            <token id="4" string="through" />
            <token id="5" string="1974" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">series</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">aired</governor>
          <dependent id="2">series</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">aired</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">1974</governor>
          <dependent id="4">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">aired</governor>
          <dependent id="5">1974</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1974" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="1974" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="128" has_coreference="true">
      <content>With her children&amp;apost;s careers off the launching pad, the comedienne, then 63, decided it was time to retire her legendary character.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="careers" lemma="career" stem="career" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="off" lemma="off" stem="off" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="launching" lemma="launch" stem="launch" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="pad" lemma="pad" stem="pad" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="comedienne" lemma="comedienne" stem="comedienn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="63" lemma="63" stem="63" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="decided" lemma="decide" stem="decid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="retire" lemma="retire" stem="retir" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="legendary" lemma="legendary" stem="legendari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="character" lemma="character" stem="charact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN With) (NP (NP (NP (PRP$ her) (NNS children) (POS 's)) (NNS careers)) (PP (IN off) (NP (DT the) (VBG launching) (NN pad))))) (, ,) (NP (NP (DT the) (NN comedienne)) (, ,) (NP (RB then) (CD 63)) (, ,)) (VP (VBD decided) (SBAR (S (NP (PRP it)) (VP (VBD was) (VP (NN time) (S (VP (TO to) (VP (VB retire) (NP (PRP$ her) (JJ legendary) (NN character)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her children 's" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="children" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="to retire her legendary character" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="retire" />
            <token id="23" string="her" />
            <token id="24" string="legendary" />
            <token id="25" string="character" />
          </tokens>
        </chunking>
        <chunking id="3" string="decided it was time to retire her legendary character" type="VP">
          <tokens>
            <token id="17" string="decided" />
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="time" />
            <token id="21" string="to" />
            <token id="22" string="retire" />
            <token id="23" string="her" />
            <token id="24" string="legendary" />
            <token id="25" string="character" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="18" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="the comedienne , then 63 ," type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="comedienne" />
            <token id="13" string="," />
            <token id="14" string="then" />
            <token id="15" string="63" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="the launching pad" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="launching" />
            <token id="9" string="pad" />
          </tokens>
        </chunking>
        <chunking id="7" string="then 63" type="NP">
          <tokens>
            <token id="14" string="then" />
            <token id="15" string="63" />
          </tokens>
        </chunking>
        <chunking id="8" string="her children 's careers off the launching pad" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="children" />
            <token id="4" string="'s" />
            <token id="5" string="careers" />
            <token id="6" string="off" />
            <token id="7" string="the" />
            <token id="8" string="launching" />
            <token id="9" string="pad" />
          </tokens>
        </chunking>
        <chunking id="9" string="was time to retire her legendary character" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="time" />
            <token id="21" string="to" />
            <token id="22" string="retire" />
            <token id="23" string="her" />
            <token id="24" string="legendary" />
            <token id="25" string="character" />
          </tokens>
        </chunking>
        <chunking id="10" string="time to retire her legendary character" type="VP">
          <tokens>
            <token id="20" string="time" />
            <token id="21" string="to" />
            <token id="22" string="retire" />
            <token id="23" string="her" />
            <token id="24" string="legendary" />
            <token id="25" string="character" />
          </tokens>
        </chunking>
        <chunking id="11" string="retire her legendary character" type="VP">
          <tokens>
            <token id="22" string="retire" />
            <token id="23" string="her" />
            <token id="24" string="legendary" />
            <token id="25" string="character" />
          </tokens>
        </chunking>
        <chunking id="12" string="it was time to retire her legendary character" type="SBAR">
          <tokens>
            <token id="18" string="it" />
            <token id="19" string="was" />
            <token id="20" string="time" />
            <token id="21" string="to" />
            <token id="22" string="retire" />
            <token id="23" string="her" />
            <token id="24" string="legendary" />
            <token id="25" string="character" />
          </tokens>
        </chunking>
        <chunking id="13" string="her children 's careers" type="NP">
          <tokens>
            <token id="2" string="her" />
            <token id="3" string="children" />
            <token id="4" string="'s" />
            <token id="5" string="careers" />
          </tokens>
        </chunking>
        <chunking id="14" string="her legendary character" type="NP">
          <tokens>
            <token id="23" string="her" />
            <token id="24" string="legendary" />
            <token id="25" string="character" />
          </tokens>
        </chunking>
        <chunking id="15" string="the comedienne" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="comedienne" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">careers</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">children</governor>
          <dependent id="2">her</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">careers</governor>
          <dependent id="3">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">children</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">decided</governor>
          <dependent id="5">careers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">pad</governor>
          <dependent id="6">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">pad</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">pad</governor>
          <dependent id="8">launching</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">careers</governor>
          <dependent id="9">pad</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">comedienne</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">decided</governor>
          <dependent id="12">comedienne</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">63</governor>
          <dependent id="14">then</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">comedienne</governor>
          <dependent id="15">63</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">decided</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">time</governor>
          <dependent id="18">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">time</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">decided</governor>
          <dependent id="20">time</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">retire</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">time</governor>
          <dependent id="22">retire</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">character</governor>
          <dependent id="23">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">character</governor>
          <dependent id="24">legendary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">retire</governor>
          <dependent id="25">character</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="63" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="63" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="129" has_coreference="true">
      <content>&amp;quot;The Lucy character is too old to run around like an idiot,&amp;quot; she said in explanation.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="4" string="character" lemma="character" stem="charact" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="around" lemma="around" stem="around" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="idiot" lemma="idiot" stem="idiot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="explanation" lemma="explanation" stem="explan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (NNP Lucy) (NN character)) (VP (VBZ is) (ADJP (RB too) (JJ old)) (S (VP (TO to) (VP (VB run) (PRT (RP around)) (PP (IN like) (NP (DT an) (NN idiot)))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said) (PP (IN in) (NP (NN explanation)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="too old" type="ADJP">
          <tokens>
            <token id="6" string="too" />
            <token id="7" string="old" />
          </tokens>
        </chunking>
        <chunking id="2" string="is too old to run around like an idiot" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="too" />
            <token id="7" string="old" />
            <token id="8" string="to" />
            <token id="9" string="run" />
            <token id="10" string="around" />
            <token id="11" string="like" />
            <token id="12" string="an" />
            <token id="13" string="idiot" />
          </tokens>
        </chunking>
        <chunking id="3" string="said in explanation" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="in" />
            <token id="19" string="explanation" />
          </tokens>
        </chunking>
        <chunking id="4" string="to run around like an idiot" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="run" />
            <token id="10" string="around" />
            <token id="11" string="like" />
            <token id="12" string="an" />
            <token id="13" string="idiot" />
          </tokens>
        </chunking>
        <chunking id="5" string="explanation" type="NP">
          <tokens>
            <token id="19" string="explanation" />
          </tokens>
        </chunking>
        <chunking id="6" string="an idiot" type="NP">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="idiot" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="16" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="The Lucy character" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="Lucy" />
            <token id="4" string="character" />
          </tokens>
        </chunking>
        <chunking id="9" string="run around like an idiot" type="VP">
          <tokens>
            <token id="9" string="run" />
            <token id="10" string="around" />
            <token id="11" string="like" />
            <token id="12" string="an" />
            <token id="13" string="idiot" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">character</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">character</governor>
          <dependent id="3">Lucy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">old</governor>
          <dependent id="4">character</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">old</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">old</governor>
          <dependent id="6">too</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="7">old</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">run</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">old</governor>
          <dependent id="9">run</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="9">run</governor>
          <dependent id="10">around</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">idiot</governor>
          <dependent id="11">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">idiot</governor>
          <dependent id="12">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">run</governor>
          <dependent id="13">idiot</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="16">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">explanation</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">said</governor>
          <dependent id="19">explanation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="130" has_coreference="true">
      <content>That same year, she filmed her final motion picture, &amp;quot;Mame,&amp;quot; a version of the Broadway musical.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="filmed" lemma="film" stem="film" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="motion" lemma="motion" stem="motion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="picture" lemma="picture" stem="pictur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Mame" lemma="Mame" stem="mame" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="version" lemma="version" stem="version" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Broadway" lemma="Broadway" stem="broadwai" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="musical" lemma="musical" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (DT That) (JJ same) (NN year)) (, ,) (NP (PRP she)) (VP (VBD filmed) (NP (NP (PRP$ her) (JJ final) (NN motion) (NN picture)) (, ,) (`` ``) (NP (NNP Mame)) (, ,) ('' '') (NP (NP (DT a) (NN version)) (PP (IN of) (NP (DT the) (NNP Broadway) (NN musical)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="filmed her final motion picture , `` Mame , '' a version of the Broadway musical" type="VP">
          <tokens>
            <token id="6" string="filmed" />
            <token id="7" string="her" />
            <token id="8" string="final" />
            <token id="9" string="motion" />
            <token id="10" string="picture" />
            <token id="11" string="," />
            <token id="12" string="&quot;" />
            <token id="13" string="Mame" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="a" />
            <token id="17" string="version" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="Broadway" />
            <token id="21" string="musical" />
          </tokens>
        </chunking>
        <chunking id="2" string="a version" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="version" />
          </tokens>
        </chunking>
        <chunking id="3" string="her final motion picture" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="final" />
            <token id="9" string="motion" />
            <token id="10" string="picture" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Broadway musical" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Broadway" />
            <token id="21" string="musical" />
          </tokens>
        </chunking>
        <chunking id="5" string="her final motion picture , `` Mame , '' a version of the Broadway musical" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="final" />
            <token id="9" string="motion" />
            <token id="10" string="picture" />
            <token id="11" string="," />
            <token id="12" string="&quot;" />
            <token id="13" string="Mame" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="a" />
            <token id="17" string="version" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="Broadway" />
            <token id="21" string="musical" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="a version of the Broadway musical" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="version" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="Broadway" />
            <token id="21" string="musical" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mame" type="NP">
          <tokens>
            <token id="13" string="Mame" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">year</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">year</governor>
          <dependent id="2">same</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">filmed</governor>
          <dependent id="3">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">filmed</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">filmed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">picture</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">picture</governor>
          <dependent id="8">final</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">picture</governor>
          <dependent id="9">motion</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">filmed</governor>
          <dependent id="10">picture</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">picture</governor>
          <dependent id="13">Mame</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">version</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">picture</governor>
          <dependent id="17">version</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">musical</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">musical</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">musical</governor>
          <dependent id="20">Broadway</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">version</governor>
          <dependent id="21">musical</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="year" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="Broadway" type="MISC" score="0.0">
          <tokens>
            <token id="20" string="Broadway" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="131" has_coreference="true">
      <content>Although by now the world&amp;apost;s best-known television star, as a movie star Miss Ball again received mixed reviews.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="best-known" lemma="best-known" stem="best-known" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="star" lemma="star" stem="star" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="star" lemma="star" stem="star" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="16" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="17" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="received" lemma="receive" stem="receiv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="mixed" lemma="mixed" stem="mix" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="reviews" lemma="review" stem="review" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (FRAG (PP (IN by) (NP (NP (RB now)) (NP (NP (DT the) (NN world) (POS 's)) (JJ best-known) (NN television) (NN star)))))) (, ,) (PP (IN as) (NP (DT a) (NN movie) (NN star))) (NP (NNP Miss) (NNP Ball)) (VP (ADVP (RB again)) (VBD received) (NP (JJ mixed) (NNS reviews))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="mixed reviews" type="NP">
          <tokens>
            <token id="19" string="mixed" />
            <token id="20" string="reviews" />
          </tokens>
        </chunking>
        <chunking id="2" string="a movie star" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="movie" />
            <token id="14" string="star" />
          </tokens>
        </chunking>
        <chunking id="3" string="now" type="NP">
          <tokens>
            <token id="3" string="now" />
          </tokens>
        </chunking>
        <chunking id="4" string="Although by now the world 's best-known television star" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="by" />
            <token id="3" string="now" />
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
            <token id="7" string="best-known" />
            <token id="8" string="television" />
            <token id="9" string="star" />
          </tokens>
        </chunking>
        <chunking id="5" string="the world 's best-known television star" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
            <token id="7" string="best-known" />
            <token id="8" string="television" />
            <token id="9" string="star" />
          </tokens>
        </chunking>
        <chunking id="6" string="again received mixed reviews" type="VP">
          <tokens>
            <token id="17" string="again" />
            <token id="18" string="received" />
            <token id="19" string="mixed" />
            <token id="20" string="reviews" />
          </tokens>
        </chunking>
        <chunking id="7" string="now the world 's best-known television star" type="NP">
          <tokens>
            <token id="3" string="now" />
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
            <token id="7" string="best-known" />
            <token id="8" string="television" />
            <token id="9" string="star" />
          </tokens>
        </chunking>
        <chunking id="8" string="the world 's" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="world" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="Miss Ball" type="NP">
          <tokens>
            <token id="15" string="Miss" />
            <token id="16" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">now</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">now</governor>
          <dependent id="2">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">received</governor>
          <dependent id="3">now</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">world</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">star</governor>
          <dependent id="5">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">world</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">star</governor>
          <dependent id="7">best-known</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">star</governor>
          <dependent id="8">television</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">now</governor>
          <dependent id="9">star</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">star</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">star</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">star</governor>
          <dependent id="13">movie</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">received</governor>
          <dependent id="14">star</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Ball</governor>
          <dependent id="15">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">received</governor>
          <dependent id="16">Ball</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">received</governor>
          <dependent id="17">again</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">received</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">reviews</governor>
          <dependent id="19">mixed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">received</governor>
          <dependent id="20">reviews</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Miss Ball" type="MISC" score="0.0">
          <tokens>
            <token id="15" string="Miss" />
            <token id="16" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="132" has_coreference="true">
      <content>Times critic Charles Champlin wrote, &amp;quot;The shame about &amp;apost;Mame&amp;apost; is that it managed to deny us a Lucy to love.&amp;quot;</content>
      <tokens>
        <token id="1" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="critic" lemma="critic" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Charles" lemma="Charles" stem="charl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="Champlin" lemma="Champlin" stem="champlin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="5" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="shame" lemma="shame" stem="shame" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Mame" lemma="Mame" stem="mame" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="managed" lemma="manage" stem="manag" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="deny" lemma="deny" stem="deni" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="love" lemma="love" stem="love" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Times) (NN critic) (NNP Charles) (NNP Champlin)) (VP (VBD wrote) (, ,) (`` ``) (S (NP (NP (DT The) (NN shame)) (PP (IN about) (`` `) (NP (NNP Mame)) ('' '))) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP it)) (VP (VBD managed) (S (VP (TO to) (VP (VB deny) (NP (PRP us)) (NP (DT a) (NNP Lucy)) (S (VP (TO to) (VP (VB love))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="love" type="VP">
          <tokens>
            <token id="24" string="love" />
          </tokens>
        </chunking>
        <chunking id="2" string="to love" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="love" />
          </tokens>
        </chunking>
        <chunking id="3" string="to deny us a Lucy to love" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="deny" />
            <token id="20" string="us" />
            <token id="21" string="a" />
            <token id="22" string="Lucy" />
            <token id="23" string="to" />
            <token id="24" string="love" />
          </tokens>
        </chunking>
        <chunking id="4" string="that it managed to deny us a Lucy to love" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="it" />
            <token id="17" string="managed" />
            <token id="18" string="to" />
            <token id="19" string="deny" />
            <token id="20" string="us" />
            <token id="21" string="a" />
            <token id="22" string="Lucy" />
            <token id="23" string="to" />
            <token id="24" string="love" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="managed to deny us a Lucy to love" type="VP">
          <tokens>
            <token id="17" string="managed" />
            <token id="18" string="to" />
            <token id="19" string="deny" />
            <token id="20" string="us" />
            <token id="21" string="a" />
            <token id="22" string="Lucy" />
            <token id="23" string="to" />
            <token id="24" string="love" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mame" type="NP">
          <tokens>
            <token id="12" string="Mame" />
          </tokens>
        </chunking>
        <chunking id="8" string="The shame" type="NP">
          <tokens>
            <token id="8" string="The" />
            <token id="9" string="shame" />
          </tokens>
        </chunking>
        <chunking id="9" string="a Lucy" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="10" string="The shame about ` Mame '" type="NP">
          <tokens>
            <token id="8" string="The" />
            <token id="9" string="shame" />
            <token id="10" string="about" />
            <token id="11" string="'" />
            <token id="12" string="Mame" />
            <token id="13" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="Times critic Charles Champlin" type="NP">
          <tokens>
            <token id="1" string="Times" />
            <token id="2" string="critic" />
            <token id="3" string="Charles" />
            <token id="4" string="Champlin" />
          </tokens>
        </chunking>
        <chunking id="12" string="is that it managed to deny us a Lucy to love" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="that" />
            <token id="16" string="it" />
            <token id="17" string="managed" />
            <token id="18" string="to" />
            <token id="19" string="deny" />
            <token id="20" string="us" />
            <token id="21" string="a" />
            <token id="22" string="Lucy" />
            <token id="23" string="to" />
            <token id="24" string="love" />
          </tokens>
        </chunking>
        <chunking id="13" string="wrote , `` The shame about ` Mame ' is that it managed to deny us a Lucy to love" type="VP">
          <tokens>
            <token id="5" string="wrote" />
            <token id="6" string="," />
            <token id="7" string="&quot;" />
            <token id="8" string="The" />
            <token id="9" string="shame" />
            <token id="10" string="about" />
            <token id="11" string="'" />
            <token id="12" string="Mame" />
            <token id="13" string="'" />
            <token id="14" string="is" />
            <token id="15" string="that" />
            <token id="16" string="it" />
            <token id="17" string="managed" />
            <token id="18" string="to" />
            <token id="19" string="deny" />
            <token id="20" string="us" />
            <token id="21" string="a" />
            <token id="22" string="Lucy" />
            <token id="23" string="to" />
            <token id="24" string="love" />
          </tokens>
        </chunking>
        <chunking id="14" string="deny us a Lucy to love" type="VP">
          <tokens>
            <token id="19" string="deny" />
            <token id="20" string="us" />
            <token id="21" string="a" />
            <token id="22" string="Lucy" />
            <token id="23" string="to" />
            <token id="24" string="love" />
          </tokens>
        </chunking>
        <chunking id="15" string="us" type="NP">
          <tokens>
            <token id="20" string="us" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="4">Champlin</governor>
          <dependent id="1">Times</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Champlin</governor>
          <dependent id="2">critic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Champlin</governor>
          <dependent id="3">Charles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">wrote</governor>
          <dependent id="4">Champlin</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">wrote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">shame</governor>
          <dependent id="8">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">is</governor>
          <dependent id="9">shame</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Mame</governor>
          <dependent id="10">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">shame</governor>
          <dependent id="12">Mame</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">wrote</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">managed</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">managed</governor>
          <dependent id="16">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">is</governor>
          <dependent id="17">managed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">deny</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">managed</governor>
          <dependent id="19">deny</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="19">deny</governor>
          <dependent id="20">us</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Lucy</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">deny</governor>
          <dependent id="22">Lucy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">love</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">deny</governor>
          <dependent id="24">love</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Charles Champlin" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Charles" />
            <token id="4" string="Champlin" />
          </tokens>
        </entity>
        <entity id="2" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="133" has_coreference="true">
      <content>With those final starring credits to her name, she settled into co-producing shows, making occasional television appearances and accepting one after another of a continual barrage of awards and tributes.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="starring" lemma="star" stem="star" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="credits" lemma="credit" stem="credit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="name" lemma="name" stem="name" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="settled" lemma="settle" stem="settl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="co-producing" lemma="co-produce" stem="co-produc" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="shows" lemma="show" stem="show" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="occasional" lemma="occasional" stem="occasion" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="appearances" lemma="appearance" stem="appear" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="accepting" lemma="accept" stem="accept" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="continual" lemma="continual" stem="continu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="barrage" lemma="barrage" stem="barrag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="awards" lemma="award" stem="award" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="tributes" lemma="tribute" stem="tribut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN With) (S (NP (DT those) (JJ final)) (VP (VBG starring) (NP (NNS credits)) (PP (TO to) (NP (PRP$ her) (NN name)))))) (, ,) (NP (PRP she)) (VP (VBD settled) (PP (IN into) (S (VP (VP (VBG co-producing) (NP (NNS shows))) (, ,) (VP (VBG making) (NP (JJ occasional) (NN television) (NNS appearances))) (CC and) (VP (VBG accepting) (NP (CD one)) (PP (IN after) (NP (NP (DT another)) (PP (IN of) (NP (NP (DT a) (JJ continual) (NN barrage)) (PP (IN of) (NP (NNS awards) (CC and) (NNS tributes)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="settled into co-producing shows , making occasional television appearances and accepting one after another of a continual barrage of awards and tributes" type="VP">
          <tokens>
            <token id="11" string="settled" />
            <token id="12" string="into" />
            <token id="13" string="co-producing" />
            <token id="14" string="shows" />
            <token id="15" string="," />
            <token id="16" string="making" />
            <token id="17" string="occasional" />
            <token id="18" string="television" />
            <token id="19" string="appearances" />
            <token id="20" string="and" />
            <token id="21" string="accepting" />
            <token id="22" string="one" />
            <token id="23" string="after" />
            <token id="24" string="another" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="continual" />
            <token id="28" string="barrage" />
            <token id="29" string="of" />
            <token id="30" string="awards" />
            <token id="31" string="and" />
            <token id="32" string="tributes" />
          </tokens>
        </chunking>
        <chunking id="2" string="accepting one after another of a continual barrage of awards and tributes" type="VP">
          <tokens>
            <token id="21" string="accepting" />
            <token id="22" string="one" />
            <token id="23" string="after" />
            <token id="24" string="another" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="continual" />
            <token id="28" string="barrage" />
            <token id="29" string="of" />
            <token id="30" string="awards" />
            <token id="31" string="and" />
            <token id="32" string="tributes" />
          </tokens>
        </chunking>
        <chunking id="3" string="co-producing shows , making occasional television appearances and accepting one after another of a continual barrage of awards and tributes" type="VP">
          <tokens>
            <token id="13" string="co-producing" />
            <token id="14" string="shows" />
            <token id="15" string="," />
            <token id="16" string="making" />
            <token id="17" string="occasional" />
            <token id="18" string="television" />
            <token id="19" string="appearances" />
            <token id="20" string="and" />
            <token id="21" string="accepting" />
            <token id="22" string="one" />
            <token id="23" string="after" />
            <token id="24" string="another" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="continual" />
            <token id="28" string="barrage" />
            <token id="29" string="of" />
            <token id="30" string="awards" />
            <token id="31" string="and" />
            <token id="32" string="tributes" />
          </tokens>
        </chunking>
        <chunking id="4" string="one" type="NP">
          <tokens>
            <token id="22" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="awards and tributes" type="NP">
          <tokens>
            <token id="30" string="awards" />
            <token id="31" string="and" />
            <token id="32" string="tributes" />
          </tokens>
        </chunking>
        <chunking id="6" string="another" type="NP">
          <tokens>
            <token id="24" string="another" />
          </tokens>
        </chunking>
        <chunking id="7" string="starring credits to her name" type="VP">
          <tokens>
            <token id="4" string="starring" />
            <token id="5" string="credits" />
            <token id="6" string="to" />
            <token id="7" string="her" />
            <token id="8" string="name" />
          </tokens>
        </chunking>
        <chunking id="8" string="making occasional television appearances" type="VP">
          <tokens>
            <token id="16" string="making" />
            <token id="17" string="occasional" />
            <token id="18" string="television" />
            <token id="19" string="appearances" />
          </tokens>
        </chunking>
        <chunking id="9" string="those final" type="NP">
          <tokens>
            <token id="2" string="those" />
            <token id="3" string="final" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="10" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="occasional television appearances" type="NP">
          <tokens>
            <token id="17" string="occasional" />
            <token id="18" string="television" />
            <token id="19" string="appearances" />
          </tokens>
        </chunking>
        <chunking id="12" string="shows" type="NP">
          <tokens>
            <token id="14" string="shows" />
          </tokens>
        </chunking>
        <chunking id="13" string="a continual barrage of awards and tributes" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="continual" />
            <token id="28" string="barrage" />
            <token id="29" string="of" />
            <token id="30" string="awards" />
            <token id="31" string="and" />
            <token id="32" string="tributes" />
          </tokens>
        </chunking>
        <chunking id="14" string="credits" type="NP">
          <tokens>
            <token id="5" string="credits" />
          </tokens>
        </chunking>
        <chunking id="15" string="another of a continual barrage of awards and tributes" type="NP">
          <tokens>
            <token id="24" string="another" />
            <token id="25" string="of" />
            <token id="26" string="a" />
            <token id="27" string="continual" />
            <token id="28" string="barrage" />
            <token id="29" string="of" />
            <token id="30" string="awards" />
            <token id="31" string="and" />
            <token id="32" string="tributes" />
          </tokens>
        </chunking>
        <chunking id="16" string="her name" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="name" />
          </tokens>
        </chunking>
        <chunking id="17" string="a continual barrage" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="continual" />
            <token id="28" string="barrage" />
          </tokens>
        </chunking>
        <chunking id="18" string="co-producing shows" type="VP">
          <tokens>
            <token id="13" string="co-producing" />
            <token id="14" string="shows" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">starring</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">final</governor>
          <dependent id="2">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">starring</governor>
          <dependent id="3">final</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">settled</governor>
          <dependent id="4">starring</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">starring</governor>
          <dependent id="5">credits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">name</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">name</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">starring</governor>
          <dependent id="8">name</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">settled</governor>
          <dependent id="10">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">settled</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">co-producing</governor>
          <dependent id="12">into</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">settled</governor>
          <dependent id="13">co-producing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">co-producing</governor>
          <dependent id="14">shows</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">co-producing</governor>
          <dependent id="16">making</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">appearances</governor>
          <dependent id="17">occasional</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">appearances</governor>
          <dependent id="18">television</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">making</governor>
          <dependent id="19">appearances</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">co-producing</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">co-producing</governor>
          <dependent id="21">accepting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">accepting</governor>
          <dependent id="22">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">another</governor>
          <dependent id="23">after</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">accepting</governor>
          <dependent id="24">another</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">barrage</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">barrage</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">barrage</governor>
          <dependent id="27">continual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">another</governor>
          <dependent id="28">barrage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">awards</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">barrage</governor>
          <dependent id="30">awards</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">awards</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">awards</governor>
          <dependent id="32">tributes</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="134" has_coreference="true">
      <content>In addition to her 13 Emmy nominations (she won four), Miss Ball was feted in 1976 with a nostalgic television tribute saluting the 25th anniversary of &amp;quot;I Love Lucy.&amp;quot;</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="addition" lemma="addition" stem="addit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="Emmy" lemma="Emmy" stem="emmy" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="nominations" lemma="nomination" stem="nomin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="feted" lemma="fete" stem="fete" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="1976" lemma="1976" stem="1976" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="nostalgic" lemma="nostalgic" stem="nostalg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="tribute" lemma="tribute" stem="tribut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="saluting" lemma="salute" stem="salut" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="25th" lemma="25th" stem="25th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="28" string="anniversary" lemma="anniversary" stem="anniversari" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (NN addition)) (PP (TO to) (NP (NP (PRP$ her) (CD 13) (NNP Emmy) (NNS nominations)) (PRN (-LRB- -LRB-) (S (NP (PRP she)) (VP (VBD won) (NP (CD four)))) (-RRB- -RRB-)))))) (, ,) (NP (NNP Miss) (NNP Ball)) (VP (VBD was) (VP (VBN feted) (PP (IN in) (NP (CD 1976))) (PP (IN with) (NP (NP (DT a) (JJ nostalgic) (NN television) (NN tribute)) (VP (VBG saluting) (S (NP (NP (DT the) (JJ 25th) (NN anniversary)) (PP (IN of) (`` ``) (NP (PRP I)))) (NP (NNP Love) (NNP Lucy)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="saluting the 25th anniversary of `` I Love Lucy" type="VP">
          <tokens>
            <token id="25" string="saluting" />
            <token id="26" string="the" />
            <token id="27" string="25th" />
            <token id="28" string="anniversary" />
            <token id="29" string="of" />
            <token id="30" string="&quot;" />
            <token id="31" string="I" />
            <token id="32" string="Love" />
            <token id="33" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="2" string="won four" type="VP">
          <tokens>
            <token id="10" string="won" />
            <token id="11" string="four" />
          </tokens>
        </chunking>
        <chunking id="3" string="was feted in 1976 with a nostalgic television tribute saluting the 25th anniversary of `` I Love Lucy" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="feted" />
            <token id="18" string="in" />
            <token id="19" string="1976" />
            <token id="20" string="with" />
            <token id="21" string="a" />
            <token id="22" string="nostalgic" />
            <token id="23" string="television" />
            <token id="24" string="tribute" />
            <token id="25" string="saluting" />
            <token id="26" string="the" />
            <token id="27" string="25th" />
            <token id="28" string="anniversary" />
            <token id="29" string="of" />
            <token id="30" string="&quot;" />
            <token id="31" string="I" />
            <token id="32" string="Love" />
            <token id="33" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="31" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 25th anniversary" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="25th" />
            <token id="28" string="anniversary" />
          </tokens>
        </chunking>
        <chunking id="6" string="her 13 Emmy nominations" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="13" />
            <token id="6" string="Emmy" />
            <token id="7" string="nominations" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="9" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="addition to her 13 Emmy nominations -LRB- she won four -RRB-" type="NP">
          <tokens>
            <token id="2" string="addition" />
            <token id="3" string="to" />
            <token id="4" string="her" />
            <token id="5" string="13" />
            <token id="6" string="Emmy" />
            <token id="7" string="nominations" />
            <token id="8" string="(" />
            <token id="9" string="she" />
            <token id="10" string="won" />
            <token id="11" string="four" />
            <token id="12" string=")" />
          </tokens>
        </chunking>
        <chunking id="9" string="1976" type="NP">
          <tokens>
            <token id="19" string="1976" />
          </tokens>
        </chunking>
        <chunking id="10" string="a nostalgic television tribute" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="nostalgic" />
            <token id="23" string="television" />
            <token id="24" string="tribute" />
          </tokens>
        </chunking>
        <chunking id="11" string="four" type="NP">
          <tokens>
            <token id="11" string="four" />
          </tokens>
        </chunking>
        <chunking id="12" string="a nostalgic television tribute saluting the 25th anniversary of `` I Love Lucy" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="nostalgic" />
            <token id="23" string="television" />
            <token id="24" string="tribute" />
            <token id="25" string="saluting" />
            <token id="26" string="the" />
            <token id="27" string="25th" />
            <token id="28" string="anniversary" />
            <token id="29" string="of" />
            <token id="30" string="&quot;" />
            <token id="31" string="I" />
            <token id="32" string="Love" />
            <token id="33" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="13" string="her 13 Emmy nominations -LRB- she won four -RRB-" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="13" />
            <token id="6" string="Emmy" />
            <token id="7" string="nominations" />
            <token id="8" string="(" />
            <token id="9" string="she" />
            <token id="10" string="won" />
            <token id="11" string="four" />
            <token id="12" string=")" />
          </tokens>
        </chunking>
        <chunking id="14" string="addition" type="NP">
          <tokens>
            <token id="2" string="addition" />
          </tokens>
        </chunking>
        <chunking id="15" string="the 25th anniversary of `` I" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="25th" />
            <token id="28" string="anniversary" />
            <token id="29" string="of" />
            <token id="30" string="&quot;" />
            <token id="31" string="I" />
          </tokens>
        </chunking>
        <chunking id="16" string="feted in 1976 with a nostalgic television tribute saluting the 25th anniversary of `` I Love Lucy" type="VP">
          <tokens>
            <token id="17" string="feted" />
            <token id="18" string="in" />
            <token id="19" string="1976" />
            <token id="20" string="with" />
            <token id="21" string="a" />
            <token id="22" string="nostalgic" />
            <token id="23" string="television" />
            <token id="24" string="tribute" />
            <token id="25" string="saluting" />
            <token id="26" string="the" />
            <token id="27" string="25th" />
            <token id="28" string="anniversary" />
            <token id="29" string="of" />
            <token id="30" string="&quot;" />
            <token id="31" string="I" />
            <token id="32" string="Love" />
            <token id="33" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="17" string="Miss Ball" type="NP">
          <tokens>
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="18" string="Love Lucy" type="NP">
          <tokens>
            <token id="32" string="Love" />
            <token id="33" string="Lucy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="7">nominations</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">In</governor>
          <dependent id="2">addition</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">In</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">nominations</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">nominations</governor>
          <dependent id="5">13</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">nominations</governor>
          <dependent id="6">Emmy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">feted</governor>
          <dependent id="7">nominations</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">won</governor>
          <dependent id="9">she</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">nominations</governor>
          <dependent id="10">won</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">won</governor>
          <dependent id="11">four</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Ball</governor>
          <dependent id="14">Miss</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="17">feted</governor>
          <dependent id="15">Ball</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">feted</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">feted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">1976</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">feted</governor>
          <dependent id="19">1976</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">tribute</governor>
          <dependent id="20">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">tribute</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">tribute</governor>
          <dependent id="22">nostalgic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">tribute</governor>
          <dependent id="23">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">feted</governor>
          <dependent id="24">tribute</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="24">tribute</governor>
          <dependent id="25">saluting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">anniversary</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">anniversary</governor>
          <dependent id="27">25th</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">Lucy</governor>
          <dependent id="28">anniversary</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">I</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">anniversary</governor>
          <dependent id="31">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Lucy</governor>
          <dependent id="32">Love</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">saluting</governor>
          <dependent id="33">Lucy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="13" />
          </tokens>
        </entity>
        <entity id="2" string="1976" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="1976" />
          </tokens>
        </entity>
        <entity id="3" string="25th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="27" string="25th" />
          </tokens>
        </entity>
        <entity id="4" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="four" />
          </tokens>
        </entity>
        <entity id="5" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Lucy" />
          </tokens>
        </entity>
        <entity id="6" string="Miss Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Miss" />
            <token id="15" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="135" has_coreference="true">
      <content>Danny Kaye was among those who gave testimonials during the two hours of reminiscing.</content>
      <tokens>
        <token id="1" string="Danny" lemma="Danny" stem="danni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Kaye" lemma="Kaye" stem="kay" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="testimonials" lemma="testimonial" stem="testimoni" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="reminiscing" lemma="reminisce" stem="reminisc" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Danny) (NNP Kaye)) (VP (VBD was) (PP (IN among) (NP (NP (DT those)) (SBAR (WHNP (WP who)) (S (VP (VBD gave) (NP (NNS testimonials)) (PP (IN during) (NP (NP (DT the) (CD two) (NNS hours)) (PP (IN of) (NP (VBG reminiscing))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the two hours of reminiscing" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="hours" />
            <token id="13" string="of" />
            <token id="14" string="reminiscing" />
          </tokens>
        </chunking>
        <chunking id="2" string="was among those who gave testimonials during the two hours of reminiscing" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="among" />
            <token id="5" string="those" />
            <token id="6" string="who" />
            <token id="7" string="gave" />
            <token id="8" string="testimonials" />
            <token id="9" string="during" />
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="hours" />
            <token id="13" string="of" />
            <token id="14" string="reminiscing" />
          </tokens>
        </chunking>
        <chunking id="3" string="those who gave testimonials during the two hours of reminiscing" type="NP">
          <tokens>
            <token id="5" string="those" />
            <token id="6" string="who" />
            <token id="7" string="gave" />
            <token id="8" string="testimonials" />
            <token id="9" string="during" />
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="hours" />
            <token id="13" string="of" />
            <token id="14" string="reminiscing" />
          </tokens>
        </chunking>
        <chunking id="4" string="testimonials" type="NP">
          <tokens>
            <token id="8" string="testimonials" />
          </tokens>
        </chunking>
        <chunking id="5" string="the two hours" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="hours" />
          </tokens>
        </chunking>
        <chunking id="6" string="who gave testimonials during the two hours of reminiscing" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="gave" />
            <token id="8" string="testimonials" />
            <token id="9" string="during" />
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="hours" />
            <token id="13" string="of" />
            <token id="14" string="reminiscing" />
          </tokens>
        </chunking>
        <chunking id="7" string="gave testimonials during the two hours of reminiscing" type="VP">
          <tokens>
            <token id="7" string="gave" />
            <token id="8" string="testimonials" />
            <token id="9" string="during" />
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="hours" />
            <token id="13" string="of" />
            <token id="14" string="reminiscing" />
          </tokens>
        </chunking>
        <chunking id="8" string="Danny Kaye" type="NP">
          <tokens>
            <token id="1" string="Danny" />
            <token id="2" string="Kaye" />
          </tokens>
        </chunking>
        <chunking id="9" string="reminiscing" type="NP">
          <tokens>
            <token id="14" string="reminiscing" />
          </tokens>
        </chunking>
        <chunking id="10" string="those" type="NP">
          <tokens>
            <token id="5" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Kaye</governor>
          <dependent id="1">Danny</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">those</governor>
          <dependent id="2">Kaye</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">those</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">those</governor>
          <dependent id="4">among</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">gave</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">those</governor>
          <dependent id="7">gave</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">gave</governor>
          <dependent id="8">testimonials</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">hours</governor>
          <dependent id="9">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">hours</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">hours</governor>
          <dependent id="11">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">gave</governor>
          <dependent id="12">hours</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">reminiscing</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">hours</governor>
          <dependent id="14">reminiscing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the two hours" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="two" />
            <token id="12" string="hours" />
          </tokens>
        </entity>
        <entity id="2" string="Danny Kaye" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Danny" />
            <token id="2" string="Kaye" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="136" has_coreference="true">
      <content>&amp;quot;Calling Lucille Ball just a comedienne is like calling Margot Fonteyn just a dancer,&amp;quot; Kaye said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Calling" lemma="call" stem="call" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="comedienne" lemma="comedienne" stem="comedienn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="calling" lemma="call" stem="call" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Margot" lemma="Margot" stem="margot" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Fonteyn" lemma="Fonteyn" stem="fonteyn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="dancer" lemma="dancer" stem="dancer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Kaye" lemma="Kaye" stem="kay" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (VP (VBG Calling) (NP (NNP Lucille) (NNP Ball)) (ADVP (RB just)))) (NP (DT a) (NN comedienne)) (VP (VBZ is) (PP (IN like) (S (VP (VBG calling) (NP (NNP Margot) (NNP Fonteyn)) (ADVP (RB just) (NP (DT a) (NN dancer)))))))) (, ,) ('' '') (NP (NNP Kaye)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Calling Lucille Ball just" type="VP">
          <tokens>
            <token id="2" string="Calling" />
            <token id="3" string="Lucille" />
            <token id="4" string="Ball" />
            <token id="5" string="just" />
          </tokens>
        </chunking>
        <chunking id="2" string="Kaye" type="NP">
          <tokens>
            <token id="18" string="Kaye" />
          </tokens>
        </chunking>
        <chunking id="3" string="Margot Fonteyn" type="NP">
          <tokens>
            <token id="11" string="Margot" />
            <token id="12" string="Fonteyn" />
          </tokens>
        </chunking>
        <chunking id="4" string="a dancer" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="dancer" />
          </tokens>
        </chunking>
        <chunking id="5" string="calling Margot Fonteyn just a dancer" type="VP">
          <tokens>
            <token id="10" string="calling" />
            <token id="11" string="Margot" />
            <token id="12" string="Fonteyn" />
            <token id="13" string="just" />
            <token id="14" string="a" />
            <token id="15" string="dancer" />
          </tokens>
        </chunking>
        <chunking id="6" string="is like calling Margot Fonteyn just a dancer" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="like" />
            <token id="10" string="calling" />
            <token id="11" string="Margot" />
            <token id="12" string="Fonteyn" />
            <token id="13" string="just" />
            <token id="14" string="a" />
            <token id="15" string="dancer" />
          </tokens>
        </chunking>
        <chunking id="7" string="a comedienne" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="comedienne" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lucille Ball" type="NP">
          <tokens>
            <token id="3" string="Lucille" />
            <token id="4" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="10">calling</governor>
          <dependent id="2">Calling</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Ball</governor>
          <dependent id="3">Lucille</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">Calling</governor>
          <dependent id="4">Ball</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">Calling</governor>
          <dependent id="5">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">comedienne</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">calling</governor>
          <dependent id="7">comedienne</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">calling</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">calling</governor>
          <dependent id="9">like</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="10">calling</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Fonteyn</governor>
          <dependent id="11">Margot</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">calling</governor>
          <dependent id="12">Fonteyn</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">calling</governor>
          <dependent id="13">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">dancer</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="13">just</governor>
          <dependent id="15">dancer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">Kaye</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kaye" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Kaye" />
          </tokens>
        </entity>
        <entity id="2" string="Margot Fonteyn" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Margot" />
            <token id="12" string="Fonteyn" />
          </tokens>
        </entity>
        <entity id="3" string="Lucille Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Lucille" />
            <token id="4" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="137" has_coreference="true">
      <content>In 1984, when she was named one of seven initial inductees in the Television Hall of Fame, she credited the many &amp;quot;talented and creative people&amp;quot; around her for making her a legend.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="named" lemma="name" stem="name" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="initial" lemma="initial" stem="initi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="inductees" lemma="inductee" stem="inducte" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Television" lemma="Television" stem="televis" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="Hall" lemma="Hall" stem="hall" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="18" string="Fame" lemma="Fame" stem="fame" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="credited" lemma="credit" stem="credit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="talented" lemma="talented" stem="talent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="creative" lemma="creative" stem="creativ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="legend" lemma="legend" stem="legend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1984))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD was) (VP (VBN named) (NP (NP (CD one)) (PP (IN of) (NP (CD seven) (JJ initial) (NNS inductees)))) (PP (IN in) (NP (NP (DT the) (NNP Television) (NNP Hall)) (PP (IN of) (NP (NNP Fame))))))))) (, ,) (NP (PRP she)) (VP (VBD credited) (NP (NP (DT the) (JJ many) (`` ``) (JJ talented) (CC and) (JJ creative) (NNS people)) ('' '') (PP (IN around) (NP (PRP$ her)))) (PP (IN for) (S (VP (VBG making) (S (NP (PRP$ her)) (NP (DT a) (NN legend))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the many `` talented and creative people" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="many" />
            <token id="24" string="&quot;" />
            <token id="25" string="talented" />
            <token id="26" string="and" />
            <token id="27" string="creative" />
            <token id="28" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="8" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="named one of seven initial inductees in the Television Hall of Fame" type="VP">
          <tokens>
            <token id="7" string="named" />
            <token id="8" string="one" />
            <token id="9" string="of" />
            <token id="10" string="seven" />
            <token id="11" string="initial" />
            <token id="12" string="inductees" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="Television" />
            <token id="16" string="Hall" />
            <token id="17" string="of" />
            <token id="18" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="4" string="seven initial inductees" type="NP">
          <tokens>
            <token id="10" string="seven" />
            <token id="11" string="initial" />
            <token id="12" string="inductees" />
          </tokens>
        </chunking>
        <chunking id="5" string="the many `` talented and creative people '' around her" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="many" />
            <token id="24" string="&quot;" />
            <token id="25" string="talented" />
            <token id="26" string="and" />
            <token id="27" string="creative" />
            <token id="28" string="people" />
            <token id="29" string="&quot;" />
            <token id="30" string="around" />
            <token id="31" string="her" />
          </tokens>
        </chunking>
        <chunking id="6" string="when" type="WHADVP">
          <tokens>
            <token id="4" string="when" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="a legend" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="legend" />
          </tokens>
        </chunking>
        <chunking id="9" string="was named one of seven initial inductees in the Television Hall of Fame" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="named" />
            <token id="8" string="one" />
            <token id="9" string="of" />
            <token id="10" string="seven" />
            <token id="11" string="initial" />
            <token id="12" string="inductees" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="Television" />
            <token id="16" string="Hall" />
            <token id="17" string="of" />
            <token id="18" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Television Hall" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="Television" />
            <token id="16" string="Hall" />
          </tokens>
        </chunking>
        <chunking id="11" string="Fame" type="NP">
          <tokens>
            <token id="18" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="12" string="1984" type="NP">
          <tokens>
            <token id="2" string="1984" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Television Hall of Fame" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="Television" />
            <token id="16" string="Hall" />
            <token id="17" string="of" />
            <token id="18" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="14" string="her" type="NP">
          <tokens>
            <token id="31" string="her" />
          </tokens>
        </chunking>
        <chunking id="15" string="when she was named one of seven initial inductees in the Television Hall of Fame" type="SBAR">
          <tokens>
            <token id="4" string="when" />
            <token id="5" string="she" />
            <token id="6" string="was" />
            <token id="7" string="named" />
            <token id="8" string="one" />
            <token id="9" string="of" />
            <token id="10" string="seven" />
            <token id="11" string="initial" />
            <token id="12" string="inductees" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="Television" />
            <token id="16" string="Hall" />
            <token id="17" string="of" />
            <token id="18" string="Fame" />
          </tokens>
        </chunking>
        <chunking id="16" string="making her a legend" type="VP">
          <tokens>
            <token id="33" string="making" />
            <token id="34" string="her" />
            <token id="35" string="a" />
            <token id="36" string="legend" />
          </tokens>
        </chunking>
        <chunking id="17" string="one of seven initial inductees" type="NP">
          <tokens>
            <token id="8" string="one" />
            <token id="9" string="of" />
            <token id="10" string="seven" />
            <token id="11" string="initial" />
            <token id="12" string="inductees" />
          </tokens>
        </chunking>
        <chunking id="18" string="credited the many `` talented and creative people '' around her for making her a legend" type="VP">
          <tokens>
            <token id="21" string="credited" />
            <token id="22" string="the" />
            <token id="23" string="many" />
            <token id="24" string="&quot;" />
            <token id="25" string="talented" />
            <token id="26" string="and" />
            <token id="27" string="creative" />
            <token id="28" string="people" />
            <token id="29" string="&quot;" />
            <token id="30" string="around" />
            <token id="31" string="her" />
            <token id="32" string="for" />
            <token id="33" string="making" />
            <token id="34" string="her" />
            <token id="35" string="a" />
            <token id="36" string="legend" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1984</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">credited</governor>
          <dependent id="2">1984</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">named</governor>
          <dependent id="4">when</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">named</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">named</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">credited</governor>
          <dependent id="7">named</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">named</governor>
          <dependent id="8">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">inductees</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">inductees</governor>
          <dependent id="10">seven</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">inductees</governor>
          <dependent id="11">initial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">one</governor>
          <dependent id="12">inductees</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Hall</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Hall</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Hall</governor>
          <dependent id="15">Television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">named</governor>
          <dependent id="16">Hall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Fame</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">Hall</governor>
          <dependent id="18">Fame</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">credited</governor>
          <dependent id="20">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">credited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">talented</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">talented</governor>
          <dependent id="23">many</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">credited</governor>
          <dependent id="25">talented</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">talented</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">people</governor>
          <dependent id="27">creative</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">talented</governor>
          <dependent id="28">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">her</governor>
          <dependent id="30">around</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">talented</governor>
          <dependent id="31">her</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">making</governor>
          <dependent id="32">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">credited</governor>
          <dependent id="33">making</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">legend</governor>
          <dependent id="34">her</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">legend</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="33">making</governor>
          <dependent id="36">legend</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Television Hall of Fame" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="Television" />
            <token id="16" string="Hall" />
            <token id="17" string="of" />
            <token id="18" string="Fame" />
          </tokens>
        </entity>
        <entity id="2" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1984" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="seven" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="138" has_coreference="true">
      <content>&amp;quot;I have been absolutely blessed,&amp;quot; Miss Ball said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="absolutely" lemma="absolutely" stem="absolut" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="blessed" lemma="bless" stem="bless" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP have) (VP (VBN been) (ADJP (RB absolutely) (VBN blessed))))) (, ,) ('' '') (NP (NNP Miss) (NNP Ball)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have been absolutely blessed" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="been" />
            <token id="5" string="absolutely" />
            <token id="6" string="blessed" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="absolutely blessed" type="ADJP">
          <tokens>
            <token id="5" string="absolutely" />
            <token id="6" string="blessed" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="been absolutely blessed" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="absolutely" />
            <token id="6" string="blessed" />
          </tokens>
        </chunking>
        <chunking id="6" string="Miss Ball" type="NP">
          <tokens>
            <token id="9" string="Miss" />
            <token id="10" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="6">blessed</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">blessed</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">blessed</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">blessed</governor>
          <dependent id="5">absolutely</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="6">blessed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Ball</governor>
          <dependent id="9">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="139" has_coreference="true">
      <content>Role as Bag Lady The following year she took on one of the most challenging roles of her career: a bag lady in the television movie &amp;quot;Stone Pillow.&amp;quot;</content>
      <tokens>
        <token id="1" string="Role" lemma="role" stem="role" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Bag" lemma="bag" stem="bag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Lady" lemma="lady" stem="ladi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string="following" lemma="following" stem="follow" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="7" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="challenging" lemma="challenging" stem="challeng" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="roles" lemma="role" stem="role" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="career" lemma="career" stem="career" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="bag" lemma="bag" stem="bag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="lady" lemma="lady" stem="ladi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Stone" lemma="Stone" stem="stone" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Pillow" lemma="Pillow" stem="pillow" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NN Role)) (PP (IN as) (NP (NN Bag) (NN Lady))) (NP-TMP (DT The) (JJ following) (NN year)))) (NP (PRP she)) (VP (VBD took) (PP (IN on) (NP (NP (CD one)) (PP (IN of) (NP (NP (NP (DT the) (ADJP (RBS most) (JJ challenging)) (NNS roles)) (PP (IN of) (NP (PRP$ her) (NN career)))) (: :) (NP (NP (DT a) (NN bag) (NN lady)) (PP (IN in) (NP (DT the) (NN television) (NN movie) (`` ``) (NNP Stone) (NNP Pillow))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the most challenging roles of her career : a bag lady in the television movie `` Stone Pillow" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="challenging" />
            <token id="16" string="roles" />
            <token id="17" string="of" />
            <token id="18" string="her" />
            <token id="19" string="career" />
            <token id="20" string=":" />
            <token id="21" string="a" />
            <token id="22" string="bag" />
            <token id="23" string="lady" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="television" />
            <token id="27" string="movie" />
            <token id="28" string="&quot;" />
            <token id="29" string="Stone" />
            <token id="30" string="Pillow" />
          </tokens>
        </chunking>
        <chunking id="2" string="most challenging" type="ADJP">
          <tokens>
            <token id="14" string="most" />
            <token id="15" string="challenging" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="11" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="a bag lady in the television movie `` Stone Pillow" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="bag" />
            <token id="23" string="lady" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="television" />
            <token id="27" string="movie" />
            <token id="28" string="&quot;" />
            <token id="29" string="Stone" />
            <token id="30" string="Pillow" />
          </tokens>
        </chunking>
        <chunking id="5" string="Role as Bag Lady The following year" type="NP">
          <tokens>
            <token id="1" string="Role" />
            <token id="2" string="as" />
            <token id="3" string="Bag" />
            <token id="4" string="Lady" />
            <token id="5" string="The" />
            <token id="6" string="following" />
            <token id="7" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="one of the most challenging roles of her career : a bag lady in the television movie `` Stone Pillow" type="NP">
          <tokens>
            <token id="11" string="one" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="challenging" />
            <token id="16" string="roles" />
            <token id="17" string="of" />
            <token id="18" string="her" />
            <token id="19" string="career" />
            <token id="20" string=":" />
            <token id="21" string="a" />
            <token id="22" string="bag" />
            <token id="23" string="lady" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="television" />
            <token id="27" string="movie" />
            <token id="28" string="&quot;" />
            <token id="29" string="Stone" />
            <token id="30" string="Pillow" />
          </tokens>
        </chunking>
        <chunking id="7" string="a bag lady" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="bag" />
            <token id="23" string="lady" />
          </tokens>
        </chunking>
        <chunking id="8" string="took on one of the most challenging roles of her career : a bag lady in the television movie `` Stone Pillow" type="VP">
          <tokens>
            <token id="9" string="took" />
            <token id="10" string="on" />
            <token id="11" string="one" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="challenging" />
            <token id="16" string="roles" />
            <token id="17" string="of" />
            <token id="18" string="her" />
            <token id="19" string="career" />
            <token id="20" string=":" />
            <token id="21" string="a" />
            <token id="22" string="bag" />
            <token id="23" string="lady" />
            <token id="24" string="in" />
            <token id="25" string="the" />
            <token id="26" string="television" />
            <token id="27" string="movie" />
            <token id="28" string="&quot;" />
            <token id="29" string="Stone" />
            <token id="30" string="Pillow" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="8" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="the most challenging roles of her career" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="challenging" />
            <token id="16" string="roles" />
            <token id="17" string="of" />
            <token id="18" string="her" />
            <token id="19" string="career" />
          </tokens>
        </chunking>
        <chunking id="11" string="Role" type="NP">
          <tokens>
            <token id="1" string="Role" />
          </tokens>
        </chunking>
        <chunking id="12" string="Bag Lady" type="NP">
          <tokens>
            <token id="3" string="Bag" />
            <token id="4" string="Lady" />
          </tokens>
        </chunking>
        <chunking id="13" string="her career" type="NP">
          <tokens>
            <token id="18" string="her" />
            <token id="19" string="career" />
          </tokens>
        </chunking>
        <chunking id="14" string="the television movie `` Stone Pillow" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="television" />
            <token id="27" string="movie" />
            <token id="28" string="&quot;" />
            <token id="29" string="Stone" />
            <token id="30" string="Pillow" />
          </tokens>
        </chunking>
        <chunking id="15" string="the most challenging roles" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="most" />
            <token id="15" string="challenging" />
            <token id="16" string="roles" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="9">took</governor>
          <dependent id="1">Role</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Lady</governor>
          <dependent id="2">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Lady</governor>
          <dependent id="3">Bag</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Role</governor>
          <dependent id="4">Lady</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">year</governor>
          <dependent id="5">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">year</governor>
          <dependent id="6">following</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">Role</governor>
          <dependent id="7">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">took</governor>
          <dependent id="8">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">took</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">one</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">took</governor>
          <dependent id="11">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">roles</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">roles</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">challenging</governor>
          <dependent id="14">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">roles</governor>
          <dependent id="15">challenging</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">one</governor>
          <dependent id="16">roles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">career</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">career</governor>
          <dependent id="18">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">roles</governor>
          <dependent id="19">career</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">lady</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">lady</governor>
          <dependent id="22">bag</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">roles</governor>
          <dependent id="23">lady</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Pillow</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">Pillow</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Pillow</governor>
          <dependent id="26">television</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Pillow</governor>
          <dependent id="27">movie</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Pillow</governor>
          <dependent id="29">Stone</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">lady</governor>
          <dependent id="30">Pillow</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="The following year" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="The" />
            <token id="6" string="following" />
            <token id="7" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="140" has_coreference="true">
      <content>She was hospitalized for dehydration when it was over, but it was a critical and ratings success.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hospitalized" lemma="hospitalize" stem="hospit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="dehydration" lemma="dehydration" stem="dehydr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="over" lemma="over" stem="over" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="critical" lemma="critical" stem="critic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="ratings" lemma="rating" stem="rate" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="success" lemma="success" stem="success" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP She)) (VP (VBD was) (VP (VBN hospitalized) (PP (IN for) (NP (NN dehydration))) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBD was) (ADVP (RB over)))))))) (, ,) (CC but) (S (NP (PRP it)) (VP (VBD was) (NP (DT a) (JJ critical) (CC and) (NNS ratings) (NN success)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was a critical and ratings success" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="a" />
            <token id="15" string="critical" />
            <token id="16" string="and" />
            <token id="17" string="ratings" />
            <token id="18" string="success" />
          </tokens>
        </chunking>
        <chunking id="2" string="a critical and ratings success" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="critical" />
            <token id="16" string="and" />
            <token id="17" string="ratings" />
            <token id="18" string="success" />
          </tokens>
        </chunking>
        <chunking id="3" string="hospitalized for dehydration when it was over" type="VP">
          <tokens>
            <token id="3" string="hospitalized" />
            <token id="4" string="for" />
            <token id="5" string="dehydration" />
            <token id="6" string="when" />
            <token id="7" string="it" />
            <token id="8" string="was" />
            <token id="9" string="over" />
          </tokens>
        </chunking>
        <chunking id="4" string="was over" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="over" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="dehydration" type="NP">
          <tokens>
            <token id="5" string="dehydration" />
          </tokens>
        </chunking>
        <chunking id="7" string="when it was over" type="SBAR">
          <tokens>
            <token id="6" string="when" />
            <token id="7" string="it" />
            <token id="8" string="was" />
            <token id="9" string="over" />
          </tokens>
        </chunking>
        <chunking id="8" string="was hospitalized for dehydration when it was over" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="hospitalized" />
            <token id="4" string="for" />
            <token id="5" string="dehydration" />
            <token id="6" string="when" />
            <token id="7" string="it" />
            <token id="8" string="was" />
            <token id="9" string="over" />
          </tokens>
        </chunking>
        <chunking id="9" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="6" string="when" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="3">hospitalized</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="3">hospitalized</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">hospitalized</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">dehydration</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">hospitalized</governor>
          <dependent id="5">dehydration</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">was</governor>
          <dependent id="6">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">was</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">hospitalized</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">was</governor>
          <dependent id="9">over</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">hospitalized</governor>
          <dependent id="11">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">success</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">success</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">success</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">success</governor>
          <dependent id="15">critical</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">critical</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">critical</governor>
          <dependent id="17">ratings</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">hospitalized</governor>
          <dependent id="18">success</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="141" has_coreference="true">
      <content>Her last flirtation with television came with her ill-fated and short-lived 1986 series, &amp;quot;Life With Lucy,&amp;quot; in which she again teamed with longtime sidekick Gale Gordon.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="flirtation" lemma="flirtation" stem="flirtat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="ill-fated" lemma="ill-fated" stem="ill-fat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="short-lived" lemma="short-lived" stem="short-liv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="series" lemma="series" stem="seri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Life" lemma="Life" stem="life" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="teamed" lemma="team" stem="team" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="longtime" lemma="longtime" stem="longtim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="sidekick" lemma="sidekick" stem="sidekick" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Gale" lemma="Gale" stem="gale" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="Gordon" lemma="Gordon" stem="gordon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ Her) (JJ last) (NN flirtation)) (PP (IN with) (NP (NN television)))) (VP (VBD came) (PP (IN with) (NP (NP (NP (PRP$ her) (JJ ill-fated) (CC and) (JJ short-lived) (CD 1986) (NN series)) (, ,) (`` ``) (NP (NP (NNP Life)) (PP (IN With) (NP (NNP Lucy)))) (, ,) ('' '')) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (PRP she)) (ADVP (RB again)) (VP (VBD teamed) (PP (IN with) (NP (JJ longtime) (NN sidekick) (NNP Gale) (NNP Gordon))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Life With Lucy" type="NP">
          <tokens>
            <token id="16" string="Life" />
            <token id="17" string="With" />
            <token id="18" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="2" string="television" type="NP">
          <tokens>
            <token id="5" string="television" />
          </tokens>
        </chunking>
        <chunking id="3" string="Her last flirtation" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="last" />
            <token id="3" string="flirtation" />
          </tokens>
        </chunking>
        <chunking id="4" string="Her last flirtation with television" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="last" />
            <token id="3" string="flirtation" />
            <token id="4" string="with" />
            <token id="5" string="television" />
          </tokens>
        </chunking>
        <chunking id="5" string="her ill-fated and short-lived 1986 series , `` Life With Lucy , '' in which she again teamed with longtime sidekick Gale Gordon" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="ill-fated" />
            <token id="10" string="and" />
            <token id="11" string="short-lived" />
            <token id="12" string="1986" />
            <token id="13" string="series" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="Life" />
            <token id="17" string="With" />
            <token id="18" string="Lucy" />
            <token id="19" string="," />
            <token id="20" string="&quot;" />
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="she" />
            <token id="24" string="again" />
            <token id="25" string="teamed" />
            <token id="26" string="with" />
            <token id="27" string="longtime" />
            <token id="28" string="sidekick" />
            <token id="29" string="Gale" />
            <token id="30" string="Gordon" />
          </tokens>
        </chunking>
        <chunking id="6" string="her ill-fated and short-lived 1986 series , `` Life With Lucy , ''" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="ill-fated" />
            <token id="10" string="and" />
            <token id="11" string="short-lived" />
            <token id="12" string="1986" />
            <token id="13" string="series" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="Life" />
            <token id="17" string="With" />
            <token id="18" string="Lucy" />
            <token id="19" string="," />
            <token id="20" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="7" string="in which she again teamed with longtime sidekick Gale Gordon" type="SBAR">
          <tokens>
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="she" />
            <token id="24" string="again" />
            <token id="25" string="teamed" />
            <token id="26" string="with" />
            <token id="27" string="longtime" />
            <token id="28" string="sidekick" />
            <token id="29" string="Gale" />
            <token id="30" string="Gordon" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="23" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="came with her ill-fated and short-lived 1986 series , `` Life With Lucy , '' in which she again teamed with longtime sidekick Gale Gordon" type="VP">
          <tokens>
            <token id="6" string="came" />
            <token id="7" string="with" />
            <token id="8" string="her" />
            <token id="9" string="ill-fated" />
            <token id="10" string="and" />
            <token id="11" string="short-lived" />
            <token id="12" string="1986" />
            <token id="13" string="series" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="Life" />
            <token id="17" string="With" />
            <token id="18" string="Lucy" />
            <token id="19" string="," />
            <token id="20" string="&quot;" />
            <token id="21" string="in" />
            <token id="22" string="which" />
            <token id="23" string="she" />
            <token id="24" string="again" />
            <token id="25" string="teamed" />
            <token id="26" string="with" />
            <token id="27" string="longtime" />
            <token id="28" string="sidekick" />
            <token id="29" string="Gale" />
            <token id="30" string="Gordon" />
          </tokens>
        </chunking>
        <chunking id="10" string="teamed with longtime sidekick Gale Gordon" type="VP">
          <tokens>
            <token id="25" string="teamed" />
            <token id="26" string="with" />
            <token id="27" string="longtime" />
            <token id="28" string="sidekick" />
            <token id="29" string="Gale" />
            <token id="30" string="Gordon" />
          </tokens>
        </chunking>
        <chunking id="11" string="her ill-fated and short-lived 1986 series" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="ill-fated" />
            <token id="10" string="and" />
            <token id="11" string="short-lived" />
            <token id="12" string="1986" />
            <token id="13" string="series" />
          </tokens>
        </chunking>
        <chunking id="12" string="Lucy" type="NP">
          <tokens>
            <token id="18" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="13" string="longtime sidekick Gale Gordon" type="NP">
          <tokens>
            <token id="27" string="longtime" />
            <token id="28" string="sidekick" />
            <token id="29" string="Gale" />
            <token id="30" string="Gordon" />
          </tokens>
        </chunking>
        <chunking id="14" string="Life" type="NP">
          <tokens>
            <token id="16" string="Life" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">flirtation</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">flirtation</governor>
          <dependent id="2">last</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">came</governor>
          <dependent id="3">flirtation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">television</governor>
          <dependent id="4">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">flirtation</governor>
          <dependent id="5">television</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">ill-fated</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">ill-fated</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">came</governor>
          <dependent id="9">ill-fated</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">ill-fated</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">series</governor>
          <dependent id="11">short-lived</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">series</governor>
          <dependent id="12">1986</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">ill-fated</governor>
          <dependent id="13">series</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">ill-fated</governor>
          <dependent id="16">Life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Lucy</governor>
          <dependent id="17">With</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">Life</governor>
          <dependent id="18">Lucy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">which</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">teamed</governor>
          <dependent id="22">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">teamed</governor>
          <dependent id="23">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">teamed</governor>
          <dependent id="24">again</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">ill-fated</governor>
          <dependent id="25">teamed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Gordon</governor>
          <dependent id="26">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">Gordon</governor>
          <dependent id="27">longtime</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Gordon</governor>
          <dependent id="28">sidekick</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Gordon</governor>
          <dependent id="29">Gale</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">teamed</governor>
          <dependent id="30">Gordon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1986" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1986" />
          </tokens>
        </entity>
        <entity id="2" string="Gale Gordon" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Gale" />
            <token id="30" string="Gordon" />
          </tokens>
        </entity>
        <entity id="3" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="142" has_coreference="true">
      <content>It was quickly pulled by the network because of abysmal ratings.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="quickly" lemma="quickly" stem="quickli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="pulled" lemma="pull" stem="pull" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="network" lemma="network" stem="network" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="abysmal" lemma="abysmal" stem="abysm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="ratings" lemma="rating" stem="rate" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (ADVP (RB quickly)) (VP (VBN pulled) (PP (IN by) (NP (DT the) (NN network))) (PP (IN because) (PP (IN of) (NP (JJ abysmal) (NNS ratings)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the network" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="network" />
          </tokens>
        </chunking>
        <chunking id="2" string="pulled by the network because of abysmal ratings" type="VP">
          <tokens>
            <token id="4" string="pulled" />
            <token id="5" string="by" />
            <token id="6" string="the" />
            <token id="7" string="network" />
            <token id="8" string="because" />
            <token id="9" string="of" />
            <token id="10" string="abysmal" />
            <token id="11" string="ratings" />
          </tokens>
        </chunking>
        <chunking id="3" string="was quickly pulled by the network because of abysmal ratings" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="quickly" />
            <token id="4" string="pulled" />
            <token id="5" string="by" />
            <token id="6" string="the" />
            <token id="7" string="network" />
            <token id="8" string="because" />
            <token id="9" string="of" />
            <token id="10" string="abysmal" />
            <token id="11" string="ratings" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="abysmal ratings" type="NP">
          <tokens>
            <token id="10" string="abysmal" />
            <token id="11" string="ratings" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">pulled</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">pulled</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">pulled</governor>
          <dependent id="3">quickly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">pulled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">network</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">network</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">pulled</governor>
          <dependent id="7">network</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">ratings</governor>
          <dependent id="8">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">ratings</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">ratings</governor>
          <dependent id="10">abysmal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">pulled</governor>
          <dependent id="11">ratings</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="143" has_coreference="true">
      <content>Her final public appearance proved to be during the 61st annual Academy Awards ceremony on March 29 when she joined her old friend Hope as a presenter.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="appearance" lemma="appearance" stem="appear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="proved" lemma="prove" stem="prove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="61st" lemma="61st" stem="61st" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="11" string="annual" lemma="annual" stem="annual" pos="JJ" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="12" string="Academy" lemma="academy" stem="academi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Awards" lemma="award" stem="award" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="ceremony" lemma="ceremony" stem="ceremoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="29" lemma="29" stem="29" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="joined" lemma="join" stem="join" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="friend" lemma="friend" stem="friend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Hope" lemma="Hope" stem="hope" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="presenter" lemma="presenter" stem="present" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Her) (JJ final) (JJ public) (NN appearance)) (VP (VBD proved) (S (VP (TO to) (VP (VB be) (PP (IN during) (NP (DT the) (JJ 61st) (JJ annual) (NN Academy) (NNS Awards) (NN ceremony))) (PP (IN on) (NP (NP (NNP March) (CD 29)) (SBAR (WHADVP (WRB when)) (S (NP (PRP she)) (VP (VBD joined) (NP (PRP$ her) (JJ old) (NN friend)) (PP (NP (NNP Hope)) (IN as) (NP (DT a) (NN presenter)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="March 29" type="NP">
          <tokens>
            <token id="16" string="March" />
            <token id="17" string="29" />
          </tokens>
        </chunking>
        <chunking id="2" string="be during the 61st annual Academy Awards ceremony on March 29 when she joined her old friend Hope as a presenter" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="during" />
            <token id="9" string="the" />
            <token id="10" string="61st" />
            <token id="11" string="annual" />
            <token id="12" string="Academy" />
            <token id="13" string="Awards" />
            <token id="14" string="ceremony" />
            <token id="15" string="on" />
            <token id="16" string="March" />
            <token id="17" string="29" />
            <token id="18" string="when" />
            <token id="19" string="she" />
            <token id="20" string="joined" />
            <token id="21" string="her" />
            <token id="22" string="old" />
            <token id="23" string="friend" />
            <token id="24" string="Hope" />
            <token id="25" string="as" />
            <token id="26" string="a" />
            <token id="27" string="presenter" />
          </tokens>
        </chunking>
        <chunking id="3" string="a presenter" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="presenter" />
          </tokens>
        </chunking>
        <chunking id="4" string="Her final public appearance" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="final" />
            <token id="3" string="public" />
            <token id="4" string="appearance" />
          </tokens>
        </chunking>
        <chunking id="5" string="proved to be during the 61st annual Academy Awards ceremony on March 29 when she joined her old friend Hope as a presenter" type="VP">
          <tokens>
            <token id="5" string="proved" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="during" />
            <token id="9" string="the" />
            <token id="10" string="61st" />
            <token id="11" string="annual" />
            <token id="12" string="Academy" />
            <token id="13" string="Awards" />
            <token id="14" string="ceremony" />
            <token id="15" string="on" />
            <token id="16" string="March" />
            <token id="17" string="29" />
            <token id="18" string="when" />
            <token id="19" string="she" />
            <token id="20" string="joined" />
            <token id="21" string="her" />
            <token id="22" string="old" />
            <token id="23" string="friend" />
            <token id="24" string="Hope" />
            <token id="25" string="as" />
            <token id="26" string="a" />
            <token id="27" string="presenter" />
          </tokens>
        </chunking>
        <chunking id="6" string="March 29 when she joined her old friend Hope as a presenter" type="NP">
          <tokens>
            <token id="16" string="March" />
            <token id="17" string="29" />
            <token id="18" string="when" />
            <token id="19" string="she" />
            <token id="20" string="joined" />
            <token id="21" string="her" />
            <token id="22" string="old" />
            <token id="23" string="friend" />
            <token id="24" string="Hope" />
            <token id="25" string="as" />
            <token id="26" string="a" />
            <token id="27" string="presenter" />
          </tokens>
        </chunking>
        <chunking id="7" string="joined her old friend Hope as a presenter" type="VP">
          <tokens>
            <token id="20" string="joined" />
            <token id="21" string="her" />
            <token id="22" string="old" />
            <token id="23" string="friend" />
            <token id="24" string="Hope" />
            <token id="25" string="as" />
            <token id="26" string="a" />
            <token id="27" string="presenter" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="18" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="19" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="when she joined her old friend Hope as a presenter" type="SBAR">
          <tokens>
            <token id="18" string="when" />
            <token id="19" string="she" />
            <token id="20" string="joined" />
            <token id="21" string="her" />
            <token id="22" string="old" />
            <token id="23" string="friend" />
            <token id="24" string="Hope" />
            <token id="25" string="as" />
            <token id="26" string="a" />
            <token id="27" string="presenter" />
          </tokens>
        </chunking>
        <chunking id="11" string="her old friend" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="old" />
            <token id="23" string="friend" />
          </tokens>
        </chunking>
        <chunking id="12" string="Hope" type="NP">
          <tokens>
            <token id="24" string="Hope" />
          </tokens>
        </chunking>
        <chunking id="13" string="the 61st annual Academy Awards ceremony" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="61st" />
            <token id="11" string="annual" />
            <token id="12" string="Academy" />
            <token id="13" string="Awards" />
            <token id="14" string="ceremony" />
          </tokens>
        </chunking>
        <chunking id="14" string="to be during the 61st annual Academy Awards ceremony on March 29 when she joined her old friend Hope as a presenter" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="during" />
            <token id="9" string="the" />
            <token id="10" string="61st" />
            <token id="11" string="annual" />
            <token id="12" string="Academy" />
            <token id="13" string="Awards" />
            <token id="14" string="ceremony" />
            <token id="15" string="on" />
            <token id="16" string="March" />
            <token id="17" string="29" />
            <token id="18" string="when" />
            <token id="19" string="she" />
            <token id="20" string="joined" />
            <token id="21" string="her" />
            <token id="22" string="old" />
            <token id="23" string="friend" />
            <token id="24" string="Hope" />
            <token id="25" string="as" />
            <token id="26" string="a" />
            <token id="27" string="presenter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">appearance</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">appearance</governor>
          <dependent id="2">final</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">appearance</governor>
          <dependent id="3">public</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">proved</governor>
          <dependent id="4">appearance</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">proved</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">ceremony</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">ceremony</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">ceremony</governor>
          <dependent id="8">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">ceremony</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">ceremony</governor>
          <dependent id="10">61st</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">ceremony</governor>
          <dependent id="11">annual</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">ceremony</governor>
          <dependent id="12">Academy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">ceremony</governor>
          <dependent id="13">Awards</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">proved</governor>
          <dependent id="14">ceremony</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">March</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">ceremony</governor>
          <dependent id="16">March</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">March</governor>
          <dependent id="17">29</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">joined</governor>
          <dependent id="18">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">joined</governor>
          <dependent id="19">she</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">March</governor>
          <dependent id="20">joined</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">friend</governor>
          <dependent id="21">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">friend</governor>
          <dependent id="22">old</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">joined</governor>
          <dependent id="23">friend</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">joined</governor>
          <dependent id="24">Hope</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Hope</governor>
          <dependent id="25">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">presenter</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">Hope</governor>
          <dependent id="27">presenter</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="March 29" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="March" />
            <token id="17" string="29" />
          </tokens>
        </entity>
        <entity id="2" string="61st" type="ORDINAL" score="0.0">
          <tokens>
            <token id="10" string="61st" />
          </tokens>
        </entity>
        <entity id="3" string="annual" type="SET" score="0.0">
          <tokens>
            <token id="11" string="annual" />
          </tokens>
        </entity>
        <entity id="4" string="Hope" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Hope" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="144" has_coreference="true">
      <content>She had signed a contract with Putnam to publish her autobiography but died before she could begin work on it.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="signed" lemma="sign" stem="sign" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="contract" lemma="contract" stem="contract" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Putnam" lemma="Putnam" stem="putnam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="publish" lemma="publish" stem="publish" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="autobiography" lemma="autobiography" stem="autobiographi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="begin" lemma="begin" stem="begin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VP (VBD had) (VP (VBN signed) (NP (DT a) (NN contract)) (PP (IN with) (NP (NNP Putnam))) (S (VP (TO to) (VP (VB publish) (NP (PRP$ her) (NN autobiography))))))) (CC but) (VP (VBD died) (SBAR (IN before) (S (NP (PRP she)) (VP (MD could) (VP (VB begin) (NP (NN work)) (PP (IN on) (NP (PRP it))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Putnam" type="NP">
          <tokens>
            <token id="7" string="Putnam" />
          </tokens>
        </chunking>
        <chunking id="2" string="a contract" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="contract" />
          </tokens>
        </chunking>
        <chunking id="3" string="work" type="NP">
          <tokens>
            <token id="18" string="work" />
          </tokens>
        </chunking>
        <chunking id="4" string="signed a contract with Putnam to publish her autobiography" type="VP">
          <tokens>
            <token id="3" string="signed" />
            <token id="4" string="a" />
            <token id="5" string="contract" />
            <token id="6" string="with" />
            <token id="7" string="Putnam" />
            <token id="8" string="to" />
            <token id="9" string="publish" />
            <token id="10" string="her" />
            <token id="11" string="autobiography" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="died before she could begin work on it" type="VP">
          <tokens>
            <token id="13" string="died" />
            <token id="14" string="before" />
            <token id="15" string="she" />
            <token id="16" string="could" />
            <token id="17" string="begin" />
            <token id="18" string="work" />
            <token id="19" string="on" />
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="15" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="publish her autobiography" type="VP">
          <tokens>
            <token id="9" string="publish" />
            <token id="10" string="her" />
            <token id="11" string="autobiography" />
          </tokens>
        </chunking>
        <chunking id="10" string="to publish her autobiography" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="publish" />
            <token id="10" string="her" />
            <token id="11" string="autobiography" />
          </tokens>
        </chunking>
        <chunking id="11" string="could begin work on it" type="VP">
          <tokens>
            <token id="16" string="could" />
            <token id="17" string="begin" />
            <token id="18" string="work" />
            <token id="19" string="on" />
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="begin work on it" type="VP">
          <tokens>
            <token id="17" string="begin" />
            <token id="18" string="work" />
            <token id="19" string="on" />
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="had signed a contract with Putnam to publish her autobiography" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="signed" />
            <token id="4" string="a" />
            <token id="5" string="contract" />
            <token id="6" string="with" />
            <token id="7" string="Putnam" />
            <token id="8" string="to" />
            <token id="9" string="publish" />
            <token id="10" string="her" />
            <token id="11" string="autobiography" />
          </tokens>
        </chunking>
        <chunking id="14" string="her autobiography" type="NP">
          <tokens>
            <token id="10" string="her" />
            <token id="11" string="autobiography" />
          </tokens>
        </chunking>
        <chunking id="15" string="had signed a contract with Putnam to publish her autobiography but died before she could begin work on it" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="signed" />
            <token id="4" string="a" />
            <token id="5" string="contract" />
            <token id="6" string="with" />
            <token id="7" string="Putnam" />
            <token id="8" string="to" />
            <token id="9" string="publish" />
            <token id="10" string="her" />
            <token id="11" string="autobiography" />
            <token id="12" string="but" />
            <token id="13" string="died" />
            <token id="14" string="before" />
            <token id="15" string="she" />
            <token id="16" string="could" />
            <token id="17" string="begin" />
            <token id="18" string="work" />
            <token id="19" string="on" />
            <token id="20" string="it" />
          </tokens>
        </chunking>
        <chunking id="16" string="before she could begin work on it" type="SBAR">
          <tokens>
            <token id="14" string="before" />
            <token id="15" string="she" />
            <token id="16" string="could" />
            <token id="17" string="begin" />
            <token id="18" string="work" />
            <token id="19" string="on" />
            <token id="20" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">signed</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">signed</governor>
          <dependent id="2">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">signed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">contract</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">signed</governor>
          <dependent id="5">contract</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Putnam</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">signed</governor>
          <dependent id="7">Putnam</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">publish</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">signed</governor>
          <dependent id="9">publish</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">autobiography</governor>
          <dependent id="10">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">publish</governor>
          <dependent id="11">autobiography</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">signed</governor>
          <dependent id="12">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">signed</governor>
          <dependent id="13">died</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">begin</governor>
          <dependent id="14">before</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">begin</governor>
          <dependent id="15">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">begin</governor>
          <dependent id="16">could</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">died</governor>
          <dependent id="17">begin</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">begin</governor>
          <dependent id="18">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">it</governor>
          <dependent id="19">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">begin</governor>
          <dependent id="20">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Putnam" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Putnam" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="145" has_coreference="true">
      <content>Tearfully sentimental when it came to her husband and family, she reveled in life as a grandmother and glowed whenever she talked of her children.</content>
      <tokens>
        <token id="1" string="Tearfully" lemma="tearfully" stem="tearfulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="sentimental" lemma="sentimental" stem="sentiment" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="reveled" lemma="revel" stem="revel" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="grandmother" lemma="grandmother" stem="grandmoth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="glowed" lemma="glow" stem="glow" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="whenever" lemma="whenever" stem="whenev" pos="WRB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="talked" lemma="talk" stem="talk" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADJP (ADJP (RB Tearfully) (JJ sentimental)) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBD came) (PP (TO to) (NP (PRP$ her) (NN husband) (CC and) (NN family)))))))) (, ,) (NP (PRP she)) (VP (VP (VBD reveled) (PP (IN in) (NP (NN life))) (PP (IN as) (NP (DT a) (NN grandmother)))) (CC and) (VP (VBD glowed) (SBAR (WHADVP (WRB whenever)) (S (NP (PRP she)) (VP (VBD talked) (PP (IN of) (NP (PRP$ her) (NNS children)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her husband and family" type="NP">
          <tokens>
            <token id="7" string="her" />
            <token id="8" string="husband" />
            <token id="9" string="and" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
        <chunking id="2" string="Tearfully sentimental when it came to her husband and family" type="ADJP">
          <tokens>
            <token id="1" string="Tearfully" />
            <token id="2" string="sentimental" />
            <token id="3" string="when" />
            <token id="4" string="it" />
            <token id="5" string="came" />
            <token id="6" string="to" />
            <token id="7" string="her" />
            <token id="8" string="husband" />
            <token id="9" string="and" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
        <chunking id="3" string="Tearfully sentimental" type="ADJP">
          <tokens>
            <token id="1" string="Tearfully" />
            <token id="2" string="sentimental" />
          </tokens>
        </chunking>
        <chunking id="4" string="when it came to her husband and family" type="SBAR">
          <tokens>
            <token id="3" string="when" />
            <token id="4" string="it" />
            <token id="5" string="came" />
            <token id="6" string="to" />
            <token id="7" string="her" />
            <token id="8" string="husband" />
            <token id="9" string="and" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
        <chunking id="5" string="glowed whenever she talked of her children" type="VP">
          <tokens>
            <token id="20" string="glowed" />
            <token id="21" string="whenever" />
            <token id="22" string="she" />
            <token id="23" string="talked" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="life" type="NP">
          <tokens>
            <token id="15" string="life" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="a grandmother" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="grandmother" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="3" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="she" type="NP">
          <tokens>
            <token id="12" string="she" />
          </tokens>
        </chunking>
        <chunking id="11" string="reveled in life as a grandmother and glowed whenever she talked of her children" type="VP">
          <tokens>
            <token id="13" string="reveled" />
            <token id="14" string="in" />
            <token id="15" string="life" />
            <token id="16" string="as" />
            <token id="17" string="a" />
            <token id="18" string="grandmother" />
            <token id="19" string="and" />
            <token id="20" string="glowed" />
            <token id="21" string="whenever" />
            <token id="22" string="she" />
            <token id="23" string="talked" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="whenever she talked of her children" type="SBAR">
          <tokens>
            <token id="21" string="whenever" />
            <token id="22" string="she" />
            <token id="23" string="talked" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="13" string="talked of her children" type="VP">
          <tokens>
            <token id="23" string="talked" />
            <token id="24" string="of" />
            <token id="25" string="her" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="14" string="came to her husband and family" type="VP">
          <tokens>
            <token id="5" string="came" />
            <token id="6" string="to" />
            <token id="7" string="her" />
            <token id="8" string="husband" />
            <token id="9" string="and" />
            <token id="10" string="family" />
          </tokens>
        </chunking>
        <chunking id="15" string="reveled in life as a grandmother" type="VP">
          <tokens>
            <token id="13" string="reveled" />
            <token id="14" string="in" />
            <token id="15" string="life" />
            <token id="16" string="as" />
            <token id="17" string="a" />
            <token id="18" string="grandmother" />
          </tokens>
        </chunking>
        <chunking id="16" string="her children" type="NP">
          <tokens>
            <token id="25" string="her" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="17" string="whenever" type="WHADVP">
          <tokens>
            <token id="21" string="whenever" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">sentimental</governor>
          <dependent id="1">Tearfully</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">reveled</governor>
          <dependent id="2">sentimental</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">came</governor>
          <dependent id="3">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">came</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">sentimental</governor>
          <dependent id="5">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">husband</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">husband</governor>
          <dependent id="7">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">came</governor>
          <dependent id="8">husband</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">husband</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">husband</governor>
          <dependent id="10">family</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">reveled</governor>
          <dependent id="12">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">reveled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">life</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">reveled</governor>
          <dependent id="15">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">grandmother</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">grandmother</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">reveled</governor>
          <dependent id="18">grandmother</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">reveled</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">reveled</governor>
          <dependent id="20">glowed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">talked</governor>
          <dependent id="21">whenever</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">talked</governor>
          <dependent id="22">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">glowed</governor>
          <dependent id="23">talked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">children</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">children</governor>
          <dependent id="25">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">talked</governor>
          <dependent id="26">children</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="146" has_coreference="true">
      <content>Their struggles and early failed marriages seemed not to matter.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="struggles" lemma="struggle" stem="struggl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="early" lemma="early" stem="earli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="failed" lemma="fail" stem="fail" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="marriages" lemma="marriage" stem="marriag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ Their) (NNS struggles)) (ADVP (CC and) (RB early))) (VP (VBD failed) (SBAR (S (NP (NNS marriages)) (VP (VBD seemed) (S (RB not) (VP (TO to) (VP (NN matter)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="marriages" type="NP">
          <tokens>
            <token id="6" string="marriages" />
          </tokens>
        </chunking>
        <chunking id="2" string="Their struggles" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="struggles" />
          </tokens>
        </chunking>
        <chunking id="3" string="seemed not to matter" type="VP">
          <tokens>
            <token id="7" string="seemed" />
            <token id="8" string="not" />
            <token id="9" string="to" />
            <token id="10" string="matter" />
          </tokens>
        </chunking>
        <chunking id="4" string="failed marriages seemed not to matter" type="VP">
          <tokens>
            <token id="5" string="failed" />
            <token id="6" string="marriages" />
            <token id="7" string="seemed" />
            <token id="8" string="not" />
            <token id="9" string="to" />
            <token id="10" string="matter" />
          </tokens>
        </chunking>
        <chunking id="5" string="marriages seemed not to matter" type="SBAR">
          <tokens>
            <token id="6" string="marriages" />
            <token id="7" string="seemed" />
            <token id="8" string="not" />
            <token id="9" string="to" />
            <token id="10" string="matter" />
          </tokens>
        </chunking>
        <chunking id="6" string="to matter" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="matter" />
          </tokens>
        </chunking>
        <chunking id="7" string="Their struggles and early" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="struggles" />
            <token id="3" string="and" />
            <token id="4" string="early" />
          </tokens>
        </chunking>
        <chunking id="8" string="matter" type="VP">
          <tokens>
            <token id="10" string="matter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">struggles</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">failed</governor>
          <dependent id="2">struggles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">early</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">struggles</governor>
          <dependent id="4">early</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">failed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">seemed</governor>
          <dependent id="6">marriages</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">failed</governor>
          <dependent id="7">seemed</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">matter</governor>
          <dependent id="8">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">matter</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">seemed</governor>
          <dependent id="10">matter</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="147" has_coreference="true">
      <content>While she always spoke fondly of Arnaz, Miss Ball claimed that she had found the perfect mate in Morton.</content>
      <tokens>
        <token id="1" string="While" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="spoke" lemma="speak" stem="spoke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="fondly" lemma="fondly" stem="fondli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Arnaz" lemma="Arnaz" stem="arnaz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="11" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="perfect" lemma="perfect" stem="perfect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="mate" lemma="mate" stem="mate" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Morton" lemma="Morton" stem="morton" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN While) (S (NP (PRP she)) (ADVP (RB always)) (VP (VBD spoke) (ADVP (RB fondly)) (PP (IN of) (NP (NNP Arnaz)))))) (, ,) (NP (NNP Miss) (NNP Ball)) (VP (VBD claimed) (SBAR (IN that) (S (NP (PRP she)) (VP (VBD had) (VP (VBN found) (NP (NP (DT the) (JJ perfect) (NN mate)) (PP (IN in) (NP (NNP Morton))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="While she always spoke fondly of Arnaz" type="SBAR">
          <tokens>
            <token id="1" string="While" />
            <token id="2" string="she" />
            <token id="3" string="always" />
            <token id="4" string="spoke" />
            <token id="5" string="fondly" />
            <token id="6" string="of" />
            <token id="7" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="2" string="that she had found the perfect mate in Morton" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="she" />
            <token id="14" string="had" />
            <token id="15" string="found" />
            <token id="16" string="the" />
            <token id="17" string="perfect" />
            <token id="18" string="mate" />
            <token id="19" string="in" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="3" string="spoke fondly of Arnaz" type="VP">
          <tokens>
            <token id="4" string="spoke" />
            <token id="5" string="fondly" />
            <token id="6" string="of" />
            <token id="7" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="4" string="Morton" type="NP">
          <tokens>
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="5" string="the perfect mate" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="perfect" />
            <token id="18" string="mate" />
          </tokens>
        </chunking>
        <chunking id="6" string="claimed that she had found the perfect mate in Morton" type="VP">
          <tokens>
            <token id="11" string="claimed" />
            <token id="12" string="that" />
            <token id="13" string="she" />
            <token id="14" string="had" />
            <token id="15" string="found" />
            <token id="16" string="the" />
            <token id="17" string="perfect" />
            <token id="18" string="mate" />
            <token id="19" string="in" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="7" string="found the perfect mate in Morton" type="VP">
          <tokens>
            <token id="15" string="found" />
            <token id="16" string="the" />
            <token id="17" string="perfect" />
            <token id="18" string="mate" />
            <token id="19" string="in" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="8" string="Arnaz" type="NP">
          <tokens>
            <token id="7" string="Arnaz" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="had found the perfect mate in Morton" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="found" />
            <token id="16" string="the" />
            <token id="17" string="perfect" />
            <token id="18" string="mate" />
            <token id="19" string="in" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="11" string="the perfect mate in Morton" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="perfect" />
            <token id="18" string="mate" />
            <token id="19" string="in" />
            <token id="20" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="12" string="Miss Ball" type="NP">
          <tokens>
            <token id="9" string="Miss" />
            <token id="10" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">spoke</governor>
          <dependent id="1">While</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">spoke</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">spoke</governor>
          <dependent id="3">always</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">claimed</governor>
          <dependent id="4">spoke</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">spoke</governor>
          <dependent id="5">fondly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Arnaz</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">spoke</governor>
          <dependent id="7">Arnaz</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Ball</governor>
          <dependent id="9">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">claimed</governor>
          <dependent id="10">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">claimed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">found</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">found</governor>
          <dependent id="13">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">found</governor>
          <dependent id="14">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">claimed</governor>
          <dependent id="15">found</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">mate</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">mate</governor>
          <dependent id="17">perfect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">found</governor>
          <dependent id="18">mate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Morton</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">mate</governor>
          <dependent id="20">Morton</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Morton" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Morton" />
          </tokens>
        </entity>
        <entity id="2" string="Arnaz" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Arnaz" />
          </tokens>
        </entity>
        <entity id="3" string="Miss Ball" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Miss" />
            <token id="10" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="148" has_coreference="true">
      <content>&amp;quot;He (Morton) takes care of me like I was his mother,&amp;quot; she told an interviewer in 1981.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Morton" lemma="Morton" stem="morton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="care" lemma="care" stem="care" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="interviewer" lemma="interviewer" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="1981" lemma="1981" stem="1981" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP He)) (PRN (-LRB- -LRB-) (NP (NNP Morton)) (-RRB- -RRB-)) (VP (VBZ takes) (NP (NP (NN care)) (PP (IN of) (NP (PRP me)))) (SBAR (IN like) (S (NP (PRP I)) (VP (VBD was) (NP (PRP$ his) (NN mother))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD told) (NP (DT an) (NN interviewer)) (PP (IN in) (NP (CD 1981)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="takes care of me like I was his mother" type="VP">
          <tokens>
            <token id="6" string="takes" />
            <token id="7" string="care" />
            <token id="8" string="of" />
            <token id="9" string="me" />
            <token id="10" string="like" />
            <token id="11" string="I" />
            <token id="12" string="was" />
            <token id="13" string="his" />
            <token id="14" string="mother" />
          </tokens>
        </chunking>
        <chunking id="2" string="an interviewer" type="NP">
          <tokens>
            <token id="19" string="an" />
            <token id="20" string="interviewer" />
          </tokens>
        </chunking>
        <chunking id="3" string="told an interviewer in 1981" type="VP">
          <tokens>
            <token id="18" string="told" />
            <token id="19" string="an" />
            <token id="20" string="interviewer" />
            <token id="21" string="in" />
            <token id="22" string="1981" />
          </tokens>
        </chunking>
        <chunking id="4" string="care of me" type="NP">
          <tokens>
            <token id="7" string="care" />
            <token id="8" string="of" />
            <token id="9" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="was his mother" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="his" />
            <token id="14" string="mother" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="17" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="Morton" type="NP">
          <tokens>
            <token id="4" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="9" string="me" type="NP">
          <tokens>
            <token id="9" string="me" />
          </tokens>
        </chunking>
        <chunking id="10" string="1981" type="NP">
          <tokens>
            <token id="22" string="1981" />
          </tokens>
        </chunking>
        <chunking id="11" string="his mother" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="mother" />
          </tokens>
        </chunking>
        <chunking id="12" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
        <chunking id="13" string="care" type="NP">
          <tokens>
            <token id="7" string="care" />
          </tokens>
        </chunking>
        <chunking id="14" string="like I was his mother" type="SBAR">
          <tokens>
            <token id="10" string="like" />
            <token id="11" string="I" />
            <token id="12" string="was" />
            <token id="13" string="his" />
            <token id="14" string="mother" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">takes</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">takes</governor>
          <dependent id="4">Morton</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">told</governor>
          <dependent id="6">takes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">takes</governor>
          <dependent id="7">care</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">me</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">care</governor>
          <dependent id="9">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">mother</governor>
          <dependent id="10">like</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">mother</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">mother</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">mother</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">takes</governor>
          <dependent id="14">mother</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">told</governor>
          <dependent id="17">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">interviewer</governor>
          <dependent id="19">an</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">told</governor>
          <dependent id="20">interviewer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">1981</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">told</governor>
          <dependent id="22">1981</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Morton" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Morton" />
          </tokens>
        </entity>
        <entity id="2" string="1981" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="1981" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="149" has_coreference="true">
      <content>&amp;quot;Gary gives me protection.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Gary" lemma="Gary" stem="gari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="gives" lemma="give" stem="give" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="protection" lemma="protection" stem="protect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Gary)) (VP (VBZ gives) (NP (PRP me)) (NP (NN protection))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Gary" type="NP">
          <tokens>
            <token id="2" string="Gary" />
          </tokens>
        </chunking>
        <chunking id="2" string="me" type="NP">
          <tokens>
            <token id="4" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="protection" type="NP">
          <tokens>
            <token id="5" string="protection" />
          </tokens>
        </chunking>
        <chunking id="4" string="gives me protection" type="VP">
          <tokens>
            <token id="3" string="gives" />
            <token id="4" string="me" />
            <token id="5" string="protection" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">gives</governor>
          <dependent id="2">Gary</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">gives</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="3">gives</governor>
          <dependent id="4">me</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">gives</governor>
          <dependent id="5">protection</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gary" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Gary" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="150" has_coreference="true">
      <content>On a scale of 1 to 10, Miss Ball said, &amp;quot;I rate my marriage to Gary a 12.&amp;quot;</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="scale" lemma="scale" stem="scale" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="1" lemma="1" stem="1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="rate" lemma="rate" stem="rate" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Gary" lemma="Gary" stem="gari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (NP (DT a) (NN scale)) (PP (IN of) (NP (QP (CD 1) (TO to) (CD 10)))))) (PRN (, ,) (S (NP (NNP Miss) (NNP Ball)) (VP (VBD said))) (, ,)) (`` ``) (NP (PRP I)) (VP (VBP rate) (NP (PRP$ my) (NN marriage)) (PP (TO to) (NP (NP (NNP Gary)) (NP (DT a) (CD 12))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a scale" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="scale" />
          </tokens>
        </chunking>
        <chunking id="2" string="Gary" type="NP">
          <tokens>
            <token id="19" string="Gary" />
          </tokens>
        </chunking>
        <chunking id="3" string="a scale of 1 to 10" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="scale" />
            <token id="4" string="of" />
            <token id="5" string="1" />
            <token id="6" string="to" />
            <token id="7" string="10" />
          </tokens>
        </chunking>
        <chunking id="4" string="Gary a 12" type="NP">
          <tokens>
            <token id="19" string="Gary" />
            <token id="20" string="a" />
            <token id="21" string="12" />
          </tokens>
        </chunking>
        <chunking id="5" string="a 12" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="12" />
          </tokens>
        </chunking>
        <chunking id="6" string="1 to 10" type="NP">
          <tokens>
            <token id="5" string="1" />
            <token id="6" string="to" />
            <token id="7" string="10" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="14" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="my marriage" type="NP">
          <tokens>
            <token id="16" string="my" />
            <token id="17" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="Miss Ball" type="NP">
          <tokens>
            <token id="9" string="Miss" />
            <token id="10" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="11" string="rate my marriage to Gary a 12" type="VP">
          <tokens>
            <token id="15" string="rate" />
            <token id="16" string="my" />
            <token id="17" string="marriage" />
            <token id="18" string="to" />
            <token id="19" string="Gary" />
            <token id="20" string="a" />
            <token id="21" string="12" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">scale</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">scale</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">rate</governor>
          <dependent id="3">scale</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">10</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">10</governor>
          <dependent id="5">1</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">10</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">scale</governor>
          <dependent id="7">10</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Ball</governor>
          <dependent id="9">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Ball</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="15">rate</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">rate</governor>
          <dependent id="14">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">rate</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">marriage</governor>
          <dependent id="16">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">rate</governor>
          <dependent id="17">marriage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Gary</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">rate</governor>
          <dependent id="19">Gary</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">12</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">Gary</governor>
          <dependent id="21">12</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="1" />
          </tokens>
        </entity>
        <entity id="2" string="12" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="12" />
          </tokens>
        </entity>
        <entity id="3" string="Gary" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Gary" />
          </tokens>
        </entity>
        <entity id="4" string="10" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="10" />
          </tokens>
        </entity>
        <entity id="5" string="Miss Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Miss" />
            <token id="10" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="151" has_coreference="true">
      <content>But to her countless television fans -- from the postwar babies who adored her during the &amp;apost;50s to their children and children&amp;apost;s children who roared at her antics through decades of reruns -- it was always Lucy and Ricky.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="countless" lemma="countless" stem="countless" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="fans" lemma="fan" stem="fan" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="postwar" lemma="postwar" stem="postwar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="babies" lemma="baby" stem="babi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="adored" lemma="adore" stem="ador" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="17" string="'50s" lemma="'50s" stem="'50" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="roared" lemma="roar" stem="roar" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="antics" lemma="antic" stem="antic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="reruns" lemma="rerun" stem="rerun" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="39" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="Ricky" lemma="Ricky" stem="ricki" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (TO to) (NP (PRP$ her) (JJ countless) (NN television) (NNS fans))) (PRN (: --) (PP (IN from) (NP (NP (NP (DT the) (JJ postwar) (NNS babies)) (SBAR (WHNP (WP who)) (S (VP (VBD adored) (NP (PRP$ her)) (PP (IN during) (NP (DT the) (CD '50s))) (PP (TO to) (NP (PRP$ their) (NNS children))))))) (CC and) (NP (NP (NP (NNS children) (POS 's)) (NNS children)) (SBAR (WHNP (WP who)) (S (VP (VBD roared) (PP (IN at) (NP (PRP$ her) (NNS antics))) (PP (IN through) (NP (NP (NNS decades)) (PP (IN of) (NP (NNS reruns))))))))))) (: --)) (NP (PRP it)) (VP (VBD was) (ADVP (RB always)) (NP (NNP Lucy) (CC and) (NNP Ricky))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the '50s" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="'50s" />
          </tokens>
        </chunking>
        <chunking id="2" string="the postwar babies" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="postwar" />
            <token id="11" string="babies" />
          </tokens>
        </chunking>
        <chunking id="3" string="decades of reruns" type="NP">
          <tokens>
            <token id="31" string="decades" />
            <token id="32" string="of" />
            <token id="33" string="reruns" />
          </tokens>
        </chunking>
        <chunking id="4" string="roared at her antics through decades of reruns" type="VP">
          <tokens>
            <token id="26" string="roared" />
            <token id="27" string="at" />
            <token id="28" string="her" />
            <token id="29" string="antics" />
            <token id="30" string="through" />
            <token id="31" string="decades" />
            <token id="32" string="of" />
            <token id="33" string="reruns" />
          </tokens>
        </chunking>
        <chunking id="5" string="who roared at her antics through decades of reruns" type="SBAR">
          <tokens>
            <token id="25" string="who" />
            <token id="26" string="roared" />
            <token id="27" string="at" />
            <token id="28" string="her" />
            <token id="29" string="antics" />
            <token id="30" string="through" />
            <token id="31" string="decades" />
            <token id="32" string="of" />
            <token id="33" string="reruns" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="35" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="the postwar babies who adored her during the '50s to their children" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="postwar" />
            <token id="11" string="babies" />
            <token id="12" string="who" />
            <token id="13" string="adored" />
            <token id="14" string="her" />
            <token id="15" string="during" />
            <token id="16" string="the" />
            <token id="17" string="'50s" />
            <token id="18" string="to" />
            <token id="19" string="their" />
            <token id="20" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="their children" type="NP">
          <tokens>
            <token id="19" string="their" />
            <token id="20" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lucy and Ricky" type="NP">
          <tokens>
            <token id="38" string="Lucy" />
            <token id="39" string="and" />
            <token id="40" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="10" string="children 's children who roared at her antics through decades of reruns" type="NP">
          <tokens>
            <token id="22" string="children" />
            <token id="23" string="'s" />
            <token id="24" string="children" />
            <token id="25" string="who" />
            <token id="26" string="roared" />
            <token id="27" string="at" />
            <token id="28" string="her" />
            <token id="29" string="antics" />
            <token id="30" string="through" />
            <token id="31" string="decades" />
            <token id="32" string="of" />
            <token id="33" string="reruns" />
          </tokens>
        </chunking>
        <chunking id="11" string="her antics" type="NP">
          <tokens>
            <token id="28" string="her" />
            <token id="29" string="antics" />
          </tokens>
        </chunking>
        <chunking id="12" string="the postwar babies who adored her during the '50s to their children and children 's children who roared at her antics through decades of reruns" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="postwar" />
            <token id="11" string="babies" />
            <token id="12" string="who" />
            <token id="13" string="adored" />
            <token id="14" string="her" />
            <token id="15" string="during" />
            <token id="16" string="the" />
            <token id="17" string="'50s" />
            <token id="18" string="to" />
            <token id="19" string="their" />
            <token id="20" string="children" />
            <token id="21" string="and" />
            <token id="22" string="children" />
            <token id="23" string="'s" />
            <token id="24" string="children" />
            <token id="25" string="who" />
            <token id="26" string="roared" />
            <token id="27" string="at" />
            <token id="28" string="her" />
            <token id="29" string="antics" />
            <token id="30" string="through" />
            <token id="31" string="decades" />
            <token id="32" string="of" />
            <token id="33" string="reruns" />
          </tokens>
        </chunking>
        <chunking id="13" string="her" type="NP">
          <tokens>
            <token id="14" string="her" />
          </tokens>
        </chunking>
        <chunking id="14" string="was always Lucy and Ricky" type="VP">
          <tokens>
            <token id="36" string="was" />
            <token id="37" string="always" />
            <token id="38" string="Lucy" />
            <token id="39" string="and" />
            <token id="40" string="Ricky" />
          </tokens>
        </chunking>
        <chunking id="15" string="reruns" type="NP">
          <tokens>
            <token id="33" string="reruns" />
          </tokens>
        </chunking>
        <chunking id="16" string="adored her during the '50s to their children" type="VP">
          <tokens>
            <token id="13" string="adored" />
            <token id="14" string="her" />
            <token id="15" string="during" />
            <token id="16" string="the" />
            <token id="17" string="'50s" />
            <token id="18" string="to" />
            <token id="19" string="their" />
            <token id="20" string="children" />
          </tokens>
        </chunking>
        <chunking id="17" string="decades" type="NP">
          <tokens>
            <token id="31" string="decades" />
          </tokens>
        </chunking>
        <chunking id="18" string="her countless television fans" type="NP">
          <tokens>
            <token id="3" string="her" />
            <token id="4" string="countless" />
            <token id="5" string="television" />
            <token id="6" string="fans" />
          </tokens>
        </chunking>
        <chunking id="19" string="who adored her during the '50s to their children" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="adored" />
            <token id="14" string="her" />
            <token id="15" string="during" />
            <token id="16" string="the" />
            <token id="17" string="'50s" />
            <token id="18" string="to" />
            <token id="19" string="their" />
            <token id="20" string="children" />
          </tokens>
        </chunking>
        <chunking id="20" string="children 's" type="NP">
          <tokens>
            <token id="22" string="children" />
            <token id="23" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="children 's children" type="NP">
          <tokens>
            <token id="22" string="children" />
            <token id="23" string="'s" />
            <token id="24" string="children" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="38">Lucy</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">fans</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">fans</governor>
          <dependent id="3">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">fans</governor>
          <dependent id="4">countless</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">fans</governor>
          <dependent id="5">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">Lucy</governor>
          <dependent id="6">fans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">babies</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">babies</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">babies</governor>
          <dependent id="10">postwar</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="38">Lucy</governor>
          <dependent id="11">babies</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">adored</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">babies</governor>
          <dependent id="13">adored</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">adored</governor>
          <dependent id="14">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">'50s</governor>
          <dependent id="15">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">'50s</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">adored</governor>
          <dependent id="17">'50s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">children</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">children</governor>
          <dependent id="19">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">adored</governor>
          <dependent id="20">children</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">babies</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">children</governor>
          <dependent id="22">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">children</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">babies</governor>
          <dependent id="24">children</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">roared</governor>
          <dependent id="25">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">children</governor>
          <dependent id="26">roared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">antics</governor>
          <dependent id="27">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">antics</governor>
          <dependent id="28">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">roared</governor>
          <dependent id="29">antics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">decades</governor>
          <dependent id="30">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">roared</governor>
          <dependent id="31">decades</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">reruns</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">decades</governor>
          <dependent id="33">reruns</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">Lucy</governor>
          <dependent id="35">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="38">Lucy</governor>
          <dependent id="36">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="38">Lucy</governor>
          <dependent id="37">always</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="38">Lucy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="38">Lucy</governor>
          <dependent id="39">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="38">Lucy</governor>
          <dependent id="40">Ricky</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the '50s" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="'50s" />
          </tokens>
        </entity>
        <entity id="2" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="Lucy" />
          </tokens>
        </entity>
        <entity id="3" string="decades" type="DURATION" score="0.0">
          <tokens>
            <token id="31" string="decades" />
          </tokens>
        </entity>
        <entity id="4" string="Ricky" type="PERSON" score="0.0">
          <tokens>
            <token id="40" string="Ricky" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="152" has_coreference="true">
      <content>More than a quarter-century of marriage to Morton could not erase that.</content>
      <tokens>
        <token id="1" string="More" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="quarter-century" lemma="quarter-century" stem="quarter-centuri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Morton" lemma="Morton" stem="morton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="9" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="erase" lemma="erase" stem="eras" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (QP (JJR More) (IN than) (DT a)) (NN quarter-century)) (PP (IN of) (NP (NP (NN marriage)) (PP (TO to) (NP (NNP Morton)))))) (VP (MD could) (RB not) (VP (VB erase) (NP (DT that)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="12" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="Morton" type="NP">
          <tokens>
            <token id="8" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="3" string="erase that" type="VP">
          <tokens>
            <token id="11" string="erase" />
            <token id="12" string="that" />
          </tokens>
        </chunking>
        <chunking id="4" string="More than a quarter-century of marriage to Morton" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="a" />
            <token id="4" string="quarter-century" />
            <token id="5" string="of" />
            <token id="6" string="marriage" />
            <token id="7" string="to" />
            <token id="8" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="5" string="marriage" type="NP">
          <tokens>
            <token id="6" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="6" string="could not erase that" type="VP">
          <tokens>
            <token id="9" string="could" />
            <token id="10" string="not" />
            <token id="11" string="erase" />
            <token id="12" string="that" />
          </tokens>
        </chunking>
        <chunking id="7" string="marriage to Morton" type="NP">
          <tokens>
            <token id="6" string="marriage" />
            <token id="7" string="to" />
            <token id="8" string="Morton" />
          </tokens>
        </chunking>
        <chunking id="8" string="More than a quarter-century" type="NP">
          <tokens>
            <token id="1" string="More" />
            <token id="2" string="than" />
            <token id="3" string="a" />
            <token id="4" string="quarter-century" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">a</governor>
          <dependent id="1">More</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">More</governor>
          <dependent id="2">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">quarter-century</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">erase</governor>
          <dependent id="4">quarter-century</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">marriage</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">quarter-century</governor>
          <dependent id="6">marriage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Morton</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">marriage</governor>
          <dependent id="8">Morton</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">erase</governor>
          <dependent id="9">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">erase</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">erase</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">erase</governor>
          <dependent id="12">that</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Morton" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Morton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="153" has_coreference="true">
      <content>There was always the hilarious image of the redhead and &amp;quot;that Cuban bongo player,&amp;quot; as Miss Ball affectionately called him.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="hilarious" lemma="hilarious" stem="hilari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="redhead" lemma="redhead" stem="redhead" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Cuban" lemma="cuban" stem="cuban" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="14" string="bongo" lemma="bongo" stem="bongo" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="player" lemma="player" stem="player" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Miss" lemma="Miss" stem="miss" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="affectionately" lemma="affectionately" stem="affection" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBD was) (ADVP (RB always)) (NP (NP (DT the) (ADJP (JJ hilarious)) (NN image)) (PP (IN of) (NP (NP (DT the) (NN redhead)) (CC and) (`` ``) (PP (IN that) (NP (JJ Cuban) (NN bongo) (NN player)))))) (, ,) ('' '') (SBAR (IN as) (S (NP (NNP Miss) (NNP Ball)) (ADVP (RB affectionately)) (VP (VBD called) (NP (PRP him)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the hilarious image of the redhead and `` that Cuban bongo player" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="hilarious" />
            <token id="6" string="image" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="redhead" />
            <token id="10" string="and" />
            <token id="11" string="&quot;" />
            <token id="12" string="that" />
            <token id="13" string="Cuban" />
            <token id="14" string="bongo" />
            <token id="15" string="player" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="the hilarious image" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="hilarious" />
            <token id="6" string="image" />
          </tokens>
        </chunking>
        <chunking id="4" string="called him" type="VP">
          <tokens>
            <token id="22" string="called" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="hilarious" type="ADJP">
          <tokens>
            <token id="5" string="hilarious" />
          </tokens>
        </chunking>
        <chunking id="6" string="Cuban bongo player" type="NP">
          <tokens>
            <token id="13" string="Cuban" />
            <token id="14" string="bongo" />
            <token id="15" string="player" />
          </tokens>
        </chunking>
        <chunking id="7" string="the redhead and `` that Cuban bongo player" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="redhead" />
            <token id="10" string="and" />
            <token id="11" string="&quot;" />
            <token id="12" string="that" />
            <token id="13" string="Cuban" />
            <token id="14" string="bongo" />
            <token id="15" string="player" />
          </tokens>
        </chunking>
        <chunking id="8" string="was always the hilarious image of the redhead and `` that Cuban bongo player , '' as Miss Ball affectionately called him" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="always" />
            <token id="4" string="the" />
            <token id="5" string="hilarious" />
            <token id="6" string="image" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="redhead" />
            <token id="10" string="and" />
            <token id="11" string="&quot;" />
            <token id="12" string="that" />
            <token id="13" string="Cuban" />
            <token id="14" string="bongo" />
            <token id="15" string="player" />
            <token id="16" string="," />
            <token id="17" string="&quot;" />
            <token id="18" string="as" />
            <token id="19" string="Miss" />
            <token id="20" string="Ball" />
            <token id="21" string="affectionately" />
            <token id="22" string="called" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="as Miss Ball affectionately called him" type="SBAR">
          <tokens>
            <token id="18" string="as" />
            <token id="19" string="Miss" />
            <token id="20" string="Ball" />
            <token id="21" string="affectionately" />
            <token id="22" string="called" />
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="him" type="NP">
          <tokens>
            <token id="23" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="the redhead" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="redhead" />
          </tokens>
        </chunking>
        <chunking id="12" string="Miss Ball" type="NP">
          <tokens>
            <token id="19" string="Miss" />
            <token id="20" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">was</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">was</governor>
          <dependent id="3">always</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">image</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">image</governor>
          <dependent id="5">hilarious</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">was</governor>
          <dependent id="6">image</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">image</governor>
          <dependent id="6">image</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">redhead</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">redhead</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">image</governor>
          <dependent id="9">redhead</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">image</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">player</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">player</governor>
          <dependent id="13">Cuban</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">player</governor>
          <dependent id="14">bongo</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">image</governor>
          <dependent id="15">player</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">called</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Ball</governor>
          <dependent id="19">Miss</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">called</governor>
          <dependent id="20">Ball</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">called</governor>
          <dependent id="21">affectionately</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">was</governor>
          <dependent id="22">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">called</governor>
          <dependent id="23">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Ball" />
          </tokens>
        </entity>
        <entity id="2" string="Cuban" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="13" string="Cuban" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="154" has_coreference="true">
      <content>Even years after the Lucy shows ended, the comedienne openly admitted to missing the characterization.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="3" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="ended" lemma="end" stem="end" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="comedienne" lemma="comedienne" stem="comedienn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="openly" lemma="openly" stem="openli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="admitted" lemma="admit" stem="admit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="missing" lemma="miss" stem="miss" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="characterization" lemma="characterization" stem="character" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (RB Even) (S (NP (NP (NNS years)) (PP (IN after) (NP (DT the) (NNP Lucy)))) (VP (VBZ shows) (VP (VBN ended))))) (, ,) (NP (DT the) (NN comedienne)) (ADVP (RB openly)) (VP (VBD admitted) (PP (TO to) (S (VP (VBG missing) (NP (DT the) (NN characterization)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Even years after the Lucy shows ended" type="SBAR">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="years" />
            <token id="3" string="after" />
            <token id="4" string="the" />
            <token id="5" string="Lucy" />
            <token id="6" string="shows" />
            <token id="7" string="ended" />
          </tokens>
        </chunking>
        <chunking id="2" string="admitted to missing the characterization" type="VP">
          <tokens>
            <token id="12" string="admitted" />
            <token id="13" string="to" />
            <token id="14" string="missing" />
            <token id="15" string="the" />
            <token id="16" string="characterization" />
          </tokens>
        </chunking>
        <chunking id="3" string="missing the characterization" type="VP">
          <tokens>
            <token id="14" string="missing" />
            <token id="15" string="the" />
            <token id="16" string="characterization" />
          </tokens>
        </chunking>
        <chunking id="4" string="the characterization" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="characterization" />
          </tokens>
        </chunking>
        <chunking id="5" string="years after the Lucy" type="NP">
          <tokens>
            <token id="2" string="years" />
            <token id="3" string="after" />
            <token id="4" string="the" />
            <token id="5" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="6" string="shows ended" type="VP">
          <tokens>
            <token id="6" string="shows" />
            <token id="7" string="ended" />
          </tokens>
        </chunking>
        <chunking id="7" string="ended" type="VP">
          <tokens>
            <token id="7" string="ended" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Lucy" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="9" string="years" type="NP">
          <tokens>
            <token id="2" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="the comedienne" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="comedienne" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">shows</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">shows</governor>
          <dependent id="2">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Lucy</governor>
          <dependent id="3">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Lucy</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">years</governor>
          <dependent id="5">Lucy</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">admitted</governor>
          <dependent id="6">shows</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">shows</governor>
          <dependent id="7">ended</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">comedienne</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">admitted</governor>
          <dependent id="10">comedienne</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">admitted</governor>
          <dependent id="11">openly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">admitted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">missing</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">admitted</governor>
          <dependent id="14">missing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">characterization</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">missing</governor>
          <dependent id="16">characterization</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Lucy" />
          </tokens>
        </entity>
        <entity id="2" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="155" has_coreference="true">
      <content>&amp;quot;After Lucy ended, I thought, &amp;apost;I&amp;apost;ll live a few more years and then I&amp;apost;ll die,&amp;quot; she said in 1983.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="ended" lemma="end" stem="end" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="live" lemma="live" stem="live" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="die" lemma="die" stem="die" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (IN After) (S (NP (NNP Lucy)) (VP (VBD ended)))) (, ,) (NP (PRP I)) (VP (VBD thought) (, ,) (`` `) (S (S (NP (PRP I)) (VP (MD 'll) (VP (VB live) (NP (DT a) (JJ few) (JJR more) (NNS years))))) (CC and) (S (ADVP (RB then)) (NP (PRP I)) (VP (MD 'll) (VP (VB die))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said) (PP (IN in) (NP (CD 1983)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'ll die" type="VP">
          <tokens>
            <token id="20" string="'ll" />
            <token id="21" string="die" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="thought , ` I 'll live a few more years and then I 'll die" type="VP">
          <tokens>
            <token id="7" string="thought" />
            <token id="8" string="," />
            <token id="9" string="'" />
            <token id="10" string="I" />
            <token id="11" string="'ll" />
            <token id="12" string="live" />
            <token id="13" string="a" />
            <token id="14" string="few" />
            <token id="15" string="more" />
            <token id="16" string="years" />
            <token id="17" string="and" />
            <token id="18" string="then" />
            <token id="19" string="I" />
            <token id="20" string="'ll" />
            <token id="21" string="die" />
          </tokens>
        </chunking>
        <chunking id="4" string="After Lucy ended" type="SBAR">
          <tokens>
            <token id="2" string="After" />
            <token id="3" string="Lucy" />
            <token id="4" string="ended" />
          </tokens>
        </chunking>
        <chunking id="5" string="live a few more years" type="VP">
          <tokens>
            <token id="12" string="live" />
            <token id="13" string="a" />
            <token id="14" string="few" />
            <token id="15" string="more" />
            <token id="16" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="24" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="said in 1983" type="VP">
          <tokens>
            <token id="25" string="said" />
            <token id="26" string="in" />
            <token id="27" string="1983" />
          </tokens>
        </chunking>
        <chunking id="8" string="1983" type="NP">
          <tokens>
            <token id="27" string="1983" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lucy" type="NP">
          <tokens>
            <token id="3" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="10" string="ended" type="VP">
          <tokens>
            <token id="4" string="ended" />
          </tokens>
        </chunking>
        <chunking id="11" string="'ll live a few more years" type="VP">
          <tokens>
            <token id="11" string="'ll" />
            <token id="12" string="live" />
            <token id="13" string="a" />
            <token id="14" string="few" />
            <token id="15" string="more" />
            <token id="16" string="years" />
          </tokens>
        </chunking>
        <chunking id="12" string="a few more years" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="few" />
            <token id="15" string="more" />
            <token id="16" string="years" />
          </tokens>
        </chunking>
        <chunking id="13" string="die" type="VP">
          <tokens>
            <token id="21" string="die" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">ended</governor>
          <dependent id="2">After</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">ended</governor>
          <dependent id="3">Lucy</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">thought</governor>
          <dependent id="4">ended</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">thought</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">said</governor>
          <dependent id="7">thought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">live</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">live</governor>
          <dependent id="11">'ll</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">thought</governor>
          <dependent id="12">live</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">years</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">years</governor>
          <dependent id="14">few</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">years</governor>
          <dependent id="15">more</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">live</governor>
          <dependent id="16">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">live</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">die</governor>
          <dependent id="18">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">die</governor>
          <dependent id="19">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">die</governor>
          <dependent id="20">'ll</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">live</governor>
          <dependent id="21">die</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">said</governor>
          <dependent id="24">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">1983</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">said</governor>
          <dependent id="27">1983</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="1983" />
          </tokens>
        </entity>
        <entity id="2" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Lucy" />
          </tokens>
        </entity>
        <entity id="3" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="16" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="156" has_coreference="true">
      <content>&amp;quot;I didn&amp;apost;t plan on living this long. . . .</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="plan" lemma="plan" stem="plan" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD did) (RB n't) (VP (VB plan) (PP (IN on) (S (VP (VBG living) (NP (DT this) (JJ long))))))) (: ...) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="this long" type="NP">
          <tokens>
            <token id="8" string="this" />
            <token id="9" string="long" />
          </tokens>
        </chunking>
        <chunking id="2" string="living this long" type="VP">
          <tokens>
            <token id="7" string="living" />
            <token id="8" string="this" />
            <token id="9" string="long" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="did n't plan on living this long" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="n't" />
            <token id="5" string="plan" />
            <token id="6" string="on" />
            <token id="7" string="living" />
            <token id="8" string="this" />
            <token id="9" string="long" />
          </tokens>
        </chunking>
        <chunking id="5" string="plan on living this long" type="VP">
          <tokens>
            <token id="5" string="plan" />
            <token id="6" string="on" />
            <token id="7" string="living" />
            <token id="8" string="this" />
            <token id="9" string="long" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">plan</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">plan</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">plan</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">plan</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">living</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">plan</governor>
          <dependent id="7">living</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">long</governor>
          <dependent id="8">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">living</governor>
          <dependent id="9">long</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="157" has_coreference="true">
      <content>Now I miss her. . . .&amp;quot; Related Stories: Page 3 and Calendar, Page 1</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="miss" lemma="miss" stem="miss" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string=". . . ." lemma="..." stem=". . . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Related" lemma="relate" stem="relat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Stories" lemma="Stories" stem="stori" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Page" lemma="Page" stem="page" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="3" lemma="3" stem="3" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Calendar" lemma="Calendar" stem="calendar" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Page" lemma="Page" stem="page" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="1" lemma="1" stem="1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Now)) (NP (PRP I)) (VP (VBP miss) (NP (PRP$ her)))) (: ...) ('' '') (PP (VBN Related) (NP (NP (NNP Stories)) (: :) (NP (NP (NNP Page) (CD 3)) (CC and) (NP (NNP Calendar) (, ,) (NNP Page))))) (CD 1)))</syntactictree>
      <chunkings>
        <chunking id="1" string="miss her" type="VP">
          <tokens>
            <token id="3" string="miss" />
            <token id="4" string="her" />
          </tokens>
        </chunking>
        <chunking id="2" string="Stories : Page 3 and Calendar , Page" type="NP">
          <tokens>
            <token id="8" string="Stories" />
            <token id="9" string=":" />
            <token id="10" string="Page" />
            <token id="11" string="3" />
            <token id="12" string="and" />
            <token id="13" string="Calendar" />
            <token id="14" string="," />
            <token id="15" string="Page" />
          </tokens>
        </chunking>
        <chunking id="3" string="her" type="NP">
          <tokens>
            <token id="4" string="her" />
          </tokens>
        </chunking>
        <chunking id="4" string="Calendar , Page" type="NP">
          <tokens>
            <token id="13" string="Calendar" />
            <token id="14" string="," />
            <token id="15" string="Page" />
          </tokens>
        </chunking>
        <chunking id="5" string="Page 3 and Calendar , Page" type="NP">
          <tokens>
            <token id="10" string="Page" />
            <token id="11" string="3" />
            <token id="12" string="and" />
            <token id="13" string="Calendar" />
            <token id="14" string="," />
            <token id="15" string="Page" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="Stories" type="NP">
          <tokens>
            <token id="8" string="Stories" />
          </tokens>
        </chunking>
        <chunking id="8" string="Page 3" type="NP">
          <tokens>
            <token id="10" string="Page" />
            <token id="11" string="3" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">miss</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">miss</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">miss</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">miss</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Stories</governor>
          <dependent id="7">Related</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">miss</governor>
          <dependent id="8">Stories</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">Stories</governor>
          <dependent id="10">Page</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">Page</governor>
          <dependent id="11">3</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">Page</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Page</governor>
          <dependent id="13">Calendar</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Page</governor>
          <dependent id="15">Page</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">miss</governor>
          <dependent id="16">1</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="1" />
          </tokens>
        </entity>
        <entity id="2" string="3" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="3" />
          </tokens>
        </entity>
        <entity id="3" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="5-6-7" string="Pretty Lucille Ball" id_sentence="74" />
      <mentions>
        <mention ids_tokens="1-2" string="Lucille Ball" id_sentence="1" />
        <mention ids_tokens="4-25" string="the leggy showgirl , model and B-grade movie queen whose pumpkin hair and genius for comedy made her an icon of television" id_sentence="1" />
        <mention ids_tokens="7" string="I" id_sentence="2" />
        <mention ids_tokens="10-12" string="Miss Ball's" id_sentence="7" />
        <mention ids_tokens="1-2" string="Miss Ball" id_sentence="10" />
        <mention ids_tokens="4-37" string="a tough-talking woman who had used her stardom and show business savvy to become , with her then-husband , the late Desi Arnaz , head of one of Hollywood's major studios , Desilu" id_sentence="10" />
        <mention ids_tokens="10" string="her" id_sentence="10" />
        <mention ids_tokens="20" string="her" id_sentence="10" />
        <mention ids_tokens="2" string="her" id_sentence="11" />
        <mention ids_tokens="6" string="she" id_sentence="11" />
        <mention ids_tokens="2" string="her" id_sentence="12" />
        <mention ids_tokens="6" string="her" id_sentence="12" />
        <mention ids_tokens="24" string="her" id_sentence="12" />
        <mention ids_tokens="28-30" string="Miss Ball's" id_sentence="12" />
        <mention ids_tokens="4" string="she" id_sentence="13" />
        <mention ids_tokens="8" string="she" id_sentence="13" />
        <mention ids_tokens="10" string="her" id_sentence="13" />
        <mention ids_tokens="1" string="Her" id_sentence="14" />
        <mention ids_tokens="5" string="she" id_sentence="14" />
        <mention ids_tokens="15" string="her" id_sentence="14" />
        <mention ids_tokens="24" string="her" id_sentence="14" />
        <mention ids_tokens="8" string="Ball" id_sentence="15" />
        <mention ids_tokens="21-22" string="Miss Ball" id_sentence="22" />
        <mention ids_tokens="23" string="her" id_sentence="22" />
        <mention ids_tokens="5-6" string="Miss Ball" id_sentence="23" />
        <mention ids_tokens="17" string="her" id_sentence="23" />
        <mention ids_tokens="10" string="Ball" id_sentence="25" />
        <mention ids_tokens="5-6" string="Miss Ball" id_sentence="30" />
        <mention ids_tokens="24" string="her" id_sentence="30" />
        <mention ids_tokens="6" string="her" id_sentence="31" />
        <mention ids_tokens="19-20" string="Miss Ball" id_sentence="31" />
        <mention ids_tokens="22" string="she" id_sentence="31" />
        <mention ids_tokens="29" string="her" id_sentence="31" />
        <mention ids_tokens="1" string="Lucille" id_sentence="44" />
        <mention ids_tokens="10-11" string="Miss Ball" id_sentence="46" />
        <mention ids_tokens="15" string="I" id_sentence="46" />
        <mention ids_tokens="8" string="her" id_sentence="47" />
        <mention ids_tokens="2" string="She" id_sentence="48" />
        <mention ids_tokens="10" string="she" id_sentence="48" />
        <mention ids_tokens="22" string="she" id_sentence="48" />
        <mention ids_tokens="3" string="that" id_sentence="49" />
        <mention ids_tokens="2" string="she" id_sentence="50" />
        <mention ids_tokens="9" string="her" id_sentence="50" />
        <mention ids_tokens="1-3" string="Miss Ball's" id_sentence="52" />
        <mention ids_tokens="10" string="she" id_sentence="52" />
        <mention ids_tokens="23" string="she" id_sentence="53" />
        <mention ids_tokens="14" string="she" id_sentence="54" />
        <mention ids_tokens="2" string="I" id_sentence="55" />
        <mention ids_tokens="15" string="I" id_sentence="55" />
        <mention ids_tokens="19" string="I" id_sentence="55" />
        <mention ids_tokens="28" string="she" id_sentence="55" />
        <mention ids_tokens="2" string="I" id_sentence="56" />
        <mention ids_tokens="13-15" string="Miss Ball's" id_sentence="57" />
        <mention ids_tokens="5" string="she" id_sentence="58" />
        <mention ids_tokens="18-19" string="Miss Ball" id_sentence="58" />
        <mention ids_tokens="23-24" string="Miss Ball" id_sentence="60" />
        <mention ids_tokens="6-7" string="Miss Ball" id_sentence="63" />
        <mention ids_tokens="12-13" string="Miss Ball" id_sentence="66" />
        <mention ids_tokens="5" string="her" id_sentence="67" />
        <mention ids_tokens="5" string="she" id_sentence="68" />
        <mention ids_tokens="1" string="Her" id_sentence="69" />
        <mention ids_tokens="10-11" string="Miss Ball" id_sentence="69" />
        <mention ids_tokens="7" string="her" id_sentence="70" />
        <mention ids_tokens="13" string="she" id_sentence="70" />
        <mention ids_tokens="5" string="she" id_sentence="71" />
        <mention ids_tokens="7" string="her" id_sentence="71" />
        <mention ids_tokens="3" string="her" id_sentence="72" />
        <mention ids_tokens="1" string="She" id_sentence="73" />
        <mention ids_tokens="20" string="her" id_sentence="73" />
        <mention ids_tokens="15-16" string="Miss Ball" id_sentence="75" />
        <mention ids_tokens="1" string="She" id_sentence="76" />
        <mention ids_tokens="8" string="It" id_sentence="76" />
        <mention ids_tokens="10-11" string="Miss Ball" id_sentence="79" />
        <mention ids_tokens="2" string="We" id_sentence="80" />
        <mention ids_tokens="19-20" string="Miss Ball" id_sentence="80" />
        <mention ids_tokens="11-12" string="Miss Ball" id_sentence="87" />
        <mention ids_tokens="15" string="her" id_sentence="87" />
        <mention ids_tokens="20-21" string="Miss Ball" id_sentence="94" />
        <mention ids_tokens="6" string="them" id_sentence="95" />
        <mention ids_tokens="11" string="it" id_sentence="96" />
        <mention ids_tokens="27" string="them" id_sentence="98" />
        <mention ids_tokens="1-3" string="Miss Ball's" id_sentence="100" />
        <mention ids_tokens="10" string="her" id_sentence="101" />
        <mention ids_tokens="9-12" string="Miss Ball and Arnaz" id_sentence="102" />
        <mention ids_tokens="9-10" string="Miss Ball" id_sentence="102" />
        <mention ids_tokens="13" string="she" id_sentence="103" />
        <mention ids_tokens="1" string="It" id_sentence="105" />
        <mention ids_tokens="6-7" string="Miss Ball" id_sentence="106" />
        <mention ids_tokens="12" string="her" id_sentence="107" />
        <mention ids_tokens="18" string="she" id_sentence="107" />
        <mention ids_tokens="3-6" string="Arnaz and Miss Ball" id_sentence="109" />
        <mention ids_tokens="9-17" string="their &quot; I Love Lucy &quot; films to CBS" id_sentence="109" />
        <mention ids_tokens="23" string="she" id_sentence="109" />
        <mention ids_tokens="25" string="her" id_sentence="109" />
        <mention ids_tokens="39-40" string="Miss Ball" id_sentence="112" />
        <mention ids_tokens="2" string="We" id_sentence="113" />
        <mention ids_tokens="4-5" string="Miss Ball" id_sentence="116" />
        <mention ids_tokens="3" string="she" id_sentence="117" />
        <mention ids_tokens="13" string="she" id_sentence="117" />
        <mention ids_tokens="4-5" string="Miss Ball" id_sentence="118" />
        <mention ids_tokens="10" string="her" id_sentence="118" />
        <mention ids_tokens="30" string="her" id_sentence="118" />
        <mention ids_tokens="6-7" string="Miss Ball" id_sentence="122" />
        <mention ids_tokens="2" string="My" id_sentence="123" />
        <mention ids_tokens="6" string="my" id_sentence="123" />
        <mention ids_tokens="12-13" string="Miss Ball" id_sentence="123" />
        <mention ids_tokens="2" string="I" id_sentence="124" />
        <mention ids_tokens="3" string="they" id_sentence="125" />
        <mention ids_tokens="1" string="I" id_sentence="126" />
        <mention ids_tokens="2" string="her" id_sentence="128" />
        <mention ids_tokens="23" string="her" id_sentence="128" />
        <mention ids_tokens="15-16" string="Miss Ball" id_sentence="131" />
        <mention ids_tokens="20" string="us" id_sentence="132" />
        <mention ids_tokens="7" string="her" id_sentence="133" />
        <mention ids_tokens="10" string="she" id_sentence="133" />
        <mention ids_tokens="4" string="her" id_sentence="134" />
        <mention ids_tokens="9" string="she" id_sentence="134" />
        <mention ids_tokens="14-15" string="Miss Ball" id_sentence="134" />
        <mention ids_tokens="3-4" string="Lucille Ball" id_sentence="136" />
        <mention ids_tokens="5" string="she" id_sentence="137" />
        <mention ids_tokens="20" string="she" id_sentence="137" />
        <mention ids_tokens="31" string="her" id_sentence="137" />
        <mention ids_tokens="34" string="her" id_sentence="137" />
        <mention ids_tokens="2" string="I" id_sentence="138" />
        <mention ids_tokens="9-10" string="Miss Ball" id_sentence="138" />
        <mention ids_tokens="8" string="she" id_sentence="139" />
        <mention ids_tokens="9-10" string="Miss Ball" id_sentence="147" />
        <mention ids_tokens="9-10" string="Miss Ball" id_sentence="150" />
        <mention ids_tokens="3" string="her" id_sentence="151" />
        <mention ids_tokens="14" string="her" id_sentence="151" />
        <mention ids_tokens="28" string="her" id_sentence="151" />
        <mention ids_tokens="19-20" string="Miss Ball" id_sentence="153" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="14-15" string="Lucy Ricardo" id_sentence="23" />
      <mentions>
        <mention ids_tokens="9" string="Lucy" id_sentence="2" />
        <mention ids_tokens="6" string="Lucy" id_sentence="22" />
        <mention ids_tokens="27" string="Lucy" id_sentence="28" />
        <mention ids_tokens="12" string="Lucy" id_sentence="33" />
        <mention ids_tokens="10" string="Lucy" id_sentence="35" />
        <mention ids_tokens="5" string="Lucy" id_sentence="36" />
        <mention ids_tokens="7" string="her" id_sentence="36" />
        <mention ids_tokens="6" string="she" id_sentence="37" />
        <mention ids_tokens="25" string="her" id_sentence="37" />
        <mention ids_tokens="6" string="Lucy" id_sentence="38" />
        <mention ids_tokens="5" string="Lucy" id_sentence="40" />
        <mention ids_tokens="8" string="herself" id_sentence="40" />
        <mention ids_tokens="34" string="her" id_sentence="40" />
        <mention ids_tokens="1" string="Her" id_sentence="41" />
        <mention ids_tokens="5" string="her" id_sentence="41" />
        <mention ids_tokens="17" string="Lucy" id_sentence="46" />
        <mention ids_tokens="1" string="Lucy" id_sentence="51" />
        <mention ids_tokens="14" string="Lucy" id_sentence="86" />
        <mention ids_tokens="30-37" string="Lucy , &quot; a series featuring Desi Jr." id_sentence="122" />
        <mention ids_tokens="30" string="Lucy" id_sentence="122" />
        <mention ids_tokens="3" string="Lucy" id_sentence="129" />
        <mention ids_tokens="18" string="Lucy" id_sentence="141" />
        <mention ids_tokens="38" string="Lucy" id_sentence="151" />
        <mention ids_tokens="4-5" string="the Lucy" id_sentence="154" />
        <mention ids_tokens="3" string="Lucy" id_sentence="155" />
        <mention ids_tokens="24" string="she" id_sentence="155" />
        <mention ids_tokens="4" string="her" id_sentence="157" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="8-9" string="Love Lucy" id_sentence="2" />
      <mentions>
        <mention ids_tokens="5-27" string="Love Lucy , &quot; which premiered on CBS on Oct. 15 , 1951 , that earned Miss Ball her niche in television history" id_sentence="22" />
        <mention ids_tokens="26-29" string="Love Lucy , too" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="29-30" string="the world" id_sentence="2" />
      <mentions>
        <mention ids_tokens="4-6" string="the world's" id_sentence="131" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="41-42-43-44" string="a ruptured abdominal aorta" id_sentence="2" />
      <mentions>
        <mention ids_tokens="28-29" string="her aorta" id_sentence="3" />
        <mention ids_tokens="13-14" string="the aorta" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13" string="&quot; Lucy &quot; to four decades of smitten television fans" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="8-9-10-11-12-13" string="four decades of smitten television fans" id_sentence="3" />
      <mentions>
        <mention ids_tokens="30" string="decades" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="11-12-13" string="smitten television fans" id_sentence="3" />
      <mentions>
        <mention ids_tokens="7" string="fans" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="40-41" string="hour operation" id_sentence="3" />
      <mentions>
        <mention ids_tokens="24-25" string="the operation" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="1-2-3-4" string="Hospital spokesman Ronald Wise" id_sentence="4" />
      <mentions>
        <mention ids_tokens="20" string="Wise" id_sentence="5" />
        <mention ids_tokens="12" string="Wise" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="8-9" string="5 a.m." id_sentence="5" />
      <mentions>
        <mention ids_tokens="2" string="5" id_sentence="61" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="7" string="this" id_sentence="6" />
      <mentions>
        <mention ids_tokens="4" string="itself" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="2-3-4" string="last week 's" id_sentence="8" />
      <mentions>
        <mention ids_tokens="4" string="it" id_sentence="9" />
        <mention ids_tokens="6-12" string="the largest outpouring they had ever seen" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="23-24-25-26-27-28-29-30-31-32-33-34-35-36-37" string="the late Desi Arnaz , head of one of Hollywood 's major studios , Desilu" id_sentence="10" />
      <mentions>
        <mention ids_tokens="8-10" string="the Cuban-born Arnaz" id_sentence="23" />
        <mention ids_tokens="12" string="Arnaz" id_sentence="25" />
        <mention ids_tokens="20" string="Arnaz" id_sentence="75" />
        <mention ids_tokens="2" string="Arnaz" id_sentence="79" />
        <mention ids_tokens="7" string="his" id_sentence="79" />
        <mention ids_tokens="10-13" string="the heavily accented Arnaz" id_sentence="85" />
        <mention ids_tokens="11-18" string="&quot; I Love Lucy &quot; a time slot" id_sentence="86" />
        <mention ids_tokens="12" string="Arnaz" id_sentence="102" />
        <mention ids_tokens="4" string="Arnaz" id_sentence="103" />
        <mention ids_tokens="3" string="Arnaz" id_sentence="109" />
        <mention ids_tokens="21" string="Arnaz" id_sentence="118" />
        <mention ids_tokens="7" string="Arnaz" id_sentence="147" />
        <mention ids_tokens="2" string="He" id_sentence="148" />
        <mention ids_tokens="13" string="his" id_sentence="148" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="37" string="Desilu" id_sentence="10" />
      <mentions>
        <mention ids_tokens="34-35" string="her head" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="6-7" string="her struggles" id_sentence="12" />
      <mentions>
        <mention ids_tokens="1-4" string="Their struggles and early" id_sentence="146" />
        <mention ids_tokens="1-2" string="Their struggles" id_sentence="146" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22-23-24-25-26" string="the television career that made her a legend" id_sentence="12" />
      <mentions>
        <mention ids_tokens="15-16" string="her career" id_sentence="14" />
        <mention ids_tokens="18-19" string="her career" id_sentence="139" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="1" string="Life" id_sentence="114" />
      <mentions>
        <mention ids_tokens="28-31" string="Miss Ball's life" id_sentence="12" />
        <mention ids_tokens="2" string="I" id_sentence="112" />
        <mention ids_tokens="12" string="my" id_sentence="112" />
        <mention ids_tokens="22" string="I" id_sentence="112" />
        <mention ids_tokens="29" string="my" id_sentence="112" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="35-36" string="two years" id_sentence="14" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="15" />
        <mention ids_tokens="2" string="My" id_sentence="16" />
        <mention ids_tokens="1" string="My" id_sentence="17" />
        <mention ids_tokens="2" string="I" id_sentence="19" />
        <mention ids_tokens="1" string="I" id_sentence="20" />
        <mention ids_tokens="3" string="I" id_sentence="21" />
        <mention ids_tokens="10" string="I" id_sentence="21" />
        <mention ids_tokens="12-13" string="a model" id_sentence="21" />
        <mention ids_tokens="17" string="I" id_sentence="21" />
        <mention ids_tokens="19-20" string="&quot; I" id_sentence="21" />
        <mention ids_tokens="1" string="It" id_sentence="22" />
        <mention ids_tokens="4-27" string="I Love Lucy , &quot; which premiered on CBS on Oct. 15 , 1951 , that earned Miss Ball her niche in television history" id_sentence="22" />
        <mention ids_tokens="9" string="two" id_sentence="37" />
        <mention ids_tokens="4" string="two" id_sentence="47" />
        <mention ids_tokens="23-41" string="the years that followed to everyone from The Three Stooges and Buster Keaton to Katharine Hepburn and Spencer Tracy" id_sentence="70" />
        <mention ids_tokens="7-8" string="40 years" id_sentence="98" />
        <mention ids_tokens="16-29" string="the years since the original 153 &quot; I Love Lucy &quot; episodes were telecast" id_sentence="99" />
        <mention ids_tokens="23-29" string="I Love Lucy &quot; episodes were telecast" id_sentence="99" />
        <mention ids_tokens="15" string="years" id_sentence="103" />
        <mention ids_tokens="19-20" string="19 years" id_sentence="112" />
        <mention ids_tokens="2-5" string="years after the Lucy" id_sentence="154" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="24-25-26" string="her two children" id_sentence="14" />
      <mentions>
        <mention ids_tokens="2-4" string="her children's" id_sentence="128" />
        <mention ids_tokens="25-26" string="her children" id_sentence="145" />
        <mention ids_tokens="19-20" string="their children" id_sentence="151" />
        <mention ids_tokens="22-23" string="children's" id_sentence="151" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="28-29-30" string="Lucie in 1951" id_sentence="14" />
      <mentions>
        <mention ids_tokens="39" string="Lucie" id_sentence="122" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="10-11" string="an interviewer" id_sentence="15" />
      <mentions>
        <mention ids_tokens="14" string="me" id_sentence="76" />
      </mentions>
    </coreference>
    <coreference id="29" type="PROPER">
      <referenced ids_tokens="12" string="CBS" id_sentence="22" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="86" />
        <mention ids_tokens="3-4" string="a smash" id_sentence="86" />
        <mention ids_tokens="14" string="it" id_sentence="91" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="29-30-31-32-33" string="the show 's little Ricky" id_sentence="53" />
      <mentions>
        <mention ids_tokens="20" string="Ricky" id_sentence="23" />
        <mention ids_tokens="18" string="Ricky" id_sentence="33" />
        <mention ids_tokens="10-11" string="Ricky's" id_sentence="36" />
        <mention ids_tokens="40" string="Ricky" id_sentence="151" />
      </mentions>
    </coreference>
    <coreference id="31" type="LIST">
      <referenced ids_tokens="12-13-14-15-16-17-18-19-20" string="the wacky Lucy Ricardo and her conga-playing husband Ricky" id_sentence="23" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="26" />
        <mention ids_tokens="38-40" string="Lucy and Ricky" id_sentence="151" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20" string="her conga-playing husband Ricky" id_sentence="23" />
      <mentions>
        <mention ids_tokens="15-16" string="the husband" id_sentence="85" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="a weekly dash" id_sentence="24" />
      <mentions>
        <mention ids_tokens="6-7" string="the show" id_sentence="25" />
        <mention ids_tokens="1-2" string="The show" id_sentence="27" />
        <mention ids_tokens="10" string="it" id_sentence="27" />
        <mention ids_tokens="8-9" string="the show" id_sentence="29" />
        <mention ids_tokens="29-31" string="the show's" id_sentence="53" />
        <mention ids_tokens="18-19" string="the show" id_sentence="87" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17-18-19-20-21-22" string="the biggest television audience of its time -- of almost any time" id_sentence="24" />
      <mentions>
        <mention ids_tokens="10-12" string="the television audience" id_sentence="53" />
      </mentions>
    </coreference>
    <coreference id="37" type="PROPER">
      <referenced ids_tokens="9" string="Miss" id_sentence="25" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="110" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="7-8" string="the rerun" id_sentence="97" />
      <mentions>
        <mention ids_tokens="17-22" string="the popular and financially rewarding rerun" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5" string="A phenomenal 40 million viewers" id_sentence="33" />
      <mentions>
        <mention ids_tokens="2" string="their" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="43" type="NOMINAL">
      <referenced ids_tokens="7-8" string="the antics" id_sentence="33" />
      <mentions>
        <mention ids_tokens="28-29" string="her antics" id_sentence="151" />
      </mentions>
    </coreference>
    <coreference id="44" type="PROPER">
      <referenced ids_tokens="9-10" string="each week" id_sentence="33" />
      <mentions>
        <mention ids_tokens="1" string="Week" id_sentence="40" />
        <mention ids_tokens="3" string="week" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="45" type="PROPER">
      <referenced ids_tokens="10-11" string="Ethel Mertz" id_sentence="34" />
      <mentions>
        <mention ids_tokens="8" string="Ethel" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="46" type="LIST">
      <referenced ids_tokens="2-3-4-5-6" string="their best friends and landlords" id_sentence="34" />
      <mentions>
        <mention ids_tokens="8" string="their" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="47" type="PROPER">
      <referenced ids_tokens="14-15" string="New York" id_sentence="38" />
      <mentions>
        <mention ids_tokens="21" string="N.Y." id_sentence="60" />
      </mentions>
    </coreference>
    <coreference id="49" type="PROPER">
      <referenced ids_tokens="16-17" string="the time" id_sentence="123" />
      <mentions>
        <mention ids_tokens="4-44" string="the time Lucy and Ethel , trying to impress their New York friends with the ultimate souvenir from a trip to Hollywood , pried loose the cement block containing John Wayne's footprints from in front of Grauman's Chinese Theater" id_sentence="38" />
        <mention ids_tokens="38" string="time" id_sentence="117" />
      </mentions>
    </coreference>
    <coreference id="51" type="NOMINAL">
      <referenced ids_tokens="29-30-31-32-33-34-35-36-37-38-39-40-41-42-43-44" string="the cement block containing John Wayne 's footprints from in front of Grauman 's Chinese Theater" id_sentence="38" />
      <mentions>
        <mention ids_tokens="4-5" string="the block" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="52" type="PROPER">
      <referenced ids_tokens="22-23-24" string="New York Times" id_sentence="42" />
      <mentions>
        <mention ids_tokens="6-7" string="The Times" id_sentence="46" />
        <mention ids_tokens="23-24" string="The Times" id_sentence="94" />
      </mentions>
    </coreference>
    <coreference id="54" type="PROPER">
      <referenced ids_tokens="13" string="Love" id_sentence="42" />
      <mentions>
        <mention ids_tokens="2" string="its" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="57" type="NOMINAL">
      <referenced ids_tokens="11-12" string="the comedienne" id_sentence="47" />
      <mentions>
        <mention ids_tokens="11-15" string="the comedienne , then 63" id_sentence="128" />
      </mentions>
    </coreference>
    <coreference id="59" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6" string="Miss Ball 's personal favorite episodes" id_sentence="52" />
      <mentions>
        <mention ids_tokens="1-2" string="The episodes" id_sentence="92" />
      </mentions>
    </coreference>
    <coreference id="60" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12" string="just floating on a cloud" id_sentence="55" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="61" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20-21-22-23-24-25" string="the way I felt came across on the film" id_sentence="55" />
      <mentions>
        <mention ids_tokens="2-3" string="the way" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="62" type="PROPER">
      <referenced ids_tokens="33-34" string="the first" id_sentence="60" />
      <mentions>
        <mention ids_tokens="13" string="first" id_sentence="58" />
        <mention ids_tokens="6" string="first" id_sentence="78" />
        <mention ids_tokens="14" string="first" id_sentence="98" />
        <mention ids_tokens="37" string="first" id_sentence="109" />
      </mentions>
    </coreference>
    <coreference id="64" type="NOMINAL">
      <referenced ids_tokens="13-14" string="his mother" id_sentence="148" />
      <mentions>
        <mention ids_tokens="3-8" string="an electrician father and pianist mother" id_sentence="60" />
        <mention ids_tokens="27" string="her" id_sentence="60" />
        <mention ids_tokens="4" string="me" id_sentence="149" />
      </mentions>
    </coreference>
    <coreference id="65" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7" string="the brown-haired little girl" id_sentence="61" />
      <mentions>
        <mention ids_tokens="5" string="she" id_sentence="62" />
        <mention ids_tokens="17" string="her" id_sentence="62" />
        <mention ids_tokens="20" string="her" id_sentence="62" />
        <mention ids_tokens="22" string="her" id_sentence="62" />
      </mentions>
    </coreference>
    <coreference id="67" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11" string="a Ziegfeld Follies road show" id_sentence="64" />
      <mentions>
        <mention ids_tokens="32-33" string="their show" id_sentence="85" />
      </mentions>
    </coreference>
    <coreference id="68" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20-21-22" string="a handful of Broadway chorus lines" id_sentence="64" />
      <mentions>
        <mention ids_tokens="2" string="her" id_sentence="65" />
        <mention ids_tokens="9" string="I" id_sentence="65" />
        <mention ids_tokens="16" string="I" id_sentence="65" />
        <mention ids_tokens="34" string="she" id_sentence="65" />
      </mentions>
    </coreference>
    <coreference id="72" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11" string="Her curly hair bleached a Jean Harlow platinum , Miss Ball" id_sentence="69" />
      <mentions>
        <mention ids_tokens="7-8" string="her hair" id_sentence="71" />
      </mentions>
    </coreference>
    <coreference id="75" type="NOMINAL">
      <referenced ids_tokens="16-17-18" string="a troubled marriage" id_sentence="77" />
      <mentions>
        <mention ids_tokens="10-12" string="her troubled marriage" id_sentence="101" />
      </mentions>
    </coreference>
    <coreference id="76" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11" string="the phone -- no" id_sentence="80" />
      <mentions>
        <mention ids_tokens="9-10" string="the phone" id_sentence="81" />
        <mention ids_tokens="7-8" string="the phone" id_sentence="82" />
      </mentions>
    </coreference>
    <coreference id="77" type="PRONOMINAL">
      <referenced ids_tokens="2" string="You" id_sentence="81" />
      <mentions>
        <mention ids_tokens="10-12" string="I Love Lucy" id_sentence="84" />
      </mentions>
    </coreference>
    <coreference id="78" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10" string="a marriage over the phone" id_sentence="81" />
      <mentions>
        <mention ids_tokens="6-7" string="the marriage" id_sentence="84" />
      </mentions>
    </coreference>
    <coreference id="79" type="NOMINAL">
      <referenced ids_tokens="6-7" string="my children" id_sentence="123" />
      <mentions>
        <mention ids_tokens="5-8" string="children over the phone" id_sentence="82" />
        <mention ids_tokens="9" string="them" id_sentence="124" />
        <mention ids_tokens="10" string="they" id_sentence="125" />
      </mentions>
    </coreference>
    <coreference id="80" type="PROPER">
      <referenced ids_tokens="18-19-20" string="the determined Arnazes" id_sentence="85" />
      <mentions>
        <mention ids_tokens="2-3" string="the Arnazes" id_sentence="93" />
        <mention ids_tokens="12" string="our" id_sentence="93" />
      </mentions>
    </coreference>
    <coreference id="81" type="NOMINAL">
      <referenced ids_tokens="7-8" string="television executives" id_sentence="86" />
      <mentions>
        <mention ids_tokens="4" string="our" id_sentence="87" />
      </mentions>
    </coreference>
    <coreference id="82" type="NOMINAL">
      <referenced ids_tokens="15-16" string="her concept" id_sentence="87" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="88" />
        <mention ids_tokens="2" string="I" id_sentence="90" />
        <mention ids_tokens="4" string="my" id_sentence="90" />
        <mention ids_tokens="8" string="me" id_sentence="90" />
      </mentions>
    </coreference>
    <coreference id="85" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24-25-26-27-28" string="such films as &quot; The Good Earth &quot;" id_sentence="92" />
      <mentions>
        <mention ids_tokens="7-8" string="the films" id_sentence="93" />
        <mention ids_tokens="10-11" string="These films" id_sentence="94" />
        <mention ids_tokens="8" string="I" id_sentence="96" />
        <mention ids_tokens="13" string="me" id_sentence="97" />
        <mention ids_tokens="2" string="I" id_sentence="98" />
        <mention ids_tokens="5" string="I" id_sentence="98" />
        <mention ids_tokens="13" string="my" id_sentence="98" />
        <mention ids_tokens="17" string="I" id_sentence="98" />
        <mention ids_tokens="1" string="I" id_sentence="99" />
        <mention ids_tokens="6-7" string="the films" id_sentence="99" />
        <mention ids_tokens="31" string="they" id_sentence="99" />
        <mention ids_tokens="5" string="their" id_sentence="102" />
        <mention ids_tokens="2" string="He" id_sentence="103" />
        <mention ids_tokens="2" string="He" id_sentence="104" />
        <mention ids_tokens="8" string="he" id_sentence="104" />
      </mentions>
    </coreference>
    <coreference id="86" type="PROPER">
      <referenced ids_tokens="12" string="Earth" id_sentence="100" />
      <mentions>
        <mention ids_tokens="25-27" string="The Good Earth" id_sentence="92" />
      </mentions>
    </coreference>
    <coreference id="87" type="PRONOMINAL">
      <referenced ids_tokens="2" string="I" id_sentence="94" />
      <mentions>
        <mention ids_tokens="2" string="You" id_sentence="95" />
      </mentions>
    </coreference>
    <coreference id="88" type="PROPER">
      <referenced ids_tokens="2" string="Desi" id_sentence="96" />
      <mentions>
        <mention ids_tokens="2" string="he" id_sentence="97" />
        <mention ids_tokens="4" string="he" id_sentence="97" />
        <mention ids_tokens="10" string="he" id_sentence="97" />
      </mentions>
    </coreference>
    <coreference id="89" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="their television fans" id_sentence="102" />
      <mentions>
        <mention ids_tokens="30-31" string="her fans" id_sentence="118" />
      </mentions>
    </coreference>
    <coreference id="90" type="NOMINAL">
      <referenced ids_tokens="9" string="broads" id_sentence="105" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="108" />
        <mention ids_tokens="9" string="their" id_sentence="109" />
      </mentions>
    </coreference>
    <coreference id="91" type="PROPER">
      <referenced ids_tokens="20-21-22-23" string="stand-up comedian Gary Morton" id_sentence="107" />
      <mentions>
        <mention ids_tokens="1-2" string="Husband Morton" id_sentence="116" />
        <mention ids_tokens="9" string="he" id_sentence="117" />
        <mention ids_tokens="11" string="Morton" id_sentence="122" />
        <mention ids_tokens="20" string="Morton" id_sentence="147" />
        <mention ids_tokens="4" string="Morton" id_sentence="148" />
        <mention ids_tokens="2" string="Gary" id_sentence="149" />
        <mention ids_tokens="8" string="Morton" id_sentence="152" />
        <mention ids_tokens="23" string="him" id_sentence="153" />
      </mentions>
    </coreference>
    <coreference id="92" type="NOMINAL">
      <referenced ids_tokens="41-42-43" string="a major studio" id_sentence="109" />
      <mentions>
        <mention ids_tokens="15-16" string="the studio" id_sentence="125" />
      </mentions>
    </coreference>
    <coreference id="93" type="NOMINAL">
      <referenced ids_tokens="4" string="then" id_sentence="110" />
      <mentions>
        <mention ids_tokens="5" string="her" id_sentence="111" />
      </mentions>
    </coreference>
    <coreference id="94" type="NOMINAL">
      <referenced ids_tokens="7-8" string="18 shows" id_sentence="110" />
      <mentions>
        <mention ids_tokens="2-3" string="the shows" id_sentence="118" />
        <mention ids_tokens="14" string="shows" id_sentence="133" />
      </mentions>
    </coreference>
    <coreference id="95" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Friend Bob Hope" id_sentence="111" />
      <mentions>
        <mention ids_tokens="24" string="Hope" id_sentence="143" />
      </mentions>
    </coreference>
    <coreference id="96" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15" string="my marriage to Desi" id_sentence="112" />
      <mentions>
        <mention ids_tokens="14" string="I" id_sentence="150" />
        <mention ids_tokens="16-17" string="my marriage" id_sentence="150" />
        <mention ids_tokens="16" string="my" id_sentence="150" />
      </mentions>
    </coreference>
    <coreference id="101" type="LIST">
      <referenced ids_tokens="10-11-12-13-14" string="Elizabeth Taylor and Richard Burton" id_sentence="119" />
      <mentions>
        <mention ids_tokens="26" string="them" id_sentence="120" />
      </mentions>
    </coreference>
    <coreference id="103" type="NOMINAL">
      <referenced ids_tokens="33-34" string="a series" id_sentence="122" />
      <mentions>
        <mention ids_tokens="1-2" string="The series" id_sentence="127" />
      </mentions>
    </coreference>
    <coreference id="105" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="The Lucy character" id_sentence="129" />
      <mentions>
        <mention ids_tokens="5" string="she" id_sentence="130" />
        <mention ids_tokens="7" string="her" id_sentence="130" />
      </mentions>
    </coreference>
    <coreference id="109" type="PROPER">
      <referenced ids_tokens="1-2" string="Danny Kaye" id_sentence="135" />
      <mentions>
        <mention ids_tokens="18" string="Kaye" id_sentence="136" />
      </mentions>
    </coreference>
    <coreference id="110" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7" string="Role as Bag Lady The following year" id_sentence="139" />
      <mentions>
        <mention ids_tokens="7" string="it" id_sentence="140" />
      </mentions>
    </coreference>
    <coreference id="111" type="NOMINAL">
      <referenced ids_tokens="3-4" string="Bag Lady" id_sentence="139" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="140" />
        <mention ids_tokens="1" string="Her" id_sentence="141" />
        <mention ids_tokens="8" string="her" id_sentence="141" />
        <mention ids_tokens="23" string="she" id_sentence="141" />
        <mention ids_tokens="1" string="Her" id_sentence="143" />
        <mention ids_tokens="1" string="She" id_sentence="144" />
        <mention ids_tokens="10" string="her" id_sentence="144" />
        <mention ids_tokens="15" string="she" id_sentence="144" />
        <mention ids_tokens="7" string="her" id_sentence="145" />
        <mention ids_tokens="12" string="she" id_sentence="145" />
        <mention ids_tokens="22" string="she" id_sentence="145" />
        <mention ids_tokens="25" string="her" id_sentence="145" />
        <mention ids_tokens="2" string="she" id_sentence="147" />
        <mention ids_tokens="13" string="she" id_sentence="147" />
      </mentions>
    </coreference>
    <coreference id="112" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5" string="Her last flirtation with television" id_sentence="141" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="142" />
      </mentions>
    </coreference>
    <coreference id="114" type="NOMINAL">
      <referenced ids_tokens="4-5" string="a contract" id_sentence="144" />
      <mentions>
        <mention ids_tokens="4" string="it" id_sentence="145" />
      </mentions>
    </coreference>
    <coreference id="115" type="LIST">
      <referenced ids_tokens="7-8-9-10" string="her husband and family" id_sentence="145" />
      <mentions>
        <mention ids_tokens="1" string="Their" id_sentence="146" />
      </mentions>
    </coreference>
    <coreference id="120" type="PROPER">
      <referenced ids_tokens="11" string="3" id_sentence="157" />
      <mentions>
        <mention ids_tokens="6" string="I" id_sentence="155" />
        <mention ids_tokens="10" string="I" id_sentence="155" />
        <mention ids_tokens="19" string="I" id_sentence="155" />
        <mention ids_tokens="2" string="I" id_sentence="156" />
      </mentions>
    </coreference>
  </coreferences>
</document>
