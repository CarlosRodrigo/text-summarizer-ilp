<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP900118-0190">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Jurors in the McMartin Pre-School molestation case denounced the techniques of a child therapy center and a police department letter that inflamed parents and ignited the case.</content>
      <tokens>
        <token id="1" string="Jurors" lemma="Jurors" stem="juror" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="5" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="6" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="denounced" lemma="denounce" stem="denounc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="techniques" lemma="technique" stem="techniqu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="therapy" lemma="therapy" stem="therapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="department" lemma="department" stem="depart" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="inflamed" lemma="inflamed" stem="inflam" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="ignited" lemma="ignite" stem="ignit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Jurors)) (PP (IN in) (NP (DT the) (NNP McMartin) (NNP Pre-School) (NN molestation) (NN case)))) (VP (VP (VBD denounced) (NP (NP (NP (DT the) (NNS techniques)) (PP (IN of) (NP (DT a) (NN child) (NN therapy) (NN center)))) (CC and) (NP (NP (NP (DT a) (NN police) (NN department) (NN letter)) (SBAR (WHNP (WDT that)))) (NP (JJ inflamed) (NNS parents))))) (CC and) (VP (VBD ignited) (NP (DT the) (NN case)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Jurors" type="NP">
          <tokens>
            <token id="1" string="Jurors" />
          </tokens>
        </chunking>
        <chunking id="2" string="the case" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="denounced the techniques of a child therapy center and a police department letter that inflamed parents" type="VP">
          <tokens>
            <token id="8" string="denounced" />
            <token id="9" string="the" />
            <token id="10" string="techniques" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="child" />
            <token id="14" string="therapy" />
            <token id="15" string="center" />
            <token id="16" string="and" />
            <token id="17" string="a" />
            <token id="18" string="police" />
            <token id="19" string="department" />
            <token id="20" string="letter" />
            <token id="21" string="that" />
            <token id="22" string="inflamed" />
            <token id="23" string="parents" />
          </tokens>
        </chunking>
        <chunking id="4" string="the techniques of a child therapy center and a police department letter that inflamed parents" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="techniques" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="child" />
            <token id="14" string="therapy" />
            <token id="15" string="center" />
            <token id="16" string="and" />
            <token id="17" string="a" />
            <token id="18" string="police" />
            <token id="19" string="department" />
            <token id="20" string="letter" />
            <token id="21" string="that" />
            <token id="22" string="inflamed" />
            <token id="23" string="parents" />
          </tokens>
        </chunking>
        <chunking id="5" string="the techniques" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="techniques" />
          </tokens>
        </chunking>
        <chunking id="6" string="a police department letter that inflamed parents" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="police" />
            <token id="19" string="department" />
            <token id="20" string="letter" />
            <token id="21" string="that" />
            <token id="22" string="inflamed" />
            <token id="23" string="parents" />
          </tokens>
        </chunking>
        <chunking id="7" string="a police department letter that" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="police" />
            <token id="19" string="department" />
            <token id="20" string="letter" />
            <token id="21" string="that" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jurors in the McMartin Pre-School molestation case" type="NP">
          <tokens>
            <token id="1" string="Jurors" />
            <token id="2" string="in" />
            <token id="3" string="the" />
            <token id="4" string="McMartin" />
            <token id="5" string="Pre-School" />
            <token id="6" string="molestation" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="9" string="the McMartin Pre-School molestation case" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="McMartin" />
            <token id="5" string="Pre-School" />
            <token id="6" string="molestation" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="that" type="SBAR">
          <tokens>
            <token id="21" string="that" />
          </tokens>
        </chunking>
        <chunking id="11" string="denounced the techniques of a child therapy center and a police department letter that inflamed parents and ignited the case" type="VP">
          <tokens>
            <token id="8" string="denounced" />
            <token id="9" string="the" />
            <token id="10" string="techniques" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="child" />
            <token id="14" string="therapy" />
            <token id="15" string="center" />
            <token id="16" string="and" />
            <token id="17" string="a" />
            <token id="18" string="police" />
            <token id="19" string="department" />
            <token id="20" string="letter" />
            <token id="21" string="that" />
            <token id="22" string="inflamed" />
            <token id="23" string="parents" />
            <token id="24" string="and" />
            <token id="25" string="ignited" />
            <token id="26" string="the" />
            <token id="27" string="case" />
          </tokens>
        </chunking>
        <chunking id="12" string="the techniques of a child therapy center" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="techniques" />
            <token id="11" string="of" />
            <token id="12" string="a" />
            <token id="13" string="child" />
            <token id="14" string="therapy" />
            <token id="15" string="center" />
          </tokens>
        </chunking>
        <chunking id="13" string="a child therapy center" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="child" />
            <token id="14" string="therapy" />
            <token id="15" string="center" />
          </tokens>
        </chunking>
        <chunking id="14" string="ignited the case" type="VP">
          <tokens>
            <token id="25" string="ignited" />
            <token id="26" string="the" />
            <token id="27" string="case" />
          </tokens>
        </chunking>
        <chunking id="15" string="a police department letter" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="police" />
            <token id="19" string="department" />
            <token id="20" string="letter" />
          </tokens>
        </chunking>
        <chunking id="16" string="inflamed parents" type="NP">
          <tokens>
            <token id="22" string="inflamed" />
            <token id="23" string="parents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">denounced</governor>
          <dependent id="1">Jurors</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">case</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">case</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">case</governor>
          <dependent id="4">McMartin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">case</governor>
          <dependent id="5">Pre-School</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">case</governor>
          <dependent id="6">molestation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Jurors</governor>
          <dependent id="7">case</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">denounced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">techniques</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">denounced</governor>
          <dependent id="10">techniques</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">center</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">center</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">center</governor>
          <dependent id="13">child</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">center</governor>
          <dependent id="14">therapy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">techniques</governor>
          <dependent id="15">center</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">techniques</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">letter</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">letter</governor>
          <dependent id="18">police</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">letter</governor>
          <dependent id="19">department</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">techniques</governor>
          <dependent id="20">letter</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">letter</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">parents</governor>
          <dependent id="22">inflamed</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">letter</governor>
          <dependent id="23">parents</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">denounced</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">denounced</governor>
          <dependent id="25">ignited</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">case</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">ignited</governor>
          <dependent id="27">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McMartin Pre-School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="McMartin" />
            <token id="5" string="Pre-School" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Seven jurors who spoke with reporters in a joint news conference after acquitting Raymond Buckey and his mother, Peggy McMartin Buckey, on 52 molestation charges Thursday said they felt some children who testified may have been molested _ but not at the family-run McMartin Pre-School.</content>
      <tokens>
        <token id="1" string="Seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="2" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="spoke" lemma="speak" stem="spoke" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="joint" lemma="joint" stem="joint" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="acquitting" lemma="acquit" stem="acquit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="Raymond" lemma="Raymond" stem="raymond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="21" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="22" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="52" lemma="52" stem="52" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="26" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="testified" lemma="testify" stem="testifi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="_" lemma="_" stem="_" pos="RB" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="45" string="family-run" lemma="family-run" stem="family-run" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="46" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="47" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="48" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (CD Seven) (NNS jurors)) (SBAR (WHNP (WP who)) (S (VP (VBD spoke) (PP (IN with) (NP (NP (NNS reporters)) (PP (IN in) (NP (DT a) (JJ joint) (NN news) (NN conference))))) (PP (IN after) (S (VP (VBG acquitting) (NP (NP (NNP Raymond) (NNP Buckey)) (CC and) (NP (NP (NP (PRP$ his) (NN mother)) (, ,) (NP (NNP Peggy) (NNP McMartin) (NNP Buckey)) (, ,)) (PP (IN on) (NP (CD 52) (NN molestation) (NNS charges))))) (NP-TMP (NNP Thursday))))))))) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VBD felt) (SBAR (S (NP (NP (DT some) (NNS children)) (SBAR (WHNP (WP who)) (S (VP (VBD testified))))) (VP (MD may) (VP (VB have) (VP (VBN been) (VP (VBN molested) (UCP (ADVP (RB _)) (CC but) (PP (RB not) (IN at) (NP (DT the) (JJ family-run) (NNP McMartin) (NNP Pre-School)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="spoke with reporters in a joint news conference after acquitting Raymond Buckey and his mother , Peggy McMartin Buckey , on 52 molestation charges Thursday" type="VP">
          <tokens>
            <token id="4" string="spoke" />
            <token id="5" string="with" />
            <token id="6" string="reporters" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="joint" />
            <token id="10" string="news" />
            <token id="11" string="conference" />
            <token id="12" string="after" />
            <token id="13" string="acquitting" />
            <token id="14" string="Raymond" />
            <token id="15" string="Buckey" />
            <token id="16" string="and" />
            <token id="17" string="his" />
            <token id="18" string="mother" />
            <token id="19" string="," />
            <token id="20" string="Peggy" />
            <token id="21" string="McMartin" />
            <token id="22" string="Buckey" />
            <token id="23" string="," />
            <token id="24" string="on" />
            <token id="25" string="52" />
            <token id="26" string="molestation" />
            <token id="27" string="charges" />
            <token id="28" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="2" string="Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="20" string="Peggy" />
            <token id="21" string="McMartin" />
            <token id="22" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="3" string="have been molested _ but not at the family-run McMartin Pre-School" type="VP">
          <tokens>
            <token id="37" string="have" />
            <token id="38" string="been" />
            <token id="39" string="molested" />
            <token id="40" string="_" />
            <token id="41" string="but" />
            <token id="42" string="not" />
            <token id="43" string="at" />
            <token id="44" string="the" />
            <token id="45" string="family-run" />
            <token id="46" string="McMartin" />
            <token id="47" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="4" string="felt some children who testified may have been molested _ but not at the family-run McMartin Pre-School" type="VP">
          <tokens>
            <token id="31" string="felt" />
            <token id="32" string="some" />
            <token id="33" string="children" />
            <token id="34" string="who" />
            <token id="35" string="testified" />
            <token id="36" string="may" />
            <token id="37" string="have" />
            <token id="38" string="been" />
            <token id="39" string="molested" />
            <token id="40" string="_" />
            <token id="41" string="but" />
            <token id="42" string="not" />
            <token id="43" string="at" />
            <token id="44" string="the" />
            <token id="45" string="family-run" />
            <token id="46" string="McMartin" />
            <token id="47" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="5" string="said they felt some children who testified may have been molested _ but not at the family-run McMartin Pre-School" type="VP">
          <tokens>
            <token id="29" string="said" />
            <token id="30" string="they" />
            <token id="31" string="felt" />
            <token id="32" string="some" />
            <token id="33" string="children" />
            <token id="34" string="who" />
            <token id="35" string="testified" />
            <token id="36" string="may" />
            <token id="37" string="have" />
            <token id="38" string="been" />
            <token id="39" string="molested" />
            <token id="40" string="_" />
            <token id="41" string="but" />
            <token id="42" string="not" />
            <token id="43" string="at" />
            <token id="44" string="the" />
            <token id="45" string="family-run" />
            <token id="46" string="McMartin" />
            <token id="47" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="6" string="Seven jurors" type="NP">
          <tokens>
            <token id="1" string="Seven" />
            <token id="2" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="7" string="they felt some children who testified may have been molested _ but not at the family-run McMartin Pre-School" type="SBAR">
          <tokens>
            <token id="30" string="they" />
            <token id="31" string="felt" />
            <token id="32" string="some" />
            <token id="33" string="children" />
            <token id="34" string="who" />
            <token id="35" string="testified" />
            <token id="36" string="may" />
            <token id="37" string="have" />
            <token id="38" string="been" />
            <token id="39" string="molested" />
            <token id="40" string="_" />
            <token id="41" string="but" />
            <token id="42" string="not" />
            <token id="43" string="at" />
            <token id="44" string="the" />
            <token id="45" string="family-run" />
            <token id="46" string="McMartin" />
            <token id="47" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="8" string="his mother , Peggy McMartin Buckey ," type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="mother" />
            <token id="19" string="," />
            <token id="20" string="Peggy" />
            <token id="21" string="McMartin" />
            <token id="22" string="Buckey" />
            <token id="23" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="his mother" type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="mother" />
          </tokens>
        </chunking>
        <chunking id="10" string="been molested _ but not at the family-run McMartin Pre-School" type="VP">
          <tokens>
            <token id="38" string="been" />
            <token id="39" string="molested" />
            <token id="40" string="_" />
            <token id="41" string="but" />
            <token id="42" string="not" />
            <token id="43" string="at" />
            <token id="44" string="the" />
            <token id="45" string="family-run" />
            <token id="46" string="McMartin" />
            <token id="47" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="11" string="may have been molested _ but not at the family-run McMartin Pre-School" type="VP">
          <tokens>
            <token id="36" string="may" />
            <token id="37" string="have" />
            <token id="38" string="been" />
            <token id="39" string="molested" />
            <token id="40" string="_" />
            <token id="41" string="but" />
            <token id="42" string="not" />
            <token id="43" string="at" />
            <token id="44" string="the" />
            <token id="45" string="family-run" />
            <token id="46" string="McMartin" />
            <token id="47" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="12" string="reporters" type="NP">
          <tokens>
            <token id="6" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="13" string="Seven jurors who spoke with reporters in a joint news conference after acquitting Raymond Buckey and his mother , Peggy McMartin Buckey , on 52 molestation charges Thursday" type="NP">
          <tokens>
            <token id="1" string="Seven" />
            <token id="2" string="jurors" />
            <token id="3" string="who" />
            <token id="4" string="spoke" />
            <token id="5" string="with" />
            <token id="6" string="reporters" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="joint" />
            <token id="10" string="news" />
            <token id="11" string="conference" />
            <token id="12" string="after" />
            <token id="13" string="acquitting" />
            <token id="14" string="Raymond" />
            <token id="15" string="Buckey" />
            <token id="16" string="and" />
            <token id="17" string="his" />
            <token id="18" string="mother" />
            <token id="19" string="," />
            <token id="20" string="Peggy" />
            <token id="21" string="McMartin" />
            <token id="22" string="Buckey" />
            <token id="23" string="," />
            <token id="24" string="on" />
            <token id="25" string="52" />
            <token id="26" string="molestation" />
            <token id="27" string="charges" />
            <token id="28" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="14" string="reporters in a joint news conference" type="NP">
          <tokens>
            <token id="6" string="reporters" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="joint" />
            <token id="10" string="news" />
            <token id="11" string="conference" />
          </tokens>
        </chunking>
        <chunking id="15" string="molested _ but not at the family-run McMartin Pre-School" type="VP">
          <tokens>
            <token id="39" string="molested" />
            <token id="40" string="_" />
            <token id="41" string="but" />
            <token id="42" string="not" />
            <token id="43" string="at" />
            <token id="44" string="the" />
            <token id="45" string="family-run" />
            <token id="46" string="McMartin" />
            <token id="47" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="16" string="the family-run McMartin Pre-School" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="family-run" />
            <token id="46" string="McMartin" />
            <token id="47" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="17" string="who testified" type="SBAR">
          <tokens>
            <token id="34" string="who" />
            <token id="35" string="testified" />
          </tokens>
        </chunking>
        <chunking id="18" string="his mother , Peggy McMartin Buckey , on 52 molestation charges" type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="mother" />
            <token id="19" string="," />
            <token id="20" string="Peggy" />
            <token id="21" string="McMartin" />
            <token id="22" string="Buckey" />
            <token id="23" string="," />
            <token id="24" string="on" />
            <token id="25" string="52" />
            <token id="26" string="molestation" />
            <token id="27" string="charges" />
          </tokens>
        </chunking>
        <chunking id="19" string="some children who testified" type="NP">
          <tokens>
            <token id="32" string="some" />
            <token id="33" string="children" />
            <token id="34" string="who" />
            <token id="35" string="testified" />
          </tokens>
        </chunking>
        <chunking id="20" string="a joint news conference" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="joint" />
            <token id="10" string="news" />
            <token id="11" string="conference" />
          </tokens>
        </chunking>
        <chunking id="21" string="acquitting Raymond Buckey and his mother , Peggy McMartin Buckey , on 52 molestation charges Thursday" type="VP">
          <tokens>
            <token id="13" string="acquitting" />
            <token id="14" string="Raymond" />
            <token id="15" string="Buckey" />
            <token id="16" string="and" />
            <token id="17" string="his" />
            <token id="18" string="mother" />
            <token id="19" string="," />
            <token id="20" string="Peggy" />
            <token id="21" string="McMartin" />
            <token id="22" string="Buckey" />
            <token id="23" string="," />
            <token id="24" string="on" />
            <token id="25" string="52" />
            <token id="26" string="molestation" />
            <token id="27" string="charges" />
            <token id="28" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="22" string="Raymond Buckey" type="NP">
          <tokens>
            <token id="14" string="Raymond" />
            <token id="15" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="23" string="they" type="NP">
          <tokens>
            <token id="30" string="they" />
          </tokens>
        </chunking>
        <chunking id="24" string="some children who testified may have been molested _ but not at the family-run McMartin Pre-School" type="SBAR">
          <tokens>
            <token id="32" string="some" />
            <token id="33" string="children" />
            <token id="34" string="who" />
            <token id="35" string="testified" />
            <token id="36" string="may" />
            <token id="37" string="have" />
            <token id="38" string="been" />
            <token id="39" string="molested" />
            <token id="40" string="_" />
            <token id="41" string="but" />
            <token id="42" string="not" />
            <token id="43" string="at" />
            <token id="44" string="the" />
            <token id="45" string="family-run" />
            <token id="46" string="McMartin" />
            <token id="47" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="25" string="Raymond Buckey and his mother , Peggy McMartin Buckey , on 52 molestation charges" type="NP">
          <tokens>
            <token id="14" string="Raymond" />
            <token id="15" string="Buckey" />
            <token id="16" string="and" />
            <token id="17" string="his" />
            <token id="18" string="mother" />
            <token id="19" string="," />
            <token id="20" string="Peggy" />
            <token id="21" string="McMartin" />
            <token id="22" string="Buckey" />
            <token id="23" string="," />
            <token id="24" string="on" />
            <token id="25" string="52" />
            <token id="26" string="molestation" />
            <token id="27" string="charges" />
          </tokens>
        </chunking>
        <chunking id="26" string="52 molestation charges" type="NP">
          <tokens>
            <token id="25" string="52" />
            <token id="26" string="molestation" />
            <token id="27" string="charges" />
          </tokens>
        </chunking>
        <chunking id="27" string="testified" type="VP">
          <tokens>
            <token id="35" string="testified" />
          </tokens>
        </chunking>
        <chunking id="28" string="who spoke with reporters in a joint news conference after acquitting Raymond Buckey and his mother , Peggy McMartin Buckey , on 52 molestation charges Thursday" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="spoke" />
            <token id="5" string="with" />
            <token id="6" string="reporters" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="joint" />
            <token id="10" string="news" />
            <token id="11" string="conference" />
            <token id="12" string="after" />
            <token id="13" string="acquitting" />
            <token id="14" string="Raymond" />
            <token id="15" string="Buckey" />
            <token id="16" string="and" />
            <token id="17" string="his" />
            <token id="18" string="mother" />
            <token id="19" string="," />
            <token id="20" string="Peggy" />
            <token id="21" string="McMartin" />
            <token id="22" string="Buckey" />
            <token id="23" string="," />
            <token id="24" string="on" />
            <token id="25" string="52" />
            <token id="26" string="molestation" />
            <token id="27" string="charges" />
            <token id="28" string="Thursday" />
          </tokens>
        </chunking>
        <chunking id="29" string="some children" type="NP">
          <tokens>
            <token id="32" string="some" />
            <token id="33" string="children" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">jurors</governor>
          <dependent id="1">Seven</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="2">jurors</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">spoke</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">jurors</governor>
          <dependent id="4">spoke</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">reporters</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">spoke</governor>
          <dependent id="6">reporters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">conference</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">conference</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">conference</governor>
          <dependent id="9">joint</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">conference</governor>
          <dependent id="10">news</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">reporters</governor>
          <dependent id="11">conference</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">acquitting</governor>
          <dependent id="12">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">spoke</governor>
          <dependent id="13">acquitting</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Buckey</governor>
          <dependent id="14">Raymond</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">acquitting</governor>
          <dependent id="15">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">Buckey</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">mother</governor>
          <dependent id="17">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">Buckey</governor>
          <dependent id="18">mother</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Buckey</governor>
          <dependent id="20">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Buckey</governor>
          <dependent id="21">McMartin</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">mother</governor>
          <dependent id="22">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">charges</governor>
          <dependent id="24">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">charges</governor>
          <dependent id="25">52</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">charges</governor>
          <dependent id="26">molestation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">mother</governor>
          <dependent id="27">charges</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">acquitting</governor>
          <dependent id="28">Thursday</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">felt</governor>
          <dependent id="30">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="31">felt</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">children</governor>
          <dependent id="32">some</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="39">molested</governor>
          <dependent id="33">children</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">testified</governor>
          <dependent id="34">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="33">children</governor>
          <dependent id="35">testified</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="39">molested</governor>
          <dependent id="36">may</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="39">molested</governor>
          <dependent id="37">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="39">molested</governor>
          <dependent id="38">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="31">felt</governor>
          <dependent id="39">molested</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="41">but</governor>
          <dependent id="40">_</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="39">molested</governor>
          <dependent id="41">but</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="47">Pre-School</governor>
          <dependent id="42">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">Pre-School</governor>
          <dependent id="43">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">Pre-School</governor>
          <dependent id="44">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="47">Pre-School</governor>
          <dependent id="45">family-run</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">Pre-School</governor>
          <dependent id="46">McMartin</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="41">but</governor>
          <dependent id="47">Pre-School</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Peggy" />
            <token id="21" string="McMartin" />
            <token id="22" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="28" string="Thursday" />
          </tokens>
        </entity>
        <entity id="3" string="McMartin Pre-School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="46" string="McMartin" />
            <token id="47" string="Pre-School" />
          </tokens>
        </entity>
        <entity id="4" string="52" type="NUMBER" score="0.0">
          <tokens>
            <token id="25" string="52" />
          </tokens>
        </entity>
        <entity id="5" string="Seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Seven" />
          </tokens>
        </entity>
        <entity id="6" string="Raymond Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Raymond" />
            <token id="15" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>And they said some children may have merely repeated stories told them by their parents and interviewers at Children&amp;apost;s Institute International.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="merely" lemma="merely" stem="mere" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="repeated" lemma="repeat" stem="repeat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="stories" lemma="story" stem="stori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="interviewers" lemma="interviewer" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Children" lemma="Children" stem="children" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="21" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="International" lemma="International" stem="internat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (PRP they)) (VP (VBD said) (SBAR (S (NP (DT some) (NNS children)) (VP (MD may) (VP (VB have) (ADVP (RB merely)) (VP (VBN repeated) (SBAR (S (NP (NNS stories)) (VP (VBD told) (NP (PRP them)) (PP (IN by) (NP (PRP$ their) (NNS parents) (CC and) (NNS interviewers))) (PP (IN at) (NP (NP (NNP Children) (POS 's)) (NNP Institute) (NNP International)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="told them by their parents and interviewers at Children 's Institute International" type="VP">
          <tokens>
            <token id="11" string="told" />
            <token id="12" string="them" />
            <token id="13" string="by" />
            <token id="14" string="their" />
            <token id="15" string="parents" />
            <token id="16" string="and" />
            <token id="17" string="interviewers" />
            <token id="18" string="at" />
            <token id="19" string="Children" />
            <token id="20" string="'s" />
            <token id="21" string="Institute" />
            <token id="22" string="International" />
          </tokens>
        </chunking>
        <chunking id="2" string="some children may have merely repeated stories told them by their parents and interviewers at Children 's Institute International" type="SBAR">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="children" />
            <token id="6" string="may" />
            <token id="7" string="have" />
            <token id="8" string="merely" />
            <token id="9" string="repeated" />
            <token id="10" string="stories" />
            <token id="11" string="told" />
            <token id="12" string="them" />
            <token id="13" string="by" />
            <token id="14" string="their" />
            <token id="15" string="parents" />
            <token id="16" string="and" />
            <token id="17" string="interviewers" />
            <token id="18" string="at" />
            <token id="19" string="Children" />
            <token id="20" string="'s" />
            <token id="21" string="Institute" />
            <token id="22" string="International" />
          </tokens>
        </chunking>
        <chunking id="3" string="stories" type="NP">
          <tokens>
            <token id="10" string="stories" />
          </tokens>
        </chunking>
        <chunking id="4" string="their parents and interviewers" type="NP">
          <tokens>
            <token id="14" string="their" />
            <token id="15" string="parents" />
            <token id="16" string="and" />
            <token id="17" string="interviewers" />
          </tokens>
        </chunking>
        <chunking id="5" string="may have merely repeated stories told them by their parents and interviewers at Children 's Institute International" type="VP">
          <tokens>
            <token id="6" string="may" />
            <token id="7" string="have" />
            <token id="8" string="merely" />
            <token id="9" string="repeated" />
            <token id="10" string="stories" />
            <token id="11" string="told" />
            <token id="12" string="them" />
            <token id="13" string="by" />
            <token id="14" string="their" />
            <token id="15" string="parents" />
            <token id="16" string="and" />
            <token id="17" string="interviewers" />
            <token id="18" string="at" />
            <token id="19" string="Children" />
            <token id="20" string="'s" />
            <token id="21" string="Institute" />
            <token id="22" string="International" />
          </tokens>
        </chunking>
        <chunking id="6" string="have merely repeated stories told them by their parents and interviewers at Children 's Institute International" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="merely" />
            <token id="9" string="repeated" />
            <token id="10" string="stories" />
            <token id="11" string="told" />
            <token id="12" string="them" />
            <token id="13" string="by" />
            <token id="14" string="their" />
            <token id="15" string="parents" />
            <token id="16" string="and" />
            <token id="17" string="interviewers" />
            <token id="18" string="at" />
            <token id="19" string="Children" />
            <token id="20" string="'s" />
            <token id="21" string="Institute" />
            <token id="22" string="International" />
          </tokens>
        </chunking>
        <chunking id="7" string="stories told them by their parents and interviewers at Children 's Institute International" type="SBAR">
          <tokens>
            <token id="10" string="stories" />
            <token id="11" string="told" />
            <token id="12" string="them" />
            <token id="13" string="by" />
            <token id="14" string="their" />
            <token id="15" string="parents" />
            <token id="16" string="and" />
            <token id="17" string="interviewers" />
            <token id="18" string="at" />
            <token id="19" string="Children" />
            <token id="20" string="'s" />
            <token id="21" string="Institute" />
            <token id="22" string="International" />
          </tokens>
        </chunking>
        <chunking id="8" string="them" type="NP">
          <tokens>
            <token id="12" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="Children 's Institute International" type="NP">
          <tokens>
            <token id="19" string="Children" />
            <token id="20" string="'s" />
            <token id="21" string="Institute" />
            <token id="22" string="International" />
          </tokens>
        </chunking>
        <chunking id="11" string="Children 's" type="NP">
          <tokens>
            <token id="19" string="Children" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="repeated stories told them by their parents and interviewers at Children 's Institute International" type="VP">
          <tokens>
            <token id="9" string="repeated" />
            <token id="10" string="stories" />
            <token id="11" string="told" />
            <token id="12" string="them" />
            <token id="13" string="by" />
            <token id="14" string="their" />
            <token id="15" string="parents" />
            <token id="16" string="and" />
            <token id="17" string="interviewers" />
            <token id="18" string="at" />
            <token id="19" string="Children" />
            <token id="20" string="'s" />
            <token id="21" string="Institute" />
            <token id="22" string="International" />
          </tokens>
        </chunking>
        <chunking id="13" string="said some children may have merely repeated stories told them by their parents and interviewers at Children 's Institute International" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="some" />
            <token id="5" string="children" />
            <token id="6" string="may" />
            <token id="7" string="have" />
            <token id="8" string="merely" />
            <token id="9" string="repeated" />
            <token id="10" string="stories" />
            <token id="11" string="told" />
            <token id="12" string="them" />
            <token id="13" string="by" />
            <token id="14" string="their" />
            <token id="15" string="parents" />
            <token id="16" string="and" />
            <token id="17" string="interviewers" />
            <token id="18" string="at" />
            <token id="19" string="Children" />
            <token id="20" string="'s" />
            <token id="21" string="Institute" />
            <token id="22" string="International" />
          </tokens>
        </chunking>
        <chunking id="14" string="some children" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="children" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">said</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">children</governor>
          <dependent id="4">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">repeated</governor>
          <dependent id="5">children</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">repeated</governor>
          <dependent id="6">may</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">repeated</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">repeated</governor>
          <dependent id="8">merely</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="9">repeated</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">told</governor>
          <dependent id="10">stories</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">repeated</governor>
          <dependent id="11">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">told</governor>
          <dependent id="12">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">parents</governor>
          <dependent id="13">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">parents</governor>
          <dependent id="14">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">told</governor>
          <dependent id="15">parents</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">parents</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">parents</governor>
          <dependent id="17">interviewers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">International</governor>
          <dependent id="18">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">International</governor>
          <dependent id="19">Children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Children</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">International</governor>
          <dependent id="21">Institute</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">told</governor>
          <dependent id="22">International</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Children 's Institute International" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Children" />
            <token id="20" string="'s" />
            <token id="21" string="Institute" />
            <token id="22" string="International" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>The private child therapy center, which specializes in abused children, videotaped interviews with children from the McMartin school after reports of molestations surfaced.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="therapy" lemma="therapy" stem="therapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="specializes" lemma="specialize" stem="special" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="abused" lemma="abused" stem="abus" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="videotaped" lemma="videotaped" stem="videotap" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="reports" lemma="report" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="molestations" lemma="molestation" stem="molest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="surfaced" lemma="surface" stem="surfac" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ private) (NN child) (NN therapy) (NN center)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ specializes) (PP (IN in) (S (VP (JJ abused) (NP (NP (NNS children)) (, ,) (NP (NP (JJ videotaped) (NNS interviews)) (PP (IN with) (NP (NNS children))))) (PP (IN from) (NP (DT the) (NNP McMartin) (NN school)))))) (PP (IN after) (NP (NP (NNS reports)) (PP (IN of) (NP (NNS molestations))))))))) (VP (VBD surfaced)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reports" type="NP">
          <tokens>
            <token id="22" string="reports" />
          </tokens>
        </chunking>
        <chunking id="2" string="which specializes in abused children , videotaped interviews with children from the McMartin school after reports of molestations" type="SBAR">
          <tokens>
            <token id="7" string="which" />
            <token id="8" string="specializes" />
            <token id="9" string="in" />
            <token id="10" string="abused" />
            <token id="11" string="children" />
            <token id="12" string="," />
            <token id="13" string="videotaped" />
            <token id="14" string="interviews" />
            <token id="15" string="with" />
            <token id="16" string="children" />
            <token id="17" string="from" />
            <token id="18" string="the" />
            <token id="19" string="McMartin" />
            <token id="20" string="school" />
            <token id="21" string="after" />
            <token id="22" string="reports" />
            <token id="23" string="of" />
            <token id="24" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="3" string="molestations" type="NP">
          <tokens>
            <token id="24" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="4" string="surfaced" type="VP">
          <tokens>
            <token id="25" string="surfaced" />
          </tokens>
        </chunking>
        <chunking id="5" string="The private child therapy center" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="private" />
            <token id="3" string="child" />
            <token id="4" string="therapy" />
            <token id="5" string="center" />
          </tokens>
        </chunking>
        <chunking id="6" string="videotaped interviews with children" type="NP">
          <tokens>
            <token id="13" string="videotaped" />
            <token id="14" string="interviews" />
            <token id="15" string="with" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="reports of molestations" type="NP">
          <tokens>
            <token id="22" string="reports" />
            <token id="23" string="of" />
            <token id="24" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="8" string="The private child therapy center , which specializes in abused children , videotaped interviews with children from the McMartin school after reports of molestations" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="private" />
            <token id="3" string="child" />
            <token id="4" string="therapy" />
            <token id="5" string="center" />
            <token id="6" string="," />
            <token id="7" string="which" />
            <token id="8" string="specializes" />
            <token id="9" string="in" />
            <token id="10" string="abused" />
            <token id="11" string="children" />
            <token id="12" string="," />
            <token id="13" string="videotaped" />
            <token id="14" string="interviews" />
            <token id="15" string="with" />
            <token id="16" string="children" />
            <token id="17" string="from" />
            <token id="18" string="the" />
            <token id="19" string="McMartin" />
            <token id="20" string="school" />
            <token id="21" string="after" />
            <token id="22" string="reports" />
            <token id="23" string="of" />
            <token id="24" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="9" string="children" type="NP">
          <tokens>
            <token id="11" string="children" />
          </tokens>
        </chunking>
        <chunking id="10" string="specializes in abused children , videotaped interviews with children from the McMartin school after reports of molestations" type="VP">
          <tokens>
            <token id="8" string="specializes" />
            <token id="9" string="in" />
            <token id="10" string="abused" />
            <token id="11" string="children" />
            <token id="12" string="," />
            <token id="13" string="videotaped" />
            <token id="14" string="interviews" />
            <token id="15" string="with" />
            <token id="16" string="children" />
            <token id="17" string="from" />
            <token id="18" string="the" />
            <token id="19" string="McMartin" />
            <token id="20" string="school" />
            <token id="21" string="after" />
            <token id="22" string="reports" />
            <token id="23" string="of" />
            <token id="24" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="11" string="children , videotaped interviews with children" type="NP">
          <tokens>
            <token id="11" string="children" />
            <token id="12" string="," />
            <token id="13" string="videotaped" />
            <token id="14" string="interviews" />
            <token id="15" string="with" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="abused children , videotaped interviews with children from the McMartin school" type="VP">
          <tokens>
            <token id="10" string="abused" />
            <token id="11" string="children" />
            <token id="12" string="," />
            <token id="13" string="videotaped" />
            <token id="14" string="interviews" />
            <token id="15" string="with" />
            <token id="16" string="children" />
            <token id="17" string="from" />
            <token id="18" string="the" />
            <token id="19" string="McMartin" />
            <token id="20" string="school" />
          </tokens>
        </chunking>
        <chunking id="13" string="videotaped interviews" type="NP">
          <tokens>
            <token id="13" string="videotaped" />
            <token id="14" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="14" string="the McMartin school" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="McMartin" />
            <token id="20" string="school" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">center</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">center</governor>
          <dependent id="2">private</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">center</governor>
          <dependent id="3">child</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">center</governor>
          <dependent id="4">therapy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">surfaced</governor>
          <dependent id="5">center</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">specializes</governor>
          <dependent id="7">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">center</governor>
          <dependent id="8">specializes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">abused</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">specializes</governor>
          <dependent id="10">abused</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">abused</governor>
          <dependent id="11">children</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">interviews</governor>
          <dependent id="13">videotaped</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">children</governor>
          <dependent id="14">interviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">children</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">interviews</governor>
          <dependent id="16">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">school</governor>
          <dependent id="17">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">school</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">school</governor>
          <dependent id="19">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">abused</governor>
          <dependent id="20">school</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">reports</governor>
          <dependent id="21">after</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">specializes</governor>
          <dependent id="22">reports</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">molestations</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">reports</governor>
          <dependent id="24">molestations</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">surfaced</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Jurors saw the tapes in which interviewers used anatomically explicit puppets and leading questions to elicit descriptions of molestation from children.</content>
      <tokens>
        <token id="1" string="Jurors" lemma="Jurors" stem="juror" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="saw" lemma="see" stem="saw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="tapes" lemma="tape" stem="tape" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="interviewers" lemma="interviewer" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="anatomically" lemma="anatomically" stem="anatom" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="explicit" lemma="explicit" stem="explicit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="puppets" lemma="puppet" stem="puppet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="leading" lemma="lead" stem="lead" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="elicit" lemma="elicit" stem="elicit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="descriptions" lemma="description" stem="descript" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Jurors)) (VP (VBD saw) (NP (NP (DT the) (NNS tapes)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NNS interviewers)) (VP (VBN used) (ADVP (RB anatomically)) (NP (NP (JJ explicit) (NNS puppets)) (CC and) (NP (VBG leading) (NNS questions))))))) (S (VP (TO to) (VP (VB elicit) (NP (NP (NNS descriptions)) (PP (IN of) (NP (NN molestation)))) (PP (IN from) (NP (NNS children))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="molestation" type="NP">
          <tokens>
            <token id="19" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="2" string="to elicit descriptions of molestation from children" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="elicit" />
            <token id="17" string="descriptions" />
            <token id="18" string="of" />
            <token id="19" string="molestation" />
            <token id="20" string="from" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="Jurors" type="NP">
          <tokens>
            <token id="1" string="Jurors" />
          </tokens>
        </chunking>
        <chunking id="4" string="interviewers" type="NP">
          <tokens>
            <token id="7" string="interviewers" />
          </tokens>
        </chunking>
        <chunking id="5" string="elicit descriptions of molestation from children" type="VP">
          <tokens>
            <token id="16" string="elicit" />
            <token id="17" string="descriptions" />
            <token id="18" string="of" />
            <token id="19" string="molestation" />
            <token id="20" string="from" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="descriptions" type="NP">
          <tokens>
            <token id="17" string="descriptions" />
          </tokens>
        </chunking>
        <chunking id="7" string="saw the tapes in which interviewers used anatomically explicit puppets and leading questions to elicit descriptions of molestation from children" type="VP">
          <tokens>
            <token id="2" string="saw" />
            <token id="3" string="the" />
            <token id="4" string="tapes" />
            <token id="5" string="in" />
            <token id="6" string="which" />
            <token id="7" string="interviewers" />
            <token id="8" string="used" />
            <token id="9" string="anatomically" />
            <token id="10" string="explicit" />
            <token id="11" string="puppets" />
            <token id="12" string="and" />
            <token id="13" string="leading" />
            <token id="14" string="questions" />
            <token id="15" string="to" />
            <token id="16" string="elicit" />
            <token id="17" string="descriptions" />
            <token id="18" string="of" />
            <token id="19" string="molestation" />
            <token id="20" string="from" />
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="the tapes in which interviewers used anatomically explicit puppets and leading questions" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="tapes" />
            <token id="5" string="in" />
            <token id="6" string="which" />
            <token id="7" string="interviewers" />
            <token id="8" string="used" />
            <token id="9" string="anatomically" />
            <token id="10" string="explicit" />
            <token id="11" string="puppets" />
            <token id="12" string="and" />
            <token id="13" string="leading" />
            <token id="14" string="questions" />
          </tokens>
        </chunking>
        <chunking id="9" string="leading questions" type="NP">
          <tokens>
            <token id="13" string="leading" />
            <token id="14" string="questions" />
          </tokens>
        </chunking>
        <chunking id="10" string="children" type="NP">
          <tokens>
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="11" string="in which interviewers used anatomically explicit puppets and leading questions" type="SBAR">
          <tokens>
            <token id="5" string="in" />
            <token id="6" string="which" />
            <token id="7" string="interviewers" />
            <token id="8" string="used" />
            <token id="9" string="anatomically" />
            <token id="10" string="explicit" />
            <token id="11" string="puppets" />
            <token id="12" string="and" />
            <token id="13" string="leading" />
            <token id="14" string="questions" />
          </tokens>
        </chunking>
        <chunking id="12" string="explicit puppets" type="NP">
          <tokens>
            <token id="10" string="explicit" />
            <token id="11" string="puppets" />
          </tokens>
        </chunking>
        <chunking id="13" string="explicit puppets and leading questions" type="NP">
          <tokens>
            <token id="10" string="explicit" />
            <token id="11" string="puppets" />
            <token id="12" string="and" />
            <token id="13" string="leading" />
            <token id="14" string="questions" />
          </tokens>
        </chunking>
        <chunking id="14" string="the tapes" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="15" string="used anatomically explicit puppets and leading questions" type="VP">
          <tokens>
            <token id="8" string="used" />
            <token id="9" string="anatomically" />
            <token id="10" string="explicit" />
            <token id="11" string="puppets" />
            <token id="12" string="and" />
            <token id="13" string="leading" />
            <token id="14" string="questions" />
          </tokens>
        </chunking>
        <chunking id="16" string="descriptions of molestation" type="NP">
          <tokens>
            <token id="17" string="descriptions" />
            <token id="18" string="of" />
            <token id="19" string="molestation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">saw</governor>
          <dependent id="1">Jurors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">saw</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">tapes</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">saw</governor>
          <dependent id="4">tapes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">which</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">used</governor>
          <dependent id="6">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">used</governor>
          <dependent id="7">interviewers</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">tapes</governor>
          <dependent id="8">used</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">used</governor>
          <dependent id="9">anatomically</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">puppets</governor>
          <dependent id="10">explicit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">used</governor>
          <dependent id="11">puppets</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">puppets</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">questions</governor>
          <dependent id="13">leading</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">puppets</governor>
          <dependent id="14">questions</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">elicit</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">saw</governor>
          <dependent id="16">elicit</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">elicit</governor>
          <dependent id="17">descriptions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">molestation</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">descriptions</governor>
          <dependent id="19">molestation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">children</governor>
          <dependent id="20">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">elicit</governor>
          <dependent id="21">children</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Asked what led to acquittals, juror Brenda Williams focused on the taped interviews from the center jurors call CII.</content>
      <tokens>
        <token id="1" string="Asked" lemma="ask" stem="asked" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="what" lemma="what" stem="what" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="acquittals" lemma="acquittal" stem="acquitt" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="Brenda" lemma="Brenda" stem="brenda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="focused" lemma="focus" stem="focus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="taped" lemma="tape" stem="tape" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="center" lemma="center" stem="center" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="call" lemma="call" stem="call" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="CII" lemma="CII" stem="cii" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Asked) (SBAR (WHNP (WDT what)) (S (VP (VBD led) (PP (TO to) (NP (NNS acquittals)))))))) (, ,) (NP (NN juror) (NNP Brenda) (NNP Williams)) (VP (VBD focused) (PP (IN on) (NP (NP (DT the) (VBN taped) (NNS interviews)) (PP (IN from) (NP (NP (DT the) (NN center)) (SBAR (S (NP (NNS jurors)) (VP (VBP call) (NP (NNP CII)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="jurors call CII" type="SBAR">
          <tokens>
            <token id="18" string="jurors" />
            <token id="19" string="call" />
            <token id="20" string="CII" />
          </tokens>
        </chunking>
        <chunking id="2" string="focused on the taped interviews from the center jurors call CII" type="VP">
          <tokens>
            <token id="10" string="focused" />
            <token id="11" string="on" />
            <token id="12" string="the" />
            <token id="13" string="taped" />
            <token id="14" string="interviews" />
            <token id="15" string="from" />
            <token id="16" string="the" />
            <token id="17" string="center" />
            <token id="18" string="jurors" />
            <token id="19" string="call" />
            <token id="20" string="CII" />
          </tokens>
        </chunking>
        <chunking id="3" string="CII" type="NP">
          <tokens>
            <token id="20" string="CII" />
          </tokens>
        </chunking>
        <chunking id="4" string="the center jurors call CII" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="center" />
            <token id="18" string="jurors" />
            <token id="19" string="call" />
            <token id="20" string="CII" />
          </tokens>
        </chunking>
        <chunking id="5" string="the center" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="center" />
          </tokens>
        </chunking>
        <chunking id="6" string="what led to acquittals" type="SBAR">
          <tokens>
            <token id="2" string="what" />
            <token id="3" string="led" />
            <token id="4" string="to" />
            <token id="5" string="acquittals" />
          </tokens>
        </chunking>
        <chunking id="7" string="juror Brenda Williams" type="NP">
          <tokens>
            <token id="7" string="juror" />
            <token id="8" string="Brenda" />
            <token id="9" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="8" string="acquittals" type="NP">
          <tokens>
            <token id="5" string="acquittals" />
          </tokens>
        </chunking>
        <chunking id="9" string="jurors" type="NP">
          <tokens>
            <token id="18" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="10" string="Asked what led to acquittals" type="VP">
          <tokens>
            <token id="1" string="Asked" />
            <token id="2" string="what" />
            <token id="3" string="led" />
            <token id="4" string="to" />
            <token id="5" string="acquittals" />
          </tokens>
        </chunking>
        <chunking id="11" string="the taped interviews from the center jurors call CII" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="taped" />
            <token id="14" string="interviews" />
            <token id="15" string="from" />
            <token id="16" string="the" />
            <token id="17" string="center" />
            <token id="18" string="jurors" />
            <token id="19" string="call" />
            <token id="20" string="CII" />
          </tokens>
        </chunking>
        <chunking id="12" string="the taped interviews" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="taped" />
            <token id="14" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="13" string="led to acquittals" type="VP">
          <tokens>
            <token id="3" string="led" />
            <token id="4" string="to" />
            <token id="5" string="acquittals" />
          </tokens>
        </chunking>
        <chunking id="14" string="call CII" type="VP">
          <tokens>
            <token id="19" string="call" />
            <token id="20" string="CII" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="10">focused</governor>
          <dependent id="1">Asked</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">led</governor>
          <dependent id="2">what</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">Asked</governor>
          <dependent id="3">led</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">acquittals</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">led</governor>
          <dependent id="5">acquittals</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Williams</governor>
          <dependent id="7">juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Williams</governor>
          <dependent id="8">Brenda</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">focused</governor>
          <dependent id="9">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">focused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">interviews</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">interviews</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">interviews</governor>
          <dependent id="13">taped</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">focused</governor>
          <dependent id="14">interviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">center</governor>
          <dependent id="15">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">center</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">interviews</governor>
          <dependent id="17">center</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">call</governor>
          <dependent id="18">jurors</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">center</governor>
          <dependent id="19">call</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">call</governor>
          <dependent id="20">CII</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CII" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="CII" />
          </tokens>
        </entity>
        <entity id="2" string="Brenda Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Brenda" />
            <token id="9" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``The CII interviews _ I could not accept them,&amp;apost;&amp;apost; Mrs. Williams said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="CII" lemma="CII" stem="cii" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="4" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="accept" lemma="accept" stem="accept" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (NNP CII) (NNS interviews)) (VP (VBP _) (SBAR (S (NP (PRP I)) (VP (MD could) (RB not) (VP (VB accept) (NP (PRP them)))))))) (, ,) ('' '') (NP (NNP Mrs.) (NNP Williams)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="accept them" type="VP">
          <tokens>
            <token id="9" string="accept" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="The CII interviews" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="CII" />
            <token id="4" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="3" string="I could not accept them" type="SBAR">
          <tokens>
            <token id="6" string="I" />
            <token id="7" string="could" />
            <token id="8" string="not" />
            <token id="9" string="accept" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="_ I could not accept them" type="VP">
          <tokens>
            <token id="5" string="_" />
            <token id="6" string="I" />
            <token id="7" string="could" />
            <token id="8" string="not" />
            <token id="9" string="accept" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mrs. Williams" type="NP">
          <tokens>
            <token id="13" string="Mrs." />
            <token id="14" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="7" string="could not accept them" type="VP">
          <tokens>
            <token id="7" string="could" />
            <token id="8" string="not" />
            <token id="9" string="accept" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="them" type="NP">
          <tokens>
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">interviews</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">interviews</governor>
          <dependent id="3">CII</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">_</governor>
          <dependent id="4">interviews</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="5">_</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">accept</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">accept</governor>
          <dependent id="7">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">accept</governor>
          <dependent id="8">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">_</governor>
          <dependent id="9">accept</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">accept</governor>
          <dependent id="10">them</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Williams</governor>
          <dependent id="13">Mrs.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CII" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="CII" />
          </tokens>
        </entity>
        <entity id="2" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>``I believe the children believe what they were saying was true.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="believe" lemma="believe" stem="believ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP believe) (SBAR (S (NP (DT the) (NNS children)) (VP (VBP believe) (SBAR (WHNP (WP what)) (S (NP (PRP they)) (VP (VBD were) (VP (VBG saying) (VP (VBD was) (ADJP (JJ true))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="what they were saying was true" type="SBAR">
          <tokens>
            <token id="7" string="what" />
            <token id="8" string="they" />
            <token id="9" string="were" />
            <token id="10" string="saying" />
            <token id="11" string="was" />
            <token id="12" string="true" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="the children believe what they were saying was true" type="SBAR">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="children" />
            <token id="6" string="believe" />
            <token id="7" string="what" />
            <token id="8" string="they" />
            <token id="9" string="were" />
            <token id="10" string="saying" />
            <token id="11" string="was" />
            <token id="12" string="true" />
          </tokens>
        </chunking>
        <chunking id="4" string="were saying was true" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="saying" />
            <token id="11" string="was" />
            <token id="12" string="true" />
          </tokens>
        </chunking>
        <chunking id="5" string="the children" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="believe what they were saying was true" type="VP">
          <tokens>
            <token id="6" string="believe" />
            <token id="7" string="what" />
            <token id="8" string="they" />
            <token id="9" string="were" />
            <token id="10" string="saying" />
            <token id="11" string="was" />
            <token id="12" string="true" />
          </tokens>
        </chunking>
        <chunking id="8" string="believe the children believe what they were saying was true" type="VP">
          <tokens>
            <token id="3" string="believe" />
            <token id="4" string="the" />
            <token id="5" string="children" />
            <token id="6" string="believe" />
            <token id="7" string="what" />
            <token id="8" string="they" />
            <token id="9" string="were" />
            <token id="10" string="saying" />
            <token id="11" string="was" />
            <token id="12" string="true" />
          </tokens>
        </chunking>
        <chunking id="9" string="was true" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="true" />
          </tokens>
        </chunking>
        <chunking id="10" string="true" type="ADJP">
          <tokens>
            <token id="12" string="true" />
          </tokens>
        </chunking>
        <chunking id="11" string="saying was true" type="VP">
          <tokens>
            <token id="10" string="saying" />
            <token id="11" string="was" />
            <token id="12" string="true" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">believe</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">believe</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">children</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">believe</governor>
          <dependent id="5">children</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">believe</governor>
          <dependent id="6">believe</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">saying</governor>
          <dependent id="7">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">saying</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">saying</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">believe</governor>
          <dependent id="10">saying</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">true</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">saying</governor>
          <dependent id="12">true</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>But at CII, I could not tell if the children were saying what was told to them (by interviewers) or if they were repeating what their parents had told them.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="CII" lemma="CII" stem="cii" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="told" lemma="tell" stem="told" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="interviewers" lemma="interviewer" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="repeating" lemma="repeat" stem="repeat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="told" lemma="tell" stem="told" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN at) (NP (NNP CII))) (, ,) (NP (PRP I)) (VP (MD could) (RB not) (VP (VB tell) (SBAR (IN if) (S (NP (DT the) (NNS children)) (VP (VBD were) (VP (VBG saying) (SBAR (SBAR (WHNP (WP what)) (S (VP (VBD was) (VP (VBN told) (PP (TO to) (NP (PRP them))) (PRN (-LRB- -LRB-) (PP (IN by) (NP (NNS interviewers))) (-RRB- -RRB-)))))) (CC or) (SBAR (IN if) (S (NP (PRP they)) (VP (VBD were) (VP (VBG repeating) (SBAR (WHNP (WP what)) (S (NP (PRP$ their) (NNS parents)) (VP (VBD had) (VP (VBN told) (NP (PRP them))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could not tell if the children were saying what was told to them -LRB- by interviewers -RRB- or if they were repeating what their parents had told them" type="VP">
          <tokens>
            <token id="6" string="could" />
            <token id="7" string="not" />
            <token id="8" string="tell" />
            <token id="9" string="if" />
            <token id="10" string="the" />
            <token id="11" string="children" />
            <token id="12" string="were" />
            <token id="13" string="saying" />
            <token id="14" string="what" />
            <token id="15" string="was" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="them" />
            <token id="19" string="(" />
            <token id="20" string="by" />
            <token id="21" string="interviewers" />
            <token id="22" string=")" />
            <token id="23" string="or" />
            <token id="24" string="if" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="repeating" />
            <token id="28" string="what" />
            <token id="29" string="their" />
            <token id="30" string="parents" />
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="tell if the children were saying what was told to them -LRB- by interviewers -RRB- or if they were repeating what their parents had told them" type="VP">
          <tokens>
            <token id="8" string="tell" />
            <token id="9" string="if" />
            <token id="10" string="the" />
            <token id="11" string="children" />
            <token id="12" string="were" />
            <token id="13" string="saying" />
            <token id="14" string="what" />
            <token id="15" string="was" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="them" />
            <token id="19" string="(" />
            <token id="20" string="by" />
            <token id="21" string="interviewers" />
            <token id="22" string=")" />
            <token id="23" string="or" />
            <token id="24" string="if" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="repeating" />
            <token id="28" string="what" />
            <token id="29" string="their" />
            <token id="30" string="parents" />
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="had told them" type="VP">
          <tokens>
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="CII" type="NP">
          <tokens>
            <token id="3" string="CII" />
          </tokens>
        </chunking>
        <chunking id="5" string="if they were repeating what their parents had told them" type="SBAR">
          <tokens>
            <token id="24" string="if" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="repeating" />
            <token id="28" string="what" />
            <token id="29" string="their" />
            <token id="30" string="parents" />
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="if the children were saying what was told to them -LRB- by interviewers -RRB- or if they were repeating what their parents had told them" type="SBAR">
          <tokens>
            <token id="9" string="if" />
            <token id="10" string="the" />
            <token id="11" string="children" />
            <token id="12" string="were" />
            <token id="13" string="saying" />
            <token id="14" string="what" />
            <token id="15" string="was" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="them" />
            <token id="19" string="(" />
            <token id="20" string="by" />
            <token id="21" string="interviewers" />
            <token id="22" string=")" />
            <token id="23" string="or" />
            <token id="24" string="if" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="repeating" />
            <token id="28" string="what" />
            <token id="29" string="their" />
            <token id="30" string="parents" />
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="what was told to them -LRB- by interviewers -RRB-" type="SBAR">
          <tokens>
            <token id="14" string="what" />
            <token id="15" string="was" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="them" />
            <token id="19" string="(" />
            <token id="20" string="by" />
            <token id="21" string="interviewers" />
            <token id="22" string=")" />
          </tokens>
        </chunking>
        <chunking id="8" string="interviewers" type="NP">
          <tokens>
            <token id="21" string="interviewers" />
          </tokens>
        </chunking>
        <chunking id="9" string="were saying what was told to them -LRB- by interviewers -RRB- or if they were repeating what their parents had told them" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="saying" />
            <token id="14" string="what" />
            <token id="15" string="was" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="them" />
            <token id="19" string="(" />
            <token id="20" string="by" />
            <token id="21" string="interviewers" />
            <token id="22" string=")" />
            <token id="23" string="or" />
            <token id="24" string="if" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="repeating" />
            <token id="28" string="what" />
            <token id="29" string="their" />
            <token id="30" string="parents" />
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="I" type="NP">
          <tokens>
            <token id="5" string="I" />
          </tokens>
        </chunking>
        <chunking id="11" string="told them" type="VP">
          <tokens>
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="12" string="them" type="NP">
          <tokens>
            <token id="18" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="they" type="NP">
          <tokens>
            <token id="25" string="they" />
          </tokens>
        </chunking>
        <chunking id="14" string="what was told to them -LRB- by interviewers -RRB- or if they were repeating what their parents had told them" type="SBAR">
          <tokens>
            <token id="14" string="what" />
            <token id="15" string="was" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="them" />
            <token id="19" string="(" />
            <token id="20" string="by" />
            <token id="21" string="interviewers" />
            <token id="22" string=")" />
            <token id="23" string="or" />
            <token id="24" string="if" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="repeating" />
            <token id="28" string="what" />
            <token id="29" string="their" />
            <token id="30" string="parents" />
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="15" string="the children" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="children" />
          </tokens>
        </chunking>
        <chunking id="16" string="was told to them -LRB- by interviewers -RRB-" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="them" />
            <token id="19" string="(" />
            <token id="20" string="by" />
            <token id="21" string="interviewers" />
            <token id="22" string=")" />
          </tokens>
        </chunking>
        <chunking id="17" string="were repeating what their parents had told them" type="VP">
          <tokens>
            <token id="26" string="were" />
            <token id="27" string="repeating" />
            <token id="28" string="what" />
            <token id="29" string="their" />
            <token id="30" string="parents" />
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="18" string="what their parents had told them" type="SBAR">
          <tokens>
            <token id="28" string="what" />
            <token id="29" string="their" />
            <token id="30" string="parents" />
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="19" string="told to them -LRB- by interviewers -RRB-" type="VP">
          <tokens>
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="them" />
            <token id="19" string="(" />
            <token id="20" string="by" />
            <token id="21" string="interviewers" />
            <token id="22" string=")" />
          </tokens>
        </chunking>
        <chunking id="20" string="repeating what their parents had told them" type="VP">
          <tokens>
            <token id="27" string="repeating" />
            <token id="28" string="what" />
            <token id="29" string="their" />
            <token id="30" string="parents" />
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
        <chunking id="21" string="their parents" type="NP">
          <tokens>
            <token id="29" string="their" />
            <token id="30" string="parents" />
          </tokens>
        </chunking>
        <chunking id="22" string="saying what was told to them -LRB- by interviewers -RRB- or if they were repeating what their parents had told them" type="VP">
          <tokens>
            <token id="13" string="saying" />
            <token id="14" string="what" />
            <token id="15" string="was" />
            <token id="16" string="told" />
            <token id="17" string="to" />
            <token id="18" string="them" />
            <token id="19" string="(" />
            <token id="20" string="by" />
            <token id="21" string="interviewers" />
            <token id="22" string=")" />
            <token id="23" string="or" />
            <token id="24" string="if" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="repeating" />
            <token id="28" string="what" />
            <token id="29" string="their" />
            <token id="30" string="parents" />
            <token id="31" string="had" />
            <token id="32" string="told" />
            <token id="33" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">tell</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">CII</governor>
          <dependent id="2">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">tell</governor>
          <dependent id="3">CII</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">tell</governor>
          <dependent id="5">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">tell</governor>
          <dependent id="6">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">tell</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">tell</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">saying</governor>
          <dependent id="9">if</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">children</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">saying</governor>
          <dependent id="11">children</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">saying</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">tell</governor>
          <dependent id="13">saying</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">told</governor>
          <dependent id="14">what</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">told</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">saying</governor>
          <dependent id="16">told</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">them</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">told</governor>
          <dependent id="18">them</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">interviewers</governor>
          <dependent id="20">by</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">told</governor>
          <dependent id="21">interviewers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">told</governor>
          <dependent id="23">or</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">repeating</governor>
          <dependent id="24">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">repeating</governor>
          <dependent id="25">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">repeating</governor>
          <dependent id="26">were</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">told</governor>
          <dependent id="27">repeating</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">told</governor>
          <dependent id="28">what</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">parents</governor>
          <dependent id="29">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">told</governor>
          <dependent id="30">parents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="32">told</governor>
          <dependent id="31">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">repeating</governor>
          <dependent id="32">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">told</governor>
          <dependent id="33">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CII" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="CII" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>``If the CII tapes had not been entered into evidence and I had not seen them, I could have believed the children a little more,&amp;apost;&amp;apost;&amp;apost; Mrs. Williams said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="CII" lemma="cii" stem="cii" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="tapes" lemma="tape" stem="tape" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="entered" lemma="enter" stem="enter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="believed" lemma="believe" stem="believ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="little" lemma="little" stem="littl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="33" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (IN If) (S (S (NP (DT the) (NN CII) (NNS tapes)) (VP (VBD had) (RB not) (VP (VBN been) (VP (VBN entered) (PP (IN into) (NP (NN evidence))))))) (CC and) (S (NP (PRP I)) (VP (VBD had) (RB not) (VP (VBN seen) (NP (PRP them))))))) (, ,) (NP (PRP I)) (VP (MD could) (VP (VB have) (VP (VBN believed) (NP (DT the) (NNS children)) (ADVP (NP (DT a) (RB little)) (RBR more)))))) (, ,) ('' '') ('' ') (NP (NNP Mrs.) (NNP Williams)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="If the CII tapes had not been entered into evidence and I had not seen them" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="the" />
            <token id="4" string="CII" />
            <token id="5" string="tapes" />
            <token id="6" string="had" />
            <token id="7" string="not" />
            <token id="8" string="been" />
            <token id="9" string="entered" />
            <token id="10" string="into" />
            <token id="11" string="evidence" />
            <token id="12" string="and" />
            <token id="13" string="I" />
            <token id="14" string="had" />
            <token id="15" string="not" />
            <token id="16" string="seen" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="the CII tapes" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="CII" />
            <token id="5" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="3" string="had not been entered into evidence" type="VP">
          <tokens>
            <token id="6" string="had" />
            <token id="7" string="not" />
            <token id="8" string="been" />
            <token id="9" string="entered" />
            <token id="10" string="into" />
            <token id="11" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="4" string="evidence" type="NP">
          <tokens>
            <token id="11" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="13" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="could have believed the children a little more" type="VP">
          <tokens>
            <token id="20" string="could" />
            <token id="21" string="have" />
            <token id="22" string="believed" />
            <token id="23" string="the" />
            <token id="24" string="children" />
            <token id="25" string="a" />
            <token id="26" string="little" />
            <token id="27" string="more" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mrs. Williams" type="NP">
          <tokens>
            <token id="31" string="Mrs." />
            <token id="32" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="8" string="them" type="NP">
          <tokens>
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="believed the children a little more" type="VP">
          <tokens>
            <token id="22" string="believed" />
            <token id="23" string="the" />
            <token id="24" string="children" />
            <token id="25" string="a" />
            <token id="26" string="little" />
            <token id="27" string="more" />
          </tokens>
        </chunking>
        <chunking id="10" string="been entered into evidence" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="entered" />
            <token id="10" string="into" />
            <token id="11" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="11" string="had not seen them" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="not" />
            <token id="16" string="seen" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="12" string="have believed the children a little more" type="VP">
          <tokens>
            <token id="21" string="have" />
            <token id="22" string="believed" />
            <token id="23" string="the" />
            <token id="24" string="children" />
            <token id="25" string="a" />
            <token id="26" string="little" />
            <token id="27" string="more" />
          </tokens>
        </chunking>
        <chunking id="13" string="the children" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="children" />
          </tokens>
        </chunking>
        <chunking id="14" string="a little" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="little" />
          </tokens>
        </chunking>
        <chunking id="15" string="seen them" type="VP">
          <tokens>
            <token id="16" string="seen" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="16" string="said" type="VP">
          <tokens>
            <token id="33" string="said" />
          </tokens>
        </chunking>
        <chunking id="17" string="entered into evidence" type="VP">
          <tokens>
            <token id="9" string="entered" />
            <token id="10" string="into" />
            <token id="11" string="evidence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="9">entered</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">tapes</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">tapes</governor>
          <dependent id="4">CII</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">entered</governor>
          <dependent id="5">tapes</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">entered</governor>
          <dependent id="6">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">entered</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">entered</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">believed</governor>
          <dependent id="9">entered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">evidence</governor>
          <dependent id="10">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">entered</governor>
          <dependent id="11">evidence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">entered</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">seen</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">seen</governor>
          <dependent id="14">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">seen</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">entered</governor>
          <dependent id="16">seen</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">seen</governor>
          <dependent id="17">them</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">believed</governor>
          <dependent id="19">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">believed</governor>
          <dependent id="20">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">believed</governor>
          <dependent id="21">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="33">said</governor>
          <dependent id="22">believed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">children</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">believed</governor>
          <dependent id="24">children</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">little</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="27">more</governor>
          <dependent id="26">little</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">believed</governor>
          <dependent id="27">more</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Williams</governor>
          <dependent id="31">Mrs.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">said</governor>
          <dependent id="32">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="33">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CII" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="CII" />
          </tokens>
        </entity>
        <entity id="2" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="32" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>``The CII tapes did not help me.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="CII" lemma="cii" stem="cii" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="tapes" lemma="tape" stem="tape" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT The) (NN CII) (NNS tapes)) (VP (VBD did) (RB not) (VP (VB help) (NP (PRP me)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="help me" type="VP">
          <tokens>
            <token id="7" string="help" />
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="did not help me" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="not" />
            <token id="7" string="help" />
            <token id="8" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="The CII tapes" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="CII" />
            <token id="4" string="tapes" />
          </tokens>
        </chunking>
        <chunking id="4" string="me" type="NP">
          <tokens>
            <token id="8" string="me" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">tapes</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">tapes</governor>
          <dependent id="3">CII</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">help</governor>
          <dependent id="4">tapes</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">help</governor>
          <dependent id="5">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">help</governor>
          <dependent id="6">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">help</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">help</governor>
          <dependent id="8">me</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CII" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="CII" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>They gave me a lot of reasonable doubt,&amp;apost;&amp;apost; agreed juror Julie Peters, 47, a supermarket meat wrapper.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="reasonable" lemma="reasonable" stem="reason" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="doubt" lemma="doubt" stem="doubt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="agreed" lemma="agree" stem="agre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Julie" lemma="Julie" stem="juli" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="Peters" lemma="Peters" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="47" lemma="47" stem="47" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="supermarket" lemma="supermarket" stem="supermarket" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="meat" lemma="meat" stem="meat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="wrapper" lemma="wrapper" stem="wrapper" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (PRP They)) (VP (VBD gave) (NP (PRP me)) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (JJ reasonable) (NN doubt)))))) (, ,) ('' '') (VP (VBD agreed) (NP (NN juror))) (NP (NP (NNP Julie) (NNP Peters)) (, ,) (NP (NP (CD 47)) (, ,) (NP (DT a) (NN supermarket) (NN meat) (NN wrapper)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="47" type="NP">
          <tokens>
            <token id="16" string="47" />
          </tokens>
        </chunking>
        <chunking id="3" string="juror" type="NP">
          <tokens>
            <token id="12" string="juror" />
          </tokens>
        </chunking>
        <chunking id="4" string="gave me a lot of reasonable doubt" type="VP">
          <tokens>
            <token id="2" string="gave" />
            <token id="3" string="me" />
            <token id="4" string="a" />
            <token id="5" string="lot" />
            <token id="6" string="of" />
            <token id="7" string="reasonable" />
            <token id="8" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="5" string="agreed juror" type="VP">
          <tokens>
            <token id="11" string="agreed" />
            <token id="12" string="juror" />
          </tokens>
        </chunking>
        <chunking id="6" string="a lot" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="lot" />
          </tokens>
        </chunking>
        <chunking id="7" string="me" type="NP">
          <tokens>
            <token id="3" string="me" />
          </tokens>
        </chunking>
        <chunking id="8" string="reasonable doubt" type="NP">
          <tokens>
            <token id="7" string="reasonable" />
            <token id="8" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="9" string="47 , a supermarket meat wrapper" type="NP">
          <tokens>
            <token id="16" string="47" />
            <token id="17" string="," />
            <token id="18" string="a" />
            <token id="19" string="supermarket" />
            <token id="20" string="meat" />
            <token id="21" string="wrapper" />
          </tokens>
        </chunking>
        <chunking id="10" string="a supermarket meat wrapper" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="supermarket" />
            <token id="20" string="meat" />
            <token id="21" string="wrapper" />
          </tokens>
        </chunking>
        <chunking id="11" string="a lot of reasonable doubt" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="lot" />
            <token id="6" string="of" />
            <token id="7" string="reasonable" />
            <token id="8" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="12" string="Julie Peters , 47 , a supermarket meat wrapper" type="NP">
          <tokens>
            <token id="13" string="Julie" />
            <token id="14" string="Peters" />
            <token id="15" string="," />
            <token id="16" string="47" />
            <token id="17" string="," />
            <token id="18" string="a" />
            <token id="19" string="supermarket" />
            <token id="20" string="meat" />
            <token id="21" string="wrapper" />
          </tokens>
        </chunking>
        <chunking id="13" string="Julie Peters" type="NP">
          <tokens>
            <token id="13" string="Julie" />
            <token id="14" string="Peters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">gave</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">agreed</governor>
          <dependent id="2">gave</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="2">gave</governor>
          <dependent id="3">me</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">lot</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">gave</governor>
          <dependent id="5">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">doubt</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">doubt</governor>
          <dependent id="7">reasonable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">lot</governor>
          <dependent id="8">doubt</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">agreed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">agreed</governor>
          <dependent id="12">juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Peters</governor>
          <dependent id="13">Julie</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">agreed</governor>
          <dependent id="14">Peters</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">Peters</governor>
          <dependent id="16">47</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">wrapper</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">wrapper</governor>
          <dependent id="19">supermarket</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">wrapper</governor>
          <dependent id="20">meat</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">47</governor>
          <dependent id="21">wrapper</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="47" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="47" />
          </tokens>
        </entity>
        <entity id="2" string="Julie Peters" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Julie" />
            <token id="14" string="Peters" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``The children were never allowed to say in their own words what happened to them.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="allowed" lemma="allow" stem="allow" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT The) (NNS children)) (VP (VBD were) (ADVP (RB never)) (VP (VBN allowed) (S (VP (TO to) (VP (VB say) (PP (IN in) (NP (NP (PRP$ their) (JJ own) (NNS words)) (SBAR (WHNP (WP what)) (S (VP (VBD happened) (PP (TO to) (NP (PRP them))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="their own words" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
          </tokens>
        </chunking>
        <chunking id="2" string="allowed to say in their own words what happened to them" type="VP">
          <tokens>
            <token id="6" string="allowed" />
            <token id="7" string="to" />
            <token id="8" string="say" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="to say in their own words what happened to them" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="say" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="what happened to them" type="SBAR">
          <tokens>
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="5" string="say in their own words what happened to them" type="VP">
          <tokens>
            <token id="8" string="say" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="The children" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="happened to them" type="VP">
          <tokens>
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="them" type="NP">
          <tokens>
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="were never allowed to say in their own words what happened to them" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="never" />
            <token id="6" string="allowed" />
            <token id="7" string="to" />
            <token id="8" string="say" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="their own words what happened to them" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
            <token id="13" string="what" />
            <token id="14" string="happened" />
            <token id="15" string="to" />
            <token id="16" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">children</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">allowed</governor>
          <dependent id="3">children</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">allowed</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">allowed</governor>
          <dependent id="5">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">allowed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">say</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">allowed</governor>
          <dependent id="8">say</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">words</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">words</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">words</governor>
          <dependent id="11">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">say</governor>
          <dependent id="12">words</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">happened</governor>
          <dependent id="13">what</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">words</governor>
          <dependent id="14">happened</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">them</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">happened</governor>
          <dependent id="16">them</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="false">
      <content>All the questions were leading.</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="leading" lemma="lead" stem="lead" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PDT All) (DT the) (NNS questions)) (VP (VBD were) (VP (VBG leading))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="All the questions" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="the" />
            <token id="3" string="questions" />
          </tokens>
        </chunking>
        <chunking id="2" string="leading" type="VP">
          <tokens>
            <token id="5" string="leading" />
          </tokens>
        </chunking>
        <chunking id="3" string="were leading" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="leading" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det:predet">
          <governor id="3">questions</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">questions</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">leading</governor>
          <dependent id="3">questions</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">leading</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">leading</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>They never had a chance to tell their stories,&amp;apost;&amp;apost; said juror John Breese, 51, a medical technician and grandfather of five.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="chance" lemma="chance" stem="chanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="stories" lemma="story" stem="stori" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Breese" lemma="Breese" stem="brees" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="51" lemma="51" stem="51" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="technician" lemma="technician" stem="technician" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="grandfather" lemma="grandfather" stem="grandfath" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (PRP They)) (ADVP (RB never)) (VP (VBD had) (NP (DT a) (NN chance) (S (VP (TO to) (VP (VB tell) (NP (PRP$ their) (NNS stories)))))))) (, ,) ('' '') (VP (VBD said) (NP (NN juror))) (NP (NP (NNP John) (NNP Breese)) (, ,) (NP (NP (CD 51)) (, ,) (NP (DT a) (JJ medical) (NN technician)) (CC and) (NP (NP (NN grandfather)) (PP (IN of) (NP (CD five)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="juror" type="NP">
          <tokens>
            <token id="13" string="juror" />
          </tokens>
        </chunking>
        <chunking id="3" string="51 , a medical technician and grandfather of five" type="NP">
          <tokens>
            <token id="17" string="51" />
            <token id="18" string="," />
            <token id="19" string="a" />
            <token id="20" string="medical" />
            <token id="21" string="technician" />
            <token id="22" string="and" />
            <token id="23" string="grandfather" />
            <token id="24" string="of" />
            <token id="25" string="five" />
          </tokens>
        </chunking>
        <chunking id="4" string="John Breese" type="NP">
          <tokens>
            <token id="14" string="John" />
            <token id="15" string="Breese" />
          </tokens>
        </chunking>
        <chunking id="5" string="a medical technician" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="medical" />
            <token id="21" string="technician" />
          </tokens>
        </chunking>
        <chunking id="6" string="said juror" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="juror" />
          </tokens>
        </chunking>
        <chunking id="7" string="a chance to tell their stories" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="chance" />
            <token id="6" string="to" />
            <token id="7" string="tell" />
            <token id="8" string="their" />
            <token id="9" string="stories" />
          </tokens>
        </chunking>
        <chunking id="8" string="to tell their stories" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="tell" />
            <token id="8" string="their" />
            <token id="9" string="stories" />
          </tokens>
        </chunking>
        <chunking id="9" string="grandfather" type="NP">
          <tokens>
            <token id="23" string="grandfather" />
          </tokens>
        </chunking>
        <chunking id="10" string="John Breese , 51 , a medical technician and grandfather of five" type="NP">
          <tokens>
            <token id="14" string="John" />
            <token id="15" string="Breese" />
            <token id="16" string="," />
            <token id="17" string="51" />
            <token id="18" string="," />
            <token id="19" string="a" />
            <token id="20" string="medical" />
            <token id="21" string="technician" />
            <token id="22" string="and" />
            <token id="23" string="grandfather" />
            <token id="24" string="of" />
            <token id="25" string="five" />
          </tokens>
        </chunking>
        <chunking id="11" string="had a chance to tell their stories" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="a" />
            <token id="5" string="chance" />
            <token id="6" string="to" />
            <token id="7" string="tell" />
            <token id="8" string="their" />
            <token id="9" string="stories" />
          </tokens>
        </chunking>
        <chunking id="12" string="tell their stories" type="VP">
          <tokens>
            <token id="7" string="tell" />
            <token id="8" string="their" />
            <token id="9" string="stories" />
          </tokens>
        </chunking>
        <chunking id="13" string="51" type="NP">
          <tokens>
            <token id="17" string="51" />
          </tokens>
        </chunking>
        <chunking id="14" string="grandfather of five" type="NP">
          <tokens>
            <token id="23" string="grandfather" />
            <token id="24" string="of" />
            <token id="25" string="five" />
          </tokens>
        </chunking>
        <chunking id="15" string="five" type="NP">
          <tokens>
            <token id="25" string="five" />
          </tokens>
        </chunking>
        <chunking id="16" string="their stories" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="stories" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">had</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">had</governor>
          <dependent id="2">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">chance</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">had</governor>
          <dependent id="5">chance</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">tell</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">chance</governor>
          <dependent id="7">tell</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">stories</governor>
          <dependent id="8">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">tell</governor>
          <dependent id="9">stories</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">said</governor>
          <dependent id="13">juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Breese</governor>
          <dependent id="14">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="15">Breese</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">Breese</governor>
          <dependent id="17">51</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">technician</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">technician</governor>
          <dependent id="20">medical</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">51</governor>
          <dependent id="21">technician</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">51</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">51</governor>
          <dependent id="23">grandfather</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">five</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">grandfather</governor>
          <dependent id="25">five</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Breese" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="John" />
            <token id="15" string="Breese" />
          </tokens>
        </entity>
        <entity id="2" string="51" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="51" />
          </tokens>
        </entity>
        <entity id="3" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="25" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>``I tried to believe the children,&amp;apost;&amp;apost; said juror Daryl Hutchins 28, an oil company lease operator.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="tried" lemma="try" stem="tri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Daryl" lemma="Daryl" stem="daryl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="Hutchins" lemma="Hutchins" stem="hutchin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="28" lemma="28" stem="28" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="oil" lemma="oil" stem="oil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="company" lemma="company" stem="compani" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="lease" lemma="lease" stem="leas" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="operator" lemma="operator" stem="oper" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (VBD tried) (S (VP (TO to) (VP (VB believe) (NP (DT the) (NNS children))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NN juror) (NNP Daryl) (NNP Hutchins) (CD 28)) (, ,) (NP (DT an) (NN oil) (NN company) (NN lease) (NN operator))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="tried to believe the children" type="VP">
          <tokens>
            <token id="3" string="tried" />
            <token id="4" string="to" />
            <token id="5" string="believe" />
            <token id="6" string="the" />
            <token id="7" string="children" />
          </tokens>
        </chunking>
        <chunking id="2" string="juror Daryl Hutchins 28" type="NP">
          <tokens>
            <token id="11" string="juror" />
            <token id="12" string="Daryl" />
            <token id="13" string="Hutchins" />
            <token id="14" string="28" />
          </tokens>
        </chunking>
        <chunking id="3" string="an oil company lease operator" type="NP">
          <tokens>
            <token id="16" string="an" />
            <token id="17" string="oil" />
            <token id="18" string="company" />
            <token id="19" string="lease" />
            <token id="20" string="operator" />
          </tokens>
        </chunking>
        <chunking id="4" string="the children" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="believe the children" type="VP">
          <tokens>
            <token id="5" string="believe" />
            <token id="6" string="the" />
            <token id="7" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="to believe the children" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="believe" />
            <token id="6" string="the" />
            <token id="7" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="10" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="juror Daryl Hutchins 28 , an oil company lease operator" type="NP">
          <tokens>
            <token id="11" string="juror" />
            <token id="12" string="Daryl" />
            <token id="13" string="Hutchins" />
            <token id="14" string="28" />
            <token id="15" string="," />
            <token id="16" string="an" />
            <token id="17" string="oil" />
            <token id="18" string="company" />
            <token id="19" string="lease" />
            <token id="20" string="operator" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">tried</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="3">tried</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">believe</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">tried</governor>
          <dependent id="5">believe</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">children</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">believe</governor>
          <dependent id="7">children</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Hutchins</governor>
          <dependent id="11">juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Hutchins</governor>
          <dependent id="12">Daryl</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="13">Hutchins</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">Hutchins</governor>
          <dependent id="14">28</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">operator</governor>
          <dependent id="16">an</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">operator</governor>
          <dependent id="17">oil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">operator</governor>
          <dependent id="18">company</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">operator</governor>
          <dependent id="19">lease</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Hutchins</governor>
          <dependent id="20">operator</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="28" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="28" />
          </tokens>
        </entity>
        <entity id="2" string="Daryl Hutchins" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Daryl" />
            <token id="13" string="Hutchins" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>``But if the child was so contaminated (by the interviews) I couldn&amp;apost;t.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="contaminated" lemma="contaminate" stem="contamin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (S (SBAR (IN if) (S (NP (DT the) (NN child)) (VP (VBD was) (ADVP (RB so)) (VP (VBN contaminated) (PRN (-LRB- -LRB-) (PP (IN by) (NP (DT the) (NNS interviews))) (-RRB- -RRB-)))))) (NP (PRP I)) (VP (MD could) (RB n't))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="if the child was so contaminated -LRB- by the interviews -RRB-" type="SBAR">
          <tokens>
            <token id="3" string="if" />
            <token id="4" string="the" />
            <token id="5" string="child" />
            <token id="6" string="was" />
            <token id="7" string="so" />
            <token id="8" string="contaminated" />
            <token id="9" string="(" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="interviews" />
            <token id="13" string=")" />
          </tokens>
        </chunking>
        <chunking id="2" string="the interviews" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="3" string="could n't" type="VP">
          <tokens>
            <token id="15" string="could" />
            <token id="16" string="n't" />
          </tokens>
        </chunking>
        <chunking id="4" string="contaminated -LRB- by the interviews -RRB-" type="VP">
          <tokens>
            <token id="8" string="contaminated" />
            <token id="9" string="(" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="interviews" />
            <token id="13" string=")" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="14" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="was so contaminated -LRB- by the interviews -RRB-" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="so" />
            <token id="8" string="contaminated" />
            <token id="9" string="(" />
            <token id="10" string="by" />
            <token id="11" string="the" />
            <token id="12" string="interviews" />
            <token id="13" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="the child" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="child" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="15">could</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">contaminated</governor>
          <dependent id="3">if</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">child</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">contaminated</governor>
          <dependent id="5">child</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">contaminated</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">contaminated</governor>
          <dependent id="7">so</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">could</governor>
          <dependent id="8">contaminated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">interviews</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">interviews</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">contaminated</governor>
          <dependent id="12">interviews</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">could</governor>
          <dependent id="14">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">could</governor>
          <dependent id="16">n't</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Equal criticism was aimed at a letter sent in 1983 by the Manhattan Beach Police Department to parents of McMartin school children.</content>
      <tokens>
        <token id="1" string="Equal" lemma="Equal" stem="equal" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="criticism" lemma="criticism" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="aimed" lemma="aim" stem="aim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Manhattan" lemma="Manhattan" stem="manhattan" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="14" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="16" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="21" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="22" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Equal) (NN criticism)) (VP (VBD was) (VP (VBN aimed) (PP (IN at) (NP (NP (DT a) (NN letter)) (VP (VBN sent) (PP (IN in) (NP (CD 1983))) (PP (IN by) (NP (DT the) (NNP Manhattan) (NNP Beach) (NNP Police) (NNP Department))) (PP (TO to) (NP (NP (NNS parents)) (PP (IN of) (NP (NNP McMartin) (NN school) (NNS children)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was aimed at a letter sent in 1983 by the Manhattan Beach Police Department to parents of McMartin school children" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="aimed" />
            <token id="5" string="at" />
            <token id="6" string="a" />
            <token id="7" string="letter" />
            <token id="8" string="sent" />
            <token id="9" string="in" />
            <token id="10" string="1983" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="Police" />
            <token id="16" string="Department" />
            <token id="17" string="to" />
            <token id="18" string="parents" />
            <token id="19" string="of" />
            <token id="20" string="McMartin" />
            <token id="21" string="school" />
            <token id="22" string="children" />
          </tokens>
        </chunking>
        <chunking id="2" string="1983" type="NP">
          <tokens>
            <token id="10" string="1983" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Manhattan Beach Police Department" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="Police" />
            <token id="16" string="Department" />
          </tokens>
        </chunking>
        <chunking id="4" string="a letter sent in 1983 by the Manhattan Beach Police Department to parents of McMartin school children" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="letter" />
            <token id="8" string="sent" />
            <token id="9" string="in" />
            <token id="10" string="1983" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="Police" />
            <token id="16" string="Department" />
            <token id="17" string="to" />
            <token id="18" string="parents" />
            <token id="19" string="of" />
            <token id="20" string="McMartin" />
            <token id="21" string="school" />
            <token id="22" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="McMartin school children" type="NP">
          <tokens>
            <token id="20" string="McMartin" />
            <token id="21" string="school" />
            <token id="22" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="sent in 1983 by the Manhattan Beach Police Department to parents of McMartin school children" type="VP">
          <tokens>
            <token id="8" string="sent" />
            <token id="9" string="in" />
            <token id="10" string="1983" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="Police" />
            <token id="16" string="Department" />
            <token id="17" string="to" />
            <token id="18" string="parents" />
            <token id="19" string="of" />
            <token id="20" string="McMartin" />
            <token id="21" string="school" />
            <token id="22" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="parents of McMartin school children" type="NP">
          <tokens>
            <token id="18" string="parents" />
            <token id="19" string="of" />
            <token id="20" string="McMartin" />
            <token id="21" string="school" />
            <token id="22" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="Equal criticism" type="NP">
          <tokens>
            <token id="1" string="Equal" />
            <token id="2" string="criticism" />
          </tokens>
        </chunking>
        <chunking id="9" string="a letter" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="letter" />
          </tokens>
        </chunking>
        <chunking id="10" string="parents" type="NP">
          <tokens>
            <token id="18" string="parents" />
          </tokens>
        </chunking>
        <chunking id="11" string="aimed at a letter sent in 1983 by the Manhattan Beach Police Department to parents of McMartin school children" type="VP">
          <tokens>
            <token id="4" string="aimed" />
            <token id="5" string="at" />
            <token id="6" string="a" />
            <token id="7" string="letter" />
            <token id="8" string="sent" />
            <token id="9" string="in" />
            <token id="10" string="1983" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="Police" />
            <token id="16" string="Department" />
            <token id="17" string="to" />
            <token id="18" string="parents" />
            <token id="19" string="of" />
            <token id="20" string="McMartin" />
            <token id="21" string="school" />
            <token id="22" string="children" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">criticism</governor>
          <dependent id="1">Equal</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">aimed</governor>
          <dependent id="2">criticism</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">aimed</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">aimed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">letter</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">letter</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">aimed</governor>
          <dependent id="7">letter</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">letter</governor>
          <dependent id="8">sent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">1983</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">sent</governor>
          <dependent id="10">1983</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Department</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Department</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Department</governor>
          <dependent id="13">Manhattan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Department</governor>
          <dependent id="14">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Department</governor>
          <dependent id="15">Police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">sent</governor>
          <dependent id="16">Department</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">parents</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">sent</governor>
          <dependent id="18">parents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">children</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">children</governor>
          <dependent id="20">McMartin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">children</governor>
          <dependent id="21">school</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">parents</governor>
          <dependent id="22">children</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1983" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="1983" />
          </tokens>
        </entity>
        <entity id="2" string="Manhattan Beach Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Manhattan" />
            <token id="14" string="Beach" />
            <token id="15" string="Police" />
            <token id="16" string="Department" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>The letter alerted parents to a claim of molestation at the school and to Buckey&amp;apost;s arrest.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="alerted" lemma="alert" stem="alert" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="claim" lemma="claim" stem="claim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="arrest" lemma="arrest" stem="arrest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN letter)) (VP (VBD alerted) (NP (NNS parents)) (PP (TO to) (NP (NP (DT a) (NN claim)) (PP (IN of) (NP (NN molestation))))) (PP (PP (IN at) (NP (DT the) (NN school))) (CC and) (PP (TO to) (NP (NP (NNP Buckey) (POS 's)) (NN arrest))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The letter" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="letter" />
          </tokens>
        </chunking>
        <chunking id="2" string="a claim" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="claim" />
          </tokens>
        </chunking>
        <chunking id="3" string="molestation" type="NP">
          <tokens>
            <token id="9" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="4" string="the school" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="school" />
          </tokens>
        </chunking>
        <chunking id="5" string="Buckey 's arrest" type="NP">
          <tokens>
            <token id="15" string="Buckey" />
            <token id="16" string="'s" />
            <token id="17" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="6" string="a claim of molestation" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="claim" />
            <token id="8" string="of" />
            <token id="9" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="7" string="Buckey 's" type="NP">
          <tokens>
            <token id="15" string="Buckey" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="alerted parents to a claim of molestation at the school and to Buckey 's arrest" type="VP">
          <tokens>
            <token id="3" string="alerted" />
            <token id="4" string="parents" />
            <token id="5" string="to" />
            <token id="6" string="a" />
            <token id="7" string="claim" />
            <token id="8" string="of" />
            <token id="9" string="molestation" />
            <token id="10" string="at" />
            <token id="11" string="the" />
            <token id="12" string="school" />
            <token id="13" string="and" />
            <token id="14" string="to" />
            <token id="15" string="Buckey" />
            <token id="16" string="'s" />
            <token id="17" string="arrest" />
          </tokens>
        </chunking>
        <chunking id="9" string="parents" type="NP">
          <tokens>
            <token id="4" string="parents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">letter</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">alerted</governor>
          <dependent id="2">letter</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">alerted</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">alerted</governor>
          <dependent id="3">alerted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">alerted</governor>
          <dependent id="4">parents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">claim</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">claim</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">alerted</governor>
          <dependent id="7">claim</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">molestation</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">claim</governor>
          <dependent id="9">molestation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">school</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">school</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">alerted</governor>
          <dependent id="12">school</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">alerted</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">arrest</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">arrest</governor>
          <dependent id="15">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Buckey</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">alerted</governor>
          <dependent id="17">arrest</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>``The police letter should never have been sent,&amp;apost;&amp;apost; said juror Sally Cordova, 27, a supermarket checker.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="sent" lemma="send" stem="sent" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Sally" lemma="Sally" stem="salli" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Cordova" lemma="Cordova" stem="cordova" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="27" lemma="27" stem="27" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="supermarket" lemma="supermarket" stem="supermarket" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="checker" lemma="checker" stem="checker" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT The) (NN police) (NN letter)) (VP (MD should) (ADVP (RB never)) (VP (VB have) (VP (VBN been) (VP (VBN sent)))))) (, ,) ('' '') (VP (VBD said) (NP (NN juror))) (NP (NP (NNP Sally) (NNP Cordova)) (, ,) (NP (NP (CD 27)) (, ,) (NP (DT a) (NN supermarket) (NN checker)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sent" type="VP">
          <tokens>
            <token id="9" string="sent" />
          </tokens>
        </chunking>
        <chunking id="2" string="27" type="NP">
          <tokens>
            <token id="17" string="27" />
          </tokens>
        </chunking>
        <chunking id="3" string="have been sent" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="sent" />
          </tokens>
        </chunking>
        <chunking id="4" string="juror" type="NP">
          <tokens>
            <token id="13" string="juror" />
          </tokens>
        </chunking>
        <chunking id="5" string="should never have been sent" type="VP">
          <tokens>
            <token id="5" string="should" />
            <token id="6" string="never" />
            <token id="7" string="have" />
            <token id="8" string="been" />
            <token id="9" string="sent" />
          </tokens>
        </chunking>
        <chunking id="6" string="been sent" type="VP">
          <tokens>
            <token id="8" string="been" />
            <token id="9" string="sent" />
          </tokens>
        </chunking>
        <chunking id="7" string="Sally Cordova" type="NP">
          <tokens>
            <token id="14" string="Sally" />
            <token id="15" string="Cordova" />
          </tokens>
        </chunking>
        <chunking id="8" string="The police letter" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="police" />
            <token id="4" string="letter" />
          </tokens>
        </chunking>
        <chunking id="9" string="said juror" type="VP">
          <tokens>
            <token id="12" string="said" />
            <token id="13" string="juror" />
          </tokens>
        </chunking>
        <chunking id="10" string="a supermarket checker" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="supermarket" />
            <token id="21" string="checker" />
          </tokens>
        </chunking>
        <chunking id="11" string="Sally Cordova , 27 , a supermarket checker" type="NP">
          <tokens>
            <token id="14" string="Sally" />
            <token id="15" string="Cordova" />
            <token id="16" string="," />
            <token id="17" string="27" />
            <token id="18" string="," />
            <token id="19" string="a" />
            <token id="20" string="supermarket" />
            <token id="21" string="checker" />
          </tokens>
        </chunking>
        <chunking id="12" string="27 , a supermarket checker" type="NP">
          <tokens>
            <token id="17" string="27" />
            <token id="18" string="," />
            <token id="19" string="a" />
            <token id="20" string="supermarket" />
            <token id="21" string="checker" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">letter</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">letter</governor>
          <dependent id="3">police</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">sent</governor>
          <dependent id="4">letter</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">sent</governor>
          <dependent id="5">should</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">sent</governor>
          <dependent id="6">never</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">sent</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">sent</governor>
          <dependent id="8">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="9">sent</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">said</governor>
          <dependent id="13">juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Cordova</governor>
          <dependent id="14">Sally</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="15">Cordova</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">Cordova</governor>
          <dependent id="17">27</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">checker</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">checker</governor>
          <dependent id="20">supermarket</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">27</governor>
          <dependent id="21">checker</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="27" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="27" />
          </tokens>
        </entity>
        <entity id="2" string="Sally Cordova" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Sally" />
            <token id="15" string="Cordova" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>``It put the information out there too early.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="put" lemma="put" stem="put" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBD put) (NP (DT the) (NN information)) (PRT (IN out)) (ADVP (RB there) (RB too) (JJ early))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="put the information out there too early" type="VP">
          <tokens>
            <token id="3" string="put" />
            <token id="4" string="the" />
            <token id="5" string="information" />
            <token id="6" string="out" />
            <token id="7" string="there" />
            <token id="8" string="too" />
            <token id="9" string="early" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="the information" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="information" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">put</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">put</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">information</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">put</governor>
          <dependent id="5">information</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="3">put</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">early</governor>
          <dependent id="7">there</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">early</governor>
          <dependent id="8">too</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">put</governor>
          <dependent id="9">early</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>The whole city knew.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="whole" lemma="whole" stem="whole" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ whole) (NN city)) (VP (VBD knew)) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="knew" type="VP">
          <tokens>
            <token id="4" string="knew" />
          </tokens>
        </chunking>
        <chunking id="2" string="The whole city" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="whole" />
            <token id="3" string="city" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">city</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">city</governor>
          <dependent id="2">whole</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">knew</governor>
          <dependent id="3">city</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">knew</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>At that point, jurors said, they felt parents had been programmed to believe their children had been molested.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="felt" lemma="feel" stem="felt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="programmed" lemma="program" stem="program" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (DT that) (NN point))) (PRN (, ,) (S (NP (NNS jurors)) (VP (VBD said))) (, ,)) (NP (PRP they)) (VP (VBD felt) (SBAR (S (NP (NNS parents)) (VP (VBD had) (VP (VBN been) (VP (VBN programmed) (S (VP (TO to) (VP (VB believe) (SBAR (S (NP (PRP$ their) (NNS children)) (VP (VBD had) (VP (VBN been) (VP (VBN molested))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="felt parents had been programmed to believe their children had been molested" type="VP">
          <tokens>
            <token id="9" string="felt" />
            <token id="10" string="parents" />
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="programmed" />
            <token id="14" string="to" />
            <token id="15" string="believe" />
            <token id="16" string="their" />
            <token id="17" string="children" />
            <token id="18" string="had" />
            <token id="19" string="been" />
            <token id="20" string="molested" />
          </tokens>
        </chunking>
        <chunking id="2" string="programmed to believe their children had been molested" type="VP">
          <tokens>
            <token id="13" string="programmed" />
            <token id="14" string="to" />
            <token id="15" string="believe" />
            <token id="16" string="their" />
            <token id="17" string="children" />
            <token id="18" string="had" />
            <token id="19" string="been" />
            <token id="20" string="molested" />
          </tokens>
        </chunking>
        <chunking id="3" string="that point" type="NP">
          <tokens>
            <token id="2" string="that" />
            <token id="3" string="point" />
          </tokens>
        </chunking>
        <chunking id="4" string="their children had been molested" type="SBAR">
          <tokens>
            <token id="16" string="their" />
            <token id="17" string="children" />
            <token id="18" string="had" />
            <token id="19" string="been" />
            <token id="20" string="molested" />
          </tokens>
        </chunking>
        <chunking id="5" string="to believe their children had been molested" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="believe" />
            <token id="16" string="their" />
            <token id="17" string="children" />
            <token id="18" string="had" />
            <token id="19" string="been" />
            <token id="20" string="molested" />
          </tokens>
        </chunking>
        <chunking id="6" string="had been molested" type="VP">
          <tokens>
            <token id="18" string="had" />
            <token id="19" string="been" />
            <token id="20" string="molested" />
          </tokens>
        </chunking>
        <chunking id="7" string="been programmed to believe their children had been molested" type="VP">
          <tokens>
            <token id="12" string="been" />
            <token id="13" string="programmed" />
            <token id="14" string="to" />
            <token id="15" string="believe" />
            <token id="16" string="their" />
            <token id="17" string="children" />
            <token id="18" string="had" />
            <token id="19" string="been" />
            <token id="20" string="molested" />
          </tokens>
        </chunking>
        <chunking id="8" string="their children" type="NP">
          <tokens>
            <token id="16" string="their" />
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="jurors" type="NP">
          <tokens>
            <token id="5" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="parents had been programmed to believe their children had been molested" type="SBAR">
          <tokens>
            <token id="10" string="parents" />
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="programmed" />
            <token id="14" string="to" />
            <token id="15" string="believe" />
            <token id="16" string="their" />
            <token id="17" string="children" />
            <token id="18" string="had" />
            <token id="19" string="been" />
            <token id="20" string="molested" />
          </tokens>
        </chunking>
        <chunking id="12" string="been molested" type="VP">
          <tokens>
            <token id="19" string="been" />
            <token id="20" string="molested" />
          </tokens>
        </chunking>
        <chunking id="13" string="had been programmed to believe their children had been molested" type="VP">
          <tokens>
            <token id="11" string="had" />
            <token id="12" string="been" />
            <token id="13" string="programmed" />
            <token id="14" string="to" />
            <token id="15" string="believe" />
            <token id="16" string="their" />
            <token id="17" string="children" />
            <token id="18" string="had" />
            <token id="19" string="been" />
            <token id="20" string="molested" />
          </tokens>
        </chunking>
        <chunking id="14" string="believe their children had been molested" type="VP">
          <tokens>
            <token id="15" string="believe" />
            <token id="16" string="their" />
            <token id="17" string="children" />
            <token id="18" string="had" />
            <token id="19" string="been" />
            <token id="20" string="molested" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="6" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="parents" type="NP">
          <tokens>
            <token id="10" string="parents" />
          </tokens>
        </chunking>
        <chunking id="17" string="molested" type="VP">
          <tokens>
            <token id="20" string="molested" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">point</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">point</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">felt</governor>
          <dependent id="3">point</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="5">jurors</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="9">felt</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">felt</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">felt</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">programmed</governor>
          <dependent id="10">parents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">programmed</governor>
          <dependent id="11">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">programmed</governor>
          <dependent id="12">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">felt</governor>
          <dependent id="13">programmed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">believe</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">programmed</governor>
          <dependent id="15">believe</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">children</governor>
          <dependent id="16">their</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">molested</governor>
          <dependent id="17">children</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">molested</governor>
          <dependent id="18">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">molested</governor>
          <dependent id="19">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">believe</governor>
          <dependent id="20">molested</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>``One child said his parents told him that he was molested even before he went to CII,&amp;apost;&amp;apost; Mrs. Williams recalled.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="CII" lemma="CII" stem="cii" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="recalled" lemma="recall" stem="recal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (CD One) (NN child)) (VP (VBD said) (SBAR (S (NP (PRP$ his) (NNS parents)) (VP (VBD told) (NP (PRP him)) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (VP (VBN molested) (SBAR (RB even) (IN before) (S (NP (PRP he)) (VP (VBD went) (PP (TO to) (NP (NNP CII))))))))))))))) (, ,) ('' '') (NP (NNP Mrs.) (NNP Williams)) (VP (VBD recalled)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="CII" type="NP">
          <tokens>
            <token id="18" string="CII" />
          </tokens>
        </chunking>
        <chunking id="2" string="that he was molested even before he went to CII" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="molested" />
            <token id="13" string="even" />
            <token id="14" string="before" />
            <token id="15" string="he" />
            <token id="16" string="went" />
            <token id="17" string="to" />
            <token id="18" string="CII" />
          </tokens>
        </chunking>
        <chunking id="3" string="him" type="NP">
          <tokens>
            <token id="8" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="told him that he was molested even before he went to CII" type="VP">
          <tokens>
            <token id="7" string="told" />
            <token id="8" string="him" />
            <token id="9" string="that" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="molested" />
            <token id="13" string="even" />
            <token id="14" string="before" />
            <token id="15" string="he" />
            <token id="16" string="went" />
            <token id="17" string="to" />
            <token id="18" string="CII" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mrs. Williams" type="NP">
          <tokens>
            <token id="21" string="Mrs." />
            <token id="22" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="6" string="molested even before he went to CII" type="VP">
          <tokens>
            <token id="12" string="molested" />
            <token id="13" string="even" />
            <token id="14" string="before" />
            <token id="15" string="he" />
            <token id="16" string="went" />
            <token id="17" string="to" />
            <token id="18" string="CII" />
          </tokens>
        </chunking>
        <chunking id="7" string="even before he went to CII" type="SBAR">
          <tokens>
            <token id="13" string="even" />
            <token id="14" string="before" />
            <token id="15" string="he" />
            <token id="16" string="went" />
            <token id="17" string="to" />
            <token id="18" string="CII" />
          </tokens>
        </chunking>
        <chunking id="8" string="One child" type="NP">
          <tokens>
            <token id="2" string="One" />
            <token id="3" string="child" />
          </tokens>
        </chunking>
        <chunking id="9" string="went to CII" type="VP">
          <tokens>
            <token id="16" string="went" />
            <token id="17" string="to" />
            <token id="18" string="CII" />
          </tokens>
        </chunking>
        <chunking id="10" string="his parents told him that he was molested even before he went to CII" type="SBAR">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="parents" />
            <token id="7" string="told" />
            <token id="8" string="him" />
            <token id="9" string="that" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="molested" />
            <token id="13" string="even" />
            <token id="14" string="before" />
            <token id="15" string="he" />
            <token id="16" string="went" />
            <token id="17" string="to" />
            <token id="18" string="CII" />
          </tokens>
        </chunking>
        <chunking id="11" string="said his parents told him that he was molested even before he went to CII" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="his" />
            <token id="6" string="parents" />
            <token id="7" string="told" />
            <token id="8" string="him" />
            <token id="9" string="that" />
            <token id="10" string="he" />
            <token id="11" string="was" />
            <token id="12" string="molested" />
            <token id="13" string="even" />
            <token id="14" string="before" />
            <token id="15" string="he" />
            <token id="16" string="went" />
            <token id="17" string="to" />
            <token id="18" string="CII" />
          </tokens>
        </chunking>
        <chunking id="12" string="his parents" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="parents" />
          </tokens>
        </chunking>
        <chunking id="13" string="recalled" type="VP">
          <tokens>
            <token id="23" string="recalled" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="was molested even before he went to CII" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="molested" />
            <token id="13" string="even" />
            <token id="14" string="before" />
            <token id="15" string="he" />
            <token id="16" string="went" />
            <token id="17" string="to" />
            <token id="18" string="CII" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="3">child</governor>
          <dependent id="2">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">child</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">recalled</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">parents</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">told</governor>
          <dependent id="6">parents</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="7">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">told</governor>
          <dependent id="8">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">molested</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">molested</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">molested</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">told</governor>
          <dependent id="12">molested</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">went</governor>
          <dependent id="13">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">went</governor>
          <dependent id="14">before</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">went</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">molested</governor>
          <dependent id="16">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">CII</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">went</governor>
          <dependent id="18">CII</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Williams</governor>
          <dependent id="21">Mrs.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">recalled</governor>
          <dependent id="22">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">recalled</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CII" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="18" string="CII" />
          </tokens>
        </entity>
        <entity id="2" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="One" />
          </tokens>
        </entity>
        <entity id="3" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>The panelists said they threw out entirely the most fantastic allegations, including some children&amp;apost;s accounts of being molested in a car wash.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="panelists" lemma="panelist" stem="panelist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="threw" lemma="throw" stem="threw" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="entirely" lemma="entirely" stem="entir" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="fantastic" lemma="fantastic" stem="fantast" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="accounts" lemma="account" stem="account" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="car" lemma="car" stem="car" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="wash" lemma="wash" stem="wash" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS panelists)) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VBD threw) (PRT (RP out)) (NP (NP (ADVP (RB entirely)) (DT the) (ADJP (RBS most) (JJ fantastic)) (NNS allegations)) (, ,) (PP (VBG including) (NP (NP (NP (DT some) (NNS children) (POS 's)) (NNS accounts)) (PP (IN of) (S (VP (VBG being) (VP (VBN molested) (PP (IN in) (NP (DT a) (NN car) (NN wash)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="most fantastic" type="ADJP">
          <tokens>
            <token id="9" string="most" />
            <token id="10" string="fantastic" />
          </tokens>
        </chunking>
        <chunking id="2" string="entirely the most fantastic allegations" type="NP">
          <tokens>
            <token id="7" string="entirely" />
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="fantastic" />
            <token id="11" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="3" string="entirely the most fantastic allegations , including some children 's accounts of being molested in a car wash" type="NP">
          <tokens>
            <token id="7" string="entirely" />
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="fantastic" />
            <token id="11" string="allegations" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="some" />
            <token id="15" string="children" />
            <token id="16" string="'s" />
            <token id="17" string="accounts" />
            <token id="18" string="of" />
            <token id="19" string="being" />
            <token id="20" string="molested" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="car" />
            <token id="24" string="wash" />
          </tokens>
        </chunking>
        <chunking id="4" string="The panelists" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="panelists" />
          </tokens>
        </chunking>
        <chunking id="5" string="molested in a car wash" type="VP">
          <tokens>
            <token id="20" string="molested" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="car" />
            <token id="24" string="wash" />
          </tokens>
        </chunking>
        <chunking id="6" string="said they threw out entirely the most fantastic allegations , including some children 's accounts of being molested in a car wash" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="they" />
            <token id="5" string="threw" />
            <token id="6" string="out" />
            <token id="7" string="entirely" />
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="fantastic" />
            <token id="11" string="allegations" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="some" />
            <token id="15" string="children" />
            <token id="16" string="'s" />
            <token id="17" string="accounts" />
            <token id="18" string="of" />
            <token id="19" string="being" />
            <token id="20" string="molested" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="car" />
            <token id="24" string="wash" />
          </tokens>
        </chunking>
        <chunking id="7" string="some children 's" type="NP">
          <tokens>
            <token id="14" string="some" />
            <token id="15" string="children" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="being molested in a car wash" type="VP">
          <tokens>
            <token id="19" string="being" />
            <token id="20" string="molested" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="car" />
            <token id="24" string="wash" />
          </tokens>
        </chunking>
        <chunking id="10" string="they threw out entirely the most fantastic allegations , including some children 's accounts of being molested in a car wash" type="SBAR">
          <tokens>
            <token id="4" string="they" />
            <token id="5" string="threw" />
            <token id="6" string="out" />
            <token id="7" string="entirely" />
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="fantastic" />
            <token id="11" string="allegations" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="some" />
            <token id="15" string="children" />
            <token id="16" string="'s" />
            <token id="17" string="accounts" />
            <token id="18" string="of" />
            <token id="19" string="being" />
            <token id="20" string="molested" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="car" />
            <token id="24" string="wash" />
          </tokens>
        </chunking>
        <chunking id="11" string="some children 's accounts of being molested in a car wash" type="NP">
          <tokens>
            <token id="14" string="some" />
            <token id="15" string="children" />
            <token id="16" string="'s" />
            <token id="17" string="accounts" />
            <token id="18" string="of" />
            <token id="19" string="being" />
            <token id="20" string="molested" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="car" />
            <token id="24" string="wash" />
          </tokens>
        </chunking>
        <chunking id="12" string="some children 's accounts" type="NP">
          <tokens>
            <token id="14" string="some" />
            <token id="15" string="children" />
            <token id="16" string="'s" />
            <token id="17" string="accounts" />
          </tokens>
        </chunking>
        <chunking id="13" string="threw out entirely the most fantastic allegations , including some children 's accounts of being molested in a car wash" type="VP">
          <tokens>
            <token id="5" string="threw" />
            <token id="6" string="out" />
            <token id="7" string="entirely" />
            <token id="8" string="the" />
            <token id="9" string="most" />
            <token id="10" string="fantastic" />
            <token id="11" string="allegations" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="some" />
            <token id="15" string="children" />
            <token id="16" string="'s" />
            <token id="17" string="accounts" />
            <token id="18" string="of" />
            <token id="19" string="being" />
            <token id="20" string="molested" />
            <token id="21" string="in" />
            <token id="22" string="a" />
            <token id="23" string="car" />
            <token id="24" string="wash" />
          </tokens>
        </chunking>
        <chunking id="14" string="a car wash" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="car" />
            <token id="24" string="wash" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">panelists</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">panelists</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">threw</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="5">threw</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">threw</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">allegations</governor>
          <dependent id="7">entirely</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">allegations</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">fantastic</governor>
          <dependent id="9">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">allegations</governor>
          <dependent id="10">fantastic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">threw</governor>
          <dependent id="11">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">accounts</governor>
          <dependent id="13">including</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">children</governor>
          <dependent id="14">some</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">accounts</governor>
          <dependent id="15">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">children</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">allegations</governor>
          <dependent id="17">accounts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">molested</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">molested</governor>
          <dependent id="19">being</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">accounts</governor>
          <dependent id="20">molested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">wash</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">wash</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">wash</governor>
          <dependent id="23">car</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">molested</governor>
          <dependent id="24">wash</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>``We just dismissed those,&amp;apost;&amp;apost; said Mrs. Williams.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="dismissed" lemma="dismiss" stem="dismiss" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP We)) (ADVP (RB just)) (VP (VBD dismissed) (NP (DT those)))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Mrs.) (NNP Williams)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mrs. Williams" type="NP">
          <tokens>
            <token id="9" string="Mrs." />
            <token id="10" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="2" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="3" string="said" type="VP">
          <tokens>
            <token id="8" string="said" />
          </tokens>
        </chunking>
        <chunking id="4" string="dismissed those" type="VP">
          <tokens>
            <token id="4" string="dismissed" />
            <token id="5" string="those" />
          </tokens>
        </chunking>
        <chunking id="5" string="those" type="NP">
          <tokens>
            <token id="5" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">dismissed</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">dismissed</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="4">dismissed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">dismissed</governor>
          <dependent id="5">those</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Williams</governor>
          <dependent id="9">Mrs.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="10">Williams</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>They said a series of medical slides shown to them lacked impact because they weren&amp;apost;t sure what they were seeing in the photos of children&amp;apost;s genitals.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="series" lemma="series" stem="seri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="slides" lemma="slide" stem="slide" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="shown" lemma="show" stem="shown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="lacked" lemma="lack" stem="lack" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="impact" lemma="impact" stem="impact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="seeing" lemma="see" stem="see" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="photos" lemma="photo" stem="photo" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="genitals" lemma="genitals" stem="genit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD said) (SBAR (S (NP (NP (DT a) (NN series)) (PP (IN of) (NP (NP (JJ medical) (NNS slides)) (VP (VBN shown) (PP (TO to) (NP (PRP them))))))) (VP (VBD lacked) (NP (NN impact)) (SBAR (IN because) (S (NP (PRP they)) (VP (VBD were) (RB n't) (ADJP (JJ sure)) (SBAR (WHNP (WP what)) (S (NP (PRP they)) (VP (VBD were) (VP (VBG seeing) (PP (IN in) (NP (NP (DT the) (NNS photos)) (PP (IN of) (NP (NP (NNS children) (POS 's)) (NNS genitals)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="said a series of medical slides shown to them lacked impact because they were n't sure what they were seeing in the photos of children 's genitals" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="a" />
            <token id="4" string="series" />
            <token id="5" string="of" />
            <token id="6" string="medical" />
            <token id="7" string="slides" />
            <token id="8" string="shown" />
            <token id="9" string="to" />
            <token id="10" string="them" />
            <token id="11" string="lacked" />
            <token id="12" string="impact" />
            <token id="13" string="because" />
            <token id="14" string="they" />
            <token id="15" string="were" />
            <token id="16" string="n't" />
            <token id="17" string="sure" />
            <token id="18" string="what" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="seeing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="photos" />
            <token id="25" string="of" />
            <token id="26" string="children" />
            <token id="27" string="'s" />
            <token id="28" string="genitals" />
          </tokens>
        </chunking>
        <chunking id="3" string="sure" type="ADJP">
          <tokens>
            <token id="17" string="sure" />
          </tokens>
        </chunking>
        <chunking id="4" string="lacked impact because they were n't sure what they were seeing in the photos of children 's genitals" type="VP">
          <tokens>
            <token id="11" string="lacked" />
            <token id="12" string="impact" />
            <token id="13" string="because" />
            <token id="14" string="they" />
            <token id="15" string="were" />
            <token id="16" string="n't" />
            <token id="17" string="sure" />
            <token id="18" string="what" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="seeing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="photos" />
            <token id="25" string="of" />
            <token id="26" string="children" />
            <token id="27" string="'s" />
            <token id="28" string="genitals" />
          </tokens>
        </chunking>
        <chunking id="5" string="impact" type="NP">
          <tokens>
            <token id="12" string="impact" />
          </tokens>
        </chunking>
        <chunking id="6" string="what they were seeing in the photos of children 's genitals" type="SBAR">
          <tokens>
            <token id="18" string="what" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="seeing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="photos" />
            <token id="25" string="of" />
            <token id="26" string="children" />
            <token id="27" string="'s" />
            <token id="28" string="genitals" />
          </tokens>
        </chunking>
        <chunking id="7" string="shown to them" type="VP">
          <tokens>
            <token id="8" string="shown" />
            <token id="9" string="to" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="seeing in the photos of children 's genitals" type="VP">
          <tokens>
            <token id="21" string="seeing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="photos" />
            <token id="25" string="of" />
            <token id="26" string="children" />
            <token id="27" string="'s" />
            <token id="28" string="genitals" />
          </tokens>
        </chunking>
        <chunking id="9" string="a series of medical slides shown to them lacked impact because they were n't sure what they were seeing in the photos of children 's genitals" type="SBAR">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="series" />
            <token id="5" string="of" />
            <token id="6" string="medical" />
            <token id="7" string="slides" />
            <token id="8" string="shown" />
            <token id="9" string="to" />
            <token id="10" string="them" />
            <token id="11" string="lacked" />
            <token id="12" string="impact" />
            <token id="13" string="because" />
            <token id="14" string="they" />
            <token id="15" string="were" />
            <token id="16" string="n't" />
            <token id="17" string="sure" />
            <token id="18" string="what" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="seeing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="photos" />
            <token id="25" string="of" />
            <token id="26" string="children" />
            <token id="27" string="'s" />
            <token id="28" string="genitals" />
          </tokens>
        </chunking>
        <chunking id="10" string="the photos of children 's genitals" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="photos" />
            <token id="25" string="of" />
            <token id="26" string="children" />
            <token id="27" string="'s" />
            <token id="28" string="genitals" />
          </tokens>
        </chunking>
        <chunking id="11" string="them" type="NP">
          <tokens>
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="12" string="a series" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="series" />
          </tokens>
        </chunking>
        <chunking id="13" string="they" type="NP">
          <tokens>
            <token id="14" string="they" />
          </tokens>
        </chunking>
        <chunking id="14" string="the photos" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="photos" />
          </tokens>
        </chunking>
        <chunking id="15" string="medical slides shown to them" type="NP">
          <tokens>
            <token id="6" string="medical" />
            <token id="7" string="slides" />
            <token id="8" string="shown" />
            <token id="9" string="to" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="16" string="were seeing in the photos of children 's genitals" type="VP">
          <tokens>
            <token id="20" string="were" />
            <token id="21" string="seeing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="photos" />
            <token id="25" string="of" />
            <token id="26" string="children" />
            <token id="27" string="'s" />
            <token id="28" string="genitals" />
          </tokens>
        </chunking>
        <chunking id="17" string="a series of medical slides shown to them" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="series" />
            <token id="5" string="of" />
            <token id="6" string="medical" />
            <token id="7" string="slides" />
            <token id="8" string="shown" />
            <token id="9" string="to" />
            <token id="10" string="them" />
          </tokens>
        </chunking>
        <chunking id="18" string="children 's genitals" type="NP">
          <tokens>
            <token id="26" string="children" />
            <token id="27" string="'s" />
            <token id="28" string="genitals" />
          </tokens>
        </chunking>
        <chunking id="19" string="children 's" type="NP">
          <tokens>
            <token id="26" string="children" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="20" string="medical slides" type="NP">
          <tokens>
            <token id="6" string="medical" />
            <token id="7" string="slides" />
          </tokens>
        </chunking>
        <chunking id="21" string="were n't sure what they were seeing in the photos of children 's genitals" type="VP">
          <tokens>
            <token id="15" string="were" />
            <token id="16" string="n't" />
            <token id="17" string="sure" />
            <token id="18" string="what" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="seeing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="photos" />
            <token id="25" string="of" />
            <token id="26" string="children" />
            <token id="27" string="'s" />
            <token id="28" string="genitals" />
          </tokens>
        </chunking>
        <chunking id="22" string="because they were n't sure what they were seeing in the photos of children 's genitals" type="SBAR">
          <tokens>
            <token id="13" string="because" />
            <token id="14" string="they" />
            <token id="15" string="were" />
            <token id="16" string="n't" />
            <token id="17" string="sure" />
            <token id="18" string="what" />
            <token id="19" string="they" />
            <token id="20" string="were" />
            <token id="21" string="seeing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="photos" />
            <token id="25" string="of" />
            <token id="26" string="children" />
            <token id="27" string="'s" />
            <token id="28" string="genitals" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">series</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">lacked</governor>
          <dependent id="4">series</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">slides</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">slides</governor>
          <dependent id="6">medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">series</governor>
          <dependent id="7">slides</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">slides</governor>
          <dependent id="8">shown</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">them</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">shown</governor>
          <dependent id="10">them</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="11">lacked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">lacked</governor>
          <dependent id="12">impact</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">sure</governor>
          <dependent id="13">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">sure</governor>
          <dependent id="14">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">sure</governor>
          <dependent id="15">were</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">sure</governor>
          <dependent id="16">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">lacked</governor>
          <dependent id="17">sure</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">seeing</governor>
          <dependent id="18">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">seeing</governor>
          <dependent id="19">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">seeing</governor>
          <dependent id="20">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">sure</governor>
          <dependent id="21">seeing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">photos</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">photos</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">seeing</governor>
          <dependent id="24">photos</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">genitals</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">genitals</governor>
          <dependent id="26">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">children</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">photos</governor>
          <dependent id="28">genitals</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Although they acquitted defendants of most charges, the jurors deadlocked on 13 counts.</content>
      <tokens>
        <token id="1" string="Although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="acquitted" lemma="acquit" stem="acquit" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="deadlocked" lemma="deadlock" stem="deadlock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Although) (S (NP (PRP they)) (VP (VBD acquitted) (NP (NP (NNS defendants)) (PP (IN of) (NP (JJS most) (NNS charges))))))) (, ,) (S (NP (DT the) (NNS jurors)) (VP (VBN deadlocked) (PP (IN on) (NP (CD 13) (NNS counts))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="defendants" type="NP">
          <tokens>
            <token id="4" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="acquitted defendants of most charges" type="VP">
          <tokens>
            <token id="3" string="acquitted" />
            <token id="4" string="defendants" />
            <token id="5" string="of" />
            <token id="6" string="most" />
            <token id="7" string="charges" />
          </tokens>
        </chunking>
        <chunking id="4" string="defendants of most charges" type="NP">
          <tokens>
            <token id="4" string="defendants" />
            <token id="5" string="of" />
            <token id="6" string="most" />
            <token id="7" string="charges" />
          </tokens>
        </chunking>
        <chunking id="5" string="deadlocked on 13 counts" type="VP">
          <tokens>
            <token id="11" string="deadlocked" />
            <token id="12" string="on" />
            <token id="13" string="13" />
            <token id="14" string="counts" />
          </tokens>
        </chunking>
        <chunking id="6" string="Although they acquitted defendants of most charges" type="SBAR">
          <tokens>
            <token id="1" string="Although" />
            <token id="2" string="they" />
            <token id="3" string="acquitted" />
            <token id="4" string="defendants" />
            <token id="5" string="of" />
            <token id="6" string="most" />
            <token id="7" string="charges" />
          </tokens>
        </chunking>
        <chunking id="7" string="the jurors" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="8" string="most charges" type="NP">
          <tokens>
            <token id="6" string="most" />
            <token id="7" string="charges" />
          </tokens>
        </chunking>
        <chunking id="9" string="13 counts" type="NP">
          <tokens>
            <token id="13" string="13" />
            <token id="14" string="counts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">acquitted</governor>
          <dependent id="1">Although</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">acquitted</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">deadlocked</governor>
          <dependent id="3">acquitted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">acquitted</governor>
          <dependent id="4">defendants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">charges</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">charges</governor>
          <dependent id="6">most</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">defendants</governor>
          <dependent id="7">charges</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">jurors</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">deadlocked</governor>
          <dependent id="10">jurors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">deadlocked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">counts</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">counts</governor>
          <dependent id="13">13</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">deadlocked</governor>
          <dependent id="14">counts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="13" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Some said they were unsure whether Buckey was a molester but were sure the prosecution had failed to prove its molestation allegations against him beyond a reasonable doubt.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="unsure" lemma="unsure" stem="unsur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="molester" lemma="molester" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="prosecution" lemma="prosecution" stem="prosecut" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="failed" lemma="fail" stem="fail" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="prove" lemma="prove" stem="prove" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="reasonable" lemma="reasonable" stem="reason" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="doubt" lemma="doubt" stem="doubt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some)) (VP (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VBD were) (ADJP (JJ unsure)) (SBAR (IN whether) (S (NP (NNP Buckey)) (VP (VBD was) (NP (DT a) (NN molester))))))))) (CC but) (VP (VBD were) (ADJP (JJ sure) (SBAR (S (NP (DT the) (NN prosecution)) (VP (VBD had) (VP (VBN failed) (S (VP (TO to) (VP (VB prove) (NP (PRP$ its) (NN molestation) (NNS allegations)) (PP (IN against) (NP (PRP him))))))))))) (PP (IN beyond) (NP (DT a) (JJ reasonable) (NN doubt))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a molester" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="molester" />
          </tokens>
        </chunking>
        <chunking id="2" string="sure the prosecution had failed to prove its molestation allegations against him" type="ADJP">
          <tokens>
            <token id="13" string="sure" />
            <token id="14" string="the" />
            <token id="15" string="prosecution" />
            <token id="16" string="had" />
            <token id="17" string="failed" />
            <token id="18" string="to" />
            <token id="19" string="prove" />
            <token id="20" string="its" />
            <token id="21" string="molestation" />
            <token id="22" string="allegations" />
            <token id="23" string="against" />
            <token id="24" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="had failed to prove its molestation allegations against him" type="VP">
          <tokens>
            <token id="16" string="had" />
            <token id="17" string="failed" />
            <token id="18" string="to" />
            <token id="19" string="prove" />
            <token id="20" string="its" />
            <token id="21" string="molestation" />
            <token id="22" string="allegations" />
            <token id="23" string="against" />
            <token id="24" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="unsure" type="ADJP">
          <tokens>
            <token id="5" string="unsure" />
          </tokens>
        </chunking>
        <chunking id="5" string="said they were unsure whether Buckey was a molester but were sure the prosecution had failed to prove its molestation allegations against him beyond a reasonable doubt" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="they" />
            <token id="4" string="were" />
            <token id="5" string="unsure" />
            <token id="6" string="whether" />
            <token id="7" string="Buckey" />
            <token id="8" string="was" />
            <token id="9" string="a" />
            <token id="10" string="molester" />
            <token id="11" string="but" />
            <token id="12" string="were" />
            <token id="13" string="sure" />
            <token id="14" string="the" />
            <token id="15" string="prosecution" />
            <token id="16" string="had" />
            <token id="17" string="failed" />
            <token id="18" string="to" />
            <token id="19" string="prove" />
            <token id="20" string="its" />
            <token id="21" string="molestation" />
            <token id="22" string="allegations" />
            <token id="23" string="against" />
            <token id="24" string="him" />
            <token id="25" string="beyond" />
            <token id="26" string="a" />
            <token id="27" string="reasonable" />
            <token id="28" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="6" string="the prosecution had failed to prove its molestation allegations against him" type="SBAR">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="prosecution" />
            <token id="16" string="had" />
            <token id="17" string="failed" />
            <token id="18" string="to" />
            <token id="19" string="prove" />
            <token id="20" string="its" />
            <token id="21" string="molestation" />
            <token id="22" string="allegations" />
            <token id="23" string="against" />
            <token id="24" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="were sure the prosecution had failed to prove its molestation allegations against him beyond a reasonable doubt" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="sure" />
            <token id="14" string="the" />
            <token id="15" string="prosecution" />
            <token id="16" string="had" />
            <token id="17" string="failed" />
            <token id="18" string="to" />
            <token id="19" string="prove" />
            <token id="20" string="its" />
            <token id="21" string="molestation" />
            <token id="22" string="allegations" />
            <token id="23" string="against" />
            <token id="24" string="him" />
            <token id="25" string="beyond" />
            <token id="26" string="a" />
            <token id="27" string="reasonable" />
            <token id="28" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="8" string="him" type="NP">
          <tokens>
            <token id="24" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="failed to prove its molestation allegations against him" type="VP">
          <tokens>
            <token id="17" string="failed" />
            <token id="18" string="to" />
            <token id="19" string="prove" />
            <token id="20" string="its" />
            <token id="21" string="molestation" />
            <token id="22" string="allegations" />
            <token id="23" string="against" />
            <token id="24" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="Buckey" type="NP">
          <tokens>
            <token id="7" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="12" string="prove its molestation allegations against him" type="VP">
          <tokens>
            <token id="19" string="prove" />
            <token id="20" string="its" />
            <token id="21" string="molestation" />
            <token id="22" string="allegations" />
            <token id="23" string="against" />
            <token id="24" string="him" />
          </tokens>
        </chunking>
        <chunking id="13" string="its molestation allegations" type="NP">
          <tokens>
            <token id="20" string="its" />
            <token id="21" string="molestation" />
            <token id="22" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="14" string="Some" type="NP">
          <tokens>
            <token id="1" string="Some" />
          </tokens>
        </chunking>
        <chunking id="15" string="said they were unsure whether Buckey was a molester" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="they" />
            <token id="4" string="were" />
            <token id="5" string="unsure" />
            <token id="6" string="whether" />
            <token id="7" string="Buckey" />
            <token id="8" string="was" />
            <token id="9" string="a" />
            <token id="10" string="molester" />
          </tokens>
        </chunking>
        <chunking id="16" string="was a molester" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="a" />
            <token id="10" string="molester" />
          </tokens>
        </chunking>
        <chunking id="17" string="to prove its molestation allegations against him" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="prove" />
            <token id="20" string="its" />
            <token id="21" string="molestation" />
            <token id="22" string="allegations" />
            <token id="23" string="against" />
            <token id="24" string="him" />
          </tokens>
        </chunking>
        <chunking id="18" string="whether Buckey was a molester" type="SBAR">
          <tokens>
            <token id="6" string="whether" />
            <token id="7" string="Buckey" />
            <token id="8" string="was" />
            <token id="9" string="a" />
            <token id="10" string="molester" />
          </tokens>
        </chunking>
        <chunking id="19" string="the prosecution" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="20" string="a reasonable doubt" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="reasonable" />
            <token id="28" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="21" string="they were unsure whether Buckey was a molester" type="SBAR">
          <tokens>
            <token id="3" string="they" />
            <token id="4" string="were" />
            <token id="5" string="unsure" />
            <token id="6" string="whether" />
            <token id="7" string="Buckey" />
            <token id="8" string="was" />
            <token id="9" string="a" />
            <token id="10" string="molester" />
          </tokens>
        </chunking>
        <chunking id="22" string="were unsure whether Buckey was a molester" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="unsure" />
            <token id="6" string="whether" />
            <token id="7" string="Buckey" />
            <token id="8" string="was" />
            <token id="9" string="a" />
            <token id="10" string="molester" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">unsure</governor>
          <dependent id="3">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">unsure</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">unsure</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">molester</governor>
          <dependent id="6">whether</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">molester</governor>
          <dependent id="7">Buckey</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">molester</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">molester</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">unsure</governor>
          <dependent id="10">molester</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">said</governor>
          <dependent id="11">but</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">sure</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">said</governor>
          <dependent id="13">sure</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">prosecution</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">failed</governor>
          <dependent id="15">prosecution</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">failed</governor>
          <dependent id="16">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">sure</governor>
          <dependent id="17">failed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">prove</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">failed</governor>
          <dependent id="19">prove</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">allegations</governor>
          <dependent id="20">its</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">allegations</governor>
          <dependent id="21">molestation</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">prove</governor>
          <dependent id="22">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">him</governor>
          <dependent id="23">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">prove</governor>
          <dependent id="24">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">doubt</governor>
          <dependent id="25">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">doubt</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">doubt</governor>
          <dependent id="27">reasonable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">sure</governor>
          <dependent id="28">doubt</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Jurors said they didn&amp;apost;t rule out that some children in the case were molested _ but not by these defendants.</content>
      <tokens>
        <token id="1" string="Jurors" lemma="Jurors" stem="juror" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="rule" lemma="rule" stem="rule" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Jurors)) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VBD did) (RB n't) (VP (VB rule) (PRT (RP out)) (SBAR (IN that) (S (NP (NP (DT some) (NNS children)) (PP (IN in) (NP (DT the) (NN case)))) (VP (VBD were) (VP (VBN molested) (NP (NN _)) (PP (CC but) (PP (RB not) (IN by) (NP (DT these) (NNS defendants))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Jurors" type="NP">
          <tokens>
            <token id="1" string="Jurors" />
          </tokens>
        </chunking>
        <chunking id="2" string="rule out that some children in the case were molested _ but not by these defendants" type="VP">
          <tokens>
            <token id="6" string="rule" />
            <token id="7" string="out" />
            <token id="8" string="that" />
            <token id="9" string="some" />
            <token id="10" string="children" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="case" />
            <token id="14" string="were" />
            <token id="15" string="molested" />
            <token id="16" string="_" />
            <token id="17" string="but" />
            <token id="18" string="not" />
            <token id="19" string="by" />
            <token id="20" string="these" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="3" string="the case" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="some children in the case" type="NP">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="children" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="that some children in the case were molested _ but not by these defendants" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="some" />
            <token id="10" string="children" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="case" />
            <token id="14" string="were" />
            <token id="15" string="molested" />
            <token id="16" string="_" />
            <token id="17" string="but" />
            <token id="18" string="not" />
            <token id="19" string="by" />
            <token id="20" string="these" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="6" string="they" type="NP">
          <tokens>
            <token id="3" string="they" />
          </tokens>
        </chunking>
        <chunking id="7" string="they did n't rule out that some children in the case were molested _ but not by these defendants" type="SBAR">
          <tokens>
            <token id="3" string="they" />
            <token id="4" string="did" />
            <token id="5" string="n't" />
            <token id="6" string="rule" />
            <token id="7" string="out" />
            <token id="8" string="that" />
            <token id="9" string="some" />
            <token id="10" string="children" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="case" />
            <token id="14" string="were" />
            <token id="15" string="molested" />
            <token id="16" string="_" />
            <token id="17" string="but" />
            <token id="18" string="not" />
            <token id="19" string="by" />
            <token id="20" string="these" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="8" string="these defendants" type="NP">
          <tokens>
            <token id="20" string="these" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="9" string="molested _ but not by these defendants" type="VP">
          <tokens>
            <token id="15" string="molested" />
            <token id="16" string="_" />
            <token id="17" string="but" />
            <token id="18" string="not" />
            <token id="19" string="by" />
            <token id="20" string="these" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="10" string="said they did n't rule out that some children in the case were molested _ but not by these defendants" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="they" />
            <token id="4" string="did" />
            <token id="5" string="n't" />
            <token id="6" string="rule" />
            <token id="7" string="out" />
            <token id="8" string="that" />
            <token id="9" string="some" />
            <token id="10" string="children" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="case" />
            <token id="14" string="were" />
            <token id="15" string="molested" />
            <token id="16" string="_" />
            <token id="17" string="but" />
            <token id="18" string="not" />
            <token id="19" string="by" />
            <token id="20" string="these" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="11" string="did n't rule out that some children in the case were molested _ but not by these defendants" type="VP">
          <tokens>
            <token id="4" string="did" />
            <token id="5" string="n't" />
            <token id="6" string="rule" />
            <token id="7" string="out" />
            <token id="8" string="that" />
            <token id="9" string="some" />
            <token id="10" string="children" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="case" />
            <token id="14" string="were" />
            <token id="15" string="molested" />
            <token id="16" string="_" />
            <token id="17" string="but" />
            <token id="18" string="not" />
            <token id="19" string="by" />
            <token id="20" string="these" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="12" string="some children" type="NP">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="children" />
          </tokens>
        </chunking>
        <chunking id="13" string="were molested _ but not by these defendants" type="VP">
          <tokens>
            <token id="14" string="were" />
            <token id="15" string="molested" />
            <token id="16" string="_" />
            <token id="17" string="but" />
            <token id="18" string="not" />
            <token id="19" string="by" />
            <token id="20" string="these" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="14" string="_" type="NP">
          <tokens>
            <token id="16" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Jurors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">rule</governor>
          <dependent id="3">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">rule</governor>
          <dependent id="4">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">rule</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">rule</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">rule</governor>
          <dependent id="7">out</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">molested</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">children</governor>
          <dependent id="9">some</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">molested</governor>
          <dependent id="10">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">case</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">case</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">children</governor>
          <dependent id="13">case</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">molested</governor>
          <dependent id="14">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">rule</governor>
          <dependent id="15">molested</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">molested</governor>
          <dependent id="16">_</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">defendants</governor>
          <dependent id="17">but</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">defendants</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">defendants</governor>
          <dependent id="19">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">defendants</governor>
          <dependent id="20">these</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">molested</governor>
          <dependent id="21">defendants</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>``Even if you accept that the children were molested,&amp;apost;&amp;apost; said juror Mark Bassett, ``the evidence didn&amp;apost;t establish that they were molested at the McMartin Pre-School.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="accept" lemma="accept" stem="accept" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Mark" lemma="Mark" stem="mark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Bassett" lemma="Bassett" stem="bassett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="establish" lemma="establish" stem="establish" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="31" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (RB Even) (IN if) (S (NP (PRP you)) (VP (VBP accept) (SBAR (IN that) (S (NP (DT the) (NNS children)) (VP (VBD were) (VP (VBN molested)))))))) (PRN (, ,) ('' '') (SINV (VP (VBD said) (NP (NN juror))) (NP (NNP Mark) (NNP Bassett))) (, ,)) (`` ``) (NP (DT the) (NN evidence)) (VP (VBD did) (RB n't) (VP (VB establish) (SBAR (IN that) (S (NP (PRP they)) (VP (VBD were) (VP (VBN molested) (PP (IN at) (NP (DT the) (NNP McMartin) (NNP Pre-School))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mark Bassett" type="NP">
          <tokens>
            <token id="15" string="Mark" />
            <token id="16" string="Bassett" />
          </tokens>
        </chunking>
        <chunking id="2" string="juror" type="NP">
          <tokens>
            <token id="14" string="juror" />
          </tokens>
        </chunking>
        <chunking id="3" string="the evidence" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="4" string="said juror" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="juror" />
          </tokens>
        </chunking>
        <chunking id="5" string="they" type="NP">
          <tokens>
            <token id="25" string="they" />
          </tokens>
        </chunking>
        <chunking id="6" string="the children" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="were molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="26" string="were" />
            <token id="27" string="molested" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="McMartin" />
            <token id="31" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="8" string="that the children were molested" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="children" />
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="9" string="accept that the children were molested" type="VP">
          <tokens>
            <token id="5" string="accept" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="children" />
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="10" string="were molested" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="11" string="the McMartin Pre-School" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="McMartin" />
            <token id="31" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="12" string="Even if you accept that the children were molested" type="SBAR">
          <tokens>
            <token id="2" string="Even" />
            <token id="3" string="if" />
            <token id="4" string="you" />
            <token id="5" string="accept" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="children" />
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="13" string="molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="27" string="molested" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="McMartin" />
            <token id="31" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="14" string="did n't establish that they were molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="21" string="did" />
            <token id="22" string="n't" />
            <token id="23" string="establish" />
            <token id="24" string="that" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="molested" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="McMartin" />
            <token id="31" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="15" string="establish that they were molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="23" string="establish" />
            <token id="24" string="that" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="molested" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="McMartin" />
            <token id="31" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="16" string="that they were molested at the McMartin Pre-School" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="they" />
            <token id="26" string="were" />
            <token id="27" string="molested" />
            <token id="28" string="at" />
            <token id="29" string="the" />
            <token id="30" string="McMartin" />
            <token id="31" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="17" string="molested" type="VP">
          <tokens>
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="18" string="you" type="NP">
          <tokens>
            <token id="4" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">accept</governor>
          <dependent id="2">Even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">accept</governor>
          <dependent id="3">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">accept</governor>
          <dependent id="4">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">establish</governor>
          <dependent id="5">accept</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">molested</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">children</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">molested</governor>
          <dependent id="8">children</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">molested</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">accept</governor>
          <dependent id="10">molested</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="23">establish</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">said</governor>
          <dependent id="14">juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Bassett</governor>
          <dependent id="15">Mark</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="16">Bassett</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">evidence</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">establish</governor>
          <dependent id="20">evidence</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="23">establish</governor>
          <dependent id="21">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="23">establish</governor>
          <dependent id="22">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">establish</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">molested</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">molested</governor>
          <dependent id="25">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">molested</governor>
          <dependent id="26">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">establish</governor>
          <dependent id="27">molested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Pre-School</governor>
          <dependent id="28">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Pre-School</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Pre-School</governor>
          <dependent id="30">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">molested</governor>
          <dependent id="31">Pre-School</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mark Bassett" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Mark" />
            <token id="16" string="Bassett" />
          </tokens>
        </entity>
        <entity id="2" string="McMartin Pre-School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="30" string="McMartin" />
            <token id="31" string="Pre-School" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>The panelists said they were aware of the trial&amp;apost;s enormous toll on defendants as well as children and parents.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="panelists" lemma="panelist" stem="panelist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="aware" lemma="aware" stem="awar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="enormous" lemma="enormous" stem="enorm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="toll" lemma="toll" stem="toll" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS panelists)) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VBD were) (ADJP (JJ aware) (PP (IN of) (NP (NP (DT the) (NN trial) (POS 's)) (JJ enormous) (NN toll)))) (PP (IN on) (NP (NP (NNS defendants)) (CONJP (RB as) (RB well) (IN as)) (NP (NNS children) (CC and) (NNS parents)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the trial 's enormous toll" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="trial" />
            <token id="10" string="'s" />
            <token id="11" string="enormous" />
            <token id="12" string="toll" />
          </tokens>
        </chunking>
        <chunking id="2" string="defendants" type="NP">
          <tokens>
            <token id="14" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="3" string="they" type="NP">
          <tokens>
            <token id="4" string="they" />
          </tokens>
        </chunking>
        <chunking id="4" string="children and parents" type="NP">
          <tokens>
            <token id="18" string="children" />
            <token id="19" string="and" />
            <token id="20" string="parents" />
          </tokens>
        </chunking>
        <chunking id="5" string="The panelists" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="panelists" />
          </tokens>
        </chunking>
        <chunking id="6" string="aware of the trial 's enormous toll" type="ADJP">
          <tokens>
            <token id="6" string="aware" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="trial" />
            <token id="10" string="'s" />
            <token id="11" string="enormous" />
            <token id="12" string="toll" />
          </tokens>
        </chunking>
        <chunking id="7" string="were aware of the trial 's enormous toll on defendants as well as children and parents" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="aware" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="trial" />
            <token id="10" string="'s" />
            <token id="11" string="enormous" />
            <token id="12" string="toll" />
            <token id="13" string="on" />
            <token id="14" string="defendants" />
            <token id="15" string="as" />
            <token id="16" string="well" />
            <token id="17" string="as" />
            <token id="18" string="children" />
            <token id="19" string="and" />
            <token id="20" string="parents" />
          </tokens>
        </chunking>
        <chunking id="8" string="the trial 's" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="trial" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="said they were aware of the trial 's enormous toll on defendants as well as children and parents" type="VP">
          <tokens>
            <token id="3" string="said" />
            <token id="4" string="they" />
            <token id="5" string="were" />
            <token id="6" string="aware" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="trial" />
            <token id="10" string="'s" />
            <token id="11" string="enormous" />
            <token id="12" string="toll" />
            <token id="13" string="on" />
            <token id="14" string="defendants" />
            <token id="15" string="as" />
            <token id="16" string="well" />
            <token id="17" string="as" />
            <token id="18" string="children" />
            <token id="19" string="and" />
            <token id="20" string="parents" />
          </tokens>
        </chunking>
        <chunking id="10" string="defendants as well as children and parents" type="NP">
          <tokens>
            <token id="14" string="defendants" />
            <token id="15" string="as" />
            <token id="16" string="well" />
            <token id="17" string="as" />
            <token id="18" string="children" />
            <token id="19" string="and" />
            <token id="20" string="parents" />
          </tokens>
        </chunking>
        <chunking id="11" string="they were aware of the trial 's enormous toll on defendants as well as children and parents" type="SBAR">
          <tokens>
            <token id="4" string="they" />
            <token id="5" string="were" />
            <token id="6" string="aware" />
            <token id="7" string="of" />
            <token id="8" string="the" />
            <token id="9" string="trial" />
            <token id="10" string="'s" />
            <token id="11" string="enormous" />
            <token id="12" string="toll" />
            <token id="13" string="on" />
            <token id="14" string="defendants" />
            <token id="15" string="as" />
            <token id="16" string="well" />
            <token id="17" string="as" />
            <token id="18" string="children" />
            <token id="19" string="and" />
            <token id="20" string="parents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">panelists</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">said</governor>
          <dependent id="2">panelists</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">aware</governor>
          <dependent id="4">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">aware</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">said</governor>
          <dependent id="6">aware</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">toll</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">trial</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">toll</governor>
          <dependent id="9">trial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">trial</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">toll</governor>
          <dependent id="11">enormous</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">aware</governor>
          <dependent id="12">toll</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">defendants</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">aware</governor>
          <dependent id="14">defendants</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">defendants</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="15">as</governor>
          <dependent id="16">well</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="15">as</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">defendants</governor>
          <dependent id="18">children</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">children</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">children</governor>
          <dependent id="20">parents</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>``I think everybody is a victim,&amp;apost;&amp;apost; said Ms. Peters.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="everybody" lemma="everybody" stem="everybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="victim" lemma="victim" stem="victim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="Peters" lemma="Peters" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (NN everybody)) (VP (VBZ is) (NP (DT a) (NN victim))))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Ms.) (NNP Peters)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="everybody" type="NP">
          <tokens>
            <token id="4" string="everybody" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ms. Peters" type="NP">
          <tokens>
            <token id="11" string="Ms." />
            <token id="12" string="Peters" />
          </tokens>
        </chunking>
        <chunking id="3" string="everybody is a victim" type="SBAR">
          <tokens>
            <token id="4" string="everybody" />
            <token id="5" string="is" />
            <token id="6" string="a" />
            <token id="7" string="victim" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="is a victim" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="a" />
            <token id="7" string="victim" />
          </tokens>
        </chunking>
        <chunking id="6" string="think everybody is a victim" type="VP">
          <tokens>
            <token id="3" string="think" />
            <token id="4" string="everybody" />
            <token id="5" string="is" />
            <token id="6" string="a" />
            <token id="7" string="victim" />
          </tokens>
        </chunking>
        <chunking id="7" string="a victim" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="victim" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="10" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="3">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">victim</governor>
          <dependent id="4">everybody</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">victim</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">victim</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">think</governor>
          <dependent id="7">victim</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Peters</governor>
          <dependent id="11">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="12">Peters</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peters" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Peters" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>``I don&amp;apost;t think anybody came out of this case a winner.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="think" lemma="think" stem="think" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="anybody" lemma="anybody" stem="anybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB think) (NP (NN anybody))))) (VP (VBD came) (PRT (IN out)) (PP (IN of) (NP (DT this) (NN case)))) (NP (DT a) (NN winner)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="think anybody" type="VP">
          <tokens>
            <token id="5" string="think" />
            <token id="6" string="anybody" />
          </tokens>
        </chunking>
        <chunking id="2" string="anybody" type="NP">
          <tokens>
            <token id="6" string="anybody" />
          </tokens>
        </chunking>
        <chunking id="3" string="came out of this case" type="VP">
          <tokens>
            <token id="7" string="came" />
            <token id="8" string="out" />
            <token id="9" string="of" />
            <token id="10" string="this" />
            <token id="11" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="this case" type="NP">
          <tokens>
            <token id="10" string="this" />
            <token id="11" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="a winner" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="winner" />
          </tokens>
        </chunking>
        <chunking id="7" string="do n't think anybody" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="think" />
            <token id="6" string="anybody" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">think</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">think</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">came</governor>
          <dependent id="5">think</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">think</governor>
          <dependent id="6">anybody</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">came</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">came</governor>
          <dependent id="8">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">case</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">case</governor>
          <dependent id="10">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">came</governor>
          <dependent id="11">case</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">winner</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">came</governor>
          <dependent id="13">winner</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>I think it&amp;apost;s sad because everybody lost something.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sad" lemma="sad" stem="sad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="everybody" lemma="everybody" stem="everybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP think) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ sad)) (SBAR (IN because) (S (NP (NN everybody)) (VP (VBD lost) (NP (NN something))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="everybody" type="NP">
          <tokens>
            <token id="7" string="everybody" />
          </tokens>
        </chunking>
        <chunking id="2" string="sad" type="ADJP">
          <tokens>
            <token id="5" string="sad" />
          </tokens>
        </chunking>
        <chunking id="3" string="think it 's sad because everybody lost something" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="it" />
            <token id="4" string="'s" />
            <token id="5" string="sad" />
            <token id="6" string="because" />
            <token id="7" string="everybody" />
            <token id="8" string="lost" />
            <token id="9" string="something" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="lost something" type="VP">
          <tokens>
            <token id="8" string="lost" />
            <token id="9" string="something" />
          </tokens>
        </chunking>
        <chunking id="7" string="something" type="NP">
          <tokens>
            <token id="9" string="something" />
          </tokens>
        </chunking>
        <chunking id="8" string="because everybody lost something" type="SBAR">
          <tokens>
            <token id="6" string="because" />
            <token id="7" string="everybody" />
            <token id="8" string="lost" />
            <token id="9" string="something" />
          </tokens>
        </chunking>
        <chunking id="9" string="it 's sad because everybody lost something" type="SBAR">
          <tokens>
            <token id="3" string="it" />
            <token id="4" string="'s" />
            <token id="5" string="sad" />
            <token id="6" string="because" />
            <token id="7" string="everybody" />
            <token id="8" string="lost" />
            <token id="9" string="something" />
          </tokens>
        </chunking>
        <chunking id="10" string="'s sad because everybody lost something" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="sad" />
            <token id="6" string="because" />
            <token id="7" string="everybody" />
            <token id="8" string="lost" />
            <token id="9" string="something" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">sad</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">sad</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">think</governor>
          <dependent id="5">sad</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">lost</governor>
          <dependent id="6">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">lost</governor>
          <dependent id="7">everybody</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">sad</governor>
          <dependent id="8">lost</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">lost</governor>
          <dependent id="9">something</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>The defendants _ their lives have been ruined.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="ruined" lemma="ruin" stem="ruin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS defendants)) (VP (VBP _) (SBAR (S (NP (PRP$ their) (NNS lives)) (VP (VBP have) (VP (VBN been) (VP (VBN ruined))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been ruined" type="VP">
          <tokens>
            <token id="7" string="been" />
            <token id="8" string="ruined" />
          </tokens>
        </chunking>
        <chunking id="2" string="their lives have been ruined" type="SBAR">
          <tokens>
            <token id="4" string="their" />
            <token id="5" string="lives" />
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="ruined" />
          </tokens>
        </chunking>
        <chunking id="3" string="_ their lives have been ruined" type="VP">
          <tokens>
            <token id="3" string="_" />
            <token id="4" string="their" />
            <token id="5" string="lives" />
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="ruined" />
          </tokens>
        </chunking>
        <chunking id="4" string="their lives" type="NP">
          <tokens>
            <token id="4" string="their" />
            <token id="5" string="lives" />
          </tokens>
        </chunking>
        <chunking id="5" string="ruined" type="VP">
          <tokens>
            <token id="8" string="ruined" />
          </tokens>
        </chunking>
        <chunking id="6" string="have been ruined" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="been" />
            <token id="8" string="ruined" />
          </tokens>
        </chunking>
        <chunking id="7" string="The defendants" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="defendants" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">defendants</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">_</governor>
          <dependent id="2">defendants</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">_</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">lives</governor>
          <dependent id="4">their</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">ruined</governor>
          <dependent id="5">lives</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">ruined</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">ruined</governor>
          <dependent id="7">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">_</governor>
          <dependent id="8">ruined</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>They lost their business, their reputation.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="reputation" lemma="reputation" stem="reput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBD lost) (NP (NP (PRP$ their) (NN business)) (, ,) (NP (PRP$ their) (NN reputation)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="their business , their reputation" type="NP">
          <tokens>
            <token id="3" string="their" />
            <token id="4" string="business" />
            <token id="5" string="," />
            <token id="6" string="their" />
            <token id="7" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="3" string="their business" type="NP">
          <tokens>
            <token id="3" string="their" />
            <token id="4" string="business" />
          </tokens>
        </chunking>
        <chunking id="4" string="lost their business , their reputation" type="VP">
          <tokens>
            <token id="2" string="lost" />
            <token id="3" string="their" />
            <token id="4" string="business" />
            <token id="5" string="," />
            <token id="6" string="their" />
            <token id="7" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="5" string="their reputation" type="NP">
          <tokens>
            <token id="6" string="their" />
            <token id="7" string="reputation" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">lost</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">lost</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">business</governor>
          <dependent id="3">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">lost</governor>
          <dependent id="4">business</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">reputation</governor>
          <dependent id="6">their</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">business</governor>
          <dependent id="7">reputation</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>It&amp;apost;s sad.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="sad" lemma="sad" stem="sad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ 's) (ADJP (JJ sad))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s sad" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="sad" />
          </tokens>
        </chunking>
        <chunking id="2" string="sad" type="ADJP">
          <tokens>
            <token id="3" string="sad" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">sad</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">sad</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">sad</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Mrs. Williams added, ``The children have to live with this.</content>
      <tokens>
        <token id="1" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="live" lemma="live" stem="live" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mrs.) (NNP Williams)) (VP (VBD added) (, ,) (`` ``) (S (NP (DT The) (NNS children)) (VP (VBP have) (S (VP (TO to) (VP (VB live) (PP (IN with) (NP (DT this))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have to live with this" type="VP">
          <tokens>
            <token id="8" string="have" />
            <token id="9" string="to" />
            <token id="10" string="live" />
            <token id="11" string="with" />
            <token id="12" string="this" />
          </tokens>
        </chunking>
        <chunking id="2" string="added , `` The children have to live with this" type="VP">
          <tokens>
            <token id="3" string="added" />
            <token id="4" string="," />
            <token id="5" string="``" />
            <token id="6" string="The" />
            <token id="7" string="children" />
            <token id="8" string="have" />
            <token id="9" string="to" />
            <token id="10" string="live" />
            <token id="11" string="with" />
            <token id="12" string="this" />
          </tokens>
        </chunking>
        <chunking id="3" string="to live with this" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="live" />
            <token id="11" string="with" />
            <token id="12" string="this" />
          </tokens>
        </chunking>
        <chunking id="4" string="The children" type="NP">
          <tokens>
            <token id="6" string="The" />
            <token id="7" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mrs. Williams" type="NP">
          <tokens>
            <token id="1" string="Mrs." />
            <token id="2" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="6" string="live with this" type="VP">
          <tokens>
            <token id="10" string="live" />
            <token id="11" string="with" />
            <token id="12" string="this" />
          </tokens>
        </chunking>
        <chunking id="7" string="this" type="NP">
          <tokens>
            <token id="12" string="this" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Williams</governor>
          <dependent id="1">Mrs.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">added</governor>
          <dependent id="2">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">added</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">children</governor>
          <dependent id="6">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">have</governor>
          <dependent id="7">children</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">added</governor>
          <dependent id="8">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">live</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">have</governor>
          <dependent id="10">live</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">this</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">live</governor>
          <dependent id="12">this</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>The parents have to live with this.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="live" lemma="live" stem="live" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS parents)) (VP (VBP have) (S (VP (TO to) (VP (VB live) (PP (IN with) (NP (DT this))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have to live with this" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="to" />
            <token id="5" string="live" />
            <token id="6" string="with" />
            <token id="7" string="this" />
          </tokens>
        </chunking>
        <chunking id="2" string="The parents" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="parents" />
          </tokens>
        </chunking>
        <chunking id="3" string="to live with this" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="live" />
            <token id="6" string="with" />
            <token id="7" string="this" />
          </tokens>
        </chunking>
        <chunking id="4" string="live with this" type="VP">
          <tokens>
            <token id="5" string="live" />
            <token id="6" string="with" />
            <token id="7" string="this" />
          </tokens>
        </chunking>
        <chunking id="5" string="this" type="NP">
          <tokens>
            <token id="7" string="this" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">parents</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">have</governor>
          <dependent id="2">parents</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">live</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">have</governor>
          <dependent id="5">live</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">this</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">live</governor>
          <dependent id="7">this</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>There&amp;apost;s nothing I can say that will make it better.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="better" lemma="better" stem="better" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBZ 's) (NP (NP (NN nothing)) (SBAR (S (NP (PRP I)) (VP (MD can) (VP (VB say) (SBAR (S (NP (DT that)) (VP (MD will) (VP (VB make) (NP (PRP it)) (ADVP (RBR better)))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="nothing I can say that will make it better" type="NP">
          <tokens>
            <token id="3" string="nothing" />
            <token id="4" string="I" />
            <token id="5" string="can" />
            <token id="6" string="say" />
            <token id="7" string="that" />
            <token id="8" string="will" />
            <token id="9" string="make" />
            <token id="10" string="it" />
            <token id="11" string="better" />
          </tokens>
        </chunking>
        <chunking id="2" string="say that will make it better" type="VP">
          <tokens>
            <token id="6" string="say" />
            <token id="7" string="that" />
            <token id="8" string="will" />
            <token id="9" string="make" />
            <token id="10" string="it" />
            <token id="11" string="better" />
          </tokens>
        </chunking>
        <chunking id="3" string="nothing" type="NP">
          <tokens>
            <token id="3" string="nothing" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="4" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="will make it better" type="VP">
          <tokens>
            <token id="8" string="will" />
            <token id="9" string="make" />
            <token id="10" string="it" />
            <token id="11" string="better" />
          </tokens>
        </chunking>
        <chunking id="6" string="I can say that will make it better" type="SBAR">
          <tokens>
            <token id="4" string="I" />
            <token id="5" string="can" />
            <token id="6" string="say" />
            <token id="7" string="that" />
            <token id="8" string="will" />
            <token id="9" string="make" />
            <token id="10" string="it" />
            <token id="11" string="better" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="make it better" type="VP">
          <tokens>
            <token id="9" string="make" />
            <token id="10" string="it" />
            <token id="11" string="better" />
          </tokens>
        </chunking>
        <chunking id="9" string="can say that will make it better" type="VP">
          <tokens>
            <token id="5" string="can" />
            <token id="6" string="say" />
            <token id="7" string="that" />
            <token id="8" string="will" />
            <token id="9" string="make" />
            <token id="10" string="it" />
            <token id="11" string="better" />
          </tokens>
        </chunking>
        <chunking id="10" string="that" type="NP">
          <tokens>
            <token id="7" string="that" />
          </tokens>
        </chunking>
        <chunking id="11" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="12" string="that will make it better" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="will" />
            <token id="9" string="make" />
            <token id="10" string="it" />
            <token id="11" string="better" />
          </tokens>
        </chunking>
        <chunking id="13" string="'s nothing I can say that will make it better" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="nothing" />
            <token id="4" string="I" />
            <token id="5" string="can" />
            <token id="6" string="say" />
            <token id="7" string="that" />
            <token id="8" string="will" />
            <token id="9" string="make" />
            <token id="10" string="it" />
            <token id="11" string="better" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">'s</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="3">nothing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">say</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">say</governor>
          <dependent id="5">can</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">nothing</governor>
          <dependent id="6">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">make</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">make</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">say</governor>
          <dependent id="9">make</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">make</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">make</governor>
          <dependent id="11">better</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>As for themselves, the jurors said their lives were ``put on hold&amp;apost;&amp;apost; for nearly three years.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="put" lemma="put" stem="put" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="hold" lemma="hold" stem="hold" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN As) (PP (IN for) (NP (PRP themselves)))) (, ,) (NP (DT the) (NNS jurors)) (VP (VBD said) (SBAR (S (NP (PRP$ their) (NNS lives)) (VP (VBD were) (`` ``) (VP (VBN put) (PP (IN on) (NP (NP (NN hold)) ('' '') (PP (IN for) (NP (QP (RB nearly) (CD three)) (NNS years)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said their lives were `` put on hold '' for nearly three years" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="their" />
            <token id="9" string="lives" />
            <token id="10" string="were" />
            <token id="11" string="``" />
            <token id="12" string="put" />
            <token id="13" string="on" />
            <token id="14" string="hold" />
            <token id="15" string="''" />
            <token id="16" string="for" />
            <token id="17" string="nearly" />
            <token id="18" string="three" />
            <token id="19" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="themselves" type="NP">
          <tokens>
            <token id="3" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="3" string="their lives" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="lives" />
          </tokens>
        </chunking>
        <chunking id="4" string="were `` put on hold '' for nearly three years" type="VP">
          <tokens>
            <token id="10" string="were" />
            <token id="11" string="``" />
            <token id="12" string="put" />
            <token id="13" string="on" />
            <token id="14" string="hold" />
            <token id="15" string="''" />
            <token id="16" string="for" />
            <token id="17" string="nearly" />
            <token id="18" string="three" />
            <token id="19" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="nearly three years" type="NP">
          <tokens>
            <token id="17" string="nearly" />
            <token id="18" string="three" />
            <token id="19" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="the jurors" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="7" string="their lives were `` put on hold '' for nearly three years" type="SBAR">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="lives" />
            <token id="10" string="were" />
            <token id="11" string="``" />
            <token id="12" string="put" />
            <token id="13" string="on" />
            <token id="14" string="hold" />
            <token id="15" string="''" />
            <token id="16" string="for" />
            <token id="17" string="nearly" />
            <token id="18" string="three" />
            <token id="19" string="years" />
          </tokens>
        </chunking>
        <chunking id="8" string="put on hold '' for nearly three years" type="VP">
          <tokens>
            <token id="12" string="put" />
            <token id="13" string="on" />
            <token id="14" string="hold" />
            <token id="15" string="''" />
            <token id="16" string="for" />
            <token id="17" string="nearly" />
            <token id="18" string="three" />
            <token id="19" string="years" />
          </tokens>
        </chunking>
        <chunking id="9" string="hold '' for nearly three years" type="NP">
          <tokens>
            <token id="14" string="hold" />
            <token id="15" string="''" />
            <token id="16" string="for" />
            <token id="17" string="nearly" />
            <token id="18" string="three" />
            <token id="19" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="hold" type="NP">
          <tokens>
            <token id="14" string="hold" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">themselves</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">As</governor>
          <dependent id="2">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">said</governor>
          <dependent id="3">themselves</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">jurors</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">jurors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">lives</governor>
          <dependent id="8">their</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">put</governor>
          <dependent id="9">lives</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">put</governor>
          <dependent id="10">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="12">put</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">hold</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">put</governor>
          <dependent id="14">hold</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">years</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">three</governor>
          <dependent id="17">nearly</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">years</governor>
          <dependent id="18">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">hold</governor>
          <dependent id="19">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="nearly three years" type="DURATION" score="0.0">
          <tokens>
            <token id="17" string="nearly" />
            <token id="18" string="three" />
            <token id="19" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>Bassett lost his job as a research computer scientist when his company folded.</content>
      <tokens>
        <token id="1" string="Bassett" lemma="Bassett" stem="bassett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="research" lemma="research" stem="research" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="computer" lemma="computer" stem="comput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="scientist" lemma="scientist" stem="scientist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="company" lemma="company" stem="compani" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="folded" lemma="fold" stem="fold" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Bassett)) (VP (VBD lost) (NP (PRP$ his) (NN job)) (PP (IN as) (NP (DT a) (NN research) (NN computer) (NN scientist))) (SBAR (WHADVP (WRB when)) (S (NP (PRP$ his) (NN company)) (VP (VBD folded))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a research computer scientist" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="research" />
            <token id="8" string="computer" />
            <token id="9" string="scientist" />
          </tokens>
        </chunking>
        <chunking id="2" string="folded" type="VP">
          <tokens>
            <token id="13" string="folded" />
          </tokens>
        </chunking>
        <chunking id="3" string="his job" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="job" />
          </tokens>
        </chunking>
        <chunking id="4" string="lost his job as a research computer scientist when his company folded" type="VP">
          <tokens>
            <token id="2" string="lost" />
            <token id="3" string="his" />
            <token id="4" string="job" />
            <token id="5" string="as" />
            <token id="6" string="a" />
            <token id="7" string="research" />
            <token id="8" string="computer" />
            <token id="9" string="scientist" />
            <token id="10" string="when" />
            <token id="11" string="his" />
            <token id="12" string="company" />
            <token id="13" string="folded" />
          </tokens>
        </chunking>
        <chunking id="5" string="his company" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="company" />
          </tokens>
        </chunking>
        <chunking id="6" string="Bassett" type="NP">
          <tokens>
            <token id="1" string="Bassett" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="when his company folded" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="his" />
            <token id="12" string="company" />
            <token id="13" string="folded" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">lost</governor>
          <dependent id="1">Bassett</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">lost</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">job</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">lost</governor>
          <dependent id="4">job</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">scientist</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">scientist</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">scientist</governor>
          <dependent id="7">research</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">scientist</governor>
          <dependent id="8">computer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">lost</governor>
          <dependent id="9">scientist</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">folded</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">company</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">folded</governor>
          <dependent id="12">company</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">lost</governor>
          <dependent id="13">folded</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bassett" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Bassett" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Mrs. Williams got married.</content>
      <tokens>
        <token id="1" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="married" lemma="marry" stem="marri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mrs.) (NNP Williams)) (VP (VBD got) (ADJP (VBN married))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="got married" type="VP">
          <tokens>
            <token id="3" string="got" />
            <token id="4" string="married" />
          </tokens>
        </chunking>
        <chunking id="2" string="married" type="ADJP">
          <tokens>
            <token id="4" string="married" />
          </tokens>
        </chunking>
        <chunking id="3" string="Mrs. Williams" type="NP">
          <tokens>
            <token id="1" string="Mrs." />
            <token id="2" string="Williams" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Williams</governor>
          <dependent id="1">Mrs.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">got</governor>
          <dependent id="2">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">got</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">got</governor>
          <dependent id="4">married</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>Breese said his wife died during the trial and he has since remarried.</content>
      <tokens>
        <token id="1" string="Breese" lemma="Breese" stem="brees" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="remarried" lemma="remarry" stem="remarri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Breese)) (VP (VBD said) (SBAR (S (NP (PRP$ his) (NN wife)) (VP (VBD died) (PP (IN during) (NP (DT the) (NN trial)))))))) (CC and) (S (NP (PRP he)) (VP (VBZ has) (ADVP (IN since)) (VP (VBN remarried)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="died during the trial" type="VP">
          <tokens>
            <token id="5" string="died" />
            <token id="6" string="during" />
            <token id="7" string="the" />
            <token id="8" string="trial" />
          </tokens>
        </chunking>
        <chunking id="2" string="his wife died during the trial" type="SBAR">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="wife" />
            <token id="5" string="died" />
            <token id="6" string="during" />
            <token id="7" string="the" />
            <token id="8" string="trial" />
          </tokens>
        </chunking>
        <chunking id="3" string="the trial" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="trial" />
          </tokens>
        </chunking>
        <chunking id="4" string="Breese" type="NP">
          <tokens>
            <token id="1" string="Breese" />
          </tokens>
        </chunking>
        <chunking id="5" string="has since remarried" type="VP">
          <tokens>
            <token id="11" string="has" />
            <token id="12" string="since" />
            <token id="13" string="remarried" />
          </tokens>
        </chunking>
        <chunking id="6" string="remarried" type="VP">
          <tokens>
            <token id="13" string="remarried" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="his wife" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="wife" />
          </tokens>
        </chunking>
        <chunking id="9" string="said his wife died during the trial" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="his" />
            <token id="4" string="wife" />
            <token id="5" string="died" />
            <token id="6" string="during" />
            <token id="7" string="the" />
            <token id="8" string="trial" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Breese</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">wife</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">died</governor>
          <dependent id="4">wife</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="5">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">trial</governor>
          <dependent id="6">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">trial</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">died</governor>
          <dependent id="8">trial</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">said</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">remarried</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">remarried</governor>
          <dependent id="11">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">remarried</governor>
          <dependent id="12">since</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">said</governor>
          <dependent id="13">remarried</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Breese" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Breese" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>``It&amp;apost;s been very hard,&amp;apost;&amp;apost; said Mrs. Williams, a telephone company service representative.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="hard" lemma="hard" stem="hard" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="telephone" lemma="telephone" stem="telephon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="company" lemma="company" stem="compani" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="service" lemma="service" stem="servic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="representative" lemma="representative" stem="repres" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (VP (VBN been) (ADJP (RB very) (RB hard))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Mrs.) (NNP Williams)) (, ,) (NP (DT a) (NN telephone) (NN company) (NN service) (NN representative))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a telephone company service representative" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="telephone" />
            <token id="15" string="company" />
            <token id="16" string="service" />
            <token id="17" string="representative" />
          </tokens>
        </chunking>
        <chunking id="2" string="very hard" type="ADJP">
          <tokens>
            <token id="5" string="very" />
            <token id="6" string="hard" />
          </tokens>
        </chunking>
        <chunking id="3" string="been very hard" type="VP">
          <tokens>
            <token id="4" string="been" />
            <token id="5" string="very" />
            <token id="6" string="hard" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s been very hard" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="been" />
            <token id="5" string="very" />
            <token id="6" string="hard" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mrs. Williams , a telephone company service representative" type="NP">
          <tokens>
            <token id="10" string="Mrs." />
            <token id="11" string="Williams" />
            <token id="12" string="," />
            <token id="13" string="a" />
            <token id="14" string="telephone" />
            <token id="15" string="company" />
            <token id="16" string="service" />
            <token id="17" string="representative" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mrs. Williams" type="NP">
          <tokens>
            <token id="10" string="Mrs." />
            <token id="11" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="6">hard</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">hard</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">hard</governor>
          <dependent id="4">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">hard</governor>
          <dependent id="5">very</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="6">hard</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Williams</governor>
          <dependent id="10">Mrs.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="11">Williams</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">representative</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">representative</governor>
          <dependent id="14">telephone</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">representative</governor>
          <dependent id="15">company</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">representative</governor>
          <dependent id="16">service</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">Williams</governor>
          <dependent id="17">representative</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>``There were days when I thought I couldn&amp;apost;t stand it anymore.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="stand" lemma="stand" stem="stand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="anymore" lemma="anymore" stem="anymor" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (EX There)) (VP (VBD were) (NP (NP (NNS days)) (SBAR (WHADVP (WRB when)) (S (NP (PRP I)) (VP (VBD thought) (SBAR (S (NP (PRP I)) (VP (MD could) (RB n't) (VP (VB stand) (NP (PRP it)) (ADVP (RB anymore))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could n't stand it anymore" type="VP">
          <tokens>
            <token id="9" string="could" />
            <token id="10" string="n't" />
            <token id="11" string="stand" />
            <token id="12" string="it" />
            <token id="13" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="I could n't stand it anymore" type="SBAR">
          <tokens>
            <token id="8" string="I" />
            <token id="9" string="could" />
            <token id="10" string="n't" />
            <token id="11" string="stand" />
            <token id="12" string="it" />
            <token id="13" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="4" string="days when I thought I could n't stand it anymore" type="NP">
          <tokens>
            <token id="4" string="days" />
            <token id="5" string="when" />
            <token id="6" string="I" />
            <token id="7" string="thought" />
            <token id="8" string="I" />
            <token id="9" string="could" />
            <token id="10" string="n't" />
            <token id="11" string="stand" />
            <token id="12" string="it" />
            <token id="13" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="5" string="days" type="NP">
          <tokens>
            <token id="4" string="days" />
          </tokens>
        </chunking>
        <chunking id="6" string="when I thought I could n't stand it anymore" type="SBAR">
          <tokens>
            <token id="5" string="when" />
            <token id="6" string="I" />
            <token id="7" string="thought" />
            <token id="8" string="I" />
            <token id="9" string="could" />
            <token id="10" string="n't" />
            <token id="11" string="stand" />
            <token id="12" string="it" />
            <token id="13" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="thought I could n't stand it anymore" type="VP">
          <tokens>
            <token id="7" string="thought" />
            <token id="8" string="I" />
            <token id="9" string="could" />
            <token id="10" string="n't" />
            <token id="11" string="stand" />
            <token id="12" string="it" />
            <token id="13" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="stand it anymore" type="VP">
          <tokens>
            <token id="11" string="stand" />
            <token id="12" string="it" />
            <token id="13" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="11" string="when" type="WHADVP">
          <tokens>
            <token id="5" string="when" />
          </tokens>
        </chunking>
        <chunking id="12" string="were days when I thought I could n't stand it anymore" type="VP">
          <tokens>
            <token id="3" string="were" />
            <token id="4" string="days" />
            <token id="5" string="when" />
            <token id="6" string="I" />
            <token id="7" string="thought" />
            <token id="8" string="I" />
            <token id="9" string="could" />
            <token id="10" string="n't" />
            <token id="11" string="stand" />
            <token id="12" string="it" />
            <token id="13" string="anymore" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">were</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">were</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">were</governor>
          <dependent id="4">days</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">thought</governor>
          <dependent id="5">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">thought</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">days</governor>
          <dependent id="7">thought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">stand</governor>
          <dependent id="8">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">stand</governor>
          <dependent id="9">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">stand</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">thought</governor>
          <dependent id="11">stand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">stand</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">stand</governor>
          <dependent id="13">anymore</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="days" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="days" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>``I don&amp;apost;t really know my job anymore,&amp;apost;&amp;apost; she said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="job" lemma="job" stem="job" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="anymore" lemma="anymore" stem="anymor" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP do) (RB n't) (ADVP (RB really)) (VP (VB know) (NP (PRP$ my) (NN job)) (ADVP (RB anymore))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="my job" type="NP">
          <tokens>
            <token id="7" string="my" />
            <token id="8" string="job" />
          </tokens>
        </chunking>
        <chunking id="2" string="know my job anymore" type="VP">
          <tokens>
            <token id="6" string="know" />
            <token id="7" string="my" />
            <token id="8" string="job" />
            <token id="9" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="3" string="do n't really know my job anymore" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="really" />
            <token id="6" string="know" />
            <token id="7" string="my" />
            <token id="8" string="job" />
            <token id="9" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="said" type="VP">
          <tokens>
            <token id="13" string="said" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="12" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">know</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">know</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">know</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">know</governor>
          <dependent id="5">really</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="6">know</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">job</governor>
          <dependent id="7">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">know</governor>
          <dependent id="8">job</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">know</governor>
          <dependent id="9">anymore</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>``It&amp;apost;s going to be hard getting back into the real world.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="getting" lemma="get" stem="get" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ 's) (VP (VBG going) (S (VP (TO to) (VP (VB be) (ADJP (JJ hard)) (S (VP (VBG getting) (ADVP (RB back)) (PP (IN into) (NP (DT the) (JJ real) (NN world)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="getting back into the real world" type="VP">
          <tokens>
            <token id="8" string="getting" />
            <token id="9" string="back" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="real" />
            <token id="13" string="world" />
          </tokens>
        </chunking>
        <chunking id="2" string="'s going to be hard getting back into the real world" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="hard" />
            <token id="8" string="getting" />
            <token id="9" string="back" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="real" />
            <token id="13" string="world" />
          </tokens>
        </chunking>
        <chunking id="3" string="going to be hard getting back into the real world" type="VP">
          <tokens>
            <token id="4" string="going" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="hard" />
            <token id="8" string="getting" />
            <token id="9" string="back" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="real" />
            <token id="13" string="world" />
          </tokens>
        </chunking>
        <chunking id="4" string="the real world" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="real" />
            <token id="13" string="world" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="hard" type="ADJP">
          <tokens>
            <token id="7" string="hard" />
          </tokens>
        </chunking>
        <chunking id="7" string="to be hard getting back into the real world" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="hard" />
            <token id="8" string="getting" />
            <token id="9" string="back" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="real" />
            <token id="13" string="world" />
          </tokens>
        </chunking>
        <chunking id="8" string="be hard getting back into the real world" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="hard" />
            <token id="8" string="getting" />
            <token id="9" string="back" />
            <token id="10" string="into" />
            <token id="11" string="the" />
            <token id="12" string="real" />
            <token id="13" string="world" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">going</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">going</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">hard</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">hard</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">going</governor>
          <dependent id="7">hard</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">hard</governor>
          <dependent id="8">getting</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">getting</governor>
          <dependent id="9">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">world</governor>
          <dependent id="10">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">world</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">world</governor>
          <dependent id="12">real</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">getting</governor>
          <dependent id="13">world</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>The jury foreman and four other jurors declined interviews.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="foreman" lemma="foreman" stem="foreman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="declined" lemma="decline" stem="declin" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN jury) (NN foreman)) (CC and) (NP (CD four) (JJ other) (NNS jurors))) (VP (VBD declined) (NP (NNS interviews))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The jury foreman and four other jurors" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="jury" />
            <token id="3" string="foreman" />
            <token id="4" string="and" />
            <token id="5" string="four" />
            <token id="6" string="other" />
            <token id="7" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="2" string="declined interviews" type="VP">
          <tokens>
            <token id="8" string="declined" />
            <token id="9" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="3" string="interviews" type="NP">
          <tokens>
            <token id="9" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="4" string="The jury foreman" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="jury" />
            <token id="3" string="foreman" />
          </tokens>
        </chunking>
        <chunking id="5" string="four other jurors" type="NP">
          <tokens>
            <token id="5" string="four" />
            <token id="6" string="other" />
            <token id="7" string="jurors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">foreman</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">foreman</governor>
          <dependent id="2">jury</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">declined</governor>
          <dependent id="3">foreman</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">foreman</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">jurors</governor>
          <dependent id="5">four</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">jurors</governor>
          <dependent id="6">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">foreman</governor>
          <dependent id="7">jurors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">declined</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">declined</governor>
          <dependent id="9">interviews</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="four" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="44-45-46-47" string="the family-run McMartin Pre-School" id_sentence="2" />
      <mentions>
        <mention ids_tokens="4-5" string="McMartin Pre-School" id_sentence="1" />
        <mention ids_tokens="29-31" string="the McMartin Pre-School" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7" string="the McMartin Pre-School molestation case" id_sentence="1" />
      <mentions>
        <mention ids_tokens="12-13" string="the case" id_sentence="30" />
        <mention ids_tokens="10-11" string="this case" id_sentence="34" />
        <mention ids_tokens="3" string="it" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20-21-22-23" string="a police department letter that inflamed parents" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2-4" string="The police letter" id_sentence="20" />
        <mention ids_tokens="2" string="It" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="20-21-22" string="Peggy McMartin Buckey" id_sentence="2" />
      <mentions>
        <mention ids_tokens="15-16" string="Buckey's" id_sentence="19" />
        <mention ids_tokens="7" string="Buckey" id_sentence="29" />
        <mention ids_tokens="9-10" string="a molester" id_sentence="29" />
        <mention ids_tokens="24" string="him" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="1" string="Jurors" id_sentence="5" />
      <mentions>
        <mention ids_tokens="1-28" string="Seven jurors who spoke with reporters in a joint news conference after acquitting Raymond Buckey and his mother , Peggy McMartin Buckey , on 52 molestation charges Thursday" id_sentence="2" />
        <mention ids_tokens="30" string="they" id_sentence="2" />
        <mention ids_tokens="2" string="they" id_sentence="3" />
        <mention ids_tokens="8" string="they" id_sentence="23" />
        <mention ids_tokens="9-10" string="the jurors" id_sentence="28" />
        <mention ids_tokens="3" string="they" id_sentence="30" />
        <mention ids_tokens="5-6" string="the jurors" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="19-20-21-22" string="Children 's Institute International" id_sentence="3" />
      <mentions>
        <mention ids_tokens="20" string="CII" id_sentence="6" />
        <mention ids_tokens="3" string="CII" id_sentence="7" />
        <mention ids_tokens="3" string="CII" id_sentence="9" />
        <mention ids_tokens="18" string="CII" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="8-9" string="their stories" id_sentence="15" />
      <mentions>
        <mention ids_tokens="10" string="stories" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="29-30" string="their parents" id_sentence="9" />
      <mentions>
        <mention ids_tokens="14-17" string="their parents and interviewers" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="4-5" string="the children" id_sentence="8" />
      <mentions>
        <mention ids_tokens="11-16" string="children , videotaped interviews with children" id_sentence="4" />
        <mention ids_tokens="11" string="children" id_sentence="4" />
        <mention ids_tokens="16" string="children" id_sentence="4" />
        <mention ids_tokens="21" string="children" id_sentence="5" />
        <mention ids_tokens="18" string="them" id_sentence="9" />
        <mention ids_tokens="25" string="they" id_sentence="9" />
        <mention ids_tokens="29" string="their" id_sentence="9" />
        <mention ids_tokens="17" string="them" id_sentence="10" />
        <mention ids_tokens="1" string="They" id_sentence="12" />
        <mention ids_tokens="10" string="their" id_sentence="13" />
        <mention ids_tokens="16" string="them" id_sentence="13" />
        <mention ids_tokens="1" string="They" id_sentence="15" />
        <mention ids_tokens="8" string="their" id_sentence="15" />
        <mention ids_tokens="26-27" string="children's" id_sentence="27" />
        <mention ids_tokens="25" string="they" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="18-19-20" string="the McMartin school" id_sentence="4" />
      <mentions>
        <mention ids_tokens="11-12" string="the school" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="7-8-9" string="juror Brenda Williams" id_sentence="6" />
      <mentions>
        <mention ids_tokens="6" string="I" id_sentence="7" />
        <mention ids_tokens="10" string="them" id_sentence="7" />
        <mention ids_tokens="13-14" string="Mrs. Williams" id_sentence="7" />
        <mention ids_tokens="2" string="I" id_sentence="8" />
        <mention ids_tokens="5" string="I" id_sentence="9" />
        <mention ids_tokens="13" string="I" id_sentence="10" />
        <mention ids_tokens="19" string="I" id_sentence="10" />
        <mention ids_tokens="31-32" string="Mrs. Williams" id_sentence="10" />
        <mention ids_tokens="8" string="me" id_sentence="11" />
        <mention ids_tokens="3" string="me" id_sentence="12" />
        <mention ids_tokens="21-22" string="Mrs. Williams" id_sentence="24" />
        <mention ids_tokens="9-10" string="Mrs. Williams" id_sentence="26" />
        <mention ids_tokens="4" string="you" id_sentence="31" />
        <mention ids_tokens="1-2" string="Mrs. Williams" id_sentence="39" />
        <mention ids_tokens="4" string="I" id_sentence="41" />
        <mention ids_tokens="3" string="themselves" id_sentence="42" />
        <mention ids_tokens="8" string="their" id_sentence="42" />
        <mention ids_tokens="1-2" string="Mrs. Williams" id_sentence="44" />
        <mention ids_tokens="10-17" string="Mrs. Williams , a telephone company service representative" id_sentence="46" />
        <mention ids_tokens="10-11" string="Mrs. Williams" id_sentence="46" />
        <mention ids_tokens="11" string="Williams" id_sentence="46" />
        <mention ids_tokens="13-17" string="a telephone company service representative" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15-16-17-18-19-20" string="the taped interviews from the center jurors call CII" id_sentence="6" />
      <mentions>
        <mention ids_tokens="2-4" string="The CII interviews" id_sentence="7" />
        <mention ids_tokens="11-12" string="the interviews" id_sentence="17" />
        <mention ids_tokens="9" string="interviews" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="13-14-15-16-17-18-19-20-21" string="Julie Peters , 47 , a supermarket meat wrapper" id_sentence="12" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="33" />
        <mention ids_tokens="11-12" string="Ms. Peters" id_sentence="33" />
        <mention ids_tokens="2" string="I" id_sentence="34" />
        <mention ids_tokens="1" string="I" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="14-15" string="John Breese" id_sentence="15" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="16" />
        <mention ids_tokens="14" string="I" id_sentence="17" />
        <mention ids_tokens="1" string="Breese" id_sentence="45" />
        <mention ids_tokens="3" string="his" id_sentence="45" />
        <mention ids_tokens="10" string="he" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22" string="a letter sent in 1983 by the Manhattan Beach Police Department to parents of McMartin school children" id_sentence="18" />
      <mentions>
        <mention ids_tokens="1-2" string="The letter" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="5-6" string="his parents" id_sentence="24" />
      <mentions>
        <mention ids_tokens="18-22" string="parents of McMartin school children" id_sentence="18" />
        <mention ids_tokens="4" string="parents" id_sentence="19" />
        <mention ids_tokens="10" string="parents" id_sentence="23" />
        <mention ids_tokens="16" string="their" id_sentence="23" />
        <mention ids_tokens="1-2" string="The parents" id_sentence="40" />
        <mention ids_tokens="7" string="that" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="20-21-22" string="McMartin school children" id_sentence="18" />
      <mentions>
        <mention ids_tokens="16-17" string="their children" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The panelists" id_sentence="25" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="26" />
        <mention ids_tokens="1" string="They" id_sentence="27" />
        <mention ids_tokens="10" string="them" id_sentence="27" />
        <mention ids_tokens="14" string="they" id_sentence="27" />
        <mention ids_tokens="19" string="they" id_sentence="27" />
        <mention ids_tokens="2" string="they" id_sentence="28" />
        <mention ids_tokens="4" string="they" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="20-21" string="these defendants" id_sentence="30" />
      <mentions>
        <mention ids_tokens="4-7" string="defendants of most charges" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="28" type="PROPER">
      <referenced ids_tokens="15-16" string="Mark Bassett" id_sentence="31" />
      <mentions>
        <mention ids_tokens="1" string="Bassett" id_sentence="43" />
        <mention ids_tokens="3" string="his" id_sentence="43" />
        <mention ids_tokens="11" string="his" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="8-9-10" string="the trial 's" id_sentence="32" />
      <mentions>
        <mention ids_tokens="7-8" string="the trial" id_sentence="45" />
        <mention ids_tokens="2" string="It" id_sentence="46" />
        <mention ids_tokens="12" string="it" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="30" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The defendants" id_sentence="36" />
      <mentions>
        <mention ids_tokens="14-20" string="defendants as well as children and parents" id_sentence="32" />
        <mention ids_tokens="1" string="They" id_sentence="37" />
        <mention ids_tokens="3" string="their" id_sentence="37" />
        <mention ids_tokens="6" string="their" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="32" type="NOMINAL">
      <referenced ids_tokens="3-4" string="their business" id_sentence="37" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="12" string="this" id_sentence="39" />
      <mentions>
        <mention ids_tokens="10" string="it" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="3-4" string="his job" id_sentence="43" />
      <mentions>
        <mention ids_tokens="7-8" string="my job" id_sentence="48" />
        <mention ids_tokens="2" string="It" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="35" type="NOMINAL">
      <referenced ids_tokens="3-4" string="his wife" id_sentence="45" />
      <mentions>
        <mention ids_tokens="6" string="I" id_sentence="47" />
        <mention ids_tokens="8" string="I" id_sentence="47" />
        <mention ids_tokens="2" string="I" id_sentence="48" />
        <mention ids_tokens="7" string="my" id_sentence="48" />
        <mention ids_tokens="12" string="she" id_sentence="48" />
      </mentions>
    </coreference>
  </coreferences>
</document>
