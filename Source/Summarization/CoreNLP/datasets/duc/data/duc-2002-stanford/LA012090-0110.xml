<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA012090-0110">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Though the historic McMartin Pre-School criminal trial finally has ended in acquittals, a host of civil lawsuits generated by the Manhattan Beach molestation case conceivably could keep the issue alive in the courts for decades, legal experts say.</content>
      <tokens>
        <token id="1" string="Though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="historic" lemma="historic" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="finally" lemma="finally" stem="final" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="ended" lemma="end" stem="end" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="acquittals" lemma="acquittal" stem="acquitt" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="host" lemma="host" stem="host" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="lawsuits" lemma="lawsuit" stem="lawsuit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="generated" lemma="generate" stem="gener" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="Manhattan" lemma="Manhattan" stem="manhattan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="23" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="24" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="25" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="conceivably" lemma="conceivably" stem="conceiv" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="keep" lemma="keep" stem="keep" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="alive" lemma="alive" stem="aliv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="courts" lemma="court" stem="court" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="decades" lemma="decade" stem="decad" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (SBAR (IN Though) (S (NP (DT the) (JJ historic) (NNP McMartin) (NNP Pre-School) (JJ criminal) (NN trial)) (ADVP (RB finally)) (VP (VBZ has) (VP (VBN ended) (PP (IN in) (NP (NNS acquittals))))))) (, ,) (NP (NP (DT a) (NN host)) (PP (IN of) (NP (NP (JJ civil) (NNS lawsuits)) (VP (VBN generated) (PP (IN by) (NP (DT the) (NNP Manhattan) (NNP Beach) (NN molestation) (NN case))))))) (ADVP (RB conceivably)) (VP (MD could) (VP (VB keep) (S (NP (DT the) (NN issue)) (ADJP (JJ alive) (PP (IN in) (NP (NP (DT the) (NNS courts)) (PP (IN for) (NP (NNS decades)))))))))) (, ,) (NP (JJ legal) (NNS experts)) (VP (VBP say)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="keep the issue alive in the courts for decades" type="VP">
          <tokens>
            <token id="28" string="keep" />
            <token id="29" string="the" />
            <token id="30" string="issue" />
            <token id="31" string="alive" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="courts" />
            <token id="35" string="for" />
            <token id="36" string="decades" />
          </tokens>
        </chunking>
        <chunking id="2" string="civil lawsuits generated by the Manhattan Beach molestation case" type="NP">
          <tokens>
            <token id="17" string="civil" />
            <token id="18" string="lawsuits" />
            <token id="19" string="generated" />
            <token id="20" string="by" />
            <token id="21" string="the" />
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
            <token id="24" string="molestation" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="civil lawsuits" type="NP">
          <tokens>
            <token id="17" string="civil" />
            <token id="18" string="lawsuits" />
          </tokens>
        </chunking>
        <chunking id="4" string="the issue" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="issue" />
          </tokens>
        </chunking>
        <chunking id="5" string="the courts" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="courts" />
          </tokens>
        </chunking>
        <chunking id="6" string="generated by the Manhattan Beach molestation case" type="VP">
          <tokens>
            <token id="19" string="generated" />
            <token id="20" string="by" />
            <token id="21" string="the" />
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
            <token id="24" string="molestation" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="could keep the issue alive in the courts for decades" type="VP">
          <tokens>
            <token id="27" string="could" />
            <token id="28" string="keep" />
            <token id="29" string="the" />
            <token id="30" string="issue" />
            <token id="31" string="alive" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="courts" />
            <token id="35" string="for" />
            <token id="36" string="decades" />
          </tokens>
        </chunking>
        <chunking id="8" string="Though the historic McMartin Pre-School criminal trial finally has ended in acquittals" type="SBAR">
          <tokens>
            <token id="1" string="Though" />
            <token id="2" string="the" />
            <token id="3" string="historic" />
            <token id="4" string="McMartin" />
            <token id="5" string="Pre-School" />
            <token id="6" string="criminal" />
            <token id="7" string="trial" />
            <token id="8" string="finally" />
            <token id="9" string="has" />
            <token id="10" string="ended" />
            <token id="11" string="in" />
            <token id="12" string="acquittals" />
          </tokens>
        </chunking>
        <chunking id="9" string="acquittals" type="NP">
          <tokens>
            <token id="12" string="acquittals" />
          </tokens>
        </chunking>
        <chunking id="10" string="has ended in acquittals" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="ended" />
            <token id="11" string="in" />
            <token id="12" string="acquittals" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Manhattan Beach molestation case" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
            <token id="24" string="molestation" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="12" string="say" type="VP">
          <tokens>
            <token id="40" string="say" />
          </tokens>
        </chunking>
        <chunking id="13" string="ended in acquittals" type="VP">
          <tokens>
            <token id="10" string="ended" />
            <token id="11" string="in" />
            <token id="12" string="acquittals" />
          </tokens>
        </chunking>
        <chunking id="14" string="legal experts" type="NP">
          <tokens>
            <token id="38" string="legal" />
            <token id="39" string="experts" />
          </tokens>
        </chunking>
        <chunking id="15" string="the courts for decades" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="courts" />
            <token id="35" string="for" />
            <token id="36" string="decades" />
          </tokens>
        </chunking>
        <chunking id="16" string="the historic McMartin Pre-School criminal trial" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="historic" />
            <token id="4" string="McMartin" />
            <token id="5" string="Pre-School" />
            <token id="6" string="criminal" />
            <token id="7" string="trial" />
          </tokens>
        </chunking>
        <chunking id="17" string="alive in the courts for decades" type="ADJP">
          <tokens>
            <token id="31" string="alive" />
            <token id="32" string="in" />
            <token id="33" string="the" />
            <token id="34" string="courts" />
            <token id="35" string="for" />
            <token id="36" string="decades" />
          </tokens>
        </chunking>
        <chunking id="18" string="decades" type="NP">
          <tokens>
            <token id="36" string="decades" />
          </tokens>
        </chunking>
        <chunking id="19" string="a host of civil lawsuits generated by the Manhattan Beach molestation case" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="host" />
            <token id="16" string="of" />
            <token id="17" string="civil" />
            <token id="18" string="lawsuits" />
            <token id="19" string="generated" />
            <token id="20" string="by" />
            <token id="21" string="the" />
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
            <token id="24" string="molestation" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="20" string="a host" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="host" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="10">ended</governor>
          <dependent id="1">Though</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">trial</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">trial</governor>
          <dependent id="3">historic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">trial</governor>
          <dependent id="4">McMartin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">trial</governor>
          <dependent id="5">Pre-School</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">trial</governor>
          <dependent id="6">criminal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">ended</governor>
          <dependent id="7">trial</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">ended</governor>
          <dependent id="8">finally</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">ended</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">keep</governor>
          <dependent id="10">ended</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">acquittals</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">ended</governor>
          <dependent id="12">acquittals</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">host</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">keep</governor>
          <dependent id="15">host</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">lawsuits</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">lawsuits</governor>
          <dependent id="17">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">host</governor>
          <dependent id="18">lawsuits</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">lawsuits</governor>
          <dependent id="19">generated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">case</governor>
          <dependent id="20">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">case</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">case</governor>
          <dependent id="22">Manhattan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">case</governor>
          <dependent id="23">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">case</governor>
          <dependent id="24">molestation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">generated</governor>
          <dependent id="25">case</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">keep</governor>
          <dependent id="26">conceivably</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">keep</governor>
          <dependent id="27">could</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="40">say</governor>
          <dependent id="28">keep</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">issue</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">alive</governor>
          <dependent id="30">issue</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">keep</governor>
          <dependent id="31">alive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">courts</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">courts</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">alive</governor>
          <dependent id="34">courts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">decades</governor>
          <dependent id="35">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">courts</governor>
          <dependent id="36">decades</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">experts</governor>
          <dependent id="38">legal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">say</governor>
          <dependent id="39">experts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="40">say</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McMartin Pre-School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="McMartin" />
            <token id="5" string="Pre-School" />
          </tokens>
        </entity>
        <entity id="2" string="decades" type="DURATION" score="0.0">
          <tokens>
            <token id="36" string="decades" />
          </tokens>
        </entity>
        <entity id="3" string="Manhattan Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>A confusing array of civil actions await resolution.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="confusing" lemma="confusing" stem="confus" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="array" lemma="array" stem="arrai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="actions" lemma="action" stem="action" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="await" lemma="await" stem="await" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="resolution" lemma="resolution" stem="resolut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (JJ confusing) (NN array)) (PP (IN of) (NP (JJ civil) (NNS actions)))) (VP (VBP await) (NP (NN resolution))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="await resolution" type="VP">
          <tokens>
            <token id="7" string="await" />
            <token id="8" string="resolution" />
          </tokens>
        </chunking>
        <chunking id="2" string="civil actions" type="NP">
          <tokens>
            <token id="5" string="civil" />
            <token id="6" string="actions" />
          </tokens>
        </chunking>
        <chunking id="3" string="A confusing array of civil actions" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="confusing" />
            <token id="3" string="array" />
            <token id="4" string="of" />
            <token id="5" string="civil" />
            <token id="6" string="actions" />
          </tokens>
        </chunking>
        <chunking id="4" string="resolution" type="NP">
          <tokens>
            <token id="8" string="resolution" />
          </tokens>
        </chunking>
        <chunking id="5" string="A confusing array" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="confusing" />
            <token id="3" string="array" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">array</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">array</governor>
          <dependent id="2">confusing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">await</governor>
          <dependent id="3">array</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">actions</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">actions</governor>
          <dependent id="5">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">array</governor>
          <dependent id="6">actions</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">await</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">await</governor>
          <dependent id="8">resolution</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>These include a federal civil rights suit filed Friday by Peggy McMartin Buckey against her accusers and others; a lawsuit filed by former defendants against a television station and reporter and suits the pre-school owners have filed against their liability insurance carriers.</content>
      <tokens>
        <token id="1" string="These" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="include" lemma="include" stem="includ" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="accusers" lemma="accuser" stem="accus" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="station" lemma="station" stem="station" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="reporter" lemma="reporter" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="suits" lemma="suit" stem="suit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="pre-school" lemma="pre-school" stem="pre-school" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="owners" lemma="owner" stem="owner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="liability" lemma="liability" stem="liabil" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="42" string="insurance" lemma="insurance" stem="insur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="carriers" lemma="carrier" stem="carrier" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT These)) (VP (VBP include) (NP (NP (NP (DT a) (JJ federal) (JJ civil) (NNS rights) (NN suit)) (VP (VBN filed) (NP-TMP (NNP Friday)) (PP (IN by) (NP (NP (NNP Peggy) (NNP McMartin) (NNP Buckey)) (PP (IN against) (NP (PRP$ her) (NNS accusers) (CC and) (NNS others))))))) (: ;) (NP (NP (DT a) (NN lawsuit)) (VP (VBN filed) (PP (IN by) (NP (NP (JJ former) (NNS defendants)) (PP (IN against) (NP (DT a) (NN television) (NN station) (CC and) (NN reporter) (CC and) (NNS suits)))))))))) (NP (DT the) (JJ pre-school) (NNS owners)) (VP (VBP have) (VP (VBN filed) (PP (IN against) (NP (PRP$ their) (NN liability) (NN insurance) (NNS carriers))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her accusers and others" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="accusers" />
            <token id="17" string="and" />
            <token id="18" string="others" />
          </tokens>
        </chunking>
        <chunking id="2" string="Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="11" string="Peggy" />
            <token id="12" string="McMartin" />
            <token id="13" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="3" string="a federal civil rights suit filed Friday by Peggy McMartin Buckey against her accusers and others" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="federal" />
            <token id="5" string="civil" />
            <token id="6" string="rights" />
            <token id="7" string="suit" />
            <token id="8" string="filed" />
            <token id="9" string="Friday" />
            <token id="10" string="by" />
            <token id="11" string="Peggy" />
            <token id="12" string="McMartin" />
            <token id="13" string="Buckey" />
            <token id="14" string="against" />
            <token id="15" string="her" />
            <token id="16" string="accusers" />
            <token id="17" string="and" />
            <token id="18" string="others" />
          </tokens>
        </chunking>
        <chunking id="4" string="Peggy McMartin Buckey against her accusers and others" type="NP">
          <tokens>
            <token id="11" string="Peggy" />
            <token id="12" string="McMartin" />
            <token id="13" string="Buckey" />
            <token id="14" string="against" />
            <token id="15" string="her" />
            <token id="16" string="accusers" />
            <token id="17" string="and" />
            <token id="18" string="others" />
          </tokens>
        </chunking>
        <chunking id="5" string="filed Friday by Peggy McMartin Buckey against her accusers and others" type="VP">
          <tokens>
            <token id="8" string="filed" />
            <token id="9" string="Friday" />
            <token id="10" string="by" />
            <token id="11" string="Peggy" />
            <token id="12" string="McMartin" />
            <token id="13" string="Buckey" />
            <token id="14" string="against" />
            <token id="15" string="her" />
            <token id="16" string="accusers" />
            <token id="17" string="and" />
            <token id="18" string="others" />
          </tokens>
        </chunking>
        <chunking id="6" string="former defendants" type="NP">
          <tokens>
            <token id="24" string="former" />
            <token id="25" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="7" string="have filed against their liability insurance carriers" type="VP">
          <tokens>
            <token id="37" string="have" />
            <token id="38" string="filed" />
            <token id="39" string="against" />
            <token id="40" string="their" />
            <token id="41" string="liability" />
            <token id="42" string="insurance" />
            <token id="43" string="carriers" />
          </tokens>
        </chunking>
        <chunking id="8" string="their liability insurance carriers" type="NP">
          <tokens>
            <token id="40" string="their" />
            <token id="41" string="liability" />
            <token id="42" string="insurance" />
            <token id="43" string="carriers" />
          </tokens>
        </chunking>
        <chunking id="9" string="a television station and reporter and suits" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="television" />
            <token id="29" string="station" />
            <token id="30" string="and" />
            <token id="31" string="reporter" />
            <token id="32" string="and" />
            <token id="33" string="suits" />
          </tokens>
        </chunking>
        <chunking id="10" string="a federal civil rights suit" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="federal" />
            <token id="5" string="civil" />
            <token id="6" string="rights" />
            <token id="7" string="suit" />
          </tokens>
        </chunking>
        <chunking id="11" string="filed by former defendants against a television station and reporter and suits" type="VP">
          <tokens>
            <token id="22" string="filed" />
            <token id="23" string="by" />
            <token id="24" string="former" />
            <token id="25" string="defendants" />
            <token id="26" string="against" />
            <token id="27" string="a" />
            <token id="28" string="television" />
            <token id="29" string="station" />
            <token id="30" string="and" />
            <token id="31" string="reporter" />
            <token id="32" string="and" />
            <token id="33" string="suits" />
          </tokens>
        </chunking>
        <chunking id="12" string="include a federal civil rights suit filed Friday by Peggy McMartin Buckey against her accusers and others ; a lawsuit filed by former defendants against a television station and reporter and suits" type="VP">
          <tokens>
            <token id="2" string="include" />
            <token id="3" string="a" />
            <token id="4" string="federal" />
            <token id="5" string="civil" />
            <token id="6" string="rights" />
            <token id="7" string="suit" />
            <token id="8" string="filed" />
            <token id="9" string="Friday" />
            <token id="10" string="by" />
            <token id="11" string="Peggy" />
            <token id="12" string="McMartin" />
            <token id="13" string="Buckey" />
            <token id="14" string="against" />
            <token id="15" string="her" />
            <token id="16" string="accusers" />
            <token id="17" string="and" />
            <token id="18" string="others" />
            <token id="19" string=";" />
            <token id="20" string="a" />
            <token id="21" string="lawsuit" />
            <token id="22" string="filed" />
            <token id="23" string="by" />
            <token id="24" string="former" />
            <token id="25" string="defendants" />
            <token id="26" string="against" />
            <token id="27" string="a" />
            <token id="28" string="television" />
            <token id="29" string="station" />
            <token id="30" string="and" />
            <token id="31" string="reporter" />
            <token id="32" string="and" />
            <token id="33" string="suits" />
          </tokens>
        </chunking>
        <chunking id="13" string="the pre-school owners" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="pre-school" />
            <token id="36" string="owners" />
          </tokens>
        </chunking>
        <chunking id="14" string="These" type="NP">
          <tokens>
            <token id="1" string="These" />
          </tokens>
        </chunking>
        <chunking id="15" string="a lawsuit" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="16" string="filed against their liability insurance carriers" type="VP">
          <tokens>
            <token id="38" string="filed" />
            <token id="39" string="against" />
            <token id="40" string="their" />
            <token id="41" string="liability" />
            <token id="42" string="insurance" />
            <token id="43" string="carriers" />
          </tokens>
        </chunking>
        <chunking id="17" string="a federal civil rights suit filed Friday by Peggy McMartin Buckey against her accusers and others ; a lawsuit filed by former defendants against a television station and reporter and suits" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="federal" />
            <token id="5" string="civil" />
            <token id="6" string="rights" />
            <token id="7" string="suit" />
            <token id="8" string="filed" />
            <token id="9" string="Friday" />
            <token id="10" string="by" />
            <token id="11" string="Peggy" />
            <token id="12" string="McMartin" />
            <token id="13" string="Buckey" />
            <token id="14" string="against" />
            <token id="15" string="her" />
            <token id="16" string="accusers" />
            <token id="17" string="and" />
            <token id="18" string="others" />
            <token id="19" string=";" />
            <token id="20" string="a" />
            <token id="21" string="lawsuit" />
            <token id="22" string="filed" />
            <token id="23" string="by" />
            <token id="24" string="former" />
            <token id="25" string="defendants" />
            <token id="26" string="against" />
            <token id="27" string="a" />
            <token id="28" string="television" />
            <token id="29" string="station" />
            <token id="30" string="and" />
            <token id="31" string="reporter" />
            <token id="32" string="and" />
            <token id="33" string="suits" />
          </tokens>
        </chunking>
        <chunking id="18" string="a lawsuit filed by former defendants against a television station and reporter and suits" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="lawsuit" />
            <token id="22" string="filed" />
            <token id="23" string="by" />
            <token id="24" string="former" />
            <token id="25" string="defendants" />
            <token id="26" string="against" />
            <token id="27" string="a" />
            <token id="28" string="television" />
            <token id="29" string="station" />
            <token id="30" string="and" />
            <token id="31" string="reporter" />
            <token id="32" string="and" />
            <token id="33" string="suits" />
          </tokens>
        </chunking>
        <chunking id="19" string="former defendants against a television station and reporter and suits" type="NP">
          <tokens>
            <token id="24" string="former" />
            <token id="25" string="defendants" />
            <token id="26" string="against" />
            <token id="27" string="a" />
            <token id="28" string="television" />
            <token id="29" string="station" />
            <token id="30" string="and" />
            <token id="31" string="reporter" />
            <token id="32" string="and" />
            <token id="33" string="suits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">include</governor>
          <dependent id="1">These</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="38">filed</governor>
          <dependent id="2">include</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">suit</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">suit</governor>
          <dependent id="4">federal</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">suit</governor>
          <dependent id="5">civil</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">suit</governor>
          <dependent id="6">rights</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">include</governor>
          <dependent id="7">suit</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">suit</governor>
          <dependent id="8">filed</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="8">filed</governor>
          <dependent id="9">Friday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Buckey</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Buckey</governor>
          <dependent id="11">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Buckey</governor>
          <dependent id="12">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">filed</governor>
          <dependent id="13">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">accusers</governor>
          <dependent id="14">against</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">accusers</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">Buckey</governor>
          <dependent id="16">accusers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">accusers</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">accusers</governor>
          <dependent id="18">others</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">lawsuit</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">suit</governor>
          <dependent id="21">lawsuit</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">lawsuit</governor>
          <dependent id="22">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">defendants</governor>
          <dependent id="23">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">defendants</governor>
          <dependent id="24">former</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">filed</governor>
          <dependent id="25">defendants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">station</governor>
          <dependent id="26">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">station</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">station</governor>
          <dependent id="28">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">defendants</governor>
          <dependent id="29">station</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">station</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">station</governor>
          <dependent id="31">reporter</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">station</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">station</governor>
          <dependent id="33">suits</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">owners</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">owners</governor>
          <dependent id="35">pre-school</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">filed</governor>
          <dependent id="36">owners</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="38">filed</governor>
          <dependent id="37">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="38">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">carriers</governor>
          <dependent id="39">against</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="43">carriers</governor>
          <dependent id="40">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">carriers</governor>
          <dependent id="41">liability</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="43">carriers</governor>
          <dependent id="42">insurance</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">filed</governor>
          <dependent id="43">carriers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Peggy" />
            <token id="12" string="McMartin" />
            <token id="13" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="Friday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Also, Ray Buckey might file a federal suit similar to that of his mother, said his attorney, Scott Bernstein.</content>
      <tokens>
        <token id="1" string="Also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="file" lemma="file" stem="file" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="federal" lemma="federal" stem="feder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Scott" lemma="Scott" stem="scott" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Bernstein" lemma="Bernstein" stem="bernstein" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (ADVP (RB Also)) (, ,) (NP (NNP Ray) (NNP Buckey)) (VP (MD might) (VP (VB file) (S (NP (DT a) (JJ federal) (NN suit)) (ADJP (JJ similar) (PP (TO to) (NP (NP (DT that)) (PP (IN of) (NP (PRP$ his) (NN mother)))))))))) (, ,) (VP (VBD said)) (NP (NP (PRP$ his) (NN attorney)) (, ,) (NP (NNP Scott) (NNP Bernstein))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="file a federal suit similar to that of his mother" type="VP">
          <tokens>
            <token id="6" string="file" />
            <token id="7" string="a" />
            <token id="8" string="federal" />
            <token id="9" string="suit" />
            <token id="10" string="similar" />
            <token id="11" string="to" />
            <token id="12" string="that" />
            <token id="13" string="of" />
            <token id="14" string="his" />
            <token id="15" string="mother" />
          </tokens>
        </chunking>
        <chunking id="2" string="that" type="NP">
          <tokens>
            <token id="12" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="similar to that of his mother" type="ADJP">
          <tokens>
            <token id="10" string="similar" />
            <token id="11" string="to" />
            <token id="12" string="that" />
            <token id="13" string="of" />
            <token id="14" string="his" />
            <token id="15" string="mother" />
          </tokens>
        </chunking>
        <chunking id="4" string="might file a federal suit similar to that of his mother" type="VP">
          <tokens>
            <token id="5" string="might" />
            <token id="6" string="file" />
            <token id="7" string="a" />
            <token id="8" string="federal" />
            <token id="9" string="suit" />
            <token id="10" string="similar" />
            <token id="11" string="to" />
            <token id="12" string="that" />
            <token id="13" string="of" />
            <token id="14" string="his" />
            <token id="15" string="mother" />
          </tokens>
        </chunking>
        <chunking id="5" string="his attorney" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="6" string="his mother" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="mother" />
          </tokens>
        </chunking>
        <chunking id="7" string="Ray Buckey" type="NP">
          <tokens>
            <token id="3" string="Ray" />
            <token id="4" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="8" string="a federal suit" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="federal" />
            <token id="9" string="suit" />
          </tokens>
        </chunking>
        <chunking id="9" string="that of his mother" type="NP">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="of" />
            <token id="14" string="his" />
            <token id="15" string="mother" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="17" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="his attorney , Scott Bernstein" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="attorney" />
            <token id="20" string="," />
            <token id="21" string="Scott" />
            <token id="22" string="Bernstein" />
          </tokens>
        </chunking>
        <chunking id="12" string="Scott Bernstein" type="NP">
          <tokens>
            <token id="21" string="Scott" />
            <token id="22" string="Bernstein" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">file</governor>
          <dependent id="1">Also</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Buckey</governor>
          <dependent id="3">Ray</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">file</governor>
          <dependent id="4">Buckey</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">file</governor>
          <dependent id="5">might</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="6">file</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">suit</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">suit</governor>
          <dependent id="8">federal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">similar</governor>
          <dependent id="9">suit</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">file</governor>
          <dependent id="10">similar</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">that</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">similar</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">mother</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">mother</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">that</governor>
          <dependent id="15">mother</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">attorney</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="19">attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Bernstein</governor>
          <dependent id="21">Scott</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="19">attorney</governor>
          <dependent id="22">Bernstein</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ray Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Ray" />
            <token id="4" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Scott Bernstein" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Scott" />
            <token id="22" string="Bernstein" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>And an attorney representing several parents of McMartin attendees said they might now refile lawsuits against the pre-school for emotional distress allegedly suffered by the children.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="representing" lemma="represent" stem="repres" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="attendees" lemma="attendee" stem="attende" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="refile" lemma="refile" stem="refil" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="lawsuits" lemma="lawsuit" stem="lawsuit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="pre-school" lemma="pre-school" stem="pre-school" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="emotional" lemma="emotional" stem="emot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="distress" lemma="distress" stem="distress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="allegedly" lemma="allegedly" stem="allegedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="suffered" lemma="suffer" stem="suffer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (DT an) (NN attorney)) (VP (VBG representing) (NP (NP (JJ several) (NNS parents)) (PP (IN of) (NP (NNP McMartin) (NNS attendees)))))) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (MD might) (ADVP (RB now)) (VP (VB refile) (NP (NP (NNS lawsuits)) (PP (IN against) (NP (DT the) (JJ pre-school)))) (PP (IN for) (NP (NP (JJ emotional) (NN distress)) (VP (ADVP (RB allegedly)) (VBN suffered) (PP (IN by) (NP (DT the) (NNS children))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="emotional distress allegedly suffered by the children" type="NP">
          <tokens>
            <token id="20" string="emotional" />
            <token id="21" string="distress" />
            <token id="22" string="allegedly" />
            <token id="23" string="suffered" />
            <token id="24" string="by" />
            <token id="25" string="the" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="2" string="lawsuits against the pre-school" type="NP">
          <tokens>
            <token id="15" string="lawsuits" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="pre-school" />
          </tokens>
        </chunking>
        <chunking id="3" string="emotional distress" type="NP">
          <tokens>
            <token id="20" string="emotional" />
            <token id="21" string="distress" />
          </tokens>
        </chunking>
        <chunking id="4" string="several parents of McMartin attendees" type="NP">
          <tokens>
            <token id="5" string="several" />
            <token id="6" string="parents" />
            <token id="7" string="of" />
            <token id="8" string="McMartin" />
            <token id="9" string="attendees" />
          </tokens>
        </chunking>
        <chunking id="5" string="allegedly suffered by the children" type="VP">
          <tokens>
            <token id="22" string="allegedly" />
            <token id="23" string="suffered" />
            <token id="24" string="by" />
            <token id="25" string="the" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="they might now refile lawsuits against the pre-school for emotional distress allegedly suffered by the children" type="SBAR">
          <tokens>
            <token id="11" string="they" />
            <token id="12" string="might" />
            <token id="13" string="now" />
            <token id="14" string="refile" />
            <token id="15" string="lawsuits" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="pre-school" />
            <token id="19" string="for" />
            <token id="20" string="emotional" />
            <token id="21" string="distress" />
            <token id="22" string="allegedly" />
            <token id="23" string="suffered" />
            <token id="24" string="by" />
            <token id="25" string="the" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="McMartin attendees" type="NP">
          <tokens>
            <token id="8" string="McMartin" />
            <token id="9" string="attendees" />
          </tokens>
        </chunking>
        <chunking id="8" string="refile lawsuits against the pre-school for emotional distress allegedly suffered by the children" type="VP">
          <tokens>
            <token id="14" string="refile" />
            <token id="15" string="lawsuits" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="pre-school" />
            <token id="19" string="for" />
            <token id="20" string="emotional" />
            <token id="21" string="distress" />
            <token id="22" string="allegedly" />
            <token id="23" string="suffered" />
            <token id="24" string="by" />
            <token id="25" string="the" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="11" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="an attorney representing several parents of McMartin attendees" type="NP">
          <tokens>
            <token id="2" string="an" />
            <token id="3" string="attorney" />
            <token id="4" string="representing" />
            <token id="5" string="several" />
            <token id="6" string="parents" />
            <token id="7" string="of" />
            <token id="8" string="McMartin" />
            <token id="9" string="attendees" />
          </tokens>
        </chunking>
        <chunking id="11" string="said they might now refile lawsuits against the pre-school for emotional distress allegedly suffered by the children" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="they" />
            <token id="12" string="might" />
            <token id="13" string="now" />
            <token id="14" string="refile" />
            <token id="15" string="lawsuits" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="pre-school" />
            <token id="19" string="for" />
            <token id="20" string="emotional" />
            <token id="21" string="distress" />
            <token id="22" string="allegedly" />
            <token id="23" string="suffered" />
            <token id="24" string="by" />
            <token id="25" string="the" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="lawsuits" type="NP">
          <tokens>
            <token id="15" string="lawsuits" />
          </tokens>
        </chunking>
        <chunking id="13" string="the children" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="14" string="several parents" type="NP">
          <tokens>
            <token id="5" string="several" />
            <token id="6" string="parents" />
          </tokens>
        </chunking>
        <chunking id="15" string="representing several parents of McMartin attendees" type="VP">
          <tokens>
            <token id="4" string="representing" />
            <token id="5" string="several" />
            <token id="6" string="parents" />
            <token id="7" string="of" />
            <token id="8" string="McMartin" />
            <token id="9" string="attendees" />
          </tokens>
        </chunking>
        <chunking id="16" string="an attorney" type="NP">
          <tokens>
            <token id="2" string="an" />
            <token id="3" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="17" string="might now refile lawsuits against the pre-school for emotional distress allegedly suffered by the children" type="VP">
          <tokens>
            <token id="12" string="might" />
            <token id="13" string="now" />
            <token id="14" string="refile" />
            <token id="15" string="lawsuits" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="pre-school" />
            <token id="19" string="for" />
            <token id="20" string="emotional" />
            <token id="21" string="distress" />
            <token id="22" string="allegedly" />
            <token id="23" string="suffered" />
            <token id="24" string="by" />
            <token id="25" string="the" />
            <token id="26" string="children" />
          </tokens>
        </chunking>
        <chunking id="18" string="the pre-school" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="pre-school" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="10">said</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">attorney</governor>
          <dependent id="2">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="3">attorney</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">attorney</governor>
          <dependent id="4">representing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">parents</governor>
          <dependent id="5">several</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">representing</governor>
          <dependent id="6">parents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">attendees</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">attendees</governor>
          <dependent id="8">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">parents</governor>
          <dependent id="9">attendees</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">refile</governor>
          <dependent id="11">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">refile</governor>
          <dependent id="12">might</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">refile</governor>
          <dependent id="13">now</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="14">refile</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">refile</governor>
          <dependent id="15">lawsuits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">pre-school</governor>
          <dependent id="16">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">pre-school</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">lawsuits</governor>
          <dependent id="18">pre-school</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">distress</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">distress</governor>
          <dependent id="20">emotional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">refile</governor>
          <dependent id="21">distress</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">suffered</governor>
          <dependent id="22">allegedly</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">distress</governor>
          <dependent id="23">suffered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">children</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">children</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">suffered</governor>
          <dependent id="26">children</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="McMartin" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="McMartin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>&amp;quot;I&amp;apost;m convinced this case will never end,&amp;quot; Eli Gauna, who represents Babette Spitler, a former teacher at the school, said wearily.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="convinced" lemma="convinced" stem="convinc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="end" lemma="end" stem="end" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Eli" lemma="Eli" stem="eli" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Gauna" lemma="Gauna" stem="gauna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="represents" lemma="represent" stem="repres" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Babette" lemma="Babette" stem="babett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Spitler" lemma="Spitler" stem="spitler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="teacher" lemma="teacher" stem="teacher" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="wearily" lemma="wearily" stem="wearili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ convinced) (SBAR (S (NP (DT this) (NN case)) (VP (MD will) (ADVP (RB never)) (VP (VB end)))))))) (, ,) ('' '') (NP (NP (NNP Eli) (NNP Gauna)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ represents) (NP (NP (NNP Babette) (NNP Spitler)) (, ,) (NP (NP (DT a) (JJ former) (NN teacher)) (PP (IN at) (NP (DT the) (NN school)))))))) (, ,)) (VP (VBD said) (ADVP (RB wearily))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Eli Gauna , who represents Babette Spitler , a former teacher at the school ," type="NP">
          <tokens>
            <token id="12" string="Eli" />
            <token id="13" string="Gauna" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="represents" />
            <token id="17" string="Babette" />
            <token id="18" string="Spitler" />
            <token id="19" string="," />
            <token id="20" string="a" />
            <token id="21" string="former" />
            <token id="22" string="teacher" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
            <token id="26" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="convinced this case will never end" type="ADJP">
          <tokens>
            <token id="4" string="convinced" />
            <token id="5" string="this" />
            <token id="6" string="case" />
            <token id="7" string="will" />
            <token id="8" string="never" />
            <token id="9" string="end" />
          </tokens>
        </chunking>
        <chunking id="3" string="will never end" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="never" />
            <token id="9" string="end" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="this case" type="NP">
          <tokens>
            <token id="5" string="this" />
            <token id="6" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="a former teacher at the school" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="former" />
            <token id="22" string="teacher" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="7" string="represents Babette Spitler , a former teacher at the school" type="VP">
          <tokens>
            <token id="16" string="represents" />
            <token id="17" string="Babette" />
            <token id="18" string="Spitler" />
            <token id="19" string="," />
            <token id="20" string="a" />
            <token id="21" string="former" />
            <token id="22" string="teacher" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="8" string="the school" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="9" string="who represents Babette Spitler , a former teacher at the school" type="SBAR">
          <tokens>
            <token id="15" string="who" />
            <token id="16" string="represents" />
            <token id="17" string="Babette" />
            <token id="18" string="Spitler" />
            <token id="19" string="," />
            <token id="20" string="a" />
            <token id="21" string="former" />
            <token id="22" string="teacher" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="10" string="a former teacher" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="former" />
            <token id="22" string="teacher" />
          </tokens>
        </chunking>
        <chunking id="11" string="Babette Spitler , a former teacher at the school" type="NP">
          <tokens>
            <token id="17" string="Babette" />
            <token id="18" string="Spitler" />
            <token id="19" string="," />
            <token id="20" string="a" />
            <token id="21" string="former" />
            <token id="22" string="teacher" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="12" string="'m convinced this case will never end" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="convinced" />
            <token id="5" string="this" />
            <token id="6" string="case" />
            <token id="7" string="will" />
            <token id="8" string="never" />
            <token id="9" string="end" />
          </tokens>
        </chunking>
        <chunking id="13" string="Babette Spitler" type="NP">
          <tokens>
            <token id="17" string="Babette" />
            <token id="18" string="Spitler" />
          </tokens>
        </chunking>
        <chunking id="14" string="end" type="VP">
          <tokens>
            <token id="9" string="end" />
          </tokens>
        </chunking>
        <chunking id="15" string="this case will never end" type="SBAR">
          <tokens>
            <token id="5" string="this" />
            <token id="6" string="case" />
            <token id="7" string="will" />
            <token id="8" string="never" />
            <token id="9" string="end" />
          </tokens>
        </chunking>
        <chunking id="16" string="Eli Gauna" type="NP">
          <tokens>
            <token id="12" string="Eli" />
            <token id="13" string="Gauna" />
          </tokens>
        </chunking>
        <chunking id="17" string="said wearily" type="VP">
          <tokens>
            <token id="27" string="said" />
            <token id="28" string="wearily" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">convinced</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">convinced</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">said</governor>
          <dependent id="4">convinced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">case</governor>
          <dependent id="5">this</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">end</governor>
          <dependent id="6">case</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">end</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">end</governor>
          <dependent id="8">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">convinced</governor>
          <dependent id="9">end</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Gauna</governor>
          <dependent id="12">Eli</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">said</governor>
          <dependent id="13">Gauna</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">represents</governor>
          <dependent id="15">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">Gauna</governor>
          <dependent id="16">represents</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Spitler</governor>
          <dependent id="17">Babette</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">represents</governor>
          <dependent id="18">Spitler</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">teacher</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">teacher</governor>
          <dependent id="21">former</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Spitler</governor>
          <dependent id="22">teacher</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">school</governor>
          <dependent id="23">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">school</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">teacher</governor>
          <dependent id="25">school</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">said</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">said</governor>
          <dependent id="28">wearily</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Babette Spitler" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Babette" />
            <token id="18" string="Spitler" />
          </tokens>
        </entity>
        <entity id="2" string="Eli Gauna" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Eli" />
            <token id="13" string="Gauna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>&amp;quot;It will always be there, until everyone who was ever involved gets to old age or dies.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="involved" lemma="involve" stem="involv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="gets" lemma="get" stem="get" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="age" lemma="age" stem="ag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="dies" lemma="die" stem="di" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (MD will) (ADVP (RB always)) (VP (VB be) (ADVP (RB there)) (, ,) (SBAR (IN until) (S (NP (NP (NN everyone)) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (ADVP (RB ever)) (VBN involved)))))) (VP (VP (VBZ gets) (PP (TO to) (NP (JJ old) (NN age)))) (CC or) (VP (VBZ dies))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="be there , until everyone who was ever involved gets to old age or dies" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="there" />
            <token id="7" string="," />
            <token id="8" string="until" />
            <token id="9" string="everyone" />
            <token id="10" string="who" />
            <token id="11" string="was" />
            <token id="12" string="ever" />
            <token id="13" string="involved" />
            <token id="14" string="gets" />
            <token id="15" string="to" />
            <token id="16" string="old" />
            <token id="17" string="age" />
            <token id="18" string="or" />
            <token id="19" string="dies" />
          </tokens>
        </chunking>
        <chunking id="2" string="everyone" type="NP">
          <tokens>
            <token id="9" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="ever involved" type="VP">
          <tokens>
            <token id="12" string="ever" />
            <token id="13" string="involved" />
          </tokens>
        </chunking>
        <chunking id="5" string="who was ever involved" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="was" />
            <token id="12" string="ever" />
            <token id="13" string="involved" />
          </tokens>
        </chunking>
        <chunking id="6" string="gets to old age or dies" type="VP">
          <tokens>
            <token id="14" string="gets" />
            <token id="15" string="to" />
            <token id="16" string="old" />
            <token id="17" string="age" />
            <token id="18" string="or" />
            <token id="19" string="dies" />
          </tokens>
        </chunking>
        <chunking id="7" string="old age" type="NP">
          <tokens>
            <token id="16" string="old" />
            <token id="17" string="age" />
          </tokens>
        </chunking>
        <chunking id="8" string="gets to old age" type="VP">
          <tokens>
            <token id="14" string="gets" />
            <token id="15" string="to" />
            <token id="16" string="old" />
            <token id="17" string="age" />
          </tokens>
        </chunking>
        <chunking id="9" string="was ever involved" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="ever" />
            <token id="13" string="involved" />
          </tokens>
        </chunking>
        <chunking id="10" string="everyone who was ever involved" type="NP">
          <tokens>
            <token id="9" string="everyone" />
            <token id="10" string="who" />
            <token id="11" string="was" />
            <token id="12" string="ever" />
            <token id="13" string="involved" />
          </tokens>
        </chunking>
        <chunking id="11" string="will always be there , until everyone who was ever involved gets to old age or dies" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="always" />
            <token id="5" string="be" />
            <token id="6" string="there" />
            <token id="7" string="," />
            <token id="8" string="until" />
            <token id="9" string="everyone" />
            <token id="10" string="who" />
            <token id="11" string="was" />
            <token id="12" string="ever" />
            <token id="13" string="involved" />
            <token id="14" string="gets" />
            <token id="15" string="to" />
            <token id="16" string="old" />
            <token id="17" string="age" />
            <token id="18" string="or" />
            <token id="19" string="dies" />
          </tokens>
        </chunking>
        <chunking id="12" string="dies" type="VP">
          <tokens>
            <token id="19" string="dies" />
          </tokens>
        </chunking>
        <chunking id="13" string="until everyone who was ever involved gets to old age or dies" type="SBAR">
          <tokens>
            <token id="8" string="until" />
            <token id="9" string="everyone" />
            <token id="10" string="who" />
            <token id="11" string="was" />
            <token id="12" string="ever" />
            <token id="13" string="involved" />
            <token id="14" string="gets" />
            <token id="15" string="to" />
            <token id="16" string="old" />
            <token id="17" string="age" />
            <token id="18" string="or" />
            <token id="19" string="dies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">be</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">be</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">be</governor>
          <dependent id="4">always</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">be</governor>
          <dependent id="6">there</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">gets</governor>
          <dependent id="8">until</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">gets</governor>
          <dependent id="9">everyone</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">involved</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">involved</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">involved</governor>
          <dependent id="12">ever</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">everyone</governor>
          <dependent id="13">involved</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">be</governor>
          <dependent id="14">gets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">age</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">age</governor>
          <dependent id="16">old</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">gets</governor>
          <dependent id="17">age</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">gets</governor>
          <dependent id="18">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">gets</governor>
          <dependent id="19">dies</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>In the criminal case -- the longest and costliest criminal proceeding in U.S. history -- Ray Buckey, 31, and his mother Peggy McMartin Buckey, 63, were acquitted Thursday of 52 counts of molestation involving 11 youngsters who attended the family nursery school in Manhattan Beach.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="longest" lemma="longest" stem="longest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="costliest" lemma="costliest" stem="costliest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="proceeding" lemma="proceeding" stem="proceed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="14" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="31" lemma="31" stem="31" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="63" lemma="63" stem="63" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="acquitted" lemma="acquit" stem="acquit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="52" lemma="52" stem="52" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="35" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="involving" lemma="involve" stem="involv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="40" string="youngsters" lemma="youngster" stem="youngster" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="attended" lemma="attend" stem="attend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="nursery" lemma="nursery" stem="nurseri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="Manhattan" lemma="Manhattan" stem="manhattan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="49" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="50" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT the) (JJ criminal) (NN case)) (: --) (NP (NP (DT the) (JJS longest) (CC and) (JJS costliest)) (NP (NP (JJ criminal) (NN proceeding)) (PP (IN in) (NP (NNP U.S.) (NN history))))) (: --) (NP (NNP Ray) (NNP Buckey)) (, ,) (NP (CD 31)) (, ,) (CC and) (NP (PRP$ his) (NN mother)))) (NP (NP (NNP Peggy) (NNP McMartin) (NNP Buckey)) (, ,) (NP (CD 63)) (, ,)) (VP (VBD were) (VP (VBN acquitted) (NP-TMP (NNP Thursday)) (PP (IN of) (NP (NP (CD 52) (NNS counts)) (PP (IN of) (NP (NN molestation))))) (PP (VBG involving) (NP (NP (CD 11) (NNS youngsters)) (SBAR (WHNP (WP who)) (S (VP (VBD attended) (NP (DT the) (NN family) (NN nursery) (NN school)) (PP (IN in) (NP (NNP Manhattan) (NNP Beach)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="24" string="Peggy" />
            <token id="25" string="McMartin" />
            <token id="26" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="molestation" type="NP">
          <tokens>
            <token id="37" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="3" string="criminal proceeding" type="NP">
          <tokens>
            <token id="10" string="criminal" />
            <token id="11" string="proceeding" />
          </tokens>
        </chunking>
        <chunking id="4" string="52 counts" type="NP">
          <tokens>
            <token id="34" string="52" />
            <token id="35" string="counts" />
          </tokens>
        </chunking>
        <chunking id="5" string="attended the family nursery school in Manhattan Beach" type="VP">
          <tokens>
            <token id="42" string="attended" />
            <token id="43" string="the" />
            <token id="44" string="family" />
            <token id="45" string="nursery" />
            <token id="46" string="school" />
            <token id="47" string="in" />
            <token id="48" string="Manhattan" />
            <token id="49" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ray Buckey" type="NP">
          <tokens>
            <token id="16" string="Ray" />
            <token id="17" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="7" string="11 youngsters who attended the family nursery school in Manhattan Beach" type="NP">
          <tokens>
            <token id="39" string="11" />
            <token id="40" string="youngsters" />
            <token id="41" string="who" />
            <token id="42" string="attended" />
            <token id="43" string="the" />
            <token id="44" string="family" />
            <token id="45" string="nursery" />
            <token id="46" string="school" />
            <token id="47" string="in" />
            <token id="48" string="Manhattan" />
            <token id="49" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="8" string="who attended the family nursery school in Manhattan Beach" type="SBAR">
          <tokens>
            <token id="41" string="who" />
            <token id="42" string="attended" />
            <token id="43" string="the" />
            <token id="44" string="family" />
            <token id="45" string="nursery" />
            <token id="46" string="school" />
            <token id="47" string="in" />
            <token id="48" string="Manhattan" />
            <token id="49" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="9" string="the family nursery school" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="family" />
            <token id="45" string="nursery" />
            <token id="46" string="school" />
          </tokens>
        </chunking>
        <chunking id="10" string="U.S. history" type="NP">
          <tokens>
            <token id="13" string="U.S." />
            <token id="14" string="history" />
          </tokens>
        </chunking>
        <chunking id="11" string="the criminal case -- the longest and costliest criminal proceeding in U.S. history -- Ray Buckey , 31 , and his mother" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="criminal" />
            <token id="4" string="case" />
            <token id="5" string="--" />
            <token id="6" string="the" />
            <token id="7" string="longest" />
            <token id="8" string="and" />
            <token id="9" string="costliest" />
            <token id="10" string="criminal" />
            <token id="11" string="proceeding" />
            <token id="12" string="in" />
            <token id="13" string="U.S." />
            <token id="14" string="history" />
            <token id="15" string="--" />
            <token id="16" string="Ray" />
            <token id="17" string="Buckey" />
            <token id="18" string="," />
            <token id="19" string="31" />
            <token id="20" string="," />
            <token id="21" string="and" />
            <token id="22" string="his" />
            <token id="23" string="mother" />
          </tokens>
        </chunking>
        <chunking id="12" string="acquitted Thursday of 52 counts of molestation involving 11 youngsters who attended the family nursery school in Manhattan Beach" type="VP">
          <tokens>
            <token id="31" string="acquitted" />
            <token id="32" string="Thursday" />
            <token id="33" string="of" />
            <token id="34" string="52" />
            <token id="35" string="counts" />
            <token id="36" string="of" />
            <token id="37" string="molestation" />
            <token id="38" string="involving" />
            <token id="39" string="11" />
            <token id="40" string="youngsters" />
            <token id="41" string="who" />
            <token id="42" string="attended" />
            <token id="43" string="the" />
            <token id="44" string="family" />
            <token id="45" string="nursery" />
            <token id="46" string="school" />
            <token id="47" string="in" />
            <token id="48" string="Manhattan" />
            <token id="49" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="13" string="the criminal case" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="criminal" />
            <token id="4" string="case" />
          </tokens>
        </chunking>
        <chunking id="14" string="were acquitted Thursday of 52 counts of molestation involving 11 youngsters who attended the family nursery school in Manhattan Beach" type="VP">
          <tokens>
            <token id="30" string="were" />
            <token id="31" string="acquitted" />
            <token id="32" string="Thursday" />
            <token id="33" string="of" />
            <token id="34" string="52" />
            <token id="35" string="counts" />
            <token id="36" string="of" />
            <token id="37" string="molestation" />
            <token id="38" string="involving" />
            <token id="39" string="11" />
            <token id="40" string="youngsters" />
            <token id="41" string="who" />
            <token id="42" string="attended" />
            <token id="43" string="the" />
            <token id="44" string="family" />
            <token id="45" string="nursery" />
            <token id="46" string="school" />
            <token id="47" string="in" />
            <token id="48" string="Manhattan" />
            <token id="49" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="15" string="the longest and costliest criminal proceeding in U.S. history" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="longest" />
            <token id="8" string="and" />
            <token id="9" string="costliest" />
            <token id="10" string="criminal" />
            <token id="11" string="proceeding" />
            <token id="12" string="in" />
            <token id="13" string="U.S." />
            <token id="14" string="history" />
          </tokens>
        </chunking>
        <chunking id="16" string="his mother" type="NP">
          <tokens>
            <token id="22" string="his" />
            <token id="23" string="mother" />
          </tokens>
        </chunking>
        <chunking id="17" string="Peggy McMartin Buckey , 63 ," type="NP">
          <tokens>
            <token id="24" string="Peggy" />
            <token id="25" string="McMartin" />
            <token id="26" string="Buckey" />
            <token id="27" string="," />
            <token id="28" string="63" />
            <token id="29" string="," />
          </tokens>
        </chunking>
        <chunking id="18" string="63" type="NP">
          <tokens>
            <token id="28" string="63" />
          </tokens>
        </chunking>
        <chunking id="19" string="52 counts of molestation" type="NP">
          <tokens>
            <token id="34" string="52" />
            <token id="35" string="counts" />
            <token id="36" string="of" />
            <token id="37" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="20" string="31" type="NP">
          <tokens>
            <token id="19" string="31" />
          </tokens>
        </chunking>
        <chunking id="21" string="the longest and costliest" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="longest" />
            <token id="8" string="and" />
            <token id="9" string="costliest" />
          </tokens>
        </chunking>
        <chunking id="22" string="criminal proceeding in U.S. history" type="NP">
          <tokens>
            <token id="10" string="criminal" />
            <token id="11" string="proceeding" />
            <token id="12" string="in" />
            <token id="13" string="U.S." />
            <token id="14" string="history" />
          </tokens>
        </chunking>
        <chunking id="23" string="11 youngsters" type="NP">
          <tokens>
            <token id="39" string="11" />
            <token id="40" string="youngsters" />
          </tokens>
        </chunking>
        <chunking id="24" string="Manhattan Beach" type="NP">
          <tokens>
            <token id="48" string="Manhattan" />
            <token id="49" string="Beach" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">case</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">case</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">case</governor>
          <dependent id="3">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">acquitted</governor>
          <dependent id="4">case</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">longest</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">case</governor>
          <dependent id="7">longest</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">longest</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">longest</governor>
          <dependent id="9">costliest</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">proceeding</governor>
          <dependent id="10">criminal</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">longest</governor>
          <dependent id="11">proceeding</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">history</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">history</governor>
          <dependent id="13">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">proceeding</governor>
          <dependent id="14">history</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Buckey</governor>
          <dependent id="16">Ray</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">case</governor>
          <dependent id="17">Buckey</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">case</governor>
          <dependent id="19">31</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">case</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">mother</governor>
          <dependent id="22">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">case</governor>
          <dependent id="23">mother</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Buckey</governor>
          <dependent id="24">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Buckey</governor>
          <dependent id="25">McMartin</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">acquitted</governor>
          <dependent id="26">Buckey</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">Buckey</governor>
          <dependent id="28">63</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">acquitted</governor>
          <dependent id="30">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">acquitted</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="31">acquitted</governor>
          <dependent id="32">Thursday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">counts</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="35">counts</governor>
          <dependent id="34">52</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">acquitted</governor>
          <dependent id="35">counts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">molestation</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">counts</governor>
          <dependent id="37">molestation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">youngsters</governor>
          <dependent id="38">involving</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="40">youngsters</governor>
          <dependent id="39">11</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">acquitted</governor>
          <dependent id="40">youngsters</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">attended</governor>
          <dependent id="41">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="40">youngsters</governor>
          <dependent id="42">attended</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">school</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="46">school</governor>
          <dependent id="44">family</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="46">school</governor>
          <dependent id="45">nursery</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="42">attended</governor>
          <dependent id="46">school</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">Beach</governor>
          <dependent id="47">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="49">Beach</governor>
          <dependent id="48">Manhattan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="42">attended</governor>
          <dependent id="49">Beach</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Peggy" />
            <token id="25" string="McMartin" />
            <token id="26" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="U.S." />
          </tokens>
        </entity>
        <entity id="3" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="Thursday" />
          </tokens>
        </entity>
        <entity id="4" string="63" type="NUMBER" score="0.0">
          <tokens>
            <token id="28" string="63" />
          </tokens>
        </entity>
        <entity id="5" string="52" type="NUMBER" score="0.0">
          <tokens>
            <token id="34" string="52" />
          </tokens>
        </entity>
        <entity id="6" string="Ray Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Ray" />
            <token id="17" string="Buckey" />
          </tokens>
        </entity>
        <entity id="7" string="31" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="31" />
          </tokens>
        </entity>
        <entity id="8" string="11" type="NUMBER" score="0.0">
          <tokens>
            <token id="39" string="11" />
          </tokens>
        </entity>
        <entity id="9" string="Manhattan Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="48" string="Manhattan" />
            <token id="49" string="Beach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>The jury deadlocked on 13 remaining counts, and a mistrial was declared on those allegations.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="deadlocked" lemma="deadlock" stem="deadlock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="6" string="remaining" lemma="remain" stem="remain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="mistrial" lemma="mistrial" stem="mistrial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="declared" lemma="declare" stem="declar" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN jury)) (VP (VBN deadlocked) (PP (IN on) (NP (NP (CD 13) (VBG remaining) (NNS counts)) (, ,) (CC and) (NP (DT a) (NN mistrial)))))) (VP (VBD was) (VP (VBN declared) (PP (IN on) (NP (DT those) (NNS allegations))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="13 remaining counts" type="NP">
          <tokens>
            <token id="5" string="13" />
            <token id="6" string="remaining" />
            <token id="7" string="counts" />
          </tokens>
        </chunking>
        <chunking id="2" string="13 remaining counts , and a mistrial" type="NP">
          <tokens>
            <token id="5" string="13" />
            <token id="6" string="remaining" />
            <token id="7" string="counts" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="a" />
            <token id="11" string="mistrial" />
          </tokens>
        </chunking>
        <chunking id="3" string="those allegations" type="NP">
          <tokens>
            <token id="15" string="those" />
            <token id="16" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="4" string="a mistrial" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="mistrial" />
          </tokens>
        </chunking>
        <chunking id="5" string="declared on those allegations" type="VP">
          <tokens>
            <token id="13" string="declared" />
            <token id="14" string="on" />
            <token id="15" string="those" />
            <token id="16" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="6" string="The jury" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="jury" />
          </tokens>
        </chunking>
        <chunking id="7" string="was declared on those allegations" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="declared" />
            <token id="14" string="on" />
            <token id="15" string="those" />
            <token id="16" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="8" string="The jury deadlocked on 13 remaining counts , and a mistrial" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="jury" />
            <token id="3" string="deadlocked" />
            <token id="4" string="on" />
            <token id="5" string="13" />
            <token id="6" string="remaining" />
            <token id="7" string="counts" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="a" />
            <token id="11" string="mistrial" />
          </tokens>
        </chunking>
        <chunking id="9" string="deadlocked on 13 remaining counts , and a mistrial" type="VP">
          <tokens>
            <token id="3" string="deadlocked" />
            <token id="4" string="on" />
            <token id="5" string="13" />
            <token id="6" string="remaining" />
            <token id="7" string="counts" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="a" />
            <token id="11" string="mistrial" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">jury</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">declared</governor>
          <dependent id="2">jury</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">jury</governor>
          <dependent id="3">deadlocked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">counts</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">counts</governor>
          <dependent id="5">13</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">counts</governor>
          <dependent id="6">remaining</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">deadlocked</governor>
          <dependent id="7">counts</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">counts</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">mistrial</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">counts</governor>
          <dependent id="11">mistrial</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">declared</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">declared</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">allegations</governor>
          <dependent id="14">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">allegations</governor>
          <dependent id="15">those</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">declared</governor>
          <dependent id="16">allegations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="13" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>A decision is expected next week over whether those charges will be refiled against Ray Buckey.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="expected" lemma="expect" stem="expect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="refiled" lemma="refile" stem="refil" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (NN decision)) (VP (VBZ is) (VP (VBN expected) (NP-TMP (JJ next) (NN week)) (PP (IN over) (SBAR (IN whether) (S (NP (DT those) (NNS charges)) (VP (MD will) (VP (VB be) (VP (VBN refiled) (PP (IN against) (NP (NNP Ray) (NNP Buckey))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A decision" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="decision" />
          </tokens>
        </chunking>
        <chunking id="2" string="refiled against Ray Buckey" type="VP">
          <tokens>
            <token id="13" string="refiled" />
            <token id="14" string="against" />
            <token id="15" string="Ray" />
            <token id="16" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="3" string="expected next week over whether those charges will be refiled against Ray Buckey" type="VP">
          <tokens>
            <token id="4" string="expected" />
            <token id="5" string="next" />
            <token id="6" string="week" />
            <token id="7" string="over" />
            <token id="8" string="whether" />
            <token id="9" string="those" />
            <token id="10" string="charges" />
            <token id="11" string="will" />
            <token id="12" string="be" />
            <token id="13" string="refiled" />
            <token id="14" string="against" />
            <token id="15" string="Ray" />
            <token id="16" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="4" string="be refiled against Ray Buckey" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="refiled" />
            <token id="14" string="against" />
            <token id="15" string="Ray" />
            <token id="16" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="5" string="is expected next week over whether those charges will be refiled against Ray Buckey" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="expected" />
            <token id="5" string="next" />
            <token id="6" string="week" />
            <token id="7" string="over" />
            <token id="8" string="whether" />
            <token id="9" string="those" />
            <token id="10" string="charges" />
            <token id="11" string="will" />
            <token id="12" string="be" />
            <token id="13" string="refiled" />
            <token id="14" string="against" />
            <token id="15" string="Ray" />
            <token id="16" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="6" string="whether those charges will be refiled against Ray Buckey" type="SBAR">
          <tokens>
            <token id="8" string="whether" />
            <token id="9" string="those" />
            <token id="10" string="charges" />
            <token id="11" string="will" />
            <token id="12" string="be" />
            <token id="13" string="refiled" />
            <token id="14" string="against" />
            <token id="15" string="Ray" />
            <token id="16" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="7" string="will be refiled against Ray Buckey" type="VP">
          <tokens>
            <token id="11" string="will" />
            <token id="12" string="be" />
            <token id="13" string="refiled" />
            <token id="14" string="against" />
            <token id="15" string="Ray" />
            <token id="16" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ray Buckey" type="NP">
          <tokens>
            <token id="15" string="Ray" />
            <token id="16" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="9" string="those charges" type="NP">
          <tokens>
            <token id="9" string="those" />
            <token id="10" string="charges" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">decision</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">expected</governor>
          <dependent id="2">decision</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">expected</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">expected</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">week</governor>
          <dependent id="5">next</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">expected</governor>
          <dependent id="6">week</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">refiled</governor>
          <dependent id="7">over</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">refiled</governor>
          <dependent id="8">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">charges</governor>
          <dependent id="9">those</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">refiled</governor>
          <dependent id="10">charges</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">refiled</governor>
          <dependent id="11">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">refiled</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">expected</governor>
          <dependent id="13">refiled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Buckey</governor>
          <dependent id="14">against</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Buckey</governor>
          <dependent id="15">Ray</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">refiled</governor>
          <dependent id="16">Buckey</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="next week" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="next" />
            <token id="6" string="week" />
          </tokens>
        </entity>
        <entity id="2" string="Ray Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Ray" />
            <token id="16" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>The verdict was a high mark, but not the final moment, in a lengthy and entangled legal saga.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="verdict" lemma="verdict" stem="verdict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="mark" lemma="mark" stem="mark" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="moment" lemma="moment" stem="moment" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="lengthy" lemma="lengthy" stem="lengthi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="entangled" lemma="entangled" stem="entangl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="saga" lemma="saga" stem="saga" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN verdict)) (VP (VBD was) (NP (NP (NP (DT a) (JJ high) (NN mark)) (, ,) (CONJP (CC but) (RB not)) (NP (DT the) (JJ final) (NN moment)) (, ,)) (PP (IN in) (NP (DT a) (ADJP (JJ lengthy) (CC and) (JJ entangled)) (JJ legal) (NN saga))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a high mark , but not the final moment , in a lengthy and entangled legal saga" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="high" />
            <token id="6" string="mark" />
            <token id="7" string="," />
            <token id="8" string="but" />
            <token id="9" string="not" />
            <token id="10" string="the" />
            <token id="11" string="final" />
            <token id="12" string="moment" />
            <token id="13" string="," />
            <token id="14" string="in" />
            <token id="15" string="a" />
            <token id="16" string="lengthy" />
            <token id="17" string="and" />
            <token id="18" string="entangled" />
            <token id="19" string="legal" />
            <token id="20" string="saga" />
          </tokens>
        </chunking>
        <chunking id="2" string="a high mark , but not the final moment ," type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="high" />
            <token id="6" string="mark" />
            <token id="7" string="," />
            <token id="8" string="but" />
            <token id="9" string="not" />
            <token id="10" string="the" />
            <token id="11" string="final" />
            <token id="12" string="moment" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="a high mark" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="high" />
            <token id="6" string="mark" />
          </tokens>
        </chunking>
        <chunking id="4" string="a lengthy and entangled legal saga" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="lengthy" />
            <token id="17" string="and" />
            <token id="18" string="entangled" />
            <token id="19" string="legal" />
            <token id="20" string="saga" />
          </tokens>
        </chunking>
        <chunking id="5" string="was a high mark , but not the final moment , in a lengthy and entangled legal saga" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="high" />
            <token id="6" string="mark" />
            <token id="7" string="," />
            <token id="8" string="but" />
            <token id="9" string="not" />
            <token id="10" string="the" />
            <token id="11" string="final" />
            <token id="12" string="moment" />
            <token id="13" string="," />
            <token id="14" string="in" />
            <token id="15" string="a" />
            <token id="16" string="lengthy" />
            <token id="17" string="and" />
            <token id="18" string="entangled" />
            <token id="19" string="legal" />
            <token id="20" string="saga" />
          </tokens>
        </chunking>
        <chunking id="6" string="the final moment" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="final" />
            <token id="12" string="moment" />
          </tokens>
        </chunking>
        <chunking id="7" string="lengthy and entangled" type="ADJP">
          <tokens>
            <token id="16" string="lengthy" />
            <token id="17" string="and" />
            <token id="18" string="entangled" />
          </tokens>
        </chunking>
        <chunking id="8" string="The verdict" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="verdict" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">verdict</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">mark</governor>
          <dependent id="2">verdict</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">mark</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">mark</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">mark</governor>
          <dependent id="5">high</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">mark</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">not</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">mark</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">moment</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">moment</governor>
          <dependent id="11">final</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">mark</governor>
          <dependent id="12">moment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">saga</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">saga</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">saga</governor>
          <dependent id="16">lengthy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">lengthy</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">lengthy</governor>
          <dependent id="18">entangled</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">saga</governor>
          <dependent id="19">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">mark</governor>
          <dependent id="20">saga</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>The criminal case began in March, 1984, when seven McMartin teachers were indicted by a county grand jury on 115 counts of molestation.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="12" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="teachers" lemma="teacher" stem="teacher" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="indicted" lemma="indict" stem="indict" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="county" lemma="county" stem="counti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="grand" lemma="grand" stem="grand" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="115" lemma="115" stem="115" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ criminal) (NN case)) (VP (VBD began) (PP (IN in) (NP (NP (NNP March)) (, ,) (NP (CD 1984)) (, ,))) (SBAR (WHADVP (WRB when)) (S (NP (CD seven) (NNP McMartin) (NNS teachers)) (VP (VBD were) (VP (VBN indicted) (PP (IN by) (NP (NP (DT a) (NN county) (JJ grand) (NN jury)) (PP (IN on) (NP (NP (CD 115) (NNS counts)) (PP (IN of) (NP (NN molestation)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="indicted by a county grand jury on 115 counts of molestation" type="VP">
          <tokens>
            <token id="15" string="indicted" />
            <token id="16" string="by" />
            <token id="17" string="a" />
            <token id="18" string="county" />
            <token id="19" string="grand" />
            <token id="20" string="jury" />
            <token id="21" string="on" />
            <token id="22" string="115" />
            <token id="23" string="counts" />
            <token id="24" string="of" />
            <token id="25" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="2" string="March , 1984 ," type="NP">
          <tokens>
            <token id="6" string="March" />
            <token id="7" string="," />
            <token id="8" string="1984" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="115 counts of molestation" type="NP">
          <tokens>
            <token id="22" string="115" />
            <token id="23" string="counts" />
            <token id="24" string="of" />
            <token id="25" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="4" string="molestation" type="NP">
          <tokens>
            <token id="25" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="5" string="began in March , 1984 , when seven McMartin teachers were indicted by a county grand jury on 115 counts of molestation" type="VP">
          <tokens>
            <token id="4" string="began" />
            <token id="5" string="in" />
            <token id="6" string="March" />
            <token id="7" string="," />
            <token id="8" string="1984" />
            <token id="9" string="," />
            <token id="10" string="when" />
            <token id="11" string="seven" />
            <token id="12" string="McMartin" />
            <token id="13" string="teachers" />
            <token id="14" string="were" />
            <token id="15" string="indicted" />
            <token id="16" string="by" />
            <token id="17" string="a" />
            <token id="18" string="county" />
            <token id="19" string="grand" />
            <token id="20" string="jury" />
            <token id="21" string="on" />
            <token id="22" string="115" />
            <token id="23" string="counts" />
            <token id="24" string="of" />
            <token id="25" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="6" string="seven McMartin teachers" type="NP">
          <tokens>
            <token id="11" string="seven" />
            <token id="12" string="McMartin" />
            <token id="13" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="7" string="a county grand jury" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="county" />
            <token id="19" string="grand" />
            <token id="20" string="jury" />
          </tokens>
        </chunking>
        <chunking id="8" string="March" type="NP">
          <tokens>
            <token id="6" string="March" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="10" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="were indicted by a county grand jury on 115 counts of molestation" type="VP">
          <tokens>
            <token id="14" string="were" />
            <token id="15" string="indicted" />
            <token id="16" string="by" />
            <token id="17" string="a" />
            <token id="18" string="county" />
            <token id="19" string="grand" />
            <token id="20" string="jury" />
            <token id="21" string="on" />
            <token id="22" string="115" />
            <token id="23" string="counts" />
            <token id="24" string="of" />
            <token id="25" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="11" string="a county grand jury on 115 counts of molestation" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="county" />
            <token id="19" string="grand" />
            <token id="20" string="jury" />
            <token id="21" string="on" />
            <token id="22" string="115" />
            <token id="23" string="counts" />
            <token id="24" string="of" />
            <token id="25" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="12" string="The criminal case" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="criminal" />
            <token id="3" string="case" />
          </tokens>
        </chunking>
        <chunking id="13" string="1984" type="NP">
          <tokens>
            <token id="8" string="1984" />
          </tokens>
        </chunking>
        <chunking id="14" string="when seven McMartin teachers were indicted by a county grand jury on 115 counts of molestation" type="SBAR">
          <tokens>
            <token id="10" string="when" />
            <token id="11" string="seven" />
            <token id="12" string="McMartin" />
            <token id="13" string="teachers" />
            <token id="14" string="were" />
            <token id="15" string="indicted" />
            <token id="16" string="by" />
            <token id="17" string="a" />
            <token id="18" string="county" />
            <token id="19" string="grand" />
            <token id="20" string="jury" />
            <token id="21" string="on" />
            <token id="22" string="115" />
            <token id="23" string="counts" />
            <token id="24" string="of" />
            <token id="25" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="15" string="115 counts" type="NP">
          <tokens>
            <token id="22" string="115" />
            <token id="23" string="counts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">case</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">case</governor>
          <dependent id="2">criminal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">began</governor>
          <dependent id="3">case</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">began</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">March</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">began</governor>
          <dependent id="6">March</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">March</governor>
          <dependent id="8">1984</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">indicted</governor>
          <dependent id="10">when</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">teachers</governor>
          <dependent id="11">seven</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">teachers</governor>
          <dependent id="12">McMartin</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">indicted</governor>
          <dependent id="13">teachers</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">indicted</governor>
          <dependent id="14">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">began</governor>
          <dependent id="15">indicted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">jury</governor>
          <dependent id="16">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">jury</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">jury</governor>
          <dependent id="18">county</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">jury</governor>
          <dependent id="19">grand</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">indicted</governor>
          <dependent id="20">jury</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">counts</governor>
          <dependent id="21">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">counts</governor>
          <dependent id="22">115</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">jury</governor>
          <dependent id="23">counts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">molestation</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">counts</governor>
          <dependent id="25">molestation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="115" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="115" />
          </tokens>
        </entity>
        <entity id="2" string="March , 1984" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="March" />
            <token id="7" string="," />
            <token id="8" string="1984" />
          </tokens>
        </entity>
        <entity id="3" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="seven" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>The indictment was superseded by a criminal complaint of 208 counts of molestation and conspiracy.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="indictment" lemma="indictment" stem="indict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="superseded" lemma="supersede" stem="supersed" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="208" lemma="208" stem="208" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="conspiracy" lemma="conspiracy" stem="conspiraci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN indictment)) (VP (VBD was) (VP (VBN superseded) (PP (IN by) (NP (NP (DT a) (JJ criminal) (NN complaint)) (PP (IN of) (NP (NP (CD 208) (NNS counts)) (PP (IN of) (NP (NN molestation) (CC and) (NN conspiracy))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="208 counts" type="NP">
          <tokens>
            <token id="10" string="208" />
            <token id="11" string="counts" />
          </tokens>
        </chunking>
        <chunking id="2" string="a criminal complaint" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="criminal" />
            <token id="8" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="3" string="The indictment" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="indictment" />
          </tokens>
        </chunking>
        <chunking id="4" string="superseded by a criminal complaint of 208 counts of molestation and conspiracy" type="VP">
          <tokens>
            <token id="4" string="superseded" />
            <token id="5" string="by" />
            <token id="6" string="a" />
            <token id="7" string="criminal" />
            <token id="8" string="complaint" />
            <token id="9" string="of" />
            <token id="10" string="208" />
            <token id="11" string="counts" />
            <token id="12" string="of" />
            <token id="13" string="molestation" />
            <token id="14" string="and" />
            <token id="15" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="5" string="a criminal complaint of 208 counts of molestation and conspiracy" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="criminal" />
            <token id="8" string="complaint" />
            <token id="9" string="of" />
            <token id="10" string="208" />
            <token id="11" string="counts" />
            <token id="12" string="of" />
            <token id="13" string="molestation" />
            <token id="14" string="and" />
            <token id="15" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="6" string="was superseded by a criminal complaint of 208 counts of molestation and conspiracy" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="superseded" />
            <token id="5" string="by" />
            <token id="6" string="a" />
            <token id="7" string="criminal" />
            <token id="8" string="complaint" />
            <token id="9" string="of" />
            <token id="10" string="208" />
            <token id="11" string="counts" />
            <token id="12" string="of" />
            <token id="13" string="molestation" />
            <token id="14" string="and" />
            <token id="15" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="7" string="208 counts of molestation and conspiracy" type="NP">
          <tokens>
            <token id="10" string="208" />
            <token id="11" string="counts" />
            <token id="12" string="of" />
            <token id="13" string="molestation" />
            <token id="14" string="and" />
            <token id="15" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="8" string="molestation and conspiracy" type="NP">
          <tokens>
            <token id="13" string="molestation" />
            <token id="14" string="and" />
            <token id="15" string="conspiracy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">indictment</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">superseded</governor>
          <dependent id="2">indictment</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">superseded</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">superseded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">complaint</governor>
          <dependent id="5">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">complaint</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">complaint</governor>
          <dependent id="7">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">superseded</governor>
          <dependent id="8">complaint</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">counts</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">counts</governor>
          <dependent id="10">208</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">complaint</governor>
          <dependent id="11">counts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">molestation</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">counts</governor>
          <dependent id="13">molestation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">molestation</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">molestation</governor>
          <dependent id="15">conspiracy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="208" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="208" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>After an 18-month preliminary hearing, all seven were ordered to stand trial.</content>
      <tokens>
        <token id="1" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="18-month" lemma="18-month" stem="18-month" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="4" string="preliminary" lemma="preliminary" stem="preliminari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="ordered" lemma="order" stem="order" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="stand" lemma="stand" stem="stand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN After) (NP (DT an) (JJ 18-month) (JJ preliminary) (NN hearing))) (, ,) (NP (DT all) (CD seven)) (VP (VBD were) (VP (VBN ordered) (S (VP (TO to) (VP (VB stand) (NP (NN trial))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all seven" type="NP">
          <tokens>
            <token id="7" string="all" />
            <token id="8" string="seven" />
          </tokens>
        </chunking>
        <chunking id="2" string="an 18-month preliminary hearing" type="NP">
          <tokens>
            <token id="2" string="an" />
            <token id="3" string="18-month" />
            <token id="4" string="preliminary" />
            <token id="5" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="3" string="ordered to stand trial" type="VP">
          <tokens>
            <token id="10" string="ordered" />
            <token id="11" string="to" />
            <token id="12" string="stand" />
            <token id="13" string="trial" />
          </tokens>
        </chunking>
        <chunking id="4" string="were ordered to stand trial" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="ordered" />
            <token id="11" string="to" />
            <token id="12" string="stand" />
            <token id="13" string="trial" />
          </tokens>
        </chunking>
        <chunking id="5" string="trial" type="NP">
          <tokens>
            <token id="13" string="trial" />
          </tokens>
        </chunking>
        <chunking id="6" string="stand trial" type="VP">
          <tokens>
            <token id="12" string="stand" />
            <token id="13" string="trial" />
          </tokens>
        </chunking>
        <chunking id="7" string="to stand trial" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="stand" />
            <token id="13" string="trial" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">hearing</governor>
          <dependent id="1">After</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">hearing</governor>
          <dependent id="2">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">hearing</governor>
          <dependent id="3">18-month</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">hearing</governor>
          <dependent id="4">preliminary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">ordered</governor>
          <dependent id="5">hearing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">seven</governor>
          <dependent id="7">all</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">ordered</governor>
          <dependent id="8">seven</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">ordered</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">ordered</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">stand</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">ordered</governor>
          <dependent id="12">stand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">stand</governor>
          <dependent id="13">trial</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="seven" />
          </tokens>
        </entity>
        <entity id="2" string="18-month" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="18-month" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Defendants included Buckey; his mother; his grandmother, Virginia McMartin, who was the school founder; his sister Peggy Ann Buckey; and teachers Spitler, Betty Raidor and Mary Ann Jackson.</content>
      <tokens>
        <token id="1" string="Defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="included" lemma="include" stem="includ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="grandmother" lemma="grandmother" stem="grandmoth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="12" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="founder" lemma="founder" stem="founder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="sister" lemma="sister" stem="sister" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="23" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="24" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="25" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="teachers" lemma="teacher" stem="teacher" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="Spitler" lemma="Spitler" stem="spitler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="Betty" lemma="Betty" stem="betti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="31" string="Raidor" lemma="Raidor" stem="raidor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="Mary" lemma="Mary" stem="mari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="34" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="35" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Defendants)) (VP (VBD included) (NP (NP (NP (NNP Buckey)) (: ;) (NP (PRP$ his) (NN mother))) (: ;) (NP (NP (PRP$ his) (NN grandmother)) (, ,) (NP (NNP Virginia) (NNP McMartin)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD was) (NP (DT the) (NN school) (NN founder)))))) (: ;) (NP (NP (PRP$ his) (NN sister)) (NP (NNP Peggy) (NNP Ann) (NNP Buckey))) (: ;) (CC and) (NP (NP (NNS teachers) (NNP Spitler)) (, ,) (NP (NNP Betty) (NNP Raidor)) (CC and) (NP (NNP Mary) (NNP Ann) (NNP Jackson))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his grandmother , Virginia McMartin , who was the school founder" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="grandmother" />
            <token id="10" string="," />
            <token id="11" string="Virginia" />
            <token id="12" string="McMartin" />
            <token id="13" string="," />
            <token id="14" string="who" />
            <token id="15" string="was" />
            <token id="16" string="the" />
            <token id="17" string="school" />
            <token id="18" string="founder" />
          </tokens>
        </chunking>
        <chunking id="2" string="his sister" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="sister" />
          </tokens>
        </chunking>
        <chunking id="3" string="Mary Ann Jackson" type="NP">
          <tokens>
            <token id="33" string="Mary" />
            <token id="34" string="Ann" />
            <token id="35" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="4" string="Virginia McMartin" type="NP">
          <tokens>
            <token id="11" string="Virginia" />
            <token id="12" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="5" string="who was the school founder" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="was" />
            <token id="16" string="the" />
            <token id="17" string="school" />
            <token id="18" string="founder" />
          </tokens>
        </chunking>
        <chunking id="6" string="teachers Spitler , Betty Raidor and Mary Ann Jackson" type="NP">
          <tokens>
            <token id="27" string="teachers" />
            <token id="28" string="Spitler" />
            <token id="29" string="," />
            <token id="30" string="Betty" />
            <token id="31" string="Raidor" />
            <token id="32" string="and" />
            <token id="33" string="Mary" />
            <token id="34" string="Ann" />
            <token id="35" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="7" string="Betty Raidor" type="NP">
          <tokens>
            <token id="30" string="Betty" />
            <token id="31" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="8" string="the school founder" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="school" />
            <token id="18" string="founder" />
          </tokens>
        </chunking>
        <chunking id="9" string="Buckey" type="NP">
          <tokens>
            <token id="3" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="10" string="Defendants" type="NP">
          <tokens>
            <token id="1" string="Defendants" />
          </tokens>
        </chunking>
        <chunking id="11" string="his grandmother" type="NP">
          <tokens>
            <token id="8" string="his" />
            <token id="9" string="grandmother" />
          </tokens>
        </chunking>
        <chunking id="12" string="was the school founder" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="the" />
            <token id="17" string="school" />
            <token id="18" string="founder" />
          </tokens>
        </chunking>
        <chunking id="13" string="Peggy Ann Buckey" type="NP">
          <tokens>
            <token id="22" string="Peggy" />
            <token id="23" string="Ann" />
            <token id="24" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="14" string="his mother" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="mother" />
          </tokens>
        </chunking>
        <chunking id="15" string="included Buckey ; his mother ; his grandmother , Virginia McMartin , who was the school founder ; his sister Peggy Ann Buckey ; and teachers Spitler , Betty Raidor and Mary Ann Jackson" type="VP">
          <tokens>
            <token id="2" string="included" />
            <token id="3" string="Buckey" />
            <token id="4" string=";" />
            <token id="5" string="his" />
            <token id="6" string="mother" />
            <token id="7" string=";" />
            <token id="8" string="his" />
            <token id="9" string="grandmother" />
            <token id="10" string="," />
            <token id="11" string="Virginia" />
            <token id="12" string="McMartin" />
            <token id="13" string="," />
            <token id="14" string="who" />
            <token id="15" string="was" />
            <token id="16" string="the" />
            <token id="17" string="school" />
            <token id="18" string="founder" />
            <token id="19" string=";" />
            <token id="20" string="his" />
            <token id="21" string="sister" />
            <token id="22" string="Peggy" />
            <token id="23" string="Ann" />
            <token id="24" string="Buckey" />
            <token id="25" string=";" />
            <token id="26" string="and" />
            <token id="27" string="teachers" />
            <token id="28" string="Spitler" />
            <token id="29" string="," />
            <token id="30" string="Betty" />
            <token id="31" string="Raidor" />
            <token id="32" string="and" />
            <token id="33" string="Mary" />
            <token id="34" string="Ann" />
            <token id="35" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="16" string="teachers Spitler" type="NP">
          <tokens>
            <token id="27" string="teachers" />
            <token id="28" string="Spitler" />
          </tokens>
        </chunking>
        <chunking id="17" string="his sister Peggy Ann Buckey" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="sister" />
            <token id="22" string="Peggy" />
            <token id="23" string="Ann" />
            <token id="24" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="18" string="Buckey ; his mother ; his grandmother , Virginia McMartin , who was the school founder ; his sister Peggy Ann Buckey ; and teachers Spitler , Betty Raidor and Mary Ann Jackson" type="NP">
          <tokens>
            <token id="3" string="Buckey" />
            <token id="4" string=";" />
            <token id="5" string="his" />
            <token id="6" string="mother" />
            <token id="7" string=";" />
            <token id="8" string="his" />
            <token id="9" string="grandmother" />
            <token id="10" string="," />
            <token id="11" string="Virginia" />
            <token id="12" string="McMartin" />
            <token id="13" string="," />
            <token id="14" string="who" />
            <token id="15" string="was" />
            <token id="16" string="the" />
            <token id="17" string="school" />
            <token id="18" string="founder" />
            <token id="19" string=";" />
            <token id="20" string="his" />
            <token id="21" string="sister" />
            <token id="22" string="Peggy" />
            <token id="23" string="Ann" />
            <token id="24" string="Buckey" />
            <token id="25" string=";" />
            <token id="26" string="and" />
            <token id="27" string="teachers" />
            <token id="28" string="Spitler" />
            <token id="29" string="," />
            <token id="30" string="Betty" />
            <token id="31" string="Raidor" />
            <token id="32" string="and" />
            <token id="33" string="Mary" />
            <token id="34" string="Ann" />
            <token id="35" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="19" string="Buckey ; his mother" type="NP">
          <tokens>
            <token id="3" string="Buckey" />
            <token id="4" string=";" />
            <token id="5" string="his" />
            <token id="6" string="mother" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">included</governor>
          <dependent id="1">Defendants</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">included</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">included</governor>
          <dependent id="3">Buckey</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">mother</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">Buckey</governor>
          <dependent id="6">mother</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">grandmother</governor>
          <dependent id="8">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Buckey</governor>
          <dependent id="9">grandmother</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">McMartin</governor>
          <dependent id="11">Virginia</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">grandmother</governor>
          <dependent id="12">McMartin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">founder</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">founder</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">founder</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">founder</governor>
          <dependent id="17">school</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">grandmother</governor>
          <dependent id="18">founder</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">sister</governor>
          <dependent id="20">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Buckey</governor>
          <dependent id="21">sister</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Buckey</governor>
          <dependent id="22">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Buckey</governor>
          <dependent id="23">Ann</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">sister</governor>
          <dependent id="24">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">Buckey</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Spitler</governor>
          <dependent id="27">teachers</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Buckey</governor>
          <dependent id="28">Spitler</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Raidor</governor>
          <dependent id="30">Betty</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">Spitler</governor>
          <dependent id="31">Raidor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">Spitler</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Jackson</governor>
          <dependent id="33">Mary</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Jackson</governor>
          <dependent id="34">Ann</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">Spitler</governor>
          <dependent id="35">Jackson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Spitler" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Spitler" />
          </tokens>
        </entity>
        <entity id="3" string="Mary Ann Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="33" string="Mary" />
            <token id="34" string="Ann" />
            <token id="35" string="Jackson" />
          </tokens>
        </entity>
        <entity id="4" string="Peggy Ann Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Peggy" />
            <token id="23" string="Ann" />
            <token id="24" string="Buckey" />
          </tokens>
        </entity>
        <entity id="5" string="Virginia McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Virginia" />
            <token id="12" string="McMartin" />
          </tokens>
        </entity>
        <entity id="6" string="Betty Raidor" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Betty" />
            <token id="31" string="Raidor" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>But a week after the hearing ended, Dist.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="ended" lemma="end" stem="end" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Dist" lemma="Dist" stem="dist" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (S (NP (NP (DT a) (NN week)) (PP (IN after) (NP (DT the) (NN hearing)))) (VP (VBD ended))) (, ,) (S (NP (NNP Dist))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a week" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="week" />
          </tokens>
        </chunking>
        <chunking id="2" string="Dist" type="NP">
          <tokens>
            <token id="9" string="Dist" />
          </tokens>
        </chunking>
        <chunking id="3" string="a week after the hearing" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="week" />
            <token id="4" string="after" />
            <token id="5" string="the" />
            <token id="6" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="4" string="ended" type="VP">
          <tokens>
            <token id="7" string="ended" />
          </tokens>
        </chunking>
        <chunking id="5" string="the hearing" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="hearing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">ended</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">week</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">ended</governor>
          <dependent id="3">week</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">hearing</governor>
          <dependent id="4">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">hearing</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">week</governor>
          <dependent id="6">hearing</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">ended</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">ended</governor>
          <dependent id="9">Dist</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="a week" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="week" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Atty. Ira Reiner dropped charges against the latter five defendants citing &amp;quot;incredibly weak evidence.&amp;quot;</content>
      <tokens>
        <token id="1" string="Atty." lemma="Atty." stem="atty." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Ira" lemma="Ira" stem="ira" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="dropped" lemma="drop" stem="drop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="latter" lemma="latter" stem="latter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="citing" lemma="cite" stem="cite" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="incredibly" lemma="incredibly" stem="incredibli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="weak" lemma="weak" stem="weak" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Atty.) (NNP Ira) (NNP Reiner)) (VP (VBD dropped) (NP (NNS charges)) (PP (IN against) (NP (DT the) (JJ latter) (CD five) (NNS defendants))) (S (VP (VBG citing) (`` ``) (NP (ADJP (RB incredibly) (JJ weak)) (NN evidence))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Atty. Ira Reiner" type="NP">
          <tokens>
            <token id="1" string="Atty." />
            <token id="2" string="Ira" />
            <token id="3" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="2" string="dropped charges against the latter five defendants citing `` incredibly weak evidence" type="VP">
          <tokens>
            <token id="4" string="dropped" />
            <token id="5" string="charges" />
            <token id="6" string="against" />
            <token id="7" string="the" />
            <token id="8" string="latter" />
            <token id="9" string="five" />
            <token id="10" string="defendants" />
            <token id="11" string="citing" />
            <token id="12" string="&quot;" />
            <token id="13" string="incredibly" />
            <token id="14" string="weak" />
            <token id="15" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="3" string="charges" type="NP">
          <tokens>
            <token id="5" string="charges" />
          </tokens>
        </chunking>
        <chunking id="4" string="the latter five defendants" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="latter" />
            <token id="9" string="five" />
            <token id="10" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="5" string="incredibly weak evidence" type="NP">
          <tokens>
            <token id="13" string="incredibly" />
            <token id="14" string="weak" />
            <token id="15" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="6" string="incredibly weak" type="ADJP">
          <tokens>
            <token id="13" string="incredibly" />
            <token id="14" string="weak" />
          </tokens>
        </chunking>
        <chunking id="7" string="citing `` incredibly weak evidence" type="VP">
          <tokens>
            <token id="11" string="citing" />
            <token id="12" string="&quot;" />
            <token id="13" string="incredibly" />
            <token id="14" string="weak" />
            <token id="15" string="evidence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Reiner</governor>
          <dependent id="1">Atty.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Reiner</governor>
          <dependent id="2">Ira</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">dropped</governor>
          <dependent id="3">Reiner</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">dropped</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">dropped</governor>
          <dependent id="5">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">defendants</governor>
          <dependent id="6">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">defendants</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">defendants</governor>
          <dependent id="8">latter</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">defendants</governor>
          <dependent id="9">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">dropped</governor>
          <dependent id="10">defendants</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">dropped</governor>
          <dependent id="11">citing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">weak</governor>
          <dependent id="13">incredibly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">evidence</governor>
          <dependent id="14">weak</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">citing</governor>
          <dependent id="15">evidence</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ira Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ira" />
            <token id="3" string="Reiner" />
          </tokens>
        </entity>
        <entity id="2" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="false">
      <content>Even before the criminal case went to trial, civil litigation already was in the works.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="litigation" lemma="litigation" stem="litig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="works" lemma="work" stem="work" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (RB Even) (IN before) (S (NP (DT the) (JJ criminal) (NN case)) (VP (VBD went) (PP (TO to) (NP (NN trial)))))) (, ,) (NP (JJ civil) (NN litigation)) (ADVP (RB already)) (VP (VBD was) (PP (IN in) (NP (DT the) (NNS works)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="civil litigation" type="NP">
          <tokens>
            <token id="10" string="civil" />
            <token id="11" string="litigation" />
          </tokens>
        </chunking>
        <chunking id="2" string="Even before the criminal case went to trial" type="SBAR">
          <tokens>
            <token id="1" string="Even" />
            <token id="2" string="before" />
            <token id="3" string="the" />
            <token id="4" string="criminal" />
            <token id="5" string="case" />
            <token id="6" string="went" />
            <token id="7" string="to" />
            <token id="8" string="trial" />
          </tokens>
        </chunking>
        <chunking id="3" string="the criminal case" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="criminal" />
            <token id="5" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="went to trial" type="VP">
          <tokens>
            <token id="6" string="went" />
            <token id="7" string="to" />
            <token id="8" string="trial" />
          </tokens>
        </chunking>
        <chunking id="5" string="the works" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="works" />
          </tokens>
        </chunking>
        <chunking id="6" string="trial" type="NP">
          <tokens>
            <token id="8" string="trial" />
          </tokens>
        </chunking>
        <chunking id="7" string="was in the works" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="works" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">went</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">went</governor>
          <dependent id="2">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">case</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">case</governor>
          <dependent id="4">criminal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">went</governor>
          <dependent id="5">case</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">works</governor>
          <dependent id="6">went</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">trial</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">went</governor>
          <dependent id="8">trial</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">litigation</governor>
          <dependent id="10">civil</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">works</governor>
          <dependent id="11">litigation</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">works</governor>
          <dependent id="12">already</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">works</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">works</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">works</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">works</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>In 1984, a handful of lawsuits were filed by 22 families seeking monetary damages against the school for medical bills, cost of psychiatric therapy and emotional distress arising from the alleged molestations.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="handful" lemma="handful" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="lawsuits" lemma="lawsuit" stem="lawsuit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="22" lemma="22" stem="22" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="12" string="families" lemma="family" stem="famili" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="seeking" lemma="seek" stem="seek" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="monetary" lemma="monetary" stem="monetari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="damages" lemma="damages" stem="damag" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="medical" lemma="medical" stem="medic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="bills" lemma="bill" stem="bill" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="psychiatric" lemma="psychiatric" stem="psychiatr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="therapy" lemma="therapy" stem="therapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="emotional" lemma="emotional" stem="emot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="distress" lemma="distress" stem="distress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="arising" lemma="arise" stem="aris" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="alleged" lemma="alleged" stem="alleg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="molestations" lemma="molestation" stem="molest" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1984))) (, ,) (NP (NP (DT a) (NN handful)) (PP (IN of) (NP (NNS lawsuits)))) (VP (VBD were) (VP (VBN filed) (PP (IN by) (NP (NP (NP (CD 22) (NNS families)) (VP (VBG seeking) (NP (JJ monetary) (NNS damages)) (PP (IN against) (NP (NP (DT the) (NN school)) (PP (IN for) (NP (JJ medical) (NNS bills))))))) (, ,) (NP (NP (NN cost)) (PP (IN of) (NP (JJ psychiatric) (NN therapy)))) (CC and) (NP (NP (JJ emotional) (NN distress)) (VP (VBG arising) (PP (IN from) (NP (DT the) (JJ alleged) (NNS molestations))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="arising from the alleged molestations" type="VP">
          <tokens>
            <token id="30" string="arising" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="alleged" />
            <token id="34" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="2" string="cost of psychiatric therapy" type="NP">
          <tokens>
            <token id="23" string="cost" />
            <token id="24" string="of" />
            <token id="25" string="psychiatric" />
            <token id="26" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="3" string="cost" type="NP">
          <tokens>
            <token id="23" string="cost" />
          </tokens>
        </chunking>
        <chunking id="4" string="the school for medical bills" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="school" />
            <token id="19" string="for" />
            <token id="20" string="medical" />
            <token id="21" string="bills" />
          </tokens>
        </chunking>
        <chunking id="5" string="a handful of lawsuits" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="handful" />
            <token id="6" string="of" />
            <token id="7" string="lawsuits" />
          </tokens>
        </chunking>
        <chunking id="6" string="seeking monetary damages against the school for medical bills" type="VP">
          <tokens>
            <token id="13" string="seeking" />
            <token id="14" string="monetary" />
            <token id="15" string="damages" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="school" />
            <token id="19" string="for" />
            <token id="20" string="medical" />
            <token id="21" string="bills" />
          </tokens>
        </chunking>
        <chunking id="7" string="emotional distress" type="NP">
          <tokens>
            <token id="28" string="emotional" />
            <token id="29" string="distress" />
          </tokens>
        </chunking>
        <chunking id="8" string="the alleged molestations" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="alleged" />
            <token id="34" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="9" string="monetary damages" type="NP">
          <tokens>
            <token id="14" string="monetary" />
            <token id="15" string="damages" />
          </tokens>
        </chunking>
        <chunking id="10" string="22 families seeking monetary damages against the school for medical bills" type="NP">
          <tokens>
            <token id="11" string="22" />
            <token id="12" string="families" />
            <token id="13" string="seeking" />
            <token id="14" string="monetary" />
            <token id="15" string="damages" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="school" />
            <token id="19" string="for" />
            <token id="20" string="medical" />
            <token id="21" string="bills" />
          </tokens>
        </chunking>
        <chunking id="11" string="medical bills" type="NP">
          <tokens>
            <token id="20" string="medical" />
            <token id="21" string="bills" />
          </tokens>
        </chunking>
        <chunking id="12" string="a handful" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="handful" />
          </tokens>
        </chunking>
        <chunking id="13" string="emotional distress arising from the alleged molestations" type="NP">
          <tokens>
            <token id="28" string="emotional" />
            <token id="29" string="distress" />
            <token id="30" string="arising" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="alleged" />
            <token id="34" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="14" string="the school" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="school" />
          </tokens>
        </chunking>
        <chunking id="15" string="1984" type="NP">
          <tokens>
            <token id="2" string="1984" />
          </tokens>
        </chunking>
        <chunking id="16" string="lawsuits" type="NP">
          <tokens>
            <token id="7" string="lawsuits" />
          </tokens>
        </chunking>
        <chunking id="17" string="filed by 22 families seeking monetary damages against the school for medical bills , cost of psychiatric therapy and emotional distress arising from the alleged molestations" type="VP">
          <tokens>
            <token id="9" string="filed" />
            <token id="10" string="by" />
            <token id="11" string="22" />
            <token id="12" string="families" />
            <token id="13" string="seeking" />
            <token id="14" string="monetary" />
            <token id="15" string="damages" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="school" />
            <token id="19" string="for" />
            <token id="20" string="medical" />
            <token id="21" string="bills" />
            <token id="22" string="," />
            <token id="23" string="cost" />
            <token id="24" string="of" />
            <token id="25" string="psychiatric" />
            <token id="26" string="therapy" />
            <token id="27" string="and" />
            <token id="28" string="emotional" />
            <token id="29" string="distress" />
            <token id="30" string="arising" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="alleged" />
            <token id="34" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="18" string="22 families seeking monetary damages against the school for medical bills , cost of psychiatric therapy and emotional distress arising from the alleged molestations" type="NP">
          <tokens>
            <token id="11" string="22" />
            <token id="12" string="families" />
            <token id="13" string="seeking" />
            <token id="14" string="monetary" />
            <token id="15" string="damages" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="school" />
            <token id="19" string="for" />
            <token id="20" string="medical" />
            <token id="21" string="bills" />
            <token id="22" string="," />
            <token id="23" string="cost" />
            <token id="24" string="of" />
            <token id="25" string="psychiatric" />
            <token id="26" string="therapy" />
            <token id="27" string="and" />
            <token id="28" string="emotional" />
            <token id="29" string="distress" />
            <token id="30" string="arising" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="alleged" />
            <token id="34" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="19" string="were filed by 22 families seeking monetary damages against the school for medical bills , cost of psychiatric therapy and emotional distress arising from the alleged molestations" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="filed" />
            <token id="10" string="by" />
            <token id="11" string="22" />
            <token id="12" string="families" />
            <token id="13" string="seeking" />
            <token id="14" string="monetary" />
            <token id="15" string="damages" />
            <token id="16" string="against" />
            <token id="17" string="the" />
            <token id="18" string="school" />
            <token id="19" string="for" />
            <token id="20" string="medical" />
            <token id="21" string="bills" />
            <token id="22" string="," />
            <token id="23" string="cost" />
            <token id="24" string="of" />
            <token id="25" string="psychiatric" />
            <token id="26" string="therapy" />
            <token id="27" string="and" />
            <token id="28" string="emotional" />
            <token id="29" string="distress" />
            <token id="30" string="arising" />
            <token id="31" string="from" />
            <token id="32" string="the" />
            <token id="33" string="alleged" />
            <token id="34" string="molestations" />
          </tokens>
        </chunking>
        <chunking id="20" string="psychiatric therapy" type="NP">
          <tokens>
            <token id="25" string="psychiatric" />
            <token id="26" string="therapy" />
          </tokens>
        </chunking>
        <chunking id="21" string="22 families" type="NP">
          <tokens>
            <token id="11" string="22" />
            <token id="12" string="families" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1984</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">filed</governor>
          <dependent id="2">1984</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">handful</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">filed</governor>
          <dependent id="5">handful</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">lawsuits</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">handful</governor>
          <dependent id="7">lawsuits</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">filed</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">families</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">families</governor>
          <dependent id="11">22</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">filed</governor>
          <dependent id="12">families</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">families</governor>
          <dependent id="13">seeking</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">damages</governor>
          <dependent id="14">monetary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">seeking</governor>
          <dependent id="15">damages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">school</governor>
          <dependent id="16">against</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">school</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">seeking</governor>
          <dependent id="18">school</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">bills</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">bills</governor>
          <dependent id="20">medical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">school</governor>
          <dependent id="21">bills</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">families</governor>
          <dependent id="23">cost</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">therapy</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">therapy</governor>
          <dependent id="25">psychiatric</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">cost</governor>
          <dependent id="26">therapy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">families</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">distress</governor>
          <dependent id="28">emotional</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">families</governor>
          <dependent id="29">distress</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="29">distress</governor>
          <dependent id="30">arising</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">molestations</governor>
          <dependent id="31">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">molestations</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">molestations</governor>
          <dependent id="33">alleged</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">arising</governor>
          <dependent id="34">molestations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1984" />
          </tokens>
        </entity>
        <entity id="2" string="22" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="22" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>But those lawsuits later were withdrawn to prevent the children&amp;apost;s psychiatric histories from being introduced as evidence in the criminal case.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="lawsuits" lemma="lawsuit" stem="lawsuit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="withdrawn" lemma="withdraw" stem="withdrawn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="prevent" lemma="prevent" stem="prevent" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="psychiatric" lemma="psychiatric" stem="psychiatr" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="histories" lemma="history" stem="histori" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="introduced" lemma="introduce" stem="introduc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT those) (NNS lawsuits)) (ADVP (RB later)) (VP (VBD were) (VP (VBN withdrawn) (S (VP (TO to) (VP (VB prevent) (NP (NP (DT the) (NNS children) (POS 's)) (JJ psychiatric) (NNS histories)) (PP (IN from) (S (VP (VBG being) (VP (VBN introduced) (PP (IN as) (NP (NP (NN evidence)) (PP (IN in) (NP (DT the) (JJ criminal) (NN case)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the children 's" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="children" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="evidence in the criminal case" type="NP">
          <tokens>
            <token id="18" string="evidence" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="criminal" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="being introduced as evidence in the criminal case" type="VP">
          <tokens>
            <token id="15" string="being" />
            <token id="16" string="introduced" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="criminal" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="evidence" type="NP">
          <tokens>
            <token id="18" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="5" string="were withdrawn to prevent the children 's psychiatric histories from being introduced as evidence in the criminal case" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="withdrawn" />
            <token id="7" string="to" />
            <token id="8" string="prevent" />
            <token id="9" string="the" />
            <token id="10" string="children" />
            <token id="11" string="'s" />
            <token id="12" string="psychiatric" />
            <token id="13" string="histories" />
            <token id="14" string="from" />
            <token id="15" string="being" />
            <token id="16" string="introduced" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="criminal" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="the criminal case" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="criminal" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="introduced as evidence in the criminal case" type="VP">
          <tokens>
            <token id="16" string="introduced" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="criminal" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="to prevent the children 's psychiatric histories from being introduced as evidence in the criminal case" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="prevent" />
            <token id="9" string="the" />
            <token id="10" string="children" />
            <token id="11" string="'s" />
            <token id="12" string="psychiatric" />
            <token id="13" string="histories" />
            <token id="14" string="from" />
            <token id="15" string="being" />
            <token id="16" string="introduced" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="criminal" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="9" string="withdrawn to prevent the children 's psychiatric histories from being introduced as evidence in the criminal case" type="VP">
          <tokens>
            <token id="6" string="withdrawn" />
            <token id="7" string="to" />
            <token id="8" string="prevent" />
            <token id="9" string="the" />
            <token id="10" string="children" />
            <token id="11" string="'s" />
            <token id="12" string="psychiatric" />
            <token id="13" string="histories" />
            <token id="14" string="from" />
            <token id="15" string="being" />
            <token id="16" string="introduced" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="criminal" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="prevent the children 's psychiatric histories from being introduced as evidence in the criminal case" type="VP">
          <tokens>
            <token id="8" string="prevent" />
            <token id="9" string="the" />
            <token id="10" string="children" />
            <token id="11" string="'s" />
            <token id="12" string="psychiatric" />
            <token id="13" string="histories" />
            <token id="14" string="from" />
            <token id="15" string="being" />
            <token id="16" string="introduced" />
            <token id="17" string="as" />
            <token id="18" string="evidence" />
            <token id="19" string="in" />
            <token id="20" string="the" />
            <token id="21" string="criminal" />
            <token id="22" string="case" />
          </tokens>
        </chunking>
        <chunking id="11" string="the children 's psychiatric histories" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="children" />
            <token id="11" string="'s" />
            <token id="12" string="psychiatric" />
            <token id="13" string="histories" />
          </tokens>
        </chunking>
        <chunking id="12" string="those lawsuits" type="NP">
          <tokens>
            <token id="2" string="those" />
            <token id="3" string="lawsuits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">withdrawn</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">lawsuits</governor>
          <dependent id="2">those</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">withdrawn</governor>
          <dependent id="3">lawsuits</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">withdrawn</governor>
          <dependent id="4">later</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">withdrawn</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">withdrawn</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">prevent</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">withdrawn</governor>
          <dependent id="8">prevent</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">children</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">histories</governor>
          <dependent id="10">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">children</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">histories</governor>
          <dependent id="12">psychiatric</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">prevent</governor>
          <dependent id="13">histories</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">introduced</governor>
          <dependent id="14">from</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">introduced</governor>
          <dependent id="15">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">prevent</governor>
          <dependent id="16">introduced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">evidence</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">introduced</governor>
          <dependent id="18">evidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">case</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">case</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">case</governor>
          <dependent id="21">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">evidence</governor>
          <dependent id="22">case</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Greg Mooney, an attorney who represented some of the plaintiffs, explained that during the criminal preliminary hearing, defense attorneys had sought psychiatric records of the alleged victims.</content>
      <tokens>
        <token id="1" string="Greg" lemma="Greg" stem="greg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Mooney" lemma="Mooney" stem="moonei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="represented" lemma="represent" stem="repres" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="plaintiffs" lemma="plaintiff" stem="plaintiff" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="explained" lemma="explain" stem="explain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="preliminary" lemma="preliminary" stem="preliminari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="defense" lemma="defense" stem="defens" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="attorneys" lemma="attorney" stem="attornei" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="sought" lemma="seek" stem="sought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="psychiatric" lemma="psychiatric" stem="psychiatr" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="alleged" lemma="allege" stem="alleg" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Greg) (NNP Mooney)) (, ,) (NP (NP (DT an) (NN attorney)) (SBAR (WHNP (WP who)) (S (VP (VBD represented) (NP (NP (DT some)) (PP (IN of) (NP (DT the) (NNS plaintiffs)))))))) (, ,)) (VP (VBD explained) (SBAR (IN that) (S (PP (IN during) (NP (DT the) (JJ criminal) (JJ preliminary) (NN hearing))) (, ,) (NP (NN defense) (NNS attorneys)) (VP (VBD had) (VP (VBN sought) (NP (NP (JJ psychiatric) (NNS records)) (PP (IN of) (NP (DT the) (VBN alleged) (NNS victims))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the alleged victims" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="alleged" />
            <token id="30" string="victims" />
          </tokens>
        </chunking>
        <chunking id="2" string="Greg Mooney , an attorney who represented some of the plaintiffs ," type="NP">
          <tokens>
            <token id="1" string="Greg" />
            <token id="2" string="Mooney" />
            <token id="3" string="," />
            <token id="4" string="an" />
            <token id="5" string="attorney" />
            <token id="6" string="who" />
            <token id="7" string="represented" />
            <token id="8" string="some" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="plaintiffs" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="had sought psychiatric records of the alleged victims" type="VP">
          <tokens>
            <token id="23" string="had" />
            <token id="24" string="sought" />
            <token id="25" string="psychiatric" />
            <token id="26" string="records" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="alleged" />
            <token id="30" string="victims" />
          </tokens>
        </chunking>
        <chunking id="4" string="an attorney who represented some of the plaintiffs" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="attorney" />
            <token id="6" string="who" />
            <token id="7" string="represented" />
            <token id="8" string="some" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="plaintiffs" />
          </tokens>
        </chunking>
        <chunking id="5" string="some" type="NP">
          <tokens>
            <token id="8" string="some" />
          </tokens>
        </chunking>
        <chunking id="6" string="psychiatric records of the alleged victims" type="NP">
          <tokens>
            <token id="25" string="psychiatric" />
            <token id="26" string="records" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="alleged" />
            <token id="30" string="victims" />
          </tokens>
        </chunking>
        <chunking id="7" string="represented some of the plaintiffs" type="VP">
          <tokens>
            <token id="7" string="represented" />
            <token id="8" string="some" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="plaintiffs" />
          </tokens>
        </chunking>
        <chunking id="8" string="that during the criminal preliminary hearing , defense attorneys had sought psychiatric records of the alleged victims" type="SBAR">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="during" />
            <token id="16" string="the" />
            <token id="17" string="criminal" />
            <token id="18" string="preliminary" />
            <token id="19" string="hearing" />
            <token id="20" string="," />
            <token id="21" string="defense" />
            <token id="22" string="attorneys" />
            <token id="23" string="had" />
            <token id="24" string="sought" />
            <token id="25" string="psychiatric" />
            <token id="26" string="records" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="alleged" />
            <token id="30" string="victims" />
          </tokens>
        </chunking>
        <chunking id="9" string="sought psychiatric records of the alleged victims" type="VP">
          <tokens>
            <token id="24" string="sought" />
            <token id="25" string="psychiatric" />
            <token id="26" string="records" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="alleged" />
            <token id="30" string="victims" />
          </tokens>
        </chunking>
        <chunking id="10" string="Greg Mooney" type="NP">
          <tokens>
            <token id="1" string="Greg" />
            <token id="2" string="Mooney" />
          </tokens>
        </chunking>
        <chunking id="11" string="who represented some of the plaintiffs" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="represented" />
            <token id="8" string="some" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="plaintiffs" />
          </tokens>
        </chunking>
        <chunking id="12" string="defense attorneys" type="NP">
          <tokens>
            <token id="21" string="defense" />
            <token id="22" string="attorneys" />
          </tokens>
        </chunking>
        <chunking id="13" string="the plaintiffs" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="plaintiffs" />
          </tokens>
        </chunking>
        <chunking id="14" string="psychiatric records" type="NP">
          <tokens>
            <token id="25" string="psychiatric" />
            <token id="26" string="records" />
          </tokens>
        </chunking>
        <chunking id="15" string="some of the plaintiffs" type="NP">
          <tokens>
            <token id="8" string="some" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="plaintiffs" />
          </tokens>
        </chunking>
        <chunking id="16" string="explained that during the criminal preliminary hearing , defense attorneys had sought psychiatric records of the alleged victims" type="VP">
          <tokens>
            <token id="13" string="explained" />
            <token id="14" string="that" />
            <token id="15" string="during" />
            <token id="16" string="the" />
            <token id="17" string="criminal" />
            <token id="18" string="preliminary" />
            <token id="19" string="hearing" />
            <token id="20" string="," />
            <token id="21" string="defense" />
            <token id="22" string="attorneys" />
            <token id="23" string="had" />
            <token id="24" string="sought" />
            <token id="25" string="psychiatric" />
            <token id="26" string="records" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="alleged" />
            <token id="30" string="victims" />
          </tokens>
        </chunking>
        <chunking id="17" string="an attorney" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="18" string="the criminal preliminary hearing" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="criminal" />
            <token id="18" string="preliminary" />
            <token id="19" string="hearing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Mooney</governor>
          <dependent id="1">Greg</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">explained</governor>
          <dependent id="2">Mooney</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">attorney</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Mooney</governor>
          <dependent id="5">attorney</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">represented</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">attorney</governor>
          <dependent id="7">represented</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">represented</governor>
          <dependent id="8">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">plaintiffs</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">plaintiffs</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">some</governor>
          <dependent id="11">plaintiffs</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">explained</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">sought</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">hearing</governor>
          <dependent id="15">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">hearing</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">hearing</governor>
          <dependent id="17">criminal</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">hearing</governor>
          <dependent id="18">preliminary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">sought</governor>
          <dependent id="19">hearing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">attorneys</governor>
          <dependent id="21">defense</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">sought</governor>
          <dependent id="22">attorneys</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">sought</governor>
          <dependent id="23">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">explained</governor>
          <dependent id="24">sought</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">records</governor>
          <dependent id="25">psychiatric</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">sought</governor>
          <dependent id="26">records</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">victims</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">victims</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">victims</governor>
          <dependent id="29">alleged</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">records</governor>
          <dependent id="30">victims</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Greg Mooney" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Greg" />
            <token id="2" string="Mooney" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Defense attorneys argued that they should be entitled to the records because the children had waived their patient-therapist confidentiality by filing civil suits in which their psychiatric histories would be at issue.</content>
      <tokens>
        <token id="1" string="Defense" lemma="Defense" stem="defens" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="attorneys" lemma="attorney" stem="attornei" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="argued" lemma="argue" stem="argu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="entitled" lemma="entitle" stem="entitl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="waived" lemma="waive" stem="waiv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="patient-therapist" lemma="patient-therapist" stem="patient-therapist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="confidentiality" lemma="confidentiality" stem="confidenti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="filing" lemma="file" stem="file" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="suits" lemma="suit" stem="suit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="psychiatric" lemma="psychiatric" stem="psychiatr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="histories" lemma="history" stem="histori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Defense) (NNS attorneys)) (VP (VBD argued) (SBAR (IN that) (S (NP (PRP they)) (VP (MD should) (VP (VB be) (VP (VBN entitled) (PP (TO to) (NP (DT the) (NNS records))) (SBAR (IN because) (S (NP (DT the) (NNS children)) (VP (VBD had) (VP (VBN waived) (NP (PRP$ their) (JJ patient-therapist) (NN confidentiality)) (PP (IN by) (S (VP (VBG filing) (NP (NP (JJ civil) (NNS suits)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (PRP$ their) (JJ psychiatric) (NNS histories)) (VP (MD would) (VP (VB be) (PP (IN at) (NP (NN issue))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="filing civil suits in which their psychiatric histories would be at issue" type="VP">
          <tokens>
            <token id="21" string="filing" />
            <token id="22" string="civil" />
            <token id="23" string="suits" />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="2" string="in which their psychiatric histories would be at issue" type="SBAR">
          <tokens>
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="3" string="should be entitled to the records because the children had waived their patient-therapist confidentiality by filing civil suits in which their psychiatric histories would be at issue" type="VP">
          <tokens>
            <token id="6" string="should" />
            <token id="7" string="be" />
            <token id="8" string="entitled" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="records" />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="children" />
            <token id="15" string="had" />
            <token id="16" string="waived" />
            <token id="17" string="their" />
            <token id="18" string="patient-therapist" />
            <token id="19" string="confidentiality" />
            <token id="20" string="by" />
            <token id="21" string="filing" />
            <token id="22" string="civil" />
            <token id="23" string="suits" />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="4" string="issue" type="NP">
          <tokens>
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="5" string="civil suits" type="NP">
          <tokens>
            <token id="22" string="civil" />
            <token id="23" string="suits" />
          </tokens>
        </chunking>
        <chunking id="6" string="waived their patient-therapist confidentiality by filing civil suits in which their psychiatric histories would be at issue" type="VP">
          <tokens>
            <token id="16" string="waived" />
            <token id="17" string="their" />
            <token id="18" string="patient-therapist" />
            <token id="19" string="confidentiality" />
            <token id="20" string="by" />
            <token id="21" string="filing" />
            <token id="22" string="civil" />
            <token id="23" string="suits" />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="7" string="their psychiatric histories" type="NP">
          <tokens>
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="5" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="the records" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="records" />
          </tokens>
        </chunking>
        <chunking id="10" string="civil suits in which their psychiatric histories would be at issue" type="NP">
          <tokens>
            <token id="22" string="civil" />
            <token id="23" string="suits" />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="11" string="because the children had waived their patient-therapist confidentiality by filing civil suits in which their psychiatric histories would be at issue" type="SBAR">
          <tokens>
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="children" />
            <token id="15" string="had" />
            <token id="16" string="waived" />
            <token id="17" string="their" />
            <token id="18" string="patient-therapist" />
            <token id="19" string="confidentiality" />
            <token id="20" string="by" />
            <token id="21" string="filing" />
            <token id="22" string="civil" />
            <token id="23" string="suits" />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="12" string="the children" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="13" string="their patient-therapist confidentiality" type="NP">
          <tokens>
            <token id="17" string="their" />
            <token id="18" string="patient-therapist" />
            <token id="19" string="confidentiality" />
          </tokens>
        </chunking>
        <chunking id="14" string="had waived their patient-therapist confidentiality by filing civil suits in which their psychiatric histories would be at issue" type="VP">
          <tokens>
            <token id="15" string="had" />
            <token id="16" string="waived" />
            <token id="17" string="their" />
            <token id="18" string="patient-therapist" />
            <token id="19" string="confidentiality" />
            <token id="20" string="by" />
            <token id="21" string="filing" />
            <token id="22" string="civil" />
            <token id="23" string="suits" />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="15" string="be entitled to the records because the children had waived their patient-therapist confidentiality by filing civil suits in which their psychiatric histories would be at issue" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="entitled" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="records" />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="children" />
            <token id="15" string="had" />
            <token id="16" string="waived" />
            <token id="17" string="their" />
            <token id="18" string="patient-therapist" />
            <token id="19" string="confidentiality" />
            <token id="20" string="by" />
            <token id="21" string="filing" />
            <token id="22" string="civil" />
            <token id="23" string="suits" />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="16" string="entitled to the records because the children had waived their patient-therapist confidentiality by filing civil suits in which their psychiatric histories would be at issue" type="VP">
          <tokens>
            <token id="8" string="entitled" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="records" />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="children" />
            <token id="15" string="had" />
            <token id="16" string="waived" />
            <token id="17" string="their" />
            <token id="18" string="patient-therapist" />
            <token id="19" string="confidentiality" />
            <token id="20" string="by" />
            <token id="21" string="filing" />
            <token id="22" string="civil" />
            <token id="23" string="suits" />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="17" string="be at issue" type="VP">
          <tokens>
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="18" string="argued that they should be entitled to the records because the children had waived their patient-therapist confidentiality by filing civil suits in which their psychiatric histories would be at issue" type="VP">
          <tokens>
            <token id="3" string="argued" />
            <token id="4" string="that" />
            <token id="5" string="they" />
            <token id="6" string="should" />
            <token id="7" string="be" />
            <token id="8" string="entitled" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="records" />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="children" />
            <token id="15" string="had" />
            <token id="16" string="waived" />
            <token id="17" string="their" />
            <token id="18" string="patient-therapist" />
            <token id="19" string="confidentiality" />
            <token id="20" string="by" />
            <token id="21" string="filing" />
            <token id="22" string="civil" />
            <token id="23" string="suits" />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="19" string="Defense attorneys" type="NP">
          <tokens>
            <token id="1" string="Defense" />
            <token id="2" string="attorneys" />
          </tokens>
        </chunking>
        <chunking id="20" string="that they should be entitled to the records because the children had waived their patient-therapist confidentiality by filing civil suits in which their psychiatric histories would be at issue" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="they" />
            <token id="6" string="should" />
            <token id="7" string="be" />
            <token id="8" string="entitled" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="records" />
            <token id="12" string="because" />
            <token id="13" string="the" />
            <token id="14" string="children" />
            <token id="15" string="had" />
            <token id="16" string="waived" />
            <token id="17" string="their" />
            <token id="18" string="patient-therapist" />
            <token id="19" string="confidentiality" />
            <token id="20" string="by" />
            <token id="21" string="filing" />
            <token id="22" string="civil" />
            <token id="23" string="suits" />
            <token id="24" string="in" />
            <token id="25" string="which" />
            <token id="26" string="their" />
            <token id="27" string="psychiatric" />
            <token id="28" string="histories" />
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
        <chunking id="21" string="would be at issue" type="VP">
          <tokens>
            <token id="29" string="would" />
            <token id="30" string="be" />
            <token id="31" string="at" />
            <token id="32" string="issue" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">attorneys</governor>
          <dependent id="1">Defense</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">argued</governor>
          <dependent id="2">attorneys</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">argued</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">entitled</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">entitled</governor>
          <dependent id="5">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">entitled</governor>
          <dependent id="6">should</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">entitled</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">argued</governor>
          <dependent id="8">entitled</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">records</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">records</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">entitled</governor>
          <dependent id="11">records</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">waived</governor>
          <dependent id="12">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">children</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">waived</governor>
          <dependent id="14">children</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">waived</governor>
          <dependent id="15">had</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">entitled</governor>
          <dependent id="16">waived</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">confidentiality</governor>
          <dependent id="17">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">confidentiality</governor>
          <dependent id="18">patient-therapist</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">waived</governor>
          <dependent id="19">confidentiality</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">filing</governor>
          <dependent id="20">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">waived</governor>
          <dependent id="21">filing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">suits</governor>
          <dependent id="22">civil</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">filing</governor>
          <dependent id="23">suits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">which</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">issue</governor>
          <dependent id="25">which</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">histories</governor>
          <dependent id="26">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">histories</governor>
          <dependent id="27">psychiatric</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">issue</governor>
          <dependent id="28">histories</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="32">issue</governor>
          <dependent id="29">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="32">issue</governor>
          <dependent id="30">be</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">issue</governor>
          <dependent id="31">at</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">suits</governor>
          <dependent id="32">issue</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>&amp;quot;The civil suits were withdrawn so they would not become an issue in the criminal case,&amp;quot; Mooney said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="suits" lemma="suit" stem="suit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="withdrawn" lemma="withdraw" stem="withdrawn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Mooney" lemma="Mooney" stem="moonei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (JJ civil) (NNS suits)) (VP (VBD were) (VP (VBN withdrawn) (SBAR (IN so) (S (NP (PRP they)) (VP (MD would) (RB not) (VP (VB become) (NP (NP (DT an) (NN issue)) (PP (IN in) (NP (DT the) (JJ criminal) (NN case))))))))))) (, ,) ('' '') (NP (NNP Mooney)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mooney" type="NP">
          <tokens>
            <token id="20" string="Mooney" />
          </tokens>
        </chunking>
        <chunking id="3" string="withdrawn so they would not become an issue in the criminal case" type="VP">
          <tokens>
            <token id="6" string="withdrawn" />
            <token id="7" string="so" />
            <token id="8" string="they" />
            <token id="9" string="would" />
            <token id="10" string="not" />
            <token id="11" string="become" />
            <token id="12" string="an" />
            <token id="13" string="issue" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="The civil suits" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="civil" />
            <token id="4" string="suits" />
          </tokens>
        </chunking>
        <chunking id="5" string="would not become an issue in the criminal case" type="VP">
          <tokens>
            <token id="9" string="would" />
            <token id="10" string="not" />
            <token id="11" string="become" />
            <token id="12" string="an" />
            <token id="13" string="issue" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="an issue in the criminal case" type="NP">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="issue" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="the criminal case" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="so they would not become an issue in the criminal case" type="SBAR">
          <tokens>
            <token id="7" string="so" />
            <token id="8" string="they" />
            <token id="9" string="would" />
            <token id="10" string="not" />
            <token id="11" string="become" />
            <token id="12" string="an" />
            <token id="13" string="issue" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="case" />
          </tokens>
        </chunking>
        <chunking id="9" string="were withdrawn so they would not become an issue in the criminal case" type="VP">
          <tokens>
            <token id="5" string="were" />
            <token id="6" string="withdrawn" />
            <token id="7" string="so" />
            <token id="8" string="they" />
            <token id="9" string="would" />
            <token id="10" string="not" />
            <token id="11" string="become" />
            <token id="12" string="an" />
            <token id="13" string="issue" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="become an issue in the criminal case" type="VP">
          <tokens>
            <token id="11" string="become" />
            <token id="12" string="an" />
            <token id="13" string="issue" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="case" />
          </tokens>
        </chunking>
        <chunking id="11" string="an issue" type="NP">
          <tokens>
            <token id="12" string="an" />
            <token id="13" string="issue" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="21" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">suits</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">suits</governor>
          <dependent id="3">civil</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">withdrawn</governor>
          <dependent id="4">suits</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">withdrawn</governor>
          <dependent id="5">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">said</governor>
          <dependent id="6">withdrawn</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">become</governor>
          <dependent id="7">so</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">become</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">become</governor>
          <dependent id="9">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">become</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">withdrawn</governor>
          <dependent id="11">become</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">issue</governor>
          <dependent id="12">an</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">become</governor>
          <dependent id="13">issue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">case</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">case</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">case</governor>
          <dependent id="16">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">issue</governor>
          <dependent id="17">case</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">said</governor>
          <dependent id="20">Mooney</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mooney" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Mooney" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>He said Friday, however, that the civil lawsuits can now be refiled.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Friday" lemma="Friday" stem="fridai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="lawsuits" lemma="lawsuit" stem="lawsuit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="refiled" lemma="refile" stem="refil" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD said) (NP-TMP (NNP Friday)) (, ,) (ADVP (RB however)) (, ,) (SBAR (IN that) (S (NP (DT the) (JJ civil) (NNS lawsuits)) (VP (MD can) (ADVP (RB now)) (VP (VB be) (VP (VBN refiled))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that the civil lawsuits can now be refiled" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="civil" />
            <token id="10" string="lawsuits" />
            <token id="11" string="can" />
            <token id="12" string="now" />
            <token id="13" string="be" />
            <token id="14" string="refiled" />
          </tokens>
        </chunking>
        <chunking id="2" string="the civil lawsuits" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="civil" />
            <token id="10" string="lawsuits" />
          </tokens>
        </chunking>
        <chunking id="3" string="be refiled" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="refiled" />
          </tokens>
        </chunking>
        <chunking id="4" string="said Friday , however , that the civil lawsuits can now be refiled" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Friday" />
            <token id="4" string="," />
            <token id="5" string="however" />
            <token id="6" string="," />
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="civil" />
            <token id="10" string="lawsuits" />
            <token id="11" string="can" />
            <token id="12" string="now" />
            <token id="13" string="be" />
            <token id="14" string="refiled" />
          </tokens>
        </chunking>
        <chunking id="5" string="refiled" type="VP">
          <tokens>
            <token id="14" string="refiled" />
          </tokens>
        </chunking>
        <chunking id="6" string="can now be refiled" type="VP">
          <tokens>
            <token id="11" string="can" />
            <token id="12" string="now" />
            <token id="13" string="be" />
            <token id="14" string="refiled" />
          </tokens>
        </chunking>
        <chunking id="7" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">said</governor>
          <dependent id="3">Friday</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">said</governor>
          <dependent id="5">however</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">refiled</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">lawsuits</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">lawsuits</governor>
          <dependent id="9">civil</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">refiled</governor>
          <dependent id="10">lawsuits</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">refiled</governor>
          <dependent id="11">can</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">refiled</governor>
          <dependent id="12">now</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">refiled</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="14">refiled</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Friday" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="Friday" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>Mooney said a decision on whether to refile will be made only after authorities decide what to do with the 13 remaining criminal counts.</content>
      <tokens>
        <token id="1" string="Mooney" lemma="Mooney" stem="moonei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="refile" lemma="refile" stem="refil" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="authorities" lemma="authority" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="decide" lemma="decide" stem="decid" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="22" string="remaining" lemma="remain" stem="remain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mooney)) (VP (VBD said) (SBAR (S (NP (NP (DT a) (NN decision)) (PP (IN on) (SBAR (IN whether) (S (VP (TO to) (VP (VB refile))))))) (VP (MD will) (VP (VB be) (VP (VBN made) (SBAR (RB only) (IN after) (S (NP (NNS authorities)) (VP (VBP decide) (SBAR (WHNP (WP what)) (S (VP (TO to) (VP (VB do) (PP (IN with) (NP (DT the) (CD 13))) (S (VP (VBG remaining) (NP (JJ criminal) (NNS counts))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to refile" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="refile" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mooney" type="NP">
          <tokens>
            <token id="1" string="Mooney" />
          </tokens>
        </chunking>
        <chunking id="3" string="said a decision on whether to refile will be made only after authorities decide what to do with the 13 remaining criminal counts" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="a" />
            <token id="4" string="decision" />
            <token id="5" string="on" />
            <token id="6" string="whether" />
            <token id="7" string="to" />
            <token id="8" string="refile" />
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="made" />
            <token id="12" string="only" />
            <token id="13" string="after" />
            <token id="14" string="authorities" />
            <token id="15" string="decide" />
            <token id="16" string="what" />
            <token id="17" string="to" />
            <token id="18" string="do" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="13" />
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="4" string="a decision" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="decision" />
          </tokens>
        </chunking>
        <chunking id="5" string="made only after authorities decide what to do with the 13 remaining criminal counts" type="VP">
          <tokens>
            <token id="11" string="made" />
            <token id="12" string="only" />
            <token id="13" string="after" />
            <token id="14" string="authorities" />
            <token id="15" string="decide" />
            <token id="16" string="what" />
            <token id="17" string="to" />
            <token id="18" string="do" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="13" />
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="6" string="refile" type="VP">
          <tokens>
            <token id="8" string="refile" />
          </tokens>
        </chunking>
        <chunking id="7" string="will be made only after authorities decide what to do with the 13 remaining criminal counts" type="VP">
          <tokens>
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="made" />
            <token id="12" string="only" />
            <token id="13" string="after" />
            <token id="14" string="authorities" />
            <token id="15" string="decide" />
            <token id="16" string="what" />
            <token id="17" string="to" />
            <token id="18" string="do" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="13" />
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 13" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="13" />
          </tokens>
        </chunking>
        <chunking id="9" string="a decision on whether to refile will be made only after authorities decide what to do with the 13 remaining criminal counts" type="SBAR">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="decision" />
            <token id="5" string="on" />
            <token id="6" string="whether" />
            <token id="7" string="to" />
            <token id="8" string="refile" />
            <token id="9" string="will" />
            <token id="10" string="be" />
            <token id="11" string="made" />
            <token id="12" string="only" />
            <token id="13" string="after" />
            <token id="14" string="authorities" />
            <token id="15" string="decide" />
            <token id="16" string="what" />
            <token id="17" string="to" />
            <token id="18" string="do" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="13" />
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="10" string="authorities" type="NP">
          <tokens>
            <token id="14" string="authorities" />
          </tokens>
        </chunking>
        <chunking id="11" string="only after authorities decide what to do with the 13 remaining criminal counts" type="SBAR">
          <tokens>
            <token id="12" string="only" />
            <token id="13" string="after" />
            <token id="14" string="authorities" />
            <token id="15" string="decide" />
            <token id="16" string="what" />
            <token id="17" string="to" />
            <token id="18" string="do" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="13" />
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="12" string="do with the 13 remaining criminal counts" type="VP">
          <tokens>
            <token id="18" string="do" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="13" />
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="13" string="remaining criminal counts" type="VP">
          <tokens>
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="14" string="criminal counts" type="NP">
          <tokens>
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="15" string="be made only after authorities decide what to do with the 13 remaining criminal counts" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="made" />
            <token id="12" string="only" />
            <token id="13" string="after" />
            <token id="14" string="authorities" />
            <token id="15" string="decide" />
            <token id="16" string="what" />
            <token id="17" string="to" />
            <token id="18" string="do" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="13" />
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="16" string="decide what to do with the 13 remaining criminal counts" type="VP">
          <tokens>
            <token id="15" string="decide" />
            <token id="16" string="what" />
            <token id="17" string="to" />
            <token id="18" string="do" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="13" />
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="17" string="to do with the 13 remaining criminal counts" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="do" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="13" />
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="18" string="whether to refile" type="SBAR">
          <tokens>
            <token id="6" string="whether" />
            <token id="7" string="to" />
            <token id="8" string="refile" />
          </tokens>
        </chunking>
        <chunking id="19" string="what to do with the 13 remaining criminal counts" type="SBAR">
          <tokens>
            <token id="16" string="what" />
            <token id="17" string="to" />
            <token id="18" string="do" />
            <token id="19" string="with" />
            <token id="20" string="the" />
            <token id="21" string="13" />
            <token id="22" string="remaining" />
            <token id="23" string="criminal" />
            <token id="24" string="counts" />
          </tokens>
        </chunking>
        <chunking id="20" string="a decision on whether to refile" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="decision" />
            <token id="5" string="on" />
            <token id="6" string="whether" />
            <token id="7" string="to" />
            <token id="8" string="refile" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Mooney</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">decision</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">made</governor>
          <dependent id="4">decision</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">refile</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">refile</governor>
          <dependent id="6">whether</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">refile</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">decision</governor>
          <dependent id="8">refile</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">made</governor>
          <dependent id="9">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">made</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="11">made</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">decide</governor>
          <dependent id="12">only</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">decide</governor>
          <dependent id="13">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">decide</governor>
          <dependent id="14">authorities</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">made</governor>
          <dependent id="15">decide</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">do</governor>
          <dependent id="16">what</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">do</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">decide</governor>
          <dependent id="18">do</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">13</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">13</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">do</governor>
          <dependent id="21">13</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">do</governor>
          <dependent id="22">remaining</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">counts</governor>
          <dependent id="23">criminal</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">remaining</governor>
          <dependent id="24">counts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mooney" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mooney" />
          </tokens>
        </entity>
        <entity id="2" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="13" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s impossible to predict how many parents will want to sue,&amp;quot; Mooney said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="impossible" lemma="impossible" stem="imposs" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="predict" lemma="predict" stem="predict" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="want" lemma="want" stem="want" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="sue" lemma="sue" stem="sue" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Mooney" lemma="Mooney" stem="moonei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (ADJP (JJ impossible) (S (VP (TO to) (VP (VB predict) (SBAR (WHNP (WHADJP (WRB how) (JJ many)) (NNS parents)) (S (VP (MD will) (VP (VB want) (S (VP (TO to) (VP (VB sue)))))))))))))) (, ,) ('' '') (NP (NNP Mooney)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to predict how many parents will want to sue" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="predict" />
            <token id="7" string="how" />
            <token id="8" string="many" />
            <token id="9" string="parents" />
            <token id="10" string="will" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="sue" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mooney" type="NP">
          <tokens>
            <token id="16" string="Mooney" />
          </tokens>
        </chunking>
        <chunking id="3" string="to sue" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="sue" />
          </tokens>
        </chunking>
        <chunking id="4" string="sue" type="VP">
          <tokens>
            <token id="13" string="sue" />
          </tokens>
        </chunking>
        <chunking id="5" string="want to sue" type="VP">
          <tokens>
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="sue" />
          </tokens>
        </chunking>
        <chunking id="6" string="predict how many parents will want to sue" type="VP">
          <tokens>
            <token id="6" string="predict" />
            <token id="7" string="how" />
            <token id="8" string="many" />
            <token id="9" string="parents" />
            <token id="10" string="will" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="sue" />
          </tokens>
        </chunking>
        <chunking id="7" string="impossible to predict how many parents will want to sue" type="ADJP">
          <tokens>
            <token id="4" string="impossible" />
            <token id="5" string="to" />
            <token id="6" string="predict" />
            <token id="7" string="how" />
            <token id="8" string="many" />
            <token id="9" string="parents" />
            <token id="10" string="will" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="sue" />
          </tokens>
        </chunking>
        <chunking id="8" string="how many parents will want to sue" type="SBAR">
          <tokens>
            <token id="7" string="how" />
            <token id="8" string="many" />
            <token id="9" string="parents" />
            <token id="10" string="will" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="sue" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="'s impossible to predict how many parents will want to sue" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="impossible" />
            <token id="5" string="to" />
            <token id="6" string="predict" />
            <token id="7" string="how" />
            <token id="8" string="many" />
            <token id="9" string="parents" />
            <token id="10" string="will" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="sue" />
          </tokens>
        </chunking>
        <chunking id="11" string="will want to sue" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="sue" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="17" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">impossible</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">impossible</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="4">impossible</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">predict</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">impossible</governor>
          <dependent id="6">predict</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">many</governor>
          <dependent id="7">how</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">parents</governor>
          <dependent id="8">many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">want</governor>
          <dependent id="9">parents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">want</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">predict</governor>
          <dependent id="11">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">sue</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">want</governor>
          <dependent id="13">sue</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="16">Mooney</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mooney" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Mooney" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="false">
      <content>&amp;quot;Somewhere between a handful and a bushelful.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Somewhere" lemma="somewhere" stem="somewher" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="handful" lemma="handful" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="bushelful" lemma="bushelful" stem="bushel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (`` ``) (ADJP (ADJP (RB Somewhere)) (PP (IN between) (NP (NP (DT a)) (NP-TMP (NN handful)) (PP (CC and) (NP (DT a))) (NP (NN bushelful))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="a" type="NP">
          <tokens>
            <token id="4" string="a" />
          </tokens>
        </chunking>
        <chunking id="2" string="Somewhere" type="ADJP">
          <tokens>
            <token id="2" string="Somewhere" />
          </tokens>
        </chunking>
        <chunking id="3" string="a handful and a bushelful" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="handful" />
            <token id="6" string="and" />
            <token id="7" string="a" />
            <token id="8" string="bushelful" />
          </tokens>
        </chunking>
        <chunking id="4" string="Somewhere between a handful and a bushelful" type="ADJP">
          <tokens>
            <token id="2" string="Somewhere" />
            <token id="3" string="between" />
            <token id="4" string="a" />
            <token id="5" string="handful" />
            <token id="6" string="and" />
            <token id="7" string="a" />
            <token id="8" string="bushelful" />
          </tokens>
        </chunking>
        <chunking id="5" string="bushelful" type="NP">
          <tokens>
            <token id="8" string="bushelful" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Somewhere</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">a</governor>
          <dependent id="3">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Somewhere</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">a</governor>
          <dependent id="5">handful</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">a</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">a</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">a</governor>
          <dependent id="8">bushelful</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>Any new suits would have to be filed only on behalf of the children.</content>
      <tokens>
        <token id="1" string="Any" lemma="any" stem="any" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="suits" lemma="suit" stem="suit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="behalf" lemma="behalf" stem="behalf" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Any) (JJ new) (NNS suits)) (VP (MD would) (VP (VB have) (S (VP (TO to) (VP (VB be) (VP (VBN filed) (ADVP (RB only)) (PP (IN on) (NP (NP (NN behalf)) (PP (IN of) (NP (DT the) (NNS children))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="filed only on behalf of the children" type="VP">
          <tokens>
            <token id="8" string="filed" />
            <token id="9" string="only" />
            <token id="10" string="on" />
            <token id="11" string="behalf" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="2" string="the children" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="behalf of the children" type="NP">
          <tokens>
            <token id="11" string="behalf" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="4" string="to be filed only on behalf of the children" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="filed" />
            <token id="9" string="only" />
            <token id="10" string="on" />
            <token id="11" string="behalf" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="be filed only on behalf of the children" type="VP">
          <tokens>
            <token id="7" string="be" />
            <token id="8" string="filed" />
            <token id="9" string="only" />
            <token id="10" string="on" />
            <token id="11" string="behalf" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="Any new suits" type="NP">
          <tokens>
            <token id="1" string="Any" />
            <token id="2" string="new" />
            <token id="3" string="suits" />
          </tokens>
        </chunking>
        <chunking id="7" string="have to be filed only on behalf of the children" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="filed" />
            <token id="9" string="only" />
            <token id="10" string="on" />
            <token id="11" string="behalf" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="would have to be filed only on behalf of the children" type="VP">
          <tokens>
            <token id="4" string="would" />
            <token id="5" string="have" />
            <token id="6" string="to" />
            <token id="7" string="be" />
            <token id="8" string="filed" />
            <token id="9" string="only" />
            <token id="10" string="on" />
            <token id="11" string="behalf" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="behalf" type="NP">
          <tokens>
            <token id="11" string="behalf" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">suits</governor>
          <dependent id="1">Any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">suits</governor>
          <dependent id="2">new</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">have</governor>
          <dependent id="3">suits</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">have</governor>
          <dependent id="4">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">filed</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">filed</governor>
          <dependent id="7">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">have</governor>
          <dependent id="8">filed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">filed</governor>
          <dependent id="9">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">children</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="10">on</governor>
          <dependent id="11">behalf</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="10">on</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">children</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">filed</governor>
          <dependent id="14">children</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>The parents could not seek damages on their own, because the one-year statute of limitations -- the deadline in which a lawsuit can be filed -- has passed.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="seek" lemma="seek" stem="seek" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="damages" lemma="damages" stem="damag" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="one-year" lemma="one-year" stem="one-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="statute" lemma="statute" stem="statut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="limitations" lemma="limitation" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="deadline" lemma="deadline" stem="deadlin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="passed" lemma="pass" stem="pass" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS parents)) (VP (MD could) (RB not) (VP (VB seek) (NP (NNS damages)) (PP (IN on) (NP (PRP$ their) (JJ own))) (, ,) (SBAR (IN because) (S (NP (NP (DT the) (JJ one-year) (NN statute)) (PP (IN of) (NP (NP (NNS limitations)) (PRN (: --) (NP (NP (DT the) (NN deadline)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT a) (NN lawsuit)) (VP (MD can) (VP (VB be) (VP (VBN filed))))))) (: --))))) (VP (VBZ has) (VP (VBN passed))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="damages" type="NP">
          <tokens>
            <token id="6" string="damages" />
          </tokens>
        </chunking>
        <chunking id="2" string="the deadline in which a lawsuit can be filed" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="deadline" />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="a" />
            <token id="23" string="lawsuit" />
            <token id="24" string="can" />
            <token id="25" string="be" />
            <token id="26" string="filed" />
          </tokens>
        </chunking>
        <chunking id="3" string="passed" type="VP">
          <tokens>
            <token id="29" string="passed" />
          </tokens>
        </chunking>
        <chunking id="4" string="The parents" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="parents" />
          </tokens>
        </chunking>
        <chunking id="5" string="the one-year statute of limitations -- the deadline in which a lawsuit can be filed --" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="one-year" />
            <token id="14" string="statute" />
            <token id="15" string="of" />
            <token id="16" string="limitations" />
            <token id="17" string="--" />
            <token id="18" string="the" />
            <token id="19" string="deadline" />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="a" />
            <token id="23" string="lawsuit" />
            <token id="24" string="can" />
            <token id="25" string="be" />
            <token id="26" string="filed" />
            <token id="27" string="--" />
          </tokens>
        </chunking>
        <chunking id="6" string="filed" type="VP">
          <tokens>
            <token id="26" string="filed" />
          </tokens>
        </chunking>
        <chunking id="7" string="seek damages on their own , because the one-year statute of limitations -- the deadline in which a lawsuit can be filed -- has passed" type="VP">
          <tokens>
            <token id="5" string="seek" />
            <token id="6" string="damages" />
            <token id="7" string="on" />
            <token id="8" string="their" />
            <token id="9" string="own" />
            <token id="10" string="," />
            <token id="11" string="because" />
            <token id="12" string="the" />
            <token id="13" string="one-year" />
            <token id="14" string="statute" />
            <token id="15" string="of" />
            <token id="16" string="limitations" />
            <token id="17" string="--" />
            <token id="18" string="the" />
            <token id="19" string="deadline" />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="a" />
            <token id="23" string="lawsuit" />
            <token id="24" string="can" />
            <token id="25" string="be" />
            <token id="26" string="filed" />
            <token id="27" string="--" />
            <token id="28" string="has" />
            <token id="29" string="passed" />
          </tokens>
        </chunking>
        <chunking id="8" string="their own" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="own" />
          </tokens>
        </chunking>
        <chunking id="9" string="could not seek damages on their own , because the one-year statute of limitations -- the deadline in which a lawsuit can be filed -- has passed" type="VP">
          <tokens>
            <token id="3" string="could" />
            <token id="4" string="not" />
            <token id="5" string="seek" />
            <token id="6" string="damages" />
            <token id="7" string="on" />
            <token id="8" string="their" />
            <token id="9" string="own" />
            <token id="10" string="," />
            <token id="11" string="because" />
            <token id="12" string="the" />
            <token id="13" string="one-year" />
            <token id="14" string="statute" />
            <token id="15" string="of" />
            <token id="16" string="limitations" />
            <token id="17" string="--" />
            <token id="18" string="the" />
            <token id="19" string="deadline" />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="a" />
            <token id="23" string="lawsuit" />
            <token id="24" string="can" />
            <token id="25" string="be" />
            <token id="26" string="filed" />
            <token id="27" string="--" />
            <token id="28" string="has" />
            <token id="29" string="passed" />
          </tokens>
        </chunking>
        <chunking id="10" string="has passed" type="VP">
          <tokens>
            <token id="28" string="has" />
            <token id="29" string="passed" />
          </tokens>
        </chunking>
        <chunking id="11" string="in which a lawsuit can be filed" type="SBAR">
          <tokens>
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="a" />
            <token id="23" string="lawsuit" />
            <token id="24" string="can" />
            <token id="25" string="be" />
            <token id="26" string="filed" />
          </tokens>
        </chunking>
        <chunking id="12" string="a lawsuit" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="13" string="the one-year statute" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="one-year" />
            <token id="14" string="statute" />
          </tokens>
        </chunking>
        <chunking id="14" string="limitations -- the deadline in which a lawsuit can be filed --" type="NP">
          <tokens>
            <token id="16" string="limitations" />
            <token id="17" string="--" />
            <token id="18" string="the" />
            <token id="19" string="deadline" />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="a" />
            <token id="23" string="lawsuit" />
            <token id="24" string="can" />
            <token id="25" string="be" />
            <token id="26" string="filed" />
            <token id="27" string="--" />
          </tokens>
        </chunking>
        <chunking id="15" string="can be filed" type="VP">
          <tokens>
            <token id="24" string="can" />
            <token id="25" string="be" />
            <token id="26" string="filed" />
          </tokens>
        </chunking>
        <chunking id="16" string="because the one-year statute of limitations -- the deadline in which a lawsuit can be filed -- has passed" type="SBAR">
          <tokens>
            <token id="11" string="because" />
            <token id="12" string="the" />
            <token id="13" string="one-year" />
            <token id="14" string="statute" />
            <token id="15" string="of" />
            <token id="16" string="limitations" />
            <token id="17" string="--" />
            <token id="18" string="the" />
            <token id="19" string="deadline" />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="a" />
            <token id="23" string="lawsuit" />
            <token id="24" string="can" />
            <token id="25" string="be" />
            <token id="26" string="filed" />
            <token id="27" string="--" />
            <token id="28" string="has" />
            <token id="29" string="passed" />
          </tokens>
        </chunking>
        <chunking id="17" string="the deadline" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="deadline" />
          </tokens>
        </chunking>
        <chunking id="18" string="be filed" type="VP">
          <tokens>
            <token id="25" string="be" />
            <token id="26" string="filed" />
          </tokens>
        </chunking>
        <chunking id="19" string="limitations" type="NP">
          <tokens>
            <token id="16" string="limitations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">parents</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">seek</governor>
          <dependent id="2">parents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">seek</governor>
          <dependent id="3">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">seek</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">seek</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">seek</governor>
          <dependent id="6">damages</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">own</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">own</governor>
          <dependent id="8">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">seek</governor>
          <dependent id="9">own</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">passed</governor>
          <dependent id="11">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">statute</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">statute</governor>
          <dependent id="13">one-year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">passed</governor>
          <dependent id="14">statute</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">limitations</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">statute</governor>
          <dependent id="16">limitations</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">deadline</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">limitations</governor>
          <dependent id="19">deadline</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">which</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">filed</governor>
          <dependent id="21">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">lawsuit</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">filed</governor>
          <dependent id="23">lawsuit</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">filed</governor>
          <dependent id="24">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">filed</governor>
          <dependent id="25">be</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">deadline</governor>
          <dependent id="26">filed</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">passed</governor>
          <dependent id="28">has</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">seek</governor>
          <dependent id="29">passed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one-year" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="one-year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>Under state law, children who allege abuse have until they are 19 years old to file.</content>
      <tokens>
        <token id="1" string="Under" lemma="under" stem="under" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="allege" lemma="allege" stem="alleg" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="19" lemma="19" stem="19" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="file" lemma="file" stem="file" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Under) (NP (NN state) (NN law))) (, ,) (NP (NP (NNS children)) (SBAR (WHNP (WP who)) (S (VP (VBP allege) (NP (NN abuse)))))) (VP (VBP have) (SBAR (IN until) (S (NP (PRP they)) (VP (VBP are) (ADJP (ADJP (NP (CD 19) (NNS years)) (JJ old)) (S (VP (TO to) (VP (VB file))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="abuse" type="NP">
          <tokens>
            <token id="8" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="2" string="state law" type="NP">
          <tokens>
            <token id="2" string="state" />
            <token id="3" string="law" />
          </tokens>
        </chunking>
        <chunking id="3" string="until they are 19 years old to file" type="SBAR">
          <tokens>
            <token id="10" string="until" />
            <token id="11" string="they" />
            <token id="12" string="are" />
            <token id="13" string="19" />
            <token id="14" string="years" />
            <token id="15" string="old" />
            <token id="16" string="to" />
            <token id="17" string="file" />
          </tokens>
        </chunking>
        <chunking id="4" string="are 19 years old to file" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="19" />
            <token id="14" string="years" />
            <token id="15" string="old" />
            <token id="16" string="to" />
            <token id="17" string="file" />
          </tokens>
        </chunking>
        <chunking id="5" string="19 years" type="NP">
          <tokens>
            <token id="13" string="19" />
            <token id="14" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="19 years old to file" type="ADJP">
          <tokens>
            <token id="13" string="19" />
            <token id="14" string="years" />
            <token id="15" string="old" />
            <token id="16" string="to" />
            <token id="17" string="file" />
          </tokens>
        </chunking>
        <chunking id="7" string="to file" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="file" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="11" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="allege abuse" type="VP">
          <tokens>
            <token id="7" string="allege" />
            <token id="8" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="10" string="children who allege abuse" type="NP">
          <tokens>
            <token id="5" string="children" />
            <token id="6" string="who" />
            <token id="7" string="allege" />
            <token id="8" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="11" string="children" type="NP">
          <tokens>
            <token id="5" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="file" type="VP">
          <tokens>
            <token id="17" string="file" />
          </tokens>
        </chunking>
        <chunking id="13" string="have until they are 19 years old to file" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="until" />
            <token id="11" string="they" />
            <token id="12" string="are" />
            <token id="13" string="19" />
            <token id="14" string="years" />
            <token id="15" string="old" />
            <token id="16" string="to" />
            <token id="17" string="file" />
          </tokens>
        </chunking>
        <chunking id="14" string="19 years old" type="ADJP">
          <tokens>
            <token id="13" string="19" />
            <token id="14" string="years" />
            <token id="15" string="old" />
          </tokens>
        </chunking>
        <chunking id="15" string="who allege abuse" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="allege" />
            <token id="8" string="abuse" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">law</governor>
          <dependent id="1">Under</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">law</governor>
          <dependent id="2">state</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">have</governor>
          <dependent id="3">law</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">have</governor>
          <dependent id="5">children</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">allege</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">children</governor>
          <dependent id="7">allege</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">allege</governor>
          <dependent id="8">abuse</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">old</governor>
          <dependent id="10">until</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">old</governor>
          <dependent id="11">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">old</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">years</governor>
          <dependent id="13">19</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="15">old</governor>
          <dependent id="14">years</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">have</governor>
          <dependent id="15">old</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">file</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">old</governor>
          <dependent id="17">file</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="19 years old" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="19" />
            <token id="14" string="years" />
            <token id="15" string="old" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Many of the children who attended McMartin are now entering their early teens, but the youngest of those who attended the school then is now 8 years old.</content>
      <tokens>
        <token id="1" string="Many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="attended" lemma="attend" stem="attend" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="7" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="8" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="entering" lemma="enter" stem="enter" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="teens" lemma="teens" stem="teen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="youngest" lemma="youngest" stem="youngest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="attended" lemma="attend" stem="attend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="28" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="29" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (JJ Many)) (PP (IN of) (NP (NP (DT the) (NNS children)) (SBAR (WHNP (WP who)) (S (VP (VBD attended) (NP (NNP McMartin)))))))) (VP (VBP are) (ADVP (RB now)) (VP (VBG entering) (NP (PRP$ their) (JJ early) (NNS teens))))) (, ,) (CC but) (S (NP (NP (DT the) (JJS youngest)) (PP (IN of) (NP (NP (DT those)) (SBAR (WHNP (WP who)) (S (VP (VBD attended) (NP (DT the) (NN school)) (ADVP (RB then)))))))) (VP (VBZ is) (ADVP (RB now)) (ADJP (NP (CD 8) (NNS years)) (JJ old)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who attended the school then" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="attended" />
            <token id="22" string="the" />
            <token id="23" string="school" />
            <token id="24" string="then" />
          </tokens>
        </chunking>
        <chunking id="2" string="who attended McMartin" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="attended" />
            <token id="7" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="3" string="their early teens" type="NP">
          <tokens>
            <token id="11" string="their" />
            <token id="12" string="early" />
            <token id="13" string="teens" />
          </tokens>
        </chunking>
        <chunking id="4" string="attended the school then" type="VP">
          <tokens>
            <token id="21" string="attended" />
            <token id="22" string="the" />
            <token id="23" string="school" />
            <token id="24" string="then" />
          </tokens>
        </chunking>
        <chunking id="5" string="McMartin" type="NP">
          <tokens>
            <token id="7" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="6" string="entering their early teens" type="VP">
          <tokens>
            <token id="10" string="entering" />
            <token id="11" string="their" />
            <token id="12" string="early" />
            <token id="13" string="teens" />
          </tokens>
        </chunking>
        <chunking id="7" string="Many of the children who attended McMartin" type="NP">
          <tokens>
            <token id="1" string="Many" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="children" />
            <token id="5" string="who" />
            <token id="6" string="attended" />
            <token id="7" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="8" string="is now 8 years old" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="now" />
            <token id="27" string="8" />
            <token id="28" string="years" />
            <token id="29" string="old" />
          </tokens>
        </chunking>
        <chunking id="9" string="the youngest" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="youngest" />
          </tokens>
        </chunking>
        <chunking id="10" string="are now entering their early teens" type="VP">
          <tokens>
            <token id="8" string="are" />
            <token id="9" string="now" />
            <token id="10" string="entering" />
            <token id="11" string="their" />
            <token id="12" string="early" />
            <token id="13" string="teens" />
          </tokens>
        </chunking>
        <chunking id="11" string="the youngest of those who attended the school then" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="youngest" />
            <token id="18" string="of" />
            <token id="19" string="those" />
            <token id="20" string="who" />
            <token id="21" string="attended" />
            <token id="22" string="the" />
            <token id="23" string="school" />
            <token id="24" string="then" />
          </tokens>
        </chunking>
        <chunking id="12" string="those who attended the school then" type="NP">
          <tokens>
            <token id="19" string="those" />
            <token id="20" string="who" />
            <token id="21" string="attended" />
            <token id="22" string="the" />
            <token id="23" string="school" />
            <token id="24" string="then" />
          </tokens>
        </chunking>
        <chunking id="13" string="the school" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="school" />
          </tokens>
        </chunking>
        <chunking id="14" string="the children" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="children" />
          </tokens>
        </chunking>
        <chunking id="15" string="attended McMartin" type="VP">
          <tokens>
            <token id="6" string="attended" />
            <token id="7" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="16" string="Many" type="NP">
          <tokens>
            <token id="1" string="Many" />
          </tokens>
        </chunking>
        <chunking id="17" string="8 years old" type="ADJP">
          <tokens>
            <token id="27" string="8" />
            <token id="28" string="years" />
            <token id="29" string="old" />
          </tokens>
        </chunking>
        <chunking id="18" string="the children who attended McMartin" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="children" />
            <token id="5" string="who" />
            <token id="6" string="attended" />
            <token id="7" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="19" string="8 years" type="NP">
          <tokens>
            <token id="27" string="8" />
            <token id="28" string="years" />
          </tokens>
        </chunking>
        <chunking id="20" string="those" type="NP">
          <tokens>
            <token id="19" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">entering</governor>
          <dependent id="1">Many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">children</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">children</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Many</governor>
          <dependent id="4">children</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">attended</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">children</governor>
          <dependent id="6">attended</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">attended</governor>
          <dependent id="7">McMartin</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">entering</governor>
          <dependent id="8">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">entering</governor>
          <dependent id="9">now</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">entering</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">teens</governor>
          <dependent id="11">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">teens</governor>
          <dependent id="12">early</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">entering</governor>
          <dependent id="13">teens</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">entering</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">youngest</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">old</governor>
          <dependent id="17">youngest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">those</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">youngest</governor>
          <dependent id="19">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">attended</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">those</governor>
          <dependent id="21">attended</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">school</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">attended</governor>
          <dependent id="23">school</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">attended</governor>
          <dependent id="24">then</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="29">old</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">old</governor>
          <dependent id="26">now</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">years</governor>
          <dependent id="27">8</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="29">old</governor>
          <dependent id="28">years</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">entering</governor>
          <dependent id="29">old</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="McMartin" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="McMartin" />
          </tokens>
        </entity>
        <entity id="3" string="8 years old" type="DURATION" score="0.0">
          <tokens>
            <token id="27" string="8" />
            <token id="28" string="years" />
            <token id="29" string="old" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="false">
      <content>Legal experts, however, say some courts have held that child abuse victims can file at any time in their life.</content>
      <tokens>
        <token id="1" string="Legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="say" lemma="say" stem="sai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="courts" lemma="court" stem="court" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="held" lemma="hold" stem="held" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="file" lemma="file" stem="file" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Legal) (NNS experts)) (, ,) (ADVP (RB however)) (, ,) (VP (VBP say) (SBAR (S (NP (DT some) (NNS courts)) (VP (VBP have) (VP (VBN held) (SBAR (IN that) (S (NP (NN child) (NN abuse) (NNS victims)) (VP (MD can) (VP (VB file) (PP (IN at) (NP (NP (DT any) (NN time)) (PP (IN in) (NP (PRP$ their) (NN life)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="any time in their life" type="NP">
          <tokens>
            <token id="18" string="any" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="their" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="held that child abuse victims can file at any time in their life" type="VP">
          <tokens>
            <token id="10" string="held" />
            <token id="11" string="that" />
            <token id="12" string="child" />
            <token id="13" string="abuse" />
            <token id="14" string="victims" />
            <token id="15" string="can" />
            <token id="16" string="file" />
            <token id="17" string="at" />
            <token id="18" string="any" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="their" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="3" string="say some courts have held that child abuse victims can file at any time in their life" type="VP">
          <tokens>
            <token id="6" string="say" />
            <token id="7" string="some" />
            <token id="8" string="courts" />
            <token id="9" string="have" />
            <token id="10" string="held" />
            <token id="11" string="that" />
            <token id="12" string="child" />
            <token id="13" string="abuse" />
            <token id="14" string="victims" />
            <token id="15" string="can" />
            <token id="16" string="file" />
            <token id="17" string="at" />
            <token id="18" string="any" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="their" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="can file at any time in their life" type="VP">
          <tokens>
            <token id="15" string="can" />
            <token id="16" string="file" />
            <token id="17" string="at" />
            <token id="18" string="any" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="their" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="5" string="some courts" type="NP">
          <tokens>
            <token id="7" string="some" />
            <token id="8" string="courts" />
          </tokens>
        </chunking>
        <chunking id="6" string="that child abuse victims can file at any time in their life" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="child" />
            <token id="13" string="abuse" />
            <token id="14" string="victims" />
            <token id="15" string="can" />
            <token id="16" string="file" />
            <token id="17" string="at" />
            <token id="18" string="any" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="their" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="7" string="Legal experts" type="NP">
          <tokens>
            <token id="1" string="Legal" />
            <token id="2" string="experts" />
          </tokens>
        </chunking>
        <chunking id="8" string="have held that child abuse victims can file at any time in their life" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="held" />
            <token id="11" string="that" />
            <token id="12" string="child" />
            <token id="13" string="abuse" />
            <token id="14" string="victims" />
            <token id="15" string="can" />
            <token id="16" string="file" />
            <token id="17" string="at" />
            <token id="18" string="any" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="their" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="9" string="file at any time in their life" type="VP">
          <tokens>
            <token id="16" string="file" />
            <token id="17" string="at" />
            <token id="18" string="any" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="their" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="10" string="any time" type="NP">
          <tokens>
            <token id="18" string="any" />
            <token id="19" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="their life" type="NP">
          <tokens>
            <token id="21" string="their" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
        <chunking id="12" string="child abuse victims" type="NP">
          <tokens>
            <token id="12" string="child" />
            <token id="13" string="abuse" />
            <token id="14" string="victims" />
          </tokens>
        </chunking>
        <chunking id="13" string="some courts have held that child abuse victims can file at any time in their life" type="SBAR">
          <tokens>
            <token id="7" string="some" />
            <token id="8" string="courts" />
            <token id="9" string="have" />
            <token id="10" string="held" />
            <token id="11" string="that" />
            <token id="12" string="child" />
            <token id="13" string="abuse" />
            <token id="14" string="victims" />
            <token id="15" string="can" />
            <token id="16" string="file" />
            <token id="17" string="at" />
            <token id="18" string="any" />
            <token id="19" string="time" />
            <token id="20" string="in" />
            <token id="21" string="their" />
            <token id="22" string="life" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">experts</governor>
          <dependent id="1">Legal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">say</governor>
          <dependent id="2">experts</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">say</governor>
          <dependent id="4">however</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">say</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">courts</governor>
          <dependent id="7">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">held</governor>
          <dependent id="8">courts</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">held</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">say</governor>
          <dependent id="10">held</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">file</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">victims</governor>
          <dependent id="12">child</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">victims</governor>
          <dependent id="13">abuse</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">file</governor>
          <dependent id="14">victims</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">file</governor>
          <dependent id="15">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">held</governor>
          <dependent id="16">file</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">time</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">time</governor>
          <dependent id="18">any</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">file</governor>
          <dependent id="19">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">life</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">life</governor>
          <dependent id="21">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">time</governor>
          <dependent id="22">life</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>In the so-called delayed-discovery theory, a statute of limitations does not take effect until the victim actually becomes aware of molestation, and some victims might suppress memories of such attacks for years.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="so-called" lemma="so-called" stem="so-cal" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="delayed-discovery" lemma="delayed-discovery" stem="delayed-discoveri" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="theory" lemma="theory" stem="theori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="statute" lemma="statute" stem="statut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="limitations" lemma="limitation" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="effect" lemma="effect" stem="effect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="victim" lemma="victim" stem="victim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="actually" lemma="actually" stem="actual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="becomes" lemma="become" stem="becom" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="aware" lemma="aware" stem="awar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="suppress" lemma="suppress" stem="suppress" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="memories" lemma="memory" stem="memori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="attacks" lemma="attack" stem="attack" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="33" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT the) (JJ so-called) (JJ delayed-discovery) (NN theory))) (, ,) (S (NP (NP (DT a) (NN statute)) (PP (IN of) (NP (NNS limitations)))) (VP (VBZ does) (RB not) (VP (VB take) (NP (NN effect)) (SBAR (IN until) (S (NP (DT the) (NN victim)) (ADVP (RB actually)) (VP (VBZ becomes) (ADJP (JJ aware) (PP (IN of) (NP (NN molestation)))))))))) (, ,) (CC and) (S (NP (DT some) (NNS victims)) (VP (MD might) (VP (VB suppress) (NP (NP (NNS memories)) (PP (IN of) (NP (JJ such) (NNS attacks)))) (PP (IN for) (NP (NNS years)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="molestation" type="NP">
          <tokens>
            <token id="22" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="2" string="becomes aware of molestation" type="VP">
          <tokens>
            <token id="19" string="becomes" />
            <token id="20" string="aware" />
            <token id="21" string="of" />
            <token id="22" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="3" string="the so-called delayed-discovery theory" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="so-called" />
            <token id="4" string="delayed-discovery" />
            <token id="5" string="theory" />
          </tokens>
        </chunking>
        <chunking id="4" string="some victims" type="NP">
          <tokens>
            <token id="25" string="some" />
            <token id="26" string="victims" />
          </tokens>
        </chunking>
        <chunking id="5" string="aware of molestation" type="ADJP">
          <tokens>
            <token id="20" string="aware" />
            <token id="21" string="of" />
            <token id="22" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="6" string="a statute" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="statute" />
          </tokens>
        </chunking>
        <chunking id="7" string="years" type="NP">
          <tokens>
            <token id="34" string="years" />
          </tokens>
        </chunking>
        <chunking id="8" string="memories of such attacks" type="NP">
          <tokens>
            <token id="29" string="memories" />
            <token id="30" string="of" />
            <token id="31" string="such" />
            <token id="32" string="attacks" />
          </tokens>
        </chunking>
        <chunking id="9" string="until the victim actually becomes aware of molestation" type="SBAR">
          <tokens>
            <token id="15" string="until" />
            <token id="16" string="the" />
            <token id="17" string="victim" />
            <token id="18" string="actually" />
            <token id="19" string="becomes" />
            <token id="20" string="aware" />
            <token id="21" string="of" />
            <token id="22" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="10" string="the victim" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="victim" />
          </tokens>
        </chunking>
        <chunking id="11" string="effect" type="NP">
          <tokens>
            <token id="14" string="effect" />
          </tokens>
        </chunking>
        <chunking id="12" string="a statute of limitations" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="statute" />
            <token id="9" string="of" />
            <token id="10" string="limitations" />
          </tokens>
        </chunking>
        <chunking id="13" string="take effect until the victim actually becomes aware of molestation" type="VP">
          <tokens>
            <token id="13" string="take" />
            <token id="14" string="effect" />
            <token id="15" string="until" />
            <token id="16" string="the" />
            <token id="17" string="victim" />
            <token id="18" string="actually" />
            <token id="19" string="becomes" />
            <token id="20" string="aware" />
            <token id="21" string="of" />
            <token id="22" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="14" string="memories" type="NP">
          <tokens>
            <token id="29" string="memories" />
          </tokens>
        </chunking>
        <chunking id="15" string="does not take effect until the victim actually becomes aware of molestation" type="VP">
          <tokens>
            <token id="11" string="does" />
            <token id="12" string="not" />
            <token id="13" string="take" />
            <token id="14" string="effect" />
            <token id="15" string="until" />
            <token id="16" string="the" />
            <token id="17" string="victim" />
            <token id="18" string="actually" />
            <token id="19" string="becomes" />
            <token id="20" string="aware" />
            <token id="21" string="of" />
            <token id="22" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="16" string="such attacks" type="NP">
          <tokens>
            <token id="31" string="such" />
            <token id="32" string="attacks" />
          </tokens>
        </chunking>
        <chunking id="17" string="suppress memories of such attacks for years" type="VP">
          <tokens>
            <token id="28" string="suppress" />
            <token id="29" string="memories" />
            <token id="30" string="of" />
            <token id="31" string="such" />
            <token id="32" string="attacks" />
            <token id="33" string="for" />
            <token id="34" string="years" />
          </tokens>
        </chunking>
        <chunking id="18" string="might suppress memories of such attacks for years" type="VP">
          <tokens>
            <token id="27" string="might" />
            <token id="28" string="suppress" />
            <token id="29" string="memories" />
            <token id="30" string="of" />
            <token id="31" string="such" />
            <token id="32" string="attacks" />
            <token id="33" string="for" />
            <token id="34" string="years" />
          </tokens>
        </chunking>
        <chunking id="19" string="limitations" type="NP">
          <tokens>
            <token id="10" string="limitations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">theory</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">theory</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">theory</governor>
          <dependent id="3">so-called</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">theory</governor>
          <dependent id="4">delayed-discovery</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">take</governor>
          <dependent id="5">theory</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">statute</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">take</governor>
          <dependent id="8">statute</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">limitations</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">statute</governor>
          <dependent id="10">limitations</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">take</governor>
          <dependent id="11">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">take</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">take</governor>
          <dependent id="14">effect</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">becomes</governor>
          <dependent id="15">until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">victim</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">becomes</governor>
          <dependent id="17">victim</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">becomes</governor>
          <dependent id="18">actually</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">take</governor>
          <dependent id="19">becomes</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">becomes</governor>
          <dependent id="20">aware</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">molestation</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">aware</governor>
          <dependent id="22">molestation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">take</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">victims</governor>
          <dependent id="25">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">suppress</governor>
          <dependent id="26">victims</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">suppress</governor>
          <dependent id="27">might</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">take</governor>
          <dependent id="28">suppress</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">suppress</governor>
          <dependent id="29">memories</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">attacks</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">attacks</governor>
          <dependent id="31">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">memories</governor>
          <dependent id="32">attacks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">years</governor>
          <dependent id="33">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">suppress</governor>
          <dependent id="34">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="attacks" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="32" string="attacks" />
          </tokens>
        </entity>
        <entity id="2" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="34" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s a possibility that hangs over the former defendants,&amp;quot; said attorney Gauna, noting a recent landmark California court decision that set aside the statute of limitations for certain victims.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="possibility" lemma="possibility" stem="possibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="hangs" lemma="hang" stem="hang" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Gauna" lemma="Gauna" stem="gauna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="noting" lemma="note" stem="note" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="landmark" lemma="landmark" stem="landmark" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="23" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="set" lemma="set" stem="set" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="aside" lemma="aside" stem="asid" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="statute" lemma="statute" stem="statut" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="limitations" lemma="limitation" stem="limit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (NP (NP (DT a) (NN possibility)) (SBAR (WHNP (IN that)) (S (VP (VBZ hangs) (PP (IN over) (NP (DT the) (JJ former) (NNS defendants))))))))) (, ,) ('' '') (VP (VBD said) (NP (NN attorney))) (NP (NNP Gauna)) (, ,) (S (VP (VBG noting) (NP (DT a) (JJ recent) (NN landmark)) (NP-TMP (NP (NNP California) (NN court) (NN decision)) (SBAR (WHNP (WDT that)) (S (VP (VBD set) (ADVP (RB aside)) (NP (NP (DT the) (NN statute)) (PP (IN of) (NP (NP (NNS limitations)) (PP (IN for) (NP (JJ certain) (NNS victims)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="hangs over the former defendants" type="VP">
          <tokens>
            <token id="7" string="hangs" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="former" />
            <token id="11" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="2" string="that set aside the statute of limitations for certain victims" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="set" />
            <token id="27" string="aside" />
            <token id="28" string="the" />
            <token id="29" string="statute" />
            <token id="30" string="of" />
            <token id="31" string="limitations" />
            <token id="32" string="for" />
            <token id="33" string="certain" />
            <token id="34" string="victims" />
          </tokens>
        </chunking>
        <chunking id="3" string="the statute of limitations for certain victims" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="statute" />
            <token id="30" string="of" />
            <token id="31" string="limitations" />
            <token id="32" string="for" />
            <token id="33" string="certain" />
            <token id="34" string="victims" />
          </tokens>
        </chunking>
        <chunking id="4" string="limitations for certain victims" type="NP">
          <tokens>
            <token id="31" string="limitations" />
            <token id="32" string="for" />
            <token id="33" string="certain" />
            <token id="34" string="victims" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="that hangs over the former defendants" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="hangs" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="former" />
            <token id="11" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="7" string="the statute" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="statute" />
          </tokens>
        </chunking>
        <chunking id="8" string="said attorney" type="VP">
          <tokens>
            <token id="14" string="said" />
            <token id="15" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="9" string="California court decision" type="NP">
          <tokens>
            <token id="22" string="California" />
            <token id="23" string="court" />
            <token id="24" string="decision" />
          </tokens>
        </chunking>
        <chunking id="10" string="certain victims" type="NP">
          <tokens>
            <token id="33" string="certain" />
            <token id="34" string="victims" />
          </tokens>
        </chunking>
        <chunking id="11" string="a recent landmark" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="recent" />
            <token id="21" string="landmark" />
          </tokens>
        </chunking>
        <chunking id="12" string="set aside the statute of limitations for certain victims" type="VP">
          <tokens>
            <token id="26" string="set" />
            <token id="27" string="aside" />
            <token id="28" string="the" />
            <token id="29" string="statute" />
            <token id="30" string="of" />
            <token id="31" string="limitations" />
            <token id="32" string="for" />
            <token id="33" string="certain" />
            <token id="34" string="victims" />
          </tokens>
        </chunking>
        <chunking id="13" string="noting a recent landmark California court decision that set aside the statute of limitations for certain victims" type="VP">
          <tokens>
            <token id="18" string="noting" />
            <token id="19" string="a" />
            <token id="20" string="recent" />
            <token id="21" string="landmark" />
            <token id="22" string="California" />
            <token id="23" string="court" />
            <token id="24" string="decision" />
            <token id="25" string="that" />
            <token id="26" string="set" />
            <token id="27" string="aside" />
            <token id="28" string="the" />
            <token id="29" string="statute" />
            <token id="30" string="of" />
            <token id="31" string="limitations" />
            <token id="32" string="for" />
            <token id="33" string="certain" />
            <token id="34" string="victims" />
          </tokens>
        </chunking>
        <chunking id="14" string="attorney" type="NP">
          <tokens>
            <token id="15" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="15" string="'s a possibility that hangs over the former defendants" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="a" />
            <token id="5" string="possibility" />
            <token id="6" string="that" />
            <token id="7" string="hangs" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="former" />
            <token id="11" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="16" string="the former defendants" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="former" />
            <token id="11" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="17" string="a possibility that hangs over the former defendants" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="possibility" />
            <token id="6" string="that" />
            <token id="7" string="hangs" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="former" />
            <token id="11" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="18" string="a possibility" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="possibility" />
          </tokens>
        </chunking>
        <chunking id="19" string="Gauna" type="NP">
          <tokens>
            <token id="16" string="Gauna" />
          </tokens>
        </chunking>
        <chunking id="20" string="limitations" type="NP">
          <tokens>
            <token id="31" string="limitations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">possibility</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">possibility</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">possibility</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="5">possibility</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">hangs</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">possibility</governor>
          <dependent id="7">hangs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">defendants</governor>
          <dependent id="8">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">defendants</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">defendants</governor>
          <dependent id="10">former</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">hangs</governor>
          <dependent id="11">defendants</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">said</governor>
          <dependent id="15">attorney</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="16">Gauna</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">said</governor>
          <dependent id="18">noting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">landmark</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">landmark</governor>
          <dependent id="20">recent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">noting</governor>
          <dependent id="21">landmark</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">decision</governor>
          <dependent id="22">California</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">decision</governor>
          <dependent id="23">court</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="18">noting</governor>
          <dependent id="24">decision</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">set</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">decision</governor>
          <dependent id="26">set</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">set</governor>
          <dependent id="27">aside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">statute</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">set</governor>
          <dependent id="29">statute</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">limitations</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">statute</governor>
          <dependent id="31">limitations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">victims</governor>
          <dependent id="32">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">victims</governor>
          <dependent id="33">certain</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">limitations</governor>
          <dependent id="34">victims</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="California" />
          </tokens>
        </entity>
        <entity id="2" string="Gauna" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Gauna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Mooney said he knows of families that, seeking legal advantage, waited for the criminal trial to end before contemplating civil action.</content>
      <tokens>
        <token id="1" string="Mooney" lemma="Mooney" stem="moonei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="knows" lemma="know" stem="know" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="families" lemma="family" stem="famili" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="seeking" lemma="seek" stem="seek" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="advantage" lemma="advantage" stem="advantag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="waited" lemma="wait" stem="wait" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="end" lemma="end" stem="end" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="contemplating" lemma="contemplate" stem="contempl" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mooney)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBZ knows) (PP (IN of) (NP (NNS families))) (SBAR (IN that) (, ,) (S (S (VP (VBG seeking) (NP (JJ legal) (NN advantage)))) (, ,) (VP (VBD waited) (PP (IN for) (NP (DT the) (JJ criminal) (NN trial))) (S (VP (TO to) (VP (VB end) (PP (IN before) (S (VP (VBG contemplating) (NP (JJ civil) (NN action))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mooney" type="NP">
          <tokens>
            <token id="1" string="Mooney" />
          </tokens>
        </chunking>
        <chunking id="2" string="civil action" type="NP">
          <tokens>
            <token id="22" string="civil" />
            <token id="23" string="action" />
          </tokens>
        </chunking>
        <chunking id="3" string="contemplating civil action" type="VP">
          <tokens>
            <token id="21" string="contemplating" />
            <token id="22" string="civil" />
            <token id="23" string="action" />
          </tokens>
        </chunking>
        <chunking id="4" string="waited for the criminal trial to end before contemplating civil action" type="VP">
          <tokens>
            <token id="13" string="waited" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="trial" />
            <token id="18" string="to" />
            <token id="19" string="end" />
            <token id="20" string="before" />
            <token id="21" string="contemplating" />
            <token id="22" string="civil" />
            <token id="23" string="action" />
          </tokens>
        </chunking>
        <chunking id="5" string="knows of families that , seeking legal advantage , waited for the criminal trial to end before contemplating civil action" type="VP">
          <tokens>
            <token id="4" string="knows" />
            <token id="5" string="of" />
            <token id="6" string="families" />
            <token id="7" string="that" />
            <token id="8" string="," />
            <token id="9" string="seeking" />
            <token id="10" string="legal" />
            <token id="11" string="advantage" />
            <token id="12" string="," />
            <token id="13" string="waited" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="trial" />
            <token id="18" string="to" />
            <token id="19" string="end" />
            <token id="20" string="before" />
            <token id="21" string="contemplating" />
            <token id="22" string="civil" />
            <token id="23" string="action" />
          </tokens>
        </chunking>
        <chunking id="6" string="legal advantage" type="NP">
          <tokens>
            <token id="10" string="legal" />
            <token id="11" string="advantage" />
          </tokens>
        </chunking>
        <chunking id="7" string="to end before contemplating civil action" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="end" />
            <token id="20" string="before" />
            <token id="21" string="contemplating" />
            <token id="22" string="civil" />
            <token id="23" string="action" />
          </tokens>
        </chunking>
        <chunking id="8" string="he knows of families that , seeking legal advantage , waited for the criminal trial to end before contemplating civil action" type="SBAR">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="knows" />
            <token id="5" string="of" />
            <token id="6" string="families" />
            <token id="7" string="that" />
            <token id="8" string="," />
            <token id="9" string="seeking" />
            <token id="10" string="legal" />
            <token id="11" string="advantage" />
            <token id="12" string="," />
            <token id="13" string="waited" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="trial" />
            <token id="18" string="to" />
            <token id="19" string="end" />
            <token id="20" string="before" />
            <token id="21" string="contemplating" />
            <token id="22" string="civil" />
            <token id="23" string="action" />
          </tokens>
        </chunking>
        <chunking id="9" string="families" type="NP">
          <tokens>
            <token id="6" string="families" />
          </tokens>
        </chunking>
        <chunking id="10" string="seeking legal advantage" type="VP">
          <tokens>
            <token id="9" string="seeking" />
            <token id="10" string="legal" />
            <token id="11" string="advantage" />
          </tokens>
        </chunking>
        <chunking id="11" string="said he knows of families that , seeking legal advantage , waited for the criminal trial to end before contemplating civil action" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="he" />
            <token id="4" string="knows" />
            <token id="5" string="of" />
            <token id="6" string="families" />
            <token id="7" string="that" />
            <token id="8" string="," />
            <token id="9" string="seeking" />
            <token id="10" string="legal" />
            <token id="11" string="advantage" />
            <token id="12" string="," />
            <token id="13" string="waited" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="trial" />
            <token id="18" string="to" />
            <token id="19" string="end" />
            <token id="20" string="before" />
            <token id="21" string="contemplating" />
            <token id="22" string="civil" />
            <token id="23" string="action" />
          </tokens>
        </chunking>
        <chunking id="12" string="the criminal trial" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="trial" />
          </tokens>
        </chunking>
        <chunking id="13" string="end before contemplating civil action" type="VP">
          <tokens>
            <token id="19" string="end" />
            <token id="20" string="before" />
            <token id="21" string="contemplating" />
            <token id="22" string="civil" />
            <token id="23" string="action" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="that , seeking legal advantage , waited for the criminal trial to end before contemplating civil action" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="," />
            <token id="9" string="seeking" />
            <token id="10" string="legal" />
            <token id="11" string="advantage" />
            <token id="12" string="," />
            <token id="13" string="waited" />
            <token id="14" string="for" />
            <token id="15" string="the" />
            <token id="16" string="criminal" />
            <token id="17" string="trial" />
            <token id="18" string="to" />
            <token id="19" string="end" />
            <token id="20" string="before" />
            <token id="21" string="contemplating" />
            <token id="22" string="civil" />
            <token id="23" string="action" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Mooney</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">knows</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="4">knows</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">families</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">knows</governor>
          <dependent id="6">families</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">waited</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">waited</governor>
          <dependent id="9">seeking</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">advantage</governor>
          <dependent id="10">legal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">seeking</governor>
          <dependent id="11">advantage</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">knows</governor>
          <dependent id="13">waited</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">trial</governor>
          <dependent id="14">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">trial</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">trial</governor>
          <dependent id="16">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">waited</governor>
          <dependent id="17">trial</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">end</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">waited</governor>
          <dependent id="19">end</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">contemplating</governor>
          <dependent id="20">before</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">end</governor>
          <dependent id="21">contemplating</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">action</governor>
          <dependent id="22">civil</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">contemplating</governor>
          <dependent id="23">action</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mooney" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Mooney" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>He explained that some families believed they might have a better advantage in civil court rather than in a criminal case: the burden of proof in civil litigation is the preponderance of the evidence, not reasonable doubt, as in a criminal trial.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="explained" lemma="explain" stem="explain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="families" lemma="family" stem="famili" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="believed" lemma="believe" stem="believ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="better" lemma="better" stem="better" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="advantage" lemma="advantage" stem="advantag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="burden" lemma="burden" stem="burden" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="proof" lemma="proof" stem="proof" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="litigation" lemma="litigation" stem="litig" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="preponderance" lemma="preponderance" stem="preponder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="reasonable" lemma="reasonable" stem="reason" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="doubt" lemma="doubt" stem="doubt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP He)) (VP (VBD explained) (SBAR (IN that) (S (NP (DT some) (NNS families)) (VP (VBD believed) (SBAR (S (NP (PRP they)) (VP (MD might) (VP (VB have) (NP (DT a) (JJR better) (NN advantage)) (PP (PP (IN in) (NP (JJ civil) (NN court))) (CONJP (RB rather) (IN than)) (PP (IN in) (NP (DT a) (JJ criminal) (NN case))))))))))))) (: :) (S (NP (NP (DT the) (NN burden)) (PP (IN of) (NP (NP (NN proof)) (PP (IN in) (NP (JJ civil) (NN litigation)))))) (VP (VBZ is) (NP (NP (DT the) (NN preponderance)) (PP (IN of) (NP (NP (DT the) (NN evidence)) (, ,) (NP (RB not) (JJ reasonable) (NN doubt)) (, ,)))) (PP (IN as) (PP (IN in) (NP (DT a) (JJ criminal) (NN trial)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the preponderance of the evidence , not reasonable doubt ," type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="preponderance" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="evidence" />
            <token id="36" string="," />
            <token id="37" string="not" />
            <token id="38" string="reasonable" />
            <token id="39" string="doubt" />
            <token id="40" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="not reasonable doubt" type="NP">
          <tokens>
            <token id="37" string="not" />
            <token id="38" string="reasonable" />
            <token id="39" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="3" string="they might have a better advantage in civil court rather than in a criminal case" type="SBAR">
          <tokens>
            <token id="7" string="they" />
            <token id="8" string="might" />
            <token id="9" string="have" />
            <token id="10" string="a" />
            <token id="11" string="better" />
            <token id="12" string="advantage" />
            <token id="13" string="in" />
            <token id="14" string="civil" />
            <token id="15" string="court" />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="criminal" />
            <token id="21" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="civil court" type="NP">
          <tokens>
            <token id="14" string="civil" />
            <token id="15" string="court" />
          </tokens>
        </chunking>
        <chunking id="5" string="the evidence" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="6" string="a better advantage" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="better" />
            <token id="12" string="advantage" />
          </tokens>
        </chunking>
        <chunking id="7" string="explained that some families believed they might have a better advantage in civil court rather than in a criminal case" type="VP">
          <tokens>
            <token id="2" string="explained" />
            <token id="3" string="that" />
            <token id="4" string="some" />
            <token id="5" string="families" />
            <token id="6" string="believed" />
            <token id="7" string="they" />
            <token id="8" string="might" />
            <token id="9" string="have" />
            <token id="10" string="a" />
            <token id="11" string="better" />
            <token id="12" string="advantage" />
            <token id="13" string="in" />
            <token id="14" string="civil" />
            <token id="15" string="court" />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="criminal" />
            <token id="21" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="proof in civil litigation" type="NP">
          <tokens>
            <token id="26" string="proof" />
            <token id="27" string="in" />
            <token id="28" string="civil" />
            <token id="29" string="litigation" />
          </tokens>
        </chunking>
        <chunking id="9" string="a criminal trial" type="NP">
          <tokens>
            <token id="43" string="a" />
            <token id="44" string="criminal" />
            <token id="45" string="trial" />
          </tokens>
        </chunking>
        <chunking id="10" string="the burden of proof in civil litigation" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="burden" />
            <token id="25" string="of" />
            <token id="26" string="proof" />
            <token id="27" string="in" />
            <token id="28" string="civil" />
            <token id="29" string="litigation" />
          </tokens>
        </chunking>
        <chunking id="11" string="a criminal case" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="criminal" />
            <token id="21" string="case" />
          </tokens>
        </chunking>
        <chunking id="12" string="the burden" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="burden" />
          </tokens>
        </chunking>
        <chunking id="13" string="civil litigation" type="NP">
          <tokens>
            <token id="28" string="civil" />
            <token id="29" string="litigation" />
          </tokens>
        </chunking>
        <chunking id="14" string="they" type="NP">
          <tokens>
            <token id="7" string="they" />
          </tokens>
        </chunking>
        <chunking id="15" string="have a better advantage in civil court rather than in a criminal case" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="a" />
            <token id="11" string="better" />
            <token id="12" string="advantage" />
            <token id="13" string="in" />
            <token id="14" string="civil" />
            <token id="15" string="court" />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="criminal" />
            <token id="21" string="case" />
          </tokens>
        </chunking>
        <chunking id="16" string="some families" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="families" />
          </tokens>
        </chunking>
        <chunking id="17" string="that some families believed they might have a better advantage in civil court rather than in a criminal case" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="some" />
            <token id="5" string="families" />
            <token id="6" string="believed" />
            <token id="7" string="they" />
            <token id="8" string="might" />
            <token id="9" string="have" />
            <token id="10" string="a" />
            <token id="11" string="better" />
            <token id="12" string="advantage" />
            <token id="13" string="in" />
            <token id="14" string="civil" />
            <token id="15" string="court" />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="criminal" />
            <token id="21" string="case" />
          </tokens>
        </chunking>
        <chunking id="18" string="the evidence , not reasonable doubt ," type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="evidence" />
            <token id="36" string="," />
            <token id="37" string="not" />
            <token id="38" string="reasonable" />
            <token id="39" string="doubt" />
            <token id="40" string="," />
          </tokens>
        </chunking>
        <chunking id="19" string="might have a better advantage in civil court rather than in a criminal case" type="VP">
          <tokens>
            <token id="8" string="might" />
            <token id="9" string="have" />
            <token id="10" string="a" />
            <token id="11" string="better" />
            <token id="12" string="advantage" />
            <token id="13" string="in" />
            <token id="14" string="civil" />
            <token id="15" string="court" />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="criminal" />
            <token id="21" string="case" />
          </tokens>
        </chunking>
        <chunking id="20" string="believed they might have a better advantage in civil court rather than in a criminal case" type="VP">
          <tokens>
            <token id="6" string="believed" />
            <token id="7" string="they" />
            <token id="8" string="might" />
            <token id="9" string="have" />
            <token id="10" string="a" />
            <token id="11" string="better" />
            <token id="12" string="advantage" />
            <token id="13" string="in" />
            <token id="14" string="civil" />
            <token id="15" string="court" />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="criminal" />
            <token id="21" string="case" />
          </tokens>
        </chunking>
        <chunking id="21" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="22" string="proof" type="NP">
          <tokens>
            <token id="26" string="proof" />
          </tokens>
        </chunking>
        <chunking id="23" string="the preponderance" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="preponderance" />
          </tokens>
        </chunking>
        <chunking id="24" string="is the preponderance of the evidence , not reasonable doubt , as in a criminal trial" type="VP">
          <tokens>
            <token id="30" string="is" />
            <token id="31" string="the" />
            <token id="32" string="preponderance" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="evidence" />
            <token id="36" string="," />
            <token id="37" string="not" />
            <token id="38" string="reasonable" />
            <token id="39" string="doubt" />
            <token id="40" string="," />
            <token id="41" string="as" />
            <token id="42" string="in" />
            <token id="43" string="a" />
            <token id="44" string="criminal" />
            <token id="45" string="trial" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">explained</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">explained</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">believed</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">families</governor>
          <dependent id="4">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">believed</governor>
          <dependent id="5">families</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">explained</governor>
          <dependent id="6">believed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">have</governor>
          <dependent id="7">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">have</governor>
          <dependent id="8">might</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">believed</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">have</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">advantage</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">advantage</governor>
          <dependent id="11">better</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">have</governor>
          <dependent id="12">advantage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">court</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">court</governor>
          <dependent id="14">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">have</governor>
          <dependent id="15">court</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">have</governor>
          <dependent id="16">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="16">rather</governor>
          <dependent id="17">than</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">case</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">case</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">case</governor>
          <dependent id="20">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">have</governor>
          <dependent id="21">case</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">burden</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">preponderance</governor>
          <dependent id="24">burden</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">proof</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">burden</governor>
          <dependent id="26">proof</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">litigation</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">litigation</governor>
          <dependent id="28">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">proof</governor>
          <dependent id="29">litigation</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="32">preponderance</governor>
          <dependent id="30">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">preponderance</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">explained</governor>
          <dependent id="32">preponderance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">evidence</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">evidence</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">preponderance</governor>
          <dependent id="35">evidence</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="39">doubt</governor>
          <dependent id="37">not</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">doubt</governor>
          <dependent id="38">reasonable</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="35">evidence</governor>
          <dependent id="39">doubt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">trial</governor>
          <dependent id="41">as</dependent>
        </dependency>
        <dependency type="case">
          <governor id="45">trial</governor>
          <dependent id="42">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">trial</governor>
          <dependent id="43">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="45">trial</governor>
          <dependent id="44">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">preponderance</governor>
          <dependent id="45">trial</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="false">
      <content>Also, in a civil case, only nine of the 12 jurors must agree on a verdict.</content>
      <tokens>
        <token id="1" string="Also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="nine" lemma="nine" stem="nine" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="agree" lemma="agree" stem="agre" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="verdict" lemma="verdict" stem="verdict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Also)) (, ,) (PP (IN in) (NP (DT a) (JJ civil) (NN case))) (, ,) (NP (NP (RB only) (CD nine)) (PP (IN of) (NP (DT the) (CD 12) (NNS jurors)))) (VP (MD must) (VP (VB agree) (PP (IN on) (NP (DT a) (NN verdict))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="must agree on a verdict" type="VP">
          <tokens>
            <token id="14" string="must" />
            <token id="15" string="agree" />
            <token id="16" string="on" />
            <token id="17" string="a" />
            <token id="18" string="verdict" />
          </tokens>
        </chunking>
        <chunking id="2" string="a verdict" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="verdict" />
          </tokens>
        </chunking>
        <chunking id="3" string="only nine" type="NP">
          <tokens>
            <token id="8" string="only" />
            <token id="9" string="nine" />
          </tokens>
        </chunking>
        <chunking id="4" string="only nine of the 12 jurors" type="NP">
          <tokens>
            <token id="8" string="only" />
            <token id="9" string="nine" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="12" />
            <token id="13" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="5" string="agree on a verdict" type="VP">
          <tokens>
            <token id="15" string="agree" />
            <token id="16" string="on" />
            <token id="17" string="a" />
            <token id="18" string="verdict" />
          </tokens>
        </chunking>
        <chunking id="6" string="the 12 jurors" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="12" />
            <token id="13" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="7" string="a civil case" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="civil" />
            <token id="6" string="case" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="15">agree</governor>
          <dependent id="1">Also</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">case</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">case</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">case</governor>
          <dependent id="5">civil</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">agree</governor>
          <dependent id="6">case</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">nine</governor>
          <dependent id="8">only</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">agree</governor>
          <dependent id="9">nine</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">jurors</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">jurors</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">jurors</governor>
          <dependent id="12">12</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">nine</governor>
          <dependent id="13">jurors</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">agree</governor>
          <dependent id="14">must</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">agree</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">verdict</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">verdict</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">agree</governor>
          <dependent id="18">verdict</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="12" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="12" />
          </tokens>
        </entity>
        <entity id="2" string="nine" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="nine" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="false">
      <content>Criminal convictions require unanimous juries.</content>
      <tokens>
        <token id="1" string="Criminal" lemma="Criminal" stem="crimin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="convictions" lemma="conviction" stem="convict" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="require" lemma="require" stem="requir" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="unanimous" lemma="unanimous" stem="unanim" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="juries" lemma="jury" stem="juri" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Criminal) (NNS convictions)) (VP (VBP require) (NP (JJ unanimous) (NNS juries))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="require unanimous juries" type="VP">
          <tokens>
            <token id="3" string="require" />
            <token id="4" string="unanimous" />
            <token id="5" string="juries" />
          </tokens>
        </chunking>
        <chunking id="2" string="Criminal convictions" type="NP">
          <tokens>
            <token id="1" string="Criminal" />
            <token id="2" string="convictions" />
          </tokens>
        </chunking>
        <chunking id="3" string="unanimous juries" type="NP">
          <tokens>
            <token id="4" string="unanimous" />
            <token id="5" string="juries" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">convictions</governor>
          <dependent id="1">Criminal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">require</governor>
          <dependent id="2">convictions</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">require</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">juries</governor>
          <dependent id="4">unanimous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">require</governor>
          <dependent id="5">juries</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Whether the families would be willing to tackle more years of legal proceedings is yet to be seen.</content>
      <tokens>
        <token id="1" string="Whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="families" lemma="family" stem="famili" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="willing" lemma="willing" stem="will" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="tackle" lemma="tackle" stem="tackl" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="proceedings" lemma="proceedings" stem="proceed" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Whether) (S (NP (DT the) (NNS families)) (VP (MD would) (VP (VB be) (ADJP (JJ willing) (S (VP (TO to) (VP (VB tackle) (NP (NP (JJR more) (NNS years)) (PP (IN of) (NP (JJ legal) (NNS proceedings)))))))))))) (VP (VBZ is) (ADVP (RB yet)) (S (VP (TO to) (VP (VB be) (VP (VBN seen)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="more years of legal proceedings" type="NP">
          <tokens>
            <token id="9" string="more" />
            <token id="10" string="years" />
            <token id="11" string="of" />
            <token id="12" string="legal" />
            <token id="13" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="2" string="be seen" type="VP">
          <tokens>
            <token id="17" string="be" />
            <token id="18" string="seen" />
          </tokens>
        </chunking>
        <chunking id="3" string="is yet to be seen" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="yet" />
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="seen" />
          </tokens>
        </chunking>
        <chunking id="4" string="more years" type="NP">
          <tokens>
            <token id="9" string="more" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="the families" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="families" />
          </tokens>
        </chunking>
        <chunking id="6" string="would be willing to tackle more years of legal proceedings" type="VP">
          <tokens>
            <token id="4" string="would" />
            <token id="5" string="be" />
            <token id="6" string="willing" />
            <token id="7" string="to" />
            <token id="8" string="tackle" />
            <token id="9" string="more" />
            <token id="10" string="years" />
            <token id="11" string="of" />
            <token id="12" string="legal" />
            <token id="13" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="7" string="tackle more years of legal proceedings" type="VP">
          <tokens>
            <token id="8" string="tackle" />
            <token id="9" string="more" />
            <token id="10" string="years" />
            <token id="11" string="of" />
            <token id="12" string="legal" />
            <token id="13" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="8" string="seen" type="VP">
          <tokens>
            <token id="18" string="seen" />
          </tokens>
        </chunking>
        <chunking id="9" string="willing to tackle more years of legal proceedings" type="ADJP">
          <tokens>
            <token id="6" string="willing" />
            <token id="7" string="to" />
            <token id="8" string="tackle" />
            <token id="9" string="more" />
            <token id="10" string="years" />
            <token id="11" string="of" />
            <token id="12" string="legal" />
            <token id="13" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="10" string="legal proceedings" type="NP">
          <tokens>
            <token id="12" string="legal" />
            <token id="13" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="11" string="be willing to tackle more years of legal proceedings" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="willing" />
            <token id="7" string="to" />
            <token id="8" string="tackle" />
            <token id="9" string="more" />
            <token id="10" string="years" />
            <token id="11" string="of" />
            <token id="12" string="legal" />
            <token id="13" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="12" string="Whether the families would be willing to tackle more years of legal proceedings" type="SBAR">
          <tokens>
            <token id="1" string="Whether" />
            <token id="2" string="the" />
            <token id="3" string="families" />
            <token id="4" string="would" />
            <token id="5" string="be" />
            <token id="6" string="willing" />
            <token id="7" string="to" />
            <token id="8" string="tackle" />
            <token id="9" string="more" />
            <token id="10" string="years" />
            <token id="11" string="of" />
            <token id="12" string="legal" />
            <token id="13" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="13" string="to tackle more years of legal proceedings" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="tackle" />
            <token id="9" string="more" />
            <token id="10" string="years" />
            <token id="11" string="of" />
            <token id="12" string="legal" />
            <token id="13" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="14" string="to be seen" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="be" />
            <token id="18" string="seen" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">willing</governor>
          <dependent id="1">Whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">families</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">willing</governor>
          <dependent id="3">families</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">willing</governor>
          <dependent id="4">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">willing</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="14">is</governor>
          <dependent id="6">willing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">tackle</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">willing</governor>
          <dependent id="8">tackle</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">years</governor>
          <dependent id="9">more</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">tackle</governor>
          <dependent id="10">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">proceedings</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">proceedings</governor>
          <dependent id="12">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">years</governor>
          <dependent id="13">proceedings</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">is</governor>
          <dependent id="15">yet</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">seen</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">seen</governor>
          <dependent id="17">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">is</governor>
          <dependent id="18">seen</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>And some families question whether the McMartin defendants&amp;apost; insurance carriers would pay out to plaintiffs who successfully sued the school.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="families" lemma="family" stem="famili" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="question" lemma="question" stem="question" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="insurance" lemma="insurance" stem="insur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="carriers" lemma="carrier" stem="carrier" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="pay" lemma="pay" stem="pai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="plaintiffs" lemma="plaintiff" stem="plaintiff" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="successfully" lemma="successfully" stem="successfulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="sued" lemma="sue" stem="su" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (DT some) (NNS families)) (VP (VBP question) (SBAR (IN whether) (S (NP (NP (DT the) (NNP McMartin) (NNS defendants) (POS ')) (NN insurance) (NNS carriers)) (VP (MD would) (VP (VB pay) (PRT (RP out)) (PP (TO to) (NP (NP (NNS plaintiffs)) (SBAR (WHNP (WP who)) (S (ADVP (RB successfully)) (VP (VBD sued) (NP (DT the) (NN school)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="pay out to plaintiffs who successfully sued the school" type="VP">
          <tokens>
            <token id="13" string="pay" />
            <token id="14" string="out" />
            <token id="15" string="to" />
            <token id="16" string="plaintiffs" />
            <token id="17" string="who" />
            <token id="18" string="successfully" />
            <token id="19" string="sued" />
            <token id="20" string="the" />
            <token id="21" string="school" />
          </tokens>
        </chunking>
        <chunking id="2" string="the school" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="school" />
          </tokens>
        </chunking>
        <chunking id="3" string="some families" type="NP">
          <tokens>
            <token id="2" string="some" />
            <token id="3" string="families" />
          </tokens>
        </chunking>
        <chunking id="4" string="would pay out to plaintiffs who successfully sued the school" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="pay" />
            <token id="14" string="out" />
            <token id="15" string="to" />
            <token id="16" string="plaintiffs" />
            <token id="17" string="who" />
            <token id="18" string="successfully" />
            <token id="19" string="sued" />
            <token id="20" string="the" />
            <token id="21" string="school" />
          </tokens>
        </chunking>
        <chunking id="5" string="whether the McMartin defendants ' insurance carriers would pay out to plaintiffs who successfully sued the school" type="SBAR">
          <tokens>
            <token id="5" string="whether" />
            <token id="6" string="the" />
            <token id="7" string="McMartin" />
            <token id="8" string="defendants" />
            <token id="9" string="'" />
            <token id="10" string="insurance" />
            <token id="11" string="carriers" />
            <token id="12" string="would" />
            <token id="13" string="pay" />
            <token id="14" string="out" />
            <token id="15" string="to" />
            <token id="16" string="plaintiffs" />
            <token id="17" string="who" />
            <token id="18" string="successfully" />
            <token id="19" string="sued" />
            <token id="20" string="the" />
            <token id="21" string="school" />
          </tokens>
        </chunking>
        <chunking id="6" string="the McMartin defendants ' insurance carriers" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="McMartin" />
            <token id="8" string="defendants" />
            <token id="9" string="'" />
            <token id="10" string="insurance" />
            <token id="11" string="carriers" />
          </tokens>
        </chunking>
        <chunking id="7" string="the McMartin defendants '" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="McMartin" />
            <token id="8" string="defendants" />
            <token id="9" string="'" />
          </tokens>
        </chunking>
        <chunking id="8" string="plaintiffs" type="NP">
          <tokens>
            <token id="16" string="plaintiffs" />
          </tokens>
        </chunking>
        <chunking id="9" string="plaintiffs who successfully sued the school" type="NP">
          <tokens>
            <token id="16" string="plaintiffs" />
            <token id="17" string="who" />
            <token id="18" string="successfully" />
            <token id="19" string="sued" />
            <token id="20" string="the" />
            <token id="21" string="school" />
          </tokens>
        </chunking>
        <chunking id="10" string="question whether the McMartin defendants ' insurance carriers would pay out to plaintiffs who successfully sued the school" type="VP">
          <tokens>
            <token id="4" string="question" />
            <token id="5" string="whether" />
            <token id="6" string="the" />
            <token id="7" string="McMartin" />
            <token id="8" string="defendants" />
            <token id="9" string="'" />
            <token id="10" string="insurance" />
            <token id="11" string="carriers" />
            <token id="12" string="would" />
            <token id="13" string="pay" />
            <token id="14" string="out" />
            <token id="15" string="to" />
            <token id="16" string="plaintiffs" />
            <token id="17" string="who" />
            <token id="18" string="successfully" />
            <token id="19" string="sued" />
            <token id="20" string="the" />
            <token id="21" string="school" />
          </tokens>
        </chunking>
        <chunking id="11" string="who successfully sued the school" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="successfully" />
            <token id="19" string="sued" />
            <token id="20" string="the" />
            <token id="21" string="school" />
          </tokens>
        </chunking>
        <chunking id="12" string="sued the school" type="VP">
          <tokens>
            <token id="19" string="sued" />
            <token id="20" string="the" />
            <token id="21" string="school" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">question</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">families</governor>
          <dependent id="2">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">question</governor>
          <dependent id="3">families</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">question</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">pay</governor>
          <dependent id="5">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">defendants</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">defendants</governor>
          <dependent id="7">McMartin</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">carriers</governor>
          <dependent id="8">defendants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">defendants</governor>
          <dependent id="9">'</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">carriers</governor>
          <dependent id="10">insurance</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">pay</governor>
          <dependent id="11">carriers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">pay</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">question</governor>
          <dependent id="13">pay</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="13">pay</governor>
          <dependent id="14">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">plaintiffs</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">pay</governor>
          <dependent id="16">plaintiffs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">sued</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">sued</governor>
          <dependent id="18">successfully</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">plaintiffs</governor>
          <dependent id="19">sued</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">school</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">sued</governor>
          <dependent id="21">school</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="false">
      <content>&amp;quot;There hasn&amp;apost;t been any decisions yet.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="decisions" lemma="decision" stem="decis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (EX There)) (VP (VBZ has) (RB n't) (VP (VBN been) (NP (DT any) (NNS decisions)) (ADVP (RB yet)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="has n't been any decisions yet" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="n't" />
            <token id="5" string="been" />
            <token id="6" string="any" />
            <token id="7" string="decisions" />
            <token id="8" string="yet" />
          </tokens>
        </chunking>
        <chunking id="3" string="any decisions" type="NP">
          <tokens>
            <token id="6" string="any" />
            <token id="7" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="4" string="been any decisions yet" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="any" />
            <token id="7" string="decisions" />
            <token id="8" string="yet" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="7">decisions</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">decisions</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">decisions</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">decisions</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">decisions</governor>
          <dependent id="6">any</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">decisions</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">decisions</governor>
          <dependent id="8">yet</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>The parents need a little space between the events of this week and deciding what they will do,&amp;quot; Mooney said.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="space" lemma="space" stem="space" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="events" lemma="event" stem="event" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="deciding" lemma="decide" stem="decid" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Mooney" lemma="Mooney" stem="moonei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNS parents)) (VP (VBP need) (NP (NP (DT a) (JJ little) (NN space)) (PP (IN between) (NP (NP (DT the) (NNS events)) (PP (IN of) (NP (NP (DT this) (NN week) (CC and) (VBG deciding)) (SBAR (WHNP (WP what)) (S (NP (PRP they)) (VP (MD will) (VP (VB do)))))))))))) (, ,) ('' '') (NP (NNP Mooney)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mooney" type="NP">
          <tokens>
            <token id="21" string="Mooney" />
          </tokens>
        </chunking>
        <chunking id="2" string="The parents" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="parents" />
          </tokens>
        </chunking>
        <chunking id="3" string="do" type="VP">
          <tokens>
            <token id="18" string="do" />
          </tokens>
        </chunking>
        <chunking id="4" string="what they will do" type="SBAR">
          <tokens>
            <token id="15" string="what" />
            <token id="16" string="they" />
            <token id="17" string="will" />
            <token id="18" string="do" />
          </tokens>
        </chunking>
        <chunking id="5" string="will do" type="VP">
          <tokens>
            <token id="17" string="will" />
            <token id="18" string="do" />
          </tokens>
        </chunking>
        <chunking id="6" string="this week and deciding what they will do" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="week" />
            <token id="13" string="and" />
            <token id="14" string="deciding" />
            <token id="15" string="what" />
            <token id="16" string="they" />
            <token id="17" string="will" />
            <token id="18" string="do" />
          </tokens>
        </chunking>
        <chunking id="7" string="a little space" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="little" />
            <token id="6" string="space" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="16" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="the events of this week and deciding what they will do" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="events" />
            <token id="10" string="of" />
            <token id="11" string="this" />
            <token id="12" string="week" />
            <token id="13" string="and" />
            <token id="14" string="deciding" />
            <token id="15" string="what" />
            <token id="16" string="they" />
            <token id="17" string="will" />
            <token id="18" string="do" />
          </tokens>
        </chunking>
        <chunking id="10" string="this week and deciding" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="week" />
            <token id="13" string="and" />
            <token id="14" string="deciding" />
          </tokens>
        </chunking>
        <chunking id="11" string="need a little space between the events of this week and deciding what they will do" type="VP">
          <tokens>
            <token id="3" string="need" />
            <token id="4" string="a" />
            <token id="5" string="little" />
            <token id="6" string="space" />
            <token id="7" string="between" />
            <token id="8" string="the" />
            <token id="9" string="events" />
            <token id="10" string="of" />
            <token id="11" string="this" />
            <token id="12" string="week" />
            <token id="13" string="and" />
            <token id="14" string="deciding" />
            <token id="15" string="what" />
            <token id="16" string="they" />
            <token id="17" string="will" />
            <token id="18" string="do" />
          </tokens>
        </chunking>
        <chunking id="12" string="the events" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="events" />
          </tokens>
        </chunking>
        <chunking id="13" string="said" type="VP">
          <tokens>
            <token id="22" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="a little space between the events of this week and deciding what they will do" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="little" />
            <token id="6" string="space" />
            <token id="7" string="between" />
            <token id="8" string="the" />
            <token id="9" string="events" />
            <token id="10" string="of" />
            <token id="11" string="this" />
            <token id="12" string="week" />
            <token id="13" string="and" />
            <token id="14" string="deciding" />
            <token id="15" string="what" />
            <token id="16" string="they" />
            <token id="17" string="will" />
            <token id="18" string="do" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">parents</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">need</governor>
          <dependent id="2">parents</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="3">need</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">space</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">space</governor>
          <dependent id="5">little</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">need</governor>
          <dependent id="6">space</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">events</governor>
          <dependent id="7">between</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">events</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">space</governor>
          <dependent id="9">events</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">week</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">week</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">events</governor>
          <dependent id="12">week</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">week</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">week</governor>
          <dependent id="14">deciding</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">do</governor>
          <dependent id="15">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">do</governor>
          <dependent id="16">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">do</governor>
          <dependent id="17">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">week</governor>
          <dependent id="18">do</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="21">Mooney</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mooney" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Mooney" />
          </tokens>
        </entity>
        <entity id="2" string="this week" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="week" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>&amp;quot;There is some sentiment that says, &amp;apost;Let&amp;apost;s just put this behind us.&amp;apost;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sentiment" lemma="sentiment" stem="sentiment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (EX There)) (VP (VBZ is) (NP (NP (DT some) (NN sentiment)) (SBAR (WHNP (WDT that)) (S (VP (VBZ says) (, ,) (`` `) (S (VP (VB Let) (S (NP (POS 's)) (VP (ADVP (RB just)) (VB put) (NP (NP (DT this)) (PP (IN behind) (NP (PRP us))))))))))))) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="says , ` Let 's just put this behind us" type="VP">
          <tokens>
            <token id="7" string="says" />
            <token id="8" string="," />
            <token id="9" string="'" />
            <token id="10" string="Let" />
            <token id="11" string="'s" />
            <token id="12" string="just" />
            <token id="13" string="put" />
            <token id="14" string="this" />
            <token id="15" string="behind" />
            <token id="16" string="us" />
          </tokens>
        </chunking>
        <chunking id="2" string="Let 's just put this behind us" type="VP">
          <tokens>
            <token id="10" string="Let" />
            <token id="11" string="'s" />
            <token id="12" string="just" />
            <token id="13" string="put" />
            <token id="14" string="this" />
            <token id="15" string="behind" />
            <token id="16" string="us" />
          </tokens>
        </chunking>
        <chunking id="3" string="just put this behind us" type="VP">
          <tokens>
            <token id="12" string="just" />
            <token id="13" string="put" />
            <token id="14" string="this" />
            <token id="15" string="behind" />
            <token id="16" string="us" />
          </tokens>
        </chunking>
        <chunking id="4" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="5" string="is some sentiment that says , ` Let 's just put this behind us" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="some" />
            <token id="5" string="sentiment" />
            <token id="6" string="that" />
            <token id="7" string="says" />
            <token id="8" string="," />
            <token id="9" string="'" />
            <token id="10" string="Let" />
            <token id="11" string="'s" />
            <token id="12" string="just" />
            <token id="13" string="put" />
            <token id="14" string="this" />
            <token id="15" string="behind" />
            <token id="16" string="us" />
          </tokens>
        </chunking>
        <chunking id="6" string="that says , ` Let 's just put this behind us" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="says" />
            <token id="8" string="," />
            <token id="9" string="'" />
            <token id="10" string="Let" />
            <token id="11" string="'s" />
            <token id="12" string="just" />
            <token id="13" string="put" />
            <token id="14" string="this" />
            <token id="15" string="behind" />
            <token id="16" string="us" />
          </tokens>
        </chunking>
        <chunking id="7" string="this behind us" type="NP">
          <tokens>
            <token id="14" string="this" />
            <token id="15" string="behind" />
            <token id="16" string="us" />
          </tokens>
        </chunking>
        <chunking id="8" string="'s" type="NP">
          <tokens>
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="this" type="NP">
          <tokens>
            <token id="14" string="this" />
          </tokens>
        </chunking>
        <chunking id="10" string="us" type="NP">
          <tokens>
            <token id="16" string="us" />
          </tokens>
        </chunking>
        <chunking id="11" string="some sentiment" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="sentiment" />
          </tokens>
        </chunking>
        <chunking id="12" string="some sentiment that says , ` Let 's just put this behind us" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="sentiment" />
            <token id="6" string="that" />
            <token id="7" string="says" />
            <token id="8" string="," />
            <token id="9" string="'" />
            <token id="10" string="Let" />
            <token id="11" string="'s" />
            <token id="12" string="just" />
            <token id="13" string="put" />
            <token id="14" string="this" />
            <token id="15" string="behind" />
            <token id="16" string="us" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">sentiment</governor>
          <dependent id="4">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="5">sentiment</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">says</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">sentiment</governor>
          <dependent id="7">says</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">says</governor>
          <dependent id="10">Let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">put</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">put</governor>
          <dependent id="12">just</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">Let</governor>
          <dependent id="13">put</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">put</governor>
          <dependent id="14">this</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">us</governor>
          <dependent id="15">behind</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">this</governor>
          <dependent id="16">us</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>But there is also sentiment among others that maybe they should pick up the civil case where the criminal case left off.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="sentiment" lemma="sentiment" stem="sentiment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="maybe" lemma="maybe" stem="mayb" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="pick" lemma="pick" stem="pick" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="22" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (EX there)) (VP (VBZ is) (ADVP (RB also)) (NP (NP (NN sentiment)) (PP (IN among) (NP (NP (NNS others)) (SBAR (WHNP (WDT that)) (S (ADVP (RB maybe)) (NP (PRP they)) (VP (MD should) (VP (VB pick) (PRT (RP up)) (NP (NP (DT the) (JJ civil) (NN case)) (SBAR (WHADVP (WRB where)) (S (NP (DT the) (JJ criminal) (NN case)) (VP (VBD left) (PRT (RP off)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sentiment" type="NP">
          <tokens>
            <token id="5" string="sentiment" />
          </tokens>
        </chunking>
        <chunking id="2" string="left off" type="VP">
          <tokens>
            <token id="21" string="left" />
            <token id="22" string="off" />
          </tokens>
        </chunking>
        <chunking id="3" string="that maybe they should pick up the civil case where the criminal case left off" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="maybe" />
            <token id="10" string="they" />
            <token id="11" string="should" />
            <token id="12" string="pick" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="civil" />
            <token id="16" string="case" />
            <token id="17" string="where" />
            <token id="18" string="the" />
            <token id="19" string="criminal" />
            <token id="20" string="case" />
            <token id="21" string="left" />
            <token id="22" string="off" />
          </tokens>
        </chunking>
        <chunking id="4" string="sentiment among others that maybe they should pick up the civil case where the criminal case left off" type="NP">
          <tokens>
            <token id="5" string="sentiment" />
            <token id="6" string="among" />
            <token id="7" string="others" />
            <token id="8" string="that" />
            <token id="9" string="maybe" />
            <token id="10" string="they" />
            <token id="11" string="should" />
            <token id="12" string="pick" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="civil" />
            <token id="16" string="case" />
            <token id="17" string="where" />
            <token id="18" string="the" />
            <token id="19" string="criminal" />
            <token id="20" string="case" />
            <token id="21" string="left" />
            <token id="22" string="off" />
          </tokens>
        </chunking>
        <chunking id="5" string="is also sentiment among others that maybe they should pick up the civil case where the criminal case left off" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="also" />
            <token id="5" string="sentiment" />
            <token id="6" string="among" />
            <token id="7" string="others" />
            <token id="8" string="that" />
            <token id="9" string="maybe" />
            <token id="10" string="they" />
            <token id="11" string="should" />
            <token id="12" string="pick" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="civil" />
            <token id="16" string="case" />
            <token id="17" string="where" />
            <token id="18" string="the" />
            <token id="19" string="criminal" />
            <token id="20" string="case" />
            <token id="21" string="left" />
            <token id="22" string="off" />
          </tokens>
        </chunking>
        <chunking id="6" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="7" string="they" type="NP">
          <tokens>
            <token id="10" string="they" />
          </tokens>
        </chunking>
        <chunking id="8" string="pick up the civil case where the criminal case left off" type="VP">
          <tokens>
            <token id="12" string="pick" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="civil" />
            <token id="16" string="case" />
            <token id="17" string="where" />
            <token id="18" string="the" />
            <token id="19" string="criminal" />
            <token id="20" string="case" />
            <token id="21" string="left" />
            <token id="22" string="off" />
          </tokens>
        </chunking>
        <chunking id="9" string="should pick up the civil case where the criminal case left off" type="VP">
          <tokens>
            <token id="11" string="should" />
            <token id="12" string="pick" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="civil" />
            <token id="16" string="case" />
            <token id="17" string="where" />
            <token id="18" string="the" />
            <token id="19" string="criminal" />
            <token id="20" string="case" />
            <token id="21" string="left" />
            <token id="22" string="off" />
          </tokens>
        </chunking>
        <chunking id="10" string="others that maybe they should pick up the civil case where the criminal case left off" type="NP">
          <tokens>
            <token id="7" string="others" />
            <token id="8" string="that" />
            <token id="9" string="maybe" />
            <token id="10" string="they" />
            <token id="11" string="should" />
            <token id="12" string="pick" />
            <token id="13" string="up" />
            <token id="14" string="the" />
            <token id="15" string="civil" />
            <token id="16" string="case" />
            <token id="17" string="where" />
            <token id="18" string="the" />
            <token id="19" string="criminal" />
            <token id="20" string="case" />
            <token id="21" string="left" />
            <token id="22" string="off" />
          </tokens>
        </chunking>
        <chunking id="11" string="the civil case where the criminal case left off" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="civil" />
            <token id="16" string="case" />
            <token id="17" string="where" />
            <token id="18" string="the" />
            <token id="19" string="criminal" />
            <token id="20" string="case" />
            <token id="21" string="left" />
            <token id="22" string="off" />
          </tokens>
        </chunking>
        <chunking id="12" string="the criminal case" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="criminal" />
            <token id="20" string="case" />
          </tokens>
        </chunking>
        <chunking id="13" string="where" type="WHADVP">
          <tokens>
            <token id="17" string="where" />
          </tokens>
        </chunking>
        <chunking id="14" string="where the criminal case left off" type="SBAR">
          <tokens>
            <token id="17" string="where" />
            <token id="18" string="the" />
            <token id="19" string="criminal" />
            <token id="20" string="case" />
            <token id="21" string="left" />
            <token id="22" string="off" />
          </tokens>
        </chunking>
        <chunking id="15" string="others" type="NP">
          <tokens>
            <token id="7" string="others" />
          </tokens>
        </chunking>
        <chunking id="16" string="the civil case" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="civil" />
            <token id="16" string="case" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">is</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">is</governor>
          <dependent id="4">also</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="5">sentiment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">others</governor>
          <dependent id="6">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">sentiment</governor>
          <dependent id="7">others</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">pick</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">pick</governor>
          <dependent id="9">maybe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">pick</governor>
          <dependent id="10">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">pick</governor>
          <dependent id="11">should</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">others</governor>
          <dependent id="12">pick</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">pick</governor>
          <dependent id="13">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">case</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">case</governor>
          <dependent id="15">civil</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">pick</governor>
          <dependent id="16">case</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">left</governor>
          <dependent id="17">where</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">case</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">case</governor>
          <dependent id="19">criminal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">left</governor>
          <dependent id="20">case</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="16">case</governor>
          <dependent id="21">left</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="21">left</governor>
          <dependent id="22">off</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="21" string="left" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>&amp;quot;They heard the jurors when they said they believed that things happened to the children.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="heard" lemma="hear" stem="heard" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="believed" lemma="believe" stem="believ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="happened" lemma="happen" stem="happen" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP They)) (VP (VBD heard) (NP (DT the) (NNS jurors)) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VBD believed) (SBAR (IN that) (S (NP (NNS things)) (VP (VBD happened) (PP (TO to) (NP (DT the) (NNS children))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="heard the jurors when they said they believed that things happened to the children" type="VP">
          <tokens>
            <token id="3" string="heard" />
            <token id="4" string="the" />
            <token id="5" string="jurors" />
            <token id="6" string="when" />
            <token id="7" string="they" />
            <token id="8" string="said" />
            <token id="9" string="they" />
            <token id="10" string="believed" />
            <token id="11" string="that" />
            <token id="12" string="things" />
            <token id="13" string="happened" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="believed that things happened to the children" type="VP">
          <tokens>
            <token id="10" string="believed" />
            <token id="11" string="that" />
            <token id="12" string="things" />
            <token id="13" string="happened" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="4" string="happened to the children" type="VP">
          <tokens>
            <token id="13" string="happened" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="5" string="the jurors" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="6" string="when" type="WHADVP">
          <tokens>
            <token id="6" string="when" />
          </tokens>
        </chunking>
        <chunking id="7" string="they" type="NP">
          <tokens>
            <token id="7" string="they" />
          </tokens>
        </chunking>
        <chunking id="8" string="said they believed that things happened to the children" type="VP">
          <tokens>
            <token id="8" string="said" />
            <token id="9" string="they" />
            <token id="10" string="believed" />
            <token id="11" string="that" />
            <token id="12" string="things" />
            <token id="13" string="happened" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="the children" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="10" string="when they said they believed that things happened to the children" type="SBAR">
          <tokens>
            <token id="6" string="when" />
            <token id="7" string="they" />
            <token id="8" string="said" />
            <token id="9" string="they" />
            <token id="10" string="believed" />
            <token id="11" string="that" />
            <token id="12" string="things" />
            <token id="13" string="happened" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="11" string="that things happened to the children" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="things" />
            <token id="13" string="happened" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="they believed that things happened to the children" type="SBAR">
          <tokens>
            <token id="9" string="they" />
            <token id="10" string="believed" />
            <token id="11" string="that" />
            <token id="12" string="things" />
            <token id="13" string="happened" />
            <token id="14" string="to" />
            <token id="15" string="the" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="13" string="things" type="NP">
          <tokens>
            <token id="12" string="things" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">heard</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">heard</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">jurors</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">heard</governor>
          <dependent id="5">jurors</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">said</governor>
          <dependent id="6">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="7">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">heard</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">believed</governor>
          <dependent id="9">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="10">believed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">happened</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">happened</governor>
          <dependent id="12">things</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">believed</governor>
          <dependent id="13">happened</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">children</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">children</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">happened</governor>
          <dependent id="16">children</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>They think maybe since the criminal jury couldn&amp;apost;t get the higher standard of proof, a civil jury would bring about a resolution.&amp;quot;</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="think" lemma="think" stem="think" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="maybe" lemma="maybe" stem="mayb" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="higher" lemma="higher" stem="higher" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="standard" lemma="standard" stem="standard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="proof" lemma="proof" stem="proof" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="bring" lemma="bring" stem="bring" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="resolution" lemma="resolution" stem="resolut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP They)) (VP (VBP think) (ADVP (RB maybe)) (SBAR (IN since) (S (NP (DT the) (JJ criminal) (NN jury)) (VP (MD could) (RB n't) (VP (VB get) (NP (NP (DT the) (JJR higher) (NN standard)) (PP (IN of) (NP (NN proof)))))))))) (, ,) (NP (DT a) (JJ civil) (NN jury)) (VP (MD would) (VP (VB bring) (PP (IN about) (NP (DT a) (NN resolution))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="get the higher standard of proof" type="VP">
          <tokens>
            <token id="10" string="get" />
            <token id="11" string="the" />
            <token id="12" string="higher" />
            <token id="13" string="standard" />
            <token id="14" string="of" />
            <token id="15" string="proof" />
          </tokens>
        </chunking>
        <chunking id="3" string="the higher standard of proof" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="higher" />
            <token id="13" string="standard" />
            <token id="14" string="of" />
            <token id="15" string="proof" />
          </tokens>
        </chunking>
        <chunking id="4" string="a civil jury" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="civil" />
            <token id="19" string="jury" />
          </tokens>
        </chunking>
        <chunking id="5" string="since the criminal jury could n't get the higher standard of proof" type="SBAR">
          <tokens>
            <token id="4" string="since" />
            <token id="5" string="the" />
            <token id="6" string="criminal" />
            <token id="7" string="jury" />
            <token id="8" string="could" />
            <token id="9" string="n't" />
            <token id="10" string="get" />
            <token id="11" string="the" />
            <token id="12" string="higher" />
            <token id="13" string="standard" />
            <token id="14" string="of" />
            <token id="15" string="proof" />
          </tokens>
        </chunking>
        <chunking id="6" string="bring about a resolution" type="VP">
          <tokens>
            <token id="21" string="bring" />
            <token id="22" string="about" />
            <token id="23" string="a" />
            <token id="24" string="resolution" />
          </tokens>
        </chunking>
        <chunking id="7" string="a resolution" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="resolution" />
          </tokens>
        </chunking>
        <chunking id="8" string="the higher standard" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="higher" />
            <token id="13" string="standard" />
          </tokens>
        </chunking>
        <chunking id="9" string="would bring about a resolution" type="VP">
          <tokens>
            <token id="20" string="would" />
            <token id="21" string="bring" />
            <token id="22" string="about" />
            <token id="23" string="a" />
            <token id="24" string="resolution" />
          </tokens>
        </chunking>
        <chunking id="10" string="could n't get the higher standard of proof" type="VP">
          <tokens>
            <token id="8" string="could" />
            <token id="9" string="n't" />
            <token id="10" string="get" />
            <token id="11" string="the" />
            <token id="12" string="higher" />
            <token id="13" string="standard" />
            <token id="14" string="of" />
            <token id="15" string="proof" />
          </tokens>
        </chunking>
        <chunking id="11" string="think maybe since the criminal jury could n't get the higher standard of proof" type="VP">
          <tokens>
            <token id="2" string="think" />
            <token id="3" string="maybe" />
            <token id="4" string="since" />
            <token id="5" string="the" />
            <token id="6" string="criminal" />
            <token id="7" string="jury" />
            <token id="8" string="could" />
            <token id="9" string="n't" />
            <token id="10" string="get" />
            <token id="11" string="the" />
            <token id="12" string="higher" />
            <token id="13" string="standard" />
            <token id="14" string="of" />
            <token id="15" string="proof" />
          </tokens>
        </chunking>
        <chunking id="12" string="the criminal jury" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="criminal" />
            <token id="7" string="jury" />
          </tokens>
        </chunking>
        <chunking id="13" string="proof" type="NP">
          <tokens>
            <token id="15" string="proof" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">think</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">bring</governor>
          <dependent id="2">think</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">think</governor>
          <dependent id="3">maybe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">get</governor>
          <dependent id="4">since</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">jury</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">jury</governor>
          <dependent id="6">criminal</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">get</governor>
          <dependent id="7">jury</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">get</governor>
          <dependent id="8">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">get</governor>
          <dependent id="9">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">think</governor>
          <dependent id="10">get</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">standard</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">standard</governor>
          <dependent id="12">higher</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">get</governor>
          <dependent id="13">standard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">proof</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">standard</governor>
          <dependent id="15">proof</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">jury</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">jury</governor>
          <dependent id="18">civil</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">bring</governor>
          <dependent id="19">jury</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">bring</governor>
          <dependent id="20">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">bring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">resolution</governor>
          <dependent id="22">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">resolution</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">bring</governor>
          <dependent id="24">resolution</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>Said one McMartin attendee&amp;apost;s parent, who asked not to be identified: &amp;quot;I might be tempted to file a civil suit to provide a trust fund for my child.</content>
      <tokens>
        <token id="1" string="Said" lemma="Said" stem="said" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="attendee" lemma="attendee" stem="attende" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="parent" lemma="parent" stem="parent" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="identified" lemma="identify" stem="identifi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="tempted" lemma="tempt" stem="tempt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="file" lemma="file" stem="file" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="civil" lemma="civil" stem="civil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="provide" lemma="provide" stem="provid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="trust" lemma="trust" stem="trust" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="fund" lemma="fund" stem="fund" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NP (NNP Said) (CD one)) (NP (NP (NNP McMartin) (NN attendee) (POS 's)) (NN parent))) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD asked) (S (RB not) (VP (TO to) (VP (VB be) (VP (VBN identified))))))))) (: :) (S (`` ``) (NP (PRP I)) (VP (MD might) (VP (VB be) (VP (VBN tempted) (S (VP (TO to) (VP (VB file) (NP (DT a) (JJ civil) (NN suit)) (S (VP (TO to) (VP (VB provide) (NP (DT a) (NN trust) (NN fund)) (PP (IN for) (NP (PRP$ my) (NN child))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to be identified" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="be" />
            <token id="13" string="identified" />
          </tokens>
        </chunking>
        <chunking id="2" string="Said one McMartin attendee 's parent , who asked not to be identified : `` I might be tempted to file a civil suit to provide a trust fund for my child ." type="NP">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="one" />
            <token id="3" string="McMartin" />
            <token id="4" string="attendee" />
            <token id="5" string="'s" />
            <token id="6" string="parent" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="asked" />
            <token id="10" string="not" />
            <token id="11" string="to" />
            <token id="12" string="be" />
            <token id="13" string="identified" />
            <token id="14" string=":" />
            <token id="15" string="&quot;" />
            <token id="16" string="I" />
            <token id="17" string="might" />
            <token id="18" string="be" />
            <token id="19" string="tempted" />
            <token id="20" string="to" />
            <token id="21" string="file" />
            <token id="22" string="a" />
            <token id="23" string="civil" />
            <token id="24" string="suit" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="trust" />
            <token id="29" string="fund" />
            <token id="30" string="for" />
            <token id="31" string="my" />
            <token id="32" string="child" />
            <token id="33" string="." />
          </tokens>
        </chunking>
        <chunking id="3" string="to file a civil suit to provide a trust fund for my child" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="file" />
            <token id="22" string="a" />
            <token id="23" string="civil" />
            <token id="24" string="suit" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="trust" />
            <token id="29" string="fund" />
            <token id="30" string="for" />
            <token id="31" string="my" />
            <token id="32" string="child" />
          </tokens>
        </chunking>
        <chunking id="4" string="Said one McMartin attendee 's parent , who asked not to be identified" type="NP">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="one" />
            <token id="3" string="McMartin" />
            <token id="4" string="attendee" />
            <token id="5" string="'s" />
            <token id="6" string="parent" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="asked" />
            <token id="10" string="not" />
            <token id="11" string="to" />
            <token id="12" string="be" />
            <token id="13" string="identified" />
          </tokens>
        </chunking>
        <chunking id="5" string="McMartin attendee 's" type="NP">
          <tokens>
            <token id="3" string="McMartin" />
            <token id="4" string="attendee" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="a civil suit" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="civil" />
            <token id="24" string="suit" />
          </tokens>
        </chunking>
        <chunking id="7" string="provide a trust fund for my child" type="VP">
          <tokens>
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="trust" />
            <token id="29" string="fund" />
            <token id="30" string="for" />
            <token id="31" string="my" />
            <token id="32" string="child" />
          </tokens>
        </chunking>
        <chunking id="8" string="who asked not to be identified" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="asked" />
            <token id="10" string="not" />
            <token id="11" string="to" />
            <token id="12" string="be" />
            <token id="13" string="identified" />
          </tokens>
        </chunking>
        <chunking id="9" string="Said one McMartin attendee 's parent" type="NP">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="one" />
            <token id="3" string="McMartin" />
            <token id="4" string="attendee" />
            <token id="5" string="'s" />
            <token id="6" string="parent" />
          </tokens>
        </chunking>
        <chunking id="10" string="to provide a trust fund for my child" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="trust" />
            <token id="29" string="fund" />
            <token id="30" string="for" />
            <token id="31" string="my" />
            <token id="32" string="child" />
          </tokens>
        </chunking>
        <chunking id="11" string="I" type="NP">
          <tokens>
            <token id="16" string="I" />
          </tokens>
        </chunking>
        <chunking id="12" string="might be tempted to file a civil suit to provide a trust fund for my child" type="VP">
          <tokens>
            <token id="17" string="might" />
            <token id="18" string="be" />
            <token id="19" string="tempted" />
            <token id="20" string="to" />
            <token id="21" string="file" />
            <token id="22" string="a" />
            <token id="23" string="civil" />
            <token id="24" string="suit" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="trust" />
            <token id="29" string="fund" />
            <token id="30" string="for" />
            <token id="31" string="my" />
            <token id="32" string="child" />
          </tokens>
        </chunking>
        <chunking id="13" string="a trust fund" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="trust" />
            <token id="29" string="fund" />
          </tokens>
        </chunking>
        <chunking id="14" string="be identified" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="identified" />
          </tokens>
        </chunking>
        <chunking id="15" string="tempted to file a civil suit to provide a trust fund for my child" type="VP">
          <tokens>
            <token id="19" string="tempted" />
            <token id="20" string="to" />
            <token id="21" string="file" />
            <token id="22" string="a" />
            <token id="23" string="civil" />
            <token id="24" string="suit" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="trust" />
            <token id="29" string="fund" />
            <token id="30" string="for" />
            <token id="31" string="my" />
            <token id="32" string="child" />
          </tokens>
        </chunking>
        <chunking id="16" string="McMartin attendee 's parent" type="NP">
          <tokens>
            <token id="3" string="McMartin" />
            <token id="4" string="attendee" />
            <token id="5" string="'s" />
            <token id="6" string="parent" />
          </tokens>
        </chunking>
        <chunking id="17" string="Said one" type="NP">
          <tokens>
            <token id="1" string="Said" />
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="18" string="identified" type="VP">
          <tokens>
            <token id="13" string="identified" />
          </tokens>
        </chunking>
        <chunking id="19" string="asked not to be identified" type="VP">
          <tokens>
            <token id="9" string="asked" />
            <token id="10" string="not" />
            <token id="11" string="to" />
            <token id="12" string="be" />
            <token id="13" string="identified" />
          </tokens>
        </chunking>
        <chunking id="20" string="my child" type="NP">
          <tokens>
            <token id="31" string="my" />
            <token id="32" string="child" />
          </tokens>
        </chunking>
        <chunking id="21" string="be tempted to file a civil suit to provide a trust fund for my child" type="VP">
          <tokens>
            <token id="18" string="be" />
            <token id="19" string="tempted" />
            <token id="20" string="to" />
            <token id="21" string="file" />
            <token id="22" string="a" />
            <token id="23" string="civil" />
            <token id="24" string="suit" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="trust" />
            <token id="29" string="fund" />
            <token id="30" string="for" />
            <token id="31" string="my" />
            <token id="32" string="child" />
          </tokens>
        </chunking>
        <chunking id="22" string="file a civil suit to provide a trust fund for my child" type="VP">
          <tokens>
            <token id="21" string="file" />
            <token id="22" string="a" />
            <token id="23" string="civil" />
            <token id="24" string="suit" />
            <token id="25" string="to" />
            <token id="26" string="provide" />
            <token id="27" string="a" />
            <token id="28" string="trust" />
            <token id="29" string="fund" />
            <token id="30" string="for" />
            <token id="31" string="my" />
            <token id="32" string="child" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Said</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="1">Said</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">attendee</governor>
          <dependent id="3">McMartin</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">parent</governor>
          <dependent id="4">attendee</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">attendee</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Said</governor>
          <dependent id="6">parent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">asked</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Said</governor>
          <dependent id="9">asked</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">identified</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">identified</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">identified</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">asked</governor>
          <dependent id="13">identified</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">tempted</governor>
          <dependent id="16">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">tempted</governor>
          <dependent id="17">might</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">tempted</governor>
          <dependent id="18">be</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">Said</governor>
          <dependent id="19">tempted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">file</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">tempted</governor>
          <dependent id="21">file</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">suit</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">suit</governor>
          <dependent id="23">civil</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">file</governor>
          <dependent id="24">suit</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">provide</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">file</governor>
          <dependent id="26">provide</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">fund</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">fund</governor>
          <dependent id="28">trust</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">provide</governor>
          <dependent id="29">fund</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">child</governor>
          <dependent id="30">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">child</governor>
          <dependent id="31">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">provide</governor>
          <dependent id="32">child</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="false">
      <content>But there apparently isn&amp;apost;t any money there to be had.&amp;quot;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="apparently" lemma="apparently" stem="appar" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="money" lemma="money" stem="monei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (EX there)) (ADVP (RB apparently)) (VP (VBZ is) (RB n't) (ADVP (NP (DT any) (NN money)) (RB there)) (S (VP (TO to) (VP (VB be) (VP (VBN had)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="to be had" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="had" />
          </tokens>
        </chunking>
        <chunking id="3" string="be had" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="had" />
          </tokens>
        </chunking>
        <chunking id="4" string="is n't any money there to be had" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="n't" />
            <token id="6" string="any" />
            <token id="7" string="money" />
            <token id="8" string="there" />
            <token id="9" string="to" />
            <token id="10" string="be" />
            <token id="11" string="had" />
          </tokens>
        </chunking>
        <chunking id="5" string="any money" type="NP">
          <tokens>
            <token id="6" string="any" />
            <token id="7" string="money" />
          </tokens>
        </chunking>
        <chunking id="6" string="had" type="VP">
          <tokens>
            <token id="11" string="had" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">is</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="4">is</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">is</governor>
          <dependent id="3">apparently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">is</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">money</governor>
          <dependent id="6">any</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="8">there</governor>
          <dependent id="7">money</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">is</governor>
          <dependent id="8">there</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">had</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">had</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">is</governor>
          <dependent id="11">had</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>The only other reasons for filing such a suit, the parent added, would be &amp;quot;to work through a lot of emotional things, and we have already done that by participating in the criminal proceedings.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="reasons" lemma="reason" stem="reason" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="filing" lemma="file" stem="file" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="such" lemma="such" stem="such" pos="PDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="parent" lemma="parent" stem="parent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="work" lemma="work" stem="work" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="emotional" lemma="emotional" stem="emot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="participating" lemma="participate" stem="particip" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="proceedings" lemma="proceedings" stem="proceed" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (JJ only) (JJ other) (NNS reasons)) (PP (IN for) (S (VP (VBG filing) (NP (PDT such) (DT a) (NN suit))))) (PRN (, ,) (S (NP (DT the) (NN parent)) (VP (VBD added))) (, ,))) (VP (MD would) (VP (VB be) (`` ``) (S (VP (TO to) (VP (VB work) (PP (IN through) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (JJ emotional) (NNS things))))))))))) (, ,) (CC and) (S (NP (PRP we)) (VP (VBP have) (ADVP (RB already)) (VP (VBN done) (ADVP (IN that)) (PP (IN by) (S (VP (VBG participating) (PP (IN in) (NP (DT the) (JJ criminal) (NNS proceedings))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="such a suit" type="NP">
          <tokens>
            <token id="7" string="such" />
            <token id="8" string="a" />
            <token id="9" string="suit" />
          </tokens>
        </chunking>
        <chunking id="2" string="The only other reasons" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="only" />
            <token id="3" string="other" />
            <token id="4" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="3" string="done that by participating in the criminal proceedings" type="VP">
          <tokens>
            <token id="31" string="done" />
            <token id="32" string="that" />
            <token id="33" string="by" />
            <token id="34" string="participating" />
            <token id="35" string="in" />
            <token id="36" string="the" />
            <token id="37" string="criminal" />
            <token id="38" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="4" string="the parent" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="parent" />
          </tokens>
        </chunking>
        <chunking id="5" string="would be `` to work through a lot of emotional things" type="VP">
          <tokens>
            <token id="15" string="would" />
            <token id="16" string="be" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="work" />
            <token id="20" string="through" />
            <token id="21" string="a" />
            <token id="22" string="lot" />
            <token id="23" string="of" />
            <token id="24" string="emotional" />
            <token id="25" string="things" />
          </tokens>
        </chunking>
        <chunking id="6" string="filing such a suit" type="VP">
          <tokens>
            <token id="6" string="filing" />
            <token id="7" string="such" />
            <token id="8" string="a" />
            <token id="9" string="suit" />
          </tokens>
        </chunking>
        <chunking id="7" string="we" type="NP">
          <tokens>
            <token id="28" string="we" />
          </tokens>
        </chunking>
        <chunking id="8" string="The only other reasons for filing such a suit , the parent added ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="only" />
            <token id="3" string="other" />
            <token id="4" string="reasons" />
            <token id="5" string="for" />
            <token id="6" string="filing" />
            <token id="7" string="such" />
            <token id="8" string="a" />
            <token id="9" string="suit" />
            <token id="10" string="," />
            <token id="11" string="the" />
            <token id="12" string="parent" />
            <token id="13" string="added" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="be `` to work through a lot of emotional things" type="VP">
          <tokens>
            <token id="16" string="be" />
            <token id="17" string="&quot;" />
            <token id="18" string="to" />
            <token id="19" string="work" />
            <token id="20" string="through" />
            <token id="21" string="a" />
            <token id="22" string="lot" />
            <token id="23" string="of" />
            <token id="24" string="emotional" />
            <token id="25" string="things" />
          </tokens>
        </chunking>
        <chunking id="10" string="a lot of emotional things" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="lot" />
            <token id="23" string="of" />
            <token id="24" string="emotional" />
            <token id="25" string="things" />
          </tokens>
        </chunking>
        <chunking id="11" string="the criminal proceedings" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="criminal" />
            <token id="38" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="12" string="participating in the criminal proceedings" type="VP">
          <tokens>
            <token id="34" string="participating" />
            <token id="35" string="in" />
            <token id="36" string="the" />
            <token id="37" string="criminal" />
            <token id="38" string="proceedings" />
          </tokens>
        </chunking>
        <chunking id="13" string="to work through a lot of emotional things" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="work" />
            <token id="20" string="through" />
            <token id="21" string="a" />
            <token id="22" string="lot" />
            <token id="23" string="of" />
            <token id="24" string="emotional" />
            <token id="25" string="things" />
          </tokens>
        </chunking>
        <chunking id="14" string="a lot" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="lot" />
          </tokens>
        </chunking>
        <chunking id="15" string="emotional things" type="NP">
          <tokens>
            <token id="24" string="emotional" />
            <token id="25" string="things" />
          </tokens>
        </chunking>
        <chunking id="16" string="added" type="VP">
          <tokens>
            <token id="13" string="added" />
          </tokens>
        </chunking>
        <chunking id="17" string="work through a lot of emotional things" type="VP">
          <tokens>
            <token id="19" string="work" />
            <token id="20" string="through" />
            <token id="21" string="a" />
            <token id="22" string="lot" />
            <token id="23" string="of" />
            <token id="24" string="emotional" />
            <token id="25" string="things" />
          </tokens>
        </chunking>
        <chunking id="18" string="have already done that by participating in the criminal proceedings" type="VP">
          <tokens>
            <token id="29" string="have" />
            <token id="30" string="already" />
            <token id="31" string="done" />
            <token id="32" string="that" />
            <token id="33" string="by" />
            <token id="34" string="participating" />
            <token id="35" string="in" />
            <token id="36" string="the" />
            <token id="37" string="criminal" />
            <token id="38" string="proceedings" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">reasons</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">reasons</governor>
          <dependent id="2">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">reasons</governor>
          <dependent id="3">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">be</governor>
          <dependent id="4">reasons</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">filing</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">reasons</governor>
          <dependent id="6">filing</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="9">suit</governor>
          <dependent id="7">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">suit</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">filing</governor>
          <dependent id="9">suit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">parent</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">added</governor>
          <dependent id="12">parent</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">reasons</governor>
          <dependent id="13">added</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">be</governor>
          <dependent id="15">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">be</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">work</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">be</governor>
          <dependent id="19">work</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">lot</governor>
          <dependent id="20">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">lot</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">work</governor>
          <dependent id="22">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">things</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">things</governor>
          <dependent id="24">emotional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">lot</governor>
          <dependent id="25">things</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">be</governor>
          <dependent id="27">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">done</governor>
          <dependent id="28">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">done</governor>
          <dependent id="29">have</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">done</governor>
          <dependent id="30">already</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">be</governor>
          <dependent id="31">done</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">done</governor>
          <dependent id="32">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">participating</governor>
          <dependent id="33">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">done</governor>
          <dependent id="34">participating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">proceedings</governor>
          <dependent id="35">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">proceedings</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">proceedings</governor>
          <dependent id="37">criminal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">participating</governor>
          <dependent id="38">proceedings</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>Gauna, Spitler&amp;apost;s attorney, said the litigation will go on because &amp;quot;maybe a half-dozen to a dozen hard-line parents won&amp;apost;t let it go away.</content>
      <tokens>
        <token id="1" string="Gauna" lemma="Gauna" stem="gauna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Spitler" lemma="Spitler" stem="spitler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="litigation" lemma="litigation" stem="litig" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="maybe" lemma="maybe" stem="mayb" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="half-dozen" lemma="half-dozen" stem="half-dozen" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="dozen" lemma="dozen" stem="dozen" pos="NN" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="21" string="hard-line" lemma="hard-line" stem="hard-lin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="wo" lemma="will" stem="wo" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Gauna)) (, ,) (NP (NP (NNP Spitler) (POS 's)) (NN attorney)) (, ,)) (VP (VBD said) (SBAR (S (NP (DT the) (NN litigation)) (VP (MD will) (VP (VB go) (PRT (IN on)) (SBAR (IN because) (`` ``) (S (NP (NP (RB maybe) (DT a) (NN half-dozen)) (PP (TO to) (NP (QP (DT a) (NN dozen)) (JJ hard-line) (NNS parents)))) (VP (MD wo) (RB n't) (VP (VB let) (S (NP (PRP it)) (VP (VB go) (ADVP (RB away))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="wo n't let it go away" type="VP">
          <tokens>
            <token id="23" string="wo" />
            <token id="24" string="n't" />
            <token id="25" string="let" />
            <token id="26" string="it" />
            <token id="27" string="go" />
            <token id="28" string="away" />
          </tokens>
        </chunking>
        <chunking id="2" string="maybe a half-dozen" type="NP">
          <tokens>
            <token id="15" string="maybe" />
            <token id="16" string="a" />
            <token id="17" string="half-dozen" />
          </tokens>
        </chunking>
        <chunking id="3" string="Spitler 's" type="NP">
          <tokens>
            <token id="3" string="Spitler" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="will go on because `` maybe a half-dozen to a dozen hard-line parents wo n't let it go away" type="VP">
          <tokens>
            <token id="10" string="will" />
            <token id="11" string="go" />
            <token id="12" string="on" />
            <token id="13" string="because" />
            <token id="14" string="&quot;" />
            <token id="15" string="maybe" />
            <token id="16" string="a" />
            <token id="17" string="half-dozen" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="dozen" />
            <token id="21" string="hard-line" />
            <token id="22" string="parents" />
            <token id="23" string="wo" />
            <token id="24" string="n't" />
            <token id="25" string="let" />
            <token id="26" string="it" />
            <token id="27" string="go" />
            <token id="28" string="away" />
          </tokens>
        </chunking>
        <chunking id="5" string="maybe a half-dozen to a dozen hard-line parents" type="NP">
          <tokens>
            <token id="15" string="maybe" />
            <token id="16" string="a" />
            <token id="17" string="half-dozen" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="dozen" />
            <token id="21" string="hard-line" />
            <token id="22" string="parents" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="a dozen hard-line parents" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="dozen" />
            <token id="21" string="hard-line" />
            <token id="22" string="parents" />
          </tokens>
        </chunking>
        <chunking id="8" string="let it go away" type="VP">
          <tokens>
            <token id="25" string="let" />
            <token id="26" string="it" />
            <token id="27" string="go" />
            <token id="28" string="away" />
          </tokens>
        </chunking>
        <chunking id="9" string="said the litigation will go on because `` maybe a half-dozen to a dozen hard-line parents wo n't let it go away" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="the" />
            <token id="9" string="litigation" />
            <token id="10" string="will" />
            <token id="11" string="go" />
            <token id="12" string="on" />
            <token id="13" string="because" />
            <token id="14" string="&quot;" />
            <token id="15" string="maybe" />
            <token id="16" string="a" />
            <token id="17" string="half-dozen" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="dozen" />
            <token id="21" string="hard-line" />
            <token id="22" string="parents" />
            <token id="23" string="wo" />
            <token id="24" string="n't" />
            <token id="25" string="let" />
            <token id="26" string="it" />
            <token id="27" string="go" />
            <token id="28" string="away" />
          </tokens>
        </chunking>
        <chunking id="10" string="the litigation will go on because `` maybe a half-dozen to a dozen hard-line parents wo n't let it go away" type="SBAR">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="litigation" />
            <token id="10" string="will" />
            <token id="11" string="go" />
            <token id="12" string="on" />
            <token id="13" string="because" />
            <token id="14" string="&quot;" />
            <token id="15" string="maybe" />
            <token id="16" string="a" />
            <token id="17" string="half-dozen" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="dozen" />
            <token id="21" string="hard-line" />
            <token id="22" string="parents" />
            <token id="23" string="wo" />
            <token id="24" string="n't" />
            <token id="25" string="let" />
            <token id="26" string="it" />
            <token id="27" string="go" />
            <token id="28" string="away" />
          </tokens>
        </chunking>
        <chunking id="11" string="go on because `` maybe a half-dozen to a dozen hard-line parents wo n't let it go away" type="VP">
          <tokens>
            <token id="11" string="go" />
            <token id="12" string="on" />
            <token id="13" string="because" />
            <token id="14" string="&quot;" />
            <token id="15" string="maybe" />
            <token id="16" string="a" />
            <token id="17" string="half-dozen" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="dozen" />
            <token id="21" string="hard-line" />
            <token id="22" string="parents" />
            <token id="23" string="wo" />
            <token id="24" string="n't" />
            <token id="25" string="let" />
            <token id="26" string="it" />
            <token id="27" string="go" />
            <token id="28" string="away" />
          </tokens>
        </chunking>
        <chunking id="12" string="the litigation" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="litigation" />
          </tokens>
        </chunking>
        <chunking id="13" string="Gauna , Spitler 's attorney ," type="NP">
          <tokens>
            <token id="1" string="Gauna" />
            <token id="2" string="," />
            <token id="3" string="Spitler" />
            <token id="4" string="'s" />
            <token id="5" string="attorney" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="14" string="go away" type="VP">
          <tokens>
            <token id="27" string="go" />
            <token id="28" string="away" />
          </tokens>
        </chunking>
        <chunking id="15" string="Gauna" type="NP">
          <tokens>
            <token id="1" string="Gauna" />
          </tokens>
        </chunking>
        <chunking id="16" string="Spitler 's attorney" type="NP">
          <tokens>
            <token id="3" string="Spitler" />
            <token id="4" string="'s" />
            <token id="5" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="17" string="because `` maybe a half-dozen to a dozen hard-line parents wo n't let it go away" type="SBAR">
          <tokens>
            <token id="13" string="because" />
            <token id="14" string="&quot;" />
            <token id="15" string="maybe" />
            <token id="16" string="a" />
            <token id="17" string="half-dozen" />
            <token id="18" string="to" />
            <token id="19" string="a" />
            <token id="20" string="dozen" />
            <token id="21" string="hard-line" />
            <token id="22" string="parents" />
            <token id="23" string="wo" />
            <token id="24" string="n't" />
            <token id="25" string="let" />
            <token id="26" string="it" />
            <token id="27" string="go" />
            <token id="28" string="away" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="1">Gauna</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">attorney</governor>
          <dependent id="3">Spitler</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Spitler</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Gauna</governor>
          <dependent id="5">attorney</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">litigation</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">go</governor>
          <dependent id="9">litigation</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">go</governor>
          <dependent id="10">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="11">go</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">go</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">let</governor>
          <dependent id="13">because</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">half-dozen</governor>
          <dependent id="15">maybe</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">half-dozen</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">let</governor>
          <dependent id="17">half-dozen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">parents</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">dozen</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">parents</governor>
          <dependent id="20">dozen</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">parents</governor>
          <dependent id="21">hard-line</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">half-dozen</governor>
          <dependent id="22">parents</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="25">let</governor>
          <dependent id="23">wo</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="25">let</governor>
          <dependent id="24">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">go</governor>
          <dependent id="25">let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">go</governor>
          <dependent id="26">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">let</governor>
          <dependent id="27">go</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">go</governor>
          <dependent id="28">away</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Spitler" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Spitler" />
          </tokens>
        </entity>
        <entity id="2" string="dozen" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="dozen" />
          </tokens>
        </entity>
        <entity id="3" string="Gauna" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Gauna" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>They will live this case until the day they die.&amp;quot;</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="live" lemma="live" stem="live" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="die" lemma="die" stem="die" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (MD will) (VP (VB live) (NP (DT this) (NN case)) (PP (IN until) (NP (NP (DT the) (NN day)) (SBAR (S (NP (PRP they)) (VP (VBP die)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="they" type="NP">
          <tokens>
            <token id="9" string="they" />
          </tokens>
        </chunking>
        <chunking id="3" string="they die" type="SBAR">
          <tokens>
            <token id="9" string="they" />
            <token id="10" string="die" />
          </tokens>
        </chunking>
        <chunking id="4" string="the day" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="day" />
          </tokens>
        </chunking>
        <chunking id="5" string="this case" type="NP">
          <tokens>
            <token id="4" string="this" />
            <token id="5" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="live this case until the day they die" type="VP">
          <tokens>
            <token id="3" string="live" />
            <token id="4" string="this" />
            <token id="5" string="case" />
            <token id="6" string="until" />
            <token id="7" string="the" />
            <token id="8" string="day" />
            <token id="9" string="they" />
            <token id="10" string="die" />
          </tokens>
        </chunking>
        <chunking id="7" string="the day they die" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="day" />
            <token id="9" string="they" />
            <token id="10" string="die" />
          </tokens>
        </chunking>
        <chunking id="8" string="die" type="VP">
          <tokens>
            <token id="10" string="die" />
          </tokens>
        </chunking>
        <chunking id="9" string="will live this case until the day they die" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="live" />
            <token id="4" string="this" />
            <token id="5" string="case" />
            <token id="6" string="until" />
            <token id="7" string="the" />
            <token id="8" string="day" />
            <token id="9" string="they" />
            <token id="10" string="die" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">live</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">live</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">live</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">case</governor>
          <dependent id="4">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">live</governor>
          <dependent id="5">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">day</governor>
          <dependent id="6">until</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">day</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">live</governor>
          <dependent id="8">day</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">die</governor>
          <dependent id="9">they</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">day</governor>
          <dependent id="10">die</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the day" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="day" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>Meanwhile, already wending its way through court is a lawsuit filed by the early defendants.</content>
      <tokens>
        <token id="1" string="Meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="wending" lemma="wend" stem="wend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="lawsuit" lemma="lawsuit" stem="lawsuit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Meanwhile)) (, ,) (VP (ADVP (RB already)) (VBG wending) (NP (PRP$ its) (NN way)) (PP (IN through) (NP (NN court)))) (VP (VBZ is) (NP (NP (DT a) (NN lawsuit)) (VP (VBN filed) (PP (IN by) (NP (DT the) (JJ early) (NNS defendants)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a lawsuit filed by the early defendants" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="lawsuit" />
            <token id="12" string="filed" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="early" />
            <token id="16" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="2" string="a lawsuit" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="lawsuit" />
          </tokens>
        </chunking>
        <chunking id="3" string="the early defendants" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="early" />
            <token id="16" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="4" string="its way" type="NP">
          <tokens>
            <token id="5" string="its" />
            <token id="6" string="way" />
          </tokens>
        </chunking>
        <chunking id="5" string="already wending its way through court" type="VP">
          <tokens>
            <token id="3" string="already" />
            <token id="4" string="wending" />
            <token id="5" string="its" />
            <token id="6" string="way" />
            <token id="7" string="through" />
            <token id="8" string="court" />
          </tokens>
        </chunking>
        <chunking id="6" string="is a lawsuit filed by the early defendants" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="a" />
            <token id="11" string="lawsuit" />
            <token id="12" string="filed" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="early" />
            <token id="16" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="7" string="filed by the early defendants" type="VP">
          <tokens>
            <token id="12" string="filed" />
            <token id="13" string="by" />
            <token id="14" string="the" />
            <token id="15" string="early" />
            <token id="16" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="8" string="court" type="NP">
          <tokens>
            <token id="8" string="court" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">wending</governor>
          <dependent id="1">Meanwhile</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">wending</governor>
          <dependent id="3">already</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">wending</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">way</governor>
          <dependent id="5">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">wending</governor>
          <dependent id="6">way</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">court</governor>
          <dependent id="7">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">wending</governor>
          <dependent id="8">court</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">lawsuit</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">lawsuit</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">wending</governor>
          <dependent id="11">lawsuit</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">lawsuit</governor>
          <dependent id="12">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">defendants</governor>
          <dependent id="13">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">defendants</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">defendants</governor>
          <dependent id="15">early</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">filed</governor>
          <dependent id="16">defendants</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>Peggy Ann Buckey, Virginia McMartin, Spitler and Raidor are suing the television station, the reporter who broke the McMartin story and others.</content>
      <tokens>
        <token id="1" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Spitler" lemma="Spitler" stem="spitler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Raidor" lemma="Raidor" stem="raidor" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="suing" lemma="sue" stem="su" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="station" lemma="station" stem="station" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="reporter" lemma="reporter" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="broke" lemma="break" stem="broke" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="23" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Peggy) (NNP Ann) (NNP Buckey)) (, ,) (NP (NNP Virginia) (NNP McMartin)) (, ,) (NP (NNP Spitler)) (CC and) (NP (NNP Raidor))) (VP (VBP are) (VP (VBG suing) (NP (NP (DT the) (NN television) (NN station)) (, ,) (NP (NP (DT the) (NN reporter)) (SBAR (WHNP (WP who)) (S (VP (VBD broke) (NP (NP (DT the) (NNP McMartin) (NN story)) (CC and) (NP (NNS others)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Peggy Ann Buckey , Virginia McMartin , Spitler and Raidor" type="NP">
          <tokens>
            <token id="1" string="Peggy" />
            <token id="2" string="Ann" />
            <token id="3" string="Buckey" />
            <token id="4" string="," />
            <token id="5" string="Virginia" />
            <token id="6" string="McMartin" />
            <token id="7" string="," />
            <token id="8" string="Spitler" />
            <token id="9" string="and" />
            <token id="10" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="2" string="the television station , the reporter who broke the McMartin story and others" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="television" />
            <token id="15" string="station" />
            <token id="16" string="," />
            <token id="17" string="the" />
            <token id="18" string="reporter" />
            <token id="19" string="who" />
            <token id="20" string="broke" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="story" />
            <token id="24" string="and" />
            <token id="25" string="others" />
          </tokens>
        </chunking>
        <chunking id="3" string="the McMartin story and others" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="story" />
            <token id="24" string="and" />
            <token id="25" string="others" />
          </tokens>
        </chunking>
        <chunking id="4" string="Virginia McMartin" type="NP">
          <tokens>
            <token id="5" string="Virginia" />
            <token id="6" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="5" string="the McMartin story" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="story" />
          </tokens>
        </chunking>
        <chunking id="6" string="who broke the McMartin story and others" type="SBAR">
          <tokens>
            <token id="19" string="who" />
            <token id="20" string="broke" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="story" />
            <token id="24" string="and" />
            <token id="25" string="others" />
          </tokens>
        </chunking>
        <chunking id="7" string="are suing the television station , the reporter who broke the McMartin story and others" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="suing" />
            <token id="13" string="the" />
            <token id="14" string="television" />
            <token id="15" string="station" />
            <token id="16" string="," />
            <token id="17" string="the" />
            <token id="18" string="reporter" />
            <token id="19" string="who" />
            <token id="20" string="broke" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="story" />
            <token id="24" string="and" />
            <token id="25" string="others" />
          </tokens>
        </chunking>
        <chunking id="8" string="Spitler" type="NP">
          <tokens>
            <token id="8" string="Spitler" />
          </tokens>
        </chunking>
        <chunking id="9" string="the reporter who broke the McMartin story and others" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="reporter" />
            <token id="19" string="who" />
            <token id="20" string="broke" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="story" />
            <token id="24" string="and" />
            <token id="25" string="others" />
          </tokens>
        </chunking>
        <chunking id="10" string="suing the television station , the reporter who broke the McMartin story and others" type="VP">
          <tokens>
            <token id="12" string="suing" />
            <token id="13" string="the" />
            <token id="14" string="television" />
            <token id="15" string="station" />
            <token id="16" string="," />
            <token id="17" string="the" />
            <token id="18" string="reporter" />
            <token id="19" string="who" />
            <token id="20" string="broke" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="story" />
            <token id="24" string="and" />
            <token id="25" string="others" />
          </tokens>
        </chunking>
        <chunking id="11" string="the television station" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="television" />
            <token id="15" string="station" />
          </tokens>
        </chunking>
        <chunking id="12" string="Peggy Ann Buckey" type="NP">
          <tokens>
            <token id="1" string="Peggy" />
            <token id="2" string="Ann" />
            <token id="3" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="13" string="the reporter" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="reporter" />
          </tokens>
        </chunking>
        <chunking id="14" string="Raidor" type="NP">
          <tokens>
            <token id="10" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="15" string="broke the McMartin story and others" type="VP">
          <tokens>
            <token id="20" string="broke" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="story" />
            <token id="24" string="and" />
            <token id="25" string="others" />
          </tokens>
        </chunking>
        <chunking id="16" string="others" type="NP">
          <tokens>
            <token id="25" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Buckey</governor>
          <dependent id="1">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Buckey</governor>
          <dependent id="2">Ann</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">suing</governor>
          <dependent id="3">Buckey</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">McMartin</governor>
          <dependent id="5">Virginia</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Buckey</governor>
          <dependent id="6">McMartin</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Buckey</governor>
          <dependent id="8">Spitler</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">Buckey</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">Buckey</governor>
          <dependent id="10">Raidor</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">suing</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">suing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">station</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">station</governor>
          <dependent id="14">television</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">suing</governor>
          <dependent id="15">station</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">reporter</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">station</governor>
          <dependent id="18">reporter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">broke</governor>
          <dependent id="19">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">reporter</governor>
          <dependent id="20">broke</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">story</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">story</governor>
          <dependent id="22">McMartin</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">broke</governor>
          <dependent id="23">story</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">story</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">story</governor>
          <dependent id="25">others</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Spitler" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Spitler" />
          </tokens>
        </entity>
        <entity id="2" string="Peggy Ann Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Peggy" />
            <token id="2" string="Ann" />
            <token id="3" string="Buckey" />
          </tokens>
        </entity>
        <entity id="3" string="McMartin" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="McMartin" />
          </tokens>
        </entity>
        <entity id="4" string="Virginia McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Virginia" />
            <token id="6" string="McMartin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>The suit alleges that the station and reporter, Wayne Satz, were &amp;quot;creating rather than reporting the news.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="alleges" lemma="allege" stem="alleg" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="station" lemma="station" stem="station" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="reporter" lemma="reporter" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Wayne" lemma="Wayne" stem="wayn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="Satz" lemma="Satz" stem="satz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="creating" lemma="create" stem="creat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="reporting" lemma="report" stem="report" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN suit)) (VP (VBZ alleges) (SBAR (IN that) (S (NP (NP (DT the) (NN station) (CC and) (NN reporter)) (, ,) (NP (NNP Wayne) (NNP Satz)) (, ,)) (VP (VBD were) (`` ``) (VP (VBG creating) (PP (RB rather) (IN than) (S (VP (VBG reporting) (NP (DT the) (NN news)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the news" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="news" />
          </tokens>
        </chunking>
        <chunking id="2" string="alleges that the station and reporter , Wayne Satz , were `` creating rather than reporting the news" type="VP">
          <tokens>
            <token id="3" string="alleges" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="station" />
            <token id="7" string="and" />
            <token id="8" string="reporter" />
            <token id="9" string="," />
            <token id="10" string="Wayne" />
            <token id="11" string="Satz" />
            <token id="12" string="," />
            <token id="13" string="were" />
            <token id="14" string="&quot;" />
            <token id="15" string="creating" />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="reporting" />
            <token id="19" string="the" />
            <token id="20" string="news" />
          </tokens>
        </chunking>
        <chunking id="3" string="the station and reporter" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="station" />
            <token id="7" string="and" />
            <token id="8" string="reporter" />
          </tokens>
        </chunking>
        <chunking id="4" string="The suit" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="suit" />
          </tokens>
        </chunking>
        <chunking id="5" string="were `` creating rather than reporting the news" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="&quot;" />
            <token id="15" string="creating" />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="reporting" />
            <token id="19" string="the" />
            <token id="20" string="news" />
          </tokens>
        </chunking>
        <chunking id="6" string="creating rather than reporting the news" type="VP">
          <tokens>
            <token id="15" string="creating" />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="reporting" />
            <token id="19" string="the" />
            <token id="20" string="news" />
          </tokens>
        </chunking>
        <chunking id="7" string="that the station and reporter , Wayne Satz , were `` creating rather than reporting the news" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="station" />
            <token id="7" string="and" />
            <token id="8" string="reporter" />
            <token id="9" string="," />
            <token id="10" string="Wayne" />
            <token id="11" string="Satz" />
            <token id="12" string="," />
            <token id="13" string="were" />
            <token id="14" string="&quot;" />
            <token id="15" string="creating" />
            <token id="16" string="rather" />
            <token id="17" string="than" />
            <token id="18" string="reporting" />
            <token id="19" string="the" />
            <token id="20" string="news" />
          </tokens>
        </chunking>
        <chunking id="8" string="the station and reporter , Wayne Satz ," type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="station" />
            <token id="7" string="and" />
            <token id="8" string="reporter" />
            <token id="9" string="," />
            <token id="10" string="Wayne" />
            <token id="11" string="Satz" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="reporting the news" type="VP">
          <tokens>
            <token id="18" string="reporting" />
            <token id="19" string="the" />
            <token id="20" string="news" />
          </tokens>
        </chunking>
        <chunking id="10" string="Wayne Satz" type="NP">
          <tokens>
            <token id="10" string="Wayne" />
            <token id="11" string="Satz" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">suit</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">alleges</governor>
          <dependent id="2">suit</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">alleges</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">creating</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">station</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">creating</governor>
          <dependent id="6">station</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">station</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">station</governor>
          <dependent id="8">reporter</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Satz</governor>
          <dependent id="10">Wayne</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">station</governor>
          <dependent id="11">Satz</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">creating</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">alleges</governor>
          <dependent id="15">creating</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">reporting</governor>
          <dependent id="16">rather</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="16">rather</governor>
          <dependent id="17">than</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">creating</governor>
          <dependent id="18">reporting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">news</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">reporting</governor>
          <dependent id="20">news</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wayne Satz" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Wayne" />
            <token id="11" string="Satz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>A lower court held that the station, KABC, was protected from the action on constitutional grounds, but a state appellate court ruled the case should proceed to trial, and the state Supreme Court upheld that decision.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="lower" lemma="lower" stem="lower" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="held" lemma="hold" stem="held" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="station" lemma="station" stem="station" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="KABC" lemma="KABC" stem="kabc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="protected" lemma="protect" stem="protect" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="action" lemma="action" stem="action" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="constitutional" lemma="constitutional" stem="constitut" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="grounds" lemma="grounds" stem="ground" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="appellate" lemma="appellate" stem="appel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="ruled" lemma="rule" stem="rule" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="proceed" lemma="proceed" stem="proce" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="37" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="38" string="upheld" lemma="uphold" stem="upheld" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT A) (JJR lower) (NN court)) (VP (VBD held) (SBAR (IN that) (S (NP (NP (DT the) (NN station)) (, ,) (NP (NNP KABC)) (, ,)) (VP (VBD was) (VP (VBN protected) (PP (IN from) (NP (NP (DT the) (NN action)) (PP (IN on) (NP (JJ constitutional) (NNS grounds))))))))))) (, ,) (CC but) (S (S (NP (DT a) (NN state) (JJ appellate) (NN court)) (VP (VBD ruled) (SBAR (S (NP (DT the) (NN case)) (VP (MD should) (VP (VB proceed) (PP (TO to) (NP (NN trial))))))))) (, ,) (CC and) (S (NP (DT the) (NN state) (NNP Supreme) (NNP Court)) (VP (VBD upheld) (NP (DT that) (NN decision))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was protected from the action on constitutional grounds" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="protected" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="action" />
            <token id="16" string="on" />
            <token id="17" string="constitutional" />
            <token id="18" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="2" string="the action on constitutional grounds" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="action" />
            <token id="16" string="on" />
            <token id="17" string="constitutional" />
            <token id="18" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="3" string="the action" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="action" />
          </tokens>
        </chunking>
        <chunking id="4" string="the case" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="upheld that decision" type="VP">
          <tokens>
            <token id="38" string="upheld" />
            <token id="39" string="that" />
            <token id="40" string="decision" />
          </tokens>
        </chunking>
        <chunking id="6" string="that decision" type="NP">
          <tokens>
            <token id="39" string="that" />
            <token id="40" string="decision" />
          </tokens>
        </chunking>
        <chunking id="7" string="the station" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="station" />
          </tokens>
        </chunking>
        <chunking id="8" string="trial" type="NP">
          <tokens>
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="9" string="the state Supreme Court" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="state" />
            <token id="36" string="Supreme" />
            <token id="37" string="Court" />
          </tokens>
        </chunking>
        <chunking id="10" string="the station , KABC ," type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="station" />
            <token id="8" string="," />
            <token id="9" string="KABC" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="protected from the action on constitutional grounds" type="VP">
          <tokens>
            <token id="12" string="protected" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="action" />
            <token id="16" string="on" />
            <token id="17" string="constitutional" />
            <token id="18" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="12" string="that the station , KABC , was protected from the action on constitutional grounds" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="station" />
            <token id="8" string="," />
            <token id="9" string="KABC" />
            <token id="10" string="," />
            <token id="11" string="was" />
            <token id="12" string="protected" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="action" />
            <token id="16" string="on" />
            <token id="17" string="constitutional" />
            <token id="18" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="13" string="constitutional grounds" type="NP">
          <tokens>
            <token id="17" string="constitutional" />
            <token id="18" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="14" string="KABC" type="NP">
          <tokens>
            <token id="9" string="KABC" />
          </tokens>
        </chunking>
        <chunking id="15" string="A lower court" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="lower" />
            <token id="3" string="court" />
          </tokens>
        </chunking>
        <chunking id="16" string="held that the station , KABC , was protected from the action on constitutional grounds" type="VP">
          <tokens>
            <token id="4" string="held" />
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="station" />
            <token id="8" string="," />
            <token id="9" string="KABC" />
            <token id="10" string="," />
            <token id="11" string="was" />
            <token id="12" string="protected" />
            <token id="13" string="from" />
            <token id="14" string="the" />
            <token id="15" string="action" />
            <token id="16" string="on" />
            <token id="17" string="constitutional" />
            <token id="18" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="17" string="should proceed to trial" type="VP">
          <tokens>
            <token id="28" string="should" />
            <token id="29" string="proceed" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="18" string="ruled the case should proceed to trial" type="VP">
          <tokens>
            <token id="25" string="ruled" />
            <token id="26" string="the" />
            <token id="27" string="case" />
            <token id="28" string="should" />
            <token id="29" string="proceed" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="19" string="proceed to trial" type="VP">
          <tokens>
            <token id="29" string="proceed" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
        <chunking id="20" string="a state appellate court" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="state" />
            <token id="23" string="appellate" />
            <token id="24" string="court" />
          </tokens>
        </chunking>
        <chunking id="21" string="the case should proceed to trial" type="SBAR">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="case" />
            <token id="28" string="should" />
            <token id="29" string="proceed" />
            <token id="30" string="to" />
            <token id="31" string="trial" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">court</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">court</governor>
          <dependent id="2">lower</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">held</governor>
          <dependent id="3">court</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">held</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">protected</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">station</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">protected</governor>
          <dependent id="7">station</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">station</governor>
          <dependent id="9">KABC</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">protected</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">held</governor>
          <dependent id="12">protected</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">action</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">action</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">protected</governor>
          <dependent id="15">action</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">grounds</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">grounds</governor>
          <dependent id="17">constitutional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">action</governor>
          <dependent id="18">grounds</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">held</governor>
          <dependent id="20">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">court</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">court</governor>
          <dependent id="22">state</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">court</governor>
          <dependent id="23">appellate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">ruled</governor>
          <dependent id="24">court</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">held</governor>
          <dependent id="25">ruled</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">case</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">proceed</governor>
          <dependent id="27">case</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">proceed</governor>
          <dependent id="28">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">ruled</governor>
          <dependent id="29">proceed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">trial</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">proceed</governor>
          <dependent id="31">trial</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">ruled</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">Court</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Court</governor>
          <dependent id="35">state</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Court</governor>
          <dependent id="36">Supreme</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">upheld</governor>
          <dependent id="37">Court</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">ruled</governor>
          <dependent id="38">upheld</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">decision</governor>
          <dependent id="39">that</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">upheld</governor>
          <dependent id="40">decision</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Supreme Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="36" string="Supreme" />
            <token id="37" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="KABC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="KABC" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>The case, now in the early pretrial stages, is being watched closely, because it could set precedent in the field of press law, experts said.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="pretrial" lemma="pretrial" stem="pretrial" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="stages" lemma="stage" stem="stage" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="watched" lemma="watch" stem="watch" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="closely" lemma="closely" stem="close" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="set" lemma="set" stem="set" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="precedent" lemma="precedent" stem="preced" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="experts" lemma="expert" stem="expert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN case)) (, ,) (NP (NP (RB now)) (PP (IN in) (NP (DT the) (JJ early) (JJ pretrial) (NNS stages)))) (, ,)) (VP (VBZ is) (VP (VBG being) (VP (VBN watched) (ADVP (RB closely)) (, ,) (SBAR (IN because) (S (NP (PRP it)) (VP (MD could) (VP (VB set) (NP (NN precedent)) (PP (IN in) (NP (NP (DT the) (NN field)) (PP (IN of) (NP (NN press) (NN law))))))))))))) (, ,) (NP (NNS experts)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the early pretrial stages" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="early" />
            <token id="8" string="pretrial" />
            <token id="9" string="stages" />
          </tokens>
        </chunking>
        <chunking id="2" string="The case , now in the early pretrial stages ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="case" />
            <token id="3" string="," />
            <token id="4" string="now" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="early" />
            <token id="8" string="pretrial" />
            <token id="9" string="stages" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="the field of press law" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="field" />
            <token id="24" string="of" />
            <token id="25" string="press" />
            <token id="26" string="law" />
          </tokens>
        </chunking>
        <chunking id="4" string="watched closely , because it could set precedent in the field of press law" type="VP">
          <tokens>
            <token id="13" string="watched" />
            <token id="14" string="closely" />
            <token id="15" string="," />
            <token id="16" string="because" />
            <token id="17" string="it" />
            <token id="18" string="could" />
            <token id="19" string="set" />
            <token id="20" string="precedent" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="field" />
            <token id="24" string="of" />
            <token id="25" string="press" />
            <token id="26" string="law" />
          </tokens>
        </chunking>
        <chunking id="5" string="set precedent in the field of press law" type="VP">
          <tokens>
            <token id="19" string="set" />
            <token id="20" string="precedent" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="field" />
            <token id="24" string="of" />
            <token id="25" string="press" />
            <token id="26" string="law" />
          </tokens>
        </chunking>
        <chunking id="6" string="press law" type="NP">
          <tokens>
            <token id="25" string="press" />
            <token id="26" string="law" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="The case" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="case" />
          </tokens>
        </chunking>
        <chunking id="9" string="is being watched closely , because it could set precedent in the field of press law" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="being" />
            <token id="13" string="watched" />
            <token id="14" string="closely" />
            <token id="15" string="," />
            <token id="16" string="because" />
            <token id="17" string="it" />
            <token id="18" string="could" />
            <token id="19" string="set" />
            <token id="20" string="precedent" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="field" />
            <token id="24" string="of" />
            <token id="25" string="press" />
            <token id="26" string="law" />
          </tokens>
        </chunking>
        <chunking id="10" string="could set precedent in the field of press law" type="VP">
          <tokens>
            <token id="18" string="could" />
            <token id="19" string="set" />
            <token id="20" string="precedent" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="field" />
            <token id="24" string="of" />
            <token id="25" string="press" />
            <token id="26" string="law" />
          </tokens>
        </chunking>
        <chunking id="11" string="being watched closely , because it could set precedent in the field of press law" type="VP">
          <tokens>
            <token id="12" string="being" />
            <token id="13" string="watched" />
            <token id="14" string="closely" />
            <token id="15" string="," />
            <token id="16" string="because" />
            <token id="17" string="it" />
            <token id="18" string="could" />
            <token id="19" string="set" />
            <token id="20" string="precedent" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="field" />
            <token id="24" string="of" />
            <token id="25" string="press" />
            <token id="26" string="law" />
          </tokens>
        </chunking>
        <chunking id="12" string="the field" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="field" />
          </tokens>
        </chunking>
        <chunking id="13" string="precedent" type="NP">
          <tokens>
            <token id="20" string="precedent" />
          </tokens>
        </chunking>
        <chunking id="14" string="now" type="NP">
          <tokens>
            <token id="4" string="now" />
          </tokens>
        </chunking>
        <chunking id="15" string="because it could set precedent in the field of press law" type="SBAR">
          <tokens>
            <token id="16" string="because" />
            <token id="17" string="it" />
            <token id="18" string="could" />
            <token id="19" string="set" />
            <token id="20" string="precedent" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="field" />
            <token id="24" string="of" />
            <token id="25" string="press" />
            <token id="26" string="law" />
          </tokens>
        </chunking>
        <chunking id="16" string="experts" type="NP">
          <tokens>
            <token id="28" string="experts" />
          </tokens>
        </chunking>
        <chunking id="17" string="said" type="VP">
          <tokens>
            <token id="29" string="said" />
          </tokens>
        </chunking>
        <chunking id="18" string="now in the early pretrial stages" type="NP">
          <tokens>
            <token id="4" string="now" />
            <token id="5" string="in" />
            <token id="6" string="the" />
            <token id="7" string="early" />
            <token id="8" string="pretrial" />
            <token id="9" string="stages" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">case</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">watched</governor>
          <dependent id="2">case</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">case</governor>
          <dependent id="4">now</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">stages</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">stages</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">stages</governor>
          <dependent id="7">early</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">stages</governor>
          <dependent id="8">pretrial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">now</governor>
          <dependent id="9">stages</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">watched</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">watched</governor>
          <dependent id="12">being</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">said</governor>
          <dependent id="13">watched</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">watched</governor>
          <dependent id="14">closely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">set</governor>
          <dependent id="16">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">set</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">set</governor>
          <dependent id="18">could</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">watched</governor>
          <dependent id="19">set</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">set</governor>
          <dependent id="20">precedent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">field</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">field</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">set</governor>
          <dependent id="23">field</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">law</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">law</governor>
          <dependent id="25">press</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">field</governor>
          <dependent id="26">law</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">said</governor>
          <dependent id="28">experts</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>Another suit pits former McMartin defendants and the pre-school against their liability insurance carriers.</content>
      <tokens>
        <token id="1" string="Another" lemma="another" stem="another" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="suit" lemma="suit" stem="suit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="pits" lemma="pit" stem="pit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="pre-school" lemma="pre-school" stem="pre-school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="liability" lemma="liability" stem="liabil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="insurance" lemma="insurance" stem="insur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="carriers" lemma="carrier" stem="carrier" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (DT Another) (NN suit) (NNS pits)) (NP (NP (JJ former) (NNP McMartin) (NNS defendants)) (CC and) (NP (DT the) (NN pre-school))) (PP (IN against) (NP (PRP$ their) (NN liability) (NN insurance) (NNS carriers))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="former McMartin defendants and the pre-school" type="NP">
          <tokens>
            <token id="4" string="former" />
            <token id="5" string="McMartin" />
            <token id="6" string="defendants" />
            <token id="7" string="and" />
            <token id="8" string="the" />
            <token id="9" string="pre-school" />
          </tokens>
        </chunking>
        <chunking id="2" string="their liability insurance carriers" type="NP">
          <tokens>
            <token id="11" string="their" />
            <token id="12" string="liability" />
            <token id="13" string="insurance" />
            <token id="14" string="carriers" />
          </tokens>
        </chunking>
        <chunking id="3" string="Another suit pits former McMartin defendants and the pre-school against their liability insurance carriers ." type="NP">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="suit" />
            <token id="3" string="pits" />
            <token id="4" string="former" />
            <token id="5" string="McMartin" />
            <token id="6" string="defendants" />
            <token id="7" string="and" />
            <token id="8" string="the" />
            <token id="9" string="pre-school" />
            <token id="10" string="against" />
            <token id="11" string="their" />
            <token id="12" string="liability" />
            <token id="13" string="insurance" />
            <token id="14" string="carriers" />
            <token id="15" string="." />
          </tokens>
        </chunking>
        <chunking id="4" string="former McMartin defendants" type="NP">
          <tokens>
            <token id="4" string="former" />
            <token id="5" string="McMartin" />
            <token id="6" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="5" string="Another suit pits" type="NP">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="suit" />
            <token id="3" string="pits" />
          </tokens>
        </chunking>
        <chunking id="6" string="the pre-school" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="pre-school" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">pits</governor>
          <dependent id="1">Another</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">pits</governor>
          <dependent id="2">suit</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">pits</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">defendants</governor>
          <dependent id="4">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">defendants</governor>
          <dependent id="5">McMartin</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">pits</governor>
          <dependent id="6">defendants</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">defendants</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">pre-school</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">defendants</governor>
          <dependent id="9">pre-school</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">carriers</governor>
          <dependent id="10">against</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">carriers</governor>
          <dependent id="11">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">carriers</governor>
          <dependent id="12">liability</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">carriers</governor>
          <dependent id="13">insurance</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">pits</governor>
          <dependent id="14">carriers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McMartin" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="McMartin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>The McMartin side alleges that the insurance carriers were required by the policy to pay for their attorney bills.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="alleges" lemma="allege" stem="alleg" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="insurance" lemma="insurance" stem="insur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="carriers" lemma="carrier" stem="carrier" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="required" lemma="require" stem="requir" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="policy" lemma="policy" stem="polici" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="pay" lemma="pay" stem="pai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="bills" lemma="bill" stem="bill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP McMartin) (NN side)) (VP (VBZ alleges) (SBAR (IN that) (S (NP (DT the) (NN insurance) (NNS carriers)) (VP (VBD were) (VP (VBN required) (PP (IN by) (NP (DT the) (NN policy))) (S (VP (TO to) (VP (VB pay) (PP (IN for) (NP (PRP$ their) (NN attorney) (NNS bills))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the policy" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="policy" />
          </tokens>
        </chunking>
        <chunking id="2" string="that the insurance carriers were required by the policy to pay for their attorney bills" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="insurance" />
            <token id="8" string="carriers" />
            <token id="9" string="were" />
            <token id="10" string="required" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="policy" />
            <token id="14" string="to" />
            <token id="15" string="pay" />
            <token id="16" string="for" />
            <token id="17" string="their" />
            <token id="18" string="attorney" />
            <token id="19" string="bills" />
          </tokens>
        </chunking>
        <chunking id="3" string="the insurance carriers" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="insurance" />
            <token id="8" string="carriers" />
          </tokens>
        </chunking>
        <chunking id="4" string="The McMartin side" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="McMartin" />
            <token id="3" string="side" />
          </tokens>
        </chunking>
        <chunking id="5" string="pay for their attorney bills" type="VP">
          <tokens>
            <token id="15" string="pay" />
            <token id="16" string="for" />
            <token id="17" string="their" />
            <token id="18" string="attorney" />
            <token id="19" string="bills" />
          </tokens>
        </chunking>
        <chunking id="6" string="alleges that the insurance carriers were required by the policy to pay for their attorney bills" type="VP">
          <tokens>
            <token id="4" string="alleges" />
            <token id="5" string="that" />
            <token id="6" string="the" />
            <token id="7" string="insurance" />
            <token id="8" string="carriers" />
            <token id="9" string="were" />
            <token id="10" string="required" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="policy" />
            <token id="14" string="to" />
            <token id="15" string="pay" />
            <token id="16" string="for" />
            <token id="17" string="their" />
            <token id="18" string="attorney" />
            <token id="19" string="bills" />
          </tokens>
        </chunking>
        <chunking id="7" string="to pay for their attorney bills" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="pay" />
            <token id="16" string="for" />
            <token id="17" string="their" />
            <token id="18" string="attorney" />
            <token id="19" string="bills" />
          </tokens>
        </chunking>
        <chunking id="8" string="required by the policy to pay for their attorney bills" type="VP">
          <tokens>
            <token id="10" string="required" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="policy" />
            <token id="14" string="to" />
            <token id="15" string="pay" />
            <token id="16" string="for" />
            <token id="17" string="their" />
            <token id="18" string="attorney" />
            <token id="19" string="bills" />
          </tokens>
        </chunking>
        <chunking id="9" string="were required by the policy to pay for their attorney bills" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="required" />
            <token id="11" string="by" />
            <token id="12" string="the" />
            <token id="13" string="policy" />
            <token id="14" string="to" />
            <token id="15" string="pay" />
            <token id="16" string="for" />
            <token id="17" string="their" />
            <token id="18" string="attorney" />
            <token id="19" string="bills" />
          </tokens>
        </chunking>
        <chunking id="10" string="their attorney bills" type="NP">
          <tokens>
            <token id="17" string="their" />
            <token id="18" string="attorney" />
            <token id="19" string="bills" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">side</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">side</governor>
          <dependent id="2">McMartin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">alleges</governor>
          <dependent id="3">side</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">alleges</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">required</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">carriers</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">carriers</governor>
          <dependent id="7">insurance</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">required</governor>
          <dependent id="8">carriers</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">required</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">alleges</governor>
          <dependent id="10">required</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">policy</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">policy</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">required</governor>
          <dependent id="13">policy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">pay</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">required</governor>
          <dependent id="15">pay</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">bills</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">bills</governor>
          <dependent id="17">their</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">bills</governor>
          <dependent id="18">attorney</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">pay</governor>
          <dependent id="19">bills</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="59" has_coreference="true">
      <content>While the insurers have paid a portion of the defense costs, they contend the defendants should have used only one attorney.</content>
      <tokens>
        <token id="1" string="While" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="insurers" lemma="insurer" stem="insur" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="paid" lemma="pay" stem="paid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="portion" lemma="portion" stem="portion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="defense" lemma="defense" stem="defens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="costs" lemma="cost" stem="cost" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="contend" lemma="contend" stem="contend" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="used" lemma="use" stem="us" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN While) (S (NP (DT the) (NNS insurers)) (VP (VBP have) (VP (VBN paid) (NP (NP (DT a) (NN portion)) (PP (IN of) (NP (DT the) (NN defense) (NNS costs)))))))) (, ,) (NP (PRP they)) (VP (VBP contend) (SBAR (S (NP (DT the) (NNS defendants)) (VP (MD should) (VP (VB have) (VP (VBN used) (NP (RB only) (CD one) (NN attorney)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="should have used only one attorney" type="VP">
          <tokens>
            <token id="17" string="should" />
            <token id="18" string="have" />
            <token id="19" string="used" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="2" string="used only one attorney" type="VP">
          <tokens>
            <token id="19" string="used" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="3" string="While the insurers have paid a portion of the defense costs" type="SBAR">
          <tokens>
            <token id="1" string="While" />
            <token id="2" string="the" />
            <token id="3" string="insurers" />
            <token id="4" string="have" />
            <token id="5" string="paid" />
            <token id="6" string="a" />
            <token id="7" string="portion" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="defense" />
            <token id="11" string="costs" />
          </tokens>
        </chunking>
        <chunking id="4" string="contend the defendants should have used only one attorney" type="VP">
          <tokens>
            <token id="14" string="contend" />
            <token id="15" string="the" />
            <token id="16" string="defendants" />
            <token id="17" string="should" />
            <token id="18" string="have" />
            <token id="19" string="used" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="5" string="have used only one attorney" type="VP">
          <tokens>
            <token id="18" string="have" />
            <token id="19" string="used" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="6" string="they" type="NP">
          <tokens>
            <token id="13" string="they" />
          </tokens>
        </chunking>
        <chunking id="7" string="the insurers" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="insurers" />
          </tokens>
        </chunking>
        <chunking id="8" string="a portion" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="portion" />
          </tokens>
        </chunking>
        <chunking id="9" string="the defendants" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="10" string="only one attorney" type="NP">
          <tokens>
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="11" string="have paid a portion of the defense costs" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="paid" />
            <token id="6" string="a" />
            <token id="7" string="portion" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="defense" />
            <token id="11" string="costs" />
          </tokens>
        </chunking>
        <chunking id="12" string="a portion of the defense costs" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="portion" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="defense" />
            <token id="11" string="costs" />
          </tokens>
        </chunking>
        <chunking id="13" string="paid a portion of the defense costs" type="VP">
          <tokens>
            <token id="5" string="paid" />
            <token id="6" string="a" />
            <token id="7" string="portion" />
            <token id="8" string="of" />
            <token id="9" string="the" />
            <token id="10" string="defense" />
            <token id="11" string="costs" />
          </tokens>
        </chunking>
        <chunking id="14" string="the defense costs" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="defense" />
            <token id="11" string="costs" />
          </tokens>
        </chunking>
        <chunking id="15" string="the defendants should have used only one attorney" type="SBAR">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="defendants" />
            <token id="17" string="should" />
            <token id="18" string="have" />
            <token id="19" string="used" />
            <token id="20" string="only" />
            <token id="21" string="one" />
            <token id="22" string="attorney" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">paid</governor>
          <dependent id="1">While</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">insurers</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">paid</governor>
          <dependent id="3">insurers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">paid</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">contend</governor>
          <dependent id="5">paid</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">portion</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">paid</governor>
          <dependent id="7">portion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">costs</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">costs</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">costs</governor>
          <dependent id="10">defense</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">portion</governor>
          <dependent id="11">costs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">contend</governor>
          <dependent id="13">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">contend</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">defendants</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">used</governor>
          <dependent id="16">defendants</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">used</governor>
          <dependent id="17">should</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="19">used</governor>
          <dependent id="18">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">contend</governor>
          <dependent id="19">used</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">attorney</governor>
          <dependent id="20">only</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">attorney</governor>
          <dependent id="21">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">used</governor>
          <dependent id="22">attorney</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="60" has_coreference="true">
      <content>However, the defendants are arguing that because of possible conflicts of interest, each needed their own counsel.</content>
      <tokens>
        <token id="1" string="However" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="arguing" lemma="argue" stem="argu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="conflicts" lemma="conflict" stem="conflict" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="needed" lemma="need" stem="need" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="counsel" lemma="counsel" stem="counsel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB However)) (, ,) (NP (DT the) (NNS defendants)) (VP (VBP are) (VP (VBG arguing) (SBAR (IN that) (IN because) (S (PP (IN of) (NP (NP (JJ possible) (NNS conflicts)) (PP (IN of) (NP (NN interest))))) (, ,) (NP (DT each)) (VP (VBD needed) (NP (PRP$ their) (JJ own) (NN counsel))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are arguing that because of possible conflicts of interest , each needed their own counsel" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="arguing" />
            <token id="7" string="that" />
            <token id="8" string="because" />
            <token id="9" string="of" />
            <token id="10" string="possible" />
            <token id="11" string="conflicts" />
            <token id="12" string="of" />
            <token id="13" string="interest" />
            <token id="14" string="," />
            <token id="15" string="each" />
            <token id="16" string="needed" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="counsel" />
          </tokens>
        </chunking>
        <chunking id="2" string="that because of possible conflicts of interest , each needed their own counsel" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="because" />
            <token id="9" string="of" />
            <token id="10" string="possible" />
            <token id="11" string="conflicts" />
            <token id="12" string="of" />
            <token id="13" string="interest" />
            <token id="14" string="," />
            <token id="15" string="each" />
            <token id="16" string="needed" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="counsel" />
          </tokens>
        </chunking>
        <chunking id="3" string="arguing that because of possible conflicts of interest , each needed their own counsel" type="VP">
          <tokens>
            <token id="6" string="arguing" />
            <token id="7" string="that" />
            <token id="8" string="because" />
            <token id="9" string="of" />
            <token id="10" string="possible" />
            <token id="11" string="conflicts" />
            <token id="12" string="of" />
            <token id="13" string="interest" />
            <token id="14" string="," />
            <token id="15" string="each" />
            <token id="16" string="needed" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="counsel" />
          </tokens>
        </chunking>
        <chunking id="4" string="possible conflicts" type="NP">
          <tokens>
            <token id="10" string="possible" />
            <token id="11" string="conflicts" />
          </tokens>
        </chunking>
        <chunking id="5" string="interest" type="NP">
          <tokens>
            <token id="13" string="interest" />
          </tokens>
        </chunking>
        <chunking id="6" string="their own counsel" type="NP">
          <tokens>
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="counsel" />
          </tokens>
        </chunking>
        <chunking id="7" string="the defendants" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="8" string="possible conflicts of interest" type="NP">
          <tokens>
            <token id="10" string="possible" />
            <token id="11" string="conflicts" />
            <token id="12" string="of" />
            <token id="13" string="interest" />
          </tokens>
        </chunking>
        <chunking id="9" string="each" type="NP">
          <tokens>
            <token id="15" string="each" />
          </tokens>
        </chunking>
        <chunking id="10" string="needed their own counsel" type="VP">
          <tokens>
            <token id="16" string="needed" />
            <token id="17" string="their" />
            <token id="18" string="own" />
            <token id="19" string="counsel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">arguing</governor>
          <dependent id="1">However</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">defendants</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">arguing</governor>
          <dependent id="4">defendants</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">arguing</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">arguing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">needed</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">needed</governor>
          <dependent id="8">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">conflicts</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">conflicts</governor>
          <dependent id="10">possible</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">needed</governor>
          <dependent id="11">conflicts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">interest</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">conflicts</governor>
          <dependent id="13">interest</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">needed</governor>
          <dependent id="15">each</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">arguing</governor>
          <dependent id="16">needed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">counsel</governor>
          <dependent id="17">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">counsel</governor>
          <dependent id="18">own</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">needed</governor>
          <dependent id="19">counsel</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="61" has_coreference="false">
      <content>One of the former defendants, preschool teacher Maryann Jackson, settled out of court.</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="preschool" lemma="preschool" stem="preschool" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="teacher" lemma="teacher" stem="teacher" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Maryann" lemma="Maryann" stem="maryann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="settled" lemma="settle" stem="settl" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="court" lemma="court" stem="court" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (CD One)) (PP (IN of) (NP (NP (DT the) (JJ former) (NNS defendants)) (, ,) (NP (JJ preschool) (NN teacher) (NNP Maryann) (NNP Jackson)) (, ,)))) (VP (VBD settled) (PRT (IN out)) (PP (IN of) (NP (NN court)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="One of the former defendants , preschool teacher Maryann Jackson ," type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="former" />
            <token id="5" string="defendants" />
            <token id="6" string="," />
            <token id="7" string="preschool" />
            <token id="8" string="teacher" />
            <token id="9" string="Maryann" />
            <token id="10" string="Jackson" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="One" type="NP">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </chunking>
        <chunking id="3" string="settled out of court" type="VP">
          <tokens>
            <token id="12" string="settled" />
            <token id="13" string="out" />
            <token id="14" string="of" />
            <token id="15" string="court" />
          </tokens>
        </chunking>
        <chunking id="4" string="the former defendants" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="former" />
            <token id="5" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="5" string="the former defendants , preschool teacher Maryann Jackson ," type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="former" />
            <token id="5" string="defendants" />
            <token id="6" string="," />
            <token id="7" string="preschool" />
            <token id="8" string="teacher" />
            <token id="9" string="Maryann" />
            <token id="10" string="Jackson" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="preschool teacher Maryann Jackson" type="NP">
          <tokens>
            <token id="7" string="preschool" />
            <token id="8" string="teacher" />
            <token id="9" string="Maryann" />
            <token id="10" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="7" string="court" type="NP">
          <tokens>
            <token id="15" string="court" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="12">settled</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">defendants</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">defendants</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">defendants</governor>
          <dependent id="4">former</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">One</governor>
          <dependent id="5">defendants</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Jackson</governor>
          <dependent id="7">preschool</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Jackson</governor>
          <dependent id="8">teacher</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Jackson</governor>
          <dependent id="9">Maryann</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">defendants</governor>
          <dependent id="10">Jackson</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">settled</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">settled</governor>
          <dependent id="13">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">court</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">settled</governor>
          <dependent id="15">court</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="2" string="Maryann Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Maryann" />
            <token id="10" string="Jackson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="62" has_coreference="true">
      <content>As it becomes apparent that McMartin cases will stretch out for years to come, parents and the former criminal defendants alike are trying to resign themselves to the inevitability that the matter may be one they can never leave behind.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="becomes" lemma="become" stem="becom" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="apparent" lemma="apparent" stem="appar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="stretch" lemma="stretch" stem="stretch" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="alike" lemma="alike" stem="alik" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="resign" lemma="resign" stem="resign" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="inevitability" lemma="inevitability" stem="inevit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="37" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="leave" lemma="leave" stem="leav" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="behind" lemma="behind" stem="behind" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN As) (S (NP (PRP it)) (VP (VBZ becomes) (ADJP (JJ apparent)) (SBAR (IN that) (S (NP (NNP McMartin) (NNS cases)) (VP (MD will) (VP (VB stretch) (PRT (RP out)) (PP (IN for) (NP (NNS years))) (S (VP (TO to) (VP (VB come))))))))))) (, ,) (NP (NP (NNS parents)) (CC and) (NP (DT the) (JJ former) (JJ criminal) (NNS defendants))) (ADVP (RB alike)) (VP (VBP are) (VP (VBG trying) (S (VP (TO to) (VP (VB resign) (NP (PRP themselves)) (PP (TO to) (NP (DT the) (NN inevitability))) (SBAR (IN that) (S (NP (DT the) (NN matter)) (VP (MD may) (VP (VB be) (NP (NP (CD one)) (SBAR (S (NP (PRP they)) (VP (MD can) (ADVP (RB never)) (VP (VB leave) (ADVP (RB behind)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="becomes apparent that McMartin cases will stretch out for years to come" type="VP">
          <tokens>
            <token id="3" string="becomes" />
            <token id="4" string="apparent" />
            <token id="5" string="that" />
            <token id="6" string="McMartin" />
            <token id="7" string="cases" />
            <token id="8" string="will" />
            <token id="9" string="stretch" />
            <token id="10" string="out" />
            <token id="11" string="for" />
            <token id="12" string="years" />
            <token id="13" string="to" />
            <token id="14" string="come" />
          </tokens>
        </chunking>
        <chunking id="2" string="be one they can never leave behind" type="VP">
          <tokens>
            <token id="35" string="be" />
            <token id="36" string="one" />
            <token id="37" string="they" />
            <token id="38" string="can" />
            <token id="39" string="never" />
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="36" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="the former criminal defendants" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="former" />
            <token id="20" string="criminal" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="5" string="to come" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="come" />
          </tokens>
        </chunking>
        <chunking id="6" string="leave behind" type="VP">
          <tokens>
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="can never leave behind" type="VP">
          <tokens>
            <token id="38" string="can" />
            <token id="39" string="never" />
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="9" string="that McMartin cases will stretch out for years to come" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="McMartin" />
            <token id="7" string="cases" />
            <token id="8" string="will" />
            <token id="9" string="stretch" />
            <token id="10" string="out" />
            <token id="11" string="for" />
            <token id="12" string="years" />
            <token id="13" string="to" />
            <token id="14" string="come" />
          </tokens>
        </chunking>
        <chunking id="10" string="come" type="VP">
          <tokens>
            <token id="14" string="come" />
          </tokens>
        </chunking>
        <chunking id="11" string="apparent" type="ADJP">
          <tokens>
            <token id="4" string="apparent" />
          </tokens>
        </chunking>
        <chunking id="12" string="the inevitability" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="inevitability" />
          </tokens>
        </chunking>
        <chunking id="13" string="stretch out for years to come" type="VP">
          <tokens>
            <token id="9" string="stretch" />
            <token id="10" string="out" />
            <token id="11" string="for" />
            <token id="12" string="years" />
            <token id="13" string="to" />
            <token id="14" string="come" />
          </tokens>
        </chunking>
        <chunking id="14" string="one they can never leave behind" type="NP">
          <tokens>
            <token id="36" string="one" />
            <token id="37" string="they" />
            <token id="38" string="can" />
            <token id="39" string="never" />
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="15" string="are trying to resign themselves to the inevitability that the matter may be one they can never leave behind" type="VP">
          <tokens>
            <token id="23" string="are" />
            <token id="24" string="trying" />
            <token id="25" string="to" />
            <token id="26" string="resign" />
            <token id="27" string="themselves" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="inevitability" />
            <token id="31" string="that" />
            <token id="32" string="the" />
            <token id="33" string="matter" />
            <token id="34" string="may" />
            <token id="35" string="be" />
            <token id="36" string="one" />
            <token id="37" string="they" />
            <token id="38" string="can" />
            <token id="39" string="never" />
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="16" string="parents" type="NP">
          <tokens>
            <token id="16" string="parents" />
          </tokens>
        </chunking>
        <chunking id="17" string="McMartin cases" type="NP">
          <tokens>
            <token id="6" string="McMartin" />
            <token id="7" string="cases" />
          </tokens>
        </chunking>
        <chunking id="18" string="may be one they can never leave behind" type="VP">
          <tokens>
            <token id="34" string="may" />
            <token id="35" string="be" />
            <token id="36" string="one" />
            <token id="37" string="they" />
            <token id="38" string="can" />
            <token id="39" string="never" />
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="19" string="that the matter may be one they can never leave behind" type="SBAR">
          <tokens>
            <token id="31" string="that" />
            <token id="32" string="the" />
            <token id="33" string="matter" />
            <token id="34" string="may" />
            <token id="35" string="be" />
            <token id="36" string="one" />
            <token id="37" string="they" />
            <token id="38" string="can" />
            <token id="39" string="never" />
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="20" string="As it becomes apparent that McMartin cases will stretch out for years to come" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="it" />
            <token id="3" string="becomes" />
            <token id="4" string="apparent" />
            <token id="5" string="that" />
            <token id="6" string="McMartin" />
            <token id="7" string="cases" />
            <token id="8" string="will" />
            <token id="9" string="stretch" />
            <token id="10" string="out" />
            <token id="11" string="for" />
            <token id="12" string="years" />
            <token id="13" string="to" />
            <token id="14" string="come" />
          </tokens>
        </chunking>
        <chunking id="21" string="years" type="NP">
          <tokens>
            <token id="12" string="years" />
          </tokens>
        </chunking>
        <chunking id="22" string="resign themselves to the inevitability that the matter may be one they can never leave behind" type="VP">
          <tokens>
            <token id="26" string="resign" />
            <token id="27" string="themselves" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="inevitability" />
            <token id="31" string="that" />
            <token id="32" string="the" />
            <token id="33" string="matter" />
            <token id="34" string="may" />
            <token id="35" string="be" />
            <token id="36" string="one" />
            <token id="37" string="they" />
            <token id="38" string="can" />
            <token id="39" string="never" />
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="23" string="the matter" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="matter" />
          </tokens>
        </chunking>
        <chunking id="24" string="they can never leave behind" type="SBAR">
          <tokens>
            <token id="37" string="they" />
            <token id="38" string="can" />
            <token id="39" string="never" />
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="25" string="they" type="NP">
          <tokens>
            <token id="37" string="they" />
          </tokens>
        </chunking>
        <chunking id="26" string="themselves" type="NP">
          <tokens>
            <token id="27" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="27" string="trying to resign themselves to the inevitability that the matter may be one they can never leave behind" type="VP">
          <tokens>
            <token id="24" string="trying" />
            <token id="25" string="to" />
            <token id="26" string="resign" />
            <token id="27" string="themselves" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="inevitability" />
            <token id="31" string="that" />
            <token id="32" string="the" />
            <token id="33" string="matter" />
            <token id="34" string="may" />
            <token id="35" string="be" />
            <token id="36" string="one" />
            <token id="37" string="they" />
            <token id="38" string="can" />
            <token id="39" string="never" />
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="28" string="to resign themselves to the inevitability that the matter may be one they can never leave behind" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="resign" />
            <token id="27" string="themselves" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="inevitability" />
            <token id="31" string="that" />
            <token id="32" string="the" />
            <token id="33" string="matter" />
            <token id="34" string="may" />
            <token id="35" string="be" />
            <token id="36" string="one" />
            <token id="37" string="they" />
            <token id="38" string="can" />
            <token id="39" string="never" />
            <token id="40" string="leave" />
            <token id="41" string="behind" />
          </tokens>
        </chunking>
        <chunking id="29" string="will stretch out for years to come" type="VP">
          <tokens>
            <token id="8" string="will" />
            <token id="9" string="stretch" />
            <token id="10" string="out" />
            <token id="11" string="for" />
            <token id="12" string="years" />
            <token id="13" string="to" />
            <token id="14" string="come" />
          </tokens>
        </chunking>
        <chunking id="30" string="parents and the former criminal defendants" type="NP">
          <tokens>
            <token id="16" string="parents" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="former" />
            <token id="20" string="criminal" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">becomes</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">becomes</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="24">trying</governor>
          <dependent id="3">becomes</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">becomes</governor>
          <dependent id="4">apparent</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">stretch</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">cases</governor>
          <dependent id="6">McMartin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">stretch</governor>
          <dependent id="7">cases</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">stretch</governor>
          <dependent id="8">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">becomes</governor>
          <dependent id="9">stretch</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="9">stretch</governor>
          <dependent id="10">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">years</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">stretch</governor>
          <dependent id="12">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">come</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">stretch</governor>
          <dependent id="14">come</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">trying</governor>
          <dependent id="16">parents</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">parents</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">defendants</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">defendants</governor>
          <dependent id="19">former</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">defendants</governor>
          <dependent id="20">criminal</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">parents</governor>
          <dependent id="21">defendants</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">trying</governor>
          <dependent id="22">alike</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">trying</governor>
          <dependent id="23">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">resign</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">trying</governor>
          <dependent id="26">resign</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">resign</governor>
          <dependent id="27">themselves</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">inevitability</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">inevitability</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">resign</governor>
          <dependent id="30">inevitability</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">one</governor>
          <dependent id="31">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">matter</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">one</governor>
          <dependent id="33">matter</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">one</governor>
          <dependent id="34">may</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="36">one</governor>
          <dependent id="35">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">resign</governor>
          <dependent id="36">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">leave</governor>
          <dependent id="37">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="40">leave</governor>
          <dependent id="38">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="40">leave</governor>
          <dependent id="39">never</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="36">one</governor>
          <dependent id="40">leave</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="40">leave</governor>
          <dependent id="41">behind</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="36" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="63" has_coreference="true">
      <content>Soon, some of the children will be able to make their own legal decisions.</content>
      <tokens>
        <token id="1" string="Soon" lemma="soon" stem="soon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="decisions" lemma="decision" stem="decis" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Soon)) (, ,) (NP (NP (DT some)) (PP (IN of) (NP (DT the) (NNS children)))) (VP (MD will) (VP (VB be) (ADJP (JJ able) (S (VP (TO to) (VP (VB make) (NP (PRP$ their) (JJ own) (JJ legal) (NNS decisions)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be able to make their own legal decisions" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="able" />
            <token id="10" string="to" />
            <token id="11" string="make" />
            <token id="12" string="their" />
            <token id="13" string="own" />
            <token id="14" string="legal" />
            <token id="15" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="2" string="will be able to make their own legal decisions" type="VP">
          <tokens>
            <token id="7" string="will" />
            <token id="8" string="be" />
            <token id="9" string="able" />
            <token id="10" string="to" />
            <token id="11" string="make" />
            <token id="12" string="their" />
            <token id="13" string="own" />
            <token id="14" string="legal" />
            <token id="15" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="3" string="the children" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="children" />
          </tokens>
        </chunking>
        <chunking id="4" string="to make their own legal decisions" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="make" />
            <token id="12" string="their" />
            <token id="13" string="own" />
            <token id="14" string="legal" />
            <token id="15" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="5" string="some of the children" type="NP">
          <tokens>
            <token id="3" string="some" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="some" type="NP">
          <tokens>
            <token id="3" string="some" />
          </tokens>
        </chunking>
        <chunking id="7" string="able to make their own legal decisions" type="ADJP">
          <tokens>
            <token id="9" string="able" />
            <token id="10" string="to" />
            <token id="11" string="make" />
            <token id="12" string="their" />
            <token id="13" string="own" />
            <token id="14" string="legal" />
            <token id="15" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="8" string="make their own legal decisions" type="VP">
          <tokens>
            <token id="11" string="make" />
            <token id="12" string="their" />
            <token id="13" string="own" />
            <token id="14" string="legal" />
            <token id="15" string="decisions" />
          </tokens>
        </chunking>
        <chunking id="9" string="their own legal decisions" type="NP">
          <tokens>
            <token id="12" string="their" />
            <token id="13" string="own" />
            <token id="14" string="legal" />
            <token id="15" string="decisions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="9">able</governor>
          <dependent id="1">Soon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">able</governor>
          <dependent id="3">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">children</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">children</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">some</governor>
          <dependent id="6">children</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">able</governor>
          <dependent id="7">will</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">able</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">make</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">able</governor>
          <dependent id="11">make</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">decisions</governor>
          <dependent id="12">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">decisions</governor>
          <dependent id="13">own</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">decisions</governor>
          <dependent id="14">legal</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">make</governor>
          <dependent id="15">decisions</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="64" has_coreference="true">
      <content>Noted one parent: &amp;quot;It&amp;apost;s really not our decision as parents anymore.</content>
      <tokens>
        <token id="1" string="Noted" lemma="note" stem="note" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="parent" lemma="parent" stem="parent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="anymore" lemma="anymore" stem="anymor" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Noted) (NP (CD one) (NN parent)))) (: :) (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (VP (ADVP (RB really)) (RB not) (NP (PRP$ our) (NN decision)) (PP (IN as) (NP (NP (NNS parents)) (ADVP (RB anymore))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'s really not our decision as parents anymore" type="VP">
          <tokens>
            <token id="7" string="'s" />
            <token id="8" string="really" />
            <token id="9" string="not" />
            <token id="10" string="our" />
            <token id="11" string="decision" />
            <token id="12" string="as" />
            <token id="13" string="parents" />
            <token id="14" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="2" string="Noted one parent" type="VP">
          <tokens>
            <token id="1" string="Noted" />
            <token id="2" string="one" />
            <token id="3" string="parent" />
          </tokens>
        </chunking>
        <chunking id="3" string="really not our decision as parents anymore" type="VP">
          <tokens>
            <token id="8" string="really" />
            <token id="9" string="not" />
            <token id="10" string="our" />
            <token id="11" string="decision" />
            <token id="12" string="as" />
            <token id="13" string="parents" />
            <token id="14" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="4" string="our decision" type="NP">
          <tokens>
            <token id="10" string="our" />
            <token id="11" string="decision" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="6" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="one parent" type="NP">
          <tokens>
            <token id="2" string="one" />
            <token id="3" string="parent" />
          </tokens>
        </chunking>
        <chunking id="7" string="parents anymore" type="NP">
          <tokens>
            <token id="13" string="parents" />
            <token id="14" string="anymore" />
          </tokens>
        </chunking>
        <chunking id="8" string="parents" type="NP">
          <tokens>
            <token id="13" string="parents" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Noted</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">parent</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Noted</governor>
          <dependent id="3">parent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">decision</governor>
          <dependent id="6">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">decision</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">decision</governor>
          <dependent id="8">really</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">decision</governor>
          <dependent id="9">not</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">decision</governor>
          <dependent id="10">our</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">Noted</governor>
          <dependent id="11">decision</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">parents</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">decision</governor>
          <dependent id="13">parents</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">parents</governor>
          <dependent id="14">anymore</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="65" has_coreference="true">
      <content>These children will soon be adults.&amp;quot;</content>
      <tokens>
        <token id="1" string="These" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="soon" lemma="soon" stem="soon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="adults" lemma="adult" stem="adult" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT These) (NNS children)) (VP (MD will) (ADVP (RB soon)) (VP (VB be) (NP (NNS adults)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="adults" type="NP">
          <tokens>
            <token id="6" string="adults" />
          </tokens>
        </chunking>
        <chunking id="2" string="be adults" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="adults" />
          </tokens>
        </chunking>
        <chunking id="3" string="will soon be adults" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="soon" />
            <token id="5" string="be" />
            <token id="6" string="adults" />
          </tokens>
        </chunking>
        <chunking id="4" string="These children" type="NP">
          <tokens>
            <token id="1" string="These" />
            <token id="2" string="children" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">children</governor>
          <dependent id="1">These</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">adults</governor>
          <dependent id="2">children</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">adults</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">adults</governor>
          <dependent id="4">soon</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">adults</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">adults</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="4-5" string="McMartin Pre-School" id_sentence="1" />
      <mentions>
        <mention ids_tokens="17-18" string="the pre-school" id_sentence="5" />
        <mention ids_tokens="8-9" string="the pre-school" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7" string="the historic McMartin Pre-School criminal trial" id_sentence="1" />
      <mentions>
        <mention ids_tokens="15-17" string="the criminal trial" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="8-9-10" string="the civil lawsuits" id_sentence="24" />
      <mentions>
        <mention ids_tokens="17-25" string="civil lawsuits generated by the Manhattan Beach molestation case" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="21-22-23-24-25" string="the Manhattan Beach molestation case" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="6" />
        <mention ids_tokens="5-6" string="this case" id_sentence="6" />
        <mention ids_tokens="4-5" string="this case" id_sentence="51" />
        <mention ids_tokens="5" string="its" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="38-39" string="legal experts" id_sentence="1" />
      <mentions>
        <mention ids_tokens="28" string="experts" id_sentence="56" />
        <mention ids_tokens="11" string="their" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="11-12-13-14-15-16-17-18" string="Peggy McMartin Buckey against her accusers and others" id_sentence="3" />
      <mentions>
        <mention ids_tokens="24-26" string="Peggy McMartin Buckey" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="the former defendants" id_sentence="34" />
      <mentions>
        <mention ids_tokens="24-33" string="former defendants against a television station and reporter and suits" id_sentence="3" />
        <mention ids_tokens="1" string="Defendants" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="40-41-42-43" string="their liability insurance carriers" id_sentence="3" />
      <mentions>
        <mention ids_tokens="6-8" string="the insurance carriers" id_sentence="58" />
        <mention ids_tokens="17" string="their" id_sentence="58" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="3-4" string="Ray Buckey" id_sentence="4" />
      <mentions>
        <mention ids_tokens="22" string="his" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9" string="several parents of McMartin attendees" id_sentence="5" />
      <mentions>
        <mention ids_tokens="1-2" string="The parents" id_sentence="29" />
        <mention ids_tokens="8" string="their" id_sentence="29" />
        <mention ids_tokens="1-2" string="The parents" id_sentence="42" />
        <mention ids_tokens="16" string="they" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="2-3" string="those lawsuits" id_sentence="20" />
      <mentions>
        <mention ids_tokens="15-18" string="lawsuits against the pre-school" id_sentence="5" />
        <mention ids_tokens="7" string="lawsuits" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="25-26" string="the children" id_sentence="5" />
      <mentions>
        <mention ids_tokens="9-11" string="the children's" id_sentence="20" />
        <mention ids_tokens="17" string="their" id_sentence="22" />
        <mention ids_tokens="26" string="their" id_sentence="22" />
        <mention ids_tokens="3-7" string="the children who attended McMartin" id_sentence="31" />
        <mention ids_tokens="1-2" string="These children" id_sentence="65" />
        <mention ids_tokens="6" string="adults" id_sentence="65" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="12-13" string="Eli Gauna" id_sentence="6" />
      <mentions>
        <mention ids_tokens="16" string="Gauna" id_sentence="34" />
        <mention ids_tokens="1-5" string="Gauna , Spitler's attorney" id_sentence="50" />
        <mention ids_tokens="1" string="Gauna" id_sentence="50" />
        <mention ids_tokens="3-5" string="Spitler's attorney" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="17-18" string="Babette Spitler" id_sentence="6" />
      <mentions>
        <mention ids_tokens="28" string="Spitler" id_sentence="15" />
        <mention ids_tokens="3-4" string="Spitler's" id_sentence="50" />
        <mention ids_tokens="8" string="Spitler" id_sentence="53" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="24-25" string="the school" id_sentence="6" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="The criminal case" id_sentence="12" />
      <mentions>
        <mention ids_tokens="2-23" string="the criminal case -- the longest and costliest criminal proceeding in U.S. history -- Ray Buckey , 31 , and his mother" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="20-21" string="the 13" id_sentence="25" />
      <mentions>
        <mention ids_tokens="5" string="13" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="9-10" string="those charges" id_sentence="10" />
      <mentions>
        <mention ids_tokens="5" string="charges" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="28" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5" string="an 18-month preliminary hearing" id_sentence="14" />
      <mentions>
        <mention ids_tokens="5-6" string="the hearing" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="31" type="PROPER">
      <referenced ids_tokens="30-31" string="Betty Raidor" id_sentence="15" />
      <mentions>
        <mention ids_tokens="10" string="Raidor" id_sentence="53" />
      </mentions>
    </coreference>
    <coreference id="32" type="LIST">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10" string="Peggy Ann Buckey , Virginia McMartin , Spitler and Raidor" id_sentence="53" />
      <mentions>
        <mention ids_tokens="3-35" string="Buckey ; his mother ; his grandmother , Virginia McMartin , who was the school founder ; his sister Peggy Ann Buckey ; and teachers Spitler , Betty Raidor and Mary Ann Jackson" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="34" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15-16-17-18-19-20-21" string="22 families seeking monetary damages against the school for medical bills" id_sentence="19" />
      <mentions>
        <mention ids_tokens="6" string="families" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="35" type="NOMINAL">
      <referenced ids_tokens="14-15" string="monetary damages" id_sentence="19" />
      <mentions>
        <mention ids_tokens="6" string="damages" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12-13" string="the children 's psychiatric histories" id_sentence="20" />
      <mentions>
        <mention ids_tokens="26-28" string="their psychiatric histories" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="34-35" string="the evidence" id_sentence="36" />
      <mentions>
        <mention ids_tokens="18-22" string="evidence in the criminal case" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="38" type="PROPER">
      <referenced ids_tokens="1-2" string="Greg Mooney" id_sentence="21" />
      <mentions>
        <mention ids_tokens="20" string="Mooney" id_sentence="23" />
        <mention ids_tokens="1" string="He" id_sentence="24" />
        <mention ids_tokens="1" string="Mooney" id_sentence="25" />
        <mention ids_tokens="16" string="Mooney" id_sentence="26" />
        <mention ids_tokens="1" string="Mooney" id_sentence="35" />
        <mention ids_tokens="3" string="he" id_sentence="35" />
        <mention ids_tokens="1" string="He" id_sentence="36" />
        <mention ids_tokens="21" string="Mooney" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="21-22" string="defense attorneys" id_sentence="21" />
      <mentions>
        <mention ids_tokens="5" string="they" id_sentence="22" />
        <mention ids_tokens="8" string="they" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="40" type="NOMINAL">
      <referenced ids_tokens="25-26-27-28-29-30" string="psychiatric records of the alleged victims" id_sentence="21" />
      <mentions>
        <mention ids_tokens="10-11" string="the records" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="41" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="The civil suits" id_sentence="23" />
      <mentions>
        <mention ids_tokens="22-32" string="civil suits in which their psychiatric histories would be at issue" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="42" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8" string="a decision on whether to refile" id_sentence="25" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="43" type="NOMINAL">
      <referenced ids_tokens="16-17-18-19-20-21-22-23-24-25-26-27" string="limitations -- the deadline in which a lawsuit can be filed --" id_sentence="29" />
      <mentions>
        <mention ids_tokens="10" string="limitations" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="46" type="PROPER">
      <referenced ids_tokens="27-28" string="8 years" id_sentence="31" />
      <mentions>
        <mention ids_tokens="34" string="years" id_sentence="33" />
        <mention ids_tokens="12" string="years" id_sentence="62" />
      </mentions>
    </coreference>
    <coreference id="48" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5" string="the so-called delayed-discovery theory" id_sentence="33" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="34" />
        <mention ids_tokens="4-11" string="a possibility that hangs over the former defendants" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="49" type="NOMINAL">
      <referenced ids_tokens="22-23-24-25-26-27-28-29-30-31-32-33-34" string="California court decision that set aside the statute of limitations for certain victims" id_sentence="34" />
      <mentions>
        <mention ids_tokens="39-40" string="that decision" id_sentence="55" />
        <mention ids_tokens="10-11" string="our decision" id_sentence="64" />
      </mentions>
    </coreference>
    <coreference id="50" type="NOMINAL">
      <referenced ids_tokens="4-5" string="some families" id_sentence="36" />
      <mentions>
        <mention ids_tokens="2-3" string="the families" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="52" type="NOMINAL">
      <referenced ids_tokens="2-3" string="some families" id_sentence="40" />
      <mentions>
        <mention ids_tokens="16" string="us" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="53" type="NOMINAL">
      <referenced ids_tokens="11" string="'s" id_sentence="43" />
      <mentions>
        <mention ids_tokens="10" string="they" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="54" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22" string="others that maybe they should pick up the civil case where the criminal case left off" id_sentence="44" />
      <mentions>
        <mention ids_tokens="2" string="They" id_sentence="45" />
        <mention ids_tokens="7" string="they" id_sentence="45" />
        <mention ids_tokens="9" string="they" id_sentence="45" />
        <mention ids_tokens="1" string="They" id_sentence="46" />
        <mention ids_tokens="28" string="we" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="56" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6" string="McMartin attendee 's parent" id_sentence="47" />
      <mentions>
        <mention ids_tokens="11-12" string="the parent" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="57" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="such a suit" id_sentence="49" />
      <mentions>
        <mention ids_tokens="1-2" string="The suit" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="59" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22" string="a dozen hard-line parents" id_sentence="50" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="51" />
        <mention ids_tokens="9" string="they" id_sentence="51" />
        <mention ids_tokens="16" string="parents" id_sentence="62" />
        <mention ids_tokens="27" string="themselves" id_sentence="62" />
        <mention ids_tokens="37" string="they" id_sentence="62" />
        <mention ids_tokens="13-14" string="parents anymore" id_sentence="64" />
      </mentions>
    </coreference>
    <coreference id="60" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16-17-18-19-20-21-22-23-24-25" string="the television station , the reporter who broke the McMartin story and others" id_sentence="53" />
      <mentions>
        <mention ids_tokens="5-8" string="the station and reporter" id_sentence="54" />
      </mentions>
    </coreference>
    <coreference id="62" type="PROPER">
      <referenced ids_tokens="4-5-6-7-8-9" string="now in the early pretrial stages" id_sentence="56" />
      <mentions>
        <mention ids_tokens="26-27" string="the case" id_sentence="55" />
      </mentions>
    </coreference>
    <coreference id="63" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="former McMartin defendants" id_sentence="57" />
      <mentions>
        <mention ids_tokens="15-16" string="the defendants" id_sentence="59" />
        <mention ids_tokens="3-4" string="the defendants" id_sentence="60" />
      </mentions>
    </coreference>
    <coreference id="66" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6" string="some of the children" id_sentence="63" />
      <mentions>
        <mention ids_tokens="10" string="our" id_sentence="64" />
      </mentions>
    </coreference>
  </coreferences>
</document>
