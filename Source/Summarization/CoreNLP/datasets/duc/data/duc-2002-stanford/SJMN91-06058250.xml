<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="SJMN91-06058250">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>ON A recent day, the telephone rang in the home of William Wegman.</content>
      <tokens>
        <token id="1" string="ON" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="telephone" lemma="telephone" stem="telephon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="rang" lemma="ring" stem="rang" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="14" string="Wegman" lemma="Wegman" stem="wegman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN ON) (NP (DT A) (JJ recent) (NN day))) (, ,) (NP (DT the) (NN telephone)) (VP (VBD rang) (PP (IN in) (NP (NP (DT the) (NN home)) (PP (IN of) (NP (NNP William) (NNP Wegman)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the home of William Wegman" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="home" />
            <token id="12" string="of" />
            <token id="13" string="William" />
            <token id="14" string="Wegman" />
          </tokens>
        </chunking>
        <chunking id="2" string="the home" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="home" />
          </tokens>
        </chunking>
        <chunking id="3" string="A recent day" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="recent" />
            <token id="4" string="day" />
          </tokens>
        </chunking>
        <chunking id="4" string="the telephone" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="telephone" />
          </tokens>
        </chunking>
        <chunking id="5" string="William Wegman" type="NP">
          <tokens>
            <token id="13" string="William" />
            <token id="14" string="Wegman" />
          </tokens>
        </chunking>
        <chunking id="6" string="rang in the home of William Wegman" type="VP">
          <tokens>
            <token id="8" string="rang" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="home" />
            <token id="12" string="of" />
            <token id="13" string="William" />
            <token id="14" string="Wegman" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">day</governor>
          <dependent id="1">ON</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">day</governor>
          <dependent id="2">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">day</governor>
          <dependent id="3">recent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">rang</governor>
          <dependent id="4">day</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">telephone</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">rang</governor>
          <dependent id="7">telephone</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">rang</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">home</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">home</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">rang</governor>
          <dependent id="11">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Wegman</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Wegman</governor>
          <dependent id="13">William</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">home</governor>
          <dependent id="14">Wegman</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="recent day" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="recent" />
            <token id="4" string="day" />
          </tokens>
        </entity>
        <entity id="2" string="William Wegman" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="William" />
            <token id="14" string="Wegman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>The photographer, known for his hilarious portraits of his Weimaraners, picked up &amp;quot;Hello.&amp;quot;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="photographer" lemma="photographer" stem="photograph" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="hilarious" lemma="hilarious" stem="hilari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="portraits" lemma="portrait" stem="portrait" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="Weimaraners" lemma="weimaraner" stem="weimaran" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="picked" lemma="pick" stem="pick" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Hello" lemma="hello" stem="hello" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (DT The) (NNP photographer)) (, ,) (VP (VBN known) (PP (IN for) (NP (NP (PRP$ his) (JJ hilarious) (NNS portraits)) (PP (IN of) (NP (NP (PRP$ his) (NNS Weimaraners)) (SBAR (FRAG (PRN (, ,) (S (VP (VBD picked) (PRT (RP up))))) (`` ``) (INTJ (UH Hello)) (. .))))) ('' '')))))))</syntactictree>
      <chunkings>
        <chunking id="1" string=", picked up `` Hello ." type="SBAR">
          <tokens>
            <token id="12" string="," />
            <token id="13" string="picked" />
            <token id="14" string="up" />
            <token id="15" string="&quot;" />
            <token id="16" string="Hello" />
            <token id="17" string="." />
          </tokens>
        </chunking>
        <chunking id="2" string="picked up" type="VP">
          <tokens>
            <token id="13" string="picked" />
            <token id="14" string="up" />
          </tokens>
        </chunking>
        <chunking id="3" string="The photographer" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="photographer" />
          </tokens>
        </chunking>
        <chunking id="4" string="his hilarious portraits of his Weimaraners , picked up `` Hello . ''" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="hilarious" />
            <token id="8" string="portraits" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="Weimaraners" />
            <token id="12" string="," />
            <token id="13" string="picked" />
            <token id="14" string="up" />
            <token id="15" string="&quot;" />
            <token id="16" string="Hello" />
            <token id="17" string="." />
            <token id="18" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="The photographer , known for his hilarious portraits of his Weimaraners , picked up `` Hello . ''" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="photographer" />
            <token id="3" string="," />
            <token id="4" string="known" />
            <token id="5" string="for" />
            <token id="6" string="his" />
            <token id="7" string="hilarious" />
            <token id="8" string="portraits" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="Weimaraners" />
            <token id="12" string="," />
            <token id="13" string="picked" />
            <token id="14" string="up" />
            <token id="15" string="&quot;" />
            <token id="16" string="Hello" />
            <token id="17" string="." />
            <token id="18" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="6" string="his Weimaraners" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="Weimaraners" />
          </tokens>
        </chunking>
        <chunking id="7" string="known for his hilarious portraits of his Weimaraners , picked up `` Hello . ''" type="VP">
          <tokens>
            <token id="4" string="known" />
            <token id="5" string="for" />
            <token id="6" string="his" />
            <token id="7" string="hilarious" />
            <token id="8" string="portraits" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="Weimaraners" />
            <token id="12" string="," />
            <token id="13" string="picked" />
            <token id="14" string="up" />
            <token id="15" string="&quot;" />
            <token id="16" string="Hello" />
            <token id="17" string="." />
            <token id="18" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="8" string="his hilarious portraits" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="hilarious" />
            <token id="8" string="portraits" />
          </tokens>
        </chunking>
        <chunking id="9" string="his Weimaraners , picked up `` Hello ." type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="Weimaraners" />
            <token id="12" string="," />
            <token id="13" string="picked" />
            <token id="14" string="up" />
            <token id="15" string="&quot;" />
            <token id="16" string="Hello" />
            <token id="17" string="." />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">photographer</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">photographer</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">photographer</governor>
          <dependent id="4">known</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">portraits</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">portraits</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">portraits</governor>
          <dependent id="7">hilarious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">known</governor>
          <dependent id="8">portraits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Weimaraners</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">Weimaraners</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">portraits</governor>
          <dependent id="11">Weimaraners</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">Weimaraners</governor>
          <dependent id="13">picked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="13">picked</governor>
          <dependent id="14">up</dependent>
        </dependency>
        <dependency type="discourse">
          <governor id="13">picked</governor>
          <dependent id="16">Hello</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Woof In this house, man and dogs speak as one.</content>
      <tokens>
        <token id="1" string="Woof" lemma="woof" stem="woof" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="dogs" lemma="dog" stem="dog" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="speak" lemma="speak" stem="speak" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADJP (JJ Woof)) (PP (IN In) (NP (DT this) (NN house)))) (, ,) (NP (NN man) (CC and) (NNS dogs)) (VP (VBP speak) (PP (IN as) (NP (CD one)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one" type="NP">
          <tokens>
            <token id="11" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="speak as one" type="VP">
          <tokens>
            <token id="9" string="speak" />
            <token id="10" string="as" />
            <token id="11" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="Woof" type="ADJP">
          <tokens>
            <token id="1" string="Woof" />
          </tokens>
        </chunking>
        <chunking id="4" string="this house" type="NP">
          <tokens>
            <token id="3" string="this" />
            <token id="4" string="house" />
          </tokens>
        </chunking>
        <chunking id="5" string="man and dogs" type="NP">
          <tokens>
            <token id="6" string="man" />
            <token id="7" string="and" />
            <token id="8" string="dogs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="ccomp">
          <governor id="9">speak</governor>
          <dependent id="1">Woof</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">house</governor>
          <dependent id="2">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">house</governor>
          <dependent id="3">this</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Woof</governor>
          <dependent id="4">house</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">speak</governor>
          <dependent id="6">man</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">man</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">man</governor>
          <dependent id="8">dogs</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">speak</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">one</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">speak</governor>
          <dependent id="11">one</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Their relationship is unusually tender.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="relationship" lemma="relationship" stem="relationship" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="unusually" lemma="unusually" stem="unusu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="tender" lemma="tender" stem="tender" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Their) (NN relationship)) (VP (VBZ is) (NP (RB unusually) (NN tender))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="unusually tender" type="NP">
          <tokens>
            <token id="4" string="unusually" />
            <token id="5" string="tender" />
          </tokens>
        </chunking>
        <chunking id="2" string="Their relationship" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="relationship" />
          </tokens>
        </chunking>
        <chunking id="3" string="is unusually tender" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="unusually" />
            <token id="5" string="tender" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">relationship</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">tender</governor>
          <dependent id="2">relationship</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">tender</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">tender</governor>
          <dependent id="4">unusually</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">tender</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>One need only listen while Wegman murmurs to Fay Ray and Battina, her 1 1/2-year-old daughter On Valentine&amp;apost;s Day, for example, he said, &amp;quot;I&amp;apost;ll take them out and play with them longer.&amp;quot;</content>
      <tokens>
        <token id="1" string="One" lemma="one" stem="one" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="need" lemma="need" stem="need" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="listen" lemma="listen" stem="listen" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Wegman" lemma="Wegman" stem="wegman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="murmurs" lemma="murmur" stem="murmur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Fay" lemma="Fay" stem="fai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Battina" lemma="Battina" stem="battina" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="1 1/2" lemma="1 1/2" stem="1 1/2" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="16" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="17" string="year-old" lemma="year-old" stem="year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="18" string="daughter" lemma="daughter" stem="daughter" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Valentine" lemma="Valentine" stem="valentin" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="21" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="22" string="Day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="play" lemma="play" stem="plai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="40" string="longer" lemma="longer" stem="longer" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (CD One) (NN need)) (ADVP (RB only)) (VP (VBP listen) (SBAR (IN while) (S (NP (NP (NNP Wegman) (NNS murmurs)) (PP (PP (TO to) (NP (NNP Fay) (NNP Ray))) (CC and) (PP (NP (NP (NNP Battina)) (, ,) (NP (PRP$ her) (NP (NP (CD 1 1/2)) (: -) (NP (JJ year-old) (NN daughter))))) (IN On) (NP (NP (NNP Valentine) (POS 's)) (NN Day))))) (, ,) (PP (IN for) (NP (NN example))) (, ,) (NP (PRP he)) (VP (VBD said) (, ,) (`` ``) (S (NP (PRP I)) (VP (MD 'll) (VP (VP (VB take) (NP (PRP them)) (PRT (RP out))) (CC and) (VP (VB play) (PP (IN with) (NP (PRP them))) (ADVP (RBR longer)))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Wegman murmurs" type="NP">
          <tokens>
            <token id="6" string="Wegman" />
            <token id="7" string="murmurs" />
          </tokens>
        </chunking>
        <chunking id="2" string="take them out and play with them longer" type="VP">
          <tokens>
            <token id="33" string="take" />
            <token id="34" string="them" />
            <token id="35" string="out" />
            <token id="36" string="and" />
            <token id="37" string="play" />
            <token id="38" string="with" />
            <token id="39" string="them" />
            <token id="40" string="longer" />
          </tokens>
        </chunking>
        <chunking id="3" string="Wegman murmurs to Fay Ray and Battina , her 1 1/2 - year-old daughter On Valentine 's Day" type="NP">
          <tokens>
            <token id="6" string="Wegman" />
            <token id="7" string="murmurs" />
            <token id="8" string="to" />
            <token id="9" string="Fay" />
            <token id="10" string="Ray" />
            <token id="11" string="and" />
            <token id="12" string="Battina" />
            <token id="13" string="," />
            <token id="14" string="her" />
            <token id="15" string="1 1/2" />
            <token id="16" string="-" />
            <token id="17" string="year-old" />
            <token id="18" string="daughter" />
            <token id="19" string="On" />
            <token id="20" string="Valentine" />
            <token id="21" string="'s" />
            <token id="22" string="Day" />
          </tokens>
        </chunking>
        <chunking id="4" string="Battina , her 1 1/2 - year-old daughter" type="NP">
          <tokens>
            <token id="12" string="Battina" />
            <token id="13" string="," />
            <token id="14" string="her" />
            <token id="15" string="1 1/2" />
            <token id="16" string="-" />
            <token id="17" string="year-old" />
            <token id="18" string="daughter" />
          </tokens>
        </chunking>
        <chunking id="5" string="Valentine 's Day" type="NP">
          <tokens>
            <token id="20" string="Valentine" />
            <token id="21" string="'s" />
            <token id="22" string="Day" />
          </tokens>
        </chunking>
        <chunking id="6" string="said , `` I 'll take them out and play with them longer" type="VP">
          <tokens>
            <token id="28" string="said" />
            <token id="29" string="," />
            <token id="30" string="&quot;" />
            <token id="31" string="I" />
            <token id="32" string="'ll" />
            <token id="33" string="take" />
            <token id="34" string="them" />
            <token id="35" string="out" />
            <token id="36" string="and" />
            <token id="37" string="play" />
            <token id="38" string="with" />
            <token id="39" string="them" />
            <token id="40" string="longer" />
          </tokens>
        </chunking>
        <chunking id="7" string="take them out" type="VP">
          <tokens>
            <token id="33" string="take" />
            <token id="34" string="them" />
            <token id="35" string="out" />
          </tokens>
        </chunking>
        <chunking id="8" string="Battina" type="NP">
          <tokens>
            <token id="12" string="Battina" />
          </tokens>
        </chunking>
        <chunking id="9" string="listen while Wegman murmurs to Fay Ray and Battina , her 1 1/2 - year-old daughter On Valentine 's Day , for example , he said , `` I 'll take them out and play with them longer" type="VP">
          <tokens>
            <token id="4" string="listen" />
            <token id="5" string="while" />
            <token id="6" string="Wegman" />
            <token id="7" string="murmurs" />
            <token id="8" string="to" />
            <token id="9" string="Fay" />
            <token id="10" string="Ray" />
            <token id="11" string="and" />
            <token id="12" string="Battina" />
            <token id="13" string="," />
            <token id="14" string="her" />
            <token id="15" string="1 1/2" />
            <token id="16" string="-" />
            <token id="17" string="year-old" />
            <token id="18" string="daughter" />
            <token id="19" string="On" />
            <token id="20" string="Valentine" />
            <token id="21" string="'s" />
            <token id="22" string="Day" />
            <token id="23" string="," />
            <token id="24" string="for" />
            <token id="25" string="example" />
            <token id="26" string="," />
            <token id="27" string="he" />
            <token id="28" string="said" />
            <token id="29" string="," />
            <token id="30" string="&quot;" />
            <token id="31" string="I" />
            <token id="32" string="'ll" />
            <token id="33" string="take" />
            <token id="34" string="them" />
            <token id="35" string="out" />
            <token id="36" string="and" />
            <token id="37" string="play" />
            <token id="38" string="with" />
            <token id="39" string="them" />
            <token id="40" string="longer" />
          </tokens>
        </chunking>
        <chunking id="10" string="I" type="NP">
          <tokens>
            <token id="31" string="I" />
          </tokens>
        </chunking>
        <chunking id="11" string="1 1/2 - year-old daughter" type="NP">
          <tokens>
            <token id="15" string="1 1/2" />
            <token id="16" string="-" />
            <token id="17" string="year-old" />
            <token id="18" string="daughter" />
          </tokens>
        </chunking>
        <chunking id="12" string="year-old daughter" type="NP">
          <tokens>
            <token id="17" string="year-old" />
            <token id="18" string="daughter" />
          </tokens>
        </chunking>
        <chunking id="13" string="example" type="NP">
          <tokens>
            <token id="25" string="example" />
          </tokens>
        </chunking>
        <chunking id="14" string="'ll take them out and play with them longer" type="VP">
          <tokens>
            <token id="32" string="'ll" />
            <token id="33" string="take" />
            <token id="34" string="them" />
            <token id="35" string="out" />
            <token id="36" string="and" />
            <token id="37" string="play" />
            <token id="38" string="with" />
            <token id="39" string="them" />
            <token id="40" string="longer" />
          </tokens>
        </chunking>
        <chunking id="15" string="them" type="NP">
          <tokens>
            <token id="34" string="them" />
          </tokens>
        </chunking>
        <chunking id="16" string="her 1 1/2 - year-old daughter" type="NP">
          <tokens>
            <token id="14" string="her" />
            <token id="15" string="1 1/2" />
            <token id="16" string="-" />
            <token id="17" string="year-old" />
            <token id="18" string="daughter" />
          </tokens>
        </chunking>
        <chunking id="17" string="while Wegman murmurs to Fay Ray and Battina , her 1 1/2 - year-old daughter On Valentine 's Day , for example , he said , `` I 'll take them out and play with them longer" type="SBAR">
          <tokens>
            <token id="5" string="while" />
            <token id="6" string="Wegman" />
            <token id="7" string="murmurs" />
            <token id="8" string="to" />
            <token id="9" string="Fay" />
            <token id="10" string="Ray" />
            <token id="11" string="and" />
            <token id="12" string="Battina" />
            <token id="13" string="," />
            <token id="14" string="her" />
            <token id="15" string="1 1/2" />
            <token id="16" string="-" />
            <token id="17" string="year-old" />
            <token id="18" string="daughter" />
            <token id="19" string="On" />
            <token id="20" string="Valentine" />
            <token id="21" string="'s" />
            <token id="22" string="Day" />
            <token id="23" string="," />
            <token id="24" string="for" />
            <token id="25" string="example" />
            <token id="26" string="," />
            <token id="27" string="he" />
            <token id="28" string="said" />
            <token id="29" string="," />
            <token id="30" string="&quot;" />
            <token id="31" string="I" />
            <token id="32" string="'ll" />
            <token id="33" string="take" />
            <token id="34" string="them" />
            <token id="35" string="out" />
            <token id="36" string="and" />
            <token id="37" string="play" />
            <token id="38" string="with" />
            <token id="39" string="them" />
            <token id="40" string="longer" />
          </tokens>
        </chunking>
        <chunking id="18" string="Fay Ray" type="NP">
          <tokens>
            <token id="9" string="Fay" />
            <token id="10" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="19" string="One need" type="NP">
          <tokens>
            <token id="1" string="One" />
            <token id="2" string="need" />
          </tokens>
        </chunking>
        <chunking id="20" string="Valentine 's" type="NP">
          <tokens>
            <token id="20" string="Valentine" />
            <token id="21" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="play with them longer" type="VP">
          <tokens>
            <token id="37" string="play" />
            <token id="38" string="with" />
            <token id="39" string="them" />
            <token id="40" string="longer" />
          </tokens>
        </chunking>
        <chunking id="22" string="he" type="NP">
          <tokens>
            <token id="27" string="he" />
          </tokens>
        </chunking>
        <chunking id="23" string="1 1/2" type="NP">
          <tokens>
            <token id="15" string="1 1/2" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">need</governor>
          <dependent id="1">One</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">listen</governor>
          <dependent id="2">need</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">listen</governor>
          <dependent id="3">only</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">listen</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">said</governor>
          <dependent id="5">while</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">murmurs</governor>
          <dependent id="6">Wegman</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">murmurs</governor>
          <dependent id="7">murmurs</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">said</governor>
          <dependent id="7">murmurs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Ray</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Ray</governor>
          <dependent id="9">Fay</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">murmurs</governor>
          <dependent id="10">Ray</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">murmurs</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">murmurs</governor>
          <dependent id="12">Battina</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">1 1/2</governor>
          <dependent id="14">her</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Battina</governor>
          <dependent id="15">1 1/2</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">daughter</governor>
          <dependent id="17">year-old</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">1 1/2</governor>
          <dependent id="18">daughter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Battina</governor>
          <dependent id="19">On</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">Day</governor>
          <dependent id="20">Valentine</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Valentine</governor>
          <dependent id="21">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">Battina</governor>
          <dependent id="22">Day</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">example</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">said</governor>
          <dependent id="25">example</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">said</governor>
          <dependent id="27">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">listen</governor>
          <dependent id="28">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">take</governor>
          <dependent id="31">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="33">take</governor>
          <dependent id="32">'ll</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">said</governor>
          <dependent id="33">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">take</governor>
          <dependent id="34">them</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="33">take</governor>
          <dependent id="35">out</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">take</governor>
          <dependent id="36">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">take</governor>
          <dependent id="37">play</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">them</governor>
          <dependent id="38">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">play</governor>
          <dependent id="39">them</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">play</governor>
          <dependent id="40">longer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Valentine 's Day" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="Valentine" />
            <token id="21" string="'s" />
            <token id="22" string="Day" />
          </tokens>
        </entity>
        <entity id="2" string="One" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="One" />
          </tokens>
        </entity>
        <entity id="3" string="Fay Ray" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Fay" />
            <token id="10" string="Ray" />
          </tokens>
        </entity>
        <entity id="4" string="1 1/2 - year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="15" string="1 1/2" />
            <token id="16" string="-" />
            <token id="17" string="year-old" />
          </tokens>
        </entity>
        <entity id="5" string="Wegman" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Wegman" />
          </tokens>
        </entity>
        <entity id="6" string="Battina" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Battina" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>; &amp;quot;But I don&amp;apost;t want to be known as a dog zombie,&amp;quot; said Wegman, who did go to the Westminster Kennel Club Dog Show without the dogs.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="want" lemma="want" stem="want" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="zombie" lemma="zombie" stem="zombi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Wegman" lemma="Wegman" stem="wegman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="Westminster" lemma="Westminster" stem="westminst" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="26" string="Kennel" lemma="Kennel" stem="kennel" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="27" string="Club" lemma="Club" stem="club" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="28" string="Dog" lemma="Dog" stem="dog" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="Show" lemma="Show" stem="show" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="dogs" lemma="dog" stem="dog" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (`` ``) (S (CC But) (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB want) (S (VP (TO to) (VP (VB be) (VP (VBN known) (PP (IN as) (NP (DT a) (NN dog) (NN zombie)))))))))) (, ,) ('' '') (VP (VBD said) (NP (NP (NNP Wegman)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD did) (VP (VB go) (PP (TO to) (NP (DT the) (NNP Westminster) (NNP Kennel) (NNP Club))))))))) (NP (NP (NNP Dog) (NNP Show)) (PP (IN without) (NP (DT the) (NNS dogs)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="do n't want to be known as a dog zombie" type="VP">
          <tokens>
            <token id="5" string="do" />
            <token id="6" string="n't" />
            <token id="7" string="want" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="known" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="dog" />
            <token id="14" string="zombie" />
          </tokens>
        </chunking>
        <chunking id="2" string="Wegman , who did go to the Westminster Kennel Club" type="NP">
          <tokens>
            <token id="18" string="Wegman" />
            <token id="19" string="," />
            <token id="20" string="who" />
            <token id="21" string="did" />
            <token id="22" string="go" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="Westminster" />
            <token id="26" string="Kennel" />
            <token id="27" string="Club" />
          </tokens>
        </chunking>
        <chunking id="3" string="who did go to the Westminster Kennel Club" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="did" />
            <token id="22" string="go" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="Westminster" />
            <token id="26" string="Kennel" />
            <token id="27" string="Club" />
          </tokens>
        </chunking>
        <chunking id="4" string="go to the Westminster Kennel Club" type="VP">
          <tokens>
            <token id="22" string="go" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="Westminster" />
            <token id="26" string="Kennel" />
            <token id="27" string="Club" />
          </tokens>
        </chunking>
        <chunking id="5" string="did go to the Westminster Kennel Club" type="VP">
          <tokens>
            <token id="21" string="did" />
            <token id="22" string="go" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="Westminster" />
            <token id="26" string="Kennel" />
            <token id="27" string="Club" />
          </tokens>
        </chunking>
        <chunking id="6" string="want to be known as a dog zombie" type="VP">
          <tokens>
            <token id="7" string="want" />
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="known" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="dog" />
            <token id="14" string="zombie" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Westminster Kennel Club" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Westminster" />
            <token id="26" string="Kennel" />
            <token id="27" string="Club" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="4" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="Dog Show without the dogs" type="NP">
          <tokens>
            <token id="28" string="Dog" />
            <token id="29" string="Show" />
            <token id="30" string="without" />
            <token id="31" string="the" />
            <token id="32" string="dogs" />
          </tokens>
        </chunking>
        <chunking id="10" string="a dog zombie" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="dog" />
            <token id="14" string="zombie" />
          </tokens>
        </chunking>
        <chunking id="11" string="to be known as a dog zombie" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="be" />
            <token id="10" string="known" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="dog" />
            <token id="14" string="zombie" />
          </tokens>
        </chunking>
        <chunking id="12" string="known as a dog zombie" type="VP">
          <tokens>
            <token id="10" string="known" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="dog" />
            <token id="14" string="zombie" />
          </tokens>
        </chunking>
        <chunking id="13" string="Dog Show" type="NP">
          <tokens>
            <token id="28" string="Dog" />
            <token id="29" string="Show" />
          </tokens>
        </chunking>
        <chunking id="14" string="Wegman" type="NP">
          <tokens>
            <token id="18" string="Wegman" />
          </tokens>
        </chunking>
        <chunking id="15" string="be known as a dog zombie" type="VP">
          <tokens>
            <token id="9" string="be" />
            <token id="10" string="known" />
            <token id="11" string="as" />
            <token id="12" string="a" />
            <token id="13" string="dog" />
            <token id="14" string="zombie" />
          </tokens>
        </chunking>
        <chunking id="16" string="said Wegman , who did go to the Westminster Kennel Club" type="VP">
          <tokens>
            <token id="17" string="said" />
            <token id="18" string="Wegman" />
            <token id="19" string="," />
            <token id="20" string="who" />
            <token id="21" string="did" />
            <token id="22" string="go" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="Westminster" />
            <token id="26" string="Kennel" />
            <token id="27" string="Club" />
          </tokens>
        </chunking>
        <chunking id="17" string="the dogs" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="dogs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">want</governor>
          <dependent id="3">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">want</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">want</governor>
          <dependent id="5">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">want</governor>
          <dependent id="6">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="7">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">known</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">known</governor>
          <dependent id="9">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">want</governor>
          <dependent id="10">known</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">zombie</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">zombie</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">zombie</governor>
          <dependent id="13">dog</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">known</governor>
          <dependent id="14">zombie</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">said</governor>
          <dependent id="18">Wegman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">go</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">go</governor>
          <dependent id="21">did</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">Wegman</governor>
          <dependent id="22">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Club</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Club</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Club</governor>
          <dependent id="25">Westminster</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Club</governor>
          <dependent id="26">Kennel</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">go</governor>
          <dependent id="27">Club</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Show</governor>
          <dependent id="28">Dog</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">said</governor>
          <dependent id="29">Show</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">dogs</governor>
          <dependent id="30">without</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">dogs</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">Show</governor>
          <dependent id="32">dogs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wegman" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Wegman" />
          </tokens>
        </entity>
        <entity id="2" string="Westminster Kennel Club" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="25" string="Westminster" />
            <token id="26" string="Kennel" />
            <token id="27" string="Club" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>&amp;quot;I go to movies and have friends and play sports.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="go" lemma="go" stem="go" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="movies" lemma="movie" stem="movi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="play" lemma="play" stem="plai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="sports" lemma="sport" stem="sport" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VP (VBP go) (PP (TO to) (NP (NNS movies)))) (CC and) (VP (VP (VBP have) (NP (NNS friends))) (CC and) (VP (VBP play) (NP (NNS sports))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have friends and play sports" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="friends" />
            <token id="9" string="and" />
            <token id="10" string="play" />
            <token id="11" string="sports" />
          </tokens>
        </chunking>
        <chunking id="2" string="movies" type="NP">
          <tokens>
            <token id="5" string="movies" />
          </tokens>
        </chunking>
        <chunking id="3" string="have friends" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="friends" />
          </tokens>
        </chunking>
        <chunking id="4" string="play sports" type="VP">
          <tokens>
            <token id="10" string="play" />
            <token id="11" string="sports" />
          </tokens>
        </chunking>
        <chunking id="5" string="sports" type="NP">
          <tokens>
            <token id="11" string="sports" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="go to movies and have friends and play sports" type="VP">
          <tokens>
            <token id="3" string="go" />
            <token id="4" string="to" />
            <token id="5" string="movies" />
            <token id="6" string="and" />
            <token id="7" string="have" />
            <token id="8" string="friends" />
            <token id="9" string="and" />
            <token id="10" string="play" />
            <token id="11" string="sports" />
          </tokens>
        </chunking>
        <chunking id="8" string="go to movies" type="VP">
          <tokens>
            <token id="3" string="go" />
            <token id="4" string="to" />
            <token id="5" string="movies" />
          </tokens>
        </chunking>
        <chunking id="9" string="friends" type="NP">
          <tokens>
            <token id="8" string="friends" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">go</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">movies</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">go</governor>
          <dependent id="5">movies</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">go</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">go</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="8">friends</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">have</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">have</governor>
          <dependent id="10">play</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">play</governor>
          <dependent id="11">sports</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>I swim, play tennis and wind surf.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="swim" lemma="swim" stem="swim" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="play" lemma="play" stem="plai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="tennis" lemma="tennis" stem="tenni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="wind" lemma="wind" stem="wind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="surf" lemma="surf" stem="surf" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VP (VBP swim)) (, ,) (VP (VBP play) (NP (NN tennis) (CC and) (NN wind) (NN surf)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="swim" type="VP">
          <tokens>
            <token id="2" string="swim" />
          </tokens>
        </chunking>
        <chunking id="2" string="tennis and wind surf" type="NP">
          <tokens>
            <token id="5" string="tennis" />
            <token id="6" string="and" />
            <token id="7" string="wind" />
            <token id="8" string="surf" />
          </tokens>
        </chunking>
        <chunking id="3" string="swim , play tennis and wind surf" type="VP">
          <tokens>
            <token id="2" string="swim" />
            <token id="3" string="," />
            <token id="4" string="play" />
            <token id="5" string="tennis" />
            <token id="6" string="and" />
            <token id="7" string="wind" />
            <token id="8" string="surf" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="play tennis and wind surf" type="VP">
          <tokens>
            <token id="4" string="play" />
            <token id="5" string="tennis" />
            <token id="6" string="and" />
            <token id="7" string="wind" />
            <token id="8" string="surf" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">swim</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">swim</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">swim</governor>
          <dependent id="4">play</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">surf</governor>
          <dependent id="5">tennis</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">tennis</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">tennis</governor>
          <dependent id="7">wind</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">play</governor>
          <dependent id="8">surf</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>; Battina begs to differ.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Battina" lemma="Battina" stem="battina" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="begs" lemma="beg" stem="beg" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="differ" lemma="differ" stem="differ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (NP (NNP Battina)) (VP (VBZ begs) (S (VP (TO to) (VP (VB differ))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="begs to differ" type="VP">
          <tokens>
            <token id="3" string="begs" />
            <token id="4" string="to" />
            <token id="5" string="differ" />
          </tokens>
        </chunking>
        <chunking id="2" string="Battina" type="NP">
          <tokens>
            <token id="2" string="Battina" />
          </tokens>
        </chunking>
        <chunking id="3" string="differ" type="VP">
          <tokens>
            <token id="5" string="differ" />
          </tokens>
        </chunking>
        <chunking id="4" string="to differ" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="differ" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">begs</governor>
          <dependent id="2">Battina</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">begs</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">differ</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">begs</governor>
          <dependent id="5">differ</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Battina" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Battina" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>&amp;quot;When Bill leaves, Batty howls,&amp;quot; said Andrea Beeman, an assistant to Wegman Man and dog; Their home is one floor of a former Orthodox synagogue on the Lower East Side of Manhattan.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Bill" lemma="Bill" stem="bill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="leaves" lemma="leave" stem="leav" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Batty" lemma="Batty" stem="batti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="howls" lemma="howl" stem="howl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Andrea" lemma="Andrea" stem="andrea" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Beeman" lemma="Beeman" stem="beeman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="assistant" lemma="assistant" stem="assist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Wegman" lemma="Wegman" stem="wegman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="18" string="Man" lemma="Man" stem="man" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="26" string="floor" lemma="floor" stem="floor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Orthodox" lemma="Orthodox" stem="orthodox" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="31" string="synagogue" lemma="synagogue" stem="synagogu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Lower" lemma="Lower" stem="lower" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="35" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="36" string="Side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="37" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="38" string="Manhattan" lemma="Manhattan" stem="manhattan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (WHADVP (WRB When)) (S (NP (NNP Bill)) (VP (VBZ leaves)))) (, ,) (NP (NNP Batty) (NNS howls)) (, ,) ('' '') (VP (VBD said) (SBAR (S (NP (NNP Andrea) (NNP Beeman)) (, ,) (NP (NP (DT an) (NN assistant)) (PP (TO to) (NP (NP (NNP Wegman) (NNP Man)) (CC and) (NP (NN dog))))) (: ;) (NP (PRP$ Their) (NN home)) (VP (VBZ is) (NP (NP (CD one) (NN floor)) (PP (IN of) (NP (NP (DT a) (JJ former) (NNP Orthodox) (NN synagogue)) (PP (IN on) (NP (DT the) (NNP Lower) (NNP East)))))))))) (NP (NP (NN Side)) (PP (IN of) (NP (NNP Manhattan)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Wegman Man and dog" type="NP">
          <tokens>
            <token id="17" string="Wegman" />
            <token id="18" string="Man" />
            <token id="19" string="and" />
            <token id="20" string="dog" />
          </tokens>
        </chunking>
        <chunking id="2" string="Wegman Man" type="NP">
          <tokens>
            <token id="17" string="Wegman" />
            <token id="18" string="Man" />
          </tokens>
        </chunking>
        <chunking id="3" string="Their home" type="NP">
          <tokens>
            <token id="22" string="Their" />
            <token id="23" string="home" />
          </tokens>
        </chunking>
        <chunking id="4" string="Andrea Beeman , an assistant to Wegman Man and dog ; Their home is one floor of a former Orthodox synagogue on the Lower East" type="SBAR">
          <tokens>
            <token id="11" string="Andrea" />
            <token id="12" string="Beeman" />
            <token id="13" string="," />
            <token id="14" string="an" />
            <token id="15" string="assistant" />
            <token id="16" string="to" />
            <token id="17" string="Wegman" />
            <token id="18" string="Man" />
            <token id="19" string="and" />
            <token id="20" string="dog" />
            <token id="21" string=";" />
            <token id="22" string="Their" />
            <token id="23" string="home" />
            <token id="24" string="is" />
            <token id="25" string="one" />
            <token id="26" string="floor" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="former" />
            <token id="30" string="Orthodox" />
            <token id="31" string="synagogue" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="Lower" />
            <token id="35" string="East" />
          </tokens>
        </chunking>
        <chunking id="5" string="Manhattan" type="NP">
          <tokens>
            <token id="38" string="Manhattan" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Lower East" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="Lower" />
            <token id="35" string="East" />
          </tokens>
        </chunking>
        <chunking id="7" string="one floor of a former Orthodox synagogue on the Lower East" type="NP">
          <tokens>
            <token id="25" string="one" />
            <token id="26" string="floor" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="former" />
            <token id="30" string="Orthodox" />
            <token id="31" string="synagogue" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="Lower" />
            <token id="35" string="East" />
          </tokens>
        </chunking>
        <chunking id="8" string="a former Orthodox synagogue" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="former" />
            <token id="30" string="Orthodox" />
            <token id="31" string="synagogue" />
          </tokens>
        </chunking>
        <chunking id="9" string="is one floor of a former Orthodox synagogue on the Lower East" type="VP">
          <tokens>
            <token id="24" string="is" />
            <token id="25" string="one" />
            <token id="26" string="floor" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="former" />
            <token id="30" string="Orthodox" />
            <token id="31" string="synagogue" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="Lower" />
            <token id="35" string="East" />
          </tokens>
        </chunking>
        <chunking id="10" string="When" type="WHADVP">
          <tokens>
            <token id="2" string="When" />
          </tokens>
        </chunking>
        <chunking id="11" string="Side" type="NP">
          <tokens>
            <token id="36" string="Side" />
          </tokens>
        </chunking>
        <chunking id="12" string="leaves" type="VP">
          <tokens>
            <token id="4" string="leaves" />
          </tokens>
        </chunking>
        <chunking id="13" string="Side of Manhattan" type="NP">
          <tokens>
            <token id="36" string="Side" />
            <token id="37" string="of" />
            <token id="38" string="Manhattan" />
          </tokens>
        </chunking>
        <chunking id="14" string="When Bill leaves" type="SBAR">
          <tokens>
            <token id="2" string="When" />
            <token id="3" string="Bill" />
            <token id="4" string="leaves" />
          </tokens>
        </chunking>
        <chunking id="15" string="a former Orthodox synagogue on the Lower East" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="former" />
            <token id="30" string="Orthodox" />
            <token id="31" string="synagogue" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="Lower" />
            <token id="35" string="East" />
          </tokens>
        </chunking>
        <chunking id="16" string="an assistant to Wegman Man and dog" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="assistant" />
            <token id="16" string="to" />
            <token id="17" string="Wegman" />
            <token id="18" string="Man" />
            <token id="19" string="and" />
            <token id="20" string="dog" />
          </tokens>
        </chunking>
        <chunking id="17" string="an assistant" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="assistant" />
          </tokens>
        </chunking>
        <chunking id="18" string="Bill" type="NP">
          <tokens>
            <token id="3" string="Bill" />
          </tokens>
        </chunking>
        <chunking id="19" string="said Andrea Beeman , an assistant to Wegman Man and dog ; Their home is one floor of a former Orthodox synagogue on the Lower East" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="Andrea" />
            <token id="12" string="Beeman" />
            <token id="13" string="," />
            <token id="14" string="an" />
            <token id="15" string="assistant" />
            <token id="16" string="to" />
            <token id="17" string="Wegman" />
            <token id="18" string="Man" />
            <token id="19" string="and" />
            <token id="20" string="dog" />
            <token id="21" string=";" />
            <token id="22" string="Their" />
            <token id="23" string="home" />
            <token id="24" string="is" />
            <token id="25" string="one" />
            <token id="26" string="floor" />
            <token id="27" string="of" />
            <token id="28" string="a" />
            <token id="29" string="former" />
            <token id="30" string="Orthodox" />
            <token id="31" string="synagogue" />
            <token id="32" string="on" />
            <token id="33" string="the" />
            <token id="34" string="Lower" />
            <token id="35" string="East" />
          </tokens>
        </chunking>
        <chunking id="20" string="dog" type="NP">
          <tokens>
            <token id="20" string="dog" />
          </tokens>
        </chunking>
        <chunking id="21" string="Andrea Beeman" type="NP">
          <tokens>
            <token id="11" string="Andrea" />
            <token id="12" string="Beeman" />
          </tokens>
        </chunking>
        <chunking id="22" string="Batty howls" type="NP">
          <tokens>
            <token id="6" string="Batty" />
            <token id="7" string="howls" />
          </tokens>
        </chunking>
        <chunking id="23" string="one floor" type="NP">
          <tokens>
            <token id="25" string="one" />
            <token id="26" string="floor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">leaves</governor>
          <dependent id="2">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">leaves</governor>
          <dependent id="3">Bill</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">said</governor>
          <dependent id="4">leaves</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">howls</governor>
          <dependent id="6">Batty</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="7">howls</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Beeman</governor>
          <dependent id="11">Andrea</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">floor</governor>
          <dependent id="12">Beeman</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">assistant</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">floor</governor>
          <dependent id="15">assistant</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Man</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Man</governor>
          <dependent id="17">Wegman</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">assistant</governor>
          <dependent id="18">Man</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">Man</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">Man</governor>
          <dependent id="20">dog</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">home</governor>
          <dependent id="22">Their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">floor</governor>
          <dependent id="23">home</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">floor</governor>
          <dependent id="24">is</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">floor</governor>
          <dependent id="25">one</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="26">floor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">synagogue</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">synagogue</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">synagogue</governor>
          <dependent id="29">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">synagogue</governor>
          <dependent id="30">Orthodox</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">floor</governor>
          <dependent id="31">synagogue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">East</governor>
          <dependent id="32">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">East</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">East</governor>
          <dependent id="34">Lower</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">synagogue</governor>
          <dependent id="35">East</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">said</governor>
          <dependent id="36">Side</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">Manhattan</governor>
          <dependent id="37">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">Side</governor>
          <dependent id="38">Manhattan</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wegman Man" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Wegman" />
            <token id="18" string="Man" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="25" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Batty" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Batty" />
          </tokens>
        </entity>
        <entity id="4" string="Orthodox" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="30" string="Orthodox" />
          </tokens>
        </entity>
        <entity id="5" string="Lower East Side of Manhattan" type="LOCATION" score="0.0">
          <tokens>
            <token id="34" string="Lower" />
            <token id="35" string="East" />
            <token id="36" string="Side" />
            <token id="37" string="of" />
            <token id="38" string="Manhattan" />
          </tokens>
        </entity>
        <entity id="6" string="Bill" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Bill" />
          </tokens>
        </entity>
        <entity id="7" string="Andrea Beeman" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Andrea" />
            <token id="12" string="Beeman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>During a recent visit, it was possible to see how the artist gets two even-tempered, relaxed, normal dogs to slip into florid housedresses or scratch each other&amp;apost;s backs.</content>
      <tokens>
        <token id="1" string="During" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="visit" lemma="visit" stem="visit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="artist" lemma="artist" stem="artist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="gets" lemma="get" stem="get" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="even-tempered" lemma="even-tempered" stem="even-temp" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="relaxed" lemma="relax" stem="relax" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="normal" lemma="normal" stem="normal" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="dogs" lemma="dog" stem="dog" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="slip" lemma="slip" stem="slip" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="florid" lemma="florid" stem="florid" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="housedresses" lemma="housedress" stem="housedress" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="scratch" lemma="scratch" stem="scratch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="backs" lemma="back" stem="back" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN During) (NP (DT a) (JJ recent) (NN visit))) (, ,) (NP (PRP it)) (VP (VBD was) (ADJP (JJ possible) (S (VP (TO to) (VP (VB see) (SBAR (WHADVP (WRB how)) (S (NP (DT the) (NN artist)) (VP (VBZ gets) (NP (NP (NP (CD two)) (ADJP (JJ even-tempered))) (, ,) (VP (VBN relaxed)) (, ,) (NP (JJ normal) (NNS dogs) (S (VP (TO to) (VP (VB slip) (PP (IN into) (NP (JJ florid) (NNS housedresses))))))) (CC or) (NP (NP (NN scratch)) (NP (NP (DT each) (JJ other) (POS 's)) (NNS backs)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the artist" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="artist" />
          </tokens>
        </chunking>
        <chunking id="2" string="two even-tempered" type="NP">
          <tokens>
            <token id="15" string="two" />
            <token id="16" string="even-tempered" />
          </tokens>
        </chunking>
        <chunking id="3" string="a recent visit" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="recent" />
            <token id="4" string="visit" />
          </tokens>
        </chunking>
        <chunking id="4" string="gets two even-tempered , relaxed , normal dogs to slip into florid housedresses or scratch each other 's backs" type="VP">
          <tokens>
            <token id="14" string="gets" />
            <token id="15" string="two" />
            <token id="16" string="even-tempered" />
            <token id="17" string="," />
            <token id="18" string="relaxed" />
            <token id="19" string="," />
            <token id="20" string="normal" />
            <token id="21" string="dogs" />
            <token id="22" string="to" />
            <token id="23" string="slip" />
            <token id="24" string="into" />
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
            <token id="27" string="or" />
            <token id="28" string="scratch" />
            <token id="29" string="each" />
            <token id="30" string="other" />
            <token id="31" string="'s" />
            <token id="32" string="backs" />
          </tokens>
        </chunking>
        <chunking id="5" string="florid housedresses" type="NP">
          <tokens>
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
          </tokens>
        </chunking>
        <chunking id="6" string="scratch" type="NP">
          <tokens>
            <token id="28" string="scratch" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="two" type="NP">
          <tokens>
            <token id="15" string="two" />
          </tokens>
        </chunking>
        <chunking id="9" string="was possible to see how the artist gets two even-tempered , relaxed , normal dogs to slip into florid housedresses or scratch each other 's backs" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="possible" />
            <token id="9" string="to" />
            <token id="10" string="see" />
            <token id="11" string="how" />
            <token id="12" string="the" />
            <token id="13" string="artist" />
            <token id="14" string="gets" />
            <token id="15" string="two" />
            <token id="16" string="even-tempered" />
            <token id="17" string="," />
            <token id="18" string="relaxed" />
            <token id="19" string="," />
            <token id="20" string="normal" />
            <token id="21" string="dogs" />
            <token id="22" string="to" />
            <token id="23" string="slip" />
            <token id="24" string="into" />
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
            <token id="27" string="or" />
            <token id="28" string="scratch" />
            <token id="29" string="each" />
            <token id="30" string="other" />
            <token id="31" string="'s" />
            <token id="32" string="backs" />
          </tokens>
        </chunking>
        <chunking id="10" string="slip into florid housedresses" type="VP">
          <tokens>
            <token id="23" string="slip" />
            <token id="24" string="into" />
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
          </tokens>
        </chunking>
        <chunking id="11" string="how" type="WHADVP">
          <tokens>
            <token id="11" string="how" />
          </tokens>
        </chunking>
        <chunking id="12" string="even-tempered" type="ADJP">
          <tokens>
            <token id="16" string="even-tempered" />
          </tokens>
        </chunking>
        <chunking id="13" string="normal dogs to slip into florid housedresses" type="NP">
          <tokens>
            <token id="20" string="normal" />
            <token id="21" string="dogs" />
            <token id="22" string="to" />
            <token id="23" string="slip" />
            <token id="24" string="into" />
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
          </tokens>
        </chunking>
        <chunking id="14" string="relaxed" type="VP">
          <tokens>
            <token id="18" string="relaxed" />
          </tokens>
        </chunking>
        <chunking id="15" string="to slip into florid housedresses" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="slip" />
            <token id="24" string="into" />
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
          </tokens>
        </chunking>
        <chunking id="16" string="how the artist gets two even-tempered , relaxed , normal dogs to slip into florid housedresses or scratch each other 's backs" type="SBAR">
          <tokens>
            <token id="11" string="how" />
            <token id="12" string="the" />
            <token id="13" string="artist" />
            <token id="14" string="gets" />
            <token id="15" string="two" />
            <token id="16" string="even-tempered" />
            <token id="17" string="," />
            <token id="18" string="relaxed" />
            <token id="19" string="," />
            <token id="20" string="normal" />
            <token id="21" string="dogs" />
            <token id="22" string="to" />
            <token id="23" string="slip" />
            <token id="24" string="into" />
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
            <token id="27" string="or" />
            <token id="28" string="scratch" />
            <token id="29" string="each" />
            <token id="30" string="other" />
            <token id="31" string="'s" />
            <token id="32" string="backs" />
          </tokens>
        </chunking>
        <chunking id="17" string="scratch each other 's backs" type="NP">
          <tokens>
            <token id="28" string="scratch" />
            <token id="29" string="each" />
            <token id="30" string="other" />
            <token id="31" string="'s" />
            <token id="32" string="backs" />
          </tokens>
        </chunking>
        <chunking id="18" string="to see how the artist gets two even-tempered , relaxed , normal dogs to slip into florid housedresses or scratch each other 's backs" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="see" />
            <token id="11" string="how" />
            <token id="12" string="the" />
            <token id="13" string="artist" />
            <token id="14" string="gets" />
            <token id="15" string="two" />
            <token id="16" string="even-tempered" />
            <token id="17" string="," />
            <token id="18" string="relaxed" />
            <token id="19" string="," />
            <token id="20" string="normal" />
            <token id="21" string="dogs" />
            <token id="22" string="to" />
            <token id="23" string="slip" />
            <token id="24" string="into" />
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
            <token id="27" string="or" />
            <token id="28" string="scratch" />
            <token id="29" string="each" />
            <token id="30" string="other" />
            <token id="31" string="'s" />
            <token id="32" string="backs" />
          </tokens>
        </chunking>
        <chunking id="19" string="possible to see how the artist gets two even-tempered , relaxed , normal dogs to slip into florid housedresses or scratch each other 's backs" type="ADJP">
          <tokens>
            <token id="8" string="possible" />
            <token id="9" string="to" />
            <token id="10" string="see" />
            <token id="11" string="how" />
            <token id="12" string="the" />
            <token id="13" string="artist" />
            <token id="14" string="gets" />
            <token id="15" string="two" />
            <token id="16" string="even-tempered" />
            <token id="17" string="," />
            <token id="18" string="relaxed" />
            <token id="19" string="," />
            <token id="20" string="normal" />
            <token id="21" string="dogs" />
            <token id="22" string="to" />
            <token id="23" string="slip" />
            <token id="24" string="into" />
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
            <token id="27" string="or" />
            <token id="28" string="scratch" />
            <token id="29" string="each" />
            <token id="30" string="other" />
            <token id="31" string="'s" />
            <token id="32" string="backs" />
          </tokens>
        </chunking>
        <chunking id="20" string="two even-tempered , relaxed , normal dogs to slip into florid housedresses or scratch each other 's backs" type="NP">
          <tokens>
            <token id="15" string="two" />
            <token id="16" string="even-tempered" />
            <token id="17" string="," />
            <token id="18" string="relaxed" />
            <token id="19" string="," />
            <token id="20" string="normal" />
            <token id="21" string="dogs" />
            <token id="22" string="to" />
            <token id="23" string="slip" />
            <token id="24" string="into" />
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
            <token id="27" string="or" />
            <token id="28" string="scratch" />
            <token id="29" string="each" />
            <token id="30" string="other" />
            <token id="31" string="'s" />
            <token id="32" string="backs" />
          </tokens>
        </chunking>
        <chunking id="21" string="each other 's" type="NP">
          <tokens>
            <token id="29" string="each" />
            <token id="30" string="other" />
            <token id="31" string="'s" />
          </tokens>
        </chunking>
        <chunking id="22" string="each other 's backs" type="NP">
          <tokens>
            <token id="29" string="each" />
            <token id="30" string="other" />
            <token id="31" string="'s" />
            <token id="32" string="backs" />
          </tokens>
        </chunking>
        <chunking id="23" string="see how the artist gets two even-tempered , relaxed , normal dogs to slip into florid housedresses or scratch each other 's backs" type="VP">
          <tokens>
            <token id="10" string="see" />
            <token id="11" string="how" />
            <token id="12" string="the" />
            <token id="13" string="artist" />
            <token id="14" string="gets" />
            <token id="15" string="two" />
            <token id="16" string="even-tempered" />
            <token id="17" string="," />
            <token id="18" string="relaxed" />
            <token id="19" string="," />
            <token id="20" string="normal" />
            <token id="21" string="dogs" />
            <token id="22" string="to" />
            <token id="23" string="slip" />
            <token id="24" string="into" />
            <token id="25" string="florid" />
            <token id="26" string="housedresses" />
            <token id="27" string="or" />
            <token id="28" string="scratch" />
            <token id="29" string="each" />
            <token id="30" string="other" />
            <token id="31" string="'s" />
            <token id="32" string="backs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">visit</governor>
          <dependent id="1">During</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">visit</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">visit</governor>
          <dependent id="3">recent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">possible</governor>
          <dependent id="4">visit</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">possible</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">possible</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">possible</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">see</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">possible</governor>
          <dependent id="10">see</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">gets</governor>
          <dependent id="11">how</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">artist</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">gets</governor>
          <dependent id="13">artist</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">see</governor>
          <dependent id="14">gets</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">gets</governor>
          <dependent id="15">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">two</governor>
          <dependent id="16">even-tempered</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">two</governor>
          <dependent id="18">relaxed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">dogs</governor>
          <dependent id="20">normal</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">two</governor>
          <dependent id="21">dogs</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">slip</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">dogs</governor>
          <dependent id="23">slip</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">housedresses</governor>
          <dependent id="24">into</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">housedresses</governor>
          <dependent id="25">florid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">slip</governor>
          <dependent id="26">housedresses</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">two</governor>
          <dependent id="27">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">two</governor>
          <dependent id="28">scratch</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">other</governor>
          <dependent id="29">each</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">backs</governor>
          <dependent id="30">other</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">other</governor>
          <dependent id="31">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">scratch</governor>
          <dependent id="32">backs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>The three simply adore each other &amp;quot;I&amp;apost;d never heard of Weimaraners,&amp;quot; said the artist, who was born 47 years ago in Longmeadow, Mass.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="simply" lemma="simply" stem="simpli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="adore" lemma="adore" stem="ador" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="heard" lemma="hear" stem="heard" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Weimaraners" lemma="weimaraner" stem="weimaran" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="artist" lemma="artist" stem="artist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="47" lemma="47" stem="47" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="24" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="25" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="Longmeadow" lemma="Longmeadow" stem="longmeadow" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="Mass" lemma="Mass." stem="mass" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (CD three)) (ADVP (RB simply)) (VP (VBP adore) (S (NP (DT each)) (ADJP (JJ other)) (SBAR (SINV (`` ``) (S (NP (PRP I)) (VP (MD 'd) (VP (ADVP (RB never)) (VBN heard) (PP (IN of) (NP (NNS Weimaraners)))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (DT the) (NN artist)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBN born) (PP (ADVP (NP (CD 47) (NNS years)) (RB ago)) (IN in) (NP (NNP Longmeadow) (, ,) (NNP Mass.)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the artist" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="artist" />
          </tokens>
        </chunking>
        <chunking id="2" string="'d never heard of Weimaraners" type="VP">
          <tokens>
            <token id="9" string="'d" />
            <token id="10" string="never" />
            <token id="11" string="heard" />
            <token id="12" string="of" />
            <token id="13" string="Weimaraners" />
          </tokens>
        </chunking>
        <chunking id="3" string="who was born 47 years ago in Longmeadow , Mass." type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="was" />
            <token id="22" string="born" />
            <token id="23" string="47" />
            <token id="24" string="years" />
            <token id="25" string="ago" />
            <token id="26" string="in" />
            <token id="27" string="Longmeadow" />
            <token id="28" string="," />
            <token id="29" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="4" string="Weimaraners" type="NP">
          <tokens>
            <token id="13" string="Weimaraners" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="8" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="the artist , who was born 47 years ago in Longmeadow , Mass." type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="artist" />
            <token id="19" string="," />
            <token id="20" string="who" />
            <token id="21" string="was" />
            <token id="22" string="born" />
            <token id="23" string="47" />
            <token id="24" string="years" />
            <token id="25" string="ago" />
            <token id="26" string="in" />
            <token id="27" string="Longmeadow" />
            <token id="28" string="," />
            <token id="29" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="7" string="each" type="NP">
          <tokens>
            <token id="5" string="each" />
          </tokens>
        </chunking>
        <chunking id="8" string="born 47 years ago in Longmeadow , Mass." type="VP">
          <tokens>
            <token id="22" string="born" />
            <token id="23" string="47" />
            <token id="24" string="years" />
            <token id="25" string="ago" />
            <token id="26" string="in" />
            <token id="27" string="Longmeadow" />
            <token id="28" string="," />
            <token id="29" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="9" string="Longmeadow , Mass." type="NP">
          <tokens>
            <token id="27" string="Longmeadow" />
            <token id="28" string="," />
            <token id="29" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="10" string="`` I 'd never heard of Weimaraners , '' said the artist , who was born 47 years ago in Longmeadow , Mass." type="SBAR">
          <tokens>
            <token id="7" string="&quot;" />
            <token id="8" string="I" />
            <token id="9" string="'d" />
            <token id="10" string="never" />
            <token id="11" string="heard" />
            <token id="12" string="of" />
            <token id="13" string="Weimaraners" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="said" />
            <token id="17" string="the" />
            <token id="18" string="artist" />
            <token id="19" string="," />
            <token id="20" string="who" />
            <token id="21" string="was" />
            <token id="22" string="born" />
            <token id="23" string="47" />
            <token id="24" string="years" />
            <token id="25" string="ago" />
            <token id="26" string="in" />
            <token id="27" string="Longmeadow" />
            <token id="28" string="," />
            <token id="29" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="11" string="adore each other `` I 'd never heard of Weimaraners , '' said the artist , who was born 47 years ago in Longmeadow , Mass." type="VP">
          <tokens>
            <token id="4" string="adore" />
            <token id="5" string="each" />
            <token id="6" string="other" />
            <token id="7" string="&quot;" />
            <token id="8" string="I" />
            <token id="9" string="'d" />
            <token id="10" string="never" />
            <token id="11" string="heard" />
            <token id="12" string="of" />
            <token id="13" string="Weimaraners" />
            <token id="14" string="," />
            <token id="15" string="&quot;" />
            <token id="16" string="said" />
            <token id="17" string="the" />
            <token id="18" string="artist" />
            <token id="19" string="," />
            <token id="20" string="who" />
            <token id="21" string="was" />
            <token id="22" string="born" />
            <token id="23" string="47" />
            <token id="24" string="years" />
            <token id="25" string="ago" />
            <token id="26" string="in" />
            <token id="27" string="Longmeadow" />
            <token id="28" string="," />
            <token id="29" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="12" string="The three" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="three" />
          </tokens>
        </chunking>
        <chunking id="13" string="other" type="ADJP">
          <tokens>
            <token id="6" string="other" />
          </tokens>
        </chunking>
        <chunking id="14" string="never heard of Weimaraners" type="VP">
          <tokens>
            <token id="10" string="never" />
            <token id="11" string="heard" />
            <token id="12" string="of" />
            <token id="13" string="Weimaraners" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="was born 47 years ago in Longmeadow , Mass." type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="born" />
            <token id="23" string="47" />
            <token id="24" string="years" />
            <token id="25" string="ago" />
            <token id="26" string="in" />
            <token id="27" string="Longmeadow" />
            <token id="28" string="," />
            <token id="29" string="Mass" />
          </tokens>
        </chunking>
        <chunking id="17" string="47 years" type="NP">
          <tokens>
            <token id="23" string="47" />
            <token id="24" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">three</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">adore</governor>
          <dependent id="2">three</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">adore</governor>
          <dependent id="3">simply</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">adore</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="5">each</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">said</governor>
          <dependent id="6">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">heard</governor>
          <dependent id="8">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">heard</governor>
          <dependent id="9">'d</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">heard</governor>
          <dependent id="10">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="11">heard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Weimaraners</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">heard</governor>
          <dependent id="13">Weimaraners</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">adore</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">artist</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="18">artist</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="22">born</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">born</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">artist</governor>
          <dependent id="22">born</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">years</governor>
          <dependent id="23">47</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="25">ago</governor>
          <dependent id="24">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">Mass.</governor>
          <dependent id="25">ago</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Mass.</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Mass.</governor>
          <dependent id="27">Longmeadow</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">born</governor>
          <dependent id="29">Mass.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Longmeadow" type="LOCATION" score="0.0">
          <tokens>
            <token id="27" string="Longmeadow" />
          </tokens>
        </entity>
        <entity id="2" string="Mass" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Mass" />
          </tokens>
        </entity>
        <entity id="3" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="three" />
          </tokens>
        </entity>
        <entity id="4" string="47 years ago" type="DATE" score="0.0">
          <tokens>
            <token id="23" string="47" />
            <token id="24" string="years" />
            <token id="25" string="ago" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>His life with Weimaraners began in 1970, the year he bought a new video camera and Man Ray, a puppy that cost $35 Wegman had never photographed dogs before, but Man Ray was a perfect subject &amp;quot;He was gray and neutral,&amp;quot; the artist said.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Weimaraners" lemma="weimaraner" stem="weimaran" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="1970" lemma="1970" stem="1970" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="bought" lemma="buy" stem="bought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="video" lemma="video" stem="video" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="camera" lemma="camera" stem="camera" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="puppy" lemma="puppy" stem="puppi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="cost" lemma="cost" stem="cost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="26" string="35" lemma="35" stem="35" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="27" string="Wegman" lemma="Wegman" stem="wegman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="photographed" lemma="photograph" stem="photograph" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="dogs" lemma="dog" stem="dog" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="36" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="37" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="perfect" lemma="perfect" stem="perfect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="subject" lemma="subject" stem="subject" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="43" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="gray" lemma="gray" stem="grai" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="neutral" lemma="neutral" stem="neutral" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="artist" lemma="artist" stem="artist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="51" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (PRP$ His) (NN life)) (PP (IN with) (NP (NNS Weimaraners)))) (VP (VBD began) (PP (IN in) (NP (CD 1970))) (, ,) (NP-TMP (DT the) (NN year)) (SBAR (S (NP (PRP he)) (VP (VBD bought) (NP (NP (NP (DT a) (JJ new) (NN video) (NN camera)) (CC and) (NP (NN Man) (NNP Ray))) (, ,) (NP (NP (DT a) (NN puppy)) (SBAR (WHNP (WDT that)) (S (VP (VBD cost) (NP ($ $) (CD 35)) (NP (NP (NNP Wegman)) (SBAR (S (VP (VBD had) (ADVP (RB never)) (VP (VBN photographed) (NP (NNS dogs)) (PP (IN before)))))))))))))) (, ,) (CC but) (S (NP (NN Man) (NNP Ray)) (VP (VBD was) (NP (DT a) (JJ perfect) (NN subject)) (SBAR (`` ``) (S (NP (PRP He)) (VP (VBD was) (ADJP (JJ gray) (CC and) (JJ neutral)))))))))) (, ,) ('' '') (NP (DT the) (NN artist)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the artist" type="NP">
          <tokens>
            <token id="49" string="the" />
            <token id="50" string="artist" />
          </tokens>
        </chunking>
        <chunking id="2" string="was a perfect subject `` He was gray and neutral" type="VP">
          <tokens>
            <token id="37" string="was" />
            <token id="38" string="a" />
            <token id="39" string="perfect" />
            <token id="40" string="subject" />
            <token id="41" string="&quot;" />
            <token id="42" string="He" />
            <token id="43" string="was" />
            <token id="44" string="gray" />
            <token id="45" string="and" />
            <token id="46" string="neutral" />
          </tokens>
        </chunking>
        <chunking id="3" string="began in 1970 , the year he bought a new video camera and Man Ray , a puppy that cost $ 35 Wegman had never photographed dogs before , but Man Ray was a perfect subject `` He was gray and neutral" type="VP">
          <tokens>
            <token id="5" string="began" />
            <token id="6" string="in" />
            <token id="7" string="1970" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="year" />
            <token id="11" string="he" />
            <token id="12" string="bought" />
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="video" />
            <token id="16" string="camera" />
            <token id="17" string="and" />
            <token id="18" string="Man" />
            <token id="19" string="Ray" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="puppy" />
            <token id="23" string="that" />
            <token id="24" string="cost" />
            <token id="25" string="$" />
            <token id="26" string="35" />
            <token id="27" string="Wegman" />
            <token id="28" string="had" />
            <token id="29" string="never" />
            <token id="30" string="photographed" />
            <token id="31" string="dogs" />
            <token id="32" string="before" />
            <token id="33" string="," />
            <token id="34" string="but" />
            <token id="35" string="Man" />
            <token id="36" string="Ray" />
            <token id="37" string="was" />
            <token id="38" string="a" />
            <token id="39" string="perfect" />
            <token id="40" string="subject" />
            <token id="41" string="&quot;" />
            <token id="42" string="He" />
            <token id="43" string="was" />
            <token id="44" string="gray" />
            <token id="45" string="and" />
            <token id="46" string="neutral" />
          </tokens>
        </chunking>
        <chunking id="4" string="Wegman had never photographed dogs before" type="NP">
          <tokens>
            <token id="27" string="Wegman" />
            <token id="28" string="had" />
            <token id="29" string="never" />
            <token id="30" string="photographed" />
            <token id="31" string="dogs" />
            <token id="32" string="before" />
          </tokens>
        </chunking>
        <chunking id="5" string="a puppy" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="puppy" />
          </tokens>
        </chunking>
        <chunking id="6" string="His life with Weimaraners" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="life" />
            <token id="3" string="with" />
            <token id="4" string="Weimaraners" />
          </tokens>
        </chunking>
        <chunking id="7" string="cost $ 35 Wegman had never photographed dogs before" type="VP">
          <tokens>
            <token id="24" string="cost" />
            <token id="25" string="$" />
            <token id="26" string="35" />
            <token id="27" string="Wegman" />
            <token id="28" string="had" />
            <token id="29" string="never" />
            <token id="30" string="photographed" />
            <token id="31" string="dogs" />
            <token id="32" string="before" />
          </tokens>
        </chunking>
        <chunking id="8" string="was gray and neutral" type="VP">
          <tokens>
            <token id="43" string="was" />
            <token id="44" string="gray" />
            <token id="45" string="and" />
            <token id="46" string="neutral" />
          </tokens>
        </chunking>
        <chunking id="9" string="a new video camera and Man Ray" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="video" />
            <token id="16" string="camera" />
            <token id="17" string="and" />
            <token id="18" string="Man" />
            <token id="19" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="10" string="had never photographed dogs before" type="SBAR">
          <tokens>
            <token id="28" string="had" />
            <token id="29" string="never" />
            <token id="30" string="photographed" />
            <token id="31" string="dogs" />
            <token id="32" string="before" />
          </tokens>
        </chunking>
        <chunking id="11" string="a new video camera" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="video" />
            <token id="16" string="camera" />
          </tokens>
        </chunking>
        <chunking id="12" string="Wegman" type="NP">
          <tokens>
            <token id="27" string="Wegman" />
          </tokens>
        </chunking>
        <chunking id="13" string="a perfect subject" type="NP">
          <tokens>
            <token id="38" string="a" />
            <token id="39" string="perfect" />
            <token id="40" string="subject" />
          </tokens>
        </chunking>
        <chunking id="14" string="a puppy that cost $ 35 Wegman had never photographed dogs before" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="puppy" />
            <token id="23" string="that" />
            <token id="24" string="cost" />
            <token id="25" string="$" />
            <token id="26" string="35" />
            <token id="27" string="Wegman" />
            <token id="28" string="had" />
            <token id="29" string="never" />
            <token id="30" string="photographed" />
            <token id="31" string="dogs" />
            <token id="32" string="before" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="a new video camera and Man Ray , a puppy that cost $ 35 Wegman had never photographed dogs before" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="video" />
            <token id="16" string="camera" />
            <token id="17" string="and" />
            <token id="18" string="Man" />
            <token id="19" string="Ray" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="puppy" />
            <token id="23" string="that" />
            <token id="24" string="cost" />
            <token id="25" string="$" />
            <token id="26" string="35" />
            <token id="27" string="Wegman" />
            <token id="28" string="had" />
            <token id="29" string="never" />
            <token id="30" string="photographed" />
            <token id="31" string="dogs" />
            <token id="32" string="before" />
          </tokens>
        </chunking>
        <chunking id="17" string="Man Ray" type="NP">
          <tokens>
            <token id="18" string="Man" />
            <token id="19" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="18" string="he bought a new video camera and Man Ray , a puppy that cost $ 35 Wegman had never photographed dogs before , but Man Ray was a perfect subject `` He was gray and neutral" type="SBAR">
          <tokens>
            <token id="11" string="he" />
            <token id="12" string="bought" />
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="video" />
            <token id="16" string="camera" />
            <token id="17" string="and" />
            <token id="18" string="Man" />
            <token id="19" string="Ray" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="puppy" />
            <token id="23" string="that" />
            <token id="24" string="cost" />
            <token id="25" string="$" />
            <token id="26" string="35" />
            <token id="27" string="Wegman" />
            <token id="28" string="had" />
            <token id="29" string="never" />
            <token id="30" string="photographed" />
            <token id="31" string="dogs" />
            <token id="32" string="before" />
            <token id="33" string="," />
            <token id="34" string="but" />
            <token id="35" string="Man" />
            <token id="36" string="Ray" />
            <token id="37" string="was" />
            <token id="38" string="a" />
            <token id="39" string="perfect" />
            <token id="40" string="subject" />
            <token id="41" string="&quot;" />
            <token id="42" string="He" />
            <token id="43" string="was" />
            <token id="44" string="gray" />
            <token id="45" string="and" />
            <token id="46" string="neutral" />
          </tokens>
        </chunking>
        <chunking id="19" string="Weimaraners" type="NP">
          <tokens>
            <token id="4" string="Weimaraners" />
          </tokens>
        </chunking>
        <chunking id="20" string="photographed dogs before" type="VP">
          <tokens>
            <token id="30" string="photographed" />
            <token id="31" string="dogs" />
            <token id="32" string="before" />
          </tokens>
        </chunking>
        <chunking id="21" string="$ 35" type="NP">
          <tokens>
            <token id="25" string="$" />
            <token id="26" string="35" />
          </tokens>
        </chunking>
        <chunking id="22" string="that cost $ 35 Wegman had never photographed dogs before" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="cost" />
            <token id="25" string="$" />
            <token id="26" string="35" />
            <token id="27" string="Wegman" />
            <token id="28" string="had" />
            <token id="29" string="never" />
            <token id="30" string="photographed" />
            <token id="31" string="dogs" />
            <token id="32" string="before" />
          </tokens>
        </chunking>
        <chunking id="23" string="1970" type="NP">
          <tokens>
            <token id="7" string="1970" />
          </tokens>
        </chunking>
        <chunking id="24" string="gray and neutral" type="ADJP">
          <tokens>
            <token id="44" string="gray" />
            <token id="45" string="and" />
            <token id="46" string="neutral" />
          </tokens>
        </chunking>
        <chunking id="25" string="dogs" type="NP">
          <tokens>
            <token id="31" string="dogs" />
          </tokens>
        </chunking>
        <chunking id="26" string="bought a new video camera and Man Ray , a puppy that cost $ 35 Wegman had never photographed dogs before" type="VP">
          <tokens>
            <token id="12" string="bought" />
            <token id="13" string="a" />
            <token id="14" string="new" />
            <token id="15" string="video" />
            <token id="16" string="camera" />
            <token id="17" string="and" />
            <token id="18" string="Man" />
            <token id="19" string="Ray" />
            <token id="20" string="," />
            <token id="21" string="a" />
            <token id="22" string="puppy" />
            <token id="23" string="that" />
            <token id="24" string="cost" />
            <token id="25" string="$" />
            <token id="26" string="35" />
            <token id="27" string="Wegman" />
            <token id="28" string="had" />
            <token id="29" string="never" />
            <token id="30" string="photographed" />
            <token id="31" string="dogs" />
            <token id="32" string="before" />
          </tokens>
        </chunking>
        <chunking id="27" string="His life" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="life" />
          </tokens>
        </chunking>
        <chunking id="28" string="He" type="NP">
          <tokens>
            <token id="42" string="He" />
          </tokens>
        </chunking>
        <chunking id="29" string="`` He was gray and neutral" type="SBAR">
          <tokens>
            <token id="41" string="&quot;" />
            <token id="42" string="He" />
            <token id="43" string="was" />
            <token id="44" string="gray" />
            <token id="45" string="and" />
            <token id="46" string="neutral" />
          </tokens>
        </chunking>
        <chunking id="30" string="said" type="VP">
          <tokens>
            <token id="51" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">life</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">began</governor>
          <dependent id="2">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Weimaraners</governor>
          <dependent id="3">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">life</governor>
          <dependent id="4">Weimaraners</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="51">said</governor>
          <dependent id="5">began</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">1970</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">began</governor>
          <dependent id="7">1970</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">year</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">began</governor>
          <dependent id="10">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">bought</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">began</governor>
          <dependent id="12">bought</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">camera</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">camera</governor>
          <dependent id="14">new</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">camera</governor>
          <dependent id="15">video</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">bought</governor>
          <dependent id="16">camera</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">camera</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Ray</governor>
          <dependent id="18">Man</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">camera</governor>
          <dependent id="19">Ray</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">puppy</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">camera</governor>
          <dependent id="22">puppy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">cost</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">puppy</governor>
          <dependent id="24">cost</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="26">35</governor>
          <dependent id="25">$</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">cost</governor>
          <dependent id="26">35</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">cost</governor>
          <dependent id="27">Wegman</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="30">photographed</governor>
          <dependent id="28">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="30">photographed</governor>
          <dependent id="29">never</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="27">Wegman</governor>
          <dependent id="30">photographed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">photographed</governor>
          <dependent id="31">dogs</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">photographed</governor>
          <dependent id="32">before</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">bought</governor>
          <dependent id="34">but</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Ray</governor>
          <dependent id="35">Man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="40">subject</governor>
          <dependent id="36">Ray</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="40">subject</governor>
          <dependent id="37">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">subject</governor>
          <dependent id="38">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">subject</governor>
          <dependent id="39">perfect</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">bought</governor>
          <dependent id="40">subject</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="44">gray</governor>
          <dependent id="42">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="44">gray</governor>
          <dependent id="43">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="40">subject</governor>
          <dependent id="44">gray</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="44">gray</governor>
          <dependent id="45">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="44">gray</governor>
          <dependent id="46">neutral</dependent>
        </dependency>
        <dependency type="det">
          <governor id="50">artist</governor>
          <dependent id="49">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="51">said</governor>
          <dependent id="50">artist</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="51">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Man Ray" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Man" />
            <token id="19" string="Ray" />
          </tokens>
        </entity>
        <entity id="2" string="1970 , the year" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="1970" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="year" />
          </tokens>
        </entity>
        <entity id="3" string="Wegman" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Wegman" />
          </tokens>
        </entity>
        <entity id="4" string="$ 35" type="MONEY" score="0.0">
          <tokens>
            <token id="25" string="$" />
            <token id="26" string="35" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>&amp;quot;I could do him as a dog, a man, a sculpture, a character, a bat, a frog, an elephant, an Airedale, a dinosaur, a poodle.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="sculpture" lemma="sculpture" stem="sculptur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="character" lemma="character" stem="charact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="bat" lemma="bat" stem="bat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="frog" lemma="frog" stem="frog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="elephant" lemma="elephant" stem="eleph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Airedale" lemma="Airedale" stem="airedal" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="dinosaur" lemma="dinosaur" stem="dinosaur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="poodle" lemma="poodle" stem="poodl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (MD could) (VP (VB do) (NP (PRP him)) (PP (IN as) (NP (NP (DT a) (NN dog)) (, ,) (NP (DT a) (NN man)) (, ,) (NP (DT a) (NN sculpture)) (, ,) (NP (DT a) (NN character)) (, ,) (NP (DT a) (NN bat)) (, ,) (NP (DT a) (NN frog)) (, ,) (NP (DT an) (NN elephant)) (, ,) (NP (DT an) (NNP Airedale)) (, ,) (NP (DT a) (NN dinosaur)) (, ,) (NP (DT a) (NN poodle)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could do him as a dog , a man , a sculpture , a character , a bat , a frog , an elephant , an Airedale , a dinosaur , a poodle" type="VP">
          <tokens>
            <token id="3" string="could" />
            <token id="4" string="do" />
            <token id="5" string="him" />
            <token id="6" string="as" />
            <token id="7" string="a" />
            <token id="8" string="dog" />
            <token id="9" string="," />
            <token id="10" string="a" />
            <token id="11" string="man" />
            <token id="12" string="," />
            <token id="13" string="a" />
            <token id="14" string="sculpture" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="character" />
            <token id="18" string="," />
            <token id="19" string="a" />
            <token id="20" string="bat" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="frog" />
            <token id="24" string="," />
            <token id="25" string="an" />
            <token id="26" string="elephant" />
            <token id="27" string="," />
            <token id="28" string="an" />
            <token id="29" string="Airedale" />
            <token id="30" string="," />
            <token id="31" string="a" />
            <token id="32" string="dinosaur" />
            <token id="33" string="," />
            <token id="34" string="a" />
            <token id="35" string="poodle" />
          </tokens>
        </chunking>
        <chunking id="2" string="do him as a dog , a man , a sculpture , a character , a bat , a frog , an elephant , an Airedale , a dinosaur , a poodle" type="VP">
          <tokens>
            <token id="4" string="do" />
            <token id="5" string="him" />
            <token id="6" string="as" />
            <token id="7" string="a" />
            <token id="8" string="dog" />
            <token id="9" string="," />
            <token id="10" string="a" />
            <token id="11" string="man" />
            <token id="12" string="," />
            <token id="13" string="a" />
            <token id="14" string="sculpture" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="character" />
            <token id="18" string="," />
            <token id="19" string="a" />
            <token id="20" string="bat" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="frog" />
            <token id="24" string="," />
            <token id="25" string="an" />
            <token id="26" string="elephant" />
            <token id="27" string="," />
            <token id="28" string="an" />
            <token id="29" string="Airedale" />
            <token id="30" string="," />
            <token id="31" string="a" />
            <token id="32" string="dinosaur" />
            <token id="33" string="," />
            <token id="34" string="a" />
            <token id="35" string="poodle" />
          </tokens>
        </chunking>
        <chunking id="3" string="a dog , a man , a sculpture , a character , a bat , a frog , an elephant , an Airedale , a dinosaur , a poodle" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="dog" />
            <token id="9" string="," />
            <token id="10" string="a" />
            <token id="11" string="man" />
            <token id="12" string="," />
            <token id="13" string="a" />
            <token id="14" string="sculpture" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="character" />
            <token id="18" string="," />
            <token id="19" string="a" />
            <token id="20" string="bat" />
            <token id="21" string="," />
            <token id="22" string="a" />
            <token id="23" string="frog" />
            <token id="24" string="," />
            <token id="25" string="an" />
            <token id="26" string="elephant" />
            <token id="27" string="," />
            <token id="28" string="an" />
            <token id="29" string="Airedale" />
            <token id="30" string="," />
            <token id="31" string="a" />
            <token id="32" string="dinosaur" />
            <token id="33" string="," />
            <token id="34" string="a" />
            <token id="35" string="poodle" />
          </tokens>
        </chunking>
        <chunking id="4" string="a dinosaur" type="NP">
          <tokens>
            <token id="31" string="a" />
            <token id="32" string="dinosaur" />
          </tokens>
        </chunking>
        <chunking id="5" string="a poodle" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="poodle" />
          </tokens>
        </chunking>
        <chunking id="6" string="an Airedale" type="NP">
          <tokens>
            <token id="28" string="an" />
            <token id="29" string="Airedale" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="him" type="NP">
          <tokens>
            <token id="5" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="a sculpture" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="sculpture" />
          </tokens>
        </chunking>
        <chunking id="10" string="a bat" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="bat" />
          </tokens>
        </chunking>
        <chunking id="11" string="an elephant" type="NP">
          <tokens>
            <token id="25" string="an" />
            <token id="26" string="elephant" />
          </tokens>
        </chunking>
        <chunking id="12" string="a character" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="character" />
          </tokens>
        </chunking>
        <chunking id="13" string="a dog" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="dog" />
          </tokens>
        </chunking>
        <chunking id="14" string="a frog" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="frog" />
          </tokens>
        </chunking>
        <chunking id="15" string="a man" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="man" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">do</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">do</governor>
          <dependent id="3">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">do</governor>
          <dependent id="5">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">dog</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">dog</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">do</governor>
          <dependent id="8">dog</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">man</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">dog</governor>
          <dependent id="11">man</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">sculpture</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">dog</governor>
          <dependent id="14">sculpture</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">character</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">dog</governor>
          <dependent id="17">character</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">bat</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">dog</governor>
          <dependent id="20">bat</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">frog</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">dog</governor>
          <dependent id="23">frog</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">elephant</governor>
          <dependent id="25">an</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">dog</governor>
          <dependent id="26">elephant</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">Airedale</governor>
          <dependent id="28">an</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">dog</governor>
          <dependent id="29">Airedale</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">dinosaur</governor>
          <dependent id="31">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">dog</governor>
          <dependent id="32">dinosaur</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">poodle</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">dog</governor>
          <dependent id="35">poodle</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Airedale" type="MISC" score="0.0">
          <tokens>
            <token id="29" string="Airedale" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>I never got tired of him.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="tired" lemma="tire" stem="tire" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (ADVP (RB never)) (VP (VBD got) (ADJP (VBN tired) (PP (IN of) (NP (PRP him))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="got tired of him" type="VP">
          <tokens>
            <token id="3" string="got" />
            <token id="4" string="tired" />
            <token id="5" string="of" />
            <token id="6" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="tired of him" type="ADJP">
          <tokens>
            <token id="4" string="tired" />
            <token id="5" string="of" />
            <token id="6" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="him" type="NP">
          <tokens>
            <token id="6" string="him" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">got</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">got</governor>
          <dependent id="2">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">got</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">got</governor>
          <dependent id="4">tired</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">him</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">tired</governor>
          <dependent id="6">him</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>; A dog&amp;apost;s life; Had he been a different breed he would have been a &amp;quot;character actor,&amp;quot; Wegman said, &amp;quot;like Lassie.&amp;quot;</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="breed" lemma="breed" stem="breed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="character" lemma="character" stem="charact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="actor" lemma="actor" stem="actor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Wegman" lemma="Wegman" stem="wegman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="24" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Lassie" lemma="Lassie" stem="lassi" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRN (: ;) (NP (NP (DT A) (NN dog) (POS 's)) (NN life)) (: ;))) (VP (VBD Had) (NP (NP (PRP he)) (VP (VBN been) (NP (NP (DT a) (JJ different) (NN breed)) (SBAR (S (NP (PRP he)) (VP (MD would) (VP (VB have) (VP (VBN been) (NP (DT a) (`` ``) (NN character) (NN actor)))))))))))) (, ,) ('' '') (NP (NNP Wegman)) (VP (VBD said) (, ,) (S (`` ``) (PP (IN like) (NP (NNP Lassie))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="he would have been a `` character actor" type="SBAR">
          <tokens>
            <token id="13" string="he" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="been" />
            <token id="17" string="a" />
            <token id="18" string="&quot;" />
            <token id="19" string="character" />
            <token id="20" string="actor" />
          </tokens>
        </chunking>
        <chunking id="2" string="would have been a `` character actor" type="VP">
          <tokens>
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="been" />
            <token id="17" string="a" />
            <token id="18" string="&quot;" />
            <token id="19" string="character" />
            <token id="20" string="actor" />
          </tokens>
        </chunking>
        <chunking id="3" string="have been a `` character actor" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="been" />
            <token id="17" string="a" />
            <token id="18" string="&quot;" />
            <token id="19" string="character" />
            <token id="20" string="actor" />
          </tokens>
        </chunking>
        <chunking id="4" string="a different breed he would have been a `` character actor" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="different" />
            <token id="12" string="breed" />
            <token id="13" string="he" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="been" />
            <token id="17" string="a" />
            <token id="18" string="&quot;" />
            <token id="19" string="character" />
            <token id="20" string="actor" />
          </tokens>
        </chunking>
        <chunking id="5" string="A dog 's" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="dog" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lassie" type="NP">
          <tokens>
            <token id="28" string="Lassie" />
          </tokens>
        </chunking>
        <chunking id="7" string="he been a different breed he would have been a `` character actor" type="NP">
          <tokens>
            <token id="8" string="he" />
            <token id="9" string="been" />
            <token id="10" string="a" />
            <token id="11" string="different" />
            <token id="12" string="breed" />
            <token id="13" string="he" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="been" />
            <token id="17" string="a" />
            <token id="18" string="&quot;" />
            <token id="19" string="character" />
            <token id="20" string="actor" />
          </tokens>
        </chunking>
        <chunking id="8" string="been a different breed he would have been a `` character actor" type="VP">
          <tokens>
            <token id="9" string="been" />
            <token id="10" string="a" />
            <token id="11" string="different" />
            <token id="12" string="breed" />
            <token id="13" string="he" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="been" />
            <token id="17" string="a" />
            <token id="18" string="&quot;" />
            <token id="19" string="character" />
            <token id="20" string="actor" />
          </tokens>
        </chunking>
        <chunking id="9" string="said , `` like Lassie" type="VP">
          <tokens>
            <token id="24" string="said" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="like" />
            <token id="28" string="Lassie" />
          </tokens>
        </chunking>
        <chunking id="10" string="; A dog 's life ;" type="NP">
          <tokens>
            <token id="1" string=";" />
            <token id="2" string="A" />
            <token id="3" string="dog" />
            <token id="4" string="'s" />
            <token id="5" string="life" />
            <token id="6" string=";" />
          </tokens>
        </chunking>
        <chunking id="11" string="Wegman" type="NP">
          <tokens>
            <token id="23" string="Wegman" />
          </tokens>
        </chunking>
        <chunking id="12" string="A dog 's life" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="dog" />
            <token id="4" string="'s" />
            <token id="5" string="life" />
          </tokens>
        </chunking>
        <chunking id="13" string="a different breed" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="different" />
            <token id="12" string="breed" />
          </tokens>
        </chunking>
        <chunking id="14" string="been a `` character actor" type="VP">
          <tokens>
            <token id="16" string="been" />
            <token id="17" string="a" />
            <token id="18" string="&quot;" />
            <token id="19" string="character" />
            <token id="20" string="actor" />
          </tokens>
        </chunking>
        <chunking id="15" string="a `` character actor" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="&quot;" />
            <token id="19" string="character" />
            <token id="20" string="actor" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="Had he been a different breed he would have been a `` character actor" type="VP">
          <tokens>
            <token id="7" string="Had" />
            <token id="8" string="he" />
            <token id="9" string="been" />
            <token id="10" string="a" />
            <token id="11" string="different" />
            <token id="12" string="breed" />
            <token id="13" string="he" />
            <token id="14" string="would" />
            <token id="15" string="have" />
            <token id="16" string="been" />
            <token id="17" string="a" />
            <token id="18" string="&quot;" />
            <token id="19" string="character" />
            <token id="20" string="actor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">dog</governor>
          <dependent id="2">A</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">life</governor>
          <dependent id="3">dog</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">dog</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">Had</governor>
          <dependent id="5">life</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">said</governor>
          <dependent id="7">Had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">Had</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">breed</governor>
          <dependent id="9">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">breed</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">breed</governor>
          <dependent id="11">different</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">he</governor>
          <dependent id="12">breed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">actor</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">actor</governor>
          <dependent id="14">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">actor</governor>
          <dependent id="15">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">actor</governor>
          <dependent id="16">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">actor</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">actor</governor>
          <dependent id="19">character</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">breed</governor>
          <dependent id="20">actor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">said</governor>
          <dependent id="23">Wegman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Lassie</governor>
          <dependent id="27">like</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">said</governor>
          <dependent id="28">Lassie</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wegman" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Wegman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>; When Man Ray, who had become world famous, died of cancer in 1981, at the age of 11 years and 8 months, the artist mourned.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="become" lemma="become" stem="becom" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="famous" lemma="famous" stem="famou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="cancer" lemma="cancer" stem="cancer" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="1981" lemma="1981" stem="1981" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="age" lemma="age" stem="ag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="23" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="8" lemma="8" stem="8" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="26" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="artist" lemma="artist" stem="artist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="mourned" lemma="mourn" stem="mourn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (SBAR (WHADVP (WRB When)) (S (NP (NP (NN Man) (NNP Ray)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VBN become) (S (ADJP (NN world) (JJ famous))))))) (, ,)) (VP (VBD died) (PP (IN of) (NP (NN cancer))) (PP (IN in) (NP (CD 1981))) (, ,) (PP (IN at) (NP (NP (DT the) (NN age)) (PP (IN of) (NP (NP (CD 11) (NNS years)) (CC and) (NP (CD 8) (NNS months))))))))) (, ,) (NP (DT the) (NN artist)) (VP (VBD mourned)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Man Ray" type="NP">
          <tokens>
            <token id="3" string="Man" />
            <token id="4" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="2" string="the artist" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="artist" />
          </tokens>
        </chunking>
        <chunking id="3" string="11 years and 8 months" type="NP">
          <tokens>
            <token id="22" string="11" />
            <token id="23" string="years" />
            <token id="24" string="and" />
            <token id="25" string="8" />
            <token id="26" string="months" />
          </tokens>
        </chunking>
        <chunking id="4" string="8 months" type="NP">
          <tokens>
            <token id="25" string="8" />
            <token id="26" string="months" />
          </tokens>
        </chunking>
        <chunking id="5" string="cancer" type="NP">
          <tokens>
            <token id="14" string="cancer" />
          </tokens>
        </chunking>
        <chunking id="6" string="the age" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="age" />
          </tokens>
        </chunking>
        <chunking id="7" string="become world famous" type="VP">
          <tokens>
            <token id="8" string="become" />
            <token id="9" string="world" />
            <token id="10" string="famous" />
          </tokens>
        </chunking>
        <chunking id="8" string="11 years" type="NP">
          <tokens>
            <token id="22" string="11" />
            <token id="23" string="years" />
          </tokens>
        </chunking>
        <chunking id="9" string="world famous" type="ADJP">
          <tokens>
            <token id="9" string="world" />
            <token id="10" string="famous" />
          </tokens>
        </chunking>
        <chunking id="10" string="the age of 11 years and 8 months" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="age" />
            <token id="21" string="of" />
            <token id="22" string="11" />
            <token id="23" string="years" />
            <token id="24" string="and" />
            <token id="25" string="8" />
            <token id="26" string="months" />
          </tokens>
        </chunking>
        <chunking id="11" string="When" type="WHADVP">
          <tokens>
            <token id="2" string="When" />
          </tokens>
        </chunking>
        <chunking id="12" string="Man Ray , who had become world famous ," type="NP">
          <tokens>
            <token id="3" string="Man" />
            <token id="4" string="Ray" />
            <token id="5" string="," />
            <token id="6" string="who" />
            <token id="7" string="had" />
            <token id="8" string="become" />
            <token id="9" string="world" />
            <token id="10" string="famous" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="When Man Ray , who had become world famous , died of cancer in 1981 , at the age of 11 years and 8 months" type="SBAR">
          <tokens>
            <token id="2" string="When" />
            <token id="3" string="Man" />
            <token id="4" string="Ray" />
            <token id="5" string="," />
            <token id="6" string="who" />
            <token id="7" string="had" />
            <token id="8" string="become" />
            <token id="9" string="world" />
            <token id="10" string="famous" />
            <token id="11" string="," />
            <token id="12" string="died" />
            <token id="13" string="of" />
            <token id="14" string="cancer" />
            <token id="15" string="in" />
            <token id="16" string="1981" />
            <token id="17" string="," />
            <token id="18" string="at" />
            <token id="19" string="the" />
            <token id="20" string="age" />
            <token id="21" string="of" />
            <token id="22" string="11" />
            <token id="23" string="years" />
            <token id="24" string="and" />
            <token id="25" string="8" />
            <token id="26" string="months" />
          </tokens>
        </chunking>
        <chunking id="14" string="1981" type="NP">
          <tokens>
            <token id="16" string="1981" />
          </tokens>
        </chunking>
        <chunking id="15" string="who had become world famous" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="had" />
            <token id="8" string="become" />
            <token id="9" string="world" />
            <token id="10" string="famous" />
          </tokens>
        </chunking>
        <chunking id="16" string="died of cancer in 1981 , at the age of 11 years and 8 months" type="VP">
          <tokens>
            <token id="12" string="died" />
            <token id="13" string="of" />
            <token id="14" string="cancer" />
            <token id="15" string="in" />
            <token id="16" string="1981" />
            <token id="17" string="," />
            <token id="18" string="at" />
            <token id="19" string="the" />
            <token id="20" string="age" />
            <token id="21" string="of" />
            <token id="22" string="11" />
            <token id="23" string="years" />
            <token id="24" string="and" />
            <token id="25" string="8" />
            <token id="26" string="months" />
          </tokens>
        </chunking>
        <chunking id="17" string="mourned" type="VP">
          <tokens>
            <token id="30" string="mourned" />
          </tokens>
        </chunking>
        <chunking id="18" string="had become world famous" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="become" />
            <token id="9" string="world" />
            <token id="10" string="famous" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="12">died</governor>
          <dependent id="2">When</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Ray</governor>
          <dependent id="3">Man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">died</governor>
          <dependent id="4">Ray</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">become</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">become</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">Ray</governor>
          <dependent id="8">become</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="10">famous</governor>
          <dependent id="9">world</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">become</governor>
          <dependent id="10">famous</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="30">mourned</governor>
          <dependent id="12">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">cancer</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">died</governor>
          <dependent id="14">cancer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">1981</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">died</governor>
          <dependent id="16">1981</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">age</governor>
          <dependent id="18">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">age</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">died</governor>
          <dependent id="20">age</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">years</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">years</governor>
          <dependent id="22">11</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">age</governor>
          <dependent id="23">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">years</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">months</governor>
          <dependent id="25">8</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">years</governor>
          <dependent id="26">months</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">artist</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">mourned</governor>
          <dependent id="29">artist</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">mourned</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Man Ray" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Man" />
            <token id="4" string="Ray" />
          </tokens>
        </entity>
        <entity id="2" string="8 months" type="DURATION" score="0.0">
          <tokens>
            <token id="25" string="8" />
            <token id="26" string="months" />
          </tokens>
        </entity>
        <entity id="3" string="cancer" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="14" string="cancer" />
          </tokens>
        </entity>
        <entity id="4" string="1981" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="1981" />
          </tokens>
        </entity>
        <entity id="5" string="11 years" type="DURATION" score="0.0">
          <tokens>
            <token id="22" string="11" />
            <token id="23" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>&amp;quot;I dreamed that he came back to life,&amp;quot; said Wegman, who spent three years living without a dog.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="dreamed" lemma="dream" stem="dream" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Wegman" lemma="Wegman" stem="wegman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="spent" lemma="spend" stem="spent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="true" />
        <token id="18" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="true" />
        <token id="19" string="living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="20" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="22" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (VBD dreamed) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD came) (ADVP (RB back)) (PP (TO to) (NP (NN life)))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Wegman)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD spent) (NP (NP (CD three) (NNS years)) (VP (VBG living) (PP (IN without) (NP (DT a) (NN dog))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who spent three years living without a dog" type="SBAR">
          <tokens>
            <token id="15" string="who" />
            <token id="16" string="spent" />
            <token id="17" string="three" />
            <token id="18" string="years" />
            <token id="19" string="living" />
            <token id="20" string="without" />
            <token id="21" string="a" />
            <token id="22" string="dog" />
          </tokens>
        </chunking>
        <chunking id="2" string="three years" type="NP">
          <tokens>
            <token id="17" string="three" />
            <token id="18" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="that he came back to life" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="he" />
            <token id="6" string="came" />
            <token id="7" string="back" />
            <token id="8" string="to" />
            <token id="9" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="three years living without a dog" type="NP">
          <tokens>
            <token id="17" string="three" />
            <token id="18" string="years" />
            <token id="19" string="living" />
            <token id="20" string="without" />
            <token id="21" string="a" />
            <token id="22" string="dog" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="life" type="NP">
          <tokens>
            <token id="9" string="life" />
          </tokens>
        </chunking>
        <chunking id="7" string="living without a dog" type="VP">
          <tokens>
            <token id="19" string="living" />
            <token id="20" string="without" />
            <token id="21" string="a" />
            <token id="22" string="dog" />
          </tokens>
        </chunking>
        <chunking id="8" string="came back to life" type="VP">
          <tokens>
            <token id="6" string="came" />
            <token id="7" string="back" />
            <token id="8" string="to" />
            <token id="9" string="life" />
          </tokens>
        </chunking>
        <chunking id="9" string="Wegman" type="NP">
          <tokens>
            <token id="13" string="Wegman" />
          </tokens>
        </chunking>
        <chunking id="10" string="Wegman , who spent three years living without a dog" type="NP">
          <tokens>
            <token id="13" string="Wegman" />
            <token id="14" string="," />
            <token id="15" string="who" />
            <token id="16" string="spent" />
            <token id="17" string="three" />
            <token id="18" string="years" />
            <token id="19" string="living" />
            <token id="20" string="without" />
            <token id="21" string="a" />
            <token id="22" string="dog" />
          </tokens>
        </chunking>
        <chunking id="11" string="a dog" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="dog" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="spent three years living without a dog" type="VP">
          <tokens>
            <token id="16" string="spent" />
            <token id="17" string="three" />
            <token id="18" string="years" />
            <token id="19" string="living" />
            <token id="20" string="without" />
            <token id="21" string="a" />
            <token id="22" string="dog" />
          </tokens>
        </chunking>
        <chunking id="14" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="15" string="dreamed that he came back to life" type="VP">
          <tokens>
            <token id="3" string="dreamed" />
            <token id="4" string="that" />
            <token id="5" string="he" />
            <token id="6" string="came" />
            <token id="7" string="back" />
            <token id="8" string="to" />
            <token id="9" string="life" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">dreamed</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="3">dreamed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">came</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">came</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">dreamed</governor>
          <dependent id="6">came</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">came</governor>
          <dependent id="7">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">life</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">came</governor>
          <dependent id="9">life</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="13">Wegman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">spent</governor>
          <dependent id="15">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">Wegman</governor>
          <dependent id="16">spent</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">years</governor>
          <dependent id="17">three</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">spent</governor>
          <dependent id="18">years</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="18">years</governor>
          <dependent id="19">living</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">dog</governor>
          <dependent id="20">without</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">dog</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">living</governor>
          <dependent id="22">dog</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="three years" type="DURATION" score="0.0">
          <tokens>
            <token id="17" string="three" />
            <token id="18" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="Wegman" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Wegman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>&amp;quot;It was kind of liberating, the years I didn&amp;apost;t have a dog.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="liberating" lemma="liberating" stem="liber" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="9" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP It)) (VP (VBD was) (ADJP (ADVP (NN kind) (IN of)) (JJ liberating)))) (, ,) (S (NP-TMP (DT the) (NNS years)) (NP (PRP I)) (VP (VBD did) (RB n't) (VP (VB have) (NP (DT a) (NN dog))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="kind of liberating" type="ADJP">
          <tokens>
            <token id="4" string="kind" />
            <token id="5" string="of" />
            <token id="6" string="liberating" />
          </tokens>
        </chunking>
        <chunking id="2" string="have a dog" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="a" />
            <token id="15" string="dog" />
          </tokens>
        </chunking>
        <chunking id="3" string="did n't have a dog" type="VP">
          <tokens>
            <token id="11" string="did" />
            <token id="12" string="n't" />
            <token id="13" string="have" />
            <token id="14" string="a" />
            <token id="15" string="dog" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="10" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="was kind of liberating" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="kind" />
            <token id="5" string="of" />
            <token id="6" string="liberating" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="a dog" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="dog" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">liberating</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">liberating</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">liberating</governor>
          <dependent id="4">kind</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="4">kind</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">liberating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">years</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">have</governor>
          <dependent id="9">years</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">have</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">have</governor>
          <dependent id="11">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">have</governor>
          <dependent id="12">n't</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">liberating</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">dog</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">have</governor>
          <dependent id="15">dog</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the years" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>; In 1984, however, he got another Weimaraner, which was stolen.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Weimaraner" lemma="Weimaraner" stem="weimaran" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="stolen" lemma="steal" stem="stolen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (PP (IN In) (NP (CD 1984))) (, ,) (ADVP (RB however)) (, ,) (NP (PRP he)) (VP (VBD got) (NP (NP (DT another) (NNP Weimaraner)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (VP (VBN stolen))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="got another Weimaraner , which was stolen" type="VP">
          <tokens>
            <token id="8" string="got" />
            <token id="9" string="another" />
            <token id="10" string="Weimaraner" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="was" />
            <token id="14" string="stolen" />
          </tokens>
        </chunking>
        <chunking id="2" string="stolen" type="VP">
          <tokens>
            <token id="14" string="stolen" />
          </tokens>
        </chunking>
        <chunking id="3" string="1984" type="NP">
          <tokens>
            <token id="3" string="1984" />
          </tokens>
        </chunking>
        <chunking id="4" string="another Weimaraner" type="NP">
          <tokens>
            <token id="9" string="another" />
            <token id="10" string="Weimaraner" />
          </tokens>
        </chunking>
        <chunking id="5" string="another Weimaraner , which was stolen" type="NP">
          <tokens>
            <token id="9" string="another" />
            <token id="10" string="Weimaraner" />
            <token id="11" string="," />
            <token id="12" string="which" />
            <token id="13" string="was" />
            <token id="14" string="stolen" />
          </tokens>
        </chunking>
        <chunking id="6" string="was stolen" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="stolen" />
          </tokens>
        </chunking>
        <chunking id="7" string="which was stolen" type="SBAR">
          <tokens>
            <token id="12" string="which" />
            <token id="13" string="was" />
            <token id="14" string="stolen" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">1984</governor>
          <dependent id="2">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">got</governor>
          <dependent id="3">1984</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">got</governor>
          <dependent id="5">however</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">got</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">got</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Weimaraner</governor>
          <dependent id="9">another</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">got</governor>
          <dependent id="10">Weimaraner</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">stolen</governor>
          <dependent id="12">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">stolen</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">Weimaraner</governor>
          <dependent id="14">stolen</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="1984" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Yet another dog died of Parvo, a virus.</content>
      <tokens>
        <token id="1" string="Yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Parvo" lemma="Parvo" stem="parvo" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="virus" lemma="virus" stem="viru" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Yet) (NP (DT another) (NN dog)) (VP (VBD died) (PP (IN of) (NP (NP (NNP Parvo)) (, ,) (NP (DT a) (NN virus))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="died of Parvo , a virus" type="VP">
          <tokens>
            <token id="4" string="died" />
            <token id="5" string="of" />
            <token id="6" string="Parvo" />
            <token id="7" string="," />
            <token id="8" string="a" />
            <token id="9" string="virus" />
          </tokens>
        </chunking>
        <chunking id="2" string="a virus" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="virus" />
          </tokens>
        </chunking>
        <chunking id="3" string="another dog" type="NP">
          <tokens>
            <token id="2" string="another" />
            <token id="3" string="dog" />
          </tokens>
        </chunking>
        <chunking id="4" string="Parvo" type="NP">
          <tokens>
            <token id="6" string="Parvo" />
          </tokens>
        </chunking>
        <chunking id="5" string="Parvo , a virus" type="NP">
          <tokens>
            <token id="6" string="Parvo" />
            <token id="7" string="," />
            <token id="8" string="a" />
            <token id="9" string="virus" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">died</governor>
          <dependent id="1">Yet</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">dog</governor>
          <dependent id="2">another</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">died</governor>
          <dependent id="3">dog</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Parvo</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">died</governor>
          <dependent id="6">Parvo</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">virus</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="6">Parvo</governor>
          <dependent id="9">virus</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>In 1985, he got Fay Ray, who is now a familiar face not only among artists but among children who watch &amp;quot;Sesame Street.&amp;quot;</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Fay" lemma="Fay" stem="fai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="familiar" lemma="familiar" stem="familiar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="face" lemma="face" stem="face" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="artists" lemma="artist" stem="artist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="watch" lemma="watch" stem="watch" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="Sesame" lemma="Sesame" stem="sesam" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="Street" lemma="Street" stem="street" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (CD 1985))) (, ,) (NP (PRP he)) (VP (VBD got) (NP (NP (NNP Fay) (NNP Ray)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (ADVP (RB now)) (NP (DT a) (JJ familiar) (NN face)) (PP (CONJP (RB not) (RB only)) (PP (IN among) (NP (NNS artists))) (CC but) (PP (IN among) (NP (NP (NNS children)) (SBAR (WHNP (WP who)) (S (VP (VBP watch) (S (`` ``) (NP (NNP Sesame) (NNP Street)))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="got Fay Ray , who is now a familiar face not only among artists but among children who watch `` Sesame Street" type="VP">
          <tokens>
            <token id="5" string="got" />
            <token id="6" string="Fay" />
            <token id="7" string="Ray" />
            <token id="8" string="," />
            <token id="9" string="who" />
            <token id="10" string="is" />
            <token id="11" string="now" />
            <token id="12" string="a" />
            <token id="13" string="familiar" />
            <token id="14" string="face" />
            <token id="15" string="not" />
            <token id="16" string="only" />
            <token id="17" string="among" />
            <token id="18" string="artists" />
            <token id="19" string="but" />
            <token id="20" string="among" />
            <token id="21" string="children" />
            <token id="22" string="who" />
            <token id="23" string="watch" />
            <token id="24" string="&quot;" />
            <token id="25" string="Sesame" />
            <token id="26" string="Street" />
          </tokens>
        </chunking>
        <chunking id="2" string="a familiar face" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="familiar" />
            <token id="14" string="face" />
          </tokens>
        </chunking>
        <chunking id="3" string="who watch `` Sesame Street" type="SBAR">
          <tokens>
            <token id="22" string="who" />
            <token id="23" string="watch" />
            <token id="24" string="&quot;" />
            <token id="25" string="Sesame" />
            <token id="26" string="Street" />
          </tokens>
        </chunking>
        <chunking id="4" string="artists" type="NP">
          <tokens>
            <token id="18" string="artists" />
          </tokens>
        </chunking>
        <chunking id="5" string="1985" type="NP">
          <tokens>
            <token id="2" string="1985" />
          </tokens>
        </chunking>
        <chunking id="6" string="watch `` Sesame Street" type="VP">
          <tokens>
            <token id="23" string="watch" />
            <token id="24" string="&quot;" />
            <token id="25" string="Sesame" />
            <token id="26" string="Street" />
          </tokens>
        </chunking>
        <chunking id="7" string="Fay Ray" type="NP">
          <tokens>
            <token id="6" string="Fay" />
            <token id="7" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="8" string="children" type="NP">
          <tokens>
            <token id="21" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="children who watch `` Sesame Street" type="NP">
          <tokens>
            <token id="21" string="children" />
            <token id="22" string="who" />
            <token id="23" string="watch" />
            <token id="24" string="&quot;" />
            <token id="25" string="Sesame" />
            <token id="26" string="Street" />
          </tokens>
        </chunking>
        <chunking id="10" string="Sesame Street" type="NP">
          <tokens>
            <token id="25" string="Sesame" />
            <token id="26" string="Street" />
          </tokens>
        </chunking>
        <chunking id="11" string="who is now a familiar face not only among artists but among children who watch `` Sesame Street" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="is" />
            <token id="11" string="now" />
            <token id="12" string="a" />
            <token id="13" string="familiar" />
            <token id="14" string="face" />
            <token id="15" string="not" />
            <token id="16" string="only" />
            <token id="17" string="among" />
            <token id="18" string="artists" />
            <token id="19" string="but" />
            <token id="20" string="among" />
            <token id="21" string="children" />
            <token id="22" string="who" />
            <token id="23" string="watch" />
            <token id="24" string="&quot;" />
            <token id="25" string="Sesame" />
            <token id="26" string="Street" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="is now a familiar face not only among artists but among children who watch `` Sesame Street" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="now" />
            <token id="12" string="a" />
            <token id="13" string="familiar" />
            <token id="14" string="face" />
            <token id="15" string="not" />
            <token id="16" string="only" />
            <token id="17" string="among" />
            <token id="18" string="artists" />
            <token id="19" string="but" />
            <token id="20" string="among" />
            <token id="21" string="children" />
            <token id="22" string="who" />
            <token id="23" string="watch" />
            <token id="24" string="&quot;" />
            <token id="25" string="Sesame" />
            <token id="26" string="Street" />
          </tokens>
        </chunking>
        <chunking id="14" string="Fay Ray , who is now a familiar face not only among artists but among children who watch `` Sesame Street" type="NP">
          <tokens>
            <token id="6" string="Fay" />
            <token id="7" string="Ray" />
            <token id="8" string="," />
            <token id="9" string="who" />
            <token id="10" string="is" />
            <token id="11" string="now" />
            <token id="12" string="a" />
            <token id="13" string="familiar" />
            <token id="14" string="face" />
            <token id="15" string="not" />
            <token id="16" string="only" />
            <token id="17" string="among" />
            <token id="18" string="artists" />
            <token id="19" string="but" />
            <token id="20" string="among" />
            <token id="21" string="children" />
            <token id="22" string="who" />
            <token id="23" string="watch" />
            <token id="24" string="&quot;" />
            <token id="25" string="Sesame" />
            <token id="26" string="Street" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1985</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">got</governor>
          <dependent id="2">1985</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">got</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">got</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Ray</governor>
          <dependent id="6">Fay</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">got</governor>
          <dependent id="7">Ray</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">face</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">face</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">face</governor>
          <dependent id="11">now</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">face</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">face</governor>
          <dependent id="13">familiar</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">Ray</governor>
          <dependent id="14">face</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">face</governor>
          <dependent id="14">face</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">only</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="18">artists</governor>
          <dependent id="16">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">artists</governor>
          <dependent id="17">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">face</governor>
          <dependent id="18">artists</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">face</governor>
          <dependent id="19">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">children</governor>
          <dependent id="20">among</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">face</governor>
          <dependent id="21">children</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">watch</governor>
          <dependent id="22">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">children</governor>
          <dependent id="23">watch</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Street</governor>
          <dependent id="25">Sesame</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">watch</governor>
          <dependent id="26">Street</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1985" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1985" />
          </tokens>
        </entity>
        <entity id="2" string="Fay Ray" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Fay" />
            <token id="7" string="Ray" />
          </tokens>
        </entity>
        <entity id="3" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>; As a breed, Weimaraners combine &amp;quot;a lap-dog sensibility with a hunting capability,&amp;quot; the artist said.</content>
      <tokens>
        <token id="1" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="breed" lemma="breed" stem="breed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Weimaraners" lemma="weimaraner" stem="weimaran" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="combine" lemma="combine" stem="combin" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="lap-dog" lemma="lap-dog" stem="lap-dog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="sensibility" lemma="sensibility" stem="sensibl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="hunting" lemma="hunting" stem="hunt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="capability" lemma="capability" stem="capabl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="artist" lemma="artist" stem="artist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ;) (PP (IN As) (NP (DT a) (NN breed))) (, ,) (S (NP (NNS Weimaraners)) (VP (VBP combine) (`` ``) (NP (NP (DT a) (NN lap-dog) (NN sensibility)) (PP (IN with) (NP (DT a) (NN hunting) (NN capability)))))) (, ,) ('' '') (NP (DT the) (NN artist)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the artist" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="artist" />
          </tokens>
        </chunking>
        <chunking id="2" string="a lap-dog sensibility" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="lap-dog" />
            <token id="11" string="sensibility" />
          </tokens>
        </chunking>
        <chunking id="3" string="a breed" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="breed" />
          </tokens>
        </chunking>
        <chunking id="4" string="Weimaraners" type="NP">
          <tokens>
            <token id="6" string="Weimaraners" />
          </tokens>
        </chunking>
        <chunking id="5" string="a hunting capability" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="hunting" />
            <token id="15" string="capability" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
        <chunking id="7" string="a lap-dog sensibility with a hunting capability" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="lap-dog" />
            <token id="11" string="sensibility" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string="hunting" />
            <token id="15" string="capability" />
          </tokens>
        </chunking>
        <chunking id="8" string="combine `` a lap-dog sensibility with a hunting capability" type="VP">
          <tokens>
            <token id="7" string="combine" />
            <token id="8" string="&quot;" />
            <token id="9" string="a" />
            <token id="10" string="lap-dog" />
            <token id="11" string="sensibility" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string="hunting" />
            <token id="15" string="capability" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">breed</governor>
          <dependent id="2">As</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">breed</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">said</governor>
          <dependent id="4">breed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">combine</governor>
          <dependent id="6">Weimaraners</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="7">combine</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">sensibility</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">sensibility</governor>
          <dependent id="10">lap-dog</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">combine</governor>
          <dependent id="11">sensibility</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">capability</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">capability</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">capability</governor>
          <dependent id="14">hunting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">sensibility</governor>
          <dependent id="15">capability</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">artist</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">artist</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>They curl up on his lap, but since they are pointers, they can hold a pose They are also good companions for an artist.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="curl" lemma="curl" stem="curl" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="lap" lemma="lap" stem="lap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="pointers" lemma="pointer" stem="pointer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="hold" lemma="hold" stem="hold" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="pose" lemma="pose" stem="pose" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="companions" lemma="companion" stem="companion" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="artist" lemma="artist" stem="artist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP They)) (VP (VBP curl) (PRT (RP up)) (PP (IN on) (NP (PRP$ his) (NN lap))))) (, ,) (CC but) (S (SBAR (IN since) (S (NP (PRP they)) (VP (VBP are) (NP (NNS pointers))))) (, ,) (NP (PRP they)) (VP (MD can) (VP (VB hold) (S (NP (DT a)) (VP (VB pose) (SBAR (S (NP (PRP They)) (VP (VBP are) (ADVP (RB also)) (NP (NP (JJ good) (NNS companions)) (PP (IN for) (NP (DT an) (NN artist)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="a" type="NP">
          <tokens>
            <token id="17" string="a" />
          </tokens>
        </chunking>
        <chunking id="3" string="an artist" type="NP">
          <tokens>
            <token id="25" string="an" />
            <token id="26" string="artist" />
          </tokens>
        </chunking>
        <chunking id="4" string="are also good companions for an artist" type="VP">
          <tokens>
            <token id="20" string="are" />
            <token id="21" string="also" />
            <token id="22" string="good" />
            <token id="23" string="companions" />
            <token id="24" string="for" />
            <token id="25" string="an" />
            <token id="26" string="artist" />
          </tokens>
        </chunking>
        <chunking id="5" string="good companions for an artist" type="NP">
          <tokens>
            <token id="22" string="good" />
            <token id="23" string="companions" />
            <token id="24" string="for" />
            <token id="25" string="an" />
            <token id="26" string="artist" />
          </tokens>
        </chunking>
        <chunking id="6" string="good companions" type="NP">
          <tokens>
            <token id="22" string="good" />
            <token id="23" string="companions" />
          </tokens>
        </chunking>
        <chunking id="7" string="curl up on his lap" type="VP">
          <tokens>
            <token id="2" string="curl" />
            <token id="3" string="up" />
            <token id="4" string="on" />
            <token id="5" string="his" />
            <token id="6" string="lap" />
          </tokens>
        </chunking>
        <chunking id="8" string="since they are pointers" type="SBAR">
          <tokens>
            <token id="9" string="since" />
            <token id="10" string="they" />
            <token id="11" string="are" />
            <token id="12" string="pointers" />
          </tokens>
        </chunking>
        <chunking id="9" string="They are also good companions for an artist" type="SBAR">
          <tokens>
            <token id="19" string="They" />
            <token id="20" string="are" />
            <token id="21" string="also" />
            <token id="22" string="good" />
            <token id="23" string="companions" />
            <token id="24" string="for" />
            <token id="25" string="an" />
            <token id="26" string="artist" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="10" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="can hold a pose They are also good companions for an artist" type="VP">
          <tokens>
            <token id="15" string="can" />
            <token id="16" string="hold" />
            <token id="17" string="a" />
            <token id="18" string="pose" />
            <token id="19" string="They" />
            <token id="20" string="are" />
            <token id="21" string="also" />
            <token id="22" string="good" />
            <token id="23" string="companions" />
            <token id="24" string="for" />
            <token id="25" string="an" />
            <token id="26" string="artist" />
          </tokens>
        </chunking>
        <chunking id="12" string="his lap" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="lap" />
          </tokens>
        </chunking>
        <chunking id="13" string="are pointers" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="pointers" />
          </tokens>
        </chunking>
        <chunking id="14" string="hold a pose They are also good companions for an artist" type="VP">
          <tokens>
            <token id="16" string="hold" />
            <token id="17" string="a" />
            <token id="18" string="pose" />
            <token id="19" string="They" />
            <token id="20" string="are" />
            <token id="21" string="also" />
            <token id="22" string="good" />
            <token id="23" string="companions" />
            <token id="24" string="for" />
            <token id="25" string="an" />
            <token id="26" string="artist" />
          </tokens>
        </chunking>
        <chunking id="15" string="pose They are also good companions for an artist" type="VP">
          <tokens>
            <token id="18" string="pose" />
            <token id="19" string="They" />
            <token id="20" string="are" />
            <token id="21" string="also" />
            <token id="22" string="good" />
            <token id="23" string="companions" />
            <token id="24" string="for" />
            <token id="25" string="an" />
            <token id="26" string="artist" />
          </tokens>
        </chunking>
        <chunking id="16" string="pointers" type="NP">
          <tokens>
            <token id="12" string="pointers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">curl</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">curl</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="2">curl</governor>
          <dependent id="3">up</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">lap</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">lap</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">curl</governor>
          <dependent id="6">lap</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">curl</governor>
          <dependent id="8">but</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">pointers</governor>
          <dependent id="9">since</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">pointers</governor>
          <dependent id="10">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">pointers</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">hold</governor>
          <dependent id="12">pointers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">hold</governor>
          <dependent id="14">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">hold</governor>
          <dependent id="15">can</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">curl</governor>
          <dependent id="16">hold</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">pose</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">hold</governor>
          <dependent id="18">pose</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">companions</governor>
          <dependent id="19">They</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="23">companions</governor>
          <dependent id="20">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">companions</governor>
          <dependent id="21">also</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">companions</governor>
          <dependent id="22">good</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">pose</governor>
          <dependent id="23">companions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">artist</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">artist</governor>
          <dependent id="25">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">companions</governor>
          <dependent id="26">artist</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>They are affectionate.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="affectionate" lemma="affectionate" stem="affection" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP are) (ADJP (JJ affectionate))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="are affectionate" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="affectionate" />
          </tokens>
        </chunking>
        <chunking id="3" string="affectionate" type="ADJP">
          <tokens>
            <token id="3" string="affectionate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">affectionate</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">affectionate</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">affectionate</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>They do not drool.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="drool" lemma="drool" stem="drool" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP do) (RB not) (VP (VB drool))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="do not drool" type="VP">
          <tokens>
            <token id="2" string="do" />
            <token id="3" string="not" />
            <token id="4" string="drool" />
          </tokens>
        </chunking>
        <chunking id="3" string="drool" type="VP">
          <tokens>
            <token id="4" string="drool" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">drool</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">drool</governor>
          <dependent id="2">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">drool</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">drool</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>They have style Like world-famous fashion models, these dogs are lean, supple and fit.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="style" lemma="style" stem="style" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="world-famous" lemma="world-famous" stem="world-fam" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="fashion" lemma="fashion" stem="fashion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="models" lemma="model" stem="model" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="dogs" lemma="dog" stem="dog" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="lean" lemma="lean" stem="lean" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="supple" lemma="supple" stem="suppl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="fit" lemma="fit" stem="fit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP have) (NP (NP (NN style)) (SBAR (S (PP (IN Like) (NP (JJ world-famous) (NN fashion) (NNS models))) (, ,) (NP (DT these) (NNS dogs)) (VP (VBP are) (UCP (ADJP (JJ lean) (, ,) (JJ supple)) (CC and) (NP (NN fit)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="have style Like world-famous fashion models , these dogs are lean , supple and fit" type="VP">
          <tokens>
            <token id="2" string="have" />
            <token id="3" string="style" />
            <token id="4" string="Like" />
            <token id="5" string="world-famous" />
            <token id="6" string="fashion" />
            <token id="7" string="models" />
            <token id="8" string="," />
            <token id="9" string="these" />
            <token id="10" string="dogs" />
            <token id="11" string="are" />
            <token id="12" string="lean" />
            <token id="13" string="," />
            <token id="14" string="supple" />
            <token id="15" string="and" />
            <token id="16" string="fit" />
          </tokens>
        </chunking>
        <chunking id="3" string="these dogs" type="NP">
          <tokens>
            <token id="9" string="these" />
            <token id="10" string="dogs" />
          </tokens>
        </chunking>
        <chunking id="4" string="fit" type="NP">
          <tokens>
            <token id="16" string="fit" />
          </tokens>
        </chunking>
        <chunking id="5" string="style Like world-famous fashion models , these dogs are lean , supple and fit" type="NP">
          <tokens>
            <token id="3" string="style" />
            <token id="4" string="Like" />
            <token id="5" string="world-famous" />
            <token id="6" string="fashion" />
            <token id="7" string="models" />
            <token id="8" string="," />
            <token id="9" string="these" />
            <token id="10" string="dogs" />
            <token id="11" string="are" />
            <token id="12" string="lean" />
            <token id="13" string="," />
            <token id="14" string="supple" />
            <token id="15" string="and" />
            <token id="16" string="fit" />
          </tokens>
        </chunking>
        <chunking id="6" string="are lean , supple and fit" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="lean" />
            <token id="13" string="," />
            <token id="14" string="supple" />
            <token id="15" string="and" />
            <token id="16" string="fit" />
          </tokens>
        </chunking>
        <chunking id="7" string="lean , supple" type="ADJP">
          <tokens>
            <token id="12" string="lean" />
            <token id="13" string="," />
            <token id="14" string="supple" />
          </tokens>
        </chunking>
        <chunking id="8" string="style" type="NP">
          <tokens>
            <token id="3" string="style" />
          </tokens>
        </chunking>
        <chunking id="9" string="Like world-famous fashion models , these dogs are lean , supple and fit" type="SBAR">
          <tokens>
            <token id="4" string="Like" />
            <token id="5" string="world-famous" />
            <token id="6" string="fashion" />
            <token id="7" string="models" />
            <token id="8" string="," />
            <token id="9" string="these" />
            <token id="10" string="dogs" />
            <token id="11" string="are" />
            <token id="12" string="lean" />
            <token id="13" string="," />
            <token id="14" string="supple" />
            <token id="15" string="and" />
            <token id="16" string="fit" />
          </tokens>
        </chunking>
        <chunking id="10" string="world-famous fashion models" type="NP">
          <tokens>
            <token id="5" string="world-famous" />
            <token id="6" string="fashion" />
            <token id="7" string="models" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">have</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">have</governor>
          <dependent id="3">style</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">models</governor>
          <dependent id="4">Like</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">models</governor>
          <dependent id="5">world-famous</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">models</governor>
          <dependent id="6">fashion</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">supple</governor>
          <dependent id="7">models</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">dogs</governor>
          <dependent id="9">these</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">supple</governor>
          <dependent id="10">dogs</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">supple</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">supple</governor>
          <dependent id="12">lean</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">style</governor>
          <dependent id="14">supple</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">supple</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">supple</governor>
          <dependent id="16">fit</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>In Wegman&amp;apost;s home, which comprises 2,000 square feet with 20-foot-high ceilings, they live a life unencumbered -- one assumes -- by thoughts of fame or fortune, and seldom hunger Each morning Wegman feeds them Eukanuba dog food, which he considers the best around.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Wegman" lemma="Wegman" stem="wegman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="comprises" lemma="comprise" stem="compris" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="2,000" lemma="2,000" stem="2,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="square" lemma="square" stem="squar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="feet" lemma="foot" stem="feet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="20-foot-high" lemma="20-foot-high" stem="20-foot-high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="ceilings" lemma="ceiling" stem="ceil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="live" lemma="live" stem="live" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="unencumbered" lemma="unencumbered" stem="unencumb" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="assumes" lemma="assume" stem="assum" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="thoughts" lemma="thought" stem="thought" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="fame" lemma="fame" stem="fame" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="fortune" lemma="fortune" stem="fortun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="seldom" lemma="seldom" stem="seldom" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="hunger" lemma="hunger" stem="hunger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="Each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" ner="SET" is_referenced="false" is_refers="false" />
        <token id="35" string="morning" lemma="morning" stem="morn" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="36" string="Wegman" lemma="Wegman" stem="wegman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="37" string="feeds" lemma="feed" stem="feed" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="Eukanuba" lemma="Eukanuba" stem="eukanuba" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="40" string="dog" lemma="dog" stem="dog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="food" lemma="food" stem="food" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="45" string="considers" lemma="consider" stem="consid" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (NP (NNP Wegman) (POS 's)) (NN home)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ comprises) (NP (NP (CD 2,000) (JJ square) (NNS feet)) (PP (IN with) (NP (JJ 20-foot-high) (NNS ceilings))))))))) (, ,) (S (NP (PRP they)) (VP (VBP live) (NP (NP (DT a) (NN life)) (ADJP (ADJP (JJ unencumbered)) (PRN (: --) (S (NP (CD one)) (VP (VBZ assumes))) (: --)))) (PP (IN by) (NP (NP (NNS thoughts)) (PP (IN of) (NP (NN fame) (CC or) (NN fortune))))))) (, ,) (CC and) (S (NP-TMP (ADVP (RB seldom) (NP (NN hunger))) (DT Each) (NN morning)) (NP (NNP Wegman)) (VP (VBZ feeds) (NP (PRP them)) (NP-TMP (NP (NNP Eukanuba) (NN dog) (NN food)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (PRP he)) (VP (VBZ considers) (NP (DT the) (JJS best)) (ADVP (IN around)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a life" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="life" />
          </tokens>
        </chunking>
        <chunking id="2" string="thoughts" type="NP">
          <tokens>
            <token id="25" string="thoughts" />
          </tokens>
        </chunking>
        <chunking id="3" string="Wegman 's home" type="NP">
          <tokens>
            <token id="2" string="Wegman" />
            <token id="3" string="'s" />
            <token id="4" string="home" />
          </tokens>
        </chunking>
        <chunking id="4" string="which comprises 2,000 square feet with 20-foot-high ceilings" type="SBAR">
          <tokens>
            <token id="6" string="which" />
            <token id="7" string="comprises" />
            <token id="8" string="2,000" />
            <token id="9" string="square" />
            <token id="10" string="feet" />
            <token id="11" string="with" />
            <token id="12" string="20-foot-high" />
            <token id="13" string="ceilings" />
          </tokens>
        </chunking>
        <chunking id="5" string="one" type="NP">
          <tokens>
            <token id="21" string="one" />
          </tokens>
        </chunking>
        <chunking id="6" string="the best" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="best" />
          </tokens>
        </chunking>
        <chunking id="7" string="Wegman 's" type="NP">
          <tokens>
            <token id="2" string="Wegman" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="Eukanuba dog food" type="NP">
          <tokens>
            <token id="39" string="Eukanuba" />
            <token id="40" string="dog" />
            <token id="41" string="food" />
          </tokens>
        </chunking>
        <chunking id="9" string="unencumbered" type="ADJP">
          <tokens>
            <token id="19" string="unencumbered" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="38" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="hunger" type="NP">
          <tokens>
            <token id="33" string="hunger" />
          </tokens>
        </chunking>
        <chunking id="12" string="feeds them Eukanuba dog food , which he considers the best around" type="VP">
          <tokens>
            <token id="37" string="feeds" />
            <token id="38" string="them" />
            <token id="39" string="Eukanuba" />
            <token id="40" string="dog" />
            <token id="41" string="food" />
            <token id="42" string="," />
            <token id="43" string="which" />
            <token id="44" string="he" />
            <token id="45" string="considers" />
            <token id="46" string="the" />
            <token id="47" string="best" />
            <token id="48" string="around" />
          </tokens>
        </chunking>
        <chunking id="13" string="20-foot-high ceilings" type="NP">
          <tokens>
            <token id="12" string="20-foot-high" />
            <token id="13" string="ceilings" />
          </tokens>
        </chunking>
        <chunking id="14" string="fame or fortune" type="NP">
          <tokens>
            <token id="27" string="fame" />
            <token id="28" string="or" />
            <token id="29" string="fortune" />
          </tokens>
        </chunking>
        <chunking id="15" string="Wegman" type="NP">
          <tokens>
            <token id="36" string="Wegman" />
          </tokens>
        </chunking>
        <chunking id="16" string="2,000 square feet" type="NP">
          <tokens>
            <token id="8" string="2,000" />
            <token id="9" string="square" />
            <token id="10" string="feet" />
          </tokens>
        </chunking>
        <chunking id="17" string="thoughts of fame or fortune" type="NP">
          <tokens>
            <token id="25" string="thoughts" />
            <token id="26" string="of" />
            <token id="27" string="fame" />
            <token id="28" string="or" />
            <token id="29" string="fortune" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="44" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="considers the best around" type="VP">
          <tokens>
            <token id="45" string="considers" />
            <token id="46" string="the" />
            <token id="47" string="best" />
            <token id="48" string="around" />
          </tokens>
        </chunking>
        <chunking id="20" string="2,000 square feet with 20-foot-high ceilings" type="NP">
          <tokens>
            <token id="8" string="2,000" />
            <token id="9" string="square" />
            <token id="10" string="feet" />
            <token id="11" string="with" />
            <token id="12" string="20-foot-high" />
            <token id="13" string="ceilings" />
          </tokens>
        </chunking>
        <chunking id="21" string="assumes" type="VP">
          <tokens>
            <token id="22" string="assumes" />
          </tokens>
        </chunking>
        <chunking id="22" string="which he considers the best around" type="SBAR">
          <tokens>
            <token id="43" string="which" />
            <token id="44" string="he" />
            <token id="45" string="considers" />
            <token id="46" string="the" />
            <token id="47" string="best" />
            <token id="48" string="around" />
          </tokens>
        </chunking>
        <chunking id="23" string="Wegman 's home , which comprises 2,000 square feet with 20-foot-high ceilings" type="NP">
          <tokens>
            <token id="2" string="Wegman" />
            <token id="3" string="'s" />
            <token id="4" string="home" />
            <token id="5" string="," />
            <token id="6" string="which" />
            <token id="7" string="comprises" />
            <token id="8" string="2,000" />
            <token id="9" string="square" />
            <token id="10" string="feet" />
            <token id="11" string="with" />
            <token id="12" string="20-foot-high" />
            <token id="13" string="ceilings" />
          </tokens>
        </chunking>
        <chunking id="24" string="a life unencumbered -- one assumes --" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="life" />
            <token id="19" string="unencumbered" />
            <token id="20" string="--" />
            <token id="21" string="one" />
            <token id="22" string="assumes" />
            <token id="23" string="--" />
          </tokens>
        </chunking>
        <chunking id="25" string="they" type="NP">
          <tokens>
            <token id="15" string="they" />
          </tokens>
        </chunking>
        <chunking id="26" string="comprises 2,000 square feet with 20-foot-high ceilings" type="VP">
          <tokens>
            <token id="7" string="comprises" />
            <token id="8" string="2,000" />
            <token id="9" string="square" />
            <token id="10" string="feet" />
            <token id="11" string="with" />
            <token id="12" string="20-foot-high" />
            <token id="13" string="ceilings" />
          </tokens>
        </chunking>
        <chunking id="27" string="live a life unencumbered -- one assumes -- by thoughts of fame or fortune" type="VP">
          <tokens>
            <token id="16" string="live" />
            <token id="17" string="a" />
            <token id="18" string="life" />
            <token id="19" string="unencumbered" />
            <token id="20" string="--" />
            <token id="21" string="one" />
            <token id="22" string="assumes" />
            <token id="23" string="--" />
            <token id="24" string="by" />
            <token id="25" string="thoughts" />
            <token id="26" string="of" />
            <token id="27" string="fame" />
            <token id="28" string="or" />
            <token id="29" string="fortune" />
          </tokens>
        </chunking>
        <chunking id="28" string="unencumbered -- one assumes --" type="ADJP">
          <tokens>
            <token id="19" string="unencumbered" />
            <token id="20" string="--" />
            <token id="21" string="one" />
            <token id="22" string="assumes" />
            <token id="23" string="--" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">home</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">home</governor>
          <dependent id="2">Wegman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Wegman</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">live</governor>
          <dependent id="4">home</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">comprises</governor>
          <dependent id="6">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">home</governor>
          <dependent id="7">comprises</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">feet</governor>
          <dependent id="8">2,000</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">feet</governor>
          <dependent id="9">square</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">comprises</governor>
          <dependent id="10">feet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">ceilings</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">ceilings</governor>
          <dependent id="12">20-foot-high</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">feet</governor>
          <dependent id="13">ceilings</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">live</governor>
          <dependent id="15">they</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">live</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">life</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">live</governor>
          <dependent id="18">life</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">life</governor>
          <dependent id="19">unencumbered</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">assumes</governor>
          <dependent id="21">one</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">unencumbered</governor>
          <dependent id="22">assumes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">thoughts</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">live</governor>
          <dependent id="25">thoughts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">fame</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">thoughts</governor>
          <dependent id="27">fame</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">fame</governor>
          <dependent id="28">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">fame</governor>
          <dependent id="29">fortune</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">live</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">morning</governor>
          <dependent id="32">seldom</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="32">seldom</governor>
          <dependent id="33">hunger</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">morning</governor>
          <dependent id="34">Each</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="37">feeds</governor>
          <dependent id="35">morning</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">feeds</governor>
          <dependent id="36">Wegman</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">live</governor>
          <dependent id="37">feeds</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">feeds</governor>
          <dependent id="38">them</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">food</governor>
          <dependent id="39">Eukanuba</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">food</governor>
          <dependent id="40">dog</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="37">feeds</governor>
          <dependent id="41">food</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="45">considers</governor>
          <dependent id="43">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="45">considers</governor>
          <dependent id="44">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="41">food</governor>
          <dependent id="45">considers</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">best</governor>
          <dependent id="46">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="45">considers</governor>
          <dependent id="47">best</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="45">considers</governor>
          <dependent id="48">around</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="2,000" />
          </tokens>
        </entity>
        <entity id="2" string="Eukanuba" type="PERSON" score="0.0">
          <tokens>
            <token id="39" string="Eukanuba" />
          </tokens>
        </entity>
        <entity id="3" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="one" />
          </tokens>
        </entity>
        <entity id="4" string="Wegman" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Wegman" />
          </tokens>
        </entity>
        <entity id="5" string="Each morning" type="SET" score="0.0">
          <tokens>
            <token id="34" string="Each" />
            <token id="35" string="morning" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s the highest in protein.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="highest" lemma="highest" stem="highest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="protein" lemma="protein" stem="protein" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ 's) (NP (NP (DT the) (JJS highest)) (PP (IN in) (NP (NN protein))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="protein" type="NP">
          <tokens>
            <token id="7" string="protein" />
          </tokens>
        </chunking>
        <chunking id="2" string="the highest" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="highest" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="4" string="the highest in protein" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="highest" />
            <token id="6" string="in" />
            <token id="7" string="protein" />
          </tokens>
        </chunking>
        <chunking id="5" string="'s the highest in protein" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="the" />
            <token id="5" string="highest" />
            <token id="6" string="in" />
            <token id="7" string="protein" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">highest</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">highest</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">highest</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">highest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">protein</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">highest</governor>
          <dependent id="7">protein</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>he said.</content>
      <tokens>
        <token id="1" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he" type="NP">
          <tokens>
            <token id="1" string="he" />
          </tokens>
        </chunking>
        <chunking id="2" string="said" type="VP">
          <tokens>
            <token id="2" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>He often adds a spoonful of plain yogurt or cottage cheese.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="adds" lemma="add" stem="add" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="spoonful" lemma="spoonful" stem="spoon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="plain" lemma="plain" stem="plain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="yogurt" lemma="yogurt" stem="yogurt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="cottage" lemma="cottage" stem="cottag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="cheese" lemma="cheese" stem="chees" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (ADVP (RB often)) (VP (VBZ adds) (NP (NP (DT a) (NN spoonful)) (PP (IN of) (NP (JJ plain) (NN yogurt) (CC or) (NN cottage) (NN cheese))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="adds a spoonful of plain yogurt or cottage cheese" type="VP">
          <tokens>
            <token id="3" string="adds" />
            <token id="4" string="a" />
            <token id="5" string="spoonful" />
            <token id="6" string="of" />
            <token id="7" string="plain" />
            <token id="8" string="yogurt" />
            <token id="9" string="or" />
            <token id="10" string="cottage" />
            <token id="11" string="cheese" />
          </tokens>
        </chunking>
        <chunking id="2" string="a spoonful of plain yogurt or cottage cheese" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="spoonful" />
            <token id="6" string="of" />
            <token id="7" string="plain" />
            <token id="8" string="yogurt" />
            <token id="9" string="or" />
            <token id="10" string="cottage" />
            <token id="11" string="cheese" />
          </tokens>
        </chunking>
        <chunking id="3" string="a spoonful" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="spoonful" />
          </tokens>
        </chunking>
        <chunking id="4" string="plain yogurt or cottage cheese" type="NP">
          <tokens>
            <token id="7" string="plain" />
            <token id="8" string="yogurt" />
            <token id="9" string="or" />
            <token id="10" string="cottage" />
            <token id="11" string="cheese" />
          </tokens>
        </chunking>
        <chunking id="5" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">adds</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">adds</governor>
          <dependent id="2">often</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">adds</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">spoonful</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">adds</governor>
          <dependent id="5">spoonful</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">yogurt</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">yogurt</governor>
          <dependent id="7">plain</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">spoonful</governor>
          <dependent id="8">yogurt</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">yogurt</governor>
          <dependent id="9">or</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">cheese</governor>
          <dependent id="10">cottage</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">yogurt</governor>
          <dependent id="11">cheese</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>The dogs eat again at 6 p.m The house is designed for both human and canine comfort.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="dogs" lemma="dog" stem="dog" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="eat" lemma="eat" stem="eat" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="again" lemma="again" stem="again" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="6" lemma="6" stem="6" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="7" string="p.m" lemma="p.m" stem="p.m" pos="RB" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="8" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="designed" lemma="design" stem="design" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="canine" lemma="canine" stem="canin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="comfort" lemma="comfort" stem="comfort" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNS dogs)) (VP (VBP eat) (ADVP (RB again)) (PP (IN at) (NP (CD 6) (RB p.m))))) (NP (DT The) (NN house)) (VP (VBZ is) (VP (VBN designed) (PP (IN for) (NP (CC both) (NP (JJ human)) (CC and) (NP (JJ canine) (NN comfort)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is designed for both human and canine comfort" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="designed" />
            <token id="12" string="for" />
            <token id="13" string="both" />
            <token id="14" string="human" />
            <token id="15" string="and" />
            <token id="16" string="canine" />
            <token id="17" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="2" string="The dogs" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="dogs" />
          </tokens>
        </chunking>
        <chunking id="3" string="designed for both human and canine comfort" type="VP">
          <tokens>
            <token id="11" string="designed" />
            <token id="12" string="for" />
            <token id="13" string="both" />
            <token id="14" string="human" />
            <token id="15" string="and" />
            <token id="16" string="canine" />
            <token id="17" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="4" string="canine comfort" type="NP">
          <tokens>
            <token id="16" string="canine" />
            <token id="17" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="5" string="both human and canine comfort" type="NP">
          <tokens>
            <token id="13" string="both" />
            <token id="14" string="human" />
            <token id="15" string="and" />
            <token id="16" string="canine" />
            <token id="17" string="comfort" />
          </tokens>
        </chunking>
        <chunking id="6" string="eat again at 6 p.m" type="VP">
          <tokens>
            <token id="3" string="eat" />
            <token id="4" string="again" />
            <token id="5" string="at" />
            <token id="6" string="6" />
            <token id="7" string="p.m" />
          </tokens>
        </chunking>
        <chunking id="7" string="The house" type="NP">
          <tokens>
            <token id="8" string="The" />
            <token id="9" string="house" />
          </tokens>
        </chunking>
        <chunking id="8" string="human" type="NP">
          <tokens>
            <token id="14" string="human" />
          </tokens>
        </chunking>
        <chunking id="9" string="6 p.m" type="NP">
          <tokens>
            <token id="6" string="6" />
            <token id="7" string="p.m" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">dogs</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">eat</governor>
          <dependent id="2">dogs</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">designed</governor>
          <dependent id="3">eat</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">eat</governor>
          <dependent id="4">again</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">6</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">eat</governor>
          <dependent id="6">6</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">6</governor>
          <dependent id="7">p.m</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">house</governor>
          <dependent id="8">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">designed</governor>
          <dependent id="9">house</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">designed</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">designed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">human</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="14">human</governor>
          <dependent id="13">both</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">designed</governor>
          <dependent id="14">human</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">human</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">comfort</governor>
          <dependent id="16">canine</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">human</governor>
          <dependent id="17">comfort</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="6 p.m" type="TIME" score="0.0">
          <tokens>
            <token id="6" string="6" />
            <token id="7" string="p.m" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>There is nowhere that Wegman goes that the dogs do not.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="nowhere" lemma="nowhere" stem="nowher" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Wegman" lemma="Wegman" stem="wegman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="goes" lemma="go" stem="goe" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="dogs" lemma="dog" stem="dog" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBZ is) (ADVP (RB nowhere)) (SBAR (IN that) (S (NP (NNP Wegman)) (VP (VBZ goes) (SBAR (IN that) (S (NP (DT the) (NNS dogs)) (VP (VBP do) (RB not)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="goes that the dogs do not" type="VP">
          <tokens>
            <token id="6" string="goes" />
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="dogs" />
            <token id="10" string="do" />
            <token id="11" string="not" />
          </tokens>
        </chunking>
        <chunking id="2" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="3" string="that the dogs do not" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="dogs" />
            <token id="10" string="do" />
            <token id="11" string="not" />
          </tokens>
        </chunking>
        <chunking id="4" string="Wegman" type="NP">
          <tokens>
            <token id="5" string="Wegman" />
          </tokens>
        </chunking>
        <chunking id="5" string="is nowhere that Wegman goes that the dogs do not" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="nowhere" />
            <token id="4" string="that" />
            <token id="5" string="Wegman" />
            <token id="6" string="goes" />
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="dogs" />
            <token id="10" string="do" />
            <token id="11" string="not" />
          </tokens>
        </chunking>
        <chunking id="6" string="that Wegman goes that the dogs do not" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="Wegman" />
            <token id="6" string="goes" />
            <token id="7" string="that" />
            <token id="8" string="the" />
            <token id="9" string="dogs" />
            <token id="10" string="do" />
            <token id="11" string="not" />
          </tokens>
        </chunking>
        <chunking id="7" string="do not" type="VP">
          <tokens>
            <token id="10" string="do" />
            <token id="11" string="not" />
          </tokens>
        </chunking>
        <chunking id="8" string="the dogs" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="dogs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">is</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">is</governor>
          <dependent id="3">nowhere</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">goes</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">goes</governor>
          <dependent id="5">Wegman</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">is</governor>
          <dependent id="6">goes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">do</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">dogs</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">do</governor>
          <dependent id="9">dogs</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">goes</governor>
          <dependent id="10">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">do</governor>
          <dependent id="11">not</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Wegman" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Wegman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="false">
      <content>The yard is a run of dirt and concrete.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="yard" lemma="yard" stem="yard" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="run" lemma="run" stem="run" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="dirt" lemma="dirt" stem="dirt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="concrete" lemma="concrete" stem="concret" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN yard)) (VP (VBZ is) (NP (NP (DT a) (NN run)) (PP (IN of) (NP (NN dirt) (CC and) (NN concrete))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The yard" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="yard" />
          </tokens>
        </chunking>
        <chunking id="2" string="a run of dirt and concrete" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="run" />
            <token id="6" string="of" />
            <token id="7" string="dirt" />
            <token id="8" string="and" />
            <token id="9" string="concrete" />
          </tokens>
        </chunking>
        <chunking id="3" string="dirt and concrete" type="NP">
          <tokens>
            <token id="7" string="dirt" />
            <token id="8" string="and" />
            <token id="9" string="concrete" />
          </tokens>
        </chunking>
        <chunking id="4" string="a run" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="run" />
          </tokens>
        </chunking>
        <chunking id="5" string="is a run of dirt and concrete" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="run" />
            <token id="6" string="of" />
            <token id="7" string="dirt" />
            <token id="8" string="and" />
            <token id="9" string="concrete" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">yard</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">run</governor>
          <dependent id="2">yard</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">run</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">run</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">dirt</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">run</governor>
          <dependent id="7">dirt</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">dirt</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">dirt</governor>
          <dependent id="9">concrete</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>If their master does not play with them, the dogs just scratch, sniff, get bored and go to the door to wait for him.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="master" lemma="master" stem="master" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="play" lemma="play" stem="plai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="dogs" lemma="dog" stem="dog" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="scratch" lemma="scratch" stem="scratch" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="sniff" lemma="sniff" stem="sniff" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="bored" lemma="bore" stem="bore" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="door" lemma="door" stem="door" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="wait" lemma="wait" stem="wait" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (PRP$ their) (NN master)) (VP (VBZ does) (RB not) (VP (VB play) (PP (IN with) (NP (PRP them))))))) (, ,) (NP (DT the) (NNS dogs)) (ADVP (RB just)) (VP (VP (VBP scratch)) (, ,) (VP (VBP sniff)) (, ,) (VP (VBP get) (S (ADJP (VBN bored)))) (CC and) (VP (VB go) (PP (TO to) (NP (DT the) (NN door) (S (VP (TO to) (VP (VB wait) (PP (IN for) (NP (PRP him)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sniff" type="VP">
          <tokens>
            <token id="15" string="sniff" />
          </tokens>
        </chunking>
        <chunking id="2" string="the door to wait for him" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="door" />
            <token id="24" string="to" />
            <token id="25" string="wait" />
            <token id="26" string="for" />
            <token id="27" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="scratch , sniff , get bored and go to the door to wait for him" type="VP">
          <tokens>
            <token id="13" string="scratch" />
            <token id="14" string="," />
            <token id="15" string="sniff" />
            <token id="16" string="," />
            <token id="17" string="get" />
            <token id="18" string="bored" />
            <token id="19" string="and" />
            <token id="20" string="go" />
            <token id="21" string="to" />
            <token id="22" string="the" />
            <token id="23" string="door" />
            <token id="24" string="to" />
            <token id="25" string="wait" />
            <token id="26" string="for" />
            <token id="27" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="scratch" type="VP">
          <tokens>
            <token id="13" string="scratch" />
          </tokens>
        </chunking>
        <chunking id="5" string="their master" type="NP">
          <tokens>
            <token id="2" string="their" />
            <token id="3" string="master" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="27" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="them" type="NP">
          <tokens>
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="go to the door to wait for him" type="VP">
          <tokens>
            <token id="20" string="go" />
            <token id="21" string="to" />
            <token id="22" string="the" />
            <token id="23" string="door" />
            <token id="24" string="to" />
            <token id="25" string="wait" />
            <token id="26" string="for" />
            <token id="27" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="If their master does not play with them" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="their" />
            <token id="3" string="master" />
            <token id="4" string="does" />
            <token id="5" string="not" />
            <token id="6" string="play" />
            <token id="7" string="with" />
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="wait for him" type="VP">
          <tokens>
            <token id="25" string="wait" />
            <token id="26" string="for" />
            <token id="27" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="to wait for him" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="wait" />
            <token id="26" string="for" />
            <token id="27" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="does not play with them" type="VP">
          <tokens>
            <token id="4" string="does" />
            <token id="5" string="not" />
            <token id="6" string="play" />
            <token id="7" string="with" />
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="bored" type="ADJP">
          <tokens>
            <token id="18" string="bored" />
          </tokens>
        </chunking>
        <chunking id="14" string="play with them" type="VP">
          <tokens>
            <token id="6" string="play" />
            <token id="7" string="with" />
            <token id="8" string="them" />
          </tokens>
        </chunking>
        <chunking id="15" string="the dogs" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="dogs" />
          </tokens>
        </chunking>
        <chunking id="16" string="get bored" type="VP">
          <tokens>
            <token id="17" string="get" />
            <token id="18" string="bored" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">play</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">master</governor>
          <dependent id="2">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">play</governor>
          <dependent id="3">master</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">play</governor>
          <dependent id="4">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">play</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">scratch</governor>
          <dependent id="6">play</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">them</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">play</governor>
          <dependent id="8">them</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">dogs</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">scratch</governor>
          <dependent id="11">dogs</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">scratch</governor>
          <dependent id="12">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">scratch</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">scratch</governor>
          <dependent id="15">sniff</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">scratch</governor>
          <dependent id="17">get</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">get</governor>
          <dependent id="18">bored</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">scratch</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">scratch</governor>
          <dependent id="20">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">door</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">door</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">go</governor>
          <dependent id="23">door</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">wait</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">door</governor>
          <dependent id="25">wait</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">him</governor>
          <dependent id="26">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">wait</governor>
          <dependent id="27">him</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="13-14" string="William Wegman" id_sentence="1" />
      <mentions>
        <mention ids_tokens="6" string="his" id_sentence="2" />
        <mention ids_tokens="10" string="his" id_sentence="2" />
        <mention ids_tokens="6" string="Wegman" id_sentence="5" />
        <mention ids_tokens="27" string="he" id_sentence="5" />
        <mention ids_tokens="4" string="I" id_sentence="6" />
        <mention ids_tokens="18-27" string="Wegman , who did go to the Westminster Kennel Club" id_sentence="6" />
        <mention ids_tokens="18" string="Wegman" id_sentence="6" />
        <mention ids_tokens="2" string="I" id_sentence="7" />
        <mention ids_tokens="1" string="I" id_sentence="8" />
        <mention ids_tokens="17-18" string="Wegman Man" id_sentence="10" />
        <mention ids_tokens="23" string="Wegman" id_sentence="16" />
        <mention ids_tokens="13-22" string="Wegman , who spent three years living without a dog" id_sentence="18" />
        <mention ids_tokens="13" string="Wegman" id_sentence="18" />
        <mention ids_tokens="2-3" string="Wegman's" id_sentence="28" />
        <mention ids_tokens="36" string="Wegman" id_sentence="28" />
        <mention ids_tokens="44" string="he" id_sentence="28" />
        <mention ids_tokens="1" string="he" id_sentence="30" />
        <mention ids_tokens="1" string="He" id_sentence="31" />
        <mention ids_tokens="5" string="Wegman" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="Wegman 's home" id_sentence="28" />
      <mentions>
        <mention ids_tokens="10-14" string="the home of William Wegman" id_sentence="1" />
        <mention ids_tokens="22-23" string="Their home" id_sentence="10" />
        <mention ids_tokens="2" string="It" id_sentence="29" />
        <mention ids_tokens="4-7" string="the highest in protein" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="10-11" string="his Weimaraners" id_sentence="2" />
      <mentions>
        <mention ids_tokens="13" string="Weimaraners" id_sentence="12" />
        <mention ids_tokens="4" string="Weimaraners" id_sentence="13" />
        <mention ids_tokens="6" string="Weimaraners" id_sentence="23" />
        <mention ids_tokens="1" string="They" id_sentence="24" />
        <mention ids_tokens="10" string="they" id_sentence="24" />
        <mention ids_tokens="14" string="they" id_sentence="24" />
        <mention ids_tokens="19" string="They" id_sentence="24" />
        <mention ids_tokens="22-26" string="good companions for an artist" id_sentence="24" />
        <mention ids_tokens="1" string="They" id_sentence="25" />
        <mention ids_tokens="1" string="They" id_sentence="26" />
        <mention ids_tokens="1" string="They" id_sentence="27" />
        <mention ids_tokens="15" string="they" id_sentence="28" />
        <mention ids_tokens="38" string="them" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="3-4" string="this house" id_sentence="3" />
      <mentions>
        <mention ids_tokens="8-9" string="The house" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="5" type="LIST">
      <referenced ids_tokens="6-7-8" string="man and dogs" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1" string="Their" id_sentence="4" />
        <mention ids_tokens="34" string="them" id_sentence="5" />
        <mention ids_tokens="39" string="them" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="9-10" string="Fay Ray" id_sentence="5" />
      <mentions>
        <mention ids_tokens="18-19" string="Man Ray" id_sentence="13" />
        <mention ids_tokens="35-36" string="Man Ray" id_sentence="13" />
        <mention ids_tokens="5" string="him" id_sentence="14" />
        <mention ids_tokens="6" string="him" id_sentence="15" />
        <mention ids_tokens="3-10" string="Man Ray , who had become world famous" id_sentence="17" />
        <mention ids_tokens="3-4" string="Man Ray" id_sentence="17" />
        <mention ids_tokens="2" string="I" id_sentence="18" />
        <mention ids_tokens="5" string="he" id_sentence="18" />
        <mention ids_tokens="10" string="I" id_sentence="19" />
        <mention ids_tokens="7" string="he" id_sentence="20" />
        <mention ids_tokens="6-26" string="Fay Ray , who is now a familiar face not only among artists but among children who watch &quot; Sesame Street" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="12-13-14-15-16-17-18" string="Battina , her 1 1/2 - year-old daughter" id_sentence="5" />
      <mentions>
        <mention ids_tokens="2" string="Battina" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="12-13" string="the artist" id_sentence="11" />
      <mentions>
        <mention ids_tokens="8" string="I" id_sentence="12" />
        <mention ids_tokens="17-29" string="the artist , who was born 47 years ago in Longmeadow , Mass" id_sentence="12" />
        <mention ids_tokens="5" string="his" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="20-21-22-23-24-25-26" string="normal dogs to slip into florid housedresses" id_sentence="11" />
      <mentions>
        <mention ids_tokens="31" string="dogs" id_sentence="13" />
        <mention ids_tokens="9-10" string="these dogs" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="5" string="each" id_sentence="12" />
      <mentions>
        <mention ids_tokens="1" string="His" id_sentence="13" />
        <mention ids_tokens="11" string="he" id_sentence="13" />
        <mention ids_tokens="42" string="He" id_sentence="13" />
        <mention ids_tokens="2" string="I" id_sentence="14" />
        <mention ids_tokens="1" string="I" id_sentence="15" />
        <mention ids_tokens="13" string="he" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="7-8" string="a dog" id_sentence="14" />
      <mentions>
        <mention ids_tokens="2-4" string="A dog's" id_sentence="16" />
        <mention ids_tokens="8-20" string="he been a different breed he would have been a &quot; character actor" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="17-18-19-20-21-22" string="three years living without a dog" id_sentence="18" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="19" />
        <mention ids_tokens="8-9" string="the years" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="2-3" string="another dog" id_sentence="21" />
      <mentions>
        <mention ids_tokens="4" string="he" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="19" type="LIST">
      <referenced ids_tokens="13-14-15-16-17" string="both human and canine comfort" id_sentence="32" />
      <mentions>
        <mention ids_tokens="2" string="their" id_sentence="35" />
        <mention ids_tokens="8" string="them" id_sentence="35" />
      </mentions>
    </coreference>
  </coreferences>
</document>
