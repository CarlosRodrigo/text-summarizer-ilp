<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="WSJ871110-0154">
  <sentences>
    <sentence id="1" has_coreference="false">
      <content>On the day of the Big Event, Ladbroke, the large British betting agency, posted the final odds.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="Event" lemma="event" stem="event" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Ladbroke" lemma="Ladbroke" stem="ladbrok" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="14" string="betting" lemma="bet" stem="bet" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="agency" lemma="agency" stem="agenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="posted" lemma="post" stem="post" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="odds" lemma="odds" stem="odd" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (NP (DT the) (NN day)) (PP (IN of) (NP (DT the) (JJ Big) (NN Event))))) (, ,) (NP (NP (NNP Ladbroke)) (, ,) (NP (DT the) (JJ large) (JJ British) (VBG betting) (NN agency)) (, ,)) (VP (VBD posted) (NP (DT the) (JJ final) (NNS odds))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ladbroke , the large British betting agency ," type="NP">
          <tokens>
            <token id="9" string="Ladbroke" />
            <token id="10" string="," />
            <token id="11" string="the" />
            <token id="12" string="large" />
            <token id="13" string="British" />
            <token id="14" string="betting" />
            <token id="15" string="agency" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="the day" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="day" />
          </tokens>
        </chunking>
        <chunking id="3" string="the final odds" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="final" />
            <token id="20" string="odds" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Big Event" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Big" />
            <token id="7" string="Event" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ladbroke" type="NP">
          <tokens>
            <token id="9" string="Ladbroke" />
          </tokens>
        </chunking>
        <chunking id="6" string="the day of the Big Event" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="day" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="Big" />
            <token id="7" string="Event" />
          </tokens>
        </chunking>
        <chunking id="7" string="posted the final odds" type="VP">
          <tokens>
            <token id="17" string="posted" />
            <token id="18" string="the" />
            <token id="19" string="final" />
            <token id="20" string="odds" />
          </tokens>
        </chunking>
        <chunking id="8" string="the large British betting agency" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="large" />
            <token id="13" string="British" />
            <token id="14" string="betting" />
            <token id="15" string="agency" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">day</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">day</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">posted</governor>
          <dependent id="3">day</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Event</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Event</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Event</governor>
          <dependent id="6">Big</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">day</governor>
          <dependent id="7">Event</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">posted</governor>
          <dependent id="9">Ladbroke</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">agency</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">agency</governor>
          <dependent id="12">large</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">agency</governor>
          <dependent id="13">British</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">agency</governor>
          <dependent id="14">betting</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">Ladbroke</governor>
          <dependent id="15">agency</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">posted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">odds</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">odds</governor>
          <dependent id="19">final</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">posted</governor>
          <dependent id="20">odds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="13" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="the day" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="day" />
          </tokens>
        </entity>
        <entity id="3" string="Ladbroke" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="Ladbroke" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Brian Moore was the favorite at 7-4, followed by Peter Ackroyd (5-2), Iris Murdoch (3-1) and Chinua Achebe (9-2).</content>
      <tokens>
        <token id="1" string="Brian" lemma="Brian" stem="brian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Moore" lemma="Moore" stem="moor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="favorite" lemma="favorite" stem="favorit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="7-4" lemma="7-4" stem="7-4" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="followed" lemma="follow" stem="follow" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Ackroyd" lemma="Ackroyd" stem="ackroyd" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="5-2" lemma="5-2" stem="5-2" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Iris" lemma="Iris" stem="iri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Murdoch" lemma="Murdoch" stem="murdoch" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="3-1" lemma="3-1" stem="3-1" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="21" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Chinua" lemma="Chinua" stem="chinua" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="Achebe" lemma="Achebe" stem="achebe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="9-2" lemma="9-2" stem="9-2" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="27" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Brian) (NNP Moore)) (VP (VBD was) (NP (NP (DT the) (JJ favorite)) (PP (IN at) (NP (CD 7-4)))) (, ,) (PP (VBN followed) (PP (IN by) (NP (NP (NP (NNP Peter) (NNP Ackroyd)) (PRN (-LRB- -LRB-) (NP (CD 5-2)) (-RRB- -RRB-))) (, ,) (NP (NP (NNP Iris) (NNP Murdoch)) (PRN (-LRB- -LRB-) (NP (CD 3-1)) (-RRB- -RRB-))) (CC and) (NP (NP (NNP Chinua) (NNP Achebe)) (PRN (-LRB- -LRB-) (NP (CD 9-2)) (-RRB- -RRB-))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Brian Moore" type="NP">
          <tokens>
            <token id="1" string="Brian" />
            <token id="2" string="Moore" />
          </tokens>
        </chunking>
        <chunking id="2" string="was the favorite at 7-4 , followed by Peter Ackroyd -LRB- 5-2 -RRB- , Iris Murdoch -LRB- 3-1 -RRB- and Chinua Achebe -LRB- 9-2 -RRB-" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="favorite" />
            <token id="6" string="at" />
            <token id="7" string="7-4" />
            <token id="8" string="," />
            <token id="9" string="followed" />
            <token id="10" string="by" />
            <token id="11" string="Peter" />
            <token id="12" string="Ackroyd" />
            <token id="13" string="(" />
            <token id="14" string="5-2" />
            <token id="15" string=")" />
            <token id="16" string="," />
            <token id="17" string="Iris" />
            <token id="18" string="Murdoch" />
            <token id="19" string="(" />
            <token id="20" string="3-1" />
            <token id="21" string=")" />
            <token id="22" string="and" />
            <token id="23" string="Chinua" />
            <token id="24" string="Achebe" />
            <token id="25" string="(" />
            <token id="26" string="9-2" />
            <token id="27" string=")" />
          </tokens>
        </chunking>
        <chunking id="3" string="Chinua Achebe" type="NP">
          <tokens>
            <token id="23" string="Chinua" />
            <token id="24" string="Achebe" />
          </tokens>
        </chunking>
        <chunking id="4" string="the favorite at 7-4" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="favorite" />
            <token id="6" string="at" />
            <token id="7" string="7-4" />
          </tokens>
        </chunking>
        <chunking id="5" string="Chinua Achebe -LRB- 9-2 -RRB-" type="NP">
          <tokens>
            <token id="23" string="Chinua" />
            <token id="24" string="Achebe" />
            <token id="25" string="(" />
            <token id="26" string="9-2" />
            <token id="27" string=")" />
          </tokens>
        </chunking>
        <chunking id="6" string="Iris Murdoch -LRB- 3-1 -RRB-" type="NP">
          <tokens>
            <token id="17" string="Iris" />
            <token id="18" string="Murdoch" />
            <token id="19" string="(" />
            <token id="20" string="3-1" />
            <token id="21" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="Iris Murdoch" type="NP">
          <tokens>
            <token id="17" string="Iris" />
            <token id="18" string="Murdoch" />
          </tokens>
        </chunking>
        <chunking id="8" string="Peter Ackroyd -LRB- 5-2 -RRB-" type="NP">
          <tokens>
            <token id="11" string="Peter" />
            <token id="12" string="Ackroyd" />
            <token id="13" string="(" />
            <token id="14" string="5-2" />
            <token id="15" string=")" />
          </tokens>
        </chunking>
        <chunking id="9" string="Peter Ackroyd -LRB- 5-2 -RRB- , Iris Murdoch -LRB- 3-1 -RRB- and Chinua Achebe -LRB- 9-2 -RRB-" type="NP">
          <tokens>
            <token id="11" string="Peter" />
            <token id="12" string="Ackroyd" />
            <token id="13" string="(" />
            <token id="14" string="5-2" />
            <token id="15" string=")" />
            <token id="16" string="," />
            <token id="17" string="Iris" />
            <token id="18" string="Murdoch" />
            <token id="19" string="(" />
            <token id="20" string="3-1" />
            <token id="21" string=")" />
            <token id="22" string="and" />
            <token id="23" string="Chinua" />
            <token id="24" string="Achebe" />
            <token id="25" string="(" />
            <token id="26" string="9-2" />
            <token id="27" string=")" />
          </tokens>
        </chunking>
        <chunking id="10" string="3-1" type="NP">
          <tokens>
            <token id="20" string="3-1" />
          </tokens>
        </chunking>
        <chunking id="11" string="5-2" type="NP">
          <tokens>
            <token id="14" string="5-2" />
          </tokens>
        </chunking>
        <chunking id="12" string="the favorite" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="favorite" />
          </tokens>
        </chunking>
        <chunking id="13" string="Peter Ackroyd" type="NP">
          <tokens>
            <token id="11" string="Peter" />
            <token id="12" string="Ackroyd" />
          </tokens>
        </chunking>
        <chunking id="14" string="7-4" type="NP">
          <tokens>
            <token id="7" string="7-4" />
          </tokens>
        </chunking>
        <chunking id="15" string="9-2" type="NP">
          <tokens>
            <token id="26" string="9-2" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Moore</governor>
          <dependent id="1">Brian</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">favorite</governor>
          <dependent id="2">Moore</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">favorite</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">favorite</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">favorite</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">7-4</governor>
          <dependent id="6">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">favorite</governor>
          <dependent id="7">7-4</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Ackroyd</governor>
          <dependent id="9">followed</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="9">followed</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Ackroyd</governor>
          <dependent id="11">Peter</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">favorite</governor>
          <dependent id="12">Ackroyd</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Ackroyd</governor>
          <dependent id="14">5-2</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Murdoch</governor>
          <dependent id="17">Iris</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">Ackroyd</governor>
          <dependent id="18">Murdoch</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Murdoch</governor>
          <dependent id="20">3-1</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">Ackroyd</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Achebe</governor>
          <dependent id="23">Chinua</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">Ackroyd</governor>
          <dependent id="24">Achebe</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">Achebe</governor>
          <dependent id="26">9-2</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brian Moore" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Brian" />
            <token id="2" string="Moore" />
          </tokens>
        </entity>
        <entity id="2" string="Iris Murdoch" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Iris" />
            <token id="18" string="Murdoch" />
          </tokens>
        </entity>
        <entity id="3" string="3-1" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="3-1" />
          </tokens>
        </entity>
        <entity id="4" string="5-2" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="5-2" />
          </tokens>
        </entity>
        <entity id="5" string="Chinua Achebe" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Chinua" />
            <token id="24" string="Achebe" />
          </tokens>
        </entity>
        <entity id="6" string="Peter Ackroyd" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Peter" />
            <token id="12" string="Ackroyd" />
          </tokens>
        </entity>
        <entity id="7" string="7-4" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="7-4" />
          </tokens>
        </entity>
        <entity id="8" string="9-2" type="NUMBER" score="0.0">
          <tokens>
            <token id="26" string="9-2" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The two dark horses, Nina Bawden and Penelope Lively, were each tipped at 7-1.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="dark" lemma="dark" stem="dark" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="horses" lemma="horse" stem="hors" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Nina" lemma="Nina" stem="nina" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Bawden" lemma="Bawden" stem="bawden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Penelope" lemma="Penelope" stem="penelop" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="Lively" lemma="Lively" stem="live" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="tipped" lemma="tip" stem="tip" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="7-1" lemma="7-1" stem="7-1" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (CD two) (JJ dark) (NNS horses)) (, ,) (NP (NP (NNP Nina) (NNP Bawden)) (CC and) (NP (NNP Penelope) (NNP Lively))) (, ,)) (VP (VBD were) (NP (NP (DT each)) (SBAR (S (VP (VBD tipped) (PP (IN at) (NP (CD 7-1)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Penelope Lively" type="NP">
          <tokens>
            <token id="9" string="Penelope" />
            <token id="10" string="Lively" />
          </tokens>
        </chunking>
        <chunking id="2" string="The two dark horses , Nina Bawden and Penelope Lively ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="two" />
            <token id="3" string="dark" />
            <token id="4" string="horses" />
            <token id="5" string="," />
            <token id="6" string="Nina" />
            <token id="7" string="Bawden" />
            <token id="8" string="and" />
            <token id="9" string="Penelope" />
            <token id="10" string="Lively" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="tipped at 7-1" type="SBAR">
          <tokens>
            <token id="14" string="tipped" />
            <token id="15" string="at" />
            <token id="16" string="7-1" />
          </tokens>
        </chunking>
        <chunking id="4" string="Nina Bawden and Penelope Lively" type="NP">
          <tokens>
            <token id="6" string="Nina" />
            <token id="7" string="Bawden" />
            <token id="8" string="and" />
            <token id="9" string="Penelope" />
            <token id="10" string="Lively" />
          </tokens>
        </chunking>
        <chunking id="5" string="each tipped at 7-1" type="NP">
          <tokens>
            <token id="13" string="each" />
            <token id="14" string="tipped" />
            <token id="15" string="at" />
            <token id="16" string="7-1" />
          </tokens>
        </chunking>
        <chunking id="6" string="7-1" type="NP">
          <tokens>
            <token id="16" string="7-1" />
          </tokens>
        </chunking>
        <chunking id="7" string="The two dark horses" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="two" />
            <token id="3" string="dark" />
            <token id="4" string="horses" />
          </tokens>
        </chunking>
        <chunking id="8" string="Nina Bawden" type="NP">
          <tokens>
            <token id="6" string="Nina" />
            <token id="7" string="Bawden" />
          </tokens>
        </chunking>
        <chunking id="9" string="were each tipped at 7-1" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="each" />
            <token id="14" string="tipped" />
            <token id="15" string="at" />
            <token id="16" string="7-1" />
          </tokens>
        </chunking>
        <chunking id="10" string="each" type="NP">
          <tokens>
            <token id="13" string="each" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">horses</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">horses</governor>
          <dependent id="2">two</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">horses</governor>
          <dependent id="3">dark</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">each</governor>
          <dependent id="4">horses</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Bawden</governor>
          <dependent id="6">Nina</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">horses</governor>
          <dependent id="7">Bawden</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Bawden</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Lively</governor>
          <dependent id="9">Penelope</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Bawden</governor>
          <dependent id="10">Lively</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">each</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">each</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">each</governor>
          <dependent id="14">tipped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">7-1</governor>
          <dependent id="15">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">tipped</governor>
          <dependent id="16">7-1</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Penelope Lively" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Penelope" />
            <token id="10" string="Lively" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="two" />
          </tokens>
        </entity>
        <entity id="3" string="7-1" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="7-1" />
          </tokens>
        </entity>
        <entity id="4" string="Nina Bawden" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Nina" />
            <token id="7" string="Bawden" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>You may have noticed a distinctly literary tilt to that lineup, an affinity with the bookshelf, not the bookie.</content>
      <tokens>
        <token id="1" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="noticed" lemma="notice" stem="notic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="distinctly" lemma="distinctly" stem="distinctli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="tilt" lemma="tilt" stem="tilt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="lineup" lemma="lineup" stem="lineup" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="affinity" lemma="affinity" stem="affin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="bookshelf" lemma="bookshelf" stem="bookshelf" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="bookie" lemma="bookie" stem="booki" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP You)) (VP (MD may) (VP (VB have) (VP (VBN noticed) (NP (DT a) (ADJP (RB distinctly) (JJ literary)) (NN tilt)) (PP (TO to) (NP (NP (DT that) (NN lineup)) (, ,) (NP (NP (DT an) (NN affinity)) (PP (IN with) (NP (NP (DT the) (NN bookshelf)) (, ,) (RB not) (NP (DT the) (NN bookie)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an affinity" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="affinity" />
          </tokens>
        </chunking>
        <chunking id="2" string="noticed a distinctly literary tilt to that lineup , an affinity with the bookshelf , not the bookie" type="VP">
          <tokens>
            <token id="4" string="noticed" />
            <token id="5" string="a" />
            <token id="6" string="distinctly" />
            <token id="7" string="literary" />
            <token id="8" string="tilt" />
            <token id="9" string="to" />
            <token id="10" string="that" />
            <token id="11" string="lineup" />
            <token id="12" string="," />
            <token id="13" string="an" />
            <token id="14" string="affinity" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="bookshelf" />
            <token id="18" string="," />
            <token id="19" string="not" />
            <token id="20" string="the" />
            <token id="21" string="bookie" />
          </tokens>
        </chunking>
        <chunking id="3" string="the bookshelf" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="bookshelf" />
          </tokens>
        </chunking>
        <chunking id="4" string="a distinctly literary tilt" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="distinctly" />
            <token id="7" string="literary" />
            <token id="8" string="tilt" />
          </tokens>
        </chunking>
        <chunking id="5" string="the bookie" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="bookie" />
          </tokens>
        </chunking>
        <chunking id="6" string="an affinity with the bookshelf , not the bookie" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="affinity" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="bookshelf" />
            <token id="18" string="," />
            <token id="19" string="not" />
            <token id="20" string="the" />
            <token id="21" string="bookie" />
          </tokens>
        </chunking>
        <chunking id="7" string="the bookshelf , not the bookie" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="bookshelf" />
            <token id="18" string="," />
            <token id="19" string="not" />
            <token id="20" string="the" />
            <token id="21" string="bookie" />
          </tokens>
        </chunking>
        <chunking id="8" string="may have noticed a distinctly literary tilt to that lineup , an affinity with the bookshelf , not the bookie" type="VP">
          <tokens>
            <token id="2" string="may" />
            <token id="3" string="have" />
            <token id="4" string="noticed" />
            <token id="5" string="a" />
            <token id="6" string="distinctly" />
            <token id="7" string="literary" />
            <token id="8" string="tilt" />
            <token id="9" string="to" />
            <token id="10" string="that" />
            <token id="11" string="lineup" />
            <token id="12" string="," />
            <token id="13" string="an" />
            <token id="14" string="affinity" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="bookshelf" />
            <token id="18" string="," />
            <token id="19" string="not" />
            <token id="20" string="the" />
            <token id="21" string="bookie" />
          </tokens>
        </chunking>
        <chunking id="9" string="have noticed a distinctly literary tilt to that lineup , an affinity with the bookshelf , not the bookie" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="noticed" />
            <token id="5" string="a" />
            <token id="6" string="distinctly" />
            <token id="7" string="literary" />
            <token id="8" string="tilt" />
            <token id="9" string="to" />
            <token id="10" string="that" />
            <token id="11" string="lineup" />
            <token id="12" string="," />
            <token id="13" string="an" />
            <token id="14" string="affinity" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="bookshelf" />
            <token id="18" string="," />
            <token id="19" string="not" />
            <token id="20" string="the" />
            <token id="21" string="bookie" />
          </tokens>
        </chunking>
        <chunking id="10" string="that lineup" type="NP">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="lineup" />
          </tokens>
        </chunking>
        <chunking id="11" string="distinctly literary" type="ADJP">
          <tokens>
            <token id="6" string="distinctly" />
            <token id="7" string="literary" />
          </tokens>
        </chunking>
        <chunking id="12" string="that lineup , an affinity with the bookshelf , not the bookie" type="NP">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="lineup" />
            <token id="12" string="," />
            <token id="13" string="an" />
            <token id="14" string="affinity" />
            <token id="15" string="with" />
            <token id="16" string="the" />
            <token id="17" string="bookshelf" />
            <token id="18" string="," />
            <token id="19" string="not" />
            <token id="20" string="the" />
            <token id="21" string="bookie" />
          </tokens>
        </chunking>
        <chunking id="13" string="You" type="NP">
          <tokens>
            <token id="1" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">noticed</governor>
          <dependent id="1">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">noticed</governor>
          <dependent id="2">may</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">noticed</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">noticed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">tilt</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">literary</governor>
          <dependent id="6">distinctly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">tilt</governor>
          <dependent id="7">literary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">noticed</governor>
          <dependent id="8">tilt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">lineup</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">lineup</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">noticed</governor>
          <dependent id="11">lineup</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">affinity</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">lineup</governor>
          <dependent id="14">affinity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">bookshelf</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">bookshelf</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">affinity</governor>
          <dependent id="17">bookshelf</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="21">bookie</governor>
          <dependent id="19">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">bookie</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">bookshelf</governor>
          <dependent id="21">bookie</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>All of those people published new works of fiction here in Britain during the past 12 months.</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="works" lemma="work" stem="work" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="17" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT All)) (PP (IN of) (NP (DT those) (NNS people)))) (VP (VBN published) (NP (NP (JJ new) (NNS works)) (PP (IN of) (NP (NN fiction)))) (PP (ADVP (RB here)) (IN in) (NP (NNP Britain))) (PP (IN during) (NP (DT the) (JJ past) (CD 12) (NNS months)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="All" type="NP">
          <tokens>
            <token id="1" string="All" />
          </tokens>
        </chunking>
        <chunking id="2" string="new works" type="NP">
          <tokens>
            <token id="6" string="new" />
            <token id="7" string="works" />
          </tokens>
        </chunking>
        <chunking id="3" string="fiction" type="NP">
          <tokens>
            <token id="9" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="4" string="published new works of fiction here in Britain during the past 12 months" type="VP">
          <tokens>
            <token id="5" string="published" />
            <token id="6" string="new" />
            <token id="7" string="works" />
            <token id="8" string="of" />
            <token id="9" string="fiction" />
            <token id="10" string="here" />
            <token id="11" string="in" />
            <token id="12" string="Britain" />
            <token id="13" string="during" />
            <token id="14" string="the" />
            <token id="15" string="past" />
            <token id="16" string="12" />
            <token id="17" string="months" />
          </tokens>
        </chunking>
        <chunking id="5" string="new works of fiction" type="NP">
          <tokens>
            <token id="6" string="new" />
            <token id="7" string="works" />
            <token id="8" string="of" />
            <token id="9" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="6" string="All of those people" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="of" />
            <token id="3" string="those" />
            <token id="4" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="Britain" type="NP">
          <tokens>
            <token id="12" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="8" string="those people" type="NP">
          <tokens>
            <token id="3" string="those" />
            <token id="4" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="the past 12 months" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="past" />
            <token id="16" string="12" />
            <token id="17" string="months" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">published</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">people</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">people</governor>
          <dependent id="3">those</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">All</governor>
          <dependent id="4">people</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">published</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">works</governor>
          <dependent id="6">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">published</governor>
          <dependent id="7">works</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">fiction</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">works</governor>
          <dependent id="9">fiction</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">Britain</governor>
          <dependent id="10">here</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Britain</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">published</governor>
          <dependent id="12">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">months</governor>
          <dependent id="13">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">months</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">months</governor>
          <dependent id="15">past</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">months</governor>
          <dependent id="16">12</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">published</governor>
          <dependent id="17">months</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Britain" />
          </tokens>
        </entity>
        <entity id="2" string="the past 12 months" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="past" />
            <token id="16" string="12" />
            <token id="17" string="months" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>And for the last few weeks, literary punters throughout the British Isles have been placing bets on which of those writers would win the Booker Prize, the best-known, best-liked and, almost incidentally, most prestigious fiction award in the land.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="punters" lemma="punter" stem="punter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="throughout" lemma="throughout" stem="throughout" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="13" string="Isles" lemma="isle" stem="isle" pos="NNS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="placing" lemma="place" stem="place" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="bets" lemma="bet" stem="bet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="writers" lemma="writer" stem="writer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="win" lemma="win" stem="win" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="27" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="best-known" lemma="best-known" stem="best-known" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="best-liked" lemma="best-liked" stem="best-lik" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="incidentally" lemma="incidentally" stem="incident" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="prestigious" lemma="prestigious" stem="prestigi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="land" lemma="land" stem="land" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (PP (IN for) (NP (DT the) (JJ last) (JJ few) (NNS weeks))) (, ,) (NP (NP (JJ literary) (NNS punters)) (PP (IN throughout) (NP (DT the) (JJ British) (NNS Isles)))) (VP (VBP have) (VP (VBN been) (VP (VBG placing) (NP (NP (NNS bets)) (SBAR (WHPP (IN on) (WHNP (WHNP (WDT which)) (PP (IN of) (NP (DT those))))) (S (NP (NNS writers)) (VP (MD would) (VP (VB win) (NP (NP (DT the) (NNP Booker) (NNP Prize)) (, ,) (NP (NP (DT the) (ADJP (JJ best-known) (, ,) (JJ best-liked))) (CC and) (PRN (, ,) (ADVP (RB almost)) (ADVP (RB incidentally)) (, ,)) (NP (JJS most))))))))) (NP-TMP (NP (JJ prestigious) (NN fiction) (NN award)) (PP (IN in) (NP (DT the) (NN land))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Booker Prize , the best-known , best-liked and , almost incidentally , most" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="Booker" />
            <token id="27" string="Prize" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
            <token id="33" string="and" />
            <token id="34" string="," />
            <token id="35" string="almost" />
            <token id="36" string="incidentally" />
            <token id="37" string="," />
            <token id="38" string="most" />
          </tokens>
        </chunking>
        <chunking id="2" string="the best-known , best-liked and , almost incidentally , most" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
            <token id="33" string="and" />
            <token id="34" string="," />
            <token id="35" string="almost" />
            <token id="36" string="incidentally" />
            <token id="37" string="," />
            <token id="38" string="most" />
          </tokens>
        </chunking>
        <chunking id="3" string="the best-known , best-liked" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
          </tokens>
        </chunking>
        <chunking id="4" string="the land" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="land" />
          </tokens>
        </chunking>
        <chunking id="5" string="would win the Booker Prize , the best-known , best-liked and , almost incidentally , most" type="VP">
          <tokens>
            <token id="23" string="would" />
            <token id="24" string="win" />
            <token id="25" string="the" />
            <token id="26" string="Booker" />
            <token id="27" string="Prize" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
            <token id="33" string="and" />
            <token id="34" string="," />
            <token id="35" string="almost" />
            <token id="36" string="incidentally" />
            <token id="37" string="," />
            <token id="38" string="most" />
          </tokens>
        </chunking>
        <chunking id="6" string="literary punters throughout the British Isles" type="NP">
          <tokens>
            <token id="8" string="literary" />
            <token id="9" string="punters" />
            <token id="10" string="throughout" />
            <token id="11" string="the" />
            <token id="12" string="British" />
            <token id="13" string="Isles" />
          </tokens>
        </chunking>
        <chunking id="7" string="literary punters" type="NP">
          <tokens>
            <token id="8" string="literary" />
            <token id="9" string="punters" />
          </tokens>
        </chunking>
        <chunking id="8" string="bets on which of those writers would win the Booker Prize , the best-known , best-liked and , almost incidentally , most" type="NP">
          <tokens>
            <token id="17" string="bets" />
            <token id="18" string="on" />
            <token id="19" string="which" />
            <token id="20" string="of" />
            <token id="21" string="those" />
            <token id="22" string="writers" />
            <token id="23" string="would" />
            <token id="24" string="win" />
            <token id="25" string="the" />
            <token id="26" string="Booker" />
            <token id="27" string="Prize" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
            <token id="33" string="and" />
            <token id="34" string="," />
            <token id="35" string="almost" />
            <token id="36" string="incidentally" />
            <token id="37" string="," />
            <token id="38" string="most" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Booker Prize" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="Booker" />
            <token id="27" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="10" string="win the Booker Prize , the best-known , best-liked and , almost incidentally , most" type="VP">
          <tokens>
            <token id="24" string="win" />
            <token id="25" string="the" />
            <token id="26" string="Booker" />
            <token id="27" string="Prize" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
            <token id="33" string="and" />
            <token id="34" string="," />
            <token id="35" string="almost" />
            <token id="36" string="incidentally" />
            <token id="37" string="," />
            <token id="38" string="most" />
          </tokens>
        </chunking>
        <chunking id="11" string="prestigious fiction award" type="NP">
          <tokens>
            <token id="39" string="prestigious" />
            <token id="40" string="fiction" />
            <token id="41" string="award" />
          </tokens>
        </chunking>
        <chunking id="12" string="bets" type="NP">
          <tokens>
            <token id="17" string="bets" />
          </tokens>
        </chunking>
        <chunking id="13" string="the British Isles" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="British" />
            <token id="13" string="Isles" />
          </tokens>
        </chunking>
        <chunking id="14" string="most" type="NP">
          <tokens>
            <token id="38" string="most" />
          </tokens>
        </chunking>
        <chunking id="15" string="on which of those writers would win the Booker Prize , the best-known , best-liked and , almost incidentally , most" type="SBAR">
          <tokens>
            <token id="18" string="on" />
            <token id="19" string="which" />
            <token id="20" string="of" />
            <token id="21" string="those" />
            <token id="22" string="writers" />
            <token id="23" string="would" />
            <token id="24" string="win" />
            <token id="25" string="the" />
            <token id="26" string="Booker" />
            <token id="27" string="Prize" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
            <token id="33" string="and" />
            <token id="34" string="," />
            <token id="35" string="almost" />
            <token id="36" string="incidentally" />
            <token id="37" string="," />
            <token id="38" string="most" />
          </tokens>
        </chunking>
        <chunking id="16" string="writers" type="NP">
          <tokens>
            <token id="22" string="writers" />
          </tokens>
        </chunking>
        <chunking id="17" string="been placing bets on which of those writers would win the Booker Prize , the best-known , best-liked and , almost incidentally , most prestigious fiction award in the land" type="VP">
          <tokens>
            <token id="15" string="been" />
            <token id="16" string="placing" />
            <token id="17" string="bets" />
            <token id="18" string="on" />
            <token id="19" string="which" />
            <token id="20" string="of" />
            <token id="21" string="those" />
            <token id="22" string="writers" />
            <token id="23" string="would" />
            <token id="24" string="win" />
            <token id="25" string="the" />
            <token id="26" string="Booker" />
            <token id="27" string="Prize" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
            <token id="33" string="and" />
            <token id="34" string="," />
            <token id="35" string="almost" />
            <token id="36" string="incidentally" />
            <token id="37" string="," />
            <token id="38" string="most" />
            <token id="39" string="prestigious" />
            <token id="40" string="fiction" />
            <token id="41" string="award" />
            <token id="42" string="in" />
            <token id="43" string="the" />
            <token id="44" string="land" />
          </tokens>
        </chunking>
        <chunking id="18" string="placing bets on which of those writers would win the Booker Prize , the best-known , best-liked and , almost incidentally , most prestigious fiction award in the land" type="VP">
          <tokens>
            <token id="16" string="placing" />
            <token id="17" string="bets" />
            <token id="18" string="on" />
            <token id="19" string="which" />
            <token id="20" string="of" />
            <token id="21" string="those" />
            <token id="22" string="writers" />
            <token id="23" string="would" />
            <token id="24" string="win" />
            <token id="25" string="the" />
            <token id="26" string="Booker" />
            <token id="27" string="Prize" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
            <token id="33" string="and" />
            <token id="34" string="," />
            <token id="35" string="almost" />
            <token id="36" string="incidentally" />
            <token id="37" string="," />
            <token id="38" string="most" />
            <token id="39" string="prestigious" />
            <token id="40" string="fiction" />
            <token id="41" string="award" />
            <token id="42" string="in" />
            <token id="43" string="the" />
            <token id="44" string="land" />
          </tokens>
        </chunking>
        <chunking id="19" string="have been placing bets on which of those writers would win the Booker Prize , the best-known , best-liked and , almost incidentally , most prestigious fiction award in the land" type="VP">
          <tokens>
            <token id="14" string="have" />
            <token id="15" string="been" />
            <token id="16" string="placing" />
            <token id="17" string="bets" />
            <token id="18" string="on" />
            <token id="19" string="which" />
            <token id="20" string="of" />
            <token id="21" string="those" />
            <token id="22" string="writers" />
            <token id="23" string="would" />
            <token id="24" string="win" />
            <token id="25" string="the" />
            <token id="26" string="Booker" />
            <token id="27" string="Prize" />
            <token id="28" string="," />
            <token id="29" string="the" />
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
            <token id="33" string="and" />
            <token id="34" string="," />
            <token id="35" string="almost" />
            <token id="36" string="incidentally" />
            <token id="37" string="," />
            <token id="38" string="most" />
            <token id="39" string="prestigious" />
            <token id="40" string="fiction" />
            <token id="41" string="award" />
            <token id="42" string="in" />
            <token id="43" string="the" />
            <token id="44" string="land" />
          </tokens>
        </chunking>
        <chunking id="20" string="the last few weeks" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="last" />
            <token id="5" string="few" />
            <token id="6" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="21" string="best-known , best-liked" type="ADJP">
          <tokens>
            <token id="30" string="best-known" />
            <token id="31" string="," />
            <token id="32" string="best-liked" />
          </tokens>
        </chunking>
        <chunking id="22" string="those" type="NP">
          <tokens>
            <token id="21" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="16">placing</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">weeks</governor>
          <dependent id="2">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">weeks</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">weeks</governor>
          <dependent id="4">last</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">weeks</governor>
          <dependent id="5">few</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">placing</governor>
          <dependent id="6">weeks</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">punters</governor>
          <dependent id="8">literary</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">placing</governor>
          <dependent id="9">punters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Isles</governor>
          <dependent id="10">throughout</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Isles</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">Isles</governor>
          <dependent id="12">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">punters</governor>
          <dependent id="13">Isles</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">placing</governor>
          <dependent id="14">have</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">placing</governor>
          <dependent id="15">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">placing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">placing</governor>
          <dependent id="17">bets</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">which</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">win</governor>
          <dependent id="19">which</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">those</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">which</governor>
          <dependent id="21">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">win</governor>
          <dependent id="22">writers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">win</governor>
          <dependent id="23">would</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">bets</governor>
          <dependent id="24">win</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">Prize</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Prize</governor>
          <dependent id="26">Booker</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">win</governor>
          <dependent id="27">Prize</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">best-liked</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">best-liked</governor>
          <dependent id="30">best-known</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="27">Prize</governor>
          <dependent id="32">best-liked</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">best-liked</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="32">best-liked</governor>
          <dependent id="35">almost</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="35">almost</governor>
          <dependent id="36">incidentally</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">best-liked</governor>
          <dependent id="38">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">award</governor>
          <dependent id="39">prestigious</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">award</governor>
          <dependent id="40">fiction</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="16">placing</governor>
          <dependent id="41">award</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">land</governor>
          <dependent id="42">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">land</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">award</governor>
          <dependent id="44">land</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="Isles" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Isles" />
          </tokens>
        </entity>
        <entity id="3" string="the last few weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="last" />
            <token id="5" string="few" />
            <token id="6" string="weeks" />
          </tokens>
        </entity>
        <entity id="4" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="26" string="Booker" />
            <token id="27" string="Prize" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="false">
      <content>In recent weeks the Booker contenders have received almost as much press coverage as the Charles and Di rift.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="contenders" lemma="contender" stem="contend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="received" lemma="receive" stem="receiv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="coverage" lemma="coverage" stem="coverag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Charles" lemma="Charles" stem="charl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Di" lemma="Di" stem="di" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="19" string="rift" lemma="rift" stem="rift" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (JJ recent) (NNS weeks))) (NP (DT the) (NNP Booker) (NNS contenders)) (VP (VBP have) (VP (VBN received) (NP (QP (RB almost) (RB as) (JJ much)) (NN press) (NN coverage)) (PP (IN as) (NP (NP (DT the) (NNP Charles)) (CC and) (NP (NNP Di) (NN rift)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have received almost as much press coverage as the Charles and Di rift" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="received" />
            <token id="9" string="almost" />
            <token id="10" string="as" />
            <token id="11" string="much" />
            <token id="12" string="press" />
            <token id="13" string="coverage" />
            <token id="14" string="as" />
            <token id="15" string="the" />
            <token id="16" string="Charles" />
            <token id="17" string="and" />
            <token id="18" string="Di" />
            <token id="19" string="rift" />
          </tokens>
        </chunking>
        <chunking id="2" string="received almost as much press coverage as the Charles and Di rift" type="VP">
          <tokens>
            <token id="8" string="received" />
            <token id="9" string="almost" />
            <token id="10" string="as" />
            <token id="11" string="much" />
            <token id="12" string="press" />
            <token id="13" string="coverage" />
            <token id="14" string="as" />
            <token id="15" string="the" />
            <token id="16" string="Charles" />
            <token id="17" string="and" />
            <token id="18" string="Di" />
            <token id="19" string="rift" />
          </tokens>
        </chunking>
        <chunking id="3" string="almost as much press coverage" type="NP">
          <tokens>
            <token id="9" string="almost" />
            <token id="10" string="as" />
            <token id="11" string="much" />
            <token id="12" string="press" />
            <token id="13" string="coverage" />
          </tokens>
        </chunking>
        <chunking id="4" string="recent weeks" type="NP">
          <tokens>
            <token id="2" string="recent" />
            <token id="3" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Booker contenders" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Booker" />
            <token id="6" string="contenders" />
          </tokens>
        </chunking>
        <chunking id="6" string="Di rift" type="NP">
          <tokens>
            <token id="18" string="Di" />
            <token id="19" string="rift" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Charles" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Charles" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Charles and Di rift" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="Charles" />
            <token id="17" string="and" />
            <token id="18" string="Di" />
            <token id="19" string="rift" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">weeks</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">weeks</governor>
          <dependent id="2">recent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">received</governor>
          <dependent id="3">weeks</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">contenders</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">contenders</governor>
          <dependent id="5">Booker</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">received</governor>
          <dependent id="6">contenders</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">received</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">received</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">much</governor>
          <dependent id="9">almost</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">much</governor>
          <dependent id="10">as</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">coverage</governor>
          <dependent id="11">much</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">coverage</governor>
          <dependent id="12">press</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">received</governor>
          <dependent id="13">coverage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Charles</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">Charles</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">received</governor>
          <dependent id="16">Charles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">Charles</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">rift</governor>
          <dependent id="18">Di</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">Charles</governor>
          <dependent id="19">rift</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="recent weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="recent" />
            <token id="3" string="weeks" />
          </tokens>
        </entity>
        <entity id="2" string="Di" type="MISC" score="0.0">
          <tokens>
            <token id="18" string="Di" />
          </tokens>
        </entity>
        <entity id="3" string="Charles" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Charles" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>And nearly every article, from book reviews to author interviews, has featured the latest odds.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="article" lemma="article" stem="articl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="reviews" lemma="review" stem="review" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="featured" lemma="feature" stem="featur" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="latest" lemma="latest" stem="latest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="odds" lemma="odds" stem="odd" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (RB nearly) (DT every) (NN article)) (, ,) (PP (IN from) (NP (NP (NN book)) (SBAR (S (VP (VBZ reviews) (PP (TO to) (NP (NN author) (NNS interviews)))))))) (, ,)) (VP (VBZ has) (VP (VBN featured) (NP (DT the) (JJS latest) (NNS odds)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="book" type="NP">
          <tokens>
            <token id="7" string="book" />
          </tokens>
        </chunking>
        <chunking id="2" string="the latest odds" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="latest" />
            <token id="17" string="odds" />
          </tokens>
        </chunking>
        <chunking id="3" string="nearly every article" type="NP">
          <tokens>
            <token id="2" string="nearly" />
            <token id="3" string="every" />
            <token id="4" string="article" />
          </tokens>
        </chunking>
        <chunking id="4" string="author interviews" type="NP">
          <tokens>
            <token id="10" string="author" />
            <token id="11" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="5" string="featured the latest odds" type="VP">
          <tokens>
            <token id="14" string="featured" />
            <token id="15" string="the" />
            <token id="16" string="latest" />
            <token id="17" string="odds" />
          </tokens>
        </chunking>
        <chunking id="6" string="book reviews to author interviews" type="NP">
          <tokens>
            <token id="7" string="book" />
            <token id="8" string="reviews" />
            <token id="9" string="to" />
            <token id="10" string="author" />
            <token id="11" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="7" string="has featured the latest odds" type="VP">
          <tokens>
            <token id="13" string="has" />
            <token id="14" string="featured" />
            <token id="15" string="the" />
            <token id="16" string="latest" />
            <token id="17" string="odds" />
          </tokens>
        </chunking>
        <chunking id="8" string="reviews to author interviews" type="SBAR">
          <tokens>
            <token id="8" string="reviews" />
            <token id="9" string="to" />
            <token id="10" string="author" />
            <token id="11" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="9" string="nearly every article , from book reviews to author interviews ," type="NP">
          <tokens>
            <token id="2" string="nearly" />
            <token id="3" string="every" />
            <token id="4" string="article" />
            <token id="5" string="," />
            <token id="6" string="from" />
            <token id="7" string="book" />
            <token id="8" string="reviews" />
            <token id="9" string="to" />
            <token id="10" string="author" />
            <token id="11" string="interviews" />
            <token id="12" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="14">featured</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">article</governor>
          <dependent id="2">nearly</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">article</governor>
          <dependent id="3">every</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">featured</governor>
          <dependent id="4">article</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">book</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">article</governor>
          <dependent id="7">book</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">book</governor>
          <dependent id="8">reviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">interviews</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">interviews</governor>
          <dependent id="10">author</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">reviews</governor>
          <dependent id="11">interviews</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">featured</governor>
          <dependent id="13">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">featured</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">odds</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">odds</governor>
          <dependent id="16">latest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">featured</governor>
          <dependent id="17">odds</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>The betting is done largely by literary insiders, says Graham Sharpe, who sets the Booker odds at William Hill, Britain&amp;apost;s other big betting agency.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="betting" lemma="bet" stem="bet" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="largely" lemma="largely" stem="larg" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="insiders" lemma="insider" stem="insid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Graham" lemma="Graham" stem="graham" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Sharpe" lemma="Sharpe" stem="sharp" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="sets" lemma="set" stem="set" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="odds" lemma="odds" stem="odd" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="Hill" lemma="Hill" stem="hill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="24" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="big" lemma="big" stem="big" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="betting" lemma="bet" stem="bet" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="agency" lemma="agency" stem="agenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (DT The) (VBG betting)) (VP (VBZ is) (VP (VBN done) (ADVP (RB largely)) (PP (IN by) (NP (JJ literary) (NNS insiders)))))) (, ,) (VP (VBZ says)) (NP (NP (NNP Graham) (NNP Sharpe)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ sets) (NP (DT the) (NNP Booker) (NNS odds)) (PP (IN at) (NP (NP (NNP William) (NNP Hill)) (, ,) (NP (NP (NNP Britain) (POS 's)) (JJ other) (JJ big) (VBG betting) (NN agency)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="William Hill , Britain 's other big betting agency" type="NP">
          <tokens>
            <token id="20" string="William" />
            <token id="21" string="Hill" />
            <token id="22" string="," />
            <token id="23" string="Britain" />
            <token id="24" string="'s" />
            <token id="25" string="other" />
            <token id="26" string="big" />
            <token id="27" string="betting" />
            <token id="28" string="agency" />
          </tokens>
        </chunking>
        <chunking id="2" string="Graham Sharpe , who sets the Booker odds at William Hill , Britain 's other big betting agency" type="NP">
          <tokens>
            <token id="11" string="Graham" />
            <token id="12" string="Sharpe" />
            <token id="13" string="," />
            <token id="14" string="who" />
            <token id="15" string="sets" />
            <token id="16" string="the" />
            <token id="17" string="Booker" />
            <token id="18" string="odds" />
            <token id="19" string="at" />
            <token id="20" string="William" />
            <token id="21" string="Hill" />
            <token id="22" string="," />
            <token id="23" string="Britain" />
            <token id="24" string="'s" />
            <token id="25" string="other" />
            <token id="26" string="big" />
            <token id="27" string="betting" />
            <token id="28" string="agency" />
          </tokens>
        </chunking>
        <chunking id="3" string="who sets the Booker odds at William Hill , Britain 's other big betting agency" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="sets" />
            <token id="16" string="the" />
            <token id="17" string="Booker" />
            <token id="18" string="odds" />
            <token id="19" string="at" />
            <token id="20" string="William" />
            <token id="21" string="Hill" />
            <token id="22" string="," />
            <token id="23" string="Britain" />
            <token id="24" string="'s" />
            <token id="25" string="other" />
            <token id="26" string="big" />
            <token id="27" string="betting" />
            <token id="28" string="agency" />
          </tokens>
        </chunking>
        <chunking id="4" string="Britain 's other big betting agency" type="NP">
          <tokens>
            <token id="23" string="Britain" />
            <token id="24" string="'s" />
            <token id="25" string="other" />
            <token id="26" string="big" />
            <token id="27" string="betting" />
            <token id="28" string="agency" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Booker odds" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="Booker" />
            <token id="18" string="odds" />
          </tokens>
        </chunking>
        <chunking id="6" string="says" type="VP">
          <tokens>
            <token id="10" string="says" />
          </tokens>
        </chunking>
        <chunking id="7" string="literary insiders" type="NP">
          <tokens>
            <token id="7" string="literary" />
            <token id="8" string="insiders" />
          </tokens>
        </chunking>
        <chunking id="8" string="Graham Sharpe" type="NP">
          <tokens>
            <token id="11" string="Graham" />
            <token id="12" string="Sharpe" />
          </tokens>
        </chunking>
        <chunking id="9" string="The betting" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="betting" />
          </tokens>
        </chunking>
        <chunking id="10" string="done largely by literary insiders" type="VP">
          <tokens>
            <token id="4" string="done" />
            <token id="5" string="largely" />
            <token id="6" string="by" />
            <token id="7" string="literary" />
            <token id="8" string="insiders" />
          </tokens>
        </chunking>
        <chunking id="11" string="Britain 's" type="NP">
          <tokens>
            <token id="23" string="Britain" />
            <token id="24" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="is done largely by literary insiders" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="done" />
            <token id="5" string="largely" />
            <token id="6" string="by" />
            <token id="7" string="literary" />
            <token id="8" string="insiders" />
          </tokens>
        </chunking>
        <chunking id="13" string="William Hill" type="NP">
          <tokens>
            <token id="20" string="William" />
            <token id="21" string="Hill" />
          </tokens>
        </chunking>
        <chunking id="14" string="sets the Booker odds at William Hill , Britain 's other big betting agency" type="VP">
          <tokens>
            <token id="15" string="sets" />
            <token id="16" string="the" />
            <token id="17" string="Booker" />
            <token id="18" string="odds" />
            <token id="19" string="at" />
            <token id="20" string="William" />
            <token id="21" string="Hill" />
            <token id="22" string="," />
            <token id="23" string="Britain" />
            <token id="24" string="'s" />
            <token id="25" string="other" />
            <token id="26" string="big" />
            <token id="27" string="betting" />
            <token id="28" string="agency" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">done</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">The</governor>
          <dependent id="2">betting</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">done</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">says</governor>
          <dependent id="4">done</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">done</governor>
          <dependent id="5">largely</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">insiders</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">insiders</governor>
          <dependent id="7">literary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">done</governor>
          <dependent id="8">insiders</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Sharpe</governor>
          <dependent id="11">Graham</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">says</governor>
          <dependent id="12">Sharpe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">sets</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">Sharpe</governor>
          <dependent id="15">sets</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">odds</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">odds</governor>
          <dependent id="17">Booker</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">sets</governor>
          <dependent id="18">odds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Hill</governor>
          <dependent id="19">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Hill</governor>
          <dependent id="20">William</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">sets</governor>
          <dependent id="21">Hill</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">agency</governor>
          <dependent id="23">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Britain</governor>
          <dependent id="24">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">agency</governor>
          <dependent id="25">other</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">agency</governor>
          <dependent id="26">big</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">agency</governor>
          <dependent id="27">betting</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="21">Hill</governor>
          <dependent id="28">agency</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Graham Sharpe" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Graham" />
            <token id="12" string="Sharpe" />
          </tokens>
        </entity>
        <entity id="2" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Booker" />
          </tokens>
        </entity>
        <entity id="3" string="William Hill" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="William" />
            <token id="21" string="Hill" />
          </tokens>
        </entity>
        <entity id="4" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>&amp;quot;They read the books, hear the gossip and want to pull off a little coup for themselves,&amp;quot; he says.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="read" lemma="read" stem="read" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="hear" lemma="hear" stem="hear" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="gossip" lemma="gossip" stem="gossip" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="pull" lemma="pull" stem="pull" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="coup" lemma="coup" stem="coup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="themselves" lemma="themselves" stem="themselv" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP They)) (VP (VP (VBP read) (NP (DT the) (NNS books))) (, ,) (VP (VB hear) (NP (DT the) (NN gossip))) (CC and) (VP (VBP want) (S (VP (TO to) (VP (VB pull) (PRT (RP off)) (NP (NP (DT a) (JJ little) (NN coup)) (PP (IN for) (NP (PRP themselves)))))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBZ says)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="want to pull off a little coup for themselves" type="VP">
          <tokens>
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="pull" />
            <token id="14" string="off" />
            <token id="15" string="a" />
            <token id="16" string="little" />
            <token id="17" string="coup" />
            <token id="18" string="for" />
            <token id="19" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="3" string="to pull off a little coup for themselves" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="pull" />
            <token id="14" string="off" />
            <token id="15" string="a" />
            <token id="16" string="little" />
            <token id="17" string="coup" />
            <token id="18" string="for" />
            <token id="19" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="4" string="hear the gossip" type="VP">
          <tokens>
            <token id="7" string="hear" />
            <token id="8" string="the" />
            <token id="9" string="gossip" />
          </tokens>
        </chunking>
        <chunking id="5" string="read the books , hear the gossip and want to pull off a little coup for themselves" type="VP">
          <tokens>
            <token id="3" string="read" />
            <token id="4" string="the" />
            <token id="5" string="books" />
            <token id="6" string="," />
            <token id="7" string="hear" />
            <token id="8" string="the" />
            <token id="9" string="gossip" />
            <token id="10" string="and" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="pull" />
            <token id="14" string="off" />
            <token id="15" string="a" />
            <token id="16" string="little" />
            <token id="17" string="coup" />
            <token id="18" string="for" />
            <token id="19" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="6" string="a little coup for themselves" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="little" />
            <token id="17" string="coup" />
            <token id="18" string="for" />
            <token id="19" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="7" string="says" type="VP">
          <tokens>
            <token id="23" string="says" />
          </tokens>
        </chunking>
        <chunking id="8" string="themselves" type="NP">
          <tokens>
            <token id="19" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="9" string="the gossip" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="gossip" />
          </tokens>
        </chunking>
        <chunking id="10" string="a little coup" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="little" />
            <token id="17" string="coup" />
          </tokens>
        </chunking>
        <chunking id="11" string="pull off a little coup for themselves" type="VP">
          <tokens>
            <token id="13" string="pull" />
            <token id="14" string="off" />
            <token id="15" string="a" />
            <token id="16" string="little" />
            <token id="17" string="coup" />
            <token id="18" string="for" />
            <token id="19" string="themselves" />
          </tokens>
        </chunking>
        <chunking id="12" string="the books" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="books" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="22" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="read the books" type="VP">
          <tokens>
            <token id="3" string="read" />
            <token id="4" string="the" />
            <token id="5" string="books" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">read</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">says</governor>
          <dependent id="3">read</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">books</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">read</governor>
          <dependent id="5">books</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">read</governor>
          <dependent id="7">hear</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">gossip</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">hear</governor>
          <dependent id="9">gossip</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">read</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">read</governor>
          <dependent id="11">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">pull</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">want</governor>
          <dependent id="13">pull</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="13">pull</governor>
          <dependent id="14">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">coup</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">coup</governor>
          <dependent id="16">little</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">pull</governor>
          <dependent id="17">coup</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">themselves</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">coup</governor>
          <dependent id="19">themselves</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">says</governor>
          <dependent id="22">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">says</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Last year&amp;apost;s winner, &amp;quot;The Old Devils&amp;quot; by Kingsley Amis, was a 5-2 favorite, but this year, anyone who chose the victor made some dough.</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Old" lemma="Old" stem="old" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Devils" lemma="Devils" stem="devil" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Kingsley" lemma="Kingsley" stem="kingslei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Amis" lemma="Amis" stem="ami" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="5-2" lemma="5-2" stem="5-2" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="favorite" lemma="favorite" stem="favorit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="anyone" lemma="anyone" stem="anyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="chose" lemma="choose" stem="chose" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="victor" lemma="victor" stem="victor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="dough" lemma="dough" stem="dough" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NP (JJ Last) (NN year) (POS 's)) (NN winner)) (, ,) (NP (`` ``) (NP (DT The) (NNP Old) (NNPS Devils)) ('' '') (PP (IN by) (NP (NNP Kingsley) (NNP Amis)))) (, ,)) (VP (VBD was) (NP (DT a) (JJ 5-2) (JJ favorite)))) (, ,) (CC but) (S (NP-TMP (DT this) (NN year)) (, ,) (NP (NP (NN anyone)) (SBAR (WHNP (WP who)) (S (VP (VBD chose) (NP (DT the) (NN victor)))))) (VP (VBD made) (NP (DT some) (NN dough)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Old Devils" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="Old" />
            <token id="9" string="Devils" />
          </tokens>
        </chunking>
        <chunking id="2" string="Last year 's" type="NP">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="who chose the victor" type="SBAR">
          <tokens>
            <token id="25" string="who" />
            <token id="26" string="chose" />
            <token id="27" string="the" />
            <token id="28" string="victor" />
          </tokens>
        </chunking>
        <chunking id="4" string="made some dough" type="VP">
          <tokens>
            <token id="29" string="made" />
            <token id="30" string="some" />
            <token id="31" string="dough" />
          </tokens>
        </chunking>
        <chunking id="5" string="Last year 's winner" type="NP">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
            <token id="3" string="'s" />
            <token id="4" string="winner" />
          </tokens>
        </chunking>
        <chunking id="6" string="Last year 's winner , `` The Old Devils '' by Kingsley Amis ," type="NP">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
            <token id="3" string="'s" />
            <token id="4" string="winner" />
            <token id="5" string="," />
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="Old" />
            <token id="9" string="Devils" />
            <token id="10" string="&quot;" />
            <token id="11" string="by" />
            <token id="12" string="Kingsley" />
            <token id="13" string="Amis" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="a 5-2 favorite" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="5-2" />
            <token id="18" string="favorite" />
          </tokens>
        </chunking>
        <chunking id="8" string="Kingsley Amis" type="NP">
          <tokens>
            <token id="12" string="Kingsley" />
            <token id="13" string="Amis" />
          </tokens>
        </chunking>
        <chunking id="9" string="the victor" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="victor" />
          </tokens>
        </chunking>
        <chunking id="10" string="some dough" type="NP">
          <tokens>
            <token id="30" string="some" />
            <token id="31" string="dough" />
          </tokens>
        </chunking>
        <chunking id="11" string="`` The Old Devils '' by Kingsley Amis" type="NP">
          <tokens>
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="Old" />
            <token id="9" string="Devils" />
            <token id="10" string="&quot;" />
            <token id="11" string="by" />
            <token id="12" string="Kingsley" />
            <token id="13" string="Amis" />
          </tokens>
        </chunking>
        <chunking id="12" string="anyone" type="NP">
          <tokens>
            <token id="24" string="anyone" />
          </tokens>
        </chunking>
        <chunking id="13" string="was a 5-2 favorite" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="a" />
            <token id="17" string="5-2" />
            <token id="18" string="favorite" />
          </tokens>
        </chunking>
        <chunking id="14" string="chose the victor" type="VP">
          <tokens>
            <token id="26" string="chose" />
            <token id="27" string="the" />
            <token id="28" string="victor" />
          </tokens>
        </chunking>
        <chunking id="15" string="anyone who chose the victor" type="NP">
          <tokens>
            <token id="24" string="anyone" />
            <token id="25" string="who" />
            <token id="26" string="chose" />
            <token id="27" string="the" />
            <token id="28" string="victor" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">year</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">winner</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">year</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">favorite</governor>
          <dependent id="4">winner</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Devils</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Devils</governor>
          <dependent id="8">Old</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">winner</governor>
          <dependent id="9">Devils</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Amis</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Amis</governor>
          <dependent id="12">Kingsley</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Devils</governor>
          <dependent id="13">Amis</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">favorite</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">favorite</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">favorite</governor>
          <dependent id="17">5-2</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">favorite</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">favorite</governor>
          <dependent id="20">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">year</governor>
          <dependent id="21">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="29">made</governor>
          <dependent id="22">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">made</governor>
          <dependent id="24">anyone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">chose</governor>
          <dependent id="25">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">anyone</governor>
          <dependent id="26">chose</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">victor</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">chose</governor>
          <dependent id="28">victor</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">favorite</governor>
          <dependent id="29">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">dough</governor>
          <dependent id="30">some</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">made</governor>
          <dependent id="31">dough</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Last year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="this year" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="this" />
            <token id="22" string="year" />
          </tokens>
        </entity>
        <entity id="3" string="Kingsley Amis" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Kingsley" />
            <token id="13" string="Amis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>&amp;quot;When she accepted her prize for &amp;quot;Moon Tiger,&amp;quot; Penelope Lively looked surprised and pleased.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="accepted" lemma="accept" stem="accept" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Moon" lemma="Moon" stem="moon" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Tiger" lemma="Tiger" stem="tiger" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Penelope" lemma="Penelope" stem="penelop" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="Lively" lemma="Lively" stem="live" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="looked" lemma="look" stem="look" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="surprised" lemma="surprised" stem="surpris" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="pleased" lemma="pleased" stem="pleas" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (WHADVP (WRB When)) (S (NP (PRP she)) (VP (VBD accepted) (NP (PRP$ her) (NN prize)) (PP (IN for) (`` ``) (NP (NNP Moon) (NNP Tiger)))))) (, ,) ('' '') (NP (NNP Penelope) (NNP Lively)) (VP (VBD looked) (ADJP (JJ surprised) (CC and) (JJ pleased))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="When" type="WHADVP">
          <tokens>
            <token id="2" string="When" />
          </tokens>
        </chunking>
        <chunking id="2" string="Moon Tiger" type="NP">
          <tokens>
            <token id="9" string="Moon" />
            <token id="10" string="Tiger" />
          </tokens>
        </chunking>
        <chunking id="3" string="her prize" type="NP">
          <tokens>
            <token id="5" string="her" />
            <token id="6" string="prize" />
          </tokens>
        </chunking>
        <chunking id="4" string="Penelope Lively" type="NP">
          <tokens>
            <token id="13" string="Penelope" />
            <token id="14" string="Lively" />
          </tokens>
        </chunking>
        <chunking id="5" string="looked surprised and pleased" type="VP">
          <tokens>
            <token id="15" string="looked" />
            <token id="16" string="surprised" />
            <token id="17" string="and" />
            <token id="18" string="pleased" />
          </tokens>
        </chunking>
        <chunking id="6" string="When she accepted her prize for `` Moon Tiger" type="SBAR">
          <tokens>
            <token id="2" string="When" />
            <token id="3" string="she" />
            <token id="4" string="accepted" />
            <token id="5" string="her" />
            <token id="6" string="prize" />
            <token id="7" string="for" />
            <token id="8" string="&quot;" />
            <token id="9" string="Moon" />
            <token id="10" string="Tiger" />
          </tokens>
        </chunking>
        <chunking id="7" string="accepted her prize for `` Moon Tiger" type="VP">
          <tokens>
            <token id="4" string="accepted" />
            <token id="5" string="her" />
            <token id="6" string="prize" />
            <token id="7" string="for" />
            <token id="8" string="&quot;" />
            <token id="9" string="Moon" />
            <token id="10" string="Tiger" />
          </tokens>
        </chunking>
        <chunking id="8" string="surprised and pleased" type="ADJP">
          <tokens>
            <token id="16" string="surprised" />
            <token id="17" string="and" />
            <token id="18" string="pleased" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">accepted</governor>
          <dependent id="2">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">accepted</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">looked</governor>
          <dependent id="4">accepted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">prize</governor>
          <dependent id="5">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">accepted</governor>
          <dependent id="6">prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Tiger</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Tiger</governor>
          <dependent id="9">Moon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">accepted</governor>
          <dependent id="10">Tiger</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Lively</governor>
          <dependent id="13">Penelope</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">looked</governor>
          <dependent id="14">Lively</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">looked</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">looked</governor>
          <dependent id="16">surprised</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">surprised</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">surprised</governor>
          <dependent id="18">pleased</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Penelope Lively" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Penelope" />
            <token id="14" string="Lively" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>&amp;quot;I&amp;apost;m not a betting woman, and I have slight reservations about books becoming a spectator sport,&amp;quot; she said in soft Oxbridge tones.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="betting" lemma="bet" stem="bet" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="woman" lemma="woman" stem="woman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="slight" lemma="slight" stem="slight" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="reservations" lemma="reservation" stem="reserv" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="becoming" lemma="become" stem="becom" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="spectator" lemma="spectator" stem="spectat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="sport" lemma="sport" stem="sport" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="soft" lemma="soft" stem="soft" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Oxbridge" lemma="oxbridge" stem="oxbridg" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="27" string="tones" lemma="tone" stem="tone" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP I)) (VP (VBP 'm) (RB not) (NP (DT a) (VBG betting) (NN woman)))) (, ,) (CC and) (S (NP (PRP I)) (VP (VBP have) (NP (NP (JJ slight) (NNS reservations)) (PP (IN about) (NP (NP (NNS books)) (VP (VBG becoming) (NP (DT a) (NN spectator) (NN sport))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said) (PP (IN in) (NP (JJ soft) (JJ Oxbridge) (NNS tones)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'m not a betting woman" type="VP">
          <tokens>
            <token id="3" string="'m" />
            <token id="4" string="not" />
            <token id="5" string="a" />
            <token id="6" string="betting" />
            <token id="7" string="woman" />
          </tokens>
        </chunking>
        <chunking id="2" string="soft Oxbridge tones" type="NP">
          <tokens>
            <token id="25" string="soft" />
            <token id="26" string="Oxbridge" />
            <token id="27" string="tones" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="slight reservations" type="NP">
          <tokens>
            <token id="12" string="slight" />
            <token id="13" string="reservations" />
          </tokens>
        </chunking>
        <chunking id="5" string="she" type="NP">
          <tokens>
            <token id="22" string="she" />
          </tokens>
        </chunking>
        <chunking id="6" string="books" type="NP">
          <tokens>
            <token id="15" string="books" />
          </tokens>
        </chunking>
        <chunking id="7" string="becoming a spectator sport" type="VP">
          <tokens>
            <token id="16" string="becoming" />
            <token id="17" string="a" />
            <token id="18" string="spectator" />
            <token id="19" string="sport" />
          </tokens>
        </chunking>
        <chunking id="8" string="slight reservations about books becoming a spectator sport" type="NP">
          <tokens>
            <token id="12" string="slight" />
            <token id="13" string="reservations" />
            <token id="14" string="about" />
            <token id="15" string="books" />
            <token id="16" string="becoming" />
            <token id="17" string="a" />
            <token id="18" string="spectator" />
            <token id="19" string="sport" />
          </tokens>
        </chunking>
        <chunking id="9" string="books becoming a spectator sport" type="NP">
          <tokens>
            <token id="15" string="books" />
            <token id="16" string="becoming" />
            <token id="17" string="a" />
            <token id="18" string="spectator" />
            <token id="19" string="sport" />
          </tokens>
        </chunking>
        <chunking id="10" string="a betting woman" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="betting" />
            <token id="7" string="woman" />
          </tokens>
        </chunking>
        <chunking id="11" string="a spectator sport" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="spectator" />
            <token id="19" string="sport" />
          </tokens>
        </chunking>
        <chunking id="12" string="said in soft Oxbridge tones" type="VP">
          <tokens>
            <token id="23" string="said" />
            <token id="24" string="in" />
            <token id="25" string="soft" />
            <token id="26" string="Oxbridge" />
            <token id="27" string="tones" />
          </tokens>
        </chunking>
        <chunking id="13" string="have slight reservations about books becoming a spectator sport" type="VP">
          <tokens>
            <token id="11" string="have" />
            <token id="12" string="slight" />
            <token id="13" string="reservations" />
            <token id="14" string="about" />
            <token id="15" string="books" />
            <token id="16" string="becoming" />
            <token id="17" string="a" />
            <token id="18" string="spectator" />
            <token id="19" string="sport" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">woman</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">woman</governor>
          <dependent id="3">'m</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">woman</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">woman</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">woman</governor>
          <dependent id="6">betting</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">said</governor>
          <dependent id="7">woman</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">woman</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">have</governor>
          <dependent id="10">I</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">woman</governor>
          <dependent id="11">have</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">reservations</governor>
          <dependent id="12">slight</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">have</governor>
          <dependent id="13">reservations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">books</governor>
          <dependent id="14">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">reservations</governor>
          <dependent id="15">books</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">books</governor>
          <dependent id="16">becoming</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">sport</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">sport</governor>
          <dependent id="18">spectator</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">becoming</governor>
          <dependent id="19">sport</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">said</governor>
          <dependent id="22">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="23">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">tones</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">tones</governor>
          <dependent id="25">soft</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">tones</governor>
          <dependent id="26">Oxbridge</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">said</governor>
          <dependent id="27">tones</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oxbridge" type="MISC" score="0.0">
          <tokens>
            <token id="26" string="Oxbridge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>&amp;quot;But those who are in the know tell me that 7-1 was an irresistible flutter.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="7-1" lemma="7-1" stem="7-1" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="irresistible" lemma="irresistible" stem="irresist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="flutter" lemma="flutter" stem="flutter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC But) (NP (NP (DT those)) (SBAR (WHNP (WP who)) (S (VP (VBP are) (PP (IN in) (NP (DT the))))))) (VP (VBP know) (VP (VB tell) (NP (PRP me)) (SBAR (IN that) (S (NP (CD 7-1)) (VP (VBD was) (NP (DT an) (JJ irresistible) (NN flutter))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the" type="NP">
          <tokens>
            <token id="7" string="the" />
          </tokens>
        </chunking>
        <chunking id="2" string="who are in the" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="are" />
            <token id="6" string="in" />
            <token id="7" string="the" />
          </tokens>
        </chunking>
        <chunking id="3" string="tell me that 7-1 was an irresistible flutter" type="VP">
          <tokens>
            <token id="9" string="tell" />
            <token id="10" string="me" />
            <token id="11" string="that" />
            <token id="12" string="7-1" />
            <token id="13" string="was" />
            <token id="14" string="an" />
            <token id="15" string="irresistible" />
            <token id="16" string="flutter" />
          </tokens>
        </chunking>
        <chunking id="4" string="know tell me that 7-1 was an irresistible flutter" type="VP">
          <tokens>
            <token id="8" string="know" />
            <token id="9" string="tell" />
            <token id="10" string="me" />
            <token id="11" string="that" />
            <token id="12" string="7-1" />
            <token id="13" string="was" />
            <token id="14" string="an" />
            <token id="15" string="irresistible" />
            <token id="16" string="flutter" />
          </tokens>
        </chunking>
        <chunking id="5" string="are in the" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="in" />
            <token id="7" string="the" />
          </tokens>
        </chunking>
        <chunking id="6" string="me" type="NP">
          <tokens>
            <token id="10" string="me" />
          </tokens>
        </chunking>
        <chunking id="7" string="was an irresistible flutter" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="an" />
            <token id="15" string="irresistible" />
            <token id="16" string="flutter" />
          </tokens>
        </chunking>
        <chunking id="8" string="an irresistible flutter" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="irresistible" />
            <token id="16" string="flutter" />
          </tokens>
        </chunking>
        <chunking id="9" string="that 7-1 was an irresistible flutter" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="7-1" />
            <token id="13" string="was" />
            <token id="14" string="an" />
            <token id="15" string="irresistible" />
            <token id="16" string="flutter" />
          </tokens>
        </chunking>
        <chunking id="10" string="7-1" type="NP">
          <tokens>
            <token id="12" string="7-1" />
          </tokens>
        </chunking>
        <chunking id="11" string="those who are in the" type="NP">
          <tokens>
            <token id="3" string="those" />
            <token id="4" string="who" />
            <token id="5" string="are" />
            <token id="6" string="in" />
            <token id="7" string="the" />
          </tokens>
        </chunking>
        <chunking id="12" string="those" type="NP">
          <tokens>
            <token id="3" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">know</governor>
          <dependent id="2">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">know</governor>
          <dependent id="3">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">the</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">the</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">the</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">those</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">know</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">know</governor>
          <dependent id="9">tell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">tell</governor>
          <dependent id="10">me</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">flutter</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">flutter</governor>
          <dependent id="12">7-1</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">flutter</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">flutter</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">flutter</governor>
          <dependent id="15">irresistible</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">tell</governor>
          <dependent id="16">flutter</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="7-1" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="7-1" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Her 65-year-old mother was among those who made a killing.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="65-year-old" lemma="65-year-old" stem="65-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="among" lemma="among" stem="among" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="killing" lemma="killing" stem="kill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Her) (JJ 65-year-old) (NN mother)) (VP (VBD was) (PP (IN among) (NP (NP (DT those)) (SBAR (WHNP (WP who)) (S (VP (VBD made) (NP (DT a) (NN killing)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Her 65-year-old mother" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="65-year-old" />
            <token id="3" string="mother" />
          </tokens>
        </chunking>
        <chunking id="2" string="was among those who made a killing" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="among" />
            <token id="6" string="those" />
            <token id="7" string="who" />
            <token id="8" string="made" />
            <token id="9" string="a" />
            <token id="10" string="killing" />
          </tokens>
        </chunking>
        <chunking id="3" string="made a killing" type="VP">
          <tokens>
            <token id="8" string="made" />
            <token id="9" string="a" />
            <token id="10" string="killing" />
          </tokens>
        </chunking>
        <chunking id="4" string="who made a killing" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="made" />
            <token id="9" string="a" />
            <token id="10" string="killing" />
          </tokens>
        </chunking>
        <chunking id="5" string="a killing" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="killing" />
          </tokens>
        </chunking>
        <chunking id="6" string="those who made a killing" type="NP">
          <tokens>
            <token id="6" string="those" />
            <token id="7" string="who" />
            <token id="8" string="made" />
            <token id="9" string="a" />
            <token id="10" string="killing" />
          </tokens>
        </chunking>
        <chunking id="7" string="those" type="NP">
          <tokens>
            <token id="6" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">mother</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">mother</governor>
          <dependent id="2">65-year-old</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">those</governor>
          <dependent id="3">mother</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">those</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">those</governor>
          <dependent id="5">among</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">made</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">those</governor>
          <dependent id="8">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">killing</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">made</governor>
          <dependent id="10">killing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="65-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="65-year-old" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>America has the Pulitzer Prize for fiction and the National Book Awards, but in terms of excitement, hoopla and man-on-the-street interest, there&amp;apost;s nothing akin to the 15,000-pound ($26,000) Booker Prize.</content>
      <tokens>
        <token id="1" string="America" lemma="America" stem="america" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Pulitzer" lemma="Pulitzer" stem="pulitz" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="5" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="National" lemma="National" stem="nation" pos="NNP" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="11" string="Book" lemma="Book" stem="book" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="12" string="Awards" lemma="award" stem="award" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="terms" lemma="term" stem="term" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="excitement" lemma="excitement" stem="excit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="hoopla" lemma="hoopla" stem="hoopla" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="man-on-the-street" lemma="man-on-the-street" stem="man-on-the-street" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="akin" lemma="akin" stem="akin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="15,000-pound" lemma="15,000-pound" stem="15,000-pound" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="true" />
        <token id="34" string="26,000" lemma="26,000" stem="26,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="true" />
        <token id="35" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP America)) (VP (VBZ has) (NP (NP (DT the) (NNP Pulitzer) (NNP Prize)) (PP (IN for) (NP (NP (NN fiction)) (CC and) (NP (DT the) (NNP National) (NNP Book) (NNS Awards))))))) (, ,) (CC but) (S (PP (IN in) (NP (NP (NNS terms)) (PP (IN of) (NP (NP (NN excitement)) (, ,) (NP (NN hoopla)) (CC and) (NP (JJ man-on-the-street) (NN interest)))))) (, ,) (NP (EX there)) (VP (VBZ 's) (ADJP (NN nothing) (JJ akin) (PP (TO to) (NP (DT the) (ADJP (ADJP (JJ 15,000-pound)) (PRN (-LRB- -LRB-) (NP ($ $) (CD 26,000)) (-RRB- -RRB-))) (NNP Booker) (NNP Prize)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fiction" type="NP">
          <tokens>
            <token id="7" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="2" string="excitement" type="NP">
          <tokens>
            <token id="18" string="excitement" />
          </tokens>
        </chunking>
        <chunking id="3" string="has the Pulitzer Prize for fiction and the National Book Awards" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="the" />
            <token id="4" string="Pulitzer" />
            <token id="5" string="Prize" />
            <token id="6" string="for" />
            <token id="7" string="fiction" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="National" />
            <token id="11" string="Book" />
            <token id="12" string="Awards" />
          </tokens>
        </chunking>
        <chunking id="4" string="15,000-pound -LRB- $ 26,000 -RRB-" type="ADJP">
          <tokens>
            <token id="31" string="15,000-pound" />
            <token id="32" string="(" />
            <token id="33" string="$" />
            <token id="34" string="26,000" />
            <token id="35" string=")" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Pulitzer Prize" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Pulitzer" />
            <token id="5" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="6" string="'s nothing akin to the 15,000-pound -LRB- $ 26,000 -RRB- Booker Prize" type="VP">
          <tokens>
            <token id="26" string="'s" />
            <token id="27" string="nothing" />
            <token id="28" string="akin" />
            <token id="29" string="to" />
            <token id="30" string="the" />
            <token id="31" string="15,000-pound" />
            <token id="32" string="(" />
            <token id="33" string="$" />
            <token id="34" string="26,000" />
            <token id="35" string=")" />
            <token id="36" string="Booker" />
            <token id="37" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="7" string="there" type="NP">
          <tokens>
            <token id="25" string="there" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Pulitzer Prize for fiction and the National Book Awards" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Pulitzer" />
            <token id="5" string="Prize" />
            <token id="6" string="for" />
            <token id="7" string="fiction" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="National" />
            <token id="11" string="Book" />
            <token id="12" string="Awards" />
          </tokens>
        </chunking>
        <chunking id="9" string="$ 26,000" type="NP">
          <tokens>
            <token id="33" string="$" />
            <token id="34" string="26,000" />
          </tokens>
        </chunking>
        <chunking id="10" string="fiction and the National Book Awards" type="NP">
          <tokens>
            <token id="7" string="fiction" />
            <token id="8" string="and" />
            <token id="9" string="the" />
            <token id="10" string="National" />
            <token id="11" string="Book" />
            <token id="12" string="Awards" />
          </tokens>
        </chunking>
        <chunking id="11" string="America" type="NP">
          <tokens>
            <token id="1" string="America" />
          </tokens>
        </chunking>
        <chunking id="12" string="terms" type="NP">
          <tokens>
            <token id="16" string="terms" />
          </tokens>
        </chunking>
        <chunking id="13" string="excitement , hoopla and man-on-the-street interest" type="NP">
          <tokens>
            <token id="18" string="excitement" />
            <token id="19" string="," />
            <token id="20" string="hoopla" />
            <token id="21" string="and" />
            <token id="22" string="man-on-the-street" />
            <token id="23" string="interest" />
          </tokens>
        </chunking>
        <chunking id="14" string="hoopla" type="NP">
          <tokens>
            <token id="20" string="hoopla" />
          </tokens>
        </chunking>
        <chunking id="15" string="nothing akin to the 15,000-pound -LRB- $ 26,000 -RRB- Booker Prize" type="ADJP">
          <tokens>
            <token id="27" string="nothing" />
            <token id="28" string="akin" />
            <token id="29" string="to" />
            <token id="30" string="the" />
            <token id="31" string="15,000-pound" />
            <token id="32" string="(" />
            <token id="33" string="$" />
            <token id="34" string="26,000" />
            <token id="35" string=")" />
            <token id="36" string="Booker" />
            <token id="37" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="16" string="terms of excitement , hoopla and man-on-the-street interest" type="NP">
          <tokens>
            <token id="16" string="terms" />
            <token id="17" string="of" />
            <token id="18" string="excitement" />
            <token id="19" string="," />
            <token id="20" string="hoopla" />
            <token id="21" string="and" />
            <token id="22" string="man-on-the-street" />
            <token id="23" string="interest" />
          </tokens>
        </chunking>
        <chunking id="17" string="the 15,000-pound -LRB- $ 26,000 -RRB- Booker Prize" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="15,000-pound" />
            <token id="32" string="(" />
            <token id="33" string="$" />
            <token id="34" string="26,000" />
            <token id="35" string=")" />
            <token id="36" string="Booker" />
            <token id="37" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="18" string="15,000-pound" type="ADJP">
          <tokens>
            <token id="31" string="15,000-pound" />
          </tokens>
        </chunking>
        <chunking id="19" string="the National Book Awards" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="National" />
            <token id="11" string="Book" />
            <token id="12" string="Awards" />
          </tokens>
        </chunking>
        <chunking id="20" string="man-on-the-street interest" type="NP">
          <tokens>
            <token id="22" string="man-on-the-street" />
            <token id="23" string="interest" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">has</governor>
          <dependent id="1">America</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Prize</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Prize</governor>
          <dependent id="4">Pulitzer</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">has</governor>
          <dependent id="5">Prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">fiction</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Prize</governor>
          <dependent id="7">fiction</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">fiction</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Awards</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Awards</governor>
          <dependent id="10">National</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Awards</governor>
          <dependent id="11">Book</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">fiction</governor>
          <dependent id="12">Awards</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">has</governor>
          <dependent id="14">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">terms</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">'s</governor>
          <dependent id="16">terms</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">excitement</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">terms</governor>
          <dependent id="18">excitement</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">excitement</governor>
          <dependent id="20">hoopla</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">excitement</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">interest</governor>
          <dependent id="22">man-on-the-street</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">excitement</governor>
          <dependent id="23">interest</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="26">'s</governor>
          <dependent id="25">there</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">has</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="28">akin</governor>
          <dependent id="27">nothing</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">'s</governor>
          <dependent id="28">akin</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Prize</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">Prize</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">Prize</governor>
          <dependent id="31">15,000-pound</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="34">26,000</governor>
          <dependent id="33">$</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="31">15,000-pound</governor>
          <dependent id="34">26,000</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Prize</governor>
          <dependent id="36">Booker</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">akin</governor>
          <dependent id="37">Prize</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 26,000" type="MONEY" score="0.0">
          <tokens>
            <token id="33" string="$" />
            <token id="34" string="26,000" />
          </tokens>
        </entity>
        <entity id="2" string="America" type="LOCATION" score="0.0">
          <tokens>
            <token id="1" string="America" />
          </tokens>
        </entity>
        <entity id="3" string="National" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="10" string="National" />
          </tokens>
        </entity>
        <entity id="4" string="Book Awards" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="Book" />
            <token id="12" string="Awards" />
          </tokens>
        </entity>
        <entity id="5" string="Pulitzer Prize" type="MISC" score="0.0">
          <tokens>
            <token id="4" string="Pulitzer" />
            <token id="5" string="Prize" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>With the possible exception of France&amp;apost;s respected Prix Goncourt, there&amp;apost;s nothing quite like it anywhere else.</content>
      <tokens>
        <token id="1" string="With" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="exception" lemma="exception" stem="except" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="France" lemma="France" stem="franc" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="respected" lemma="respected" stem="respect" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="Prix" lemma="Prix" stem="prix" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Goncourt" lemma="Goncourt" stem="goncourt" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="quite" lemma="quite" stem="quit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="anywhere" lemma="anywhere" stem="anywher" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="else" lemma="else" stem="els" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN With) (NP (NP (DT the) (JJ possible) (NN exception)) (PP (IN of) (NP (NP (NNP France) (POS 's)) (JJ respected) (NNP Prix) (NNP Goncourt))))) (, ,) (NP (EX there)) (VP (VBZ 's) (NP (NP (NN nothing) (RB quite)) (PP (IN like) (NP (PRP it)))) (ADVP (RB anywhere) (RB else))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the possible exception" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="possible" />
            <token id="4" string="exception" />
          </tokens>
        </chunking>
        <chunking id="2" string="there" type="NP">
          <tokens>
            <token id="12" string="there" />
          </tokens>
        </chunking>
        <chunking id="3" string="France 's respected Prix Goncourt" type="NP">
          <tokens>
            <token id="6" string="France" />
            <token id="7" string="'s" />
            <token id="8" string="respected" />
            <token id="9" string="Prix" />
            <token id="10" string="Goncourt" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="the possible exception of France 's respected Prix Goncourt" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="possible" />
            <token id="4" string="exception" />
            <token id="5" string="of" />
            <token id="6" string="France" />
            <token id="7" string="'s" />
            <token id="8" string="respected" />
            <token id="9" string="Prix" />
            <token id="10" string="Goncourt" />
          </tokens>
        </chunking>
        <chunking id="6" string="nothing quite" type="NP">
          <tokens>
            <token id="14" string="nothing" />
            <token id="15" string="quite" />
          </tokens>
        </chunking>
        <chunking id="7" string="'s nothing quite like it anywhere else" type="VP">
          <tokens>
            <token id="13" string="'s" />
            <token id="14" string="nothing" />
            <token id="15" string="quite" />
            <token id="16" string="like" />
            <token id="17" string="it" />
            <token id="18" string="anywhere" />
            <token id="19" string="else" />
          </tokens>
        </chunking>
        <chunking id="8" string="nothing quite like it" type="NP">
          <tokens>
            <token id="14" string="nothing" />
            <token id="15" string="quite" />
            <token id="16" string="like" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="France 's" type="NP">
          <tokens>
            <token id="6" string="France" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">exception</governor>
          <dependent id="1">With</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">exception</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">exception</governor>
          <dependent id="3">possible</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">'s</governor>
          <dependent id="4">exception</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Goncourt</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">Goncourt</governor>
          <dependent id="6">France</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">France</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Goncourt</governor>
          <dependent id="8">respected</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Goncourt</governor>
          <dependent id="9">Prix</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">exception</governor>
          <dependent id="10">Goncourt</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="13">'s</governor>
          <dependent id="12">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">'s</governor>
          <dependent id="14">nothing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">nothing</governor>
          <dependent id="15">quite</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">it</governor>
          <dependent id="16">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">nothing</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">else</governor>
          <dependent id="18">anywhere</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">'s</governor>
          <dependent id="19">else</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="France" type="LOCATION" score="0.0">
          <tokens>
            <token id="6" string="France" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Britons wryly compare the Booker to the Academy Awards, and though there&amp;apost;s just one prize and no envelope, similarities exist.</content>
      <tokens>
        <token id="1" string="Britons" lemma="briton" stem="briton" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="2" string="wryly" lemma="wryly" stem="wryli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="compare" lemma="compare" stem="compar" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Academy" lemma="Academy" stem="academi" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="9" string="Awards" lemma="award" stem="award" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="envelope" lemma="envelope" stem="envelop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="similarities" lemma="similarity" stem="similar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="exist" lemma="exist" stem="exist" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Britons)) (ADVP (RB wryly)) (VP (VBP compare) (NP (DT the) (NNP Booker)) (PP (TO to) (NP (DT the) (NNP Academy) (NNS Awards))))) (, ,) (CC and) (S (SBAR (IN though) (S (NP (EX there)) (VP (VBZ 's) (NP (NP (RB just) (CD one) (NN prize)) (CC and) (NP (DT no) (NN envelope)))))) (, ,) (NP (NNS similarities)) (VP (VBP exist))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="13" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="just one prize and no envelope" type="NP">
          <tokens>
            <token id="15" string="just" />
            <token id="16" string="one" />
            <token id="17" string="prize" />
            <token id="18" string="and" />
            <token id="19" string="no" />
            <token id="20" string="envelope" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s just one prize and no envelope" type="VP">
          <tokens>
            <token id="14" string="'s" />
            <token id="15" string="just" />
            <token id="16" string="one" />
            <token id="17" string="prize" />
            <token id="18" string="and" />
            <token id="19" string="no" />
            <token id="20" string="envelope" />
          </tokens>
        </chunking>
        <chunking id="4" string="exist" type="VP">
          <tokens>
            <token id="23" string="exist" />
          </tokens>
        </chunking>
        <chunking id="5" string="just one prize" type="NP">
          <tokens>
            <token id="15" string="just" />
            <token id="16" string="one" />
            <token id="17" string="prize" />
          </tokens>
        </chunking>
        <chunking id="6" string="no envelope" type="NP">
          <tokens>
            <token id="19" string="no" />
            <token id="20" string="envelope" />
          </tokens>
        </chunking>
        <chunking id="7" string="similarities" type="NP">
          <tokens>
            <token id="22" string="similarities" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Booker" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Academy Awards" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="Academy" />
            <token id="9" string="Awards" />
          </tokens>
        </chunking>
        <chunking id="10" string="Britons" type="NP">
          <tokens>
            <token id="1" string="Britons" />
          </tokens>
        </chunking>
        <chunking id="11" string="compare the Booker to the Academy Awards" type="VP">
          <tokens>
            <token id="3" string="compare" />
            <token id="4" string="the" />
            <token id="5" string="Booker" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="Academy" />
            <token id="9" string="Awards" />
          </tokens>
        </chunking>
        <chunking id="12" string="though there 's just one prize and no envelope" type="SBAR">
          <tokens>
            <token id="12" string="though" />
            <token id="13" string="there" />
            <token id="14" string="'s" />
            <token id="15" string="just" />
            <token id="16" string="one" />
            <token id="17" string="prize" />
            <token id="18" string="and" />
            <token id="19" string="no" />
            <token id="20" string="envelope" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">compare</governor>
          <dependent id="1">Britons</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">compare</governor>
          <dependent id="2">wryly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">compare</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Booker</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">compare</governor>
          <dependent id="5">Booker</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Awards</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Awards</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Awards</governor>
          <dependent id="8">Academy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">compare</governor>
          <dependent id="9">Awards</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">compare</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">'s</governor>
          <dependent id="12">though</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="14">'s</governor>
          <dependent id="13">there</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">exist</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">prize</governor>
          <dependent id="15">just</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">prize</governor>
          <dependent id="16">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">'s</governor>
          <dependent id="17">prize</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">prize</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">envelope</governor>
          <dependent id="19">no</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">prize</governor>
          <dependent id="20">envelope</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">exist</governor>
          <dependent id="22">similarities</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">compare</governor>
          <dependent id="23">exist</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Academy Awards" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="Academy" />
            <token id="9" string="Awards" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Booker" />
          </tokens>
        </entity>
        <entity id="4" string="Britons" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="Britons" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="false">
      <content>There&amp;apost;s a team of judges and a pool of candidates.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="pool" lemma="pool" stem="pool" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="candidates" lemma="candidate" stem="candid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBZ 's) (NP (NP (NP (DT a) (NN team)) (PP (IN of) (NP (NNS judges)))) (CC and) (NP (NP (DT a) (NN pool)) (PP (IN of) (NP (NNS candidates)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a team of judges and a pool of candidates" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="team" />
            <token id="5" string="of" />
            <token id="6" string="judges" />
            <token id="7" string="and" />
            <token id="8" string="a" />
            <token id="9" string="pool" />
            <token id="10" string="of" />
            <token id="11" string="candidates" />
          </tokens>
        </chunking>
        <chunking id="2" string="a pool of candidates" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="pool" />
            <token id="10" string="of" />
            <token id="11" string="candidates" />
          </tokens>
        </chunking>
        <chunking id="3" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="4" string="a team" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="team" />
          </tokens>
        </chunking>
        <chunking id="5" string="a pool" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="pool" />
          </tokens>
        </chunking>
        <chunking id="6" string="judges" type="NP">
          <tokens>
            <token id="6" string="judges" />
          </tokens>
        </chunking>
        <chunking id="7" string="a team of judges" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="team" />
            <token id="5" string="of" />
            <token id="6" string="judges" />
          </tokens>
        </chunking>
        <chunking id="8" string="candidates" type="NP">
          <tokens>
            <token id="11" string="candidates" />
          </tokens>
        </chunking>
        <chunking id="9" string="'s a team of judges and a pool of candidates" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="a" />
            <token id="4" string="team" />
            <token id="5" string="of" />
            <token id="6" string="judges" />
            <token id="7" string="and" />
            <token id="8" string="a" />
            <token id="9" string="pool" />
            <token id="10" string="of" />
            <token id="11" string="candidates" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">'s</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">team</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">'s</governor>
          <dependent id="4">team</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">judges</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">team</governor>
          <dependent id="6">judges</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">team</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">pool</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">team</governor>
          <dependent id="9">pool</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">candidates</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">pool</governor>
          <dependent id="11">candidates</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>This year each British publisher could submit three new titles, for a grand total of 93.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="3" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="5" string="publisher" lemma="publisher" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="submit" lemma="submit" stem="submit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="titles" lemma="title" stem="titl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="grand" lemma="grand" stem="grand" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="total" lemma="total" stem="total" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="93" lemma="93" stem="93" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (DT This) (NN year)) (NP (DT each) (JJ British) (NN publisher)) (VP (MD could) (VP (VB submit) (NP (CD three) (JJ new) (NNS titles)) (, ,) (PP (IN for) (NP (NP (DT a) (JJ grand) (NN total)) (PP (IN of) (NP (CD 93))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="submit three new titles , for a grand total of 93" type="VP">
          <tokens>
            <token id="7" string="submit" />
            <token id="8" string="three" />
            <token id="9" string="new" />
            <token id="10" string="titles" />
            <token id="11" string="," />
            <token id="12" string="for" />
            <token id="13" string="a" />
            <token id="14" string="grand" />
            <token id="15" string="total" />
            <token id="16" string="of" />
            <token id="17" string="93" />
          </tokens>
        </chunking>
        <chunking id="2" string="a grand total" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="grand" />
            <token id="15" string="total" />
          </tokens>
        </chunking>
        <chunking id="3" string="three new titles" type="NP">
          <tokens>
            <token id="8" string="three" />
            <token id="9" string="new" />
            <token id="10" string="titles" />
          </tokens>
        </chunking>
        <chunking id="4" string="a grand total of 93" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="grand" />
            <token id="15" string="total" />
            <token id="16" string="of" />
            <token id="17" string="93" />
          </tokens>
        </chunking>
        <chunking id="5" string="could submit three new titles , for a grand total of 93" type="VP">
          <tokens>
            <token id="6" string="could" />
            <token id="7" string="submit" />
            <token id="8" string="three" />
            <token id="9" string="new" />
            <token id="10" string="titles" />
            <token id="11" string="," />
            <token id="12" string="for" />
            <token id="13" string="a" />
            <token id="14" string="grand" />
            <token id="15" string="total" />
            <token id="16" string="of" />
            <token id="17" string="93" />
          </tokens>
        </chunking>
        <chunking id="6" string="each British publisher" type="NP">
          <tokens>
            <token id="3" string="each" />
            <token id="4" string="British" />
            <token id="5" string="publisher" />
          </tokens>
        </chunking>
        <chunking id="7" string="93" type="NP">
          <tokens>
            <token id="17" string="93" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">year</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">submit</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">publisher</governor>
          <dependent id="3">each</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">publisher</governor>
          <dependent id="4">British</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">submit</governor>
          <dependent id="5">publisher</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">submit</governor>
          <dependent id="6">could</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">submit</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">titles</governor>
          <dependent id="8">three</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">titles</governor>
          <dependent id="9">new</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">submit</governor>
          <dependent id="10">titles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">total</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">total</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">total</governor>
          <dependent id="14">grand</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">submit</governor>
          <dependent id="15">total</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">93</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">total</governor>
          <dependent id="17">93</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="4" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="93" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="93" />
          </tokens>
        </entity>
        <entity id="3" string="This year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="4" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="three" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="false">
      <content>As one judge noted wearily, &amp;quot;By August, I was in more than a slight panic, sometimes reading all day and evening; reading while standing at the bus stop, reading while cooking, reading, almost, while talking on the telephone.&amp;quot;</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="3" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="noted" lemma="note" stem="note" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="wearily" lemma="wearily" stem="wearili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="August" lemma="August" stem="august" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="slight" lemma="slight" stem="slight" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="panic" lemma="panic" stem="panic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="sometimes" lemma="sometimes" stem="sometim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="reading" lemma="read" stem="read" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="evening" lemma="evening" stem="even" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="26" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="reading" lemma="reading" stem="read" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="standing" lemma="stand" stem="stand" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="bus" lemma="bus" stem="bu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="stop" lemma="stop" stem="stop" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="reading" lemma="read" stem="read" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="cooking" lemma="cooking" stem="cook" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="reading" lemma="reading" stem="read" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="talking" lemma="talk" stem="talk" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="telephone" lemma="telephone" stem="telephon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN As) (S (NP (CD one) (NN judge)) (VP (VBD noted) (ADVP (RB wearily))))) (, ,) (`` ``) (PP (IN By) (NP (NNP August))) (, ,) (NP (PRP I)) (VP (VBD was) (PP (IN in) (NP (QP (JJR more) (IN than) (NP (DT a) (JJ slight) (NN panic))))) (, ,) (ADVP (RB sometimes)) (VP (VP (VBG reading) (NP (DT all) (NN day) (CC and) (NN evening) (: ;) (NN reading)) (PP (IN while) (S (VP (VBG standing) (PP (IN at) (NP (DT the) (NN bus) (NN stop))))))) (, ,) (VP (VBG reading) (PP (IN while) (NP (NN cooking)))) (, ,) (NP (NN reading) (, ,) (ADVP (RB almost)) (, ,) (SBAR (IN while) (S (VP (VBG talking) (PP (IN on) (NP (DT the) (NN telephone))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the bus stop" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="bus" />
            <token id="33" string="stop" />
          </tokens>
        </chunking>
        <chunking id="2" string="was in more than a slight panic , sometimes reading all day and evening ; reading while standing at the bus stop , reading while cooking , reading , almost , while talking on the telephone" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="in" />
            <token id="14" string="more" />
            <token id="15" string="than" />
            <token id="16" string="a" />
            <token id="17" string="slight" />
            <token id="18" string="panic" />
            <token id="19" string="," />
            <token id="20" string="sometimes" />
            <token id="21" string="reading" />
            <token id="22" string="all" />
            <token id="23" string="day" />
            <token id="24" string="and" />
            <token id="25" string="evening" />
            <token id="26" string=";" />
            <token id="27" string="reading" />
            <token id="28" string="while" />
            <token id="29" string="standing" />
            <token id="30" string="at" />
            <token id="31" string="the" />
            <token id="32" string="bus" />
            <token id="33" string="stop" />
            <token id="34" string="," />
            <token id="35" string="reading" />
            <token id="36" string="while" />
            <token id="37" string="cooking" />
            <token id="38" string="," />
            <token id="39" string="reading" />
            <token id="40" string="," />
            <token id="41" string="almost" />
            <token id="42" string="," />
            <token id="43" string="while" />
            <token id="44" string="talking" />
            <token id="45" string="on" />
            <token id="46" string="the" />
            <token id="47" string="telephone" />
          </tokens>
        </chunking>
        <chunking id="3" string="while talking on the telephone" type="SBAR">
          <tokens>
            <token id="43" string="while" />
            <token id="44" string="talking" />
            <token id="45" string="on" />
            <token id="46" string="the" />
            <token id="47" string="telephone" />
          </tokens>
        </chunking>
        <chunking id="4" string="talking on the telephone" type="VP">
          <tokens>
            <token id="44" string="talking" />
            <token id="45" string="on" />
            <token id="46" string="the" />
            <token id="47" string="telephone" />
          </tokens>
        </chunking>
        <chunking id="5" string="a slight panic" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="slight" />
            <token id="18" string="panic" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="reading while cooking" type="VP">
          <tokens>
            <token id="35" string="reading" />
            <token id="36" string="while" />
            <token id="37" string="cooking" />
          </tokens>
        </chunking>
        <chunking id="8" string="standing at the bus stop" type="VP">
          <tokens>
            <token id="29" string="standing" />
            <token id="30" string="at" />
            <token id="31" string="the" />
            <token id="32" string="bus" />
            <token id="33" string="stop" />
          </tokens>
        </chunking>
        <chunking id="9" string="August" type="NP">
          <tokens>
            <token id="9" string="August" />
          </tokens>
        </chunking>
        <chunking id="10" string="reading all day and evening ; reading while standing at the bus stop" type="VP">
          <tokens>
            <token id="21" string="reading" />
            <token id="22" string="all" />
            <token id="23" string="day" />
            <token id="24" string="and" />
            <token id="25" string="evening" />
            <token id="26" string=";" />
            <token id="27" string="reading" />
            <token id="28" string="while" />
            <token id="29" string="standing" />
            <token id="30" string="at" />
            <token id="31" string="the" />
            <token id="32" string="bus" />
            <token id="33" string="stop" />
          </tokens>
        </chunking>
        <chunking id="11" string="all day and evening ; reading" type="NP">
          <tokens>
            <token id="22" string="all" />
            <token id="23" string="day" />
            <token id="24" string="and" />
            <token id="25" string="evening" />
            <token id="26" string=";" />
            <token id="27" string="reading" />
          </tokens>
        </chunking>
        <chunking id="12" string="As one judge noted wearily" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="one" />
            <token id="3" string="judge" />
            <token id="4" string="noted" />
            <token id="5" string="wearily" />
          </tokens>
        </chunking>
        <chunking id="13" string="noted wearily" type="VP">
          <tokens>
            <token id="4" string="noted" />
            <token id="5" string="wearily" />
          </tokens>
        </chunking>
        <chunking id="14" string="the telephone" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="telephone" />
          </tokens>
        </chunking>
        <chunking id="15" string="one judge" type="NP">
          <tokens>
            <token id="2" string="one" />
            <token id="3" string="judge" />
          </tokens>
        </chunking>
        <chunking id="16" string="reading , almost , while talking on the telephone" type="NP">
          <tokens>
            <token id="39" string="reading" />
            <token id="40" string="," />
            <token id="41" string="almost" />
            <token id="42" string="," />
            <token id="43" string="while" />
            <token id="44" string="talking" />
            <token id="45" string="on" />
            <token id="46" string="the" />
            <token id="47" string="telephone" />
          </tokens>
        </chunking>
        <chunking id="17" string="reading all day and evening ; reading while standing at the bus stop , reading while cooking , reading , almost , while talking on the telephone" type="VP">
          <tokens>
            <token id="21" string="reading" />
            <token id="22" string="all" />
            <token id="23" string="day" />
            <token id="24" string="and" />
            <token id="25" string="evening" />
            <token id="26" string=";" />
            <token id="27" string="reading" />
            <token id="28" string="while" />
            <token id="29" string="standing" />
            <token id="30" string="at" />
            <token id="31" string="the" />
            <token id="32" string="bus" />
            <token id="33" string="stop" />
            <token id="34" string="," />
            <token id="35" string="reading" />
            <token id="36" string="while" />
            <token id="37" string="cooking" />
            <token id="38" string="," />
            <token id="39" string="reading" />
            <token id="40" string="," />
            <token id="41" string="almost" />
            <token id="42" string="," />
            <token id="43" string="while" />
            <token id="44" string="talking" />
            <token id="45" string="on" />
            <token id="46" string="the" />
            <token id="47" string="telephone" />
          </tokens>
        </chunking>
        <chunking id="18" string="cooking" type="NP">
          <tokens>
            <token id="37" string="cooking" />
          </tokens>
        </chunking>
        <chunking id="19" string="more than a slight panic" type="NP">
          <tokens>
            <token id="14" string="more" />
            <token id="15" string="than" />
            <token id="16" string="a" />
            <token id="17" string="slight" />
            <token id="18" string="panic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">noted</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">judge</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">noted</governor>
          <dependent id="3">judge</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">reading</governor>
          <dependent id="4">noted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">noted</governor>
          <dependent id="5">wearily</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">August</governor>
          <dependent id="8">By</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">reading</governor>
          <dependent id="9">August</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">reading</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">reading</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">panic</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">panic</governor>
          <dependent id="14">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="14">more</governor>
          <dependent id="15">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">panic</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">panic</governor>
          <dependent id="17">slight</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">reading</governor>
          <dependent id="18">panic</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">reading</governor>
          <dependent id="20">sometimes</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">reading</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">day</governor>
          <dependent id="22">all</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">reading</governor>
          <dependent id="23">day</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">day</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">reading</governor>
          <dependent id="25">evening</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">day</governor>
          <dependent id="27">reading</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">standing</governor>
          <dependent id="28">while</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">reading</governor>
          <dependent id="29">standing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">stop</governor>
          <dependent id="30">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">stop</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">stop</governor>
          <dependent id="32">bus</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">standing</governor>
          <dependent id="33">stop</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">reading</governor>
          <dependent id="35">reading</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">cooking</governor>
          <dependent id="36">while</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">reading</governor>
          <dependent id="37">cooking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">reading</governor>
          <dependent id="39">reading</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="39">reading</governor>
          <dependent id="41">almost</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="44">talking</governor>
          <dependent id="43">while</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="39">reading</governor>
          <dependent id="44">talking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">telephone</governor>
          <dependent id="45">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">telephone</governor>
          <dependent id="46">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">talking</governor>
          <dependent id="47">telephone</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="evening" type="TIME" score="0.0">
          <tokens>
            <token id="25" string="evening" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="day" type="DURATION" score="0.0">
          <tokens>
            <token id="23" string="day" />
          </tokens>
        </entity>
        <entity id="4" string="August" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="August" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Next comes the &amp;quot;short-list,&amp;quot; the judges&amp;apost; top six, which was announced with great fanfare in late September.</content>
      <tokens>
        <token id="1" string="Next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="short-list" lemma="short-list" stem="short-list" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="top" lemma="top" stem="top" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="announced" lemma="announce" stem="announc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="fanfare" lemma="fanfare" stem="fanfar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="22" string="September" lemma="September" stem="septemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (ADVP (JJ Next)) (VP (VBZ comes) (NP (DT the) (`` ``) (NN short-list) (, ,) ('' ''))) (NP (NP (NP (DT the) (NNS judges) (POS ')) (QP (JJ top) (CD six))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (VP (VBN announced) (PP (IN with) (NP (NP (JJ great) (NN fanfare)) (PP (IN in) (NP (JJ late) (NNP September)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="great fanfare in late September" type="NP">
          <tokens>
            <token id="18" string="great" />
            <token id="19" string="fanfare" />
            <token id="20" string="in" />
            <token id="21" string="late" />
            <token id="22" string="September" />
          </tokens>
        </chunking>
        <chunking id="2" string="the judges ' top six" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="judges" />
            <token id="10" string="'" />
            <token id="11" string="top" />
            <token id="12" string="six" />
          </tokens>
        </chunking>
        <chunking id="3" string="the judges ' top six , which was announced with great fanfare in late September" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="judges" />
            <token id="10" string="'" />
            <token id="11" string="top" />
            <token id="12" string="six" />
            <token id="13" string="," />
            <token id="14" string="which" />
            <token id="15" string="was" />
            <token id="16" string="announced" />
            <token id="17" string="with" />
            <token id="18" string="great" />
            <token id="19" string="fanfare" />
            <token id="20" string="in" />
            <token id="21" string="late" />
            <token id="22" string="September" />
          </tokens>
        </chunking>
        <chunking id="4" string="was announced with great fanfare in late September" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="announced" />
            <token id="17" string="with" />
            <token id="18" string="great" />
            <token id="19" string="fanfare" />
            <token id="20" string="in" />
            <token id="21" string="late" />
            <token id="22" string="September" />
          </tokens>
        </chunking>
        <chunking id="5" string="great fanfare" type="NP">
          <tokens>
            <token id="18" string="great" />
            <token id="19" string="fanfare" />
          </tokens>
        </chunking>
        <chunking id="6" string="the `` short-list , ''" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="&quot;" />
            <token id="5" string="short-list" />
            <token id="6" string="," />
            <token id="7" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="7" string="the judges '" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="judges" />
            <token id="10" string="'" />
          </tokens>
        </chunking>
        <chunking id="8" string="late September" type="NP">
          <tokens>
            <token id="21" string="late" />
            <token id="22" string="September" />
          </tokens>
        </chunking>
        <chunking id="9" string="which was announced with great fanfare in late September" type="SBAR">
          <tokens>
            <token id="14" string="which" />
            <token id="15" string="was" />
            <token id="16" string="announced" />
            <token id="17" string="with" />
            <token id="18" string="great" />
            <token id="19" string="fanfare" />
            <token id="20" string="in" />
            <token id="21" string="late" />
            <token id="22" string="September" />
          </tokens>
        </chunking>
        <chunking id="10" string="comes the `` short-list , ''" type="VP">
          <tokens>
            <token id="2" string="comes" />
            <token id="3" string="the" />
            <token id="4" string="&quot;" />
            <token id="5" string="short-list" />
            <token id="6" string="," />
            <token id="7" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="11" string="announced with great fanfare in late September" type="VP">
          <tokens>
            <token id="16" string="announced" />
            <token id="17" string="with" />
            <token id="18" string="great" />
            <token id="19" string="fanfare" />
            <token id="20" string="in" />
            <token id="21" string="late" />
            <token id="22" string="September" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">comes</governor>
          <dependent id="1">Next</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">comes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">short-list</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">comes</governor>
          <dependent id="5">short-list</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">judges</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">comes</governor>
          <dependent id="9">judges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">judges</governor>
          <dependent id="10">'</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">six</governor>
          <dependent id="11">top</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">judges</governor>
          <dependent id="12">six</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="16">announced</governor>
          <dependent id="14">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">announced</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">judges</governor>
          <dependent id="16">announced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">fanfare</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">fanfare</governor>
          <dependent id="18">great</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">announced</governor>
          <dependent id="19">fanfare</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">September</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">September</governor>
          <dependent id="21">late</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">fanfare</governor>
          <dependent id="22">September</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="late September" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="late" />
            <token id="22" string="September" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>This year the works included Brian Moore&amp;apost;s political thriller &amp;quot;The Color of Blood&amp;quot; (E.P. Dutton, 182 pages, $16.95); Peter Ackroyd&amp;apost;s &amp;quot;Chatterton&amp;quot; (Grove Press, 240 pages, $17.95); Nina Bawden&amp;apost;s &amp;quot;Circles of Deceit&amp;quot; (St. Martin&amp;apost;s Press, 208 pages, $14.95); Iris Murdoch&amp;apost;s 23rd novel &amp;quot;The Book and the Brotherhood&amp;quot; (Viking, 608 pages, $19.95); Nigerian writer Chinua Achebe&amp;apost;s &amp;quot;Anthills of the Savannah&amp;quot; (Doubleday, 240 pages, $16.95); and &amp;quot;Moon Tiger&amp;quot; (Grove Press, 216 pages, $15.95).</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="works" lemma="work" stem="work" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="included" lemma="include" stem="includ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Brian" lemma="Brian" stem="brian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="Moore" lemma="Moore" stem="moor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="thriller" lemma="thriller" stem="thriller" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Color" lemma="color" stem="color" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Blood" lemma="blood" stem="blood" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="E.P." lemma="E.P." stem="e.p." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="Dutton" lemma="Dutton" stem="dutton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="182" lemma="182" stem="182" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="25" string="16.95" lemma="16.95" stem="16.95" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="26" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="29" string="Ackroyd" lemma="Ackroyd" stem="ackroyd" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Chatterton" lemma="Chatterton" stem="chatterton" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Grove" lemma="Grove" stem="grove" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="36" string="Press" lemma="Press" stem="press" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="240" lemma="240" stem="240" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="39" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="42" string="17.95" lemma="17.95" stem="17.95" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="43" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="Nina" lemma="Nina" stem="nina" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="46" string="Bawden" lemma="Bawden" stem="bawden" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="47" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="48" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="Circles" lemma="circle" stem="circl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="Deceit" lemma="Deceit" stem="deceit" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="St." lemma="St." stem="st." pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="55" string="Martin" lemma="Martin" stem="martin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="56" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="57" string="Press" lemma="Press" stem="press" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="58" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="59" string="208" lemma="208" stem="208" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="60" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="63" string="14.95" lemma="14.95" stem="14.95" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="64" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="65" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="66" string="Iris" lemma="Iris" stem="iri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="67" string="Murdoch" lemma="Murdoch" stem="murdoch" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="68" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="23rd" lemma="23rd" stem="23rd" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="70" string="novel" lemma="novel" stem="novel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="71" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="72" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="73" string="Book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="74" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="75" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="76" string="Brotherhood" lemma="Brotherhood" stem="brotherhood" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="77" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="78" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="79" string="Viking" lemma="viking" stem="vike" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="80" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="81" string="608" lemma="608" stem="608" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="82" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="83" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="84" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="true" />
        <token id="85" string="19.95" lemma="19.95" stem="19.95" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="true" />
        <token id="86" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="87" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="88" string="Nigerian" lemma="nigerian" stem="nigerian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="89" string="writer" lemma="writer" stem="writer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="90" string="Chinua" lemma="Chinua" stem="chinua" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="91" string="Achebe" lemma="Achebe" stem="achebe" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="92" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="93" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="94" string="Anthills" lemma="anthill" stem="anthill" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="95" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="96" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="97" string="Savannah" lemma="Savannah" stem="savannah" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="98" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="99" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="100" string="Doubleday" lemma="Doubleday" stem="doubledai" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="101" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="102" string="240" lemma="240" stem="240" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="103" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="104" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="105" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="106" string="16.95" lemma="16.95" stem="16.95" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="107" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="108" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="109" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="110" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="111" string="Moon" lemma="Moon" stem="moon" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="112" string="Tiger" lemma="Tiger" stem="tiger" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="113" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="114" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="115" string="Grove" lemma="Grove" stem="grove" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="116" string="Press" lemma="Press" stem="press" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="117" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="118" string="216" lemma="216" stem="216" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="119" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="120" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="121" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="122" string="15.95" lemma="15.95" stem="15.95" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="123" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="124" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (DT This) (NN year)) (NP (DT the) (NNS works)) (VP (VBD included) (NP (NP (NP (NP (NP (NNP Brian) (NNP Moore) (POS 's)) (JJ political) (NN thriller) (`` ``) (NX (NP (DT The) (NN Color)) (PP (IN of) (NP (NN Blood)))) ('' '')) (PRN (-LRB- -LRB-) (NP (NNP E.P.) (NNP Dutton)) (, ,) (NP (CD 182) (NNS pages)) (, ,) (NP ($ $) (CD 16.95)) (-RRB- -RRB-))) (: ;) (NP (NP (NNP Peter) (NNP Ackroyd) (POS 's)) (NP (NP (`` ``) (NP (NNP Chatterton)) ('' '') (PRN (-LRB- -LRB-) (NP (NNP Grove) (NNP Press)) (, ,) (NP (CD 240) (NNS pages)) (, ,) (NP ($ $) (CD 17.95)) (-RRB- -RRB-))) (: ;) (NP (NP (NP (NNP Nina) (NNP Bawden) (POS 's)) (`` ``) (NX (NP (NNS Circles)) (PP (IN of) (NP (NNP Deceit)))) ('' '')) (PRN (-LRB- -LRB-) (NP (NP (NNP St.)) (NP (NP (NP (NP (NNP Martin) (POS 's)) (NNP Press)) (, ,) (NP (CD 208) (NNS pages)) (, ,)) (NP ($ $) (CD 14.95)))) (-RRB- -RRB-))))) (: ;) (NP (NP (NP (NNP Iris) (NNP Murdoch) (POS 's)) (JJ 23rd) (JJ novel)) (NP (NP (`` ``) (NP (DT The) (NN Book)) (CC and) (NP (DT the) (NNP Brotherhood)) ('' '')) (PRN (-LRB- -LRB-) (NP (JJ Viking)) (, ,) (NP (CD 608) (NNS pages)) (, ,) (NP ($ $) (CD 19.95)) (-RRB- -RRB-)))) (: ;) (NP (NP (JJ Nigerian) (NN writer)) (NP (NP (NP (NNP Chinua) (NNP Achebe) (POS 's)) (`` ``) (NX (NP (NNS Anthills)) (PP (IN of) (NP (DT the) (NNP Savannah)))) ('' '')) (PRN (-LRB- -LRB-) (NP (NNP Doubleday)) (, ,) (NP (CD 240) (NNS pages)) (, ,) (NP ($ $) (CD 16.95)) (-RRB- -RRB-))))) (: ;) (CC and) (NP (`` ``) (NP (NNP Moon) (NNP Tiger)) ('' '') (PRN (-LRB- -LRB-) (NP (NNP Grove) (NNP Press)) (, ,) (NP (CD 216) (NNS pages)) (, ,) (NP ($ $) (CD 15.95)) (-RRB- -RRB-))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Peter Ackroyd 's" type="NP">
          <tokens>
            <token id="28" string="Peter" />
            <token id="29" string="Ackroyd" />
            <token id="30" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="Brian Moore 's political thriller `` The Color of Blood '' -LRB- E.P. Dutton , 182 pages , $ 16.95 -RRB- ; Peter Ackroyd 's `` Chatterton '' -LRB- Grove Press , 240 pages , $ 17.95 -RRB- ; Nina Bawden 's `` Circles of Deceit '' -LRB- St. Martin 's Press , 208 pages , $ 14.95 -RRB- ; Iris Murdoch 's 23rd novel `` The Book and the Brotherhood '' -LRB- Viking , 608 pages , $ 19.95 -RRB- ; Nigerian writer Chinua Achebe 's `` Anthills of the Savannah '' -LRB- Doubleday , 240 pages , $ 16.95 -RRB-" type="NP">
          <tokens>
            <token id="6" string="Brian" />
            <token id="7" string="Moore" />
            <token id="8" string="'s" />
            <token id="9" string="political" />
            <token id="10" string="thriller" />
            <token id="11" string="&quot;" />
            <token id="12" string="The" />
            <token id="13" string="Color" />
            <token id="14" string="of" />
            <token id="15" string="Blood" />
            <token id="16" string="&quot;" />
            <token id="17" string="(" />
            <token id="18" string="E.P." />
            <token id="19" string="Dutton" />
            <token id="20" string="," />
            <token id="21" string="182" />
            <token id="22" string="pages" />
            <token id="23" string="," />
            <token id="24" string="$" />
            <token id="25" string="16.95" />
            <token id="26" string=")" />
            <token id="27" string=";" />
            <token id="28" string="Peter" />
            <token id="29" string="Ackroyd" />
            <token id="30" string="'s" />
            <token id="31" string="&quot;" />
            <token id="32" string="Chatterton" />
            <token id="33" string="&quot;" />
            <token id="34" string="(" />
            <token id="35" string="Grove" />
            <token id="36" string="Press" />
            <token id="37" string="," />
            <token id="38" string="240" />
            <token id="39" string="pages" />
            <token id="40" string="," />
            <token id="41" string="$" />
            <token id="42" string="17.95" />
            <token id="43" string=")" />
            <token id="44" string=";" />
            <token id="45" string="Nina" />
            <token id="46" string="Bawden" />
            <token id="47" string="'s" />
            <token id="48" string="&quot;" />
            <token id="49" string="Circles" />
            <token id="50" string="of" />
            <token id="51" string="Deceit" />
            <token id="52" string="&quot;" />
            <token id="53" string="(" />
            <token id="54" string="St." />
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
            <token id="58" string="," />
            <token id="59" string="208" />
            <token id="60" string="pages" />
            <token id="61" string="," />
            <token id="62" string="$" />
            <token id="63" string="14.95" />
            <token id="64" string=")" />
            <token id="65" string=";" />
            <token id="66" string="Iris" />
            <token id="67" string="Murdoch" />
            <token id="68" string="'s" />
            <token id="69" string="23rd" />
            <token id="70" string="novel" />
            <token id="71" string="&quot;" />
            <token id="72" string="The" />
            <token id="73" string="Book" />
            <token id="74" string="and" />
            <token id="75" string="the" />
            <token id="76" string="Brotherhood" />
            <token id="77" string="&quot;" />
            <token id="78" string="(" />
            <token id="79" string="Viking" />
            <token id="80" string="," />
            <token id="81" string="608" />
            <token id="82" string="pages" />
            <token id="83" string="," />
            <token id="84" string="$" />
            <token id="85" string="19.95" />
            <token id="86" string=")" />
            <token id="87" string=";" />
            <token id="88" string="Nigerian" />
            <token id="89" string="writer" />
            <token id="90" string="Chinua" />
            <token id="91" string="Achebe" />
            <token id="92" string="'s" />
            <token id="93" string="&quot;" />
            <token id="94" string="Anthills" />
            <token id="95" string="of" />
            <token id="96" string="the" />
            <token id="97" string="Savannah" />
            <token id="98" string="&quot;" />
            <token id="99" string="(" />
            <token id="100" string="Doubleday" />
            <token id="101" string="," />
            <token id="102" string="240" />
            <token id="103" string="pages" />
            <token id="104" string="," />
            <token id="105" string="$" />
            <token id="106" string="16.95" />
            <token id="107" string=")" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Brotherhood" type="NP">
          <tokens>
            <token id="75" string="the" />
            <token id="76" string="Brotherhood" />
          </tokens>
        </chunking>
        <chunking id="4" string="Nina Bawden 's `` Circles of Deceit ''" type="NP">
          <tokens>
            <token id="45" string="Nina" />
            <token id="46" string="Bawden" />
            <token id="47" string="'s" />
            <token id="48" string="&quot;" />
            <token id="49" string="Circles" />
            <token id="50" string="of" />
            <token id="51" string="Deceit" />
            <token id="52" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="Deceit" type="NP">
          <tokens>
            <token id="51" string="Deceit" />
          </tokens>
        </chunking>
        <chunking id="6" string="Iris Murdoch 's 23rd novel `` The Book and the Brotherhood '' -LRB- Viking , 608 pages , $ 19.95 -RRB-" type="NP">
          <tokens>
            <token id="66" string="Iris" />
            <token id="67" string="Murdoch" />
            <token id="68" string="'s" />
            <token id="69" string="23rd" />
            <token id="70" string="novel" />
            <token id="71" string="&quot;" />
            <token id="72" string="The" />
            <token id="73" string="Book" />
            <token id="74" string="and" />
            <token id="75" string="the" />
            <token id="76" string="Brotherhood" />
            <token id="77" string="&quot;" />
            <token id="78" string="(" />
            <token id="79" string="Viking" />
            <token id="80" string="," />
            <token id="81" string="608" />
            <token id="82" string="pages" />
            <token id="83" string="," />
            <token id="84" string="$" />
            <token id="85" string="19.95" />
            <token id="86" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="$ 19.95" type="NP">
          <tokens>
            <token id="84" string="$" />
            <token id="85" string="19.95" />
          </tokens>
        </chunking>
        <chunking id="8" string="Martin 's Press" type="NP">
          <tokens>
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
          </tokens>
        </chunking>
        <chunking id="9" string="$ 15.95" type="NP">
          <tokens>
            <token id="121" string="$" />
            <token id="122" string="15.95" />
          </tokens>
        </chunking>
        <chunking id="10" string="The Color" type="NP">
          <tokens>
            <token id="12" string="The" />
            <token id="13" string="Color" />
          </tokens>
        </chunking>
        <chunking id="11" string="Brian Moore 's" type="NP">
          <tokens>
            <token id="6" string="Brian" />
            <token id="7" string="Moore" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="`` The Book and the Brotherhood '' -LRB- Viking , 608 pages , $ 19.95 -RRB-" type="NP">
          <tokens>
            <token id="71" string="&quot;" />
            <token id="72" string="The" />
            <token id="73" string="Book" />
            <token id="74" string="and" />
            <token id="75" string="the" />
            <token id="76" string="Brotherhood" />
            <token id="77" string="&quot;" />
            <token id="78" string="(" />
            <token id="79" string="Viking" />
            <token id="80" string="," />
            <token id="81" string="608" />
            <token id="82" string="pages" />
            <token id="83" string="," />
            <token id="84" string="$" />
            <token id="85" string="19.95" />
            <token id="86" string=")" />
          </tokens>
        </chunking>
        <chunking id="13" string="`` Chatterton '' -LRB- Grove Press , 240 pages , $ 17.95 -RRB- ; Nina Bawden 's `` Circles of Deceit '' -LRB- St. Martin 's Press , 208 pages , $ 14.95 -RRB-" type="NP">
          <tokens>
            <token id="31" string="&quot;" />
            <token id="32" string="Chatterton" />
            <token id="33" string="&quot;" />
            <token id="34" string="(" />
            <token id="35" string="Grove" />
            <token id="36" string="Press" />
            <token id="37" string="," />
            <token id="38" string="240" />
            <token id="39" string="pages" />
            <token id="40" string="," />
            <token id="41" string="$" />
            <token id="42" string="17.95" />
            <token id="43" string=")" />
            <token id="44" string=";" />
            <token id="45" string="Nina" />
            <token id="46" string="Bawden" />
            <token id="47" string="'s" />
            <token id="48" string="&quot;" />
            <token id="49" string="Circles" />
            <token id="50" string="of" />
            <token id="51" string="Deceit" />
            <token id="52" string="&quot;" />
            <token id="53" string="(" />
            <token id="54" string="St." />
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
            <token id="58" string="," />
            <token id="59" string="208" />
            <token id="60" string="pages" />
            <token id="61" string="," />
            <token id="62" string="$" />
            <token id="63" string="14.95" />
            <token id="64" string=")" />
          </tokens>
        </chunking>
        <chunking id="14" string="Nina Bawden 's `` Circles of Deceit '' -LRB- St. Martin 's Press , 208 pages , $ 14.95 -RRB-" type="NP">
          <tokens>
            <token id="45" string="Nina" />
            <token id="46" string="Bawden" />
            <token id="47" string="'s" />
            <token id="48" string="&quot;" />
            <token id="49" string="Circles" />
            <token id="50" string="of" />
            <token id="51" string="Deceit" />
            <token id="52" string="&quot;" />
            <token id="53" string="(" />
            <token id="54" string="St." />
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
            <token id="58" string="," />
            <token id="59" string="208" />
            <token id="60" string="pages" />
            <token id="61" string="," />
            <token id="62" string="$" />
            <token id="63" string="14.95" />
            <token id="64" string=")" />
          </tokens>
        </chunking>
        <chunking id="15" string="208 pages" type="NP">
          <tokens>
            <token id="59" string="208" />
            <token id="60" string="pages" />
          </tokens>
        </chunking>
        <chunking id="16" string="`` The Book and the Brotherhood ''" type="NP">
          <tokens>
            <token id="71" string="&quot;" />
            <token id="72" string="The" />
            <token id="73" string="Book" />
            <token id="74" string="and" />
            <token id="75" string="the" />
            <token id="76" string="Brotherhood" />
            <token id="77" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="17" string="the works" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="works" />
          </tokens>
        </chunking>
        <chunking id="18" string="216 pages" type="NP">
          <tokens>
            <token id="118" string="216" />
            <token id="119" string="pages" />
          </tokens>
        </chunking>
        <chunking id="19" string="Chinua Achebe 's `` Anthills of the Savannah '' -LRB- Doubleday , 240 pages , $ 16.95 -RRB-" type="NP">
          <tokens>
            <token id="90" string="Chinua" />
            <token id="91" string="Achebe" />
            <token id="92" string="'s" />
            <token id="93" string="&quot;" />
            <token id="94" string="Anthills" />
            <token id="95" string="of" />
            <token id="96" string="the" />
            <token id="97" string="Savannah" />
            <token id="98" string="&quot;" />
            <token id="99" string="(" />
            <token id="100" string="Doubleday" />
            <token id="101" string="," />
            <token id="102" string="240" />
            <token id="103" string="pages" />
            <token id="104" string="," />
            <token id="105" string="$" />
            <token id="106" string="16.95" />
            <token id="107" string=")" />
          </tokens>
        </chunking>
        <chunking id="20" string="Martin 's" type="NP">
          <tokens>
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="182 pages" type="NP">
          <tokens>
            <token id="21" string="182" />
            <token id="22" string="pages" />
          </tokens>
        </chunking>
        <chunking id="22" string="$ 14.95" type="NP">
          <tokens>
            <token id="62" string="$" />
            <token id="63" string="14.95" />
          </tokens>
        </chunking>
        <chunking id="23" string="Brian Moore 's political thriller `` The Color of Blood '' -LRB- E.P. Dutton , 182 pages , $ 16.95 -RRB- ; Peter Ackroyd 's `` Chatterton '' -LRB- Grove Press , 240 pages , $ 17.95 -RRB- ; Nina Bawden 's `` Circles of Deceit '' -LRB- St. Martin 's Press , 208 pages , $ 14.95 -RRB- ; Iris Murdoch 's 23rd novel `` The Book and the Brotherhood '' -LRB- Viking , 608 pages , $ 19.95 -RRB- ; Nigerian writer Chinua Achebe 's `` Anthills of the Savannah '' -LRB- Doubleday , 240 pages , $ 16.95 -RRB- ; and `` Moon Tiger '' -LRB- Grove Press , 216 pages , $ 15.95 -RRB-" type="NP">
          <tokens>
            <token id="6" string="Brian" />
            <token id="7" string="Moore" />
            <token id="8" string="'s" />
            <token id="9" string="political" />
            <token id="10" string="thriller" />
            <token id="11" string="&quot;" />
            <token id="12" string="The" />
            <token id="13" string="Color" />
            <token id="14" string="of" />
            <token id="15" string="Blood" />
            <token id="16" string="&quot;" />
            <token id="17" string="(" />
            <token id="18" string="E.P." />
            <token id="19" string="Dutton" />
            <token id="20" string="," />
            <token id="21" string="182" />
            <token id="22" string="pages" />
            <token id="23" string="," />
            <token id="24" string="$" />
            <token id="25" string="16.95" />
            <token id="26" string=")" />
            <token id="27" string=";" />
            <token id="28" string="Peter" />
            <token id="29" string="Ackroyd" />
            <token id="30" string="'s" />
            <token id="31" string="&quot;" />
            <token id="32" string="Chatterton" />
            <token id="33" string="&quot;" />
            <token id="34" string="(" />
            <token id="35" string="Grove" />
            <token id="36" string="Press" />
            <token id="37" string="," />
            <token id="38" string="240" />
            <token id="39" string="pages" />
            <token id="40" string="," />
            <token id="41" string="$" />
            <token id="42" string="17.95" />
            <token id="43" string=")" />
            <token id="44" string=";" />
            <token id="45" string="Nina" />
            <token id="46" string="Bawden" />
            <token id="47" string="'s" />
            <token id="48" string="&quot;" />
            <token id="49" string="Circles" />
            <token id="50" string="of" />
            <token id="51" string="Deceit" />
            <token id="52" string="&quot;" />
            <token id="53" string="(" />
            <token id="54" string="St." />
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
            <token id="58" string="," />
            <token id="59" string="208" />
            <token id="60" string="pages" />
            <token id="61" string="," />
            <token id="62" string="$" />
            <token id="63" string="14.95" />
            <token id="64" string=")" />
            <token id="65" string=";" />
            <token id="66" string="Iris" />
            <token id="67" string="Murdoch" />
            <token id="68" string="'s" />
            <token id="69" string="23rd" />
            <token id="70" string="novel" />
            <token id="71" string="&quot;" />
            <token id="72" string="The" />
            <token id="73" string="Book" />
            <token id="74" string="and" />
            <token id="75" string="the" />
            <token id="76" string="Brotherhood" />
            <token id="77" string="&quot;" />
            <token id="78" string="(" />
            <token id="79" string="Viking" />
            <token id="80" string="," />
            <token id="81" string="608" />
            <token id="82" string="pages" />
            <token id="83" string="," />
            <token id="84" string="$" />
            <token id="85" string="19.95" />
            <token id="86" string=")" />
            <token id="87" string=";" />
            <token id="88" string="Nigerian" />
            <token id="89" string="writer" />
            <token id="90" string="Chinua" />
            <token id="91" string="Achebe" />
            <token id="92" string="'s" />
            <token id="93" string="&quot;" />
            <token id="94" string="Anthills" />
            <token id="95" string="of" />
            <token id="96" string="the" />
            <token id="97" string="Savannah" />
            <token id="98" string="&quot;" />
            <token id="99" string="(" />
            <token id="100" string="Doubleday" />
            <token id="101" string="," />
            <token id="102" string="240" />
            <token id="103" string="pages" />
            <token id="104" string="," />
            <token id="105" string="$" />
            <token id="106" string="16.95" />
            <token id="107" string=")" />
            <token id="108" string=";" />
            <token id="109" string="and" />
            <token id="110" string="&quot;" />
            <token id="111" string="Moon" />
            <token id="112" string="Tiger" />
            <token id="113" string="&quot;" />
            <token id="114" string="(" />
            <token id="115" string="Grove" />
            <token id="116" string="Press" />
            <token id="117" string="," />
            <token id="118" string="216" />
            <token id="119" string="pages" />
            <token id="120" string="," />
            <token id="121" string="$" />
            <token id="122" string="15.95" />
            <token id="123" string=")" />
          </tokens>
        </chunking>
        <chunking id="24" string="Blood" type="NP">
          <tokens>
            <token id="15" string="Blood" />
          </tokens>
        </chunking>
        <chunking id="25" string="The Book" type="NP">
          <tokens>
            <token id="72" string="The" />
            <token id="73" string="Book" />
          </tokens>
        </chunking>
        <chunking id="26" string="Martin 's Press , 208 pages ," type="NP">
          <tokens>
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
            <token id="58" string="," />
            <token id="59" string="208" />
            <token id="60" string="pages" />
            <token id="61" string="," />
          </tokens>
        </chunking>
        <chunking id="27" string="Viking" type="NP">
          <tokens>
            <token id="79" string="Viking" />
          </tokens>
        </chunking>
        <chunking id="28" string="`` Chatterton '' -LRB- Grove Press , 240 pages , $ 17.95 -RRB-" type="NP">
          <tokens>
            <token id="31" string="&quot;" />
            <token id="32" string="Chatterton" />
            <token id="33" string="&quot;" />
            <token id="34" string="(" />
            <token id="35" string="Grove" />
            <token id="36" string="Press" />
            <token id="37" string="," />
            <token id="38" string="240" />
            <token id="39" string="pages" />
            <token id="40" string="," />
            <token id="41" string="$" />
            <token id="42" string="17.95" />
            <token id="43" string=")" />
          </tokens>
        </chunking>
        <chunking id="29" string="Nina Bawden 's" type="NP">
          <tokens>
            <token id="45" string="Nina" />
            <token id="46" string="Bawden" />
            <token id="47" string="'s" />
          </tokens>
        </chunking>
        <chunking id="30" string="Chinua Achebe 's" type="NP">
          <tokens>
            <token id="90" string="Chinua" />
            <token id="91" string="Achebe" />
            <token id="92" string="'s" />
          </tokens>
        </chunking>
        <chunking id="31" string="Brian Moore 's political thriller `` The Color of Blood ''" type="NP">
          <tokens>
            <token id="6" string="Brian" />
            <token id="7" string="Moore" />
            <token id="8" string="'s" />
            <token id="9" string="political" />
            <token id="10" string="thriller" />
            <token id="11" string="&quot;" />
            <token id="12" string="The" />
            <token id="13" string="Color" />
            <token id="14" string="of" />
            <token id="15" string="Blood" />
            <token id="16" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="32" string="$ 17.95" type="NP">
          <tokens>
            <token id="41" string="$" />
            <token id="42" string="17.95" />
          </tokens>
        </chunking>
        <chunking id="33" string="Moon Tiger" type="NP">
          <tokens>
            <token id="111" string="Moon" />
            <token id="112" string="Tiger" />
          </tokens>
        </chunking>
        <chunking id="34" string="Circles" type="NP">
          <tokens>
            <token id="49" string="Circles" />
          </tokens>
        </chunking>
        <chunking id="35" string="included Brian Moore 's political thriller `` The Color of Blood '' -LRB- E.P. Dutton , 182 pages , $ 16.95 -RRB- ; Peter Ackroyd 's `` Chatterton '' -LRB- Grove Press , 240 pages , $ 17.95 -RRB- ; Nina Bawden 's `` Circles of Deceit '' -LRB- St. Martin 's Press , 208 pages , $ 14.95 -RRB- ; Iris Murdoch 's 23rd novel `` The Book and the Brotherhood '' -LRB- Viking , 608 pages , $ 19.95 -RRB- ; Nigerian writer Chinua Achebe 's `` Anthills of the Savannah '' -LRB- Doubleday , 240 pages , $ 16.95 -RRB- ; and `` Moon Tiger '' -LRB- Grove Press , 216 pages , $ 15.95 -RRB-" type="VP">
          <tokens>
            <token id="5" string="included" />
            <token id="6" string="Brian" />
            <token id="7" string="Moore" />
            <token id="8" string="'s" />
            <token id="9" string="political" />
            <token id="10" string="thriller" />
            <token id="11" string="&quot;" />
            <token id="12" string="The" />
            <token id="13" string="Color" />
            <token id="14" string="of" />
            <token id="15" string="Blood" />
            <token id="16" string="&quot;" />
            <token id="17" string="(" />
            <token id="18" string="E.P." />
            <token id="19" string="Dutton" />
            <token id="20" string="," />
            <token id="21" string="182" />
            <token id="22" string="pages" />
            <token id="23" string="," />
            <token id="24" string="$" />
            <token id="25" string="16.95" />
            <token id="26" string=")" />
            <token id="27" string=";" />
            <token id="28" string="Peter" />
            <token id="29" string="Ackroyd" />
            <token id="30" string="'s" />
            <token id="31" string="&quot;" />
            <token id="32" string="Chatterton" />
            <token id="33" string="&quot;" />
            <token id="34" string="(" />
            <token id="35" string="Grove" />
            <token id="36" string="Press" />
            <token id="37" string="," />
            <token id="38" string="240" />
            <token id="39" string="pages" />
            <token id="40" string="," />
            <token id="41" string="$" />
            <token id="42" string="17.95" />
            <token id="43" string=")" />
            <token id="44" string=";" />
            <token id="45" string="Nina" />
            <token id="46" string="Bawden" />
            <token id="47" string="'s" />
            <token id="48" string="&quot;" />
            <token id="49" string="Circles" />
            <token id="50" string="of" />
            <token id="51" string="Deceit" />
            <token id="52" string="&quot;" />
            <token id="53" string="(" />
            <token id="54" string="St." />
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
            <token id="58" string="," />
            <token id="59" string="208" />
            <token id="60" string="pages" />
            <token id="61" string="," />
            <token id="62" string="$" />
            <token id="63" string="14.95" />
            <token id="64" string=")" />
            <token id="65" string=";" />
            <token id="66" string="Iris" />
            <token id="67" string="Murdoch" />
            <token id="68" string="'s" />
            <token id="69" string="23rd" />
            <token id="70" string="novel" />
            <token id="71" string="&quot;" />
            <token id="72" string="The" />
            <token id="73" string="Book" />
            <token id="74" string="and" />
            <token id="75" string="the" />
            <token id="76" string="Brotherhood" />
            <token id="77" string="&quot;" />
            <token id="78" string="(" />
            <token id="79" string="Viking" />
            <token id="80" string="," />
            <token id="81" string="608" />
            <token id="82" string="pages" />
            <token id="83" string="," />
            <token id="84" string="$" />
            <token id="85" string="19.95" />
            <token id="86" string=")" />
            <token id="87" string=";" />
            <token id="88" string="Nigerian" />
            <token id="89" string="writer" />
            <token id="90" string="Chinua" />
            <token id="91" string="Achebe" />
            <token id="92" string="'s" />
            <token id="93" string="&quot;" />
            <token id="94" string="Anthills" />
            <token id="95" string="of" />
            <token id="96" string="the" />
            <token id="97" string="Savannah" />
            <token id="98" string="&quot;" />
            <token id="99" string="(" />
            <token id="100" string="Doubleday" />
            <token id="101" string="," />
            <token id="102" string="240" />
            <token id="103" string="pages" />
            <token id="104" string="," />
            <token id="105" string="$" />
            <token id="106" string="16.95" />
            <token id="107" string=")" />
            <token id="108" string=";" />
            <token id="109" string="and" />
            <token id="110" string="&quot;" />
            <token id="111" string="Moon" />
            <token id="112" string="Tiger" />
            <token id="113" string="&quot;" />
            <token id="114" string="(" />
            <token id="115" string="Grove" />
            <token id="116" string="Press" />
            <token id="117" string="," />
            <token id="118" string="216" />
            <token id="119" string="pages" />
            <token id="120" string="," />
            <token id="121" string="$" />
            <token id="122" string="15.95" />
            <token id="123" string=")" />
          </tokens>
        </chunking>
        <chunking id="36" string="Brian Moore 's political thriller `` The Color of Blood '' -LRB- E.P. Dutton , 182 pages , $ 16.95 -RRB-" type="NP">
          <tokens>
            <token id="6" string="Brian" />
            <token id="7" string="Moore" />
            <token id="8" string="'s" />
            <token id="9" string="political" />
            <token id="10" string="thriller" />
            <token id="11" string="&quot;" />
            <token id="12" string="The" />
            <token id="13" string="Color" />
            <token id="14" string="of" />
            <token id="15" string="Blood" />
            <token id="16" string="&quot;" />
            <token id="17" string="(" />
            <token id="18" string="E.P." />
            <token id="19" string="Dutton" />
            <token id="20" string="," />
            <token id="21" string="182" />
            <token id="22" string="pages" />
            <token id="23" string="," />
            <token id="24" string="$" />
            <token id="25" string="16.95" />
            <token id="26" string=")" />
          </tokens>
        </chunking>
        <chunking id="37" string="Chinua Achebe 's `` Anthills of the Savannah ''" type="NP">
          <tokens>
            <token id="90" string="Chinua" />
            <token id="91" string="Achebe" />
            <token id="92" string="'s" />
            <token id="93" string="&quot;" />
            <token id="94" string="Anthills" />
            <token id="95" string="of" />
            <token id="96" string="the" />
            <token id="97" string="Savannah" />
            <token id="98" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="38" string="Chatterton" type="NP">
          <tokens>
            <token id="32" string="Chatterton" />
          </tokens>
        </chunking>
        <chunking id="39" string="Iris Murdoch 's" type="NP">
          <tokens>
            <token id="66" string="Iris" />
            <token id="67" string="Murdoch" />
            <token id="68" string="'s" />
          </tokens>
        </chunking>
        <chunking id="40" string="240 pages" type="NP">
          <tokens>
            <token id="38" string="240" />
            <token id="39" string="pages" />
          </tokens>
        </chunking>
        <chunking id="41" string="Doubleday" type="NP">
          <tokens>
            <token id="100" string="Doubleday" />
          </tokens>
        </chunking>
        <chunking id="42" string="Peter Ackroyd 's `` Chatterton '' -LRB- Grove Press , 240 pages , $ 17.95 -RRB- ; Nina Bawden 's `` Circles of Deceit '' -LRB- St. Martin 's Press , 208 pages , $ 14.95 -RRB-" type="NP">
          <tokens>
            <token id="28" string="Peter" />
            <token id="29" string="Ackroyd" />
            <token id="30" string="'s" />
            <token id="31" string="&quot;" />
            <token id="32" string="Chatterton" />
            <token id="33" string="&quot;" />
            <token id="34" string="(" />
            <token id="35" string="Grove" />
            <token id="36" string="Press" />
            <token id="37" string="," />
            <token id="38" string="240" />
            <token id="39" string="pages" />
            <token id="40" string="," />
            <token id="41" string="$" />
            <token id="42" string="17.95" />
            <token id="43" string=")" />
            <token id="44" string=";" />
            <token id="45" string="Nina" />
            <token id="46" string="Bawden" />
            <token id="47" string="'s" />
            <token id="48" string="&quot;" />
            <token id="49" string="Circles" />
            <token id="50" string="of" />
            <token id="51" string="Deceit" />
            <token id="52" string="&quot;" />
            <token id="53" string="(" />
            <token id="54" string="St." />
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
            <token id="58" string="," />
            <token id="59" string="208" />
            <token id="60" string="pages" />
            <token id="61" string="," />
            <token id="62" string="$" />
            <token id="63" string="14.95" />
            <token id="64" string=")" />
          </tokens>
        </chunking>
        <chunking id="43" string="Nigerian writer" type="NP">
          <tokens>
            <token id="88" string="Nigerian" />
            <token id="89" string="writer" />
          </tokens>
        </chunking>
        <chunking id="44" string="`` Moon Tiger '' -LRB- Grove Press , 216 pages , $ 15.95 -RRB-" type="NP">
          <tokens>
            <token id="110" string="&quot;" />
            <token id="111" string="Moon" />
            <token id="112" string="Tiger" />
            <token id="113" string="&quot;" />
            <token id="114" string="(" />
            <token id="115" string="Grove" />
            <token id="116" string="Press" />
            <token id="117" string="," />
            <token id="118" string="216" />
            <token id="119" string="pages" />
            <token id="120" string="," />
            <token id="121" string="$" />
            <token id="122" string="15.95" />
            <token id="123" string=")" />
          </tokens>
        </chunking>
        <chunking id="45" string="Nigerian writer Chinua Achebe 's `` Anthills of the Savannah '' -LRB- Doubleday , 240 pages , $ 16.95 -RRB-" type="NP">
          <tokens>
            <token id="88" string="Nigerian" />
            <token id="89" string="writer" />
            <token id="90" string="Chinua" />
            <token id="91" string="Achebe" />
            <token id="92" string="'s" />
            <token id="93" string="&quot;" />
            <token id="94" string="Anthills" />
            <token id="95" string="of" />
            <token id="96" string="the" />
            <token id="97" string="Savannah" />
            <token id="98" string="&quot;" />
            <token id="99" string="(" />
            <token id="100" string="Doubleday" />
            <token id="101" string="," />
            <token id="102" string="240" />
            <token id="103" string="pages" />
            <token id="104" string="," />
            <token id="105" string="$" />
            <token id="106" string="16.95" />
            <token id="107" string=")" />
          </tokens>
        </chunking>
        <chunking id="46" string="Martin 's Press , 208 pages , $ 14.95" type="NP">
          <tokens>
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
            <token id="58" string="," />
            <token id="59" string="208" />
            <token id="60" string="pages" />
            <token id="61" string="," />
            <token id="62" string="$" />
            <token id="63" string="14.95" />
          </tokens>
        </chunking>
        <chunking id="47" string="Iris Murdoch 's 23rd novel" type="NP">
          <tokens>
            <token id="66" string="Iris" />
            <token id="67" string="Murdoch" />
            <token id="68" string="'s" />
            <token id="69" string="23rd" />
            <token id="70" string="novel" />
          </tokens>
        </chunking>
        <chunking id="48" string="St." type="NP">
          <tokens>
            <token id="54" string="St." />
          </tokens>
        </chunking>
        <chunking id="49" string="E.P. Dutton" type="NP">
          <tokens>
            <token id="18" string="E.P." />
            <token id="19" string="Dutton" />
          </tokens>
        </chunking>
        <chunking id="50" string="$ 16.95" type="NP">
          <tokens>
            <token id="24" string="$" />
            <token id="25" string="16.95" />
          </tokens>
        </chunking>
        <chunking id="51" string="Grove Press" type="NP">
          <tokens>
            <token id="35" string="Grove" />
            <token id="36" string="Press" />
          </tokens>
        </chunking>
        <chunking id="52" string="St. Martin 's Press , 208 pages , $ 14.95" type="NP">
          <tokens>
            <token id="54" string="St." />
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
            <token id="58" string="," />
            <token id="59" string="208" />
            <token id="60" string="pages" />
            <token id="61" string="," />
            <token id="62" string="$" />
            <token id="63" string="14.95" />
          </tokens>
        </chunking>
        <chunking id="53" string="608 pages" type="NP">
          <tokens>
            <token id="81" string="608" />
            <token id="82" string="pages" />
          </tokens>
        </chunking>
        <chunking id="54" string="Anthills" type="NP">
          <tokens>
            <token id="94" string="Anthills" />
          </tokens>
        </chunking>
        <chunking id="55" string="the Savannah" type="NP">
          <tokens>
            <token id="96" string="the" />
            <token id="97" string="Savannah" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">year</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">included</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">works</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">included</governor>
          <dependent id="4">works</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">included</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Moore</governor>
          <dependent id="6">Brian</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">Color</governor>
          <dependent id="7">Moore</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Moore</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">Color</governor>
          <dependent id="9">political</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">Color</governor>
          <dependent id="10">thriller</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Color</governor>
          <dependent id="12">The</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">included</governor>
          <dependent id="13">Color</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Blood</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">Color</governor>
          <dependent id="15">Blood</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Dutton</governor>
          <dependent id="18">E.P.</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Color</governor>
          <dependent id="19">Dutton</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">pages</governor>
          <dependent id="21">182</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">Dutton</governor>
          <dependent id="22">pages</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">16.95</governor>
          <dependent id="24">$</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">Dutton</governor>
          <dependent id="25">16.95</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Ackroyd</governor>
          <dependent id="28">Peter</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">Color</governor>
          <dependent id="29">Ackroyd</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Ackroyd</governor>
          <dependent id="30">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="29">Ackroyd</governor>
          <dependent id="32">Chatterton</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Press</governor>
          <dependent id="35">Grove</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="32">Chatterton</governor>
          <dependent id="36">Press</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="39">pages</governor>
          <dependent id="38">240</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="36">Press</governor>
          <dependent id="39">pages</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="42">17.95</governor>
          <dependent id="41">$</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="36">Press</governor>
          <dependent id="42">17.95</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="46">Bawden</governor>
          <dependent id="45">Nina</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="49">Circles</governor>
          <dependent id="46">Bawden</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">Bawden</governor>
          <dependent id="47">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="32">Chatterton</governor>
          <dependent id="49">Circles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">Deceit</governor>
          <dependent id="50">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="49">Circles</governor>
          <dependent id="51">Deceit</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="49">Circles</governor>
          <dependent id="54">St.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="57">Press</governor>
          <dependent id="55">Martin</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">Martin</governor>
          <dependent id="56">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="54">St.</governor>
          <dependent id="57">Press</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="60">pages</governor>
          <dependent id="59">208</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="57">Press</governor>
          <dependent id="60">pages</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="63">14.95</governor>
          <dependent id="62">$</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="57">Press</governor>
          <dependent id="63">14.95</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="67">Murdoch</governor>
          <dependent id="66">Iris</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">Color</governor>
          <dependent id="67">Murdoch</dependent>
        </dependency>
        <dependency type="case">
          <governor id="67">Murdoch</governor>
          <dependent id="68">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="67">Murdoch</governor>
          <dependent id="69">23rd</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="67">Murdoch</governor>
          <dependent id="70">novel</dependent>
        </dependency>
        <dependency type="det">
          <governor id="73">Book</governor>
          <dependent id="72">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="67">Murdoch</governor>
          <dependent id="73">Book</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="73">Book</governor>
          <dependent id="74">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="76">Brotherhood</governor>
          <dependent id="75">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="73">Book</governor>
          <dependent id="76">Brotherhood</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="73">Book</governor>
          <dependent id="79">Viking</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="82">pages</governor>
          <dependent id="81">608</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="79">Viking</governor>
          <dependent id="82">pages</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="85">19.95</governor>
          <dependent id="84">$</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="79">Viking</governor>
          <dependent id="85">19.95</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="89">writer</governor>
          <dependent id="88">Nigerian</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">Color</governor>
          <dependent id="89">writer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="91">Achebe</governor>
          <dependent id="90">Chinua</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="94">Anthills</governor>
          <dependent id="91">Achebe</dependent>
        </dependency>
        <dependency type="case">
          <governor id="91">Achebe</governor>
          <dependent id="92">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="89">writer</governor>
          <dependent id="94">Anthills</dependent>
        </dependency>
        <dependency type="case">
          <governor id="97">Savannah</governor>
          <dependent id="95">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="97">Savannah</governor>
          <dependent id="96">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="94">Anthills</governor>
          <dependent id="97">Savannah</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="94">Anthills</governor>
          <dependent id="100">Doubleday</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="103">pages</governor>
          <dependent id="102">240</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="100">Doubleday</governor>
          <dependent id="103">pages</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="106">16.95</governor>
          <dependent id="105">$</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="100">Doubleday</governor>
          <dependent id="106">16.95</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Color</governor>
          <dependent id="109">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="112">Tiger</governor>
          <dependent id="111">Moon</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Color</governor>
          <dependent id="112">Tiger</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="116">Press</governor>
          <dependent id="115">Grove</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="112">Tiger</governor>
          <dependent id="116">Press</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="119">pages</governor>
          <dependent id="118">216</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="116">Press</governor>
          <dependent id="119">pages</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="122">15.95</governor>
          <dependent id="121">$</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="116">Press</governor>
          <dependent id="122">15.95</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 17.95" type="MONEY" score="0.0">
          <tokens>
            <token id="41" string="$" />
            <token id="42" string="17.95" />
          </tokens>
        </entity>
        <entity id="2" string="Brian Moore" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Brian" />
            <token id="7" string="Moore" />
          </tokens>
        </entity>
        <entity id="3" string="23rd" type="ORDINAL" score="0.0">
          <tokens>
            <token id="69" string="23rd" />
          </tokens>
        </entity>
        <entity id="4" string="182" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="182" />
          </tokens>
        </entity>
        <entity id="5" string="This year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="6" string="Chinua Achebe" type="PERSON" score="0.0">
          <tokens>
            <token id="90" string="Chinua" />
            <token id="91" string="Achebe" />
          </tokens>
        </entity>
        <entity id="7" string="$ 14.95" type="MONEY" score="0.0">
          <tokens>
            <token id="62" string="$" />
            <token id="63" string="14.95" />
          </tokens>
        </entity>
        <entity id="8" string="240" type="NUMBER" score="0.0">
          <tokens>
            <token id="38" string="240" />
          </tokens>
        </entity>
        <entity id="9" string="$ 19.95" type="MONEY" score="0.0">
          <tokens>
            <token id="84" string="$" />
            <token id="85" string="19.95" />
          </tokens>
        </entity>
        <entity id="10" string="Nigerian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="88" string="Nigerian" />
          </tokens>
        </entity>
        <entity id="11" string="E.P. Dutton" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="E.P." />
            <token id="19" string="Dutton" />
          </tokens>
        </entity>
        <entity id="12" string="$ 16.95" type="MONEY" score="0.0">
          <tokens>
            <token id="24" string="$" />
            <token id="25" string="16.95" />
          </tokens>
        </entity>
        <entity id="13" string="Doubleday" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="100" string="Doubleday" />
          </tokens>
        </entity>
        <entity id="14" string="$ 15.95" type="MONEY" score="0.0">
          <tokens>
            <token id="121" string="$" />
            <token id="122" string="15.95" />
          </tokens>
        </entity>
        <entity id="15" string="Grove Press" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="35" string="Grove" />
            <token id="36" string="Press" />
          </tokens>
        </entity>
        <entity id="16" string="Iris Murdoch" type="PERSON" score="0.0">
          <tokens>
            <token id="66" string="Iris" />
            <token id="67" string="Murdoch" />
          </tokens>
        </entity>
        <entity id="17" string="St. Martin 's Press" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="54" string="St." />
            <token id="55" string="Martin" />
            <token id="56" string="'s" />
            <token id="57" string="Press" />
          </tokens>
        </entity>
        <entity id="18" string="216" type="NUMBER" score="0.0">
          <tokens>
            <token id="118" string="216" />
          </tokens>
        </entity>
        <entity id="19" string="208" type="NUMBER" score="0.0">
          <tokens>
            <token id="59" string="208" />
          </tokens>
        </entity>
        <entity id="20" string="Nina Bawden" type="PERSON" score="0.0">
          <tokens>
            <token id="45" string="Nina" />
            <token id="46" string="Bawden" />
          </tokens>
        </entity>
        <entity id="21" string="Savannah" type="LOCATION" score="0.0">
          <tokens>
            <token id="97" string="Savannah" />
          </tokens>
        </entity>
        <entity id="22" string="Peter Ackroyd" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Peter" />
            <token id="29" string="Ackroyd" />
          </tokens>
        </entity>
        <entity id="23" string="608" type="NUMBER" score="0.0">
          <tokens>
            <token id="81" string="608" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="false">
      <content>The awards presentation came on the last Thursday in October, and like any major awards presentation, it came complete with limousines, banquet (salmon mousse, champagne sorbet and English roast beef) and television cameras.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="awards" lemma="award" stem="award" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="presentation" lemma="presentation" stem="present" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="October" lemma="October" stem="october" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="awards" lemma="award" stem="award" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="presentation" lemma="presentation" stem="present" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="complete" lemma="complete" stem="complet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="limousines" lemma="limousine" stem="limousin" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="banquet" lemma="banquet" stem="banquet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="salmon" lemma="salmon" stem="salmon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="mousse" lemma="mousse" stem="mouss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="champagne" lemma="champagne" stem="champagn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="sorbet" lemma="sorbet" stem="sorbet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="English" lemma="english" stem="english" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="34" string="roast" lemma="roast" stem="roast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="beef" lemma="beef" stem="beef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="cameras" lemma="camera" stem="camera" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNS awards) (NN presentation)) (VP (VBD came) (PP (IN on) (NP-TMP (DT the) (JJ last) (NNP Thursday))) (PP (IN in) (NP (NNP October))))) (, ,) (CC and) (S (PP (IN like) (NP (DT any) (JJ major) (NNS awards) (NN presentation))) (, ,) (NP (PRP it)) (VP (VBD came) (ADJP (JJ complete)) (PP (IN with) (NP (NP (NNS limousines)) (, ,) (NP (NP (NP (NN banquet)) (PRN (-LRB- -LRB-) (NP (NP (NN salmon) (NN mousse)) (, ,) (NP (NN champagne) (NN sorbet)) (CC and) (NP (JJ English) (NN roast) (NN beef))) (-RRB- -RRB-))) (CC and) (NP (NN television) (NNS cameras))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="limousines" type="NP">
          <tokens>
            <token id="23" string="limousines" />
          </tokens>
        </chunking>
        <chunking id="2" string="any major awards presentation" type="NP">
          <tokens>
            <token id="14" string="any" />
            <token id="15" string="major" />
            <token id="16" string="awards" />
            <token id="17" string="presentation" />
          </tokens>
        </chunking>
        <chunking id="3" string="came complete with limousines , banquet -LRB- salmon mousse , champagne sorbet and English roast beef -RRB- and television cameras" type="VP">
          <tokens>
            <token id="20" string="came" />
            <token id="21" string="complete" />
            <token id="22" string="with" />
            <token id="23" string="limousines" />
            <token id="24" string="," />
            <token id="25" string="banquet" />
            <token id="26" string="(" />
            <token id="27" string="salmon" />
            <token id="28" string="mousse" />
            <token id="29" string="," />
            <token id="30" string="champagne" />
            <token id="31" string="sorbet" />
            <token id="32" string="and" />
            <token id="33" string="English" />
            <token id="34" string="roast" />
            <token id="35" string="beef" />
            <token id="36" string=")" />
            <token id="37" string="and" />
            <token id="38" string="television" />
            <token id="39" string="cameras" />
          </tokens>
        </chunking>
        <chunking id="4" string="came on the last Thursday in October" type="VP">
          <tokens>
            <token id="4" string="came" />
            <token id="5" string="on" />
            <token id="6" string="the" />
            <token id="7" string="last" />
            <token id="8" string="Thursday" />
            <token id="9" string="in" />
            <token id="10" string="October" />
          </tokens>
        </chunking>
        <chunking id="5" string="English roast beef" type="NP">
          <tokens>
            <token id="33" string="English" />
            <token id="34" string="roast" />
            <token id="35" string="beef" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="19" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="banquet" type="NP">
          <tokens>
            <token id="25" string="banquet" />
          </tokens>
        </chunking>
        <chunking id="8" string="limousines , banquet -LRB- salmon mousse , champagne sorbet and English roast beef -RRB- and television cameras" type="NP">
          <tokens>
            <token id="23" string="limousines" />
            <token id="24" string="," />
            <token id="25" string="banquet" />
            <token id="26" string="(" />
            <token id="27" string="salmon" />
            <token id="28" string="mousse" />
            <token id="29" string="," />
            <token id="30" string="champagne" />
            <token id="31" string="sorbet" />
            <token id="32" string="and" />
            <token id="33" string="English" />
            <token id="34" string="roast" />
            <token id="35" string="beef" />
            <token id="36" string=")" />
            <token id="37" string="and" />
            <token id="38" string="television" />
            <token id="39" string="cameras" />
          </tokens>
        </chunking>
        <chunking id="9" string="October" type="NP">
          <tokens>
            <token id="10" string="October" />
          </tokens>
        </chunking>
        <chunking id="10" string="television cameras" type="NP">
          <tokens>
            <token id="38" string="television" />
            <token id="39" string="cameras" />
          </tokens>
        </chunking>
        <chunking id="11" string="salmon mousse , champagne sorbet and English roast beef" type="NP">
          <tokens>
            <token id="27" string="salmon" />
            <token id="28" string="mousse" />
            <token id="29" string="," />
            <token id="30" string="champagne" />
            <token id="31" string="sorbet" />
            <token id="32" string="and" />
            <token id="33" string="English" />
            <token id="34" string="roast" />
            <token id="35" string="beef" />
          </tokens>
        </chunking>
        <chunking id="12" string="banquet -LRB- salmon mousse , champagne sorbet and English roast beef -RRB- and television cameras" type="NP">
          <tokens>
            <token id="25" string="banquet" />
            <token id="26" string="(" />
            <token id="27" string="salmon" />
            <token id="28" string="mousse" />
            <token id="29" string="," />
            <token id="30" string="champagne" />
            <token id="31" string="sorbet" />
            <token id="32" string="and" />
            <token id="33" string="English" />
            <token id="34" string="roast" />
            <token id="35" string="beef" />
            <token id="36" string=")" />
            <token id="37" string="and" />
            <token id="38" string="television" />
            <token id="39" string="cameras" />
          </tokens>
        </chunking>
        <chunking id="13" string="The awards presentation" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="awards" />
            <token id="3" string="presentation" />
          </tokens>
        </chunking>
        <chunking id="14" string="salmon mousse" type="NP">
          <tokens>
            <token id="27" string="salmon" />
            <token id="28" string="mousse" />
          </tokens>
        </chunking>
        <chunking id="15" string="complete" type="ADJP">
          <tokens>
            <token id="21" string="complete" />
          </tokens>
        </chunking>
        <chunking id="16" string="champagne sorbet" type="NP">
          <tokens>
            <token id="30" string="champagne" />
            <token id="31" string="sorbet" />
          </tokens>
        </chunking>
        <chunking id="17" string="banquet -LRB- salmon mousse , champagne sorbet and English roast beef -RRB-" type="NP">
          <tokens>
            <token id="25" string="banquet" />
            <token id="26" string="(" />
            <token id="27" string="salmon" />
            <token id="28" string="mousse" />
            <token id="29" string="," />
            <token id="30" string="champagne" />
            <token id="31" string="sorbet" />
            <token id="32" string="and" />
            <token id="33" string="English" />
            <token id="34" string="roast" />
            <token id="35" string="beef" />
            <token id="36" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">presentation</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">presentation</governor>
          <dependent id="2">awards</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">came</governor>
          <dependent id="3">presentation</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Thursday</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Thursday</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">Thursday</governor>
          <dependent id="7">last</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">came</governor>
          <dependent id="8">Thursday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">October</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">came</governor>
          <dependent id="10">October</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">came</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">presentation</governor>
          <dependent id="13">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">presentation</governor>
          <dependent id="14">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">presentation</governor>
          <dependent id="15">major</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">presentation</governor>
          <dependent id="16">awards</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">came</governor>
          <dependent id="17">presentation</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">came</governor>
          <dependent id="19">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">came</governor>
          <dependent id="20">came</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">came</governor>
          <dependent id="21">complete</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">limousines</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">came</governor>
          <dependent id="23">limousines</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">limousines</governor>
          <dependent id="25">banquet</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">mousse</governor>
          <dependent id="27">salmon</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">banquet</governor>
          <dependent id="28">mousse</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">sorbet</governor>
          <dependent id="30">champagne</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">mousse</governor>
          <dependent id="31">sorbet</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">mousse</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">beef</governor>
          <dependent id="33">English</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">beef</governor>
          <dependent id="34">roast</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">mousse</governor>
          <dependent id="35">beef</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">banquet</governor>
          <dependent id="37">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">cameras</governor>
          <dependent id="38">television</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">banquet</governor>
          <dependent id="39">cameras</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the last Thursday in October" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="last" />
            <token id="8" string="Thursday" />
            <token id="9" string="in" />
            <token id="10" string="October" />
          </tokens>
        </entity>
        <entity id="2" string="English" type="MISC" score="0.0">
          <tokens>
            <token id="33" string="English" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>The suspense was genuine; the judges chose the winner just three hours before the announcement.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="suspense" lemma="suspense" stem="suspens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="genuine" lemma="genuine" stem="genuin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="chose" lemma="choose" stem="chose" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="14" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="announcement" lemma="announcement" stem="announc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN suspense)) (VP (VBD was) (ADJP (JJ genuine)))) (: ;) (S (NP (DT the) (NNS judges)) (VP (VBD chose) (NP (DT the) (NN winner)) (PP (NP (RB just) (CD three) (NNS hours)) (IN before) (NP (DT the) (NN announcement))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the announcement" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="announcement" />
          </tokens>
        </chunking>
        <chunking id="2" string="the winner" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="winner" />
          </tokens>
        </chunking>
        <chunking id="3" string="was genuine" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="genuine" />
          </tokens>
        </chunking>
        <chunking id="4" string="The suspense" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="suspense" />
          </tokens>
        </chunking>
        <chunking id="5" string="the judges" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="judges" />
          </tokens>
        </chunking>
        <chunking id="6" string="genuine" type="ADJP">
          <tokens>
            <token id="4" string="genuine" />
          </tokens>
        </chunking>
        <chunking id="7" string="chose the winner just three hours before the announcement" type="VP">
          <tokens>
            <token id="8" string="chose" />
            <token id="9" string="the" />
            <token id="10" string="winner" />
            <token id="11" string="just" />
            <token id="12" string="three" />
            <token id="13" string="hours" />
            <token id="14" string="before" />
            <token id="15" string="the" />
            <token id="16" string="announcement" />
          </tokens>
        </chunking>
        <chunking id="8" string="just three hours" type="NP">
          <tokens>
            <token id="11" string="just" />
            <token id="12" string="three" />
            <token id="13" string="hours" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">suspense</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">genuine</governor>
          <dependent id="2">suspense</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">genuine</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">genuine</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">judges</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">chose</governor>
          <dependent id="7">judges</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">genuine</governor>
          <dependent id="8">chose</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">winner</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">chose</governor>
          <dependent id="10">winner</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">hours</governor>
          <dependent id="11">just</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">hours</governor>
          <dependent id="12">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">chose</governor>
          <dependent id="13">hours</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">hours</governor>
          <dependent id="14">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">announcement</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">hours</governor>
          <dependent id="16">announcement</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="three hours" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="three" />
            <token id="13" string="hours" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>To be sure, the ratings for the prime-time broadcast didn&amp;apost;t upstage those of &amp;quot;Eastenders,&amp;quot; Britain&amp;apost;s popular soap opera.</content>
      <tokens>
        <token id="1" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="ratings" lemma="rating" stem="rate" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="prime-time" lemma="prime-time" stem="prime-tim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="broadcast" lemma="broadcast" stem="broadcast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="upstage" lemma="upstage" stem="upstag" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Eastenders" lemma="Eastenders" stem="eastend" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="21" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="popular" lemma="popular" stem="popular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="soap" lemma="soap" stem="soap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="opera" lemma="opera" stem="opera" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (TO To) (VP (VB be) (ADJP (JJ sure))))) (, ,) (NP (NP (DT the) (NNS ratings)) (PP (IN for) (NP (DT the) (NN prime-time) (NN broadcast)))) (VP (VBD did) (RB n't) (VP (VB upstage) (NP (NP (DT those)) (PP (IN of) (NP (`` ``) (NP (NNP Eastenders)) (, ,) ('' '') (NP (NP (NNP Britain) (POS 's)) (JJ popular) (NN soap) (NN opera))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sure" type="ADJP">
          <tokens>
            <token id="3" string="sure" />
          </tokens>
        </chunking>
        <chunking id="2" string="be sure" type="VP">
          <tokens>
            <token id="2" string="be" />
            <token id="3" string="sure" />
          </tokens>
        </chunking>
        <chunking id="3" string="the ratings for the prime-time broadcast" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="ratings" />
            <token id="7" string="for" />
            <token id="8" string="the" />
            <token id="9" string="prime-time" />
            <token id="10" string="broadcast" />
          </tokens>
        </chunking>
        <chunking id="4" string="did n't upstage those of `` Eastenders , '' Britain 's popular soap opera" type="VP">
          <tokens>
            <token id="11" string="did" />
            <token id="12" string="n't" />
            <token id="13" string="upstage" />
            <token id="14" string="those" />
            <token id="15" string="of" />
            <token id="16" string="&quot;" />
            <token id="17" string="Eastenders" />
            <token id="18" string="," />
            <token id="19" string="&quot;" />
            <token id="20" string="Britain" />
            <token id="21" string="'s" />
            <token id="22" string="popular" />
            <token id="23" string="soap" />
            <token id="24" string="opera" />
          </tokens>
        </chunking>
        <chunking id="5" string="those of `` Eastenders , '' Britain 's popular soap opera" type="NP">
          <tokens>
            <token id="14" string="those" />
            <token id="15" string="of" />
            <token id="16" string="&quot;" />
            <token id="17" string="Eastenders" />
            <token id="18" string="," />
            <token id="19" string="&quot;" />
            <token id="20" string="Britain" />
            <token id="21" string="'s" />
            <token id="22" string="popular" />
            <token id="23" string="soap" />
            <token id="24" string="opera" />
          </tokens>
        </chunking>
        <chunking id="6" string="Britain 's popular soap opera" type="NP">
          <tokens>
            <token id="20" string="Britain" />
            <token id="21" string="'s" />
            <token id="22" string="popular" />
            <token id="23" string="soap" />
            <token id="24" string="opera" />
          </tokens>
        </chunking>
        <chunking id="7" string="`` Eastenders , '' Britain 's popular soap opera" type="NP">
          <tokens>
            <token id="16" string="&quot;" />
            <token id="17" string="Eastenders" />
            <token id="18" string="," />
            <token id="19" string="&quot;" />
            <token id="20" string="Britain" />
            <token id="21" string="'s" />
            <token id="22" string="popular" />
            <token id="23" string="soap" />
            <token id="24" string="opera" />
          </tokens>
        </chunking>
        <chunking id="8" string="Eastenders" type="NP">
          <tokens>
            <token id="17" string="Eastenders" />
          </tokens>
        </chunking>
        <chunking id="9" string="upstage those of `` Eastenders , '' Britain 's popular soap opera" type="VP">
          <tokens>
            <token id="13" string="upstage" />
            <token id="14" string="those" />
            <token id="15" string="of" />
            <token id="16" string="&quot;" />
            <token id="17" string="Eastenders" />
            <token id="18" string="," />
            <token id="19" string="&quot;" />
            <token id="20" string="Britain" />
            <token id="21" string="'s" />
            <token id="22" string="popular" />
            <token id="23" string="soap" />
            <token id="24" string="opera" />
          </tokens>
        </chunking>
        <chunking id="10" string="To be sure" type="VP">
          <tokens>
            <token id="1" string="To" />
            <token id="2" string="be" />
            <token id="3" string="sure" />
          </tokens>
        </chunking>
        <chunking id="11" string="the prime-time broadcast" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="prime-time" />
            <token id="10" string="broadcast" />
          </tokens>
        </chunking>
        <chunking id="12" string="Britain 's" type="NP">
          <tokens>
            <token id="20" string="Britain" />
            <token id="21" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="the ratings" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="ratings" />
          </tokens>
        </chunking>
        <chunking id="14" string="those" type="NP">
          <tokens>
            <token id="14" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">sure</governor>
          <dependent id="1">To</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">sure</governor>
          <dependent id="2">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">upstage</governor>
          <dependent id="3">sure</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">ratings</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">upstage</governor>
          <dependent id="6">ratings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">broadcast</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">broadcast</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">broadcast</governor>
          <dependent id="9">prime-time</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">ratings</governor>
          <dependent id="10">broadcast</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">upstage</governor>
          <dependent id="11">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">upstage</governor>
          <dependent id="12">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">upstage</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">upstage</governor>
          <dependent id="14">those</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Eastenders</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">those</governor>
          <dependent id="17">Eastenders</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">opera</governor>
          <dependent id="20">Britain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Britain</governor>
          <dependent id="21">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">opera</governor>
          <dependent id="22">popular</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">opera</governor>
          <dependent id="23">soap</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">Eastenders</governor>
          <dependent id="24">opera</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Yet interest was sufficient for Andre Deutsch, &amp;quot;Moon Tiger&amp;apost;s&amp;quot; British publisher, to order up an additional 20,000 copies almost the minute Mrs. Lively -- and the nation -- heard the news.</content>
      <tokens>
        <token id="1" string="Yet" lemma="yet" stem="yet" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="sufficient" lemma="sufficient" stem="suffici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Andre" lemma="Andre" stem="andre" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Deutsch" lemma="Deutsch" stem="deutsch" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Moon" lemma="Moon" stem="moon" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="Tiger" lemma="Tiger" stem="tiger" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="15" string="publisher" lemma="publisher" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="order" lemma="order" stem="order" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="additional" lemma="additional" stem="addit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="20,000" lemma="20,000" stem="20,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="23" string="copies" lemma="copy" stem="copi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="26" string="minute" lemma="minute" stem="minut" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="27" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Lively" lemma="Lively" stem="live" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="heard" lemma="hear" stem="heard" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC Yet) (NP (NN interest)) (VP (VBD was) (NP (ADJP (JJ sufficient) (PP (IN for) (NP (NP (NNP Andre) (NNP Deutsch)) (, ,) (`` ``) (NP (NNP Moon) (NP (NNP Tiger) (POS 's))) ('' '')))) (JJ British) (NN publisher)) (, ,) (S (VP (TO to) (VP (VB order) (PRT (RP up)) (NP (NP (DT an) (JJ additional) (CD 20,000) (NNS copies)) (ADVP (RB almost) (NP (DT the) (NN minute)))) (SBAR (S (NP (NP (NNP Mrs.) (NNP Lively)) (PRN (: --) (CC and) (NP (DT the) (NN nation)) (: --))) (VP (VBD heard) (NP (DT the) (NN news))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the nation" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="nation" />
          </tokens>
        </chunking>
        <chunking id="2" string="the news" type="NP">
          <tokens>
            <token id="35" string="the" />
            <token id="36" string="news" />
          </tokens>
        </chunking>
        <chunking id="3" string="Mrs. Lively -- and the nation --" type="NP">
          <tokens>
            <token id="27" string="Mrs." />
            <token id="28" string="Lively" />
            <token id="29" string="--" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="nation" />
            <token id="33" string="--" />
          </tokens>
        </chunking>
        <chunking id="4" string="Moon Tiger 's" type="NP">
          <tokens>
            <token id="10" string="Moon" />
            <token id="11" string="Tiger" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="sufficient for Andre Deutsch , `` Moon Tiger 's ''" type="ADJP">
          <tokens>
            <token id="4" string="sufficient" />
            <token id="5" string="for" />
            <token id="6" string="Andre" />
            <token id="7" string="Deutsch" />
            <token id="8" string="," />
            <token id="9" string="&quot;" />
            <token id="10" string="Moon" />
            <token id="11" string="Tiger" />
            <token id="12" string="'s" />
            <token id="13" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="6" string="order up an additional 20,000 copies almost the minute Mrs. Lively -- and the nation -- heard the news" type="VP">
          <tokens>
            <token id="18" string="order" />
            <token id="19" string="up" />
            <token id="20" string="an" />
            <token id="21" string="additional" />
            <token id="22" string="20,000" />
            <token id="23" string="copies" />
            <token id="24" string="almost" />
            <token id="25" string="the" />
            <token id="26" string="minute" />
            <token id="27" string="Mrs." />
            <token id="28" string="Lively" />
            <token id="29" string="--" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="nation" />
            <token id="33" string="--" />
            <token id="34" string="heard" />
            <token id="35" string="the" />
            <token id="36" string="news" />
          </tokens>
        </chunking>
        <chunking id="7" string="sufficient for Andre Deutsch , `` Moon Tiger 's '' British publisher" type="NP">
          <tokens>
            <token id="4" string="sufficient" />
            <token id="5" string="for" />
            <token id="6" string="Andre" />
            <token id="7" string="Deutsch" />
            <token id="8" string="," />
            <token id="9" string="&quot;" />
            <token id="10" string="Moon" />
            <token id="11" string="Tiger" />
            <token id="12" string="'s" />
            <token id="13" string="&quot;" />
            <token id="14" string="British" />
            <token id="15" string="publisher" />
          </tokens>
        </chunking>
        <chunking id="8" string="to order up an additional 20,000 copies almost the minute Mrs. Lively -- and the nation -- heard the news" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="order" />
            <token id="19" string="up" />
            <token id="20" string="an" />
            <token id="21" string="additional" />
            <token id="22" string="20,000" />
            <token id="23" string="copies" />
            <token id="24" string="almost" />
            <token id="25" string="the" />
            <token id="26" string="minute" />
            <token id="27" string="Mrs." />
            <token id="28" string="Lively" />
            <token id="29" string="--" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="nation" />
            <token id="33" string="--" />
            <token id="34" string="heard" />
            <token id="35" string="the" />
            <token id="36" string="news" />
          </tokens>
        </chunking>
        <chunking id="9" string="the minute" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="minute" />
          </tokens>
        </chunking>
        <chunking id="10" string="Andre Deutsch , `` Moon Tiger 's ''" type="NP">
          <tokens>
            <token id="6" string="Andre" />
            <token id="7" string="Deutsch" />
            <token id="8" string="," />
            <token id="9" string="&quot;" />
            <token id="10" string="Moon" />
            <token id="11" string="Tiger" />
            <token id="12" string="'s" />
            <token id="13" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="11" string="an additional 20,000 copies" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="additional" />
            <token id="22" string="20,000" />
            <token id="23" string="copies" />
          </tokens>
        </chunking>
        <chunking id="12" string="Andre Deutsch" type="NP">
          <tokens>
            <token id="6" string="Andre" />
            <token id="7" string="Deutsch" />
          </tokens>
        </chunking>
        <chunking id="13" string="Mrs. Lively" type="NP">
          <tokens>
            <token id="27" string="Mrs." />
            <token id="28" string="Lively" />
          </tokens>
        </chunking>
        <chunking id="14" string="was sufficient for Andre Deutsch , `` Moon Tiger 's '' British publisher , to order up an additional 20,000 copies almost the minute Mrs. Lively -- and the nation -- heard the news" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="sufficient" />
            <token id="5" string="for" />
            <token id="6" string="Andre" />
            <token id="7" string="Deutsch" />
            <token id="8" string="," />
            <token id="9" string="&quot;" />
            <token id="10" string="Moon" />
            <token id="11" string="Tiger" />
            <token id="12" string="'s" />
            <token id="13" string="&quot;" />
            <token id="14" string="British" />
            <token id="15" string="publisher" />
            <token id="16" string="," />
            <token id="17" string="to" />
            <token id="18" string="order" />
            <token id="19" string="up" />
            <token id="20" string="an" />
            <token id="21" string="additional" />
            <token id="22" string="20,000" />
            <token id="23" string="copies" />
            <token id="24" string="almost" />
            <token id="25" string="the" />
            <token id="26" string="minute" />
            <token id="27" string="Mrs." />
            <token id="28" string="Lively" />
            <token id="29" string="--" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="nation" />
            <token id="33" string="--" />
            <token id="34" string="heard" />
            <token id="35" string="the" />
            <token id="36" string="news" />
          </tokens>
        </chunking>
        <chunking id="15" string="an additional 20,000 copies almost the minute" type="NP">
          <tokens>
            <token id="20" string="an" />
            <token id="21" string="additional" />
            <token id="22" string="20,000" />
            <token id="23" string="copies" />
            <token id="24" string="almost" />
            <token id="25" string="the" />
            <token id="26" string="minute" />
          </tokens>
        </chunking>
        <chunking id="16" string="interest" type="NP">
          <tokens>
            <token id="2" string="interest" />
          </tokens>
        </chunking>
        <chunking id="17" string="Mrs. Lively -- and the nation -- heard the news" type="SBAR">
          <tokens>
            <token id="27" string="Mrs." />
            <token id="28" string="Lively" />
            <token id="29" string="--" />
            <token id="30" string="and" />
            <token id="31" string="the" />
            <token id="32" string="nation" />
            <token id="33" string="--" />
            <token id="34" string="heard" />
            <token id="35" string="the" />
            <token id="36" string="news" />
          </tokens>
        </chunking>
        <chunking id="18" string="heard the news" type="VP">
          <tokens>
            <token id="34" string="heard" />
            <token id="35" string="the" />
            <token id="36" string="news" />
          </tokens>
        </chunking>
        <chunking id="19" string="Tiger 's" type="NP">
          <tokens>
            <token id="11" string="Tiger" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="15">publisher</governor>
          <dependent id="1">Yet</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">publisher</governor>
          <dependent id="2">interest</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">publisher</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">publisher</governor>
          <dependent id="4">sufficient</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Deutsch</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Deutsch</governor>
          <dependent id="6">Andre</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">sufficient</governor>
          <dependent id="7">Deutsch</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">Deutsch</governor>
          <dependent id="10">Moon</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">Moon</governor>
          <dependent id="11">Tiger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Tiger</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">publisher</governor>
          <dependent id="14">British</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">publisher</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">order</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">publisher</governor>
          <dependent id="18">order</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="18">order</governor>
          <dependent id="19">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">copies</governor>
          <dependent id="20">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">copies</governor>
          <dependent id="21">additional</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">copies</governor>
          <dependent id="22">20,000</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">order</governor>
          <dependent id="23">copies</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">copies</governor>
          <dependent id="24">almost</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">minute</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="24">almost</governor>
          <dependent id="26">minute</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Lively</governor>
          <dependent id="27">Mrs.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">heard</governor>
          <dependent id="28">Lively</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">nation</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">nation</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">Lively</governor>
          <dependent id="32">nation</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">order</governor>
          <dependent id="34">heard</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">news</governor>
          <dependent id="35">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">heard</governor>
          <dependent id="36">news</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Andre Deutsch" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Andre" />
            <token id="7" string="Deutsch" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="14" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="20,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="20,000" />
          </tokens>
        </entity>
        <entity id="4" string="the minute" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="minute" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>By British standards, sales figures for recent Booker winners are stunning, from &amp;quot;The Old Devils&amp;quot; (80,000 hard-cover copies) to Anita Brookner&amp;apost;s &amp;quot;Hotel du Lac&amp;quot; (40,000 copies).</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="3" string="standards" lemma="standard" stem="standard" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sales" lemma="sale" stem="sale" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="figures" lemma="figure" stem="figur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="winners" lemma="winner" stem="winner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="stunning" lemma="stunning" stem="stun" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="The" lemma="The" stem="the" pos="NNP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Old" lemma="Old" stem="old" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Devils" lemma="Devils" stem="devil" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="80,000" lemma="80,000" stem="80,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="hard-cover" lemma="hard-cover" stem="hard-cov" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="copies" lemma="copy" stem="copi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Anita" lemma="Anita" stem="anita" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="Brookner" lemma="Brookner" stem="brookner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Hotel" lemma="Hotel" stem="hotel" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="du" lemma="du" stem="du" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="Lac" lemma="Lac" stem="lac" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="40,000" lemma="40,000" stem="40,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="36" string="copies" lemma="copy" stem="copi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (JJ British) (NNS standards))) (, ,) (NP (NP (NNS sales) (NNS figures)) (PP (IN for) (NP (JJ recent) (NNP Booker) (NNS winners)))) (VP (VBP are) (ADJP (ADJP (JJ stunning) (, ,) (PP (IN from) (NP (`` ``) (NP (NNP The) (NNP Old) (NNPS Devils)) ('' '') (PRN (-LRB- -LRB-) (NP (NP (CD 80,000)) (NP (JJ hard-cover) (NNS copies))) (-RRB- -RRB-))))) (PP (TO to) (NP (NP (NNP Anita) (NNP Brookner) (POS 's)) (NP (`` ``) (NP (NNP Hotel) (NNP du) (NNP Lac)) ('' '') (PRN (-LRB- -LRB-) (NP (CD 40,000) (NNS copies)) (-RRB- -RRB-))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Old Devils" type="NP">
          <tokens>
            <token id="16" string="The" />
            <token id="17" string="Old" />
            <token id="18" string="Devils" />
          </tokens>
        </chunking>
        <chunking id="2" string="sales figures for recent Booker winners" type="NP">
          <tokens>
            <token id="5" string="sales" />
            <token id="6" string="figures" />
            <token id="7" string="for" />
            <token id="8" string="recent" />
            <token id="9" string="Booker" />
            <token id="10" string="winners" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` The Old Devils '' -LRB- 80,000 hard-cover copies -RRB-" type="NP">
          <tokens>
            <token id="15" string="&quot;" />
            <token id="16" string="The" />
            <token id="17" string="Old" />
            <token id="18" string="Devils" />
            <token id="19" string="&quot;" />
            <token id="20" string="(" />
            <token id="21" string="80,000" />
            <token id="22" string="hard-cover" />
            <token id="23" string="copies" />
            <token id="24" string=")" />
          </tokens>
        </chunking>
        <chunking id="4" string="Anita Brookner 's" type="NP">
          <tokens>
            <token id="26" string="Anita" />
            <token id="27" string="Brookner" />
            <token id="28" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="40,000 copies" type="NP">
          <tokens>
            <token id="35" string="40,000" />
            <token id="36" string="copies" />
          </tokens>
        </chunking>
        <chunking id="6" string="stunning , from `` The Old Devils '' -LRB- 80,000 hard-cover copies -RRB-" type="ADJP">
          <tokens>
            <token id="12" string="stunning" />
            <token id="13" string="," />
            <token id="14" string="from" />
            <token id="15" string="&quot;" />
            <token id="16" string="The" />
            <token id="17" string="Old" />
            <token id="18" string="Devils" />
            <token id="19" string="&quot;" />
            <token id="20" string="(" />
            <token id="21" string="80,000" />
            <token id="22" string="hard-cover" />
            <token id="23" string="copies" />
            <token id="24" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="80,000" type="NP">
          <tokens>
            <token id="21" string="80,000" />
          </tokens>
        </chunking>
        <chunking id="8" string="sales figures" type="NP">
          <tokens>
            <token id="5" string="sales" />
            <token id="6" string="figures" />
          </tokens>
        </chunking>
        <chunking id="9" string="Anita Brookner 's `` Hotel du Lac '' -LRB- 40,000 copies -RRB-" type="NP">
          <tokens>
            <token id="26" string="Anita" />
            <token id="27" string="Brookner" />
            <token id="28" string="'s" />
            <token id="29" string="&quot;" />
            <token id="30" string="Hotel" />
            <token id="31" string="du" />
            <token id="32" string="Lac" />
            <token id="33" string="&quot;" />
            <token id="34" string="(" />
            <token id="35" string="40,000" />
            <token id="36" string="copies" />
            <token id="37" string=")" />
          </tokens>
        </chunking>
        <chunking id="10" string="are stunning , from `` The Old Devils '' -LRB- 80,000 hard-cover copies -RRB- to Anita Brookner 's `` Hotel du Lac '' -LRB- 40,000 copies -RRB-" type="VP">
          <tokens>
            <token id="11" string="are" />
            <token id="12" string="stunning" />
            <token id="13" string="," />
            <token id="14" string="from" />
            <token id="15" string="&quot;" />
            <token id="16" string="The" />
            <token id="17" string="Old" />
            <token id="18" string="Devils" />
            <token id="19" string="&quot;" />
            <token id="20" string="(" />
            <token id="21" string="80,000" />
            <token id="22" string="hard-cover" />
            <token id="23" string="copies" />
            <token id="24" string=")" />
            <token id="25" string="to" />
            <token id="26" string="Anita" />
            <token id="27" string="Brookner" />
            <token id="28" string="'s" />
            <token id="29" string="&quot;" />
            <token id="30" string="Hotel" />
            <token id="31" string="du" />
            <token id="32" string="Lac" />
            <token id="33" string="&quot;" />
            <token id="34" string="(" />
            <token id="35" string="40,000" />
            <token id="36" string="copies" />
            <token id="37" string=")" />
          </tokens>
        </chunking>
        <chunking id="11" string="hard-cover copies" type="NP">
          <tokens>
            <token id="22" string="hard-cover" />
            <token id="23" string="copies" />
          </tokens>
        </chunking>
        <chunking id="12" string="Hotel du Lac" type="NP">
          <tokens>
            <token id="30" string="Hotel" />
            <token id="31" string="du" />
            <token id="32" string="Lac" />
          </tokens>
        </chunking>
        <chunking id="13" string="80,000 hard-cover copies" type="NP">
          <tokens>
            <token id="21" string="80,000" />
            <token id="22" string="hard-cover" />
            <token id="23" string="copies" />
          </tokens>
        </chunking>
        <chunking id="14" string="recent Booker winners" type="NP">
          <tokens>
            <token id="8" string="recent" />
            <token id="9" string="Booker" />
            <token id="10" string="winners" />
          </tokens>
        </chunking>
        <chunking id="15" string="stunning , from `` The Old Devils '' -LRB- 80,000 hard-cover copies -RRB- to Anita Brookner 's `` Hotel du Lac '' -LRB- 40,000 copies -RRB-" type="ADJP">
          <tokens>
            <token id="12" string="stunning" />
            <token id="13" string="," />
            <token id="14" string="from" />
            <token id="15" string="&quot;" />
            <token id="16" string="The" />
            <token id="17" string="Old" />
            <token id="18" string="Devils" />
            <token id="19" string="&quot;" />
            <token id="20" string="(" />
            <token id="21" string="80,000" />
            <token id="22" string="hard-cover" />
            <token id="23" string="copies" />
            <token id="24" string=")" />
            <token id="25" string="to" />
            <token id="26" string="Anita" />
            <token id="27" string="Brookner" />
            <token id="28" string="'s" />
            <token id="29" string="&quot;" />
            <token id="30" string="Hotel" />
            <token id="31" string="du" />
            <token id="32" string="Lac" />
            <token id="33" string="&quot;" />
            <token id="34" string="(" />
            <token id="35" string="40,000" />
            <token id="36" string="copies" />
            <token id="37" string=")" />
          </tokens>
        </chunking>
        <chunking id="16" string="British standards" type="NP">
          <tokens>
            <token id="2" string="British" />
            <token id="3" string="standards" />
          </tokens>
        </chunking>
        <chunking id="17" string="`` Hotel du Lac '' -LRB- 40,000 copies -RRB-" type="NP">
          <tokens>
            <token id="29" string="&quot;" />
            <token id="30" string="Hotel" />
            <token id="31" string="du" />
            <token id="32" string="Lac" />
            <token id="33" string="&quot;" />
            <token id="34" string="(" />
            <token id="35" string="40,000" />
            <token id="36" string="copies" />
            <token id="37" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">standards</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">standards</governor>
          <dependent id="2">British</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">stunning</governor>
          <dependent id="3">standards</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">figures</governor>
          <dependent id="5">sales</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">stunning</governor>
          <dependent id="6">figures</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">winners</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">winners</governor>
          <dependent id="8">recent</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">winners</governor>
          <dependent id="9">Booker</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">figures</governor>
          <dependent id="10">winners</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">stunning</governor>
          <dependent id="11">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">stunning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Devils</governor>
          <dependent id="14">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Devils</governor>
          <dependent id="16">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Devils</governor>
          <dependent id="17">Old</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">stunning</governor>
          <dependent id="18">Devils</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">Devils</governor>
          <dependent id="21">80,000</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">copies</governor>
          <dependent id="22">hard-cover</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">80,000</governor>
          <dependent id="23">copies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Brookner</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Brookner</governor>
          <dependent id="26">Anita</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">stunning</governor>
          <dependent id="27">Brookner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Brookner</governor>
          <dependent id="28">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Lac</governor>
          <dependent id="30">Hotel</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Lac</governor>
          <dependent id="31">du</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">Brookner</governor>
          <dependent id="32">Lac</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="36">copies</governor>
          <dependent id="35">40,000</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="32">Lac</governor>
          <dependent id="36">copies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="2" string="British" />
          </tokens>
        </entity>
        <entity id="2" string="80,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="80,000" />
          </tokens>
        </entity>
        <entity id="3" string="40,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="35" string="40,000" />
          </tokens>
        </entity>
        <entity id="4" string="Anita Brookner" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Anita" />
            <token id="27" string="Brookner" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Even Keri Hulme&amp;apost;s &amp;quot;The Bone People,&amp;quot; a look at Maori culture that most readers found impenetrable, reached a respectable 21,000 in 1985.</content>
      <tokens>
        <token id="1" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Keri" lemma="Keri" stem="keri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Hulme" lemma="Hulme" stem="hulm" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Bone" lemma="bone" stem="bone" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="look" lemma="look" stem="look" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Maori" lemma="maori" stem="maori" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="15" string="culture" lemma="culture" stem="cultur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="readers" lemma="reader" stem="reader" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="impenetrable" lemma="impenetrable" stem="impenetr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="reached" lemma="reach" stem="reach" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="respectable" lemma="respectable" stem="respect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="21,000" lemma="21,000" stem="21,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Even)) (NP (NP (NP (NNP Keri) (NNP Hulme) (POS 's)) (NP (`` ``) (DT The) (NN Bone) (NNS People))) (, ,) ('' '') (NP (NP (DT a) (NN look)) (PP (IN at) (NP (JJ Maori) (NN culture))) (SBAR (IN that) (S (NP (JJS most) (NNS readers)) (VP (VBD found) (NP (JJ impenetrable)))))) (, ,)) (VP (VBD reached) (NP (DT a) (JJ respectable) (CD 21,000)) (PP (IN in) (NP (CD 1985)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a respectable 21,000" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="respectable" />
            <token id="25" string="21,000" />
          </tokens>
        </chunking>
        <chunking id="2" string="reached a respectable 21,000 in 1985" type="VP">
          <tokens>
            <token id="22" string="reached" />
            <token id="23" string="a" />
            <token id="24" string="respectable" />
            <token id="25" string="21,000" />
            <token id="26" string="in" />
            <token id="27" string="1985" />
          </tokens>
        </chunking>
        <chunking id="3" string="Keri Hulme 's" type="NP">
          <tokens>
            <token id="2" string="Keri" />
            <token id="3" string="Hulme" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="`` The Bone People" type="NP">
          <tokens>
            <token id="5" string="&quot;" />
            <token id="6" string="The" />
            <token id="7" string="Bone" />
            <token id="8" string="People" />
          </tokens>
        </chunking>
        <chunking id="5" string="a look" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="look" />
          </tokens>
        </chunking>
        <chunking id="6" string="Keri Hulme 's `` The Bone People , '' a look at Maori culture that most readers found impenetrable ," type="NP">
          <tokens>
            <token id="2" string="Keri" />
            <token id="3" string="Hulme" />
            <token id="4" string="'s" />
            <token id="5" string="&quot;" />
            <token id="6" string="The" />
            <token id="7" string="Bone" />
            <token id="8" string="People" />
            <token id="9" string="," />
            <token id="10" string="&quot;" />
            <token id="11" string="a" />
            <token id="12" string="look" />
            <token id="13" string="at" />
            <token id="14" string="Maori" />
            <token id="15" string="culture" />
            <token id="16" string="that" />
            <token id="17" string="most" />
            <token id="18" string="readers" />
            <token id="19" string="found" />
            <token id="20" string="impenetrable" />
            <token id="21" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="most readers" type="NP">
          <tokens>
            <token id="17" string="most" />
            <token id="18" string="readers" />
          </tokens>
        </chunking>
        <chunking id="8" string="1985" type="NP">
          <tokens>
            <token id="27" string="1985" />
          </tokens>
        </chunking>
        <chunking id="9" string="Keri Hulme 's `` The Bone People" type="NP">
          <tokens>
            <token id="2" string="Keri" />
            <token id="3" string="Hulme" />
            <token id="4" string="'s" />
            <token id="5" string="&quot;" />
            <token id="6" string="The" />
            <token id="7" string="Bone" />
            <token id="8" string="People" />
          </tokens>
        </chunking>
        <chunking id="10" string="a look at Maori culture that most readers found impenetrable" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="look" />
            <token id="13" string="at" />
            <token id="14" string="Maori" />
            <token id="15" string="culture" />
            <token id="16" string="that" />
            <token id="17" string="most" />
            <token id="18" string="readers" />
            <token id="19" string="found" />
            <token id="20" string="impenetrable" />
          </tokens>
        </chunking>
        <chunking id="11" string="Maori culture" type="NP">
          <tokens>
            <token id="14" string="Maori" />
            <token id="15" string="culture" />
          </tokens>
        </chunking>
        <chunking id="12" string="that most readers found impenetrable" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="most" />
            <token id="18" string="readers" />
            <token id="19" string="found" />
            <token id="20" string="impenetrable" />
          </tokens>
        </chunking>
        <chunking id="13" string="impenetrable" type="NP">
          <tokens>
            <token id="20" string="impenetrable" />
          </tokens>
        </chunking>
        <chunking id="14" string="found impenetrable" type="VP">
          <tokens>
            <token id="19" string="found" />
            <token id="20" string="impenetrable" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="22">reached</governor>
          <dependent id="1">Even</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Hulme</governor>
          <dependent id="2">Keri</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">reached</governor>
          <dependent id="3">Hulme</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Hulme</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">People</governor>
          <dependent id="6">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">People</governor>
          <dependent id="7">Bone</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">Hulme</governor>
          <dependent id="8">People</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">look</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">Hulme</governor>
          <dependent id="12">look</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">culture</governor>
          <dependent id="13">at</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">culture</governor>
          <dependent id="14">Maori</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">look</governor>
          <dependent id="15">culture</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">found</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">readers</governor>
          <dependent id="17">most</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">found</governor>
          <dependent id="18">readers</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">look</governor>
          <dependent id="19">found</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">found</governor>
          <dependent id="20">impenetrable</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">reached</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">21,000</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">21,000</governor>
          <dependent id="24">respectable</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">reached</governor>
          <dependent id="25">21,000</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">1985</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">reached</governor>
          <dependent id="27">1985</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1985" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="1985" />
          </tokens>
        </entity>
        <entity id="2" string="Keri Hulme" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Keri" />
            <token id="3" string="Hulme" />
          </tokens>
        </entity>
        <entity id="3" string="Maori" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Maori" />
          </tokens>
        </entity>
        <entity id="4" string="21,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="25" string="21,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="false">
      <content>Short-listed authors are just a few paces behind, sharing the best-seller list with Dick Francis and Scott Turow.</content>
      <tokens>
        <token id="1" string="Short-listed" lemma="short-listed" stem="short-list" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="authors" lemma="author" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="paces" lemma="pace" stem="pace" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="sharing" lemma="share" stem="share" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="best-seller" lemma="best-seller" stem="best-sel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Dick" lemma="Dick" stem="dick" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Scott" lemma="Scott" stem="scott" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="Turow" lemma="Turow" stem="turow" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Short-listed) (NNS authors)) (VP (VBP are) (ADVP (NP (RB just) (DT a) (JJ few) (NNS paces)) (IN behind)) (, ,) (S (VP (VBG sharing) (NP (DT the) (NN best-seller) (NN list)) (PP (IN with) (NP (NP (NNP Dick) (NNP Francis)) (CC and) (NP (NNP Scott) (NNP Turow))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are just a few paces behind , sharing the best-seller list with Dick Francis and Scott Turow" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="just" />
            <token id="5" string="a" />
            <token id="6" string="few" />
            <token id="7" string="paces" />
            <token id="8" string="behind" />
            <token id="9" string="," />
            <token id="10" string="sharing" />
            <token id="11" string="the" />
            <token id="12" string="best-seller" />
            <token id="13" string="list" />
            <token id="14" string="with" />
            <token id="15" string="Dick" />
            <token id="16" string="Francis" />
            <token id="17" string="and" />
            <token id="18" string="Scott" />
            <token id="19" string="Turow" />
          </tokens>
        </chunking>
        <chunking id="2" string="sharing the best-seller list with Dick Francis and Scott Turow" type="VP">
          <tokens>
            <token id="10" string="sharing" />
            <token id="11" string="the" />
            <token id="12" string="best-seller" />
            <token id="13" string="list" />
            <token id="14" string="with" />
            <token id="15" string="Dick" />
            <token id="16" string="Francis" />
            <token id="17" string="and" />
            <token id="18" string="Scott" />
            <token id="19" string="Turow" />
          </tokens>
        </chunking>
        <chunking id="3" string="Scott Turow" type="NP">
          <tokens>
            <token id="18" string="Scott" />
            <token id="19" string="Turow" />
          </tokens>
        </chunking>
        <chunking id="4" string="the best-seller list" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="best-seller" />
            <token id="13" string="list" />
          </tokens>
        </chunking>
        <chunking id="5" string="Dick Francis and Scott Turow" type="NP">
          <tokens>
            <token id="15" string="Dick" />
            <token id="16" string="Francis" />
            <token id="17" string="and" />
            <token id="18" string="Scott" />
            <token id="19" string="Turow" />
          </tokens>
        </chunking>
        <chunking id="6" string="Short-listed authors" type="NP">
          <tokens>
            <token id="1" string="Short-listed" />
            <token id="2" string="authors" />
          </tokens>
        </chunking>
        <chunking id="7" string="Dick Francis" type="NP">
          <tokens>
            <token id="15" string="Dick" />
            <token id="16" string="Francis" />
          </tokens>
        </chunking>
        <chunking id="8" string="just a few paces" type="NP">
          <tokens>
            <token id="4" string="just" />
            <token id="5" string="a" />
            <token id="6" string="few" />
            <token id="7" string="paces" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">authors</governor>
          <dependent id="1">Short-listed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">are</governor>
          <dependent id="2">authors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">paces</governor>
          <dependent id="4">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">paces</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">paces</governor>
          <dependent id="6">few</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">are</governor>
          <dependent id="7">paces</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">paces</governor>
          <dependent id="8">behind</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">are</governor>
          <dependent id="10">sharing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">list</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">list</governor>
          <dependent id="12">best-seller</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">sharing</governor>
          <dependent id="13">list</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Francis</governor>
          <dependent id="14">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Francis</governor>
          <dependent id="15">Dick</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">sharing</governor>
          <dependent id="16">Francis</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">Francis</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Turow</governor>
          <dependent id="18">Scott</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">Francis</governor>
          <dependent id="19">Turow</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Scott Turow" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Scott" />
            <token id="19" string="Turow" />
          </tokens>
        </entity>
        <entity id="2" string="Dick Francis" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Dick" />
            <token id="16" string="Francis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Heinemann initially printed 3,000 copies of &amp;quot;Anthills of the Savannah,&amp;quot; the usual run for contemporary literary fiction.</content>
      <tokens>
        <token id="1" string="Heinemann" lemma="Heinemann" stem="heinemann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="initially" lemma="initially" stem="initi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="printed" lemma="print" stem="print" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="3,000" lemma="3,000" stem="3,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="copies" lemma="copy" stem="copi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Anthills" lemma="anthill" stem="anthill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Savannah" lemma="Savannah" stem="savannah" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="usual" lemma="usual" stem="usual" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="run" lemma="run" stem="run" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="contemporary" lemma="contemporary" stem="contemporari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Heinemann)) (ADVP (RB initially)) (VP (VBD printed) (NP (NP (CD 3,000) (NNS copies)) (PP (IN of) (NP (`` ``) (VP (NP (NNS Anthills)) (PP (IN of) (NP (DT the) (NNP Savannah)))) (, ,) ('' '') (NP (DT the) (ADJP (JJ usual)) (NN run))))) (PP (IN for) (NP (JJ contemporary) (JJ literary) (NN fiction)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="3,000 copies of `` Anthills of the Savannah , '' the usual run" type="NP">
          <tokens>
            <token id="4" string="3,000" />
            <token id="5" string="copies" />
            <token id="6" string="of" />
            <token id="7" string="&quot;" />
            <token id="8" string="Anthills" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="Savannah" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="the" />
            <token id="15" string="usual" />
            <token id="16" string="run" />
          </tokens>
        </chunking>
        <chunking id="2" string="contemporary literary fiction" type="NP">
          <tokens>
            <token id="18" string="contemporary" />
            <token id="19" string="literary" />
            <token id="20" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="3" string="`` Anthills of the Savannah , '' the usual run" type="NP">
          <tokens>
            <token id="7" string="&quot;" />
            <token id="8" string="Anthills" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="Savannah" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="the" />
            <token id="15" string="usual" />
            <token id="16" string="run" />
          </tokens>
        </chunking>
        <chunking id="4" string="3,000 copies" type="NP">
          <tokens>
            <token id="4" string="3,000" />
            <token id="5" string="copies" />
          </tokens>
        </chunking>
        <chunking id="5" string="usual" type="ADJP">
          <tokens>
            <token id="15" string="usual" />
          </tokens>
        </chunking>
        <chunking id="6" string="printed 3,000 copies of `` Anthills of the Savannah , '' the usual run for contemporary literary fiction" type="VP">
          <tokens>
            <token id="3" string="printed" />
            <token id="4" string="3,000" />
            <token id="5" string="copies" />
            <token id="6" string="of" />
            <token id="7" string="&quot;" />
            <token id="8" string="Anthills" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="Savannah" />
            <token id="12" string="," />
            <token id="13" string="&quot;" />
            <token id="14" string="the" />
            <token id="15" string="usual" />
            <token id="16" string="run" />
            <token id="17" string="for" />
            <token id="18" string="contemporary" />
            <token id="19" string="literary" />
            <token id="20" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="7" string="Anthills" type="NP">
          <tokens>
            <token id="8" string="Anthills" />
          </tokens>
        </chunking>
        <chunking id="8" string="Heinemann" type="NP">
          <tokens>
            <token id="1" string="Heinemann" />
          </tokens>
        </chunking>
        <chunking id="9" string="Anthills of the Savannah" type="VP">
          <tokens>
            <token id="8" string="Anthills" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Savannah" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Savannah" />
          </tokens>
        </chunking>
        <chunking id="11" string="the usual run" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="usual" />
            <token id="16" string="run" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">printed</governor>
          <dependent id="1">Heinemann</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">printed</governor>
          <dependent id="2">initially</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">printed</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">copies</governor>
          <dependent id="4">3,000</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">printed</governor>
          <dependent id="5">copies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">run</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">run</governor>
          <dependent id="8">Anthills</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Savannah</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Savannah</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Anthills</governor>
          <dependent id="11">Savannah</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">run</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">run</governor>
          <dependent id="15">usual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">copies</governor>
          <dependent id="16">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">fiction</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">fiction</governor>
          <dependent id="18">contemporary</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">fiction</governor>
          <dependent id="19">literary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">printed</governor>
          <dependent id="20">fiction</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="3,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="3,000" />
          </tokens>
        </entity>
        <entity id="2" string="Savannah" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="Savannah" />
          </tokens>
        </entity>
        <entity id="3" string="Heinemann" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Heinemann" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="false">
      <content>So far, 10,000 copies have sold.</content>
      <tokens>
        <token id="1" string="So" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="10,000" lemma="10,000" stem="10,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="copies" lemma="copy" stem="copi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="sold" lemma="sell" stem="sold" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB So) (RB far)) (, ,) (NP (CD 10,000) (NNS copies)) (VP (VBP have) (VP (VBN sold))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="10,000 copies" type="NP">
          <tokens>
            <token id="4" string="10,000" />
            <token id="5" string="copies" />
          </tokens>
        </chunking>
        <chunking id="2" string="sold" type="VP">
          <tokens>
            <token id="7" string="sold" />
          </tokens>
        </chunking>
        <chunking id="3" string="have sold" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="sold" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">far</governor>
          <dependent id="1">So</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">sold</governor>
          <dependent id="2">far</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">copies</governor>
          <dependent id="4">10,000</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">sold</governor>
          <dependent id="5">copies</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">sold</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">sold</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="10,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="10,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>&amp;quot;Being short-listed probably changed the destiny of that book,&amp;quot; declares a member of the Heinemann sales staff.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="short-listed" lemma="short-listed" stem="short-list" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="changed" lemma="change" stem="chang" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="destiny" lemma="destiny" stem="destini" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="declares" lemma="declare" stem="declar" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="member" lemma="member" stem="member" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Heinemann" lemma="Heinemann" stem="heinemann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="sales" lemma="sale" stem="sale" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="staff" lemma="staff" stem="staff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (VP (VBG Being) (ADJP (JJ short-listed)))) (VP (ADVP (RB probably)) (VBD changed) (NP (NP (DT the) (NN destiny)) (PP (IN of) (NP (DT that) (NN book)))))) (, ,) ('' '') (VP (VBZ declares)) (NP (NP (DT a) (NN member)) (PP (IN of) (NP (DT the) (NNP Heinemann) (NNS sales) (NN staff)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="declares" type="VP">
          <tokens>
            <token id="13" string="declares" />
          </tokens>
        </chunking>
        <chunking id="2" string="a member" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="member" />
          </tokens>
        </chunking>
        <chunking id="3" string="Being short-listed" type="VP">
          <tokens>
            <token id="2" string="Being" />
            <token id="3" string="short-listed" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Heinemann sales staff" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="Heinemann" />
            <token id="19" string="sales" />
            <token id="20" string="staff" />
          </tokens>
        </chunking>
        <chunking id="5" string="probably changed the destiny of that book" type="VP">
          <tokens>
            <token id="4" string="probably" />
            <token id="5" string="changed" />
            <token id="6" string="the" />
            <token id="7" string="destiny" />
            <token id="8" string="of" />
            <token id="9" string="that" />
            <token id="10" string="book" />
          </tokens>
        </chunking>
        <chunking id="6" string="the destiny of that book" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="destiny" />
            <token id="8" string="of" />
            <token id="9" string="that" />
            <token id="10" string="book" />
          </tokens>
        </chunking>
        <chunking id="7" string="short-listed" type="ADJP">
          <tokens>
            <token id="3" string="short-listed" />
          </tokens>
        </chunking>
        <chunking id="8" string="the destiny" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="destiny" />
          </tokens>
        </chunking>
        <chunking id="9" string="that book" type="NP">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="book" />
          </tokens>
        </chunking>
        <chunking id="10" string="a member of the Heinemann sales staff" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="member" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="Heinemann" />
            <token id="19" string="sales" />
            <token id="20" string="staff" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cop">
          <governor id="3">short-listed</governor>
          <dependent id="2">Being</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="5">changed</governor>
          <dependent id="3">short-listed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">changed</governor>
          <dependent id="4">probably</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">declares</governor>
          <dependent id="5">changed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">destiny</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">changed</governor>
          <dependent id="7">destiny</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">book</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">book</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">destiny</governor>
          <dependent id="10">book</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">declares</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">member</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">declares</governor>
          <dependent id="15">member</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">staff</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">staff</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">staff</governor>
          <dependent id="18">Heinemann</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">staff</governor>
          <dependent id="19">sales</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">member</governor>
          <dependent id="20">staff</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Heinemann" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Heinemann" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>Indeed, there&amp;apost;s currently talk of initiating a similar prize with a similar purse for the year&amp;apost;s best biography.</content>
      <tokens>
        <token id="1" string="Indeed" lemma="indeed" stem="indeed" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="currently" lemma="currently" stem="current" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="talk" lemma="talk" stem="talk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="initiating" lemma="initiate" stem="initi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="purse" lemma="purse" stem="purs" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="18" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="biography" lemma="biography" stem="biographi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Indeed)) (, ,) (NP (EX there)) (VP (VBZ 's) (ADVP (RB currently)) (NP (NP (NN talk)) (PP (IN of) (S (VP (VBG initiating) (NP (DT a) (JJ similar) (NN prize)) (PP (IN with) (NP (NP (DT a) (JJ similar) (NN purse)) (PP (IN for) (NP (NP (DT the) (NN year) (POS 's)) (JJS best) (NN biography)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="3" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="a similar purse" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="similar" />
            <token id="15" string="purse" />
          </tokens>
        </chunking>
        <chunking id="3" string="talk of initiating a similar prize with a similar purse for the year 's best biography" type="NP">
          <tokens>
            <token id="6" string="talk" />
            <token id="7" string="of" />
            <token id="8" string="initiating" />
            <token id="9" string="a" />
            <token id="10" string="similar" />
            <token id="11" string="prize" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string="similar" />
            <token id="15" string="purse" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="year" />
            <token id="19" string="'s" />
            <token id="20" string="best" />
            <token id="21" string="biography" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s currently talk of initiating a similar prize with a similar purse for the year 's best biography" type="VP">
          <tokens>
            <token id="4" string="'s" />
            <token id="5" string="currently" />
            <token id="6" string="talk" />
            <token id="7" string="of" />
            <token id="8" string="initiating" />
            <token id="9" string="a" />
            <token id="10" string="similar" />
            <token id="11" string="prize" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string="similar" />
            <token id="15" string="purse" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="year" />
            <token id="19" string="'s" />
            <token id="20" string="best" />
            <token id="21" string="biography" />
          </tokens>
        </chunking>
        <chunking id="5" string="a similar purse for the year 's best biography" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="similar" />
            <token id="15" string="purse" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="year" />
            <token id="19" string="'s" />
            <token id="20" string="best" />
            <token id="21" string="biography" />
          </tokens>
        </chunking>
        <chunking id="6" string="a similar prize" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="similar" />
            <token id="11" string="prize" />
          </tokens>
        </chunking>
        <chunking id="7" string="the year 's" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="year" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="talk" type="NP">
          <tokens>
            <token id="6" string="talk" />
          </tokens>
        </chunking>
        <chunking id="9" string="the year 's best biography" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="year" />
            <token id="19" string="'s" />
            <token id="20" string="best" />
            <token id="21" string="biography" />
          </tokens>
        </chunking>
        <chunking id="10" string="initiating a similar prize with a similar purse for the year 's best biography" type="VP">
          <tokens>
            <token id="8" string="initiating" />
            <token id="9" string="a" />
            <token id="10" string="similar" />
            <token id="11" string="prize" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string="similar" />
            <token id="15" string="purse" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="year" />
            <token id="19" string="'s" />
            <token id="20" string="best" />
            <token id="21" string="biography" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">'s</governor>
          <dependent id="1">Indeed</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="4">'s</governor>
          <dependent id="3">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">'s</governor>
          <dependent id="5">currently</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">'s</governor>
          <dependent id="6">talk</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">initiating</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">talk</governor>
          <dependent id="8">initiating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">prize</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">prize</governor>
          <dependent id="10">similar</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">initiating</governor>
          <dependent id="11">prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">purse</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">purse</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">purse</governor>
          <dependent id="14">similar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">initiating</governor>
          <dependent id="15">purse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">biography</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">year</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">biography</governor>
          <dependent id="18">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">year</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">biography</governor>
          <dependent id="20">best</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">purse</governor>
          <dependent id="21">biography</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="currently" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="currently" />
          </tokens>
        </entity>
        <entity id="2" string="the year" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Another notable spinoff is the Booker harpies, readers intent on digesting all six titles, then vigorously disputing the choices, which never please everyone.</content>
      <tokens>
        <token id="1" string="Another" lemma="another" stem="another" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="notable" lemma="notable" stem="notabl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="spinoff" lemma="spinoff" stem="spinoff" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="harpies" lemma="harpy" stem="harpi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="readers" lemma="reader" stem="reader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="intent" lemma="intent" stem="intent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="digesting" lemma="digest" stem="digest" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="titles" lemma="title" stem="titl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="vigorously" lemma="vigorously" stem="vigor" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="disputing" lemma="dispute" stem="disput" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="choices" lemma="choice" stem="choic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="please" lemma="please" stem="pleas" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Another) (JJ notable) (NN spinoff)) (VP (VBZ is) (NP (NP (DT the) (NNP Booker) (NNS harpies)) (, ,) (NP (NP (NNS readers) (NN intent)) (PP (IN on) (S (VP (VBG digesting) (NP (DT all) (CD six) (NNS titles)))) (, ,) (RB then) (S (VP (ADVP (RB vigorously)) (VBG disputing) (NP (DT the) (NNS choices))))) (, ,) (SBAR (WHNP (WDT which)) (S (ADVP (RB never)) (VP (VB please) (NP (NN everyone)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="please everyone" type="VP">
          <tokens>
            <token id="25" string="please" />
            <token id="26" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="2" string="everyone" type="NP">
          <tokens>
            <token id="26" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="3" string="is the Booker harpies , readers intent on digesting all six titles , then vigorously disputing the choices , which never please everyone" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="the" />
            <token id="6" string="Booker" />
            <token id="7" string="harpies" />
            <token id="8" string="," />
            <token id="9" string="readers" />
            <token id="10" string="intent" />
            <token id="11" string="on" />
            <token id="12" string="digesting" />
            <token id="13" string="all" />
            <token id="14" string="six" />
            <token id="15" string="titles" />
            <token id="16" string="," />
            <token id="17" string="then" />
            <token id="18" string="vigorously" />
            <token id="19" string="disputing" />
            <token id="20" string="the" />
            <token id="21" string="choices" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="never" />
            <token id="25" string="please" />
            <token id="26" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="4" string="readers intent" type="NP">
          <tokens>
            <token id="9" string="readers" />
            <token id="10" string="intent" />
          </tokens>
        </chunking>
        <chunking id="5" string="digesting all six titles" type="VP">
          <tokens>
            <token id="12" string="digesting" />
            <token id="13" string="all" />
            <token id="14" string="six" />
            <token id="15" string="titles" />
          </tokens>
        </chunking>
        <chunking id="6" string="vigorously disputing the choices" type="VP">
          <tokens>
            <token id="18" string="vigorously" />
            <token id="19" string="disputing" />
            <token id="20" string="the" />
            <token id="21" string="choices" />
          </tokens>
        </chunking>
        <chunking id="7" string="which never please everyone" type="SBAR">
          <tokens>
            <token id="23" string="which" />
            <token id="24" string="never" />
            <token id="25" string="please" />
            <token id="26" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="8" string="the choices" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="choices" />
          </tokens>
        </chunking>
        <chunking id="9" string="readers intent on digesting all six titles , then vigorously disputing the choices , which never please everyone" type="NP">
          <tokens>
            <token id="9" string="readers" />
            <token id="10" string="intent" />
            <token id="11" string="on" />
            <token id="12" string="digesting" />
            <token id="13" string="all" />
            <token id="14" string="six" />
            <token id="15" string="titles" />
            <token id="16" string="," />
            <token id="17" string="then" />
            <token id="18" string="vigorously" />
            <token id="19" string="disputing" />
            <token id="20" string="the" />
            <token id="21" string="choices" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="never" />
            <token id="25" string="please" />
            <token id="26" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="10" string="Another notable spinoff" type="NP">
          <tokens>
            <token id="1" string="Another" />
            <token id="2" string="notable" />
            <token id="3" string="spinoff" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Booker harpies , readers intent on digesting all six titles , then vigorously disputing the choices , which never please everyone" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Booker" />
            <token id="7" string="harpies" />
            <token id="8" string="," />
            <token id="9" string="readers" />
            <token id="10" string="intent" />
            <token id="11" string="on" />
            <token id="12" string="digesting" />
            <token id="13" string="all" />
            <token id="14" string="six" />
            <token id="15" string="titles" />
            <token id="16" string="," />
            <token id="17" string="then" />
            <token id="18" string="vigorously" />
            <token id="19" string="disputing" />
            <token id="20" string="the" />
            <token id="21" string="choices" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="never" />
            <token id="25" string="please" />
            <token id="26" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Booker harpies" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Booker" />
            <token id="7" string="harpies" />
          </tokens>
        </chunking>
        <chunking id="13" string="all six titles" type="NP">
          <tokens>
            <token id="13" string="all" />
            <token id="14" string="six" />
            <token id="15" string="titles" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">spinoff</governor>
          <dependent id="1">Another</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">spinoff</governor>
          <dependent id="2">notable</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">harpies</governor>
          <dependent id="3">spinoff</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">harpies</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">harpies</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">harpies</governor>
          <dependent id="6">Booker</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">harpies</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">intent</governor>
          <dependent id="9">readers</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">harpies</governor>
          <dependent id="10">intent</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">digesting</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">intent</governor>
          <dependent id="12">digesting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">titles</governor>
          <dependent id="13">all</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">titles</governor>
          <dependent id="14">six</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">digesting</governor>
          <dependent id="15">titles</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">disputing</governor>
          <dependent id="17">then</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">disputing</governor>
          <dependent id="18">vigorously</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">digesting</governor>
          <dependent id="19">disputing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">choices</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">disputing</governor>
          <dependent id="21">choices</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">please</governor>
          <dependent id="23">which</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="25">please</governor>
          <dependent id="24">never</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">intent</governor>
          <dependent id="25">please</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">please</governor>
          <dependent id="26">everyone</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="six" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>This year the Sunday Times offered readers a complete autographed collection of the six books for the equivalent of $112, perfect fodder for the literary cocktail party cot.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="5" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="offered" lemma="offer" stem="offer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="readers" lemma="reader" stem="reader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="complete" lemma="complete" stem="complet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="autographed" lemma="autographed" stem="autograph" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="collection" lemma="collection" stem="collect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="equivalent" lemma="equivalent" stem="equival" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="21" string="112" lemma="112" stem="112" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="perfect" lemma="perfect" stem="perfect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="fodder" lemma="fodder" stem="fodder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="cocktail" lemma="cocktail" stem="cocktail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="cot" lemma="cot" stem="cot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (DT This) (NN year)) (NP (DT the) (NNP Sunday) (NNP Times)) (VP (VBD offered) (NP (NNS readers)) (NP (NP (DT a) (JJ complete) (JJ autographed) (NN collection)) (PP (IN of) (NP (DT the) (CD six) (NNS books)))) (PP (IN for) (NP (NP (DT the) (NN equivalent)) (PP (IN of) (NP ($ $) (CD 112))))) (, ,) (NP (NP (JJ perfect) (NN fodder)) (PP (IN for) (NP (DT the) (JJ literary) (NN cocktail) (NN party) (NN cot))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the six books" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="six" />
            <token id="15" string="books" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Sunday Times" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Sunday" />
            <token id="5" string="Times" />
          </tokens>
        </chunking>
        <chunking id="3" string="offered readers a complete autographed collection of the six books for the equivalent of $ 112 , perfect fodder for the literary cocktail party cot" type="VP">
          <tokens>
            <token id="6" string="offered" />
            <token id="7" string="readers" />
            <token id="8" string="a" />
            <token id="9" string="complete" />
            <token id="10" string="autographed" />
            <token id="11" string="collection" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="six" />
            <token id="15" string="books" />
            <token id="16" string="for" />
            <token id="17" string="the" />
            <token id="18" string="equivalent" />
            <token id="19" string="of" />
            <token id="20" string="$" />
            <token id="21" string="112" />
            <token id="22" string="," />
            <token id="23" string="perfect" />
            <token id="24" string="fodder" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="literary" />
            <token id="28" string="cocktail" />
            <token id="29" string="party" />
            <token id="30" string="cot" />
          </tokens>
        </chunking>
        <chunking id="4" string="a complete autographed collection" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="complete" />
            <token id="10" string="autographed" />
            <token id="11" string="collection" />
          </tokens>
        </chunking>
        <chunking id="5" string="perfect fodder for the literary cocktail party cot" type="NP">
          <tokens>
            <token id="23" string="perfect" />
            <token id="24" string="fodder" />
            <token id="25" string="for" />
            <token id="26" string="the" />
            <token id="27" string="literary" />
            <token id="28" string="cocktail" />
            <token id="29" string="party" />
            <token id="30" string="cot" />
          </tokens>
        </chunking>
        <chunking id="6" string="perfect fodder" type="NP">
          <tokens>
            <token id="23" string="perfect" />
            <token id="24" string="fodder" />
          </tokens>
        </chunking>
        <chunking id="7" string="the equivalent of $ 112" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="equivalent" />
            <token id="19" string="of" />
            <token id="20" string="$" />
            <token id="21" string="112" />
          </tokens>
        </chunking>
        <chunking id="8" string="the literary cocktail party cot" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="literary" />
            <token id="28" string="cocktail" />
            <token id="29" string="party" />
            <token id="30" string="cot" />
          </tokens>
        </chunking>
        <chunking id="9" string="readers" type="NP">
          <tokens>
            <token id="7" string="readers" />
          </tokens>
        </chunking>
        <chunking id="10" string="the equivalent" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="equivalent" />
          </tokens>
        </chunking>
        <chunking id="11" string="a complete autographed collection of the six books" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="complete" />
            <token id="10" string="autographed" />
            <token id="11" string="collection" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="six" />
            <token id="15" string="books" />
          </tokens>
        </chunking>
        <chunking id="12" string="$ 112" type="NP">
          <tokens>
            <token id="20" string="$" />
            <token id="21" string="112" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">year</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="6">offered</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Times</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Times</governor>
          <dependent id="4">Sunday</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">offered</governor>
          <dependent id="5">Times</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">offered</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="6">offered</governor>
          <dependent id="7">readers</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">collection</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">collection</governor>
          <dependent id="9">complete</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">collection</governor>
          <dependent id="10">autographed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">offered</governor>
          <dependent id="11">collection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">books</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">books</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">books</governor>
          <dependent id="14">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">collection</governor>
          <dependent id="15">books</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">equivalent</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">equivalent</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">offered</governor>
          <dependent id="18">equivalent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">112</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">112</governor>
          <dependent id="20">$</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">equivalent</governor>
          <dependent id="21">112</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">fodder</governor>
          <dependent id="23">perfect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">offered</governor>
          <dependent id="24">fodder</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">cot</governor>
          <dependent id="25">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">cot</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">cot</governor>
          <dependent id="27">literary</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">cot</governor>
          <dependent id="28">cocktail</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">cot</governor>
          <dependent id="29">party</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">fodder</governor>
          <dependent id="30">cot</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="This year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="year" />
          </tokens>
        </entity>
        <entity id="3" string="Sunday Times" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Sunday" />
            <token id="5" string="Times" />
          </tokens>
        </entity>
        <entity id="4" string="$ 112" type="MONEY" score="0.0">
          <tokens>
            <token id="20" string="$" />
            <token id="21" string="112" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>It wasn&amp;apost;t always this way, of course.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (RB n't) (ADVP (RB always)) (NP (NP (DT this) (NN way)) (, ,) (PP (IN of) (NP (NN course))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="course" type="NP">
          <tokens>
            <token id="9" string="course" />
          </tokens>
        </chunking>
        <chunking id="2" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="3" string="was n't always this way , of course" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="n't" />
            <token id="4" string="always" />
            <token id="5" string="this" />
            <token id="6" string="way" />
            <token id="7" string="," />
            <token id="8" string="of" />
            <token id="9" string="course" />
          </tokens>
        </chunking>
        <chunking id="4" string="this way , of course" type="NP">
          <tokens>
            <token id="5" string="this" />
            <token id="6" string="way" />
            <token id="7" string="," />
            <token id="8" string="of" />
            <token id="9" string="course" />
          </tokens>
        </chunking>
        <chunking id="5" string="this way" type="NP">
          <tokens>
            <token id="5" string="this" />
            <token id="6" string="way" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">way</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">way</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">way</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">way</governor>
          <dependent id="4">always</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">way</governor>
          <dependent id="5">this</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">way</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">course</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">way</governor>
          <dependent id="9">course</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>Headlines were modest back in 1969 when P.H. Newby won the first ever Booker Prize for &amp;quot;Something to Answer For.&amp;quot;</content>
      <tokens>
        <token id="1" string="Headlines" lemma="headline" stem="headlin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="modest" lemma="modest" stem="modest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="1969" lemma="1969" stem="1969" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="P.H." lemma="P.H." stem="p.h." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="Newby" lemma="Newby" stem="newbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="13" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="15" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Answer" lemma="answer" stem="answer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Headlines)) (VP (VBD were) (ADJP (JJ modest)) (ADVP (RB back) (PP (IN in) (NP (CD 1969)))) (SBAR (WHADVP (WRB when)) (S (NP (NNP P.H.) (NNP Newby)) (VP (VBD won) (NP (DT the) (JJ first))))) (PRN (ADVP (ADVP (RB ever) (NP (NP (NNP Booker) (NNP Prize)) (PP (IN for) (`` ``) (NP (NN Something))))) (PP (TO to) (NP (NN Answer)))) (PP (IN For)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Booker Prize for `` Something" type="NP">
          <tokens>
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
            <token id="16" string="for" />
            <token id="17" string="&quot;" />
            <token id="18" string="Something" />
          </tokens>
        </chunking>
        <chunking id="2" string="Headlines" type="NP">
          <tokens>
            <token id="1" string="Headlines" />
          </tokens>
        </chunking>
        <chunking id="3" string="modest" type="ADJP">
          <tokens>
            <token id="3" string="modest" />
          </tokens>
        </chunking>
        <chunking id="4" string="when P.H. Newby won the first" type="SBAR">
          <tokens>
            <token id="7" string="when" />
            <token id="8" string="P.H." />
            <token id="9" string="Newby" />
            <token id="10" string="won" />
            <token id="11" string="the" />
            <token id="12" string="first" />
          </tokens>
        </chunking>
        <chunking id="5" string="were modest back in 1969 when P.H. Newby won the first ever Booker Prize for `` Something to Answer For" type="VP">
          <tokens>
            <token id="2" string="were" />
            <token id="3" string="modest" />
            <token id="4" string="back" />
            <token id="5" string="in" />
            <token id="6" string="1969" />
            <token id="7" string="when" />
            <token id="8" string="P.H." />
            <token id="9" string="Newby" />
            <token id="10" string="won" />
            <token id="11" string="the" />
            <token id="12" string="first" />
            <token id="13" string="ever" />
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
            <token id="16" string="for" />
            <token id="17" string="&quot;" />
            <token id="18" string="Something" />
            <token id="19" string="to" />
            <token id="20" string="Answer" />
            <token id="21" string="For" />
          </tokens>
        </chunking>
        <chunking id="6" string="won the first" type="VP">
          <tokens>
            <token id="10" string="won" />
            <token id="11" string="the" />
            <token id="12" string="first" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="7" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="P.H. Newby" type="NP">
          <tokens>
            <token id="8" string="P.H." />
            <token id="9" string="Newby" />
          </tokens>
        </chunking>
        <chunking id="9" string="Answer" type="NP">
          <tokens>
            <token id="20" string="Answer" />
          </tokens>
        </chunking>
        <chunking id="10" string="Booker Prize" type="NP">
          <tokens>
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="11" string="the first" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="first" />
          </tokens>
        </chunking>
        <chunking id="12" string="1969" type="NP">
          <tokens>
            <token id="6" string="1969" />
          </tokens>
        </chunking>
        <chunking id="13" string="Something" type="NP">
          <tokens>
            <token id="18" string="Something" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">modest</governor>
          <dependent id="1">Headlines</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">modest</governor>
          <dependent id="2">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">modest</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">modest</governor>
          <dependent id="4">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">1969</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">back</governor>
          <dependent id="6">1969</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">won</governor>
          <dependent id="7">when</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Newby</governor>
          <dependent id="8">P.H.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">won</governor>
          <dependent id="9">Newby</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">modest</governor>
          <dependent id="10">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">first</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">won</governor>
          <dependent id="12">first</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">For</governor>
          <dependent id="13">ever</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Prize</governor>
          <dependent id="14">Booker</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="13">ever</governor>
          <dependent id="15">Prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Something</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">Prize</governor>
          <dependent id="18">Something</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Answer</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">ever</governor>
          <dependent id="20">Answer</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">modest</governor>
          <dependent id="21">For</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="12" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="P.H. Newby" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="P.H." />
            <token id="9" string="Newby" />
          </tokens>
        </entity>
        <entity id="3" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
          </tokens>
        </entity>
        <entity id="4" string="1969" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="1969" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="false">
      <content>(The wonderfully appropriate name comes from Booker-McConnell PLC, the international food and agriculture conglomerate that puts up the prize money each year.)</content>
      <tokens>
        <token id="1" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="wonderfully" lemma="wonderfully" stem="wonderfulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="appropriate" lemma="appropriate" stem="appropri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="name" lemma="name" stem="name" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Booker-McConnell" lemma="Booker-McConnell" stem="booker-mcconnel" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="PLC" lemma="PLC" stem="plc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="international" lemma="international" stem="intern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="food" lemma="food" stem="food" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="agriculture" lemma="agriculture" stem="agricultur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="conglomerate" lemma="conglomerate" stem="conglomer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="puts" lemma="put" stem="put" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="money" lemma="money" stem="monei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" ner="SET" is_referenced="false" is_refers="false" />
        <token id="24" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (-LRB- -LRB-) (NP (DT The) (ADJP (RB wonderfully) (JJ appropriate)) (NN name)) (VP (VBZ comes) (PP (IN from) (NP (NP (NNP Booker-McConnell) (NNP PLC)) (, ,) (NP (NP (DT the) (JJ international) (NN food) (CC and) (NN agriculture) (NN conglomerate)) (SBAR (WHNP (WDT that)) (S (VP (VBZ puts) (PRT (RP up)) (NP (DT the) (NN prize) (NN money)) (NP-TMP (DT each) (NN year))))))))) (. .) (-RRB- -RRB-)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Booker-McConnell PLC" type="NP">
          <tokens>
            <token id="8" string="Booker-McConnell" />
            <token id="9" string="PLC" />
          </tokens>
        </chunking>
        <chunking id="2" string="The wonderfully appropriate name" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="wonderfully" />
            <token id="4" string="appropriate" />
            <token id="5" string="name" />
          </tokens>
        </chunking>
        <chunking id="3" string="comes from Booker-McConnell PLC , the international food and agriculture conglomerate that puts up the prize money each year" type="VP">
          <tokens>
            <token id="6" string="comes" />
            <token id="7" string="from" />
            <token id="8" string="Booker-McConnell" />
            <token id="9" string="PLC" />
            <token id="10" string="," />
            <token id="11" string="the" />
            <token id="12" string="international" />
            <token id="13" string="food" />
            <token id="14" string="and" />
            <token id="15" string="agriculture" />
            <token id="16" string="conglomerate" />
            <token id="17" string="that" />
            <token id="18" string="puts" />
            <token id="19" string="up" />
            <token id="20" string="the" />
            <token id="21" string="prize" />
            <token id="22" string="money" />
            <token id="23" string="each" />
            <token id="24" string="year" />
          </tokens>
        </chunking>
        <chunking id="4" string="wonderfully appropriate" type="ADJP">
          <tokens>
            <token id="3" string="wonderfully" />
            <token id="4" string="appropriate" />
          </tokens>
        </chunking>
        <chunking id="5" string="the international food and agriculture conglomerate" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="international" />
            <token id="13" string="food" />
            <token id="14" string="and" />
            <token id="15" string="agriculture" />
            <token id="16" string="conglomerate" />
          </tokens>
        </chunking>
        <chunking id="6" string="Booker-McConnell PLC , the international food and agriculture conglomerate that puts up the prize money each year" type="NP">
          <tokens>
            <token id="8" string="Booker-McConnell" />
            <token id="9" string="PLC" />
            <token id="10" string="," />
            <token id="11" string="the" />
            <token id="12" string="international" />
            <token id="13" string="food" />
            <token id="14" string="and" />
            <token id="15" string="agriculture" />
            <token id="16" string="conglomerate" />
            <token id="17" string="that" />
            <token id="18" string="puts" />
            <token id="19" string="up" />
            <token id="20" string="the" />
            <token id="21" string="prize" />
            <token id="22" string="money" />
            <token id="23" string="each" />
            <token id="24" string="year" />
          </tokens>
        </chunking>
        <chunking id="7" string="puts up the prize money each year" type="VP">
          <tokens>
            <token id="18" string="puts" />
            <token id="19" string="up" />
            <token id="20" string="the" />
            <token id="21" string="prize" />
            <token id="22" string="money" />
            <token id="23" string="each" />
            <token id="24" string="year" />
          </tokens>
        </chunking>
        <chunking id="8" string="the prize money" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="prize" />
            <token id="22" string="money" />
          </tokens>
        </chunking>
        <chunking id="9" string="the international food and agriculture conglomerate that puts up the prize money each year" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="international" />
            <token id="13" string="food" />
            <token id="14" string="and" />
            <token id="15" string="agriculture" />
            <token id="16" string="conglomerate" />
            <token id="17" string="that" />
            <token id="18" string="puts" />
            <token id="19" string="up" />
            <token id="20" string="the" />
            <token id="21" string="prize" />
            <token id="22" string="money" />
            <token id="23" string="each" />
            <token id="24" string="year" />
          </tokens>
        </chunking>
        <chunking id="10" string="that puts up the prize money each year" type="SBAR">
          <tokens>
            <token id="17" string="that" />
            <token id="18" string="puts" />
            <token id="19" string="up" />
            <token id="20" string="the" />
            <token id="21" string="prize" />
            <token id="22" string="money" />
            <token id="23" string="each" />
            <token id="24" string="year" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">name</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">appropriate</governor>
          <dependent id="3">wonderfully</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">name</governor>
          <dependent id="4">appropriate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">comes</governor>
          <dependent id="5">name</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">comes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">PLC</governor>
          <dependent id="7">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">PLC</governor>
          <dependent id="8">Booker-McConnell</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">comes</governor>
          <dependent id="9">PLC</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">food</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">food</governor>
          <dependent id="12">international</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">PLC</governor>
          <dependent id="13">food</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">food</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">conglomerate</governor>
          <dependent id="15">agriculture</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">food</governor>
          <dependent id="16">conglomerate</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">puts</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">food</governor>
          <dependent id="18">puts</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="18">puts</governor>
          <dependent id="19">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">money</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">money</governor>
          <dependent id="21">prize</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">puts</governor>
          <dependent id="22">money</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">year</governor>
          <dependent id="23">each</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="18">puts</governor>
          <dependent id="24">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Booker-McConnell PLC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Booker-McConnell" />
            <token id="9" string="PLC" />
          </tokens>
        </entity>
        <entity id="2" string="each year" type="SET" score="0.0">
          <tokens>
            <token id="23" string="each" />
            <token id="24" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>The idea was to devise a British equivalent to the Prix Goncourt, and like that august French award, the Booker attracted attention the minute it kicked up controversy.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="idea" lemma="idea" stem="idea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="devise" lemma="devise" stem="devis" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="British" lemma="british" stem="british" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="8" string="equivalent" lemma="equivalent" stem="equival" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="Prix" lemma="Prix" stem="prix" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="Goncourt" lemma="Goncourt" stem="goncourt" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="august" lemma="august" stem="august" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="French" lemma="French" stem="french" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="19" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="attracted" lemma="attract" stem="attract" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="minute" lemma="minute" stem="minut" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="kicked" lemma="kick" stem="kick" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN idea)) (VP (VBD was) (S (VP (TO to) (VP (VB devise) (NP (DT a) (JJ British) (NN equivalent)) (PP (TO to) (NP (DT the) (NNP Prix) (NNP Goncourt)))))))) (, ,) (CC and) (S (PP (IN like) (NP (DT that) (NNP august) (NNP French) (NN award))) (, ,) (NP (DT the) (NNP Booker)) (VP (VBD attracted) (NP (NP (NP (NN attention)) (NP (DT the) (NN minute))) (SBAR (S (NP (PRP it)) (VP (VBD kicked) (PRT (RP up)) (NP (NN controversy)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was to devise a British equivalent to the Prix Goncourt" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="to" />
            <token id="5" string="devise" />
            <token id="6" string="a" />
            <token id="7" string="British" />
            <token id="8" string="equivalent" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="Prix" />
            <token id="12" string="Goncourt" />
          </tokens>
        </chunking>
        <chunking id="2" string="attracted attention the minute it kicked up controversy" type="VP">
          <tokens>
            <token id="23" string="attracted" />
            <token id="24" string="attention" />
            <token id="25" string="the" />
            <token id="26" string="minute" />
            <token id="27" string="it" />
            <token id="28" string="kicked" />
            <token id="29" string="up" />
            <token id="30" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="3" string="attention the minute" type="NP">
          <tokens>
            <token id="24" string="attention" />
            <token id="25" string="the" />
            <token id="26" string="minute" />
          </tokens>
        </chunking>
        <chunking id="4" string="a British equivalent" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="British" />
            <token id="8" string="equivalent" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Booker" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="27" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="that august French award" type="NP">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="august" />
            <token id="18" string="French" />
            <token id="19" string="award" />
          </tokens>
        </chunking>
        <chunking id="8" string="attention the minute it kicked up controversy" type="NP">
          <tokens>
            <token id="24" string="attention" />
            <token id="25" string="the" />
            <token id="26" string="minute" />
            <token id="27" string="it" />
            <token id="28" string="kicked" />
            <token id="29" string="up" />
            <token id="30" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="9" string="the minute" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="minute" />
          </tokens>
        </chunking>
        <chunking id="10" string="devise a British equivalent to the Prix Goncourt" type="VP">
          <tokens>
            <token id="5" string="devise" />
            <token id="6" string="a" />
            <token id="7" string="British" />
            <token id="8" string="equivalent" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="Prix" />
            <token id="12" string="Goncourt" />
          </tokens>
        </chunking>
        <chunking id="11" string="controversy" type="NP">
          <tokens>
            <token id="30" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="12" string="it kicked up controversy" type="SBAR">
          <tokens>
            <token id="27" string="it" />
            <token id="28" string="kicked" />
            <token id="29" string="up" />
            <token id="30" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="13" string="kicked up controversy" type="VP">
          <tokens>
            <token id="28" string="kicked" />
            <token id="29" string="up" />
            <token id="30" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="14" string="to devise a British equivalent to the Prix Goncourt" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="devise" />
            <token id="6" string="a" />
            <token id="7" string="British" />
            <token id="8" string="equivalent" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="Prix" />
            <token id="12" string="Goncourt" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Prix Goncourt" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="Prix" />
            <token id="12" string="Goncourt" />
          </tokens>
        </chunking>
        <chunking id="16" string="attention" type="NP">
          <tokens>
            <token id="24" string="attention" />
          </tokens>
        </chunking>
        <chunking id="17" string="The idea" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="idea" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">idea</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">was</governor>
          <dependent id="2">idea</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">devise</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">was</governor>
          <dependent id="5">devise</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">equivalent</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">equivalent</governor>
          <dependent id="7">British</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">devise</governor>
          <dependent id="8">equivalent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Goncourt</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Goncourt</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Goncourt</governor>
          <dependent id="11">Prix</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">devise</governor>
          <dependent id="12">Goncourt</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">was</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">award</governor>
          <dependent id="15">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">award</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">award</governor>
          <dependent id="17">august</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">award</governor>
          <dependent id="18">French</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">attracted</governor>
          <dependent id="19">award</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Booker</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">attracted</governor>
          <dependent id="22">Booker</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">was</governor>
          <dependent id="23">attracted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">attracted</governor>
          <dependent id="24">attention</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">minute</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">attention</governor>
          <dependent id="26">minute</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">kicked</governor>
          <dependent id="27">it</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">attention</governor>
          <dependent id="28">kicked</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="28">kicked</governor>
          <dependent id="29">up</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">kicked</governor>
          <dependent id="30">controversy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="French" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="18" string="French" />
          </tokens>
        </entity>
        <entity id="2" string="British" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="7" string="British" />
          </tokens>
        </entity>
        <entity id="3" string="august" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="august" />
          </tokens>
        </entity>
        <entity id="4" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Booker" />
          </tokens>
        </entity>
        <entity id="5" string="the minute" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="minute" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>The early fuss was kept within the literary world, with critics sniping over choices and the prize&amp;apost;s varied ground rules.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="early" lemma="early" stem="earli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="fuss" lemma="fuss" stem="fuss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="kept" lemma="keep" stem="kept" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="within" lemma="within" stem="within" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="sniping" lemma="snipe" stem="snipe" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="choices" lemma="choice" stem="choic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="varied" lemma="varied" stem="vari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="ground" lemma="ground" stem="ground" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="rules" lemma="rule" stem="rule" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ early) (NN fuss)) (VP (VBD was) (VP (VBN kept) (PP (IN within) (NP (DT the) (JJ literary) (NN world))) (, ,) (PP (IN with) (NP (NP (NNS critics)) (VP (VBG sniping) (PP (IN over) (NP (NP (NNS choices)) (CC and) (NP (NP (DT the) (NN prize) (POS 's)) (JJ varied) (NN ground) (NNS rules))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the prize 's varied ground rules" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="prize" />
            <token id="19" string="'s" />
            <token id="20" string="varied" />
            <token id="21" string="ground" />
            <token id="22" string="rules" />
          </tokens>
        </chunking>
        <chunking id="2" string="the literary world" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="literary" />
            <token id="9" string="world" />
          </tokens>
        </chunking>
        <chunking id="3" string="critics" type="NP">
          <tokens>
            <token id="12" string="critics" />
          </tokens>
        </chunking>
        <chunking id="4" string="choices and the prize 's varied ground rules" type="NP">
          <tokens>
            <token id="15" string="choices" />
            <token id="16" string="and" />
            <token id="17" string="the" />
            <token id="18" string="prize" />
            <token id="19" string="'s" />
            <token id="20" string="varied" />
            <token id="21" string="ground" />
            <token id="22" string="rules" />
          </tokens>
        </chunking>
        <chunking id="5" string="The early fuss" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="early" />
            <token id="3" string="fuss" />
          </tokens>
        </chunking>
        <chunking id="6" string="the prize 's" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="prize" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="was kept within the literary world , with critics sniping over choices and the prize 's varied ground rules" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="kept" />
            <token id="6" string="within" />
            <token id="7" string="the" />
            <token id="8" string="literary" />
            <token id="9" string="world" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="critics" />
            <token id="13" string="sniping" />
            <token id="14" string="over" />
            <token id="15" string="choices" />
            <token id="16" string="and" />
            <token id="17" string="the" />
            <token id="18" string="prize" />
            <token id="19" string="'s" />
            <token id="20" string="varied" />
            <token id="21" string="ground" />
            <token id="22" string="rules" />
          </tokens>
        </chunking>
        <chunking id="8" string="sniping over choices and the prize 's varied ground rules" type="VP">
          <tokens>
            <token id="13" string="sniping" />
            <token id="14" string="over" />
            <token id="15" string="choices" />
            <token id="16" string="and" />
            <token id="17" string="the" />
            <token id="18" string="prize" />
            <token id="19" string="'s" />
            <token id="20" string="varied" />
            <token id="21" string="ground" />
            <token id="22" string="rules" />
          </tokens>
        </chunking>
        <chunking id="9" string="kept within the literary world , with critics sniping over choices and the prize 's varied ground rules" type="VP">
          <tokens>
            <token id="5" string="kept" />
            <token id="6" string="within" />
            <token id="7" string="the" />
            <token id="8" string="literary" />
            <token id="9" string="world" />
            <token id="10" string="," />
            <token id="11" string="with" />
            <token id="12" string="critics" />
            <token id="13" string="sniping" />
            <token id="14" string="over" />
            <token id="15" string="choices" />
            <token id="16" string="and" />
            <token id="17" string="the" />
            <token id="18" string="prize" />
            <token id="19" string="'s" />
            <token id="20" string="varied" />
            <token id="21" string="ground" />
            <token id="22" string="rules" />
          </tokens>
        </chunking>
        <chunking id="10" string="critics sniping over choices and the prize 's varied ground rules" type="NP">
          <tokens>
            <token id="12" string="critics" />
            <token id="13" string="sniping" />
            <token id="14" string="over" />
            <token id="15" string="choices" />
            <token id="16" string="and" />
            <token id="17" string="the" />
            <token id="18" string="prize" />
            <token id="19" string="'s" />
            <token id="20" string="varied" />
            <token id="21" string="ground" />
            <token id="22" string="rules" />
          </tokens>
        </chunking>
        <chunking id="11" string="choices" type="NP">
          <tokens>
            <token id="15" string="choices" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">fuss</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">fuss</governor>
          <dependent id="2">early</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">kept</governor>
          <dependent id="3">fuss</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">kept</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">kept</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">world</governor>
          <dependent id="6">within</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">world</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">world</governor>
          <dependent id="8">literary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">kept</governor>
          <dependent id="9">world</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">critics</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">kept</governor>
          <dependent id="12">critics</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="12">critics</governor>
          <dependent id="13">sniping</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">choices</governor>
          <dependent id="14">over</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">sniping</governor>
          <dependent id="15">choices</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">choices</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">prize</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">rules</governor>
          <dependent id="18">prize</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">prize</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">rules</governor>
          <dependent id="20">varied</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">rules</governor>
          <dependent id="21">ground</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">choices</governor>
          <dependent id="22">rules</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>The real world took notice in 1974, when Elizabeth Jane Howard, one of the three judges, wrote a letter to the Times claiming that in her opinion Kingsley Amis&amp;apost;s &amp;quot;Ending Up,&amp;quot; one of the short-listed books, was his best ever.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="notice" lemma="notice" stem="notic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="1974" lemma="1974" stem="1974" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Elizabeth" lemma="Elizabeth" stem="elizabeth" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Jane" lemma="Jane" stem="jane" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Howard" lemma="Howard" stem="howard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="26" string="claiming" lemma="claim" stem="claim" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="Kingsley" lemma="Kingsley" stem="kingslei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="Amis" lemma="Amis" stem="ami" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="33" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Ending" lemma="end" stem="ending" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="Up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="40" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="42" string="short-listed" lemma="short-listed" stem="short-list" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="47" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (JJ real) (NN world)) (VP (VBD took) (NP (NN notice)) (PP (IN in) (NP (CD 1974))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (NNP Elizabeth) (NNP Jane) (NNP Howard)) (, ,) (NP (NP (CD one)) (PP (IN of) (NP (DT the) (CD three) (NNS judges)))) (, ,)) (VP (VBD wrote) (NP (NP (DT a) (NN letter)) (PP (TO to) (NP (DT the) (NNP Times)))) (S (VP (VBG claiming) (ADVP (IN that)))) (PP (IN in) (NP (NP (PRP$ her) (NN opinion)) (NP (NNP Kingsley) (NNP Amis) (POS 's)))) (`` ``) (S (VP (VBG Ending) (PRT (RP Up))))))))) (, ,) ('' '') (NP (NP (CD one)) (PP (IN of) (NP (DT the) (JJ short-listed) (NNS books)))) (, ,) (VP (VBD was) (NP (PRP$ his) (JJS best)) (ADVP (RB ever))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one of the three judges" type="NP">
          <tokens>
            <token id="14" string="one" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="three" />
            <token id="18" string="judges" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="14" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="the short-listed books" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="short-listed" />
            <token id="43" string="books" />
          </tokens>
        </chunking>
        <chunking id="4" string="her opinion Kingsley Amis 's" type="NP">
          <tokens>
            <token id="29" string="her" />
            <token id="30" string="opinion" />
            <token id="31" string="Kingsley" />
            <token id="32" string="Amis" />
            <token id="33" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="his best" type="NP">
          <tokens>
            <token id="46" string="his" />
            <token id="47" string="best" />
          </tokens>
        </chunking>
        <chunking id="6" string="when Elizabeth Jane Howard , one of the three judges , wrote a letter to the Times claiming that in her opinion Kingsley Amis 's `` Ending Up" type="SBAR">
          <tokens>
            <token id="9" string="when" />
            <token id="10" string="Elizabeth" />
            <token id="11" string="Jane" />
            <token id="12" string="Howard" />
            <token id="13" string="," />
            <token id="14" string="one" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="three" />
            <token id="18" string="judges" />
            <token id="19" string="," />
            <token id="20" string="wrote" />
            <token id="21" string="a" />
            <token id="22" string="letter" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="Times" />
            <token id="26" string="claiming" />
            <token id="27" string="that" />
            <token id="28" string="in" />
            <token id="29" string="her" />
            <token id="30" string="opinion" />
            <token id="31" string="Kingsley" />
            <token id="32" string="Amis" />
            <token id="33" string="'s" />
            <token id="34" string="&quot;" />
            <token id="35" string="Ending" />
            <token id="36" string="Up" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Times" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Times" />
          </tokens>
        </chunking>
        <chunking id="8" string="wrote a letter to the Times claiming that in her opinion Kingsley Amis 's `` Ending Up" type="VP">
          <tokens>
            <token id="20" string="wrote" />
            <token id="21" string="a" />
            <token id="22" string="letter" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="Times" />
            <token id="26" string="claiming" />
            <token id="27" string="that" />
            <token id="28" string="in" />
            <token id="29" string="her" />
            <token id="30" string="opinion" />
            <token id="31" string="Kingsley" />
            <token id="32" string="Amis" />
            <token id="33" string="'s" />
            <token id="34" string="&quot;" />
            <token id="35" string="Ending" />
            <token id="36" string="Up" />
          </tokens>
        </chunking>
        <chunking id="9" string="Kingsley Amis 's" type="NP">
          <tokens>
            <token id="31" string="Kingsley" />
            <token id="32" string="Amis" />
            <token id="33" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="claiming that" type="VP">
          <tokens>
            <token id="26" string="claiming" />
            <token id="27" string="that" />
          </tokens>
        </chunking>
        <chunking id="11" string="took notice in 1974 , when Elizabeth Jane Howard , one of the three judges , wrote a letter to the Times claiming that in her opinion Kingsley Amis 's `` Ending Up" type="VP">
          <tokens>
            <token id="4" string="took" />
            <token id="5" string="notice" />
            <token id="6" string="in" />
            <token id="7" string="1974" />
            <token id="8" string="," />
            <token id="9" string="when" />
            <token id="10" string="Elizabeth" />
            <token id="11" string="Jane" />
            <token id="12" string="Howard" />
            <token id="13" string="," />
            <token id="14" string="one" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="three" />
            <token id="18" string="judges" />
            <token id="19" string="," />
            <token id="20" string="wrote" />
            <token id="21" string="a" />
            <token id="22" string="letter" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="Times" />
            <token id="26" string="claiming" />
            <token id="27" string="that" />
            <token id="28" string="in" />
            <token id="29" string="her" />
            <token id="30" string="opinion" />
            <token id="31" string="Kingsley" />
            <token id="32" string="Amis" />
            <token id="33" string="'s" />
            <token id="34" string="&quot;" />
            <token id="35" string="Ending" />
            <token id="36" string="Up" />
          </tokens>
        </chunking>
        <chunking id="12" string="The real world" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="real" />
            <token id="3" string="world" />
          </tokens>
        </chunking>
        <chunking id="13" string="when" type="WHADVP">
          <tokens>
            <token id="9" string="when" />
          </tokens>
        </chunking>
        <chunking id="14" string="a letter" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="letter" />
          </tokens>
        </chunking>
        <chunking id="15" string="notice" type="NP">
          <tokens>
            <token id="5" string="notice" />
          </tokens>
        </chunking>
        <chunking id="16" string="Elizabeth Jane Howard , one of the three judges ," type="NP">
          <tokens>
            <token id="10" string="Elizabeth" />
            <token id="11" string="Jane" />
            <token id="12" string="Howard" />
            <token id="13" string="," />
            <token id="14" string="one" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="three" />
            <token id="18" string="judges" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="1974" type="NP">
          <tokens>
            <token id="7" string="1974" />
          </tokens>
        </chunking>
        <chunking id="18" string="the three judges" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="three" />
            <token id="18" string="judges" />
          </tokens>
        </chunking>
        <chunking id="19" string="one of the short-listed books" type="NP">
          <tokens>
            <token id="39" string="one" />
            <token id="40" string="of" />
            <token id="41" string="the" />
            <token id="42" string="short-listed" />
            <token id="43" string="books" />
          </tokens>
        </chunking>
        <chunking id="20" string="was his best ever" type="VP">
          <tokens>
            <token id="45" string="was" />
            <token id="46" string="his" />
            <token id="47" string="best" />
            <token id="48" string="ever" />
          </tokens>
        </chunking>
        <chunking id="21" string="Elizabeth Jane Howard" type="NP">
          <tokens>
            <token id="10" string="Elizabeth" />
            <token id="11" string="Jane" />
            <token id="12" string="Howard" />
          </tokens>
        </chunking>
        <chunking id="22" string="a letter to the Times" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="letter" />
            <token id="23" string="to" />
            <token id="24" string="the" />
            <token id="25" string="Times" />
          </tokens>
        </chunking>
        <chunking id="23" string="her opinion" type="NP">
          <tokens>
            <token id="29" string="her" />
            <token id="30" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="24" string="Ending Up" type="VP">
          <tokens>
            <token id="35" string="Ending" />
            <token id="36" string="Up" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">world</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">world</governor>
          <dependent id="2">real</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">took</governor>
          <dependent id="3">world</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="47">best</governor>
          <dependent id="4">took</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">took</governor>
          <dependent id="5">notice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">1974</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">took</governor>
          <dependent id="7">1974</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">wrote</governor>
          <dependent id="9">when</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Howard</governor>
          <dependent id="10">Elizabeth</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Howard</governor>
          <dependent id="11">Jane</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">wrote</governor>
          <dependent id="12">Howard</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Howard</governor>
          <dependent id="14">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">judges</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">judges</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">judges</governor>
          <dependent id="17">three</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">one</governor>
          <dependent id="18">judges</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">took</governor>
          <dependent id="20">wrote</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">letter</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">wrote</governor>
          <dependent id="22">letter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Times</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Times</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">letter</governor>
          <dependent id="25">Times</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">wrote</governor>
          <dependent id="26">claiming</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">claiming</governor>
          <dependent id="27">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">opinion</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">opinion</governor>
          <dependent id="29">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">wrote</governor>
          <dependent id="30">opinion</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Amis</governor>
          <dependent id="31">Kingsley</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">opinion</governor>
          <dependent id="32">Amis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Amis</governor>
          <dependent id="33">'s</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">wrote</governor>
          <dependent id="35">Ending</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="35">Ending</governor>
          <dependent id="36">Up</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="47">best</governor>
          <dependent id="39">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">books</governor>
          <dependent id="40">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">books</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">books</governor>
          <dependent id="42">short-listed</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">one</governor>
          <dependent id="43">books</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="47">best</governor>
          <dependent id="45">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="47">best</governor>
          <dependent id="46">his</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="47">best</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="47">best</governor>
          <dependent id="48">ever</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1974" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="1974" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Times" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="25" string="Times" />
          </tokens>
        </entity>
        <entity id="4" string="Elizabeth Jane Howard" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Elizabeth" />
            <token id="11" string="Jane" />
            <token id="12" string="Howard" />
          </tokens>
        </entity>
        <entity id="5" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="three" />
          </tokens>
        </entity>
        <entity id="6" string="Kingsley Amis" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Kingsley" />
            <token id="32" string="Amis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>As it happens, she was married to Mr. Amis at the time.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="happens" lemma="happen" stem="happen" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="married" lemma="marry" stem="marri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Amis" lemma="Amis" stem="ami" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN As) (S (NP (PRP it)) (VP (VBZ happens)))) (, ,) (NP (PRP she)) (VP (VBD was) (VP (VBN married) (PP (TO to) (NP (NP (NNP Mr.) (NNP Amis)) (PP (IN at) (NP (DT the) (NN time))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="As it happens" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="it" />
            <token id="3" string="happens" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mr. Amis at the time" type="NP">
          <tokens>
            <token id="9" string="Mr." />
            <token id="10" string="Amis" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="the time" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="was married to Mr. Amis at the time" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="married" />
            <token id="8" string="to" />
            <token id="9" string="Mr." />
            <token id="10" string="Amis" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="time" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="happens" type="VP">
          <tokens>
            <token id="3" string="happens" />
          </tokens>
        </chunking>
        <chunking id="7" string="married to Mr. Amis at the time" type="VP">
          <tokens>
            <token id="7" string="married" />
            <token id="8" string="to" />
            <token id="9" string="Mr." />
            <token id="10" string="Amis" />
            <token id="11" string="at" />
            <token id="12" string="the" />
            <token id="13" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mr. Amis" type="NP">
          <tokens>
            <token id="9" string="Mr." />
            <token id="10" string="Amis" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">happens</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">happens</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">married</governor>
          <dependent id="3">happens</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">married</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">married</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">married</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Amis</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Amis</governor>
          <dependent id="9">Mr.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">married</governor>
          <dependent id="10">Amis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">time</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">time</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">Amis</governor>
          <dependent id="13">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Amis" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Amis" />
          </tokens>
        </entity>
        <entity id="2" string="time" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="time" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>He didn&amp;apost;t win.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="win" lemma="win" stem="win" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD did) (RB n't) (VP (VB win))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="did n't win" type="VP">
          <tokens>
            <token id="2" string="did" />
            <token id="3" string="n't" />
            <token id="4" string="win" />
          </tokens>
        </chunking>
        <chunking id="2" string="win" type="VP">
          <tokens>
            <token id="4" string="win" />
          </tokens>
        </chunking>
        <chunking id="3" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">win</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">win</governor>
          <dependent id="2">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">win</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">win</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>But many credit the Booker&amp;apost;s current appeal to the 1982 competition and Thomas Keneally&amp;apost;s &amp;quot;Schindler&amp;apost;s Ark,&amp;quot; or &amp;quot;Schindler&amp;apost;s List&amp;quot; as it is known in the U.S. Written as a novel, the book told the true story of a remarkable German who saved the lives of hundreds of Jews in concentration camps.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="credit" lemma="credit" stem="credit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="appeal" lemma="appeal" stem="appeal" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="1982" lemma="1982" stem="1982" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="12" string="competition" lemma="competition" stem="competit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Keneally" lemma="Keneally" stem="keneal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Schindler" lemma="Schindler" stem="schindler" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Ark" lemma="Ark" stem="ark" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Schindler" lemma="Schindler" stem="schindler" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="List" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="36" string="Written" lemma="write" stem="written" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="novel" lemma="novel" stem="novel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="remarkable" lemma="remarkable" stem="remark" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="German" lemma="German" stem="german" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="51" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="saved" lemma="save" stem="save" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="hundreds" lemma="hundred" stem="hundr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="Jews" lemma="Jews" stem="jew" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="59" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="concentration" lemma="concentration" stem="concentr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="camps" lemma="camp" stem="camp" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="62" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (X (CC But) (NP (JJ many) (NN credit)) (NP (NP (NP (NP (DT the) (NNP Booker) (POS 's)) (JJ current) (NN appeal)) (PP (TO to) (NP (DT the) (CD 1982) (NN competition)))) (CC and) (NP (NP (NP (NNP Thomas) (NNP Keneally) (POS 's)) (`` ``) (NX (NP (NNP Schindler) (POS 's)) (NNP Ark)) (, ,) ('' '')) (CC or) (NP (`` ``) (NP (NNP Schindler) (POS 's)) (NN List) ('' '')))) (SBAR (IN as) (S (S (NP (PRP it)) (VP (VBZ is) (VP (VBN known) (PP (IN in) (NP (NP (DT the) (NNP U.S.)) (VP (VBN Written) (PP (IN as) (NP (DT a) (JJ novel))))))))) (, ,) (S (NP (DT the) (NN book)) (VP (VBD told) (NP (NP (DT the) (JJ true) (NN story)) (PP (IN of) (NP (DT a) (JJ remarkable) (NNP German))) (SBAR (WHNP (WP who)) (S (VP (VBD saved) (NP (NP (DT the) (NNS lives)) (PP (IN of) (NP (NP (NNS hundreds)) (PP (IN of) (NP (NNPS Jews)))))) (PP (IN in) (NP (NN concentration) (NNS camps))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the true story of a remarkable German who saved the lives of hundreds of Jews in concentration camps" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="true" />
            <token id="46" string="story" />
            <token id="47" string="of" />
            <token id="48" string="a" />
            <token id="49" string="remarkable" />
            <token id="50" string="German" />
            <token id="51" string="who" />
            <token id="52" string="saved" />
            <token id="53" string="the" />
            <token id="54" string="lives" />
            <token id="55" string="of" />
            <token id="56" string="hundreds" />
            <token id="57" string="of" />
            <token id="58" string="Jews" />
            <token id="59" string="in" />
            <token id="60" string="concentration" />
            <token id="61" string="camps" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas Keneally 's `` Schindler 's Ark , '' or `` Schindler 's List ''" type="NP">
          <tokens>
            <token id="14" string="Thomas" />
            <token id="15" string="Keneally" />
            <token id="16" string="'s" />
            <token id="17" string="&quot;" />
            <token id="18" string="Schindler" />
            <token id="19" string="'s" />
            <token id="20" string="Ark" />
            <token id="21" string="," />
            <token id="22" string="&quot;" />
            <token id="23" string="or" />
            <token id="24" string="&quot;" />
            <token id="25" string="Schindler" />
            <token id="26" string="'s" />
            <token id="27" string="List" />
            <token id="28" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="3" string="a novel" type="NP">
          <tokens>
            <token id="38" string="a" />
            <token id="39" string="novel" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Booker 's current appeal to the 1982 competition" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Booker" />
            <token id="6" string="'s" />
            <token id="7" string="current" />
            <token id="8" string="appeal" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="1982" />
            <token id="12" string="competition" />
          </tokens>
        </chunking>
        <chunking id="5" string="the lives of hundreds of Jews" type="NP">
          <tokens>
            <token id="53" string="the" />
            <token id="54" string="lives" />
            <token id="55" string="of" />
            <token id="56" string="hundreds" />
            <token id="57" string="of" />
            <token id="58" string="Jews" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="30" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="the book" type="NP">
          <tokens>
            <token id="41" string="the" />
            <token id="42" string="book" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 1982 competition" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="1982" />
            <token id="12" string="competition" />
          </tokens>
        </chunking>
        <chunking id="9" string="many credit" type="NP">
          <tokens>
            <token id="2" string="many" />
            <token id="3" string="credit" />
          </tokens>
        </chunking>
        <chunking id="10" string="Written as a novel" type="VP">
          <tokens>
            <token id="36" string="Written" />
            <token id="37" string="as" />
            <token id="38" string="a" />
            <token id="39" string="novel" />
          </tokens>
        </chunking>
        <chunking id="11" string="concentration camps" type="NP">
          <tokens>
            <token id="60" string="concentration" />
            <token id="61" string="camps" />
          </tokens>
        </chunking>
        <chunking id="12" string="hundreds of Jews" type="NP">
          <tokens>
            <token id="56" string="hundreds" />
            <token id="57" string="of" />
            <token id="58" string="Jews" />
          </tokens>
        </chunking>
        <chunking id="13" string="as it is known in the U.S. Written as a novel , the book told the true story of a remarkable German who saved the lives of hundreds of Jews in concentration camps" type="SBAR">
          <tokens>
            <token id="29" string="as" />
            <token id="30" string="it" />
            <token id="31" string="is" />
            <token id="32" string="known" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="U.S." />
            <token id="36" string="Written" />
            <token id="37" string="as" />
            <token id="38" string="a" />
            <token id="39" string="novel" />
            <token id="40" string="," />
            <token id="41" string="the" />
            <token id="42" string="book" />
            <token id="43" string="told" />
            <token id="44" string="the" />
            <token id="45" string="true" />
            <token id="46" string="story" />
            <token id="47" string="of" />
            <token id="48" string="a" />
            <token id="49" string="remarkable" />
            <token id="50" string="German" />
            <token id="51" string="who" />
            <token id="52" string="saved" />
            <token id="53" string="the" />
            <token id="54" string="lives" />
            <token id="55" string="of" />
            <token id="56" string="hundreds" />
            <token id="57" string="of" />
            <token id="58" string="Jews" />
            <token id="59" string="in" />
            <token id="60" string="concentration" />
            <token id="61" string="camps" />
          </tokens>
        </chunking>
        <chunking id="14" string="told the true story of a remarkable German who saved the lives of hundreds of Jews in concentration camps" type="VP">
          <tokens>
            <token id="43" string="told" />
            <token id="44" string="the" />
            <token id="45" string="true" />
            <token id="46" string="story" />
            <token id="47" string="of" />
            <token id="48" string="a" />
            <token id="49" string="remarkable" />
            <token id="50" string="German" />
            <token id="51" string="who" />
            <token id="52" string="saved" />
            <token id="53" string="the" />
            <token id="54" string="lives" />
            <token id="55" string="of" />
            <token id="56" string="hundreds" />
            <token id="57" string="of" />
            <token id="58" string="Jews" />
            <token id="59" string="in" />
            <token id="60" string="concentration" />
            <token id="61" string="camps" />
          </tokens>
        </chunking>
        <chunking id="15" string="who saved the lives of hundreds of Jews in concentration camps" type="SBAR">
          <tokens>
            <token id="51" string="who" />
            <token id="52" string="saved" />
            <token id="53" string="the" />
            <token id="54" string="lives" />
            <token id="55" string="of" />
            <token id="56" string="hundreds" />
            <token id="57" string="of" />
            <token id="58" string="Jews" />
            <token id="59" string="in" />
            <token id="60" string="concentration" />
            <token id="61" string="camps" />
          </tokens>
        </chunking>
        <chunking id="16" string="the U.S. Written as a novel" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="U.S." />
            <token id="36" string="Written" />
            <token id="37" string="as" />
            <token id="38" string="a" />
            <token id="39" string="novel" />
          </tokens>
        </chunking>
        <chunking id="17" string="the Booker 's current appeal to the 1982 competition and Thomas Keneally 's `` Schindler 's Ark , '' or `` Schindler 's List ''" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Booker" />
            <token id="6" string="'s" />
            <token id="7" string="current" />
            <token id="8" string="appeal" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="1982" />
            <token id="12" string="competition" />
            <token id="13" string="and" />
            <token id="14" string="Thomas" />
            <token id="15" string="Keneally" />
            <token id="16" string="'s" />
            <token id="17" string="&quot;" />
            <token id="18" string="Schindler" />
            <token id="19" string="'s" />
            <token id="20" string="Ark" />
            <token id="21" string="," />
            <token id="22" string="&quot;" />
            <token id="23" string="or" />
            <token id="24" string="&quot;" />
            <token id="25" string="Schindler" />
            <token id="26" string="'s" />
            <token id="27" string="List" />
            <token id="28" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="18" string="Thomas Keneally 's `` Schindler 's Ark , ''" type="NP">
          <tokens>
            <token id="14" string="Thomas" />
            <token id="15" string="Keneally" />
            <token id="16" string="'s" />
            <token id="17" string="&quot;" />
            <token id="18" string="Schindler" />
            <token id="19" string="'s" />
            <token id="20" string="Ark" />
            <token id="21" string="," />
            <token id="22" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="19" string="the true story" type="NP">
          <tokens>
            <token id="44" string="the" />
            <token id="45" string="true" />
            <token id="46" string="story" />
          </tokens>
        </chunking>
        <chunking id="20" string="the Booker 's" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Booker" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="21" string="the lives" type="NP">
          <tokens>
            <token id="53" string="the" />
            <token id="54" string="lives" />
          </tokens>
        </chunking>
        <chunking id="22" string="saved the lives of hundreds of Jews in concentration camps" type="VP">
          <tokens>
            <token id="52" string="saved" />
            <token id="53" string="the" />
            <token id="54" string="lives" />
            <token id="55" string="of" />
            <token id="56" string="hundreds" />
            <token id="57" string="of" />
            <token id="58" string="Jews" />
            <token id="59" string="in" />
            <token id="60" string="concentration" />
            <token id="61" string="camps" />
          </tokens>
        </chunking>
        <chunking id="23" string="Thomas Keneally 's" type="NP">
          <tokens>
            <token id="14" string="Thomas" />
            <token id="15" string="Keneally" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="24" string="Schindler 's" type="NP">
          <tokens>
            <token id="18" string="Schindler" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="25" string="known in the U.S. Written as a novel" type="VP">
          <tokens>
            <token id="32" string="known" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="U.S." />
            <token id="36" string="Written" />
            <token id="37" string="as" />
            <token id="38" string="a" />
            <token id="39" string="novel" />
          </tokens>
        </chunking>
        <chunking id="26" string="the Booker 's current appeal" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Booker" />
            <token id="6" string="'s" />
            <token id="7" string="current" />
            <token id="8" string="appeal" />
          </tokens>
        </chunking>
        <chunking id="27" string="is known in the U.S. Written as a novel" type="VP">
          <tokens>
            <token id="31" string="is" />
            <token id="32" string="known" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="U.S." />
            <token id="36" string="Written" />
            <token id="37" string="as" />
            <token id="38" string="a" />
            <token id="39" string="novel" />
          </tokens>
        </chunking>
        <chunking id="28" string="Jews" type="NP">
          <tokens>
            <token id="58" string="Jews" />
          </tokens>
        </chunking>
        <chunking id="29" string="the U.S." type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="U.S." />
          </tokens>
        </chunking>
        <chunking id="30" string="a remarkable German" type="NP">
          <tokens>
            <token id="48" string="a" />
            <token id="49" string="remarkable" />
            <token id="50" string="German" />
          </tokens>
        </chunking>
        <chunking id="31" string="hundreds" type="NP">
          <tokens>
            <token id="56" string="hundreds" />
          </tokens>
        </chunking>
        <chunking id="32" string="`` Schindler 's List ''" type="NP">
          <tokens>
            <token id="24" string="&quot;" />
            <token id="25" string="Schindler" />
            <token id="26" string="'s" />
            <token id="27" string="List" />
            <token id="28" string="&quot;" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">appeal</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">credit</governor>
          <dependent id="2">many</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">appeal</governor>
          <dependent id="3">credit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Booker</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">appeal</governor>
          <dependent id="5">Booker</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Booker</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">appeal</governor>
          <dependent id="7">current</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">appeal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">competition</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">competition</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">competition</governor>
          <dependent id="11">1982</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">appeal</governor>
          <dependent id="12">competition</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">appeal</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Keneally</governor>
          <dependent id="14">Thomas</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">Ark</governor>
          <dependent id="15">Keneally</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Keneally</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">Ark</governor>
          <dependent id="18">Schindler</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Schindler</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">appeal</governor>
          <dependent id="20">Ark</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">Ark</governor>
          <dependent id="23">or</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">List</governor>
          <dependent id="25">Schindler</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Schindler</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">Ark</governor>
          <dependent id="27">List</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">known</governor>
          <dependent id="29">as</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="32">known</governor>
          <dependent id="30">it</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="32">known</governor>
          <dependent id="31">is</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">appeal</governor>
          <dependent id="32">known</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">U.S.</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">U.S.</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">known</governor>
          <dependent id="35">U.S.</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="35">U.S.</governor>
          <dependent id="36">Written</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">novel</governor>
          <dependent id="37">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">novel</governor>
          <dependent id="38">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">Written</governor>
          <dependent id="39">novel</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">book</governor>
          <dependent id="41">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">told</governor>
          <dependent id="42">book</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="32">known</governor>
          <dependent id="43">told</dependent>
        </dependency>
        <dependency type="det">
          <governor id="46">story</governor>
          <dependent id="44">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="46">story</governor>
          <dependent id="45">true</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">told</governor>
          <dependent id="46">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">German</governor>
          <dependent id="47">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="50">German</governor>
          <dependent id="48">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="50">German</governor>
          <dependent id="49">remarkable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">story</governor>
          <dependent id="50">German</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="52">saved</governor>
          <dependent id="51">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="46">story</governor>
          <dependent id="52">saved</dependent>
        </dependency>
        <dependency type="det">
          <governor id="54">lives</governor>
          <dependent id="53">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="52">saved</governor>
          <dependent id="54">lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="56">hundreds</governor>
          <dependent id="55">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="54">lives</governor>
          <dependent id="56">hundreds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="58">Jews</governor>
          <dependent id="57">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="56">hundreds</governor>
          <dependent id="58">Jews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="61">camps</governor>
          <dependent id="59">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="61">camps</governor>
          <dependent id="60">concentration</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="52">saved</governor>
          <dependent id="61">camps</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="current" />
          </tokens>
        </entity>
        <entity id="2" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="35" string="U.S." />
          </tokens>
        </entity>
        <entity id="3" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Booker" />
          </tokens>
        </entity>
        <entity id="4" string="Jews" type="MISC" score="0.0">
          <tokens>
            <token id="58" string="Jews" />
          </tokens>
        </entity>
        <entity id="5" string="1982" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1982" />
          </tokens>
        </entity>
        <entity id="6" string="German" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="50" string="German" />
          </tokens>
        </entity>
        <entity id="7" string="Thomas Keneally" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Thomas" />
            <token id="15" string="Keneally" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>But even after it won the Booker, people argued that it wasn&amp;apost;t a novel.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="argued" lemma="argue" stem="argu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (SBAR (RB even) (IN after) (S (NP (PRP it)) (VP (VBD won) (NP (DT the) (NNP Booker))))) (, ,) (NP (NNS people)) (VP (VBD argued) (SBAR (IN that) (S (NP (PRP it)) (VP (VBD was) (RB n't) (NP (DT a) (NN novel)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="argued that it was n't a novel" type="VP">
          <tokens>
            <token id="10" string="argued" />
            <token id="11" string="that" />
            <token id="12" string="it" />
            <token id="13" string="was" />
            <token id="14" string="n't" />
            <token id="15" string="a" />
            <token id="16" string="novel" />
          </tokens>
        </chunking>
        <chunking id="2" string="a novel" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="novel" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Booker" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="4" string="won the Booker" type="VP">
          <tokens>
            <token id="5" string="won" />
            <token id="6" string="the" />
            <token id="7" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="5" string="that it was n't a novel" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="it" />
            <token id="13" string="was" />
            <token id="14" string="n't" />
            <token id="15" string="a" />
            <token id="16" string="novel" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="people" type="NP">
          <tokens>
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="even after it won the Booker" type="SBAR">
          <tokens>
            <token id="2" string="even" />
            <token id="3" string="after" />
            <token id="4" string="it" />
            <token id="5" string="won" />
            <token id="6" string="the" />
            <token id="7" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="9" string="was n't a novel" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="n't" />
            <token id="15" string="a" />
            <token id="16" string="novel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="10">argued</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">won</governor>
          <dependent id="2">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">won</governor>
          <dependent id="3">after</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">won</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">argued</governor>
          <dependent id="5">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Booker</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">won</governor>
          <dependent id="7">Booker</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">argued</governor>
          <dependent id="9">people</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">argued</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">novel</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">novel</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">novel</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">novel</governor>
          <dependent id="14">n't</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">novel</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">argued</governor>
          <dependent id="16">novel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Booker" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>&amp;quot;The more people questioned it, the more it sold,&amp;quot; says Ion Trewin, editorial director at Hodder &amp;amp;amp; Stoughton.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="questioned" lemma="question" stem="question" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="sold" lemma="sell" stem="sold" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Ion" lemma="Ion" stem="ion" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Trewin" lemma="Trewin" stem="trewin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="editorial" lemma="editorial" stem="editori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Hodder" lemma="Hodder" stem="hodder" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="22" string="&amp;amp;" lemma="&amp;" stem="&amp;amp;" pos="CC" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Stoughton" lemma="Stoughton" stem="stoughton" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT The) (JJR more) (NNS people)) (VP (VBD questioned) (SBAR (S (NP (PRP it)) (, ,) (X (DT the) (RBR more)) (NP (PRP it)) (VP (VBD sold)))))) (, ,) ('' '') (VP (VBZ says)) (NP (NP (NNP Ion) (NNP Trewin)) (, ,) (NP (NP (NN editorial) (NN director)) (PP (IN at) (NP (NNP Hodder) (CC &amp;) (NNP Stoughton))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="editorial director" type="NP">
          <tokens>
            <token id="18" string="editorial" />
            <token id="19" string="director" />
          </tokens>
        </chunking>
        <chunking id="2" string="says" type="VP">
          <tokens>
            <token id="14" string="says" />
          </tokens>
        </chunking>
        <chunking id="3" string="sold" type="VP">
          <tokens>
            <token id="11" string="sold" />
          </tokens>
        </chunking>
        <chunking id="4" string="Hodder &amp; Stoughton" type="NP">
          <tokens>
            <token id="21" string="Hodder" />
            <token id="22" string="&amp;amp;" />
            <token id="23" string="Stoughton" />
          </tokens>
        </chunking>
        <chunking id="5" string="The more people" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="more" />
            <token id="4" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="editorial director at Hodder &amp; Stoughton" type="NP">
          <tokens>
            <token id="18" string="editorial" />
            <token id="19" string="director" />
            <token id="20" string="at" />
            <token id="21" string="Hodder" />
            <token id="22" string="&amp;amp;" />
            <token id="23" string="Stoughton" />
          </tokens>
        </chunking>
        <chunking id="8" string="it , the more it sold" type="SBAR">
          <tokens>
            <token id="6" string="it" />
            <token id="7" string="," />
            <token id="8" string="the" />
            <token id="9" string="more" />
            <token id="10" string="it" />
            <token id="11" string="sold" />
          </tokens>
        </chunking>
        <chunking id="9" string="questioned it , the more it sold" type="VP">
          <tokens>
            <token id="5" string="questioned" />
            <token id="6" string="it" />
            <token id="7" string="," />
            <token id="8" string="the" />
            <token id="9" string="more" />
            <token id="10" string="it" />
            <token id="11" string="sold" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ion Trewin , editorial director at Hodder &amp; Stoughton" type="NP">
          <tokens>
            <token id="15" string="Ion" />
            <token id="16" string="Trewin" />
            <token id="17" string="," />
            <token id="18" string="editorial" />
            <token id="19" string="director" />
            <token id="20" string="at" />
            <token id="21" string="Hodder" />
            <token id="22" string="&amp;amp;" />
            <token id="23" string="Stoughton" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ion Trewin" type="NP">
          <tokens>
            <token id="15" string="Ion" />
            <token id="16" string="Trewin" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">people</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">people</governor>
          <dependent id="3">more</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">questioned</governor>
          <dependent id="4">people</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">says</governor>
          <dependent id="5">questioned</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">sold</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">more</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">sold</governor>
          <dependent id="9">more</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">sold</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">questioned</governor>
          <dependent id="11">sold</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">says</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Trewin</governor>
          <dependent id="15">Ion</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">says</governor>
          <dependent id="16">Trewin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">director</governor>
          <dependent id="18">editorial</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">Trewin</governor>
          <dependent id="19">director</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Hodder</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">director</governor>
          <dependent id="21">Hodder</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">Hodder</governor>
          <dependent id="22">&amp;</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">Hodder</governor>
          <dependent id="23">Stoughton</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hodder &amp;amp; Stoughton" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="Hodder" />
            <token id="22" string="&amp;amp;" />
            <token id="23" string="Stoughton" />
          </tokens>
        </entity>
        <entity id="2" string="Ion Trewin" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Ion" />
            <token id="16" string="Trewin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>&amp;quot;That was the first year the prize caught the media and public imagination.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="5" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="6" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="9" string="caught" lemma="catch" stem="caught" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="imagination" lemma="imagination" stem="imagin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT That)) (VP (VBD was) (NP (NP (DT the) (JJ first) (NN year)) (SBAR (S (NP (DT the) (NN prize)) (VP (VBD caught) (NP (NP (DT the) (NNS media)) (CC and) (NP (JJ public) (NN imagination)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the first year" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="first" />
            <token id="6" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="That" type="NP">
          <tokens>
            <token id="2" string="That" />
          </tokens>
        </chunking>
        <chunking id="3" string="caught the media and public imagination" type="VP">
          <tokens>
            <token id="9" string="caught" />
            <token id="10" string="the" />
            <token id="11" string="media" />
            <token id="12" string="and" />
            <token id="13" string="public" />
            <token id="14" string="imagination" />
          </tokens>
        </chunking>
        <chunking id="4" string="public imagination" type="NP">
          <tokens>
            <token id="13" string="public" />
            <token id="14" string="imagination" />
          </tokens>
        </chunking>
        <chunking id="5" string="the media" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="media" />
          </tokens>
        </chunking>
        <chunking id="6" string="was the first year the prize caught the media and public imagination" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="first" />
            <token id="6" string="year" />
            <token id="7" string="the" />
            <token id="8" string="prize" />
            <token id="9" string="caught" />
            <token id="10" string="the" />
            <token id="11" string="media" />
            <token id="12" string="and" />
            <token id="13" string="public" />
            <token id="14" string="imagination" />
          </tokens>
        </chunking>
        <chunking id="7" string="the first year the prize caught the media and public imagination" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="first" />
            <token id="6" string="year" />
            <token id="7" string="the" />
            <token id="8" string="prize" />
            <token id="9" string="caught" />
            <token id="10" string="the" />
            <token id="11" string="media" />
            <token id="12" string="and" />
            <token id="13" string="public" />
            <token id="14" string="imagination" />
          </tokens>
        </chunking>
        <chunking id="8" string="the prize caught the media and public imagination" type="SBAR">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="prize" />
            <token id="9" string="caught" />
            <token id="10" string="the" />
            <token id="11" string="media" />
            <token id="12" string="and" />
            <token id="13" string="public" />
            <token id="14" string="imagination" />
          </tokens>
        </chunking>
        <chunking id="9" string="the prize" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="prize" />
          </tokens>
        </chunking>
        <chunking id="10" string="the media and public imagination" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="media" />
            <token id="12" string="and" />
            <token id="13" string="public" />
            <token id="14" string="imagination" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">year</governor>
          <dependent id="2">That</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">year</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">year</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">year</governor>
          <dependent id="5">first</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">prize</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">caught</governor>
          <dependent id="8">prize</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">year</governor>
          <dependent id="9">caught</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">media</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">caught</governor>
          <dependent id="11">media</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">media</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">imagination</governor>
          <dependent id="13">public</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">media</governor>
          <dependent id="14">imagination</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the first year" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="first" />
            <token id="6" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="false">
      <content>Suddenly the Booker gained inches on front pages.&amp;quot;</content>
      <tokens>
        <token id="1" string="Suddenly" lemma="suddenly" stem="suddenli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="gained" lemma="gain" stem="gain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="inches" lemma="inch" stem="inch" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="front" lemma="front" stem="front" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Suddenly)) (NP (DT the) (NNP Booker)) (VP (VBD gained) (NP (NNS inches)) (PP (IN on) (NP (JJ front) (NNS pages)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="gained inches on front pages" type="VP">
          <tokens>
            <token id="4" string="gained" />
            <token id="5" string="inches" />
            <token id="6" string="on" />
            <token id="7" string="front" />
            <token id="8" string="pages" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Booker" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="3" string="front pages" type="NP">
          <tokens>
            <token id="7" string="front" />
            <token id="8" string="pages" />
          </tokens>
        </chunking>
        <chunking id="4" string="inches" type="NP">
          <tokens>
            <token id="5" string="inches" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">gained</governor>
          <dependent id="1">Suddenly</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">Booker</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">gained</governor>
          <dependent id="3">Booker</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">gained</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">gained</governor>
          <dependent id="5">inches</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">pages</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">pages</governor>
          <dependent id="7">front</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">gained</governor>
          <dependent id="8">pages</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Booker" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="3" string="Booker" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="false">
      <content>Oh yes, &amp;quot;Moon Tigers&amp;quot; is a dying woman&amp;apost;s recollection of her life as a World War II war correspondent and her affair with a young tank officer.</content>
      <tokens>
        <token id="1" string="Oh" lemma="oh" stem="oh" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="yes" lemma="yes" stem="ye" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Moon" lemma="Moon" stem="moon" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="Tigers" lemma="Tigers" stem="tiger" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="dying" lemma="die" stem="dy" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="woman" lemma="woman" stem="woman" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="recollection" lemma="recollection" stem="recollect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="World" lemma="World" stem="world" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="20" string="War" lemma="War" stem="war" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="II" lemma="II" stem="ii" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="22" string="war" lemma="war" stem="war" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="23" string="correspondent" lemma="correspondent" stem="correspond" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="affair" lemma="affair" stem="affair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="tank" lemma="tank" stem="tank" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (INTJ (UH Oh)) (INTJ (UH yes)) (, ,) (NP (`` ``) (NNP Moon) (NNP Tigers) ('' '')) (VP (VBZ is) (NP (NP (NP (DT a) (VBG dying) (NN woman) (POS 's)) (NN recollection)) (PP (IN of) (NP (NP (NP (PRP$ her) (NN life)) (PP (IN as) (NP (DT a) (NNP World) (NNP War) (NNP II) (NN war) (NN correspondent)))) (CC and) (NP (NP (PRP$ her) (NN affair)) (PP (IN with) (NP (DT a) (JJ young) (NN tank) (NN officer)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is a dying woman 's recollection of her life as a World War II war correspondent and her affair with a young tank officer" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="a" />
            <token id="10" string="dying" />
            <token id="11" string="woman" />
            <token id="12" string="'s" />
            <token id="13" string="recollection" />
            <token id="14" string="of" />
            <token id="15" string="her" />
            <token id="16" string="life" />
            <token id="17" string="as" />
            <token id="18" string="a" />
            <token id="19" string="World" />
            <token id="20" string="War" />
            <token id="21" string="II" />
            <token id="22" string="war" />
            <token id="23" string="correspondent" />
            <token id="24" string="and" />
            <token id="25" string="her" />
            <token id="26" string="affair" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="young" />
            <token id="30" string="tank" />
            <token id="31" string="officer" />
          </tokens>
        </chunking>
        <chunking id="2" string="her life as a World War II war correspondent" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="life" />
            <token id="17" string="as" />
            <token id="18" string="a" />
            <token id="19" string="World" />
            <token id="20" string="War" />
            <token id="21" string="II" />
            <token id="22" string="war" />
            <token id="23" string="correspondent" />
          </tokens>
        </chunking>
        <chunking id="3" string="a dying woman 's" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="dying" />
            <token id="11" string="woman" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="a dying woman 's recollection of her life as a World War II war correspondent and her affair with a young tank officer" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="dying" />
            <token id="11" string="woman" />
            <token id="12" string="'s" />
            <token id="13" string="recollection" />
            <token id="14" string="of" />
            <token id="15" string="her" />
            <token id="16" string="life" />
            <token id="17" string="as" />
            <token id="18" string="a" />
            <token id="19" string="World" />
            <token id="20" string="War" />
            <token id="21" string="II" />
            <token id="22" string="war" />
            <token id="23" string="correspondent" />
            <token id="24" string="and" />
            <token id="25" string="her" />
            <token id="26" string="affair" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="young" />
            <token id="30" string="tank" />
            <token id="31" string="officer" />
          </tokens>
        </chunking>
        <chunking id="5" string="`` Moon Tigers ''" type="NP">
          <tokens>
            <token id="4" string="&quot;" />
            <token id="5" string="Moon" />
            <token id="6" string="Tigers" />
            <token id="7" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="6" string="her affair" type="NP">
          <tokens>
            <token id="25" string="her" />
            <token id="26" string="affair" />
          </tokens>
        </chunking>
        <chunking id="7" string="her life as a World War II war correspondent and her affair with a young tank officer" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="life" />
            <token id="17" string="as" />
            <token id="18" string="a" />
            <token id="19" string="World" />
            <token id="20" string="War" />
            <token id="21" string="II" />
            <token id="22" string="war" />
            <token id="23" string="correspondent" />
            <token id="24" string="and" />
            <token id="25" string="her" />
            <token id="26" string="affair" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="young" />
            <token id="30" string="tank" />
            <token id="31" string="officer" />
          </tokens>
        </chunking>
        <chunking id="8" string="a World War II war correspondent" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="World" />
            <token id="20" string="War" />
            <token id="21" string="II" />
            <token id="22" string="war" />
            <token id="23" string="correspondent" />
          </tokens>
        </chunking>
        <chunking id="9" string="a young tank officer" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="young" />
            <token id="30" string="tank" />
            <token id="31" string="officer" />
          </tokens>
        </chunking>
        <chunking id="10" string="a dying woman 's recollection" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="dying" />
            <token id="11" string="woman" />
            <token id="12" string="'s" />
            <token id="13" string="recollection" />
          </tokens>
        </chunking>
        <chunking id="11" string="her life" type="NP">
          <tokens>
            <token id="15" string="her" />
            <token id="16" string="life" />
          </tokens>
        </chunking>
        <chunking id="12" string="her affair with a young tank officer" type="NP">
          <tokens>
            <token id="25" string="her" />
            <token id="26" string="affair" />
            <token id="27" string="with" />
            <token id="28" string="a" />
            <token id="29" string="young" />
            <token id="30" string="tank" />
            <token id="31" string="officer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="discourse">
          <governor id="13">recollection</governor>
          <dependent id="1">Oh</dependent>
        </dependency>
        <dependency type="discourse">
          <governor id="13">recollection</governor>
          <dependent id="2">yes</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Tigers</governor>
          <dependent id="5">Moon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">recollection</governor>
          <dependent id="6">Tigers</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">recollection</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">woman</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">woman</governor>
          <dependent id="10">dying</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">recollection</governor>
          <dependent id="11">woman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">woman</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">recollection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">life</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">life</governor>
          <dependent id="15">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">recollection</governor>
          <dependent id="16">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">correspondent</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">correspondent</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">correspondent</governor>
          <dependent id="19">World</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">correspondent</governor>
          <dependent id="20">War</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">correspondent</governor>
          <dependent id="21">II</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">correspondent</governor>
          <dependent id="22">war</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">life</governor>
          <dependent id="23">correspondent</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">life</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">affair</governor>
          <dependent id="25">her</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">life</governor>
          <dependent id="26">affair</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">officer</governor>
          <dependent id="27">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">officer</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">officer</governor>
          <dependent id="29">young</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">officer</governor>
          <dependent id="30">tank</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">affair</governor>
          <dependent id="31">officer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="war" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="22" string="war" />
          </tokens>
        </entity>
        <entity id="2" string="World War II" type="MISC" score="0.0">
          <tokens>
            <token id="19" string="World" />
            <token id="20" string="War" />
            <token id="21" string="II" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="false">
      <content>--- Ms. Trucco is a free-lance writer based in London.</content>
      <tokens>
        <token id="1" string="---" lemma="--" stem="---" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Trucco" lemma="Trucco" stem="trucco" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="free-lance" lemma="free-lance" stem="free-lanc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="writer" lemma="writer" stem="writer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="based" lemma="base" stem="base" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="London" lemma="London" stem="london" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: --) (NP (NNP Ms.) (NNP Trucco)) (VP (VBZ is) (NP (NP (DT a) (JJ free-lance) (NN writer)) (PP (VBN based) (PP (IN in) (NP (NNP London)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a free-lance writer" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="free-lance" />
            <token id="7" string="writer" />
          </tokens>
        </chunking>
        <chunking id="2" string="London" type="NP">
          <tokens>
            <token id="10" string="London" />
          </tokens>
        </chunking>
        <chunking id="3" string="Ms. Trucco" type="NP">
          <tokens>
            <token id="2" string="Ms." />
            <token id="3" string="Trucco" />
          </tokens>
        </chunking>
        <chunking id="4" string="a free-lance writer based in London" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="free-lance" />
            <token id="7" string="writer" />
            <token id="8" string="based" />
            <token id="9" string="in" />
            <token id="10" string="London" />
          </tokens>
        </chunking>
        <chunking id="5" string="is a free-lance writer based in London" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="a" />
            <token id="6" string="free-lance" />
            <token id="7" string="writer" />
            <token id="8" string="based" />
            <token id="9" string="in" />
            <token id="10" string="London" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Trucco</governor>
          <dependent id="2">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">writer</governor>
          <dependent id="3">Trucco</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">writer</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">writer</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">writer</governor>
          <dependent id="6">free-lance</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">writer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">London</governor>
          <dependent id="8">based</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">London</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">writer</governor>
          <dependent id="10">London</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Trucco" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Trucco" />
          </tokens>
        </entity>
        <entity id="2" string="London" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="London" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="1-2" string="Brian Moore" id_sentence="2" />
      <mentions>
        <mention ids_tokens="6-8" string="Brian Moore's" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="23-24-25-26-27" string="Chinua Achebe ( 9-2 )" id_sentence="2" />
      <mentions>
        <mention ids_tokens="90-92" string="Chinua Achebe's" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="6-7" string="Nina Bawden" id_sentence="3" />
      <mentions>
        <mention ids_tokens="45-47" string="Nina Bawden's" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="16" string="7-1" id_sentence="3" />
      <mentions>
        <mention ids_tokens="14-16" string="an irresistible flutter" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="12" string="Britain" id_sentence="5" />
      <mentions>
        <mention ids_tokens="23-24" string="Britain's" id_sentence="9" />
        <mention ids_tokens="20-21" string="Britain's" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9" string="new works of fiction" id_sentence="5" />
      <mentions>
        <mention ids_tokens="3-4" string="the works" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="26-27" string="Booker Prize" id_sentence="6" />
      <mentions>
        <mention ids_tokens="5-6" string="her prize" id_sentence="12" />
        <mention ids_tokens="30-37" string="the 15,000-pound ( $ 26,000 ) Booker Prize" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="21" string="those" id_sentence="6" />
      <mentions>
        <mention ids_tokens="3-7" string="those who are in the" id_sentence="14" />
        <mention ids_tokens="1" string="Her" id_sentence="15" />
        <mention ids_tokens="6-10" string="those who made a killing" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="72-73" string="The Book" id_sentence="23" />
      <mentions>
        <mention ids_tokens="7-11" string="book reviews to author interviews" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="11-12" string="Graham Sharpe" id_sentence="9" />
      <mentions>
        <mention ids_tokens="22" string="he" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="4-5" string="the Booker" id_sentence="18" />
      <mentions>
        <mention ids_tokens="17" string="Booker" id_sentence="9" />
        <mention ids_tokens="4-6" string="the Booker's" id_sentence="45" />
        <mention ids_tokens="7" string="Booker" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="1-2" string="The betting" id_sentence="9" />
      <mentions>
        <mention ids_tokens="2" string="They" id_sentence="10" />
        <mention ids_tokens="19" string="themselves" id_sentence="10" />
        <mention ids_tokens="7" string="the" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="12-13" string="Kingsley Amis" id_sentence="11" />
      <mentions>
        <mention ids_tokens="31-33" string="Kingsley Amis's" id_sentence="42" />
        <mention ids_tokens="46" string="his" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Last year 's" id_sentence="11" />
      <mentions>
        <mention ids_tokens="1-2" string="This year" id_sentence="20" />
        <mention ids_tokens="1-2" string="This year" id_sentence="23" />
        <mention ids_tokens="17-19" string="the year's" id_sentence="34" />
        <mention ids_tokens="1-2" string="This year" id_sentence="36" />
        <mention ids_tokens="1" string="It" id_sentence="37" />
        <mention ids_tokens="5-9" string="this way , of course" id_sentence="37" />
        <mention ids_tokens="5-6" string="this way" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="a betting woman" id_sentence="13" />
      <mentions>
        <mention ids_tokens="3" string="she" id_sentence="12" />
        <mention ids_tokens="5" string="her" id_sentence="12" />
        <mention ids_tokens="10" string="me" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="9-10" string="Moon Tiger" id_sentence="12" />
      <mentions>
        <mention ids_tokens="10-12" string="Moon Tiger's" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="6-7-8-9-10" string="France 's respected Prix Goncourt" id_sentence="17" />
      <mentions>
        <mention ids_tokens="10-12" string="the Prix Goncourt" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12" string="the judges ' top six" id_sentence="22" />
      <mentions>
        <mention ids_tokens="6-7" string="the judges" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="9-10" string="that book" id_sentence="33" />
      <mentions>
        <mention ids_tokens="71-86" string="&quot; The Book and the Brotherhood &quot; ( Viking , 608 pages , $ 19.95 )" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="30" type="NOMINAL">
      <referenced ids_tokens="90-91-92-93-94-95-96-97-98-99-100-101-102-103-104-105-106-107" string="Chinua Achebe 's &quot; Anthills of the Savannah &quot; ( Doubleday , 240 pages , $ 16.95 )" id_sentence="23" />
      <mentions>
        <mention ids_tokens="8" string="Anthills" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="31" type="PROPER">
      <referenced ids_tokens="96-97" string="the Savannah" id_sentence="23" />
      <mentions>
        <mention ids_tokens="11" string="Savannah" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8" string="&quot; The Bone People" id_sentence="29" />
      <mentions>
        <mention ids_tokens="9" string="people" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="17-18" string="most readers" id_sentence="29" />
      <mentions>
        <mention ids_tokens="7" string="readers" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="20-21" string="the choices" id_sentence="35" />
      <mentions>
        <mention ids_tokens="15" string="choices" id_sentence="41" />
      </mentions>
    </coreference>
    <coreference id="40" type="PROPER">
      <referenced ids_tokens="3-4-5" string="the Sunday Times" id_sentence="36" />
      <mentions>
        <mention ids_tokens="24-25" string="the Times" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="41" type="PROPER">
      <referenced ids_tokens="14-15-16-17-18" string="Booker Prize for &quot; Something" id_sentence="38" />
      <mentions>
        <mention ids_tokens="17-19" string="the prize's" id_sentence="41" />
        <mention ids_tokens="7-8" string="the prize" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="44" type="PROPER">
      <referenced ids_tokens="10-11-12" string="Elizabeth Jane Howard" id_sentence="42" />
      <mentions>
        <mention ids_tokens="5" string="she" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="The real world" id_sentence="42" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="43" />
        <mention ids_tokens="30" string="it" id_sentence="45" />
      </mentions>
    </coreference>
    <coreference id="47" type="PROPER">
      <referenced ids_tokens="9-10-11-12-13" string="Mr. Amis at the time" id_sentence="43" />
      <mentions>
        <mention ids_tokens="1" string="He" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="48" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12" string="the Booker 's current appeal to the 1982 competition" id_sentence="45" />
      <mentions>
        <mention ids_tokens="4" string="it" id_sentence="46" />
        <mention ids_tokens="12" string="it" id_sentence="46" />
        <mention ids_tokens="6" string="it" id_sentence="47" />
        <mention ids_tokens="10" string="it" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="50" type="PROPER">
      <referenced ids_tokens="4-5-6-7-8-9-10-11-12-13-14" string="the first year the prize caught the media and public imagination" id_sentence="48" />
      <mentions>
        <mention ids_tokens="38-39" string="a novel" id_sentence="45" />
        <mention ids_tokens="15-16" string="a novel" id_sentence="46" />
      </mentions>
    </coreference>
  </coreferences>
</document>
