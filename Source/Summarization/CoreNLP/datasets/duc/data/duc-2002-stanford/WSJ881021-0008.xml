<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="WSJ881021-0008">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Say what you want about Albert Goldman, the author of the new biography, &amp;quot;The Lives of John Lennon&amp;quot; (Morrow, $22.95), but you&amp;apost;ve got to hand it to him: This guy is one ambitious sleazemonger.</content>
      <tokens>
        <token id="1" string="Say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Albert" lemma="Albert" stem="albert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="biography" lemma="biography" stem="biographi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="21" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="22" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Morrow" lemma="Morrow" stem="morrow" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="27" string="22.95" lemma="22.95" stem="22.95" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="28" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="got" lemma="get" stem="got" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="hand" lemma="hand" stem="hand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="guy" lemma="guy" stem="gui" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="44" string="ambitious" lemma="ambitious" stem="ambiti" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="45" string="sleazemonger" lemma="sleazemonger" stem="sleazemong" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VB Say) (SBAR (WHNP (WP what)) (S (S (NP (PRP you)) (VP (VBP want) (PP (IN about) (NP (NP (NNP Albert) (NNP Goldman)) (, ,) (NP (NP (DT the) (NN author)) (PP (IN of) (NP (NP (DT the) (JJ new) (NN biography)) (, ,) (`` ``) (NP (NP (DT The) (NNS Lives)) (PP (IN of) (NP (NNP John) (NNP Lennon)))) ('' ''))) (PRN (-LRB- -LRB-) (NP (NNP Morrow)) (, ,) (NP ($ $) (CD 22.95)) (-RRB- -RRB-))))))) (, ,) (CC but) (S (NP (PRP you)) (VP (VBP 've) (VP (VBN got) (S (VP (TO to) (VP (VB hand) (NP (PRP it)) (PP (TO to) (NP (PRP him))))))))))))) (: :) (S (NP (DT This) (NN guy)) (VP (VBZ is) (NP (CD one) (JJ ambitious) (NN sleazemonger)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is one ambitious sleazemonger" type="VP">
          <tokens>
            <token id="42" string="is" />
            <token id="43" string="one" />
            <token id="44" string="ambitious" />
            <token id="45" string="sleazemonger" />
          </tokens>
        </chunking>
        <chunking id="2" string="the author" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="author" />
          </tokens>
        </chunking>
        <chunking id="3" string="the author of the new biography , `` The Lives of John Lennon '' -LRB- Morrow , $ 22.95 -RRB-" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="author" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="new" />
            <token id="14" string="biography" />
            <token id="15" string="," />
            <token id="16" string="&quot;" />
            <token id="17" string="The" />
            <token id="18" string="Lives" />
            <token id="19" string="of" />
            <token id="20" string="John" />
            <token id="21" string="Lennon" />
            <token id="22" string="&quot;" />
            <token id="23" string="(" />
            <token id="24" string="Morrow" />
            <token id="25" string="," />
            <token id="26" string="$" />
            <token id="27" string="22.95" />
            <token id="28" string=")" />
          </tokens>
        </chunking>
        <chunking id="4" string="the new biography , `` The Lives of John Lennon ''" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="new" />
            <token id="14" string="biography" />
            <token id="15" string="," />
            <token id="16" string="&quot;" />
            <token id="17" string="The" />
            <token id="18" string="Lives" />
            <token id="19" string="of" />
            <token id="20" string="John" />
            <token id="21" string="Lennon" />
            <token id="22" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="5" string="The Lives" type="NP">
          <tokens>
            <token id="17" string="The" />
            <token id="18" string="Lives" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="38" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="Say what you want about Albert Goldman , the author of the new biography , `` The Lives of John Lennon '' -LRB- Morrow , $ 22.95 -RRB- , but you 've got to hand it to him" type="VP">
          <tokens>
            <token id="1" string="Say" />
            <token id="2" string="what" />
            <token id="3" string="you" />
            <token id="4" string="want" />
            <token id="5" string="about" />
            <token id="6" string="Albert" />
            <token id="7" string="Goldman" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="author" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="new" />
            <token id="14" string="biography" />
            <token id="15" string="," />
            <token id="16" string="&quot;" />
            <token id="17" string="The" />
            <token id="18" string="Lives" />
            <token id="19" string="of" />
            <token id="20" string="John" />
            <token id="21" string="Lennon" />
            <token id="22" string="&quot;" />
            <token id="23" string="(" />
            <token id="24" string="Morrow" />
            <token id="25" string="," />
            <token id="26" string="$" />
            <token id="27" string="22.95" />
            <token id="28" string=")" />
            <token id="29" string="," />
            <token id="30" string="but" />
            <token id="31" string="you" />
            <token id="32" string="'ve" />
            <token id="33" string="got" />
            <token id="34" string="to" />
            <token id="35" string="hand" />
            <token id="36" string="it" />
            <token id="37" string="to" />
            <token id="38" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="John Lennon" type="NP">
          <tokens>
            <token id="20" string="John" />
            <token id="21" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="10" string="'ve got to hand it to him" type="VP">
          <tokens>
            <token id="32" string="'ve" />
            <token id="33" string="got" />
            <token id="34" string="to" />
            <token id="35" string="hand" />
            <token id="36" string="it" />
            <token id="37" string="to" />
            <token id="38" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="to hand it to him" type="VP">
          <tokens>
            <token id="34" string="to" />
            <token id="35" string="hand" />
            <token id="36" string="it" />
            <token id="37" string="to" />
            <token id="38" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="hand it to him" type="VP">
          <tokens>
            <token id="35" string="hand" />
            <token id="36" string="it" />
            <token id="37" string="to" />
            <token id="38" string="him" />
          </tokens>
        </chunking>
        <chunking id="13" string="what you want about Albert Goldman , the author of the new biography , `` The Lives of John Lennon '' -LRB- Morrow , $ 22.95 -RRB- , but you 've got to hand it to him" type="SBAR">
          <tokens>
            <token id="2" string="what" />
            <token id="3" string="you" />
            <token id="4" string="want" />
            <token id="5" string="about" />
            <token id="6" string="Albert" />
            <token id="7" string="Goldman" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="author" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="new" />
            <token id="14" string="biography" />
            <token id="15" string="," />
            <token id="16" string="&quot;" />
            <token id="17" string="The" />
            <token id="18" string="Lives" />
            <token id="19" string="of" />
            <token id="20" string="John" />
            <token id="21" string="Lennon" />
            <token id="22" string="&quot;" />
            <token id="23" string="(" />
            <token id="24" string="Morrow" />
            <token id="25" string="," />
            <token id="26" string="$" />
            <token id="27" string="22.95" />
            <token id="28" string=")" />
            <token id="29" string="," />
            <token id="30" string="but" />
            <token id="31" string="you" />
            <token id="32" string="'ve" />
            <token id="33" string="got" />
            <token id="34" string="to" />
            <token id="35" string="hand" />
            <token id="36" string="it" />
            <token id="37" string="to" />
            <token id="38" string="him" />
          </tokens>
        </chunking>
        <chunking id="14" string="The Lives of John Lennon" type="NP">
          <tokens>
            <token id="17" string="The" />
            <token id="18" string="Lives" />
            <token id="19" string="of" />
            <token id="20" string="John" />
            <token id="21" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="15" string="This guy" type="NP">
          <tokens>
            <token id="40" string="This" />
            <token id="41" string="guy" />
          </tokens>
        </chunking>
        <chunking id="16" string="want about Albert Goldman , the author of the new biography , `` The Lives of John Lennon '' -LRB- Morrow , $ 22.95 -RRB-" type="VP">
          <tokens>
            <token id="4" string="want" />
            <token id="5" string="about" />
            <token id="6" string="Albert" />
            <token id="7" string="Goldman" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="author" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="new" />
            <token id="14" string="biography" />
            <token id="15" string="," />
            <token id="16" string="&quot;" />
            <token id="17" string="The" />
            <token id="18" string="Lives" />
            <token id="19" string="of" />
            <token id="20" string="John" />
            <token id="21" string="Lennon" />
            <token id="22" string="&quot;" />
            <token id="23" string="(" />
            <token id="24" string="Morrow" />
            <token id="25" string="," />
            <token id="26" string="$" />
            <token id="27" string="22.95" />
            <token id="28" string=")" />
          </tokens>
        </chunking>
        <chunking id="17" string="Albert Goldman , the author of the new biography , `` The Lives of John Lennon '' -LRB- Morrow , $ 22.95 -RRB-" type="NP">
          <tokens>
            <token id="6" string="Albert" />
            <token id="7" string="Goldman" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="author" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="new" />
            <token id="14" string="biography" />
            <token id="15" string="," />
            <token id="16" string="&quot;" />
            <token id="17" string="The" />
            <token id="18" string="Lives" />
            <token id="19" string="of" />
            <token id="20" string="John" />
            <token id="21" string="Lennon" />
            <token id="22" string="&quot;" />
            <token id="23" string="(" />
            <token id="24" string="Morrow" />
            <token id="25" string="," />
            <token id="26" string="$" />
            <token id="27" string="22.95" />
            <token id="28" string=")" />
          </tokens>
        </chunking>
        <chunking id="18" string="Albert Goldman" type="NP">
          <tokens>
            <token id="6" string="Albert" />
            <token id="7" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="19" string="the new biography" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="new" />
            <token id="14" string="biography" />
          </tokens>
        </chunking>
        <chunking id="20" string="$ 22.95" type="NP">
          <tokens>
            <token id="26" string="$" />
            <token id="27" string="22.95" />
          </tokens>
        </chunking>
        <chunking id="21" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
        <chunking id="22" string="Morrow" type="NP">
          <tokens>
            <token id="24" string="Morrow" />
          </tokens>
        </chunking>
        <chunking id="23" string="got to hand it to him" type="VP">
          <tokens>
            <token id="33" string="got" />
            <token id="34" string="to" />
            <token id="35" string="hand" />
            <token id="36" string="it" />
            <token id="37" string="to" />
            <token id="38" string="him" />
          </tokens>
        </chunking>
        <chunking id="24" string="one ambitious sleazemonger" type="NP">
          <tokens>
            <token id="43" string="one" />
            <token id="44" string="ambitious" />
            <token id="45" string="sleazemonger" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Say</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">want</governor>
          <dependent id="2">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">want</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Say</governor>
          <dependent id="4">want</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Goldman</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Goldman</governor>
          <dependent id="6">Albert</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">want</governor>
          <dependent id="7">Goldman</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">author</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">Goldman</governor>
          <dependent id="10">author</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">biography</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">biography</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">biography</governor>
          <dependent id="13">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">author</governor>
          <dependent id="14">biography</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Lives</governor>
          <dependent id="17">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">biography</governor>
          <dependent id="18">Lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Lennon</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Lennon</governor>
          <dependent id="20">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">Lives</governor>
          <dependent id="21">Lennon</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">author</governor>
          <dependent id="24">Morrow</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">22.95</governor>
          <dependent id="26">$</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">Morrow</governor>
          <dependent id="27">22.95</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">want</governor>
          <dependent id="30">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">got</governor>
          <dependent id="31">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="33">got</governor>
          <dependent id="32">'ve</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">want</governor>
          <dependent id="33">got</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">hand</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="33">got</governor>
          <dependent id="35">hand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">hand</governor>
          <dependent id="36">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">him</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">hand</governor>
          <dependent id="38">him</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">guy</governor>
          <dependent id="40">This</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="45">sleazemonger</governor>
          <dependent id="41">guy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="45">sleazemonger</governor>
          <dependent id="42">is</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="45">sleazemonger</governor>
          <dependent id="43">one</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="45">sleazemonger</governor>
          <dependent id="44">ambitious</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">Say</governor>
          <dependent id="45">sleazemonger</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="John" />
            <token id="21" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="43" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Albert Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Albert" />
            <token id="7" string="Goldman" />
          </tokens>
        </entity>
        <entity id="4" string="$ 22.95" type="MONEY" score="0.0">
          <tokens>
            <token id="26" string="$" />
            <token id="27" string="22.95" />
          </tokens>
        </entity>
        <entity id="5" string="Morrow" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Morrow" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>Most best-selling pop biographers play it safe: They choose a celeb of respectable, not to say pristine, reputation, and then they proceed to blacken it, preferably by recounting vaguely sourced tales of sexual excess, chemical dependency, personal unkindness, raw business dealings, even, in some cases, dyslexia.</content>
      <tokens>
        <token id="1" string="Most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="best-selling" lemma="best-selling" stem="best-sel" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="pop" lemma="pop" stem="pop" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="biographers" lemma="biographer" stem="biograph" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="play" lemma="play" stem="plai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="safe" lemma="safe" stem="safe" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="choose" lemma="choose" stem="choos" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="celeb" lemma="celeb" stem="celeb" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="respectable" lemma="respectable" stem="respect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="pristine" lemma="pristine" stem="pristin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="reputation" lemma="reputation" stem="reput" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="proceed" lemma="proceed" stem="proce" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="blacken" lemma="blacken" stem="blacken" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="preferably" lemma="preferably" stem="prefer" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="recounting" lemma="recount" stem="recount" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="vaguely" lemma="vaguely" stem="vagu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="sourced" lemma="sourced" stem="sourc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="tales" lemma="tale" stem="tale" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="sexual" lemma="sexual" stem="sexual" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="excess" lemma="excess" stem="excess" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="chemical" lemma="chemical" stem="chemic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="dependency" lemma="dependency" stem="depend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="unkindness" lemma="unkindness" stem="unkind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="raw" lemma="raw" stem="raw" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="dealings" lemma="dealings" stem="deal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="cases" lemma="case" stem="case" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="57" string="dyslexia" lemma="dyslexia" stem="dyslexia" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="58" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (JJS Most) (JJ best-selling) (NN pop) (NNS biographers)) (VP (VBP play) (S (NP (PRP it)) (ADJP (JJ safe))))) (: :) (S (S (NP (PRP They)) (VP (VB choose) (NP (NP (DT a) (NN celeb)) (PP (IN of) (NP (ADJP (ADJP (JJ respectable)) (PRN (, ,) (ADVP (RB not) (S (VP (TO to) (VP (VB say) (ADJP (JJ pristine)))))) (, ,))) (NN reputation)))))) (, ,) (CC and) (RB then) (S (NP (PRP they)) (VP (VBP proceed) (S (VP (TO to) (VP (VB blacken) (NP (PRP it)) (, ,) (ADVP (RB preferably)) (PP (IN by) (S (VP (VBG recounting) (ADVP (RB vaguely) (NP (JJ sourced) (NNS tales))) (PP (IN of) (NP (NP (JJ sexual) (NN excess)) (, ,) (NP (NN chemical) (NN dependency)) (, ,) (NP (JJ personal) (NN unkindness)) (, ,) (NP (JJ raw) (NN business) (NNS dealings)) (, ,) (ADVP (RB even)) (, ,) (PP (IN in) (NP (NP (DT some) (NNS cases)) (, ,) (NP (NN dyslexia))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="9" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="to blacken it , preferably by recounting vaguely sourced tales of sexual excess , chemical dependency , personal unkindness , raw business dealings , even , in some cases , dyslexia" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="blacken" />
            <token id="29" string="it" />
            <token id="30" string="," />
            <token id="31" string="preferably" />
            <token id="32" string="by" />
            <token id="33" string="recounting" />
            <token id="34" string="vaguely" />
            <token id="35" string="sourced" />
            <token id="36" string="tales" />
            <token id="37" string="of" />
            <token id="38" string="sexual" />
            <token id="39" string="excess" />
            <token id="40" string="," />
            <token id="41" string="chemical" />
            <token id="42" string="dependency" />
            <token id="43" string="," />
            <token id="44" string="personal" />
            <token id="45" string="unkindness" />
            <token id="46" string="," />
            <token id="47" string="raw" />
            <token id="48" string="business" />
            <token id="49" string="dealings" />
            <token id="50" string="," />
            <token id="51" string="even" />
            <token id="52" string="," />
            <token id="53" string="in" />
            <token id="54" string="some" />
            <token id="55" string="cases" />
            <token id="56" string="," />
            <token id="57" string="dyslexia" />
          </tokens>
        </chunking>
        <chunking id="3" string="blacken it , preferably by recounting vaguely sourced tales of sexual excess , chemical dependency , personal unkindness , raw business dealings , even , in some cases , dyslexia" type="VP">
          <tokens>
            <token id="28" string="blacken" />
            <token id="29" string="it" />
            <token id="30" string="," />
            <token id="31" string="preferably" />
            <token id="32" string="by" />
            <token id="33" string="recounting" />
            <token id="34" string="vaguely" />
            <token id="35" string="sourced" />
            <token id="36" string="tales" />
            <token id="37" string="of" />
            <token id="38" string="sexual" />
            <token id="39" string="excess" />
            <token id="40" string="," />
            <token id="41" string="chemical" />
            <token id="42" string="dependency" />
            <token id="43" string="," />
            <token id="44" string="personal" />
            <token id="45" string="unkindness" />
            <token id="46" string="," />
            <token id="47" string="raw" />
            <token id="48" string="business" />
            <token id="49" string="dealings" />
            <token id="50" string="," />
            <token id="51" string="even" />
            <token id="52" string="," />
            <token id="53" string="in" />
            <token id="54" string="some" />
            <token id="55" string="cases" />
            <token id="56" string="," />
            <token id="57" string="dyslexia" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="play it safe" type="VP">
          <tokens>
            <token id="5" string="play" />
            <token id="6" string="it" />
            <token id="7" string="safe" />
          </tokens>
        </chunking>
        <chunking id="6" string="personal unkindness" type="NP">
          <tokens>
            <token id="44" string="personal" />
            <token id="45" string="unkindness" />
          </tokens>
        </chunking>
        <chunking id="7" string="respectable" type="ADJP">
          <tokens>
            <token id="14" string="respectable" />
          </tokens>
        </chunking>
        <chunking id="8" string="safe" type="ADJP">
          <tokens>
            <token id="7" string="safe" />
          </tokens>
        </chunking>
        <chunking id="9" string="recounting vaguely sourced tales of sexual excess , chemical dependency , personal unkindness , raw business dealings , even , in some cases , dyslexia" type="VP">
          <tokens>
            <token id="33" string="recounting" />
            <token id="34" string="vaguely" />
            <token id="35" string="sourced" />
            <token id="36" string="tales" />
            <token id="37" string="of" />
            <token id="38" string="sexual" />
            <token id="39" string="excess" />
            <token id="40" string="," />
            <token id="41" string="chemical" />
            <token id="42" string="dependency" />
            <token id="43" string="," />
            <token id="44" string="personal" />
            <token id="45" string="unkindness" />
            <token id="46" string="," />
            <token id="47" string="raw" />
            <token id="48" string="business" />
            <token id="49" string="dealings" />
            <token id="50" string="," />
            <token id="51" string="even" />
            <token id="52" string="," />
            <token id="53" string="in" />
            <token id="54" string="some" />
            <token id="55" string="cases" />
            <token id="56" string="," />
            <token id="57" string="dyslexia" />
          </tokens>
        </chunking>
        <chunking id="10" string="proceed to blacken it , preferably by recounting vaguely sourced tales of sexual excess , chemical dependency , personal unkindness , raw business dealings , even , in some cases , dyslexia" type="VP">
          <tokens>
            <token id="26" string="proceed" />
            <token id="27" string="to" />
            <token id="28" string="blacken" />
            <token id="29" string="it" />
            <token id="30" string="," />
            <token id="31" string="preferably" />
            <token id="32" string="by" />
            <token id="33" string="recounting" />
            <token id="34" string="vaguely" />
            <token id="35" string="sourced" />
            <token id="36" string="tales" />
            <token id="37" string="of" />
            <token id="38" string="sexual" />
            <token id="39" string="excess" />
            <token id="40" string="," />
            <token id="41" string="chemical" />
            <token id="42" string="dependency" />
            <token id="43" string="," />
            <token id="44" string="personal" />
            <token id="45" string="unkindness" />
            <token id="46" string="," />
            <token id="47" string="raw" />
            <token id="48" string="business" />
            <token id="49" string="dealings" />
            <token id="50" string="," />
            <token id="51" string="even" />
            <token id="52" string="," />
            <token id="53" string="in" />
            <token id="54" string="some" />
            <token id="55" string="cases" />
            <token id="56" string="," />
            <token id="57" string="dyslexia" />
          </tokens>
        </chunking>
        <chunking id="11" string="sexual excess , chemical dependency , personal unkindness , raw business dealings , even , in some cases , dyslexia" type="NP">
          <tokens>
            <token id="38" string="sexual" />
            <token id="39" string="excess" />
            <token id="40" string="," />
            <token id="41" string="chemical" />
            <token id="42" string="dependency" />
            <token id="43" string="," />
            <token id="44" string="personal" />
            <token id="45" string="unkindness" />
            <token id="46" string="," />
            <token id="47" string="raw" />
            <token id="48" string="business" />
            <token id="49" string="dealings" />
            <token id="50" string="," />
            <token id="51" string="even" />
            <token id="52" string="," />
            <token id="53" string="in" />
            <token id="54" string="some" />
            <token id="55" string="cases" />
            <token id="56" string="," />
            <token id="57" string="dyslexia" />
          </tokens>
        </chunking>
        <chunking id="12" string="chemical dependency" type="NP">
          <tokens>
            <token id="41" string="chemical" />
            <token id="42" string="dependency" />
          </tokens>
        </chunking>
        <chunking id="13" string="respectable , not to say pristine , reputation" type="NP">
          <tokens>
            <token id="14" string="respectable" />
            <token id="15" string="," />
            <token id="16" string="not" />
            <token id="17" string="to" />
            <token id="18" string="say" />
            <token id="19" string="pristine" />
            <token id="20" string="," />
            <token id="21" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="14" string="choose a celeb of respectable , not to say pristine , reputation" type="VP">
          <tokens>
            <token id="10" string="choose" />
            <token id="11" string="a" />
            <token id="12" string="celeb" />
            <token id="13" string="of" />
            <token id="14" string="respectable" />
            <token id="15" string="," />
            <token id="16" string="not" />
            <token id="17" string="to" />
            <token id="18" string="say" />
            <token id="19" string="pristine" />
            <token id="20" string="," />
            <token id="21" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="15" string="to say pristine" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="say" />
            <token id="19" string="pristine" />
          </tokens>
        </chunking>
        <chunking id="16" string="a celeb of respectable , not to say pristine , reputation" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="celeb" />
            <token id="13" string="of" />
            <token id="14" string="respectable" />
            <token id="15" string="," />
            <token id="16" string="not" />
            <token id="17" string="to" />
            <token id="18" string="say" />
            <token id="19" string="pristine" />
            <token id="20" string="," />
            <token id="21" string="reputation" />
          </tokens>
        </chunking>
        <chunking id="17" string="some cases" type="NP">
          <tokens>
            <token id="54" string="some" />
            <token id="55" string="cases" />
          </tokens>
        </chunking>
        <chunking id="18" string="respectable , not to say pristine ," type="ADJP">
          <tokens>
            <token id="14" string="respectable" />
            <token id="15" string="," />
            <token id="16" string="not" />
            <token id="17" string="to" />
            <token id="18" string="say" />
            <token id="19" string="pristine" />
            <token id="20" string="," />
          </tokens>
        </chunking>
        <chunking id="19" string="they" type="NP">
          <tokens>
            <token id="25" string="they" />
          </tokens>
        </chunking>
        <chunking id="20" string="sourced tales" type="NP">
          <tokens>
            <token id="35" string="sourced" />
            <token id="36" string="tales" />
          </tokens>
        </chunking>
        <chunking id="21" string="sexual excess" type="NP">
          <tokens>
            <token id="38" string="sexual" />
            <token id="39" string="excess" />
          </tokens>
        </chunking>
        <chunking id="22" string="pristine" type="ADJP">
          <tokens>
            <token id="19" string="pristine" />
          </tokens>
        </chunking>
        <chunking id="23" string="say pristine" type="VP">
          <tokens>
            <token id="18" string="say" />
            <token id="19" string="pristine" />
          </tokens>
        </chunking>
        <chunking id="24" string="Most best-selling pop biographers" type="NP">
          <tokens>
            <token id="1" string="Most" />
            <token id="2" string="best-selling" />
            <token id="3" string="pop" />
            <token id="4" string="biographers" />
          </tokens>
        </chunking>
        <chunking id="25" string="some cases , dyslexia" type="NP">
          <tokens>
            <token id="54" string="some" />
            <token id="55" string="cases" />
            <token id="56" string="," />
            <token id="57" string="dyslexia" />
          </tokens>
        </chunking>
        <chunking id="26" string="raw business dealings" type="NP">
          <tokens>
            <token id="47" string="raw" />
            <token id="48" string="business" />
            <token id="49" string="dealings" />
          </tokens>
        </chunking>
        <chunking id="27" string="a celeb" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="celeb" />
          </tokens>
        </chunking>
        <chunking id="28" string="dyslexia" type="NP">
          <tokens>
            <token id="57" string="dyslexia" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="4">biographers</governor>
          <dependent id="1">Most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">biographers</governor>
          <dependent id="2">best-selling</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">biographers</governor>
          <dependent id="3">pop</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">play</governor>
          <dependent id="4">biographers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">play</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">safe</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">play</governor>
          <dependent id="7">safe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">choose</governor>
          <dependent id="9">They</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">play</governor>
          <dependent id="10">choose</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">celeb</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">choose</governor>
          <dependent id="12">celeb</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">reputation</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">reputation</governor>
          <dependent id="14">respectable</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">respectable</governor>
          <dependent id="16">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">say</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">not</governor>
          <dependent id="18">say</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">say</governor>
          <dependent id="19">pristine</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">celeb</governor>
          <dependent id="21">reputation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">choose</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">proceed</governor>
          <dependent id="24">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">proceed</governor>
          <dependent id="25">they</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">choose</governor>
          <dependent id="26">proceed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">blacken</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">proceed</governor>
          <dependent id="28">blacken</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">blacken</governor>
          <dependent id="29">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">recounting</governor>
          <dependent id="31">preferably</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">recounting</governor>
          <dependent id="32">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">blacken</governor>
          <dependent id="33">recounting</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">recounting</governor>
          <dependent id="34">vaguely</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">tales</governor>
          <dependent id="35">sourced</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="34">vaguely</governor>
          <dependent id="36">tales</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">excess</governor>
          <dependent id="37">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">excess</governor>
          <dependent id="38">sexual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">recounting</governor>
          <dependent id="39">excess</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">dependency</governor>
          <dependent id="41">chemical</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="39">excess</governor>
          <dependent id="42">dependency</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="45">unkindness</governor>
          <dependent id="44">personal</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="39">excess</governor>
          <dependent id="45">unkindness</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="49">dealings</governor>
          <dependent id="47">raw</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="49">dealings</governor>
          <dependent id="48">business</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="39">excess</governor>
          <dependent id="49">dealings</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="39">excess</governor>
          <dependent id="51">even</dependent>
        </dependency>
        <dependency type="case">
          <governor id="55">cases</governor>
          <dependent id="53">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="55">cases</governor>
          <dependent id="54">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">excess</governor>
          <dependent id="55">cases</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="55">cases</governor>
          <dependent id="57">dyslexia</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The resulting portrait of a dissipated ogre who can&amp;apost;t spell is duly presented in hardback form to the public, which in turn is so shocked and disgusted that it forces itself to buy the biography by the millions.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="resulting" lemma="result" stem="result" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="portrait" lemma="portrait" stem="portrait" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="dissipated" lemma="dissipate" stem="dissip" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="ogre" lemma="ogre" stem="ogr" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="spell" lemma="spell" stem="spell" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="duly" lemma="duly" stem="duli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="presented" lemma="present" stem="present" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="hardback" lemma="hardback" stem="hardback" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="turn" lemma="turn" stem="turn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="shocked" lemma="shocked" stem="shock" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="disgusted" lemma="disgusted" stem="disgust" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="forces" lemma="force" stem="forc" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="buy" lemma="buy" stem="bui" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="biography" lemma="biography" stem="biographi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="millions" lemma="million" stem="million" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (VBG resulting) (NN portrait)) (PP (IN of) (NP (NP (DT a) (VBN dissipated) (NN ogre)) (SBAR (WHNP (WP who)) (S (VP (MD ca) (RB n't) (VP (VB spell)))))))) (VP (VBZ is) (ADVP (RB duly)) (VP (VBN presented) (PP (IN in) (NP (NN hardback) (NN form))) (PP (TO to) (NP (NP (DT the) (NN public)) (, ,) (SBAR (WHNP (WDT which)) (S (PP (IN in) (NP (NN turn))) (VP (VBZ is) (ADJP (RB so) (JJ shocked) (CC and) (JJ disgusted) (SBAR (IN that) (S (NP (PRP it)) (VP (VBZ forces) (S (NP (PRP itself)) (VP (TO to) (VP (VB buy) (NP (DT the) (NN biography)) (PP (IN by) (NP (DT the) (NNS millions))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the public , which in turn is so shocked and disgusted that it forces itself to buy the biography by the millions" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="public" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="in" />
            <token id="24" string="turn" />
            <token id="25" string="is" />
            <token id="26" string="so" />
            <token id="27" string="shocked" />
            <token id="28" string="and" />
            <token id="29" string="disgusted" />
            <token id="30" string="that" />
            <token id="31" string="it" />
            <token id="32" string="forces" />
            <token id="33" string="itself" />
            <token id="34" string="to" />
            <token id="35" string="buy" />
            <token id="36" string="the" />
            <token id="37" string="biography" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="2" string="a dissipated ogre who ca n't spell" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="dissipated" />
            <token id="7" string="ogre" />
            <token id="8" string="who" />
            <token id="9" string="ca" />
            <token id="10" string="n't" />
            <token id="11" string="spell" />
          </tokens>
        </chunking>
        <chunking id="3" string="is so shocked and disgusted that it forces itself to buy the biography by the millions" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="so" />
            <token id="27" string="shocked" />
            <token id="28" string="and" />
            <token id="29" string="disgusted" />
            <token id="30" string="that" />
            <token id="31" string="it" />
            <token id="32" string="forces" />
            <token id="33" string="itself" />
            <token id="34" string="to" />
            <token id="35" string="buy" />
            <token id="36" string="the" />
            <token id="37" string="biography" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="4" string="so shocked and disgusted that it forces itself to buy the biography by the millions" type="ADJP">
          <tokens>
            <token id="26" string="so" />
            <token id="27" string="shocked" />
            <token id="28" string="and" />
            <token id="29" string="disgusted" />
            <token id="30" string="that" />
            <token id="31" string="it" />
            <token id="32" string="forces" />
            <token id="33" string="itself" />
            <token id="34" string="to" />
            <token id="35" string="buy" />
            <token id="36" string="the" />
            <token id="37" string="biography" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="5" string="the public" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="public" />
          </tokens>
        </chunking>
        <chunking id="6" string="a dissipated ogre" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="dissipated" />
            <token id="7" string="ogre" />
          </tokens>
        </chunking>
        <chunking id="7" string="the biography" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="biography" />
          </tokens>
        </chunking>
        <chunking id="8" string="presented in hardback form to the public , which in turn is so shocked and disgusted that it forces itself to buy the biography by the millions" type="VP">
          <tokens>
            <token id="14" string="presented" />
            <token id="15" string="in" />
            <token id="16" string="hardback" />
            <token id="17" string="form" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="public" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="in" />
            <token id="24" string="turn" />
            <token id="25" string="is" />
            <token id="26" string="so" />
            <token id="27" string="shocked" />
            <token id="28" string="and" />
            <token id="29" string="disgusted" />
            <token id="30" string="that" />
            <token id="31" string="it" />
            <token id="32" string="forces" />
            <token id="33" string="itself" />
            <token id="34" string="to" />
            <token id="35" string="buy" />
            <token id="36" string="the" />
            <token id="37" string="biography" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="9" string="turn" type="NP">
          <tokens>
            <token id="24" string="turn" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="31" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="forces itself to buy the biography by the millions" type="VP">
          <tokens>
            <token id="32" string="forces" />
            <token id="33" string="itself" />
            <token id="34" string="to" />
            <token id="35" string="buy" />
            <token id="36" string="the" />
            <token id="37" string="biography" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="12" string="spell" type="VP">
          <tokens>
            <token id="11" string="spell" />
          </tokens>
        </chunking>
        <chunking id="13" string="which in turn is so shocked and disgusted that it forces itself to buy the biography by the millions" type="SBAR">
          <tokens>
            <token id="22" string="which" />
            <token id="23" string="in" />
            <token id="24" string="turn" />
            <token id="25" string="is" />
            <token id="26" string="so" />
            <token id="27" string="shocked" />
            <token id="28" string="and" />
            <token id="29" string="disgusted" />
            <token id="30" string="that" />
            <token id="31" string="it" />
            <token id="32" string="forces" />
            <token id="33" string="itself" />
            <token id="34" string="to" />
            <token id="35" string="buy" />
            <token id="36" string="the" />
            <token id="37" string="biography" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="14" string="buy the biography by the millions" type="VP">
          <tokens>
            <token id="35" string="buy" />
            <token id="36" string="the" />
            <token id="37" string="biography" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="15" string="to buy the biography by the millions" type="VP">
          <tokens>
            <token id="34" string="to" />
            <token id="35" string="buy" />
            <token id="36" string="the" />
            <token id="37" string="biography" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="16" string="who ca n't spell" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="ca" />
            <token id="10" string="n't" />
            <token id="11" string="spell" />
          </tokens>
        </chunking>
        <chunking id="17" string="itself" type="NP">
          <tokens>
            <token id="33" string="itself" />
          </tokens>
        </chunking>
        <chunking id="18" string="ca n't spell" type="VP">
          <tokens>
            <token id="9" string="ca" />
            <token id="10" string="n't" />
            <token id="11" string="spell" />
          </tokens>
        </chunking>
        <chunking id="19" string="The resulting portrait of a dissipated ogre who ca n't spell" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="resulting" />
            <token id="3" string="portrait" />
            <token id="4" string="of" />
            <token id="5" string="a" />
            <token id="6" string="dissipated" />
            <token id="7" string="ogre" />
            <token id="8" string="who" />
            <token id="9" string="ca" />
            <token id="10" string="n't" />
            <token id="11" string="spell" />
          </tokens>
        </chunking>
        <chunking id="20" string="is duly presented in hardback form to the public , which in turn is so shocked and disgusted that it forces itself to buy the biography by the millions" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="duly" />
            <token id="14" string="presented" />
            <token id="15" string="in" />
            <token id="16" string="hardback" />
            <token id="17" string="form" />
            <token id="18" string="to" />
            <token id="19" string="the" />
            <token id="20" string="public" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="in" />
            <token id="24" string="turn" />
            <token id="25" string="is" />
            <token id="26" string="so" />
            <token id="27" string="shocked" />
            <token id="28" string="and" />
            <token id="29" string="disgusted" />
            <token id="30" string="that" />
            <token id="31" string="it" />
            <token id="32" string="forces" />
            <token id="33" string="itself" />
            <token id="34" string="to" />
            <token id="35" string="buy" />
            <token id="36" string="the" />
            <token id="37" string="biography" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="21" string="hardback form" type="NP">
          <tokens>
            <token id="16" string="hardback" />
            <token id="17" string="form" />
          </tokens>
        </chunking>
        <chunking id="22" string="that it forces itself to buy the biography by the millions" type="SBAR">
          <tokens>
            <token id="30" string="that" />
            <token id="31" string="it" />
            <token id="32" string="forces" />
            <token id="33" string="itself" />
            <token id="34" string="to" />
            <token id="35" string="buy" />
            <token id="36" string="the" />
            <token id="37" string="biography" />
            <token id="38" string="by" />
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="23" string="the millions" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="millions" />
          </tokens>
        </chunking>
        <chunking id="24" string="The resulting portrait" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="resulting" />
            <token id="3" string="portrait" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">portrait</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">portrait</governor>
          <dependent id="2">resulting</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">presented</governor>
          <dependent id="3">portrait</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">ogre</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">ogre</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">ogre</governor>
          <dependent id="6">dissipated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">portrait</governor>
          <dependent id="7">ogre</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">spell</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">spell</governor>
          <dependent id="9">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">spell</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">ogre</governor>
          <dependent id="11">spell</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">presented</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">presented</governor>
          <dependent id="13">duly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">presented</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">form</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">form</governor>
          <dependent id="16">hardback</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">presented</governor>
          <dependent id="17">form</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">public</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">public</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">presented</governor>
          <dependent id="20">public</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">shocked</governor>
          <dependent id="22">which</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">turn</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">shocked</governor>
          <dependent id="24">turn</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">shocked</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">shocked</governor>
          <dependent id="26">so</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">public</governor>
          <dependent id="27">shocked</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">shocked</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">shocked</governor>
          <dependent id="29">disgusted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">forces</governor>
          <dependent id="30">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">forces</governor>
          <dependent id="31">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">shocked</governor>
          <dependent id="32">forces</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">forces</governor>
          <dependent id="33">itself</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">buy</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="32">forces</governor>
          <dependent id="35">buy</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">biography</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">buy</governor>
          <dependent id="37">biography</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">millions</governor>
          <dependent id="38">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">millions</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">buy</governor>
          <dependent id="40">millions</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>A can&amp;apost;t-miss formula, surely.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="miss" lemma="miss" stem="miss" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="formula" lemma="formula" stem="formula" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="surely" lemma="surely" stem="sure" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (NP (DT A) (S (S (VP (MD ca) (RB n't))) (: -) (S (VP (VB miss) (NP (NN formula)) (, ,) (ADVP (RB surely))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="miss formula , surely" type="VP">
          <tokens>
            <token id="5" string="miss" />
            <token id="6" string="formula" />
            <token id="7" string="," />
            <token id="8" string="surely" />
          </tokens>
        </chunking>
        <chunking id="2" string="formula" type="NP">
          <tokens>
            <token id="6" string="formula" />
          </tokens>
        </chunking>
        <chunking id="3" string="A ca n't - miss formula , surely" type="VP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="ca" />
            <token id="3" string="n't" />
            <token id="4" string="-" />
            <token id="5" string="miss" />
            <token id="6" string="formula" />
            <token id="7" string="," />
            <token id="8" string="surely" />
          </tokens>
        </chunking>
        <chunking id="4" string="ca n't" type="VP">
          <tokens>
            <token id="2" string="ca" />
            <token id="3" string="n't" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">A</governor>
          <dependent id="2">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="2">ca</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">ca</governor>
          <dependent id="5">miss</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">miss</governor>
          <dependent id="6">formula</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">miss</governor>
          <dependent id="8">surely</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Albert Goldman&amp;apost;s previous victim in the genre was Elvis Presley.</content>
      <tokens>
        <token id="1" string="Albert" lemma="Albert" stem="albert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="previous" lemma="previous" stem="previou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="victim" lemma="victim" stem="victim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="genre" lemma="genre" stem="genr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Elvis" lemma="Elvis" stem="elvi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Presley" lemma="Presley" stem="preslei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Albert) (NNP Goldman) (POS 's)) (JJ previous) (NN victim)) (PP (IN in) (NP (DT the) (NN genre)))) (VP (VBD was) (NP (NNP Elvis) (NNP Presley))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was Elvis Presley" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="Elvis" />
            <token id="11" string="Presley" />
          </tokens>
        </chunking>
        <chunking id="2" string="Elvis Presley" type="NP">
          <tokens>
            <token id="10" string="Elvis" />
            <token id="11" string="Presley" />
          </tokens>
        </chunking>
        <chunking id="3" string="Albert Goldman 's" type="NP">
          <tokens>
            <token id="1" string="Albert" />
            <token id="2" string="Goldman" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="the genre" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="genre" />
          </tokens>
        </chunking>
        <chunking id="5" string="Albert Goldman 's previous victim in the genre" type="NP">
          <tokens>
            <token id="1" string="Albert" />
            <token id="2" string="Goldman" />
            <token id="3" string="'s" />
            <token id="4" string="previous" />
            <token id="5" string="victim" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="genre" />
          </tokens>
        </chunking>
        <chunking id="6" string="Albert Goldman 's previous victim" type="NP">
          <tokens>
            <token id="1" string="Albert" />
            <token id="2" string="Goldman" />
            <token id="3" string="'s" />
            <token id="4" string="previous" />
            <token id="5" string="victim" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Goldman</governor>
          <dependent id="1">Albert</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">victim</governor>
          <dependent id="2">Goldman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Goldman</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">victim</governor>
          <dependent id="4">previous</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">Presley</governor>
          <dependent id="5">victim</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">genre</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">genre</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">victim</governor>
          <dependent id="8">genre</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">Presley</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Presley</governor>
          <dependent id="10">Elvis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">Presley</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Elvis Presley" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Elvis" />
            <token id="11" string="Presley" />
          </tokens>
        </entity>
        <entity id="2" string="Albert Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Albert" />
            <token id="2" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Now Mr. Presley was, if you&amp;apost;ll forgive the expression, a fat target for a writer of Mr. Goldman&amp;apost;s methods.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="Presley" lemma="Presley" stem="preslei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="forgive" lemma="forgive" stem="forgiv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="expression" lemma="expression" stem="express" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="fat" lemma="fat" stem="fat" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="target" lemma="target" stem="target" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="writer" lemma="writer" stem="writer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="21" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="23" string="methods" lemma="method" stem="method" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Now)) (NP (NNP Mr.) (NNP Presley)) (VP (VP (VBD was)) (, ,) (SBAR (IN if) (S (NP (PRP you)) (VP (MD 'll) (VP (VB forgive) (NP (NP (DT the) (NN expression)) (, ,) (NP (NP (DT a) (JJ fat) (NN target)) (PP (IN for) (NP (NP (DT a) (NN writer)) (PP (IN of) (NP (NP (NNP Mr.) (NNP Goldman) (POS 's)) (NNS methods)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mr. Goldman 's methods" type="NP">
          <tokens>
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="methods" />
          </tokens>
        </chunking>
        <chunking id="2" string="was , if you 'll forgive the expression , a fat target for a writer of Mr. Goldman 's methods" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="," />
            <token id="6" string="if" />
            <token id="7" string="you" />
            <token id="8" string="'ll" />
            <token id="9" string="forgive" />
            <token id="10" string="the" />
            <token id="11" string="expression" />
            <token id="12" string="," />
            <token id="13" string="a" />
            <token id="14" string="fat" />
            <token id="15" string="target" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="writer" />
            <token id="19" string="of" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="methods" />
          </tokens>
        </chunking>
        <chunking id="3" string="a writer of Mr. Goldman 's methods" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="writer" />
            <token id="19" string="of" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="methods" />
          </tokens>
        </chunking>
        <chunking id="4" string="the expression" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="expression" />
          </tokens>
        </chunking>
        <chunking id="5" string="if you 'll forgive the expression , a fat target for a writer of Mr. Goldman 's methods" type="SBAR">
          <tokens>
            <token id="6" string="if" />
            <token id="7" string="you" />
            <token id="8" string="'ll" />
            <token id="9" string="forgive" />
            <token id="10" string="the" />
            <token id="11" string="expression" />
            <token id="12" string="," />
            <token id="13" string="a" />
            <token id="14" string="fat" />
            <token id="15" string="target" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="writer" />
            <token id="19" string="of" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="methods" />
          </tokens>
        </chunking>
        <chunking id="6" string="was" type="VP">
          <tokens>
            <token id="4" string="was" />
          </tokens>
        </chunking>
        <chunking id="7" string="a fat target for a writer of Mr. Goldman 's methods" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="fat" />
            <token id="15" string="target" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="writer" />
            <token id="19" string="of" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="methods" />
          </tokens>
        </chunking>
        <chunking id="8" string="forgive the expression , a fat target for a writer of Mr. Goldman 's methods" type="VP">
          <tokens>
            <token id="9" string="forgive" />
            <token id="10" string="the" />
            <token id="11" string="expression" />
            <token id="12" string="," />
            <token id="13" string="a" />
            <token id="14" string="fat" />
            <token id="15" string="target" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="writer" />
            <token id="19" string="of" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="methods" />
          </tokens>
        </chunking>
        <chunking id="9" string="the expression , a fat target for a writer of Mr. Goldman 's methods" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="expression" />
            <token id="12" string="," />
            <token id="13" string="a" />
            <token id="14" string="fat" />
            <token id="15" string="target" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="writer" />
            <token id="19" string="of" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="methods" />
          </tokens>
        </chunking>
        <chunking id="10" string="a fat target" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="fat" />
            <token id="15" string="target" />
          </tokens>
        </chunking>
        <chunking id="11" string="a writer" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="writer" />
          </tokens>
        </chunking>
        <chunking id="12" string="'ll forgive the expression , a fat target for a writer of Mr. Goldman 's methods" type="VP">
          <tokens>
            <token id="8" string="'ll" />
            <token id="9" string="forgive" />
            <token id="10" string="the" />
            <token id="11" string="expression" />
            <token id="12" string="," />
            <token id="13" string="a" />
            <token id="14" string="fat" />
            <token id="15" string="target" />
            <token id="16" string="for" />
            <token id="17" string="a" />
            <token id="18" string="writer" />
            <token id="19" string="of" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="methods" />
          </tokens>
        </chunking>
        <chunking id="13" string="Mr. Presley" type="NP">
          <tokens>
            <token id="2" string="Mr." />
            <token id="3" string="Presley" />
          </tokens>
        </chunking>
        <chunking id="14" string="Mr. Goldman 's" type="NP">
          <tokens>
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="you" type="NP">
          <tokens>
            <token id="7" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">was</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Presley</governor>
          <dependent id="2">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">was</governor>
          <dependent id="3">Presley</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">forgive</governor>
          <dependent id="6">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">forgive</governor>
          <dependent id="7">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">forgive</governor>
          <dependent id="8">'ll</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">was</governor>
          <dependent id="9">forgive</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">expression</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">forgive</governor>
          <dependent id="11">expression</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">target</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">target</governor>
          <dependent id="14">fat</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">expression</governor>
          <dependent id="15">target</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">writer</governor>
          <dependent id="16">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">writer</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">target</governor>
          <dependent id="18">writer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">methods</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Goldman</governor>
          <dependent id="20">Mr.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">methods</governor>
          <dependent id="21">Goldman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Goldman</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">writer</governor>
          <dependent id="23">methods</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
        <entity id="2" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Goldman" />
          </tokens>
        </entity>
        <entity id="3" string="Presley" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Presley" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>His title notwithstanding, the &amp;quot;King of Rock &amp;apost;n&amp;apost; Roll&amp;quot; was in truth more a creature of the old show biz, a star whose wholesome image, carefully created by P.R. wizards, was ripe for debunking.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="title" lemma="title" stem="titl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="notwithstanding" lemma="notwithstanding" stem="notwithstand" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Rock" lemma="Rock" stem="rock" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="10" string="'n'" lemma="'n'" stem="'n'" pos="CC" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="Roll" lemma="Roll" stem="roll" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="truth" lemma="truth" stem="truth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="creature" lemma="creature" stem="creatur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="biz" lemma="biz" stem="biz" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="star" lemma="star" stem="star" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="wholesome" lemma="wholesome" stem="wholesom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="carefully" lemma="carefully" stem="carefulli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="created" lemma="create" stem="creat" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="P.R." lemma="p.r." stem="p.r." pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="wizards" lemma="wizard" stem="wizard" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="ripe" lemma="ripe" stem="ripe" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="debunking" lemma="debunk" stem="debunk" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (NP (PRP$ His) (NN title)) (IN notwithstanding)) (, ,) (NP (NP (DT the) (`` ``) (NNP King)) (PP (IN of) (NP (NNP Rock) (CC 'n') (NNP Roll)))) ('' '') (VP (VBD was) (PP (IN in) (NP (NN truth))) (ADVP (RBR more)) (NP (NP (DT a) (NN creature)) (PP (IN of) (NP (NP (DT the) (JJ old) (NN show) (NN biz)) (, ,) (NP (NP (DT a) (NN star)) (SBAR (WHNP (WP$ whose) (ADJP (JJ wholesome)) (NN image)) (S (PRN (, ,) (S (ADVP (RB carefully)) (VP (VBN created) (PP (IN by) (NP (NN P.R.) (NNS wizards))))) (, ,)) (VP (VBD was) (ADJP (JJ ripe) (PP (IN for) (S (VP (VBG debunking))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the old show biz" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="old" />
            <token id="22" string="show" />
            <token id="23" string="biz" />
          </tokens>
        </chunking>
        <chunking id="2" string="wholesome" type="ADJP">
          <tokens>
            <token id="28" string="wholesome" />
          </tokens>
        </chunking>
        <chunking id="3" string="was ripe for debunking" type="VP">
          <tokens>
            <token id="37" string="was" />
            <token id="38" string="ripe" />
            <token id="39" string="for" />
            <token id="40" string="debunking" />
          </tokens>
        </chunking>
        <chunking id="4" string="the `` King of Rock 'n' Roll" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="&quot;" />
            <token id="7" string="King" />
            <token id="8" string="of" />
            <token id="9" string="Rock" />
            <token id="10" string="'n'" />
            <token id="11" string="Roll" />
          </tokens>
        </chunking>
        <chunking id="5" string="a star whose wholesome image , carefully created by P.R. wizards , was ripe for debunking" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="star" />
            <token id="27" string="whose" />
            <token id="28" string="wholesome" />
            <token id="29" string="image" />
            <token id="30" string="," />
            <token id="31" string="carefully" />
            <token id="32" string="created" />
            <token id="33" string="by" />
            <token id="34" string="P.R." />
            <token id="35" string="wizards" />
            <token id="36" string="," />
            <token id="37" string="was" />
            <token id="38" string="ripe" />
            <token id="39" string="for" />
            <token id="40" string="debunking" />
          </tokens>
        </chunking>
        <chunking id="6" string="P.R. wizards" type="NP">
          <tokens>
            <token id="34" string="P.R." />
            <token id="35" string="wizards" />
          </tokens>
        </chunking>
        <chunking id="7" string="created by P.R. wizards" type="VP">
          <tokens>
            <token id="32" string="created" />
            <token id="33" string="by" />
            <token id="34" string="P.R." />
            <token id="35" string="wizards" />
          </tokens>
        </chunking>
        <chunking id="8" string="debunking" type="VP">
          <tokens>
            <token id="40" string="debunking" />
          </tokens>
        </chunking>
        <chunking id="9" string="the `` King" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="&quot;" />
            <token id="7" string="King" />
          </tokens>
        </chunking>
        <chunking id="10" string="a star" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="star" />
          </tokens>
        </chunking>
        <chunking id="11" string="was in truth more a creature of the old show biz , a star whose wholesome image , carefully created by P.R. wizards , was ripe for debunking" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="in" />
            <token id="15" string="truth" />
            <token id="16" string="more" />
            <token id="17" string="a" />
            <token id="18" string="creature" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="old" />
            <token id="22" string="show" />
            <token id="23" string="biz" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="star" />
            <token id="27" string="whose" />
            <token id="28" string="wholesome" />
            <token id="29" string="image" />
            <token id="30" string="," />
            <token id="31" string="carefully" />
            <token id="32" string="created" />
            <token id="33" string="by" />
            <token id="34" string="P.R." />
            <token id="35" string="wizards" />
            <token id="36" string="," />
            <token id="37" string="was" />
            <token id="38" string="ripe" />
            <token id="39" string="for" />
            <token id="40" string="debunking" />
          </tokens>
        </chunking>
        <chunking id="12" string="truth" type="NP">
          <tokens>
            <token id="15" string="truth" />
          </tokens>
        </chunking>
        <chunking id="13" string="Rock 'n' Roll" type="NP">
          <tokens>
            <token id="9" string="Rock" />
            <token id="10" string="'n'" />
            <token id="11" string="Roll" />
          </tokens>
        </chunking>
        <chunking id="14" string="a creature of the old show biz , a star whose wholesome image , carefully created by P.R. wizards , was ripe for debunking" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="creature" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="old" />
            <token id="22" string="show" />
            <token id="23" string="biz" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="star" />
            <token id="27" string="whose" />
            <token id="28" string="wholesome" />
            <token id="29" string="image" />
            <token id="30" string="," />
            <token id="31" string="carefully" />
            <token id="32" string="created" />
            <token id="33" string="by" />
            <token id="34" string="P.R." />
            <token id="35" string="wizards" />
            <token id="36" string="," />
            <token id="37" string="was" />
            <token id="38" string="ripe" />
            <token id="39" string="for" />
            <token id="40" string="debunking" />
          </tokens>
        </chunking>
        <chunking id="15" string="the old show biz , a star whose wholesome image , carefully created by P.R. wizards , was ripe for debunking" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="old" />
            <token id="22" string="show" />
            <token id="23" string="biz" />
            <token id="24" string="," />
            <token id="25" string="a" />
            <token id="26" string="star" />
            <token id="27" string="whose" />
            <token id="28" string="wholesome" />
            <token id="29" string="image" />
            <token id="30" string="," />
            <token id="31" string="carefully" />
            <token id="32" string="created" />
            <token id="33" string="by" />
            <token id="34" string="P.R." />
            <token id="35" string="wizards" />
            <token id="36" string="," />
            <token id="37" string="was" />
            <token id="38" string="ripe" />
            <token id="39" string="for" />
            <token id="40" string="debunking" />
          </tokens>
        </chunking>
        <chunking id="16" string="whose wholesome image , carefully created by P.R. wizards , was ripe for debunking" type="SBAR">
          <tokens>
            <token id="27" string="whose" />
            <token id="28" string="wholesome" />
            <token id="29" string="image" />
            <token id="30" string="," />
            <token id="31" string="carefully" />
            <token id="32" string="created" />
            <token id="33" string="by" />
            <token id="34" string="P.R." />
            <token id="35" string="wizards" />
            <token id="36" string="," />
            <token id="37" string="was" />
            <token id="38" string="ripe" />
            <token id="39" string="for" />
            <token id="40" string="debunking" />
          </tokens>
        </chunking>
        <chunking id="17" string="a creature" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="creature" />
          </tokens>
        </chunking>
        <chunking id="18" string="ripe for debunking" type="ADJP">
          <tokens>
            <token id="38" string="ripe" />
            <token id="39" string="for" />
            <token id="40" string="debunking" />
          </tokens>
        </chunking>
        <chunking id="19" string="His title" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="title" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">title</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">creature</governor>
          <dependent id="2">title</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">title</governor>
          <dependent id="3">notwithstanding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">King</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">creature</governor>
          <dependent id="7">King</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Rock</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">King</governor>
          <dependent id="9">Rock</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">Rock</governor>
          <dependent id="10">'n'</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">Rock</governor>
          <dependent id="11">Roll</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">creature</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">truth</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">creature</governor>
          <dependent id="15">truth</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">creature</governor>
          <dependent id="16">more</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">creature</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">creature</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">biz</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">biz</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">biz</governor>
          <dependent id="21">old</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">biz</governor>
          <dependent id="22">show</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">creature</governor>
          <dependent id="23">biz</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">star</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">biz</governor>
          <dependent id="26">star</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">image</governor>
          <dependent id="27">whose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">image</governor>
          <dependent id="28">wholesome</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">ripe</governor>
          <dependent id="29">image</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">created</governor>
          <dependent id="31">carefully</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="38">ripe</governor>
          <dependent id="32">created</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">wizards</governor>
          <dependent id="33">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">wizards</governor>
          <dependent id="34">P.R.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">created</governor>
          <dependent id="35">wizards</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="38">ripe</governor>
          <dependent id="37">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">star</governor>
          <dependent id="38">ripe</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">debunking</governor>
          <dependent id="39">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="38">ripe</governor>
          <dependent id="40">debunking</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="King" type="TITLE" score="0.0">
          <tokens>
            <token id="7" string="King" />
          </tokens>
        </entity>
        <entity id="2" string="Rock 'n' Roll" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Rock" />
            <token id="10" string="'n'" />
            <token id="11" string="Roll" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>But in choosing Mr. Lennon as his next target, Mr. Goldman appears to be trying to debunk the undebunkable.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="choosing" lemma="choose" stem="choos" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="next" lemma="next" stem="next" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="target" lemma="target" stem="target" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="appears" lemma="appear" stem="appear" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="debunk" lemma="debunk" stem="debunk" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="undebunkable" lemma="undebunkable" stem="undebunk" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN in) (S (VP (VBG choosing) (NP (NP (NNP Mr.) (NNP Lennon)) (PP (IN as) (NP (PRP$ his) (JJ next) (NN target))))))) (, ,) (NP (NNP Mr.) (NNP Goldman)) (VP (VBZ appears) (S (VP (TO to) (VP (VB be) (VP (VBG trying) (S (VP (TO to) (VP (VB debunk) (NP (DT the) (JJ undebunkable)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his next target" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="next" />
            <token id="9" string="target" />
          </tokens>
        </chunking>
        <chunking id="2" string="be trying to debunk the undebunkable" type="VP">
          <tokens>
            <token id="15" string="be" />
            <token id="16" string="trying" />
            <token id="17" string="to" />
            <token id="18" string="debunk" />
            <token id="19" string="the" />
            <token id="20" string="undebunkable" />
          </tokens>
        </chunking>
        <chunking id="3" string="debunk the undebunkable" type="VP">
          <tokens>
            <token id="18" string="debunk" />
            <token id="19" string="the" />
            <token id="20" string="undebunkable" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mr. Goldman" type="NP">
          <tokens>
            <token id="11" string="Mr." />
            <token id="12" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="5" string="the undebunkable" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="undebunkable" />
          </tokens>
        </chunking>
        <chunking id="6" string="to debunk the undebunkable" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="debunk" />
            <token id="19" string="the" />
            <token id="20" string="undebunkable" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mr. Lennon as his next target" type="NP">
          <tokens>
            <token id="4" string="Mr." />
            <token id="5" string="Lennon" />
            <token id="6" string="as" />
            <token id="7" string="his" />
            <token id="8" string="next" />
            <token id="9" string="target" />
          </tokens>
        </chunking>
        <chunking id="8" string="to be trying to debunk the undebunkable" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="be" />
            <token id="16" string="trying" />
            <token id="17" string="to" />
            <token id="18" string="debunk" />
            <token id="19" string="the" />
            <token id="20" string="undebunkable" />
          </tokens>
        </chunking>
        <chunking id="9" string="appears to be trying to debunk the undebunkable" type="VP">
          <tokens>
            <token id="13" string="appears" />
            <token id="14" string="to" />
            <token id="15" string="be" />
            <token id="16" string="trying" />
            <token id="17" string="to" />
            <token id="18" string="debunk" />
            <token id="19" string="the" />
            <token id="20" string="undebunkable" />
          </tokens>
        </chunking>
        <chunking id="10" string="choosing Mr. Lennon as his next target" type="VP">
          <tokens>
            <token id="3" string="choosing" />
            <token id="4" string="Mr." />
            <token id="5" string="Lennon" />
            <token id="6" string="as" />
            <token id="7" string="his" />
            <token id="8" string="next" />
            <token id="9" string="target" />
          </tokens>
        </chunking>
        <chunking id="11" string="trying to debunk the undebunkable" type="VP">
          <tokens>
            <token id="16" string="trying" />
            <token id="17" string="to" />
            <token id="18" string="debunk" />
            <token id="19" string="the" />
            <token id="20" string="undebunkable" />
          </tokens>
        </chunking>
        <chunking id="12" string="Mr. Lennon" type="NP">
          <tokens>
            <token id="4" string="Mr." />
            <token id="5" string="Lennon" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="13">appears</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="3">choosing</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">appears</governor>
          <dependent id="3">choosing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Lennon</governor>
          <dependent id="4">Mr.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">choosing</governor>
          <dependent id="5">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">target</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">target</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">target</governor>
          <dependent id="8">next</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Lennon</governor>
          <dependent id="9">target</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Goldman</governor>
          <dependent id="11">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">appears</governor>
          <dependent id="12">Goldman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">appears</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">trying</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">trying</governor>
          <dependent id="15">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">appears</governor>
          <dependent id="16">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">debunk</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">trying</governor>
          <dependent id="18">debunk</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">undebunkable</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">debunk</governor>
          <dependent id="20">undebunkable</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>For apart from his puerile politics, Mr. Lennon&amp;apost;s favorite topic in the thousands of interviews he gave was his own squalid history: His voracious drug use, his perfidy to employees, his unquenchable sexual promiscuity and so on.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="apart" lemma="apart" stem="apart" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="puerile" lemma="puerile" stem="pueril" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="politics" lemma="politics" stem="polit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="9" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="favorite" lemma="favorite" stem="favorit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="topic" lemma="topic" stem="topic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="thousands" lemma="thousand" stem="thousand" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="gave" lemma="give" stem="gave" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="squalid" lemma="squalid" stem="squalid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="voracious" lemma="voracious" stem="voraci" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="use" lemma="use" stem="us" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="perfidy" lemma="perfidy" stem="perfidi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="employees" lemma="employee" stem="employe" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="unquenchable" lemma="unquenchable" stem="unquench" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="sexual" lemma="sexual" stem="sexual" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="promiscuity" lemma="promiscuity" stem="promiscu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (PP (ADVP (RB apart)) (IN from) (NP (PRP$ his) (JJ puerile) (NNS politics)))) (, ,) (NP (NP (NP (NNP Mr.) (NNP Lennon) (POS 's)) (JJ favorite) (NN topic)) (PP (IN in) (NP (NP (DT the) (NNS thousands)) (PP (IN of) (NP (NP (NNS interviews)) (SBAR (S (NP (PRP he)) (VP (VBD gave))))))))) (VP (VBD was) (NP (NP (PRP$ his) (JJ own) (JJ squalid) (NN history)) (: :) (NP (NP (PRP$ His) (JJ voracious) (NN drug) (NN use)) (, ,) (NP (NP (PRP$ his) (NN perfidy)) (PP (PP (TO to) (NP (NP (NNS employees)) (, ,) (NP (PRP$ his) (JJ unquenchable) (JJ sexual) (NN promiscuity)))) (CC and) (ADVP (RB so)) (PP (IN on))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="interviews he gave" type="NP">
          <tokens>
            <token id="17" string="interviews" />
            <token id="18" string="he" />
            <token id="19" string="gave" />
          </tokens>
        </chunking>
        <chunking id="2" string="his own squalid history : His voracious drug use , his perfidy to employees , his unquenchable sexual promiscuity and so on" type="NP">
          <tokens>
            <token id="21" string="his" />
            <token id="22" string="own" />
            <token id="23" string="squalid" />
            <token id="24" string="history" />
            <token id="25" string=":" />
            <token id="26" string="His" />
            <token id="27" string="voracious" />
            <token id="28" string="drug" />
            <token id="29" string="use" />
            <token id="30" string="," />
            <token id="31" string="his" />
            <token id="32" string="perfidy" />
            <token id="33" string="to" />
            <token id="34" string="employees" />
            <token id="35" string="," />
            <token id="36" string="his" />
            <token id="37" string="unquenchable" />
            <token id="38" string="sexual" />
            <token id="39" string="promiscuity" />
            <token id="40" string="and" />
            <token id="41" string="so" />
            <token id="42" string="on" />
          </tokens>
        </chunking>
        <chunking id="3" string="his unquenchable sexual promiscuity" type="NP">
          <tokens>
            <token id="36" string="his" />
            <token id="37" string="unquenchable" />
            <token id="38" string="sexual" />
            <token id="39" string="promiscuity" />
          </tokens>
        </chunking>
        <chunking id="4" string="his puerile politics" type="NP">
          <tokens>
            <token id="4" string="his" />
            <token id="5" string="puerile" />
            <token id="6" string="politics" />
          </tokens>
        </chunking>
        <chunking id="5" string="the thousands" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="thousands" />
          </tokens>
        </chunking>
        <chunking id="6" string="interviews" type="NP">
          <tokens>
            <token id="17" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="7" string="the thousands of interviews he gave" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="thousands" />
            <token id="16" string="of" />
            <token id="17" string="interviews" />
            <token id="18" string="he" />
            <token id="19" string="gave" />
          </tokens>
        </chunking>
        <chunking id="8" string="was his own squalid history : His voracious drug use , his perfidy to employees , his unquenchable sexual promiscuity and so on" type="VP">
          <tokens>
            <token id="20" string="was" />
            <token id="21" string="his" />
            <token id="22" string="own" />
            <token id="23" string="squalid" />
            <token id="24" string="history" />
            <token id="25" string=":" />
            <token id="26" string="His" />
            <token id="27" string="voracious" />
            <token id="28" string="drug" />
            <token id="29" string="use" />
            <token id="30" string="," />
            <token id="31" string="his" />
            <token id="32" string="perfidy" />
            <token id="33" string="to" />
            <token id="34" string="employees" />
            <token id="35" string="," />
            <token id="36" string="his" />
            <token id="37" string="unquenchable" />
            <token id="38" string="sexual" />
            <token id="39" string="promiscuity" />
            <token id="40" string="and" />
            <token id="41" string="so" />
            <token id="42" string="on" />
          </tokens>
        </chunking>
        <chunking id="9" string="his perfidy to employees , his unquenchable sexual promiscuity and so on" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="perfidy" />
            <token id="33" string="to" />
            <token id="34" string="employees" />
            <token id="35" string="," />
            <token id="36" string="his" />
            <token id="37" string="unquenchable" />
            <token id="38" string="sexual" />
            <token id="39" string="promiscuity" />
            <token id="40" string="and" />
            <token id="41" string="so" />
            <token id="42" string="on" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mr. Lennon 's favorite topic in the thousands of interviews he gave" type="NP">
          <tokens>
            <token id="8" string="Mr." />
            <token id="9" string="Lennon" />
            <token id="10" string="'s" />
            <token id="11" string="favorite" />
            <token id="12" string="topic" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="thousands" />
            <token id="16" string="of" />
            <token id="17" string="interviews" />
            <token id="18" string="he" />
            <token id="19" string="gave" />
          </tokens>
        </chunking>
        <chunking id="11" string="Mr. Lennon 's favorite topic" type="NP">
          <tokens>
            <token id="8" string="Mr." />
            <token id="9" string="Lennon" />
            <token id="10" string="'s" />
            <token id="11" string="favorite" />
            <token id="12" string="topic" />
          </tokens>
        </chunking>
        <chunking id="12" string="his perfidy" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="perfidy" />
          </tokens>
        </chunking>
        <chunking id="13" string="his own squalid history" type="NP">
          <tokens>
            <token id="21" string="his" />
            <token id="22" string="own" />
            <token id="23" string="squalid" />
            <token id="24" string="history" />
          </tokens>
        </chunking>
        <chunking id="14" string="employees , his unquenchable sexual promiscuity" type="NP">
          <tokens>
            <token id="34" string="employees" />
            <token id="35" string="," />
            <token id="36" string="his" />
            <token id="37" string="unquenchable" />
            <token id="38" string="sexual" />
            <token id="39" string="promiscuity" />
          </tokens>
        </chunking>
        <chunking id="15" string="gave" type="VP">
          <tokens>
            <token id="19" string="gave" />
          </tokens>
        </chunking>
        <chunking id="16" string="His voracious drug use" type="NP">
          <tokens>
            <token id="26" string="His" />
            <token id="27" string="voracious" />
            <token id="28" string="drug" />
            <token id="29" string="use" />
          </tokens>
        </chunking>
        <chunking id="17" string="he" type="NP">
          <tokens>
            <token id="18" string="he" />
          </tokens>
        </chunking>
        <chunking id="18" string="employees" type="NP">
          <tokens>
            <token id="34" string="employees" />
          </tokens>
        </chunking>
        <chunking id="19" string="Mr. Lennon 's" type="NP">
          <tokens>
            <token id="8" string="Mr." />
            <token id="9" string="Lennon" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="20" string="he gave" type="SBAR">
          <tokens>
            <token id="18" string="he" />
            <token id="19" string="gave" />
          </tokens>
        </chunking>
        <chunking id="21" string="His voracious drug use , his perfidy to employees , his unquenchable sexual promiscuity and so on" type="NP">
          <tokens>
            <token id="26" string="His" />
            <token id="27" string="voracious" />
            <token id="28" string="drug" />
            <token id="29" string="use" />
            <token id="30" string="," />
            <token id="31" string="his" />
            <token id="32" string="perfidy" />
            <token id="33" string="to" />
            <token id="34" string="employees" />
            <token id="35" string="," />
            <token id="36" string="his" />
            <token id="37" string="unquenchable" />
            <token id="38" string="sexual" />
            <token id="39" string="promiscuity" />
            <token id="40" string="and" />
            <token id="41" string="so" />
            <token id="42" string="on" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="6">politics</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">politics</governor>
          <dependent id="2">apart</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="2">apart</governor>
          <dependent id="3">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">politics</governor>
          <dependent id="4">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">politics</governor>
          <dependent id="5">puerile</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">history</governor>
          <dependent id="6">politics</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Lennon</governor>
          <dependent id="8">Mr.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">topic</governor>
          <dependent id="9">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Lennon</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">topic</governor>
          <dependent id="11">favorite</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">history</governor>
          <dependent id="12">topic</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">thousands</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">thousands</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">topic</governor>
          <dependent id="15">thousands</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">interviews</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">thousands</governor>
          <dependent id="17">interviews</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">gave</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">interviews</governor>
          <dependent id="19">gave</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">history</governor>
          <dependent id="20">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">history</governor>
          <dependent id="21">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">history</governor>
          <dependent id="22">own</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">history</governor>
          <dependent id="23">squalid</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">history</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">use</governor>
          <dependent id="26">His</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">use</governor>
          <dependent id="27">voracious</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">use</governor>
          <dependent id="28">drug</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">history</governor>
          <dependent id="29">use</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">perfidy</governor>
          <dependent id="31">his</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="29">use</governor>
          <dependent id="32">perfidy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">employees</governor>
          <dependent id="33">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">perfidy</governor>
          <dependent id="34">employees</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="39">promiscuity</governor>
          <dependent id="36">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">promiscuity</governor>
          <dependent id="37">unquenchable</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">promiscuity</governor>
          <dependent id="38">sexual</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">employees</governor>
          <dependent id="39">promiscuity</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="34">employees</governor>
          <dependent id="40">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="40">and</governor>
          <dependent id="41">so</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">employees</governor>
          <dependent id="42">on</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>By his own accounting, then, Mr. Lennon was not about to dethrone Ward Cleaver as the all-American dad.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="accounting" lemma="accounting" stem="account" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="dethrone" lemma="dethrone" stem="dethron" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Ward" lemma="Ward" stem="ward" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Cleaver" lemma="Cleaver" stem="cleaver" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="all-American" lemma="all-american" stem="all-american" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="20" string="dad" lemma="dad" stem="dad" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (PRP$ his) (JJ own) (NN accounting))) (, ,) (ADVP (RB then)) (, ,) (NP (NNP Mr.) (NNP Lennon)) (VP (VBD was) (RB not) (ADJP (RB about) (S (VP (TO to) (VP (VB dethrone) (NP (NP (NNP Ward) (NNP Cleaver)) (PP (IN as) (NP (DT the) (JJ all-American) (NN dad))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was not about to dethrone Ward Cleaver as the all-American dad" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="not" />
            <token id="12" string="about" />
            <token id="13" string="to" />
            <token id="14" string="dethrone" />
            <token id="15" string="Ward" />
            <token id="16" string="Cleaver" />
            <token id="17" string="as" />
            <token id="18" string="the" />
            <token id="19" string="all-American" />
            <token id="20" string="dad" />
          </tokens>
        </chunking>
        <chunking id="2" string="his own accounting" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="own" />
            <token id="4" string="accounting" />
          </tokens>
        </chunking>
        <chunking id="3" string="dethrone Ward Cleaver as the all-American dad" type="VP">
          <tokens>
            <token id="14" string="dethrone" />
            <token id="15" string="Ward" />
            <token id="16" string="Cleaver" />
            <token id="17" string="as" />
            <token id="18" string="the" />
            <token id="19" string="all-American" />
            <token id="20" string="dad" />
          </tokens>
        </chunking>
        <chunking id="4" string="about to dethrone Ward Cleaver as the all-American dad" type="ADJP">
          <tokens>
            <token id="12" string="about" />
            <token id="13" string="to" />
            <token id="14" string="dethrone" />
            <token id="15" string="Ward" />
            <token id="16" string="Cleaver" />
            <token id="17" string="as" />
            <token id="18" string="the" />
            <token id="19" string="all-American" />
            <token id="20" string="dad" />
          </tokens>
        </chunking>
        <chunking id="5" string="to dethrone Ward Cleaver as the all-American dad" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="dethrone" />
            <token id="15" string="Ward" />
            <token id="16" string="Cleaver" />
            <token id="17" string="as" />
            <token id="18" string="the" />
            <token id="19" string="all-American" />
            <token id="20" string="dad" />
          </tokens>
        </chunking>
        <chunking id="6" string="the all-American dad" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="all-American" />
            <token id="20" string="dad" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mr. Lennon" type="NP">
          <tokens>
            <token id="8" string="Mr." />
            <token id="9" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ward Cleaver as the all-American dad" type="NP">
          <tokens>
            <token id="15" string="Ward" />
            <token id="16" string="Cleaver" />
            <token id="17" string="as" />
            <token id="18" string="the" />
            <token id="19" string="all-American" />
            <token id="20" string="dad" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ward Cleaver" type="NP">
          <tokens>
            <token id="15" string="Ward" />
            <token id="16" string="Cleaver" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">accounting</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">accounting</governor>
          <dependent id="2">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">accounting</governor>
          <dependent id="3">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">about</governor>
          <dependent id="4">accounting</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">about</governor>
          <dependent id="6">then</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Lennon</governor>
          <dependent id="8">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">about</governor>
          <dependent id="9">Lennon</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">about</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">about</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">about</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">dethrone</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">about</governor>
          <dependent id="14">dethrone</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Cleaver</governor>
          <dependent id="15">Ward</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">dethrone</governor>
          <dependent id="16">Cleaver</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">dad</governor>
          <dependent id="17">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">dad</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">dad</governor>
          <dependent id="19">all-American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">Cleaver</governor>
          <dependent id="20">dad</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="all-American" type="MISC" score="0.0">
          <tokens>
            <token id="19" string="all-American" />
          </tokens>
        </entity>
        <entity id="3" string="Ward Cleaver" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Ward" />
            <token id="16" string="Cleaver" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>His public loved him in spite of it all -- or perhaps because of it all.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="loved" lemma="love" stem="love" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="spite" lemma="spite" stem="spite" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="16" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ His) (JJ public)) (VP (VBD loved) (NP (PRP him)) (PP (IN in) (NP (NP (NN spite)) (PP (IN of) (NP (NP (PRP it)) (ADJP (DT all) (PRN (: --) (CC or) (RB perhaps) (PP (IN because) (PP (IN of) (NP (PRP it)) (ADVP (DT all))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all -- or perhaps because of it all" type="ADJP">
          <tokens>
            <token id="9" string="all" />
            <token id="10" string="--" />
            <token id="11" string="or" />
            <token id="12" string="perhaps" />
            <token id="13" string="because" />
            <token id="14" string="of" />
            <token id="15" string="it" />
            <token id="16" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="His public" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="public" />
          </tokens>
        </chunking>
        <chunking id="3" string="spite" type="NP">
          <tokens>
            <token id="6" string="spite" />
          </tokens>
        </chunking>
        <chunking id="4" string="spite of it all -- or perhaps because of it all" type="NP">
          <tokens>
            <token id="6" string="spite" />
            <token id="7" string="of" />
            <token id="8" string="it" />
            <token id="9" string="all" />
            <token id="10" string="--" />
            <token id="11" string="or" />
            <token id="12" string="perhaps" />
            <token id="13" string="because" />
            <token id="14" string="of" />
            <token id="15" string="it" />
            <token id="16" string="all" />
          </tokens>
        </chunking>
        <chunking id="5" string="it all -- or perhaps because of it all" type="NP">
          <tokens>
            <token id="8" string="it" />
            <token id="9" string="all" />
            <token id="10" string="--" />
            <token id="11" string="or" />
            <token id="12" string="perhaps" />
            <token id="13" string="because" />
            <token id="14" string="of" />
            <token id="15" string="it" />
            <token id="16" string="all" />
          </tokens>
        </chunking>
        <chunking id="6" string="loved him in spite of it all -- or perhaps because of it all" type="VP">
          <tokens>
            <token id="3" string="loved" />
            <token id="4" string="him" />
            <token id="5" string="in" />
            <token id="6" string="spite" />
            <token id="7" string="of" />
            <token id="8" string="it" />
            <token id="9" string="all" />
            <token id="10" string="--" />
            <token id="11" string="or" />
            <token id="12" string="perhaps" />
            <token id="13" string="because" />
            <token id="14" string="of" />
            <token id="15" string="it" />
            <token id="16" string="all" />
          </tokens>
        </chunking>
        <chunking id="7" string="him" type="NP">
          <tokens>
            <token id="4" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="8" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">public</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">loved</governor>
          <dependent id="2">public</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">loved</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">loved</governor>
          <dependent id="4">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">it</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="5">in</governor>
          <dependent id="6">spite</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="5">in</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">loved</governor>
          <dependent id="8">it</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">it</governor>
          <dependent id="9">all</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">it</governor>
          <dependent id="11">or</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">it</governor>
          <dependent id="12">perhaps</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">it</governor>
          <dependent id="13">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">it</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">all</governor>
          <dependent id="15">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">it</governor>
          <dependent id="16">all</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Mr. Lennon grew to celebrity during a time when such transgressions as intemperance and adultery (quaint terms!)</content>
      <tokens>
        <token id="1" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="grew" lemma="grow" stem="grew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="celebrity" lemma="celebrity" stem="celebr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="transgressions" lemma="transgression" stem="transgress" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="intemperance" lemma="intemperance" stem="intemper" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="adultery" lemma="adultery" stem="adulteri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="quaint" lemma="quaint" stem="quaint" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="terms" lemma="term" stem="term" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="!" lemma="!" stem="!" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Mr.) (NNP Lennon)) (VP (VBD grew) (PP (TO to) (NP (NN celebrity))) (PP (IN during) (NP (NP (DT a) (NN time)) (SBAR (WHADVP (WRB when)) (S (NP (JJ such) (NNS transgressions)) (PP (IN as) (NP (NN intemperance) (CC and) (NN adultery))))))) (PRN (-LRB- -LRB-) (FRAG (NP (JJ quaint) (NNS terms)) (. !)) (-RRB- -RRB-)))))</syntactictree>
      <chunkings>
        <chunking id="1" string="celebrity" type="NP">
          <tokens>
            <token id="5" string="celebrity" />
          </tokens>
        </chunking>
        <chunking id="2" string="a time" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="intemperance and adultery" type="NP">
          <tokens>
            <token id="13" string="intemperance" />
            <token id="14" string="and" />
            <token id="15" string="adultery" />
          </tokens>
        </chunking>
        <chunking id="4" string="a time when such transgressions as intemperance and adultery" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="time" />
            <token id="9" string="when" />
            <token id="10" string="such" />
            <token id="11" string="transgressions" />
            <token id="12" string="as" />
            <token id="13" string="intemperance" />
            <token id="14" string="and" />
            <token id="15" string="adultery" />
          </tokens>
        </chunking>
        <chunking id="5" string="such transgressions" type="NP">
          <tokens>
            <token id="10" string="such" />
            <token id="11" string="transgressions" />
          </tokens>
        </chunking>
        <chunking id="6" string="when" type="WHADVP">
          <tokens>
            <token id="9" string="when" />
          </tokens>
        </chunking>
        <chunking id="7" string="quaint terms" type="NP">
          <tokens>
            <token id="17" string="quaint" />
            <token id="18" string="terms" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mr. Lennon" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="9" string="grew to celebrity during a time when such transgressions as intemperance and adultery -LRB- quaint terms ! -RRB-" type="VP">
          <tokens>
            <token id="3" string="grew" />
            <token id="4" string="to" />
            <token id="5" string="celebrity" />
            <token id="6" string="during" />
            <token id="7" string="a" />
            <token id="8" string="time" />
            <token id="9" string="when" />
            <token id="10" string="such" />
            <token id="11" string="transgressions" />
            <token id="12" string="as" />
            <token id="13" string="intemperance" />
            <token id="14" string="and" />
            <token id="15" string="adultery" />
            <token id="16" string="(" />
            <token id="17" string="quaint" />
            <token id="18" string="terms" />
            <token id="19" string="!" />
            <token id="20" string=")" />
          </tokens>
        </chunking>
        <chunking id="10" string="when such transgressions as intemperance and adultery" type="SBAR">
          <tokens>
            <token id="9" string="when" />
            <token id="10" string="such" />
            <token id="11" string="transgressions" />
            <token id="12" string="as" />
            <token id="13" string="intemperance" />
            <token id="14" string="and" />
            <token id="15" string="adultery" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Lennon</governor>
          <dependent id="1">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">grew</governor>
          <dependent id="2">Lennon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">grew</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">celebrity</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">grew</governor>
          <dependent id="5">celebrity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">time</governor>
          <dependent id="6">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">time</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">grew</governor>
          <dependent id="8">time</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">transgressions</governor>
          <dependent id="9">when</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">transgressions</governor>
          <dependent id="10">such</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">time</governor>
          <dependent id="11">transgressions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">intemperance</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">transgressions</governor>
          <dependent id="13">intemperance</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">intemperance</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">intemperance</governor>
          <dependent id="15">adultery</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">terms</governor>
          <dependent id="17">quaint</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">grew</governor>
          <dependent id="18">terms</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>were losing their social sting.</content>
      <tokens>
        <token id="1" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="losing" lemma="lose" stem="lose" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="social" lemma="social" stem="social" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="sting" lemma="sting" stem="sting" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VBD were) (VP (VBG losing) (NP (PRP$ their) (JJ social) (NN sting)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="losing their social sting" type="VP">
          <tokens>
            <token id="2" string="losing" />
            <token id="3" string="their" />
            <token id="4" string="social" />
            <token id="5" string="sting" />
          </tokens>
        </chunking>
        <chunking id="2" string="their social sting" type="NP">
          <tokens>
            <token id="3" string="their" />
            <token id="4" string="social" />
            <token id="5" string="sting" />
          </tokens>
        </chunking>
        <chunking id="3" string="were losing their social sting" type="VP">
          <tokens>
            <token id="1" string="were" />
            <token id="2" string="losing" />
            <token id="3" string="their" />
            <token id="4" string="social" />
            <token id="5" string="sting" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="aux">
          <governor id="2">losing</governor>
          <dependent id="1">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">losing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">sting</governor>
          <dependent id="3">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">sting</governor>
          <dependent id="4">social</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">losing</governor>
          <dependent id="5">sting</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>His candor -- if that&amp;apost;s what it was, and not simple logorrhea -- redeemed everything.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="2" string="candor" lemma="candor" stem="candor" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="simple" lemma="simple" stem="simpl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="logorrhea" lemma="logorrhea" stem="logorrhea" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="redeemed" lemma="redeem" stem="redeem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ His) (NN candor)) (PRN (: --) (SBAR (IN if) (S (NP (DT that)) (VP (VBZ 's) (SBAR (WHNP (WP what)) (S (NP (PRP it)) (VP (VP (VBD was)) (, ,) (CC and) (VP (RB not) (NP (JJ simple) (NN logorrhea))))))))) (: --))) (VP (VBD redeemed) (NP (NN everything))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="simple logorrhea" type="NP">
          <tokens>
            <token id="13" string="simple" />
            <token id="14" string="logorrhea" />
          </tokens>
        </chunking>
        <chunking id="2" string="His candor" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="candor" />
          </tokens>
        </chunking>
        <chunking id="3" string="redeemed everything" type="VP">
          <tokens>
            <token id="16" string="redeemed" />
            <token id="17" string="everything" />
          </tokens>
        </chunking>
        <chunking id="4" string="was , and not simple logorrhea" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="not" />
            <token id="13" string="simple" />
            <token id="14" string="logorrhea" />
          </tokens>
        </chunking>
        <chunking id="5" string="what it was , and not simple logorrhea" type="SBAR">
          <tokens>
            <token id="7" string="what" />
            <token id="8" string="it" />
            <token id="9" string="was" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="not" />
            <token id="13" string="simple" />
            <token id="14" string="logorrhea" />
          </tokens>
        </chunking>
        <chunking id="6" string="was" type="VP">
          <tokens>
            <token id="9" string="was" />
          </tokens>
        </chunking>
        <chunking id="7" string="His candor -- if that 's what it was , and not simple logorrhea --" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="candor" />
            <token id="3" string="--" />
            <token id="4" string="if" />
            <token id="5" string="that" />
            <token id="6" string="'s" />
            <token id="7" string="what" />
            <token id="8" string="it" />
            <token id="9" string="was" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="not" />
            <token id="13" string="simple" />
            <token id="14" string="logorrhea" />
            <token id="15" string="--" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="8" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="that" type="NP">
          <tokens>
            <token id="5" string="that" />
          </tokens>
        </chunking>
        <chunking id="10" string="if that 's what it was , and not simple logorrhea" type="SBAR">
          <tokens>
            <token id="4" string="if" />
            <token id="5" string="that" />
            <token id="6" string="'s" />
            <token id="7" string="what" />
            <token id="8" string="it" />
            <token id="9" string="was" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="not" />
            <token id="13" string="simple" />
            <token id="14" string="logorrhea" />
          </tokens>
        </chunking>
        <chunking id="11" string="not simple logorrhea" type="VP">
          <tokens>
            <token id="12" string="not" />
            <token id="13" string="simple" />
            <token id="14" string="logorrhea" />
          </tokens>
        </chunking>
        <chunking id="12" string="everything" type="NP">
          <tokens>
            <token id="17" string="everything" />
          </tokens>
        </chunking>
        <chunking id="13" string="'s what it was , and not simple logorrhea" type="VP">
          <tokens>
            <token id="6" string="'s" />
            <token id="7" string="what" />
            <token id="8" string="it" />
            <token id="9" string="was" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="not" />
            <token id="13" string="simple" />
            <token id="14" string="logorrhea" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">candor</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">redeemed</governor>
          <dependent id="2">candor</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">'s</governor>
          <dependent id="4">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">'s</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">candor</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">was</governor>
          <dependent id="7">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">was</governor>
          <dependent id="8">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">'s</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">was</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">logorrhea</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">logorrhea</governor>
          <dependent id="13">simple</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">was</governor>
          <dependent id="14">logorrhea</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">redeemed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">redeemed</governor>
          <dependent id="17">everything</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>And so it is on the grounds of insufficient candor that the resourceful Mr. Goldman, hot to debunk, attacks his subject.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="so" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="grounds" lemma="grounds" stem="ground" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="insufficient" lemma="insufficient" stem="insuffici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="candor" lemma="candor" stem="candor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="resourceful" lemma="resourceful" stem="resourc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="hot" lemma="hot" stem="hot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="debunk" lemma="debunk" stem="debunk" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="attacks" lemma="attack" stem="attack" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="22" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="subject" lemma="subject" stem="subject" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (CC And) (SBAR (IN so) (S (NP (PRP it)) (VP (VBZ is) (PP (IN on) (NP (NP (DT the) (NNS grounds)) (PP (IN of) (NP (NP (JJ insufficient) (NN candor)) (SBAR (IN that) (S (NP (DT the) (ADJP (JJ resourceful) (NP-TMP (NP (NNP Mr.) (NNP Goldman)) (, ,) (ADJP (JJ hot))))) (VP (TO to) (VP (VB debunk))))) (, ,) (NP (NP (NNS attacks)) (NP (PRP$ his) (NN subject)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the grounds" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="grounds" />
          </tokens>
        </chunking>
        <chunking id="2" string="his subject" type="NP">
          <tokens>
            <token id="22" string="his" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
        <chunking id="3" string="resourceful Mr. Goldman , hot" type="ADJP">
          <tokens>
            <token id="13" string="resourceful" />
            <token id="14" string="Mr." />
            <token id="15" string="Goldman" />
            <token id="16" string="," />
            <token id="17" string="hot" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="that the resourceful Mr. Goldman , hot to debunk" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="resourceful" />
            <token id="14" string="Mr." />
            <token id="15" string="Goldman" />
            <token id="16" string="," />
            <token id="17" string="hot" />
            <token id="18" string="to" />
            <token id="19" string="debunk" />
          </tokens>
        </chunking>
        <chunking id="6" string="insufficient candor" type="NP">
          <tokens>
            <token id="9" string="insufficient" />
            <token id="10" string="candor" />
          </tokens>
        </chunking>
        <chunking id="7" string="hot" type="ADJP">
          <tokens>
            <token id="17" string="hot" />
          </tokens>
        </chunking>
        <chunking id="8" string="the resourceful Mr. Goldman , hot" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="resourceful" />
            <token id="14" string="Mr." />
            <token id="15" string="Goldman" />
            <token id="16" string="," />
            <token id="17" string="hot" />
          </tokens>
        </chunking>
        <chunking id="9" string="debunk" type="VP">
          <tokens>
            <token id="19" string="debunk" />
          </tokens>
        </chunking>
        <chunking id="10" string="attacks his subject" type="NP">
          <tokens>
            <token id="21" string="attacks" />
            <token id="22" string="his" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
        <chunking id="11" string="so it is on the grounds of insufficient candor that the resourceful Mr. Goldman , hot to debunk , attacks his subject" type="SBAR">
          <tokens>
            <token id="2" string="so" />
            <token id="3" string="it" />
            <token id="4" string="is" />
            <token id="5" string="on" />
            <token id="6" string="the" />
            <token id="7" string="grounds" />
            <token id="8" string="of" />
            <token id="9" string="insufficient" />
            <token id="10" string="candor" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="resourceful" />
            <token id="14" string="Mr." />
            <token id="15" string="Goldman" />
            <token id="16" string="," />
            <token id="17" string="hot" />
            <token id="18" string="to" />
            <token id="19" string="debunk" />
            <token id="20" string="," />
            <token id="21" string="attacks" />
            <token id="22" string="his" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
        <chunking id="12" string="attacks" type="NP">
          <tokens>
            <token id="21" string="attacks" />
          </tokens>
        </chunking>
        <chunking id="13" string="is on the grounds of insufficient candor that the resourceful Mr. Goldman , hot to debunk , attacks his subject" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="on" />
            <token id="6" string="the" />
            <token id="7" string="grounds" />
            <token id="8" string="of" />
            <token id="9" string="insufficient" />
            <token id="10" string="candor" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="resourceful" />
            <token id="14" string="Mr." />
            <token id="15" string="Goldman" />
            <token id="16" string="," />
            <token id="17" string="hot" />
            <token id="18" string="to" />
            <token id="19" string="debunk" />
            <token id="20" string="," />
            <token id="21" string="attacks" />
            <token id="22" string="his" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
        <chunking id="14" string="Mr. Goldman" type="NP">
          <tokens>
            <token id="14" string="Mr." />
            <token id="15" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="15" string="to debunk" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="debunk" />
          </tokens>
        </chunking>
        <chunking id="16" string="the grounds of insufficient candor that the resourceful Mr. Goldman , hot to debunk , attacks his subject" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="grounds" />
            <token id="8" string="of" />
            <token id="9" string="insufficient" />
            <token id="10" string="candor" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="resourceful" />
            <token id="14" string="Mr." />
            <token id="15" string="Goldman" />
            <token id="16" string="," />
            <token id="17" string="hot" />
            <token id="18" string="to" />
            <token id="19" string="debunk" />
            <token id="20" string="," />
            <token id="21" string="attacks" />
            <token id="22" string="his" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
        <chunking id="17" string="insufficient candor that the resourceful Mr. Goldman , hot to debunk , attacks his subject" type="NP">
          <tokens>
            <token id="9" string="insufficient" />
            <token id="10" string="candor" />
            <token id="11" string="that" />
            <token id="12" string="the" />
            <token id="13" string="resourceful" />
            <token id="14" string="Mr." />
            <token id="15" string="Goldman" />
            <token id="16" string="," />
            <token id="17" string="hot" />
            <token id="18" string="to" />
            <token id="19" string="debunk" />
            <token id="20" string="," />
            <token id="21" string="attacks" />
            <token id="22" string="his" />
            <token id="23" string="subject" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">grounds</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">grounds</governor>
          <dependent id="2">so</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">grounds</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">grounds</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">grounds</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">grounds</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">grounds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">candor</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">candor</governor>
          <dependent id="9">insufficient</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">grounds</governor>
          <dependent id="10">candor</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">debunk</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">resourceful</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">debunk</governor>
          <dependent id="13">resourceful</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Goldman</governor>
          <dependent id="14">Mr.</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">resourceful</governor>
          <dependent id="15">Goldman</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">Goldman</governor>
          <dependent id="17">hot</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">debunk</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">candor</governor>
          <dependent id="19">debunk</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">candor</governor>
          <dependent id="21">attacks</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">subject</governor>
          <dependent id="22">his</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">attacks</governor>
          <dependent id="23">subject</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="attacks" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="21" string="attacks" />
          </tokens>
        </entity>
        <entity id="2" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>The leitmotif of Mr. Lennon&amp;apost;s confessions was that his worst days were behind him, and that with Yoko Ono he had at last learned to prize the virtues of quietude and domesticity.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="leitmotif" lemma="leitmotif" stem="leitmotif" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="confessions" lemma="confession" stem="confess" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="worst" lemma="worst" stem="worst" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="behind" lemma="behind" stem="behind" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="learned" lemma="learn" stem="learn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="prize" lemma="prize" stem="prize" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="virtues" lemma="virtue" stem="virtu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="quietude" lemma="quietude" stem="quietud" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="domesticity" lemma="domesticity" stem="domest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NP (DT The) (NN leitmotif)) (PP (IN of) (NP (NP (NNP Mr.) (NNP Lennon) (POS 's)) (NNS confessions)))) (VP (VBD was) (SBAR (SBAR (IN that) (S (NP (PRP$ his) (JJS worst) (NNS days)) (VP (VBD were) (PP (IN behind) (NP (PRP him)))))) (, ,) (CC and) (SBAR (IN that) (S (PP (IN with) (NP (NNP Yoko) (NNP Ono))) (NP (PRP he)) (VP (VBD had) (PP (IN at) (NP (JJ last))))))))) (VP (VBD learned) (PP (TO to) (NP (NN prize)))) (NP (NP (DT the) (NNS virtues)) (PP (IN of) (NP (NN quietude) (CC and) (NN domesticity)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that his worst days were behind him" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="his" />
            <token id="11" string="worst" />
            <token id="12" string="days" />
            <token id="13" string="were" />
            <token id="14" string="behind" />
            <token id="15" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="quietude and domesticity" type="NP">
          <tokens>
            <token id="32" string="quietude" />
            <token id="33" string="and" />
            <token id="34" string="domesticity" />
          </tokens>
        </chunking>
        <chunking id="3" string="The leitmotif" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="leitmotif" />
          </tokens>
        </chunking>
        <chunking id="4" string="last" type="NP">
          <tokens>
            <token id="25" string="last" />
          </tokens>
        </chunking>
        <chunking id="5" string="his worst days" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="worst" />
            <token id="12" string="days" />
          </tokens>
        </chunking>
        <chunking id="6" string="learned to prize" type="VP">
          <tokens>
            <token id="26" string="learned" />
            <token id="27" string="to" />
            <token id="28" string="prize" />
          </tokens>
        </chunking>
        <chunking id="7" string="the virtues of quietude and domesticity" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="virtues" />
            <token id="31" string="of" />
            <token id="32" string="quietude" />
            <token id="33" string="and" />
            <token id="34" string="domesticity" />
          </tokens>
        </chunking>
        <chunking id="8" string="him" type="NP">
          <tokens>
            <token id="15" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="had at last" type="VP">
          <tokens>
            <token id="23" string="had" />
            <token id="24" string="at" />
            <token id="25" string="last" />
          </tokens>
        </chunking>
        <chunking id="10" string="prize" type="NP">
          <tokens>
            <token id="28" string="prize" />
          </tokens>
        </chunking>
        <chunking id="11" string="that with Yoko Ono he had at last" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="with" />
            <token id="20" string="Yoko" />
            <token id="21" string="Ono" />
            <token id="22" string="he" />
            <token id="23" string="had" />
            <token id="24" string="at" />
            <token id="25" string="last" />
          </tokens>
        </chunking>
        <chunking id="12" string="was that his worst days were behind him , and that with Yoko Ono he had at last" type="VP">
          <tokens>
            <token id="8" string="was" />
            <token id="9" string="that" />
            <token id="10" string="his" />
            <token id="11" string="worst" />
            <token id="12" string="days" />
            <token id="13" string="were" />
            <token id="14" string="behind" />
            <token id="15" string="him" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="that" />
            <token id="19" string="with" />
            <token id="20" string="Yoko" />
            <token id="21" string="Ono" />
            <token id="22" string="he" />
            <token id="23" string="had" />
            <token id="24" string="at" />
            <token id="25" string="last" />
          </tokens>
        </chunking>
        <chunking id="13" string="that his worst days were behind him , and that with Yoko Ono he had at last" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="his" />
            <token id="11" string="worst" />
            <token id="12" string="days" />
            <token id="13" string="were" />
            <token id="14" string="behind" />
            <token id="15" string="him" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="that" />
            <token id="19" string="with" />
            <token id="20" string="Yoko" />
            <token id="21" string="Ono" />
            <token id="22" string="he" />
            <token id="23" string="had" />
            <token id="24" string="at" />
            <token id="25" string="last" />
          </tokens>
        </chunking>
        <chunking id="14" string="were behind him" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="behind" />
            <token id="15" string="him" />
          </tokens>
        </chunking>
        <chunking id="15" string="Mr. Lennon 's confessions" type="NP">
          <tokens>
            <token id="4" string="Mr." />
            <token id="5" string="Lennon" />
            <token id="6" string="'s" />
            <token id="7" string="confessions" />
          </tokens>
        </chunking>
        <chunking id="16" string="The leitmotif of Mr. Lennon 's confessions" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="leitmotif" />
            <token id="3" string="of" />
            <token id="4" string="Mr." />
            <token id="5" string="Lennon" />
            <token id="6" string="'s" />
            <token id="7" string="confessions" />
          </tokens>
        </chunking>
        <chunking id="17" string="Yoko Ono" type="NP">
          <tokens>
            <token id="20" string="Yoko" />
            <token id="21" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="18" string="the virtues" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="virtues" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="22" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="Mr. Lennon 's" type="NP">
          <tokens>
            <token id="4" string="Mr." />
            <token id="5" string="Lennon" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">leitmotif</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">was</governor>
          <dependent id="2">leitmotif</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">confessions</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Lennon</governor>
          <dependent id="4">Mr.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">confessions</governor>
          <dependent id="5">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Lennon</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">leitmotif</governor>
          <dependent id="7">confessions</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="26">learned</governor>
          <dependent id="8">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">him</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">days</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">days</governor>
          <dependent id="11">worst</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">him</governor>
          <dependent id="12">days</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">him</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">him</governor>
          <dependent id="14">behind</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">was</governor>
          <dependent id="15">him</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">him</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">had</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Ono</governor>
          <dependent id="19">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Ono</governor>
          <dependent id="20">Yoko</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">had</governor>
          <dependent id="21">Ono</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">had</governor>
          <dependent id="22">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">him</governor>
          <dependent id="23">had</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">last</governor>
          <dependent id="24">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">had</governor>
          <dependent id="25">last</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">learned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">prize</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">learned</governor>
          <dependent id="28">prize</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">virtues</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">learned</governor>
          <dependent id="30">virtues</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">quietude</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">virtues</governor>
          <dependent id="32">quietude</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">quietude</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">quietude</governor>
          <dependent id="34">domesticity</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Yoko Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Yoko" />
            <token id="21" string="Ono" />
          </tokens>
        </entity>
        <entity id="3" string="days" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="days" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Now Mr. Goldman is here to announce: He didn&amp;apost;t tell you the half of it.</content>
      <tokens>
        <token id="1" string="Now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="announce" lemma="announce" stem="announc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="tell" lemma="tell" stem="tell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="half" lemma="half" stem="half" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Now)) (NP (NNP Mr.) (NNP Goldman)) (VP (VBZ is) (ADVP (RB here)) (S (VP (TO to) (VP (VB announce)))))) (: :) (S (NP (PRP He)) (VP (VBD did) (RB n't) (VP (VB tell) (NP (PRP you)) (NP (NP (DT the) (NN half)) (PP (IN of) (NP (PRP it))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is here to announce" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="here" />
            <token id="6" string="to" />
            <token id="7" string="announce" />
          </tokens>
        </chunking>
        <chunking id="2" string="tell you the half of it" type="VP">
          <tokens>
            <token id="12" string="tell" />
            <token id="13" string="you" />
            <token id="14" string="the" />
            <token id="15" string="half" />
            <token id="16" string="of" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="to announce" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="announce" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mr. Goldman" type="NP">
          <tokens>
            <token id="2" string="Mr." />
            <token id="3" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="He" type="NP">
          <tokens>
            <token id="9" string="He" />
          </tokens>
        </chunking>
        <chunking id="7" string="the half" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="half" />
          </tokens>
        </chunking>
        <chunking id="8" string="the half of it" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="half" />
            <token id="16" string="of" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="announce" type="VP">
          <tokens>
            <token id="7" string="announce" />
          </tokens>
        </chunking>
        <chunking id="10" string="did n't tell you the half of it" type="VP">
          <tokens>
            <token id="10" string="did" />
            <token id="11" string="n't" />
            <token id="12" string="tell" />
            <token id="13" string="you" />
            <token id="14" string="the" />
            <token id="15" string="half" />
            <token id="16" string="of" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="you" type="NP">
          <tokens>
            <token id="13" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">is</governor>
          <dependent id="1">Now</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Goldman</governor>
          <dependent id="2">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">is</governor>
          <dependent id="3">Goldman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">is</governor>
          <dependent id="5">here</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">announce</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">is</governor>
          <dependent id="7">announce</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">tell</governor>
          <dependent id="9">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">tell</governor>
          <dependent id="10">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">tell</governor>
          <dependent id="11">n't</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">is</governor>
          <dependent id="12">tell</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="12">tell</governor>
          <dependent id="13">you</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">half</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">tell</governor>
          <dependent id="15">half</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">it</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">half</governor>
          <dependent id="17">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Now" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Now" />
          </tokens>
        </entity>
        <entity id="2" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>Hence this 718-page stew of unrelieved sordidness, percolating with the &amp;quot;scoops&amp;quot; that have by now been widely publicized in People magazine, &amp;quot;West 57th&amp;quot; and other scholarly venues: that Mr. Lennon had a thing for young boys; that his marriage to Ms. Ono was pocked by the same faithlessness and rancor that characterized his first marriage; that he had a sweet tooth that just wouldn&amp;apost;t quit.</content>
      <tokens>
        <token id="1" string="Hence" lemma="hence" stem="henc" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="718-page" lemma="718-page" stem="718-page" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="stew" lemma="stew" stem="stew" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="unrelieved" lemma="unrelieved" stem="unreliev" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="sordidness" lemma="sordidness" stem="sordid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="percolating" lemma="percolate" stem="percol" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="scoops" lemma="scoop" stem="scoop" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="widely" lemma="widely" stem="wide" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="publicized" lemma="publicize" stem="public" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="West" lemma="West" stem="west" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="57th" lemma="57th" stem="57th" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="29" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="scholarly" lemma="scholarly" stem="scholarli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="venues" lemma="venue" stem="venu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="38" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="boys" lemma="boy" stem="boi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="50" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="51" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="pocked" lemma="pock" stem="pock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="same" lemma="same" stem="same" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="56" string="faithlessness" lemma="faithlessness" stem="faithless" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="rancor" lemma="rancor" stem="rancor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="59" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="60" string="characterized" lemma="characterize" stem="character" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="61" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="63" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="64" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="65" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="66" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="67" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="68" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="69" string="sweet" lemma="sweet" stem="sweet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="70" string="tooth" lemma="tooth" stem="tooth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="71" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="72" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="73" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="74" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="75" string="quit" lemma="quit" stem="quit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="76" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (ADVP (RB Hence)) (NP (NP (DT this) (JJ 718-page) (NN stew)) (PP (IN of) (NP (NP (JJ unrelieved) (NN sordidness)) (, ,) (VP (VBG percolating) (SBAR (IN with) (S (NP (DT the)) (VP (`` ``) (VBZ scoops) ('' '')))) (SBAR (SBAR (WHNP (WDT that)) (S (VP (VBP have) (PP (IN by) (NP (RB now))) (VP (VBN been) (ADJP (RB widely) (VBN publicized) (PP (IN in) (NP (NP (NNS People) (NN magazine)) (, ,) (`` ``) (NP (NP (NP (NNP West)) (NP (JJ 57th))) ('' '') (CC and) (NP (JJ other) (JJ scholarly) (NNS venues))) (: :))) (SBAR (IN that) (S (NP (NNP Mr.) (NNP Lennon)) (VP (VBD had) (NP (NP (DT a) (NN thing)) (PP (IN for) (NP (JJ young) (NNS boys)))))))))))) (: ;) (SBAR (IN that) (S (NP (NP (PRP$ his) (NN marriage)) (PP (TO to) (NP (NNP Ms.) (NNP Ono)))) (VP (VBD was) (VP (VBN pocked) (PP (IN by) (NP (NP (DT the) (JJ same) (NN faithlessness) (CC and) (NN rancor)) (SBAR (WHNP (WDT that)) (S (VP (VBD characterized) (NP (PRP$ his) (JJ first) (NN marriage))))))))))) (: ;) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD had) (NP (NP (DT a) (JJ sweet) (NN tooth)) (SBAR (WHNP (WDT that)) (S (ADVP (RB just)) (VP (MD would) (RB n't) (VP (VB quit)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a thing for young boys" type="NP">
          <tokens>
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
          </tokens>
        </chunking>
        <chunking id="2" string="widely publicized in People magazine , `` West 57th '' and other scholarly venues : that Mr. Lennon had a thing for young boys" type="ADJP">
          <tokens>
            <token id="20" string="widely" />
            <token id="21" string="publicized" />
            <token id="22" string="in" />
            <token id="23" string="People" />
            <token id="24" string="magazine" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="West" />
            <token id="28" string="57th" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
            <token id="34" string=":" />
            <token id="35" string="that" />
            <token id="36" string="Mr." />
            <token id="37" string="Lennon" />
            <token id="38" string="had" />
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
          </tokens>
        </chunking>
        <chunking id="3" string="West" type="NP">
          <tokens>
            <token id="27" string="West" />
          </tokens>
        </chunking>
        <chunking id="4" string="People magazine" type="NP">
          <tokens>
            <token id="23" string="People" />
            <token id="24" string="magazine" />
          </tokens>
        </chunking>
        <chunking id="5" string="was pocked by the same faithlessness and rancor that characterized his first marriage" type="VP">
          <tokens>
            <token id="51" string="was" />
            <token id="52" string="pocked" />
            <token id="53" string="by" />
            <token id="54" string="the" />
            <token id="55" string="same" />
            <token id="56" string="faithlessness" />
            <token id="57" string="and" />
            <token id="58" string="rancor" />
            <token id="59" string="that" />
            <token id="60" string="characterized" />
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="6" string="pocked by the same faithlessness and rancor that characterized his first marriage" type="VP">
          <tokens>
            <token id="52" string="pocked" />
            <token id="53" string="by" />
            <token id="54" string="the" />
            <token id="55" string="same" />
            <token id="56" string="faithlessness" />
            <token id="57" string="and" />
            <token id="58" string="rancor" />
            <token id="59" string="that" />
            <token id="60" string="characterized" />
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="7" string="Mr. Lennon" type="NP">
          <tokens>
            <token id="36" string="Mr." />
            <token id="37" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="8" string="unrelieved sordidness" type="NP">
          <tokens>
            <token id="6" string="unrelieved" />
            <token id="7" string="sordidness" />
          </tokens>
        </chunking>
        <chunking id="9" string="percolating with the `` scoops '' that have by now been widely publicized in People magazine , `` West 57th '' and other scholarly venues : that Mr. Lennon had a thing for young boys ; that his marriage to Ms. Ono was pocked by the same faithlessness and rancor that characterized his first marriage ; that he had a sweet tooth that just would n't quit" type="VP">
          <tokens>
            <token id="9" string="percolating" />
            <token id="10" string="with" />
            <token id="11" string="the" />
            <token id="12" string="&quot;" />
            <token id="13" string="scoops" />
            <token id="14" string="&quot;" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="by" />
            <token id="18" string="now" />
            <token id="19" string="been" />
            <token id="20" string="widely" />
            <token id="21" string="publicized" />
            <token id="22" string="in" />
            <token id="23" string="People" />
            <token id="24" string="magazine" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="West" />
            <token id="28" string="57th" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
            <token id="34" string=":" />
            <token id="35" string="that" />
            <token id="36" string="Mr." />
            <token id="37" string="Lennon" />
            <token id="38" string="had" />
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
            <token id="44" string=";" />
            <token id="45" string="that" />
            <token id="46" string="his" />
            <token id="47" string="marriage" />
            <token id="48" string="to" />
            <token id="49" string="Ms." />
            <token id="50" string="Ono" />
            <token id="51" string="was" />
            <token id="52" string="pocked" />
            <token id="53" string="by" />
            <token id="54" string="the" />
            <token id="55" string="same" />
            <token id="56" string="faithlessness" />
            <token id="57" string="and" />
            <token id="58" string="rancor" />
            <token id="59" string="that" />
            <token id="60" string="characterized" />
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
            <token id="64" string=";" />
            <token id="65" string="that" />
            <token id="66" string="he" />
            <token id="67" string="had" />
            <token id="68" string="a" />
            <token id="69" string="sweet" />
            <token id="70" string="tooth" />
            <token id="71" string="that" />
            <token id="72" string="just" />
            <token id="73" string="would" />
            <token id="74" string="n't" />
            <token id="75" string="quit" />
          </tokens>
        </chunking>
        <chunking id="10" string="that have by now been widely publicized in People magazine , `` West 57th '' and other scholarly venues : that Mr. Lennon had a thing for young boys" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="by" />
            <token id="18" string="now" />
            <token id="19" string="been" />
            <token id="20" string="widely" />
            <token id="21" string="publicized" />
            <token id="22" string="in" />
            <token id="23" string="People" />
            <token id="24" string="magazine" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="West" />
            <token id="28" string="57th" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
            <token id="34" string=":" />
            <token id="35" string="that" />
            <token id="36" string="Mr." />
            <token id="37" string="Lennon" />
            <token id="38" string="had" />
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
          </tokens>
        </chunking>
        <chunking id="11" string="the" type="NP">
          <tokens>
            <token id="11" string="the" />
          </tokens>
        </chunking>
        <chunking id="12" string="People magazine , `` West 57th '' and other scholarly venues :" type="NP">
          <tokens>
            <token id="23" string="People" />
            <token id="24" string="magazine" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="West" />
            <token id="28" string="57th" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
            <token id="34" string=":" />
          </tokens>
        </chunking>
        <chunking id="13" string="`` scoops ''" type="VP">
          <tokens>
            <token id="12" string="&quot;" />
            <token id="13" string="scoops" />
            <token id="14" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="14" string="that his marriage to Ms. Ono was pocked by the same faithlessness and rancor that characterized his first marriage" type="SBAR">
          <tokens>
            <token id="45" string="that" />
            <token id="46" string="his" />
            <token id="47" string="marriage" />
            <token id="48" string="to" />
            <token id="49" string="Ms." />
            <token id="50" string="Ono" />
            <token id="51" string="was" />
            <token id="52" string="pocked" />
            <token id="53" string="by" />
            <token id="54" string="the" />
            <token id="55" string="same" />
            <token id="56" string="faithlessness" />
            <token id="57" string="and" />
            <token id="58" string="rancor" />
            <token id="59" string="that" />
            <token id="60" string="characterized" />
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="15" string="that Mr. Lennon had a thing for young boys" type="SBAR">
          <tokens>
            <token id="35" string="that" />
            <token id="36" string="Mr." />
            <token id="37" string="Lennon" />
            <token id="38" string="had" />
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
          </tokens>
        </chunking>
        <chunking id="16" string="characterized his first marriage" type="VP">
          <tokens>
            <token id="60" string="characterized" />
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="17" string="that just would n't quit" type="SBAR">
          <tokens>
            <token id="71" string="that" />
            <token id="72" string="just" />
            <token id="73" string="would" />
            <token id="74" string="n't" />
            <token id="75" string="quit" />
          </tokens>
        </chunking>
        <chunking id="18" string="his marriage" type="NP">
          <tokens>
            <token id="46" string="his" />
            <token id="47" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="19" string="that he had a sweet tooth that just would n't quit" type="SBAR">
          <tokens>
            <token id="65" string="that" />
            <token id="66" string="he" />
            <token id="67" string="had" />
            <token id="68" string="a" />
            <token id="69" string="sweet" />
            <token id="70" string="tooth" />
            <token id="71" string="that" />
            <token id="72" string="just" />
            <token id="73" string="would" />
            <token id="74" string="n't" />
            <token id="75" string="quit" />
          </tokens>
        </chunking>
        <chunking id="20" string="this 718-page stew of unrelieved sordidness , percolating with the `` scoops '' that have by now been widely publicized in People magazine , `` West 57th '' and other scholarly venues : that Mr. Lennon had a thing for young boys ; that his marriage to Ms. Ono was pocked by the same faithlessness and rancor that characterized his first marriage ; that he had a sweet tooth that just would n't quit" type="NP">
          <tokens>
            <token id="2" string="this" />
            <token id="3" string="718-page" />
            <token id="4" string="stew" />
            <token id="5" string="of" />
            <token id="6" string="unrelieved" />
            <token id="7" string="sordidness" />
            <token id="8" string="," />
            <token id="9" string="percolating" />
            <token id="10" string="with" />
            <token id="11" string="the" />
            <token id="12" string="&quot;" />
            <token id="13" string="scoops" />
            <token id="14" string="&quot;" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="by" />
            <token id="18" string="now" />
            <token id="19" string="been" />
            <token id="20" string="widely" />
            <token id="21" string="publicized" />
            <token id="22" string="in" />
            <token id="23" string="People" />
            <token id="24" string="magazine" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="West" />
            <token id="28" string="57th" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
            <token id="34" string=":" />
            <token id="35" string="that" />
            <token id="36" string="Mr." />
            <token id="37" string="Lennon" />
            <token id="38" string="had" />
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
            <token id="44" string=";" />
            <token id="45" string="that" />
            <token id="46" string="his" />
            <token id="47" string="marriage" />
            <token id="48" string="to" />
            <token id="49" string="Ms." />
            <token id="50" string="Ono" />
            <token id="51" string="was" />
            <token id="52" string="pocked" />
            <token id="53" string="by" />
            <token id="54" string="the" />
            <token id="55" string="same" />
            <token id="56" string="faithlessness" />
            <token id="57" string="and" />
            <token id="58" string="rancor" />
            <token id="59" string="that" />
            <token id="60" string="characterized" />
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
            <token id="64" string=";" />
            <token id="65" string="that" />
            <token id="66" string="he" />
            <token id="67" string="had" />
            <token id="68" string="a" />
            <token id="69" string="sweet" />
            <token id="70" string="tooth" />
            <token id="71" string="that" />
            <token id="72" string="just" />
            <token id="73" string="would" />
            <token id="74" string="n't" />
            <token id="75" string="quit" />
          </tokens>
        </chunking>
        <chunking id="21" string="quit" type="VP">
          <tokens>
            <token id="75" string="quit" />
          </tokens>
        </chunking>
        <chunking id="22" string="the same faithlessness and rancor" type="NP">
          <tokens>
            <token id="54" string="the" />
            <token id="55" string="same" />
            <token id="56" string="faithlessness" />
            <token id="57" string="and" />
            <token id="58" string="rancor" />
          </tokens>
        </chunking>
        <chunking id="23" string="he" type="NP">
          <tokens>
            <token id="66" string="he" />
          </tokens>
        </chunking>
        <chunking id="24" string="with the `` scoops ''" type="SBAR">
          <tokens>
            <token id="10" string="with" />
            <token id="11" string="the" />
            <token id="12" string="&quot;" />
            <token id="13" string="scoops" />
            <token id="14" string="&quot;" />
          </tokens>
        </chunking>
        <chunking id="25" string="other scholarly venues" type="NP">
          <tokens>
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
          </tokens>
        </chunking>
        <chunking id="26" string="the same faithlessness and rancor that characterized his first marriage" type="NP">
          <tokens>
            <token id="54" string="the" />
            <token id="55" string="same" />
            <token id="56" string="faithlessness" />
            <token id="57" string="and" />
            <token id="58" string="rancor" />
            <token id="59" string="that" />
            <token id="60" string="characterized" />
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="27" string="unrelieved sordidness , percolating with the `` scoops '' that have by now been widely publicized in People magazine , `` West 57th '' and other scholarly venues : that Mr. Lennon had a thing for young boys ; that his marriage to Ms. Ono was pocked by the same faithlessness and rancor that characterized his first marriage ; that he had a sweet tooth that just would n't quit" type="NP">
          <tokens>
            <token id="6" string="unrelieved" />
            <token id="7" string="sordidness" />
            <token id="8" string="," />
            <token id="9" string="percolating" />
            <token id="10" string="with" />
            <token id="11" string="the" />
            <token id="12" string="&quot;" />
            <token id="13" string="scoops" />
            <token id="14" string="&quot;" />
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="by" />
            <token id="18" string="now" />
            <token id="19" string="been" />
            <token id="20" string="widely" />
            <token id="21" string="publicized" />
            <token id="22" string="in" />
            <token id="23" string="People" />
            <token id="24" string="magazine" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="West" />
            <token id="28" string="57th" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
            <token id="34" string=":" />
            <token id="35" string="that" />
            <token id="36" string="Mr." />
            <token id="37" string="Lennon" />
            <token id="38" string="had" />
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
            <token id="44" string=";" />
            <token id="45" string="that" />
            <token id="46" string="his" />
            <token id="47" string="marriage" />
            <token id="48" string="to" />
            <token id="49" string="Ms." />
            <token id="50" string="Ono" />
            <token id="51" string="was" />
            <token id="52" string="pocked" />
            <token id="53" string="by" />
            <token id="54" string="the" />
            <token id="55" string="same" />
            <token id="56" string="faithlessness" />
            <token id="57" string="and" />
            <token id="58" string="rancor" />
            <token id="59" string="that" />
            <token id="60" string="characterized" />
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
            <token id="64" string=";" />
            <token id="65" string="that" />
            <token id="66" string="he" />
            <token id="67" string="had" />
            <token id="68" string="a" />
            <token id="69" string="sweet" />
            <token id="70" string="tooth" />
            <token id="71" string="that" />
            <token id="72" string="just" />
            <token id="73" string="would" />
            <token id="74" string="n't" />
            <token id="75" string="quit" />
          </tokens>
        </chunking>
        <chunking id="28" string="Ms. Ono" type="NP">
          <tokens>
            <token id="49" string="Ms." />
            <token id="50" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="29" string="young boys" type="NP">
          <tokens>
            <token id="42" string="young" />
            <token id="43" string="boys" />
          </tokens>
        </chunking>
        <chunking id="30" string="that have by now been widely publicized in People magazine , `` West 57th '' and other scholarly venues : that Mr. Lennon had a thing for young boys ; that his marriage to Ms. Ono was pocked by the same faithlessness and rancor that characterized his first marriage ; that he had a sweet tooth that just would n't quit" type="SBAR">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="have" />
            <token id="17" string="by" />
            <token id="18" string="now" />
            <token id="19" string="been" />
            <token id="20" string="widely" />
            <token id="21" string="publicized" />
            <token id="22" string="in" />
            <token id="23" string="People" />
            <token id="24" string="magazine" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="West" />
            <token id="28" string="57th" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
            <token id="34" string=":" />
            <token id="35" string="that" />
            <token id="36" string="Mr." />
            <token id="37" string="Lennon" />
            <token id="38" string="had" />
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
            <token id="44" string=";" />
            <token id="45" string="that" />
            <token id="46" string="his" />
            <token id="47" string="marriage" />
            <token id="48" string="to" />
            <token id="49" string="Ms." />
            <token id="50" string="Ono" />
            <token id="51" string="was" />
            <token id="52" string="pocked" />
            <token id="53" string="by" />
            <token id="54" string="the" />
            <token id="55" string="same" />
            <token id="56" string="faithlessness" />
            <token id="57" string="and" />
            <token id="58" string="rancor" />
            <token id="59" string="that" />
            <token id="60" string="characterized" />
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
            <token id="64" string=";" />
            <token id="65" string="that" />
            <token id="66" string="he" />
            <token id="67" string="had" />
            <token id="68" string="a" />
            <token id="69" string="sweet" />
            <token id="70" string="tooth" />
            <token id="71" string="that" />
            <token id="72" string="just" />
            <token id="73" string="would" />
            <token id="74" string="n't" />
            <token id="75" string="quit" />
          </tokens>
        </chunking>
        <chunking id="31" string="a thing" type="NP">
          <tokens>
            <token id="39" string="a" />
            <token id="40" string="thing" />
          </tokens>
        </chunking>
        <chunking id="32" string="been widely publicized in People magazine , `` West 57th '' and other scholarly venues : that Mr. Lennon had a thing for young boys" type="VP">
          <tokens>
            <token id="19" string="been" />
            <token id="20" string="widely" />
            <token id="21" string="publicized" />
            <token id="22" string="in" />
            <token id="23" string="People" />
            <token id="24" string="magazine" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="West" />
            <token id="28" string="57th" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
            <token id="34" string=":" />
            <token id="35" string="that" />
            <token id="36" string="Mr." />
            <token id="37" string="Lennon" />
            <token id="38" string="had" />
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
          </tokens>
        </chunking>
        <chunking id="33" string="57th" type="NP">
          <tokens>
            <token id="28" string="57th" />
          </tokens>
        </chunking>
        <chunking id="34" string="his marriage to Ms. Ono" type="NP">
          <tokens>
            <token id="46" string="his" />
            <token id="47" string="marriage" />
            <token id="48" string="to" />
            <token id="49" string="Ms." />
            <token id="50" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="35" string="a sweet tooth that just would n't quit" type="NP">
          <tokens>
            <token id="68" string="a" />
            <token id="69" string="sweet" />
            <token id="70" string="tooth" />
            <token id="71" string="that" />
            <token id="72" string="just" />
            <token id="73" string="would" />
            <token id="74" string="n't" />
            <token id="75" string="quit" />
          </tokens>
        </chunking>
        <chunking id="36" string="a sweet tooth" type="NP">
          <tokens>
            <token id="68" string="a" />
            <token id="69" string="sweet" />
            <token id="70" string="tooth" />
          </tokens>
        </chunking>
        <chunking id="37" string="his first marriage" type="NP">
          <tokens>
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="38" string="would n't quit" type="VP">
          <tokens>
            <token id="73" string="would" />
            <token id="74" string="n't" />
            <token id="75" string="quit" />
          </tokens>
        </chunking>
        <chunking id="39" string="had a thing for young boys" type="VP">
          <tokens>
            <token id="38" string="had" />
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
          </tokens>
        </chunking>
        <chunking id="40" string="have by now been widely publicized in People magazine , `` West 57th '' and other scholarly venues : that Mr. Lennon had a thing for young boys" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="by" />
            <token id="18" string="now" />
            <token id="19" string="been" />
            <token id="20" string="widely" />
            <token id="21" string="publicized" />
            <token id="22" string="in" />
            <token id="23" string="People" />
            <token id="24" string="magazine" />
            <token id="25" string="," />
            <token id="26" string="&quot;" />
            <token id="27" string="West" />
            <token id="28" string="57th" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
            <token id="34" string=":" />
            <token id="35" string="that" />
            <token id="36" string="Mr." />
            <token id="37" string="Lennon" />
            <token id="38" string="had" />
            <token id="39" string="a" />
            <token id="40" string="thing" />
            <token id="41" string="for" />
            <token id="42" string="young" />
            <token id="43" string="boys" />
          </tokens>
        </chunking>
        <chunking id="41" string="now" type="NP">
          <tokens>
            <token id="18" string="now" />
          </tokens>
        </chunking>
        <chunking id="42" string="West 57th" type="NP">
          <tokens>
            <token id="27" string="West" />
            <token id="28" string="57th" />
          </tokens>
        </chunking>
        <chunking id="43" string="that characterized his first marriage" type="SBAR">
          <tokens>
            <token id="59" string="that" />
            <token id="60" string="characterized" />
            <token id="61" string="his" />
            <token id="62" string="first" />
            <token id="63" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="44" string="this 718-page stew" type="NP">
          <tokens>
            <token id="2" string="this" />
            <token id="3" string="718-page" />
            <token id="4" string="stew" />
          </tokens>
        </chunking>
        <chunking id="45" string="West 57th '' and other scholarly venues" type="NP">
          <tokens>
            <token id="27" string="West" />
            <token id="28" string="57th" />
            <token id="29" string="&quot;" />
            <token id="30" string="and" />
            <token id="31" string="other" />
            <token id="32" string="scholarly" />
            <token id="33" string="venues" />
          </tokens>
        </chunking>
        <chunking id="46" string="had a sweet tooth that just would n't quit" type="VP">
          <tokens>
            <token id="67" string="had" />
            <token id="68" string="a" />
            <token id="69" string="sweet" />
            <token id="70" string="tooth" />
            <token id="71" string="that" />
            <token id="72" string="just" />
            <token id="73" string="would" />
            <token id="74" string="n't" />
            <token id="75" string="quit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="4">stew</governor>
          <dependent id="1">Hence</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">stew</governor>
          <dependent id="2">this</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">stew</governor>
          <dependent id="3">718-page</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">stew</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">sordidness</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">sordidness</governor>
          <dependent id="6">unrelieved</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">stew</governor>
          <dependent id="7">sordidness</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">sordidness</governor>
          <dependent id="9">percolating</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">scoops</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">scoops</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">percolating</governor>
          <dependent id="13">scoops</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">publicized</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">publicized</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">now</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">publicized</governor>
          <dependent id="18">now</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">publicized</governor>
          <dependent id="19">been</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">publicized</governor>
          <dependent id="20">widely</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">percolating</governor>
          <dependent id="21">publicized</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">magazine</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">magazine</governor>
          <dependent id="23">People</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">publicized</governor>
          <dependent id="24">magazine</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">magazine</governor>
          <dependent id="27">West</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="27">West</governor>
          <dependent id="28">57th</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">West</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">venues</governor>
          <dependent id="31">other</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">venues</governor>
          <dependent id="32">scholarly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">West</governor>
          <dependent id="33">venues</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">had</governor>
          <dependent id="35">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Lennon</governor>
          <dependent id="36">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">had</governor>
          <dependent id="37">Lennon</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">publicized</governor>
          <dependent id="38">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">thing</governor>
          <dependent id="39">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">had</governor>
          <dependent id="40">thing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">boys</governor>
          <dependent id="41">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">boys</governor>
          <dependent id="42">young</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">thing</governor>
          <dependent id="43">boys</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="52">pocked</governor>
          <dependent id="45">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="47">marriage</governor>
          <dependent id="46">his</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="52">pocked</governor>
          <dependent id="47">marriage</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">Ono</governor>
          <dependent id="48">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="50">Ono</governor>
          <dependent id="49">Ms.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">marriage</governor>
          <dependent id="50">Ono</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="52">pocked</governor>
          <dependent id="51">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">publicized</governor>
          <dependent id="52">pocked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="56">faithlessness</governor>
          <dependent id="53">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="56">faithlessness</governor>
          <dependent id="54">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="56">faithlessness</governor>
          <dependent id="55">same</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="52">pocked</governor>
          <dependent id="56">faithlessness</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="56">faithlessness</governor>
          <dependent id="57">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="56">faithlessness</governor>
          <dependent id="58">rancor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="60">characterized</governor>
          <dependent id="59">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="56">faithlessness</governor>
          <dependent id="60">characterized</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="63">marriage</governor>
          <dependent id="61">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="63">marriage</governor>
          <dependent id="62">first</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="60">characterized</governor>
          <dependent id="63">marriage</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="67">had</governor>
          <dependent id="65">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="67">had</governor>
          <dependent id="66">he</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">publicized</governor>
          <dependent id="67">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="70">tooth</governor>
          <dependent id="68">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="70">tooth</governor>
          <dependent id="69">sweet</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="67">had</governor>
          <dependent id="70">tooth</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="75">quit</governor>
          <dependent id="71">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="75">quit</governor>
          <dependent id="72">just</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="75">quit</governor>
          <dependent id="73">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="75">quit</governor>
          <dependent id="74">n't</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="70">tooth</governor>
          <dependent id="75">quit</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="62" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="now" />
          </tokens>
        </entity>
        <entity id="3" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="37" string="Lennon" />
          </tokens>
        </entity>
        <entity id="4" string="57th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="28" string="57th" />
          </tokens>
        </entity>
        <entity id="5" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="50" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="false">
      <content>The squalid revelations dribble out like a chemical leak, sliming up every page.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="squalid" lemma="squalid" stem="squalid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="revelations" lemma="revelation" stem="revel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="dribble" lemma="dribble" stem="dribbl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="chemical" lemma="chemical" stem="chemic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="leak" lemma="leak" stem="leak" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="sliming" lemma="slime" stem="slime" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="page" lemma="page" stem="page" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ squalid) (NNS revelations)) (VP (NN dribble) (PP (RP out)) (PP (IN like) (NP (DT a) (NN chemical) (NN leak))) (, ,) (S (VP (VBG sliming) (PRT (RP up)) (NP (DT every) (NN page))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="every page" type="NP">
          <tokens>
            <token id="13" string="every" />
            <token id="14" string="page" />
          </tokens>
        </chunking>
        <chunking id="2" string="dribble out like a chemical leak , sliming up every page" type="VP">
          <tokens>
            <token id="4" string="dribble" />
            <token id="5" string="out" />
            <token id="6" string="like" />
            <token id="7" string="a" />
            <token id="8" string="chemical" />
            <token id="9" string="leak" />
            <token id="10" string="," />
            <token id="11" string="sliming" />
            <token id="12" string="up" />
            <token id="13" string="every" />
            <token id="14" string="page" />
          </tokens>
        </chunking>
        <chunking id="3" string="a chemical leak" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="chemical" />
            <token id="9" string="leak" />
          </tokens>
        </chunking>
        <chunking id="4" string="sliming up every page" type="VP">
          <tokens>
            <token id="11" string="sliming" />
            <token id="12" string="up" />
            <token id="13" string="every" />
            <token id="14" string="page" />
          </tokens>
        </chunking>
        <chunking id="5" string="The squalid revelations" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="squalid" />
            <token id="3" string="revelations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">revelations</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">revelations</governor>
          <dependent id="2">squalid</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">dribble</governor>
          <dependent id="3">revelations</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">dribble</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">dribble</governor>
          <dependent id="5">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">leak</governor>
          <dependent id="6">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">leak</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">leak</governor>
          <dependent id="8">chemical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">dribble</governor>
          <dependent id="9">leak</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">dribble</governor>
          <dependent id="11">sliming</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="11">sliming</governor>
          <dependent id="12">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">page</governor>
          <dependent id="13">every</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">sliming</governor>
          <dependent id="14">page</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Remarkably, then, the sleazemonger&amp;apost;s art has triumphed: Mr. Goldman&amp;apost;s John Lennon is even worse than John Lennon&amp;apost;s John Lennon.</content>
      <tokens>
        <token id="1" string="Remarkably" lemma="remarkably" stem="remark" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="sleazemonger" lemma="sleazemonger" stem="sleazemong" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="art" lemma="art" stem="art" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="triumphed" lemma="triumph" stem="triumph" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="worse" lemma="worse" stem="wors" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Remarkably)) (, ,) (S (ADVP (RB then)) (, ,) (NP (NP (DT the) (NN sleazemonger) (POS 's)) (NN art)) (VP (VBZ has) (VP (VBN triumphed)))) (: :) (S (NP (NP (NNP Mr.) (NNP Goldman) (POS 's)) (NNP John) (NNP Lennon)) (VP (VBZ is) (ADJP (ADJP (RB even) (JJR worse)) (PP (IN than) (NP (NP (NNP John) (NNP Lennon) (POS 's)) (NNP John) (NNP Lennon)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mr. Goldman 's John Lennon" type="NP">
          <tokens>
            <token id="12" string="Mr." />
            <token id="13" string="Goldman" />
            <token id="14" string="'s" />
            <token id="15" string="John" />
            <token id="16" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="2" string="even worse" type="ADJP">
          <tokens>
            <token id="18" string="even" />
            <token id="19" string="worse" />
          </tokens>
        </chunking>
        <chunking id="3" string="even worse than John Lennon 's John Lennon" type="ADJP">
          <tokens>
            <token id="18" string="even" />
            <token id="19" string="worse" />
            <token id="20" string="than" />
            <token id="21" string="John" />
            <token id="22" string="Lennon" />
            <token id="23" string="'s" />
            <token id="24" string="John" />
            <token id="25" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="4" string="has triumphed" type="VP">
          <tokens>
            <token id="9" string="has" />
            <token id="10" string="triumphed" />
          </tokens>
        </chunking>
        <chunking id="5" string="is even worse than John Lennon 's John Lennon" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="even" />
            <token id="19" string="worse" />
            <token id="20" string="than" />
            <token id="21" string="John" />
            <token id="22" string="Lennon" />
            <token id="23" string="'s" />
            <token id="24" string="John" />
            <token id="25" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="6" string="the sleazemonger 's art" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="sleazemonger" />
            <token id="7" string="'s" />
            <token id="8" string="art" />
          </tokens>
        </chunking>
        <chunking id="7" string="John Lennon 's John Lennon" type="NP">
          <tokens>
            <token id="21" string="John" />
            <token id="22" string="Lennon" />
            <token id="23" string="'s" />
            <token id="24" string="John" />
            <token id="25" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="8" string="the sleazemonger 's" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="sleazemonger" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="Mr. Goldman 's" type="NP">
          <tokens>
            <token id="12" string="Mr." />
            <token id="13" string="Goldman" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="triumphed" type="VP">
          <tokens>
            <token id="10" string="triumphed" />
          </tokens>
        </chunking>
        <chunking id="11" string="John Lennon 's" type="NP">
          <tokens>
            <token id="21" string="John" />
            <token id="22" string="Lennon" />
            <token id="23" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="10">triumphed</governor>
          <dependent id="1">Remarkably</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">triumphed</governor>
          <dependent id="3">then</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">sleazemonger</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">art</governor>
          <dependent id="6">sleazemonger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">sleazemonger</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">triumphed</governor>
          <dependent id="8">art</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">triumphed</governor>
          <dependent id="9">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">triumphed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Goldman</governor>
          <dependent id="12">Mr.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">Lennon</governor>
          <dependent id="13">Goldman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Goldman</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Lennon</governor>
          <dependent id="15">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">worse</governor>
          <dependent id="16">Lennon</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">worse</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">worse</governor>
          <dependent id="18">even</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="10">triumphed</governor>
          <dependent id="19">worse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Lennon</governor>
          <dependent id="20">than</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Lennon</governor>
          <dependent id="21">John</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">Lennon</governor>
          <dependent id="22">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Lennon</governor>
          <dependent id="23">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Lennon</governor>
          <dependent id="24">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">worse</governor>
          <dependent id="25">Lennon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="John" />
            <token id="16" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>A great deal of this muck manages to splash onto Ms. Ono, whom Mr. Goldman portrays as a cynical manipulator whose major talent lay in exploiting Mr. Lennon to further her own craving for fame and wealth.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="deal" lemma="deal" stem="deal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="muck" lemma="muck" stem="muck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="manages" lemma="manage" stem="manag" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="splash" lemma="splash" stem="splash" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="onto" lemma="onto" stem="onto" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="whom" lemma="whom" stem="whom" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="portrays" lemma="portray" stem="portrai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="cynical" lemma="cynical" stem="cynic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="manipulator" lemma="manipulator" stem="manipul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="talent" lemma="talent" stem="talent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="lay" lemma="lay" stem="lai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="exploiting" lemma="exploit" stem="exploit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="further" lemma="further" stem="further" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="craving" lemma="craving" stem="crave" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="fame" lemma="fame" stem="fame" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="wealth" lemma="wealth" stem="wealth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT A) (JJ great) (NN deal)) (PP (IN of) (NP (DT this) (NN muck)))) (VP (VBZ manages) (S (VP (TO to) (VP (VB splash) (PP (IN onto) (NP (NP (NNP Ms.) (NNP Ono)) (, ,) (SBAR (WHNP (WP whom)) (S (NP (NNP Mr.) (NNP Goldman)) (VP (VBZ portrays) (PP (IN as) (NP (NP (DT a) (JJ cynical) (NN manipulator)) (SBAR (WHNP (WP$ whose) (JJ major) (NN talent)) (S (VP (VBD lay) (PP (IN in) (S (VP (VBG exploiting) (S (NP (NNP Mr.) (NNP Lennon)) (VP (TO to) (VP (VB further) (NP (PRP$ her) (JJ own) (NN craving)) (PP (IN for) (NP (NN fame) (CC and) (NN wealth))))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="manages to splash onto Ms. Ono , whom Mr. Goldman portrays as a cynical manipulator whose major talent lay in exploiting Mr. Lennon to further her own craving for fame and wealth" type="VP">
          <tokens>
            <token id="7" string="manages" />
            <token id="8" string="to" />
            <token id="9" string="splash" />
            <token id="10" string="onto" />
            <token id="11" string="Ms." />
            <token id="12" string="Ono" />
            <token id="13" string="," />
            <token id="14" string="whom" />
            <token id="15" string="Mr." />
            <token id="16" string="Goldman" />
            <token id="17" string="portrays" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="cynical" />
            <token id="21" string="manipulator" />
            <token id="22" string="whose" />
            <token id="23" string="major" />
            <token id="24" string="talent" />
            <token id="25" string="lay" />
            <token id="26" string="in" />
            <token id="27" string="exploiting" />
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ms. Ono" type="NP">
          <tokens>
            <token id="11" string="Ms." />
            <token id="12" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="3" string="a cynical manipulator" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="cynical" />
            <token id="21" string="manipulator" />
          </tokens>
        </chunking>
        <chunking id="4" string="splash onto Ms. Ono , whom Mr. Goldman portrays as a cynical manipulator whose major talent lay in exploiting Mr. Lennon to further her own craving for fame and wealth" type="VP">
          <tokens>
            <token id="9" string="splash" />
            <token id="10" string="onto" />
            <token id="11" string="Ms." />
            <token id="12" string="Ono" />
            <token id="13" string="," />
            <token id="14" string="whom" />
            <token id="15" string="Mr." />
            <token id="16" string="Goldman" />
            <token id="17" string="portrays" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="cynical" />
            <token id="21" string="manipulator" />
            <token id="22" string="whose" />
            <token id="23" string="major" />
            <token id="24" string="talent" />
            <token id="25" string="lay" />
            <token id="26" string="in" />
            <token id="27" string="exploiting" />
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="5" string="whose major talent lay in exploiting Mr. Lennon to further her own craving for fame and wealth" type="SBAR">
          <tokens>
            <token id="22" string="whose" />
            <token id="23" string="major" />
            <token id="24" string="talent" />
            <token id="25" string="lay" />
            <token id="26" string="in" />
            <token id="27" string="exploiting" />
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="6" string="A great deal of this muck" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="great" />
            <token id="3" string="deal" />
            <token id="4" string="of" />
            <token id="5" string="this" />
            <token id="6" string="muck" />
          </tokens>
        </chunking>
        <chunking id="7" string="to splash onto Ms. Ono , whom Mr. Goldman portrays as a cynical manipulator whose major talent lay in exploiting Mr. Lennon to further her own craving for fame and wealth" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="splash" />
            <token id="10" string="onto" />
            <token id="11" string="Ms." />
            <token id="12" string="Ono" />
            <token id="13" string="," />
            <token id="14" string="whom" />
            <token id="15" string="Mr." />
            <token id="16" string="Goldman" />
            <token id="17" string="portrays" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="cynical" />
            <token id="21" string="manipulator" />
            <token id="22" string="whose" />
            <token id="23" string="major" />
            <token id="24" string="talent" />
            <token id="25" string="lay" />
            <token id="26" string="in" />
            <token id="27" string="exploiting" />
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ms. Ono , whom Mr. Goldman portrays as a cynical manipulator whose major talent lay in exploiting Mr. Lennon to further her own craving for fame and wealth" type="NP">
          <tokens>
            <token id="11" string="Ms." />
            <token id="12" string="Ono" />
            <token id="13" string="," />
            <token id="14" string="whom" />
            <token id="15" string="Mr." />
            <token id="16" string="Goldman" />
            <token id="17" string="portrays" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="cynical" />
            <token id="21" string="manipulator" />
            <token id="22" string="whose" />
            <token id="23" string="major" />
            <token id="24" string="talent" />
            <token id="25" string="lay" />
            <token id="26" string="in" />
            <token id="27" string="exploiting" />
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="9" string="this muck" type="NP">
          <tokens>
            <token id="5" string="this" />
            <token id="6" string="muck" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mr. Lennon" type="NP">
          <tokens>
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="11" string="to further her own craving for fame and wealth" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="12" string="lay in exploiting Mr. Lennon to further her own craving for fame and wealth" type="VP">
          <tokens>
            <token id="25" string="lay" />
            <token id="26" string="in" />
            <token id="27" string="exploiting" />
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="13" string="fame and wealth" type="NP">
          <tokens>
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="14" string="portrays as a cynical manipulator whose major talent lay in exploiting Mr. Lennon to further her own craving for fame and wealth" type="VP">
          <tokens>
            <token id="17" string="portrays" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="cynical" />
            <token id="21" string="manipulator" />
            <token id="22" string="whose" />
            <token id="23" string="major" />
            <token id="24" string="talent" />
            <token id="25" string="lay" />
            <token id="26" string="in" />
            <token id="27" string="exploiting" />
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="15" string="a cynical manipulator whose major talent lay in exploiting Mr. Lennon to further her own craving for fame and wealth" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="cynical" />
            <token id="21" string="manipulator" />
            <token id="22" string="whose" />
            <token id="23" string="major" />
            <token id="24" string="talent" />
            <token id="25" string="lay" />
            <token id="26" string="in" />
            <token id="27" string="exploiting" />
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="16" string="whom Mr. Goldman portrays as a cynical manipulator whose major talent lay in exploiting Mr. Lennon to further her own craving for fame and wealth" type="SBAR">
          <tokens>
            <token id="14" string="whom" />
            <token id="15" string="Mr." />
            <token id="16" string="Goldman" />
            <token id="17" string="portrays" />
            <token id="18" string="as" />
            <token id="19" string="a" />
            <token id="20" string="cynical" />
            <token id="21" string="manipulator" />
            <token id="22" string="whose" />
            <token id="23" string="major" />
            <token id="24" string="talent" />
            <token id="25" string="lay" />
            <token id="26" string="in" />
            <token id="27" string="exploiting" />
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="17" string="A great deal" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="great" />
            <token id="3" string="deal" />
          </tokens>
        </chunking>
        <chunking id="18" string="her own craving" type="NP">
          <tokens>
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
          </tokens>
        </chunking>
        <chunking id="19" string="further her own craving for fame and wealth" type="VP">
          <tokens>
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
        <chunking id="20" string="Mr. Goldman" type="NP">
          <tokens>
            <token id="15" string="Mr." />
            <token id="16" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="21" string="exploiting Mr. Lennon to further her own craving for fame and wealth" type="VP">
          <tokens>
            <token id="27" string="exploiting" />
            <token id="28" string="Mr." />
            <token id="29" string="Lennon" />
            <token id="30" string="to" />
            <token id="31" string="further" />
            <token id="32" string="her" />
            <token id="33" string="own" />
            <token id="34" string="craving" />
            <token id="35" string="for" />
            <token id="36" string="fame" />
            <token id="37" string="and" />
            <token id="38" string="wealth" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">deal</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">deal</governor>
          <dependent id="2">great</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">manages</governor>
          <dependent id="3">deal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">muck</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">muck</governor>
          <dependent id="5">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">deal</governor>
          <dependent id="6">muck</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">manages</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">splash</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">manages</governor>
          <dependent id="9">splash</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Ono</governor>
          <dependent id="10">onto</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Ono</governor>
          <dependent id="11">Ms.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">splash</governor>
          <dependent id="12">Ono</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">portrays</governor>
          <dependent id="14">whom</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Goldman</governor>
          <dependent id="15">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">portrays</governor>
          <dependent id="16">Goldman</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">Ono</governor>
          <dependent id="17">portrays</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">manipulator</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">manipulator</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">manipulator</governor>
          <dependent id="20">cynical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">portrays</governor>
          <dependent id="21">manipulator</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">talent</governor>
          <dependent id="22">whose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">talent</governor>
          <dependent id="23">major</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">lay</governor>
          <dependent id="24">talent</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">manipulator</governor>
          <dependent id="25">lay</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">exploiting</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">lay</governor>
          <dependent id="27">exploiting</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Lennon</governor>
          <dependent id="28">Mr.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">exploiting</governor>
          <dependent id="29">Lennon</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">further</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="27">exploiting</governor>
          <dependent id="31">further</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">craving</governor>
          <dependent id="32">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">craving</governor>
          <dependent id="33">own</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">further</governor>
          <dependent id="34">craving</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">fame</governor>
          <dependent id="35">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">further</governor>
          <dependent id="36">fame</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="36">fame</governor>
          <dependent id="37">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">fame</governor>
          <dependent id="38">wealth</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Goldman" />
          </tokens>
        </entity>
        <entity id="3" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>Mr. Goldman, alas, allows to pass unremarked the obvious irony that this is a rather fine thumbnail sketch of himself as well.</content>
      <tokens>
        <token id="1" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="alas" lemma="alas" stem="ala" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="allows" lemma="allow" stem="allow" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="pass" lemma="pass" stem="pass" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="unremarked" lemma="unremarked" stem="unremark" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="obvious" lemma="obvious" stem="obviou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="irony" lemma="irony" stem="ironi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="fine" lemma="fine" stem="fine" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="thumbnail" lemma="thumbnail" stem="thumbnail" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="sketch" lemma="sketch" stem="sketch" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="23" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (SBAR (WHNP (NP (NNP Mr.) (NNP Goldman)) (PRN (, ,) (INTJ (UH alas)) (, ,))) (S (VP (VBZ allows) (S (VP (TO to) (VP (VB pass) (NP (JJ unremarked) (DT the) (JJ obvious) (NN irony)) (SBAR (IN that) (S (NP (DT this)) (VP (VBZ is) (NP (NP (DT a) (ADJP (RB rather) (JJ fine)) (JJ thumbnail) (NN sketch)) (PP (IN of) (NP (PRP himself)))) (ADVP (RB as) (RB well))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="unremarked the obvious irony" type="NP">
          <tokens>
            <token id="9" string="unremarked" />
            <token id="10" string="the" />
            <token id="11" string="obvious" />
            <token id="12" string="irony" />
          </tokens>
        </chunking>
        <chunking id="2" string="a rather fine thumbnail sketch" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="rather" />
            <token id="18" string="fine" />
            <token id="19" string="thumbnail" />
            <token id="20" string="sketch" />
          </tokens>
        </chunking>
        <chunking id="3" string="this" type="NP">
          <tokens>
            <token id="14" string="this" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mr. Goldman , alas , allows to pass unremarked the obvious irony that this is a rather fine thumbnail sketch of himself as well" type="SBAR">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Goldman" />
            <token id="3" string="," />
            <token id="4" string="alas" />
            <token id="5" string="," />
            <token id="6" string="allows" />
            <token id="7" string="to" />
            <token id="8" string="pass" />
            <token id="9" string="unremarked" />
            <token id="10" string="the" />
            <token id="11" string="obvious" />
            <token id="12" string="irony" />
            <token id="13" string="that" />
            <token id="14" string="this" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="rather" />
            <token id="18" string="fine" />
            <token id="19" string="thumbnail" />
            <token id="20" string="sketch" />
            <token id="21" string="of" />
            <token id="22" string="himself" />
            <token id="23" string="as" />
            <token id="24" string="well" />
          </tokens>
        </chunking>
        <chunking id="5" string="a rather fine thumbnail sketch of himself" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="rather" />
            <token id="18" string="fine" />
            <token id="19" string="thumbnail" />
            <token id="20" string="sketch" />
            <token id="21" string="of" />
            <token id="22" string="himself" />
          </tokens>
        </chunking>
        <chunking id="6" string="rather fine" type="ADJP">
          <tokens>
            <token id="17" string="rather" />
            <token id="18" string="fine" />
          </tokens>
        </chunking>
        <chunking id="7" string="that this is a rather fine thumbnail sketch of himself as well" type="SBAR">
          <tokens>
            <token id="13" string="that" />
            <token id="14" string="this" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="rather" />
            <token id="18" string="fine" />
            <token id="19" string="thumbnail" />
            <token id="20" string="sketch" />
            <token id="21" string="of" />
            <token id="22" string="himself" />
            <token id="23" string="as" />
            <token id="24" string="well" />
          </tokens>
        </chunking>
        <chunking id="8" string="to pass unremarked the obvious irony that this is a rather fine thumbnail sketch of himself as well" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="pass" />
            <token id="9" string="unremarked" />
            <token id="10" string="the" />
            <token id="11" string="obvious" />
            <token id="12" string="irony" />
            <token id="13" string="that" />
            <token id="14" string="this" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="rather" />
            <token id="18" string="fine" />
            <token id="19" string="thumbnail" />
            <token id="20" string="sketch" />
            <token id="21" string="of" />
            <token id="22" string="himself" />
            <token id="23" string="as" />
            <token id="24" string="well" />
          </tokens>
        </chunking>
        <chunking id="9" string="Mr. Goldman" type="NP">
          <tokens>
            <token id="1" string="Mr." />
            <token id="2" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="10" string="is a rather fine thumbnail sketch of himself as well" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="rather" />
            <token id="18" string="fine" />
            <token id="19" string="thumbnail" />
            <token id="20" string="sketch" />
            <token id="21" string="of" />
            <token id="22" string="himself" />
            <token id="23" string="as" />
            <token id="24" string="well" />
          </tokens>
        </chunking>
        <chunking id="11" string="pass unremarked the obvious irony that this is a rather fine thumbnail sketch of himself as well" type="VP">
          <tokens>
            <token id="8" string="pass" />
            <token id="9" string="unremarked" />
            <token id="10" string="the" />
            <token id="11" string="obvious" />
            <token id="12" string="irony" />
            <token id="13" string="that" />
            <token id="14" string="this" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="rather" />
            <token id="18" string="fine" />
            <token id="19" string="thumbnail" />
            <token id="20" string="sketch" />
            <token id="21" string="of" />
            <token id="22" string="himself" />
            <token id="23" string="as" />
            <token id="24" string="well" />
          </tokens>
        </chunking>
        <chunking id="12" string="allows to pass unremarked the obvious irony that this is a rather fine thumbnail sketch of himself as well" type="VP">
          <tokens>
            <token id="6" string="allows" />
            <token id="7" string="to" />
            <token id="8" string="pass" />
            <token id="9" string="unremarked" />
            <token id="10" string="the" />
            <token id="11" string="obvious" />
            <token id="12" string="irony" />
            <token id="13" string="that" />
            <token id="14" string="this" />
            <token id="15" string="is" />
            <token id="16" string="a" />
            <token id="17" string="rather" />
            <token id="18" string="fine" />
            <token id="19" string="thumbnail" />
            <token id="20" string="sketch" />
            <token id="21" string="of" />
            <token id="22" string="himself" />
            <token id="23" string="as" />
            <token id="24" string="well" />
          </tokens>
        </chunking>
        <chunking id="13" string="himself" type="NP">
          <tokens>
            <token id="22" string="himself" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Goldman</governor>
          <dependent id="1">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">allows</governor>
          <dependent id="2">Goldman</dependent>
        </dependency>
        <dependency type="discourse">
          <governor id="2">Goldman</governor>
          <dependent id="4">alas</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">allows</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">pass</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">allows</governor>
          <dependent id="8">pass</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">irony</governor>
          <dependent id="9">unremarked</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">irony</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">irony</governor>
          <dependent id="11">obvious</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">pass</governor>
          <dependent id="12">irony</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">sketch</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">sketch</governor>
          <dependent id="14">this</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">sketch</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">sketch</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">fine</governor>
          <dependent id="17">rather</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">sketch</governor>
          <dependent id="18">fine</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">sketch</governor>
          <dependent id="19">thumbnail</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">pass</governor>
          <dependent id="20">sketch</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">himself</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">sketch</governor>
          <dependent id="22">himself</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">sketch</governor>
          <dependent id="23">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="23">as</governor>
          <dependent id="24">well</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>The keepers of the Lennon flame have of course been quick to point this out.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="keepers" lemma="keeper" stem="keeper" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="flame" lemma="flame" stem="flame" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="quick" lemma="quick" stem="quick" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="point" lemma="point" stem="point" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNS keepers)) (PP (IN of) (NP (DT the) (NNP Lennon) (NN flame)))) (VP (VBP have) (PP (IN of) (NP (NN course))) (VP (VBN been) (ADJP (JJ quick) (S (VP (TO to) (VP (VB point) (NP (DT this)) (PRT (RP out)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="quick to point this out" type="ADJP">
          <tokens>
            <token id="11" string="quick" />
            <token id="12" string="to" />
            <token id="13" string="point" />
            <token id="14" string="this" />
            <token id="15" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="to point this out" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="point" />
            <token id="14" string="this" />
            <token id="15" string="out" />
          </tokens>
        </chunking>
        <chunking id="3" string="been quick to point this out" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="quick" />
            <token id="12" string="to" />
            <token id="13" string="point" />
            <token id="14" string="this" />
            <token id="15" string="out" />
          </tokens>
        </chunking>
        <chunking id="4" string="course" type="NP">
          <tokens>
            <token id="9" string="course" />
          </tokens>
        </chunking>
        <chunking id="5" string="point this out" type="VP">
          <tokens>
            <token id="13" string="point" />
            <token id="14" string="this" />
            <token id="15" string="out" />
          </tokens>
        </chunking>
        <chunking id="6" string="this" type="NP">
          <tokens>
            <token id="14" string="this" />
          </tokens>
        </chunking>
        <chunking id="7" string="The keepers" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="keepers" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Lennon flame" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Lennon" />
            <token id="6" string="flame" />
          </tokens>
        </chunking>
        <chunking id="9" string="have of course been quick to point this out" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="of" />
            <token id="9" string="course" />
            <token id="10" string="been" />
            <token id="11" string="quick" />
            <token id="12" string="to" />
            <token id="13" string="point" />
            <token id="14" string="this" />
            <token id="15" string="out" />
          </tokens>
        </chunking>
        <chunking id="10" string="The keepers of the Lennon flame" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="keepers" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="Lennon" />
            <token id="6" string="flame" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">keepers</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">quick</governor>
          <dependent id="2">keepers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">flame</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">flame</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">flame</governor>
          <dependent id="5">Lennon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">keepers</governor>
          <dependent id="6">flame</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">quick</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">course</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">quick</governor>
          <dependent id="9">course</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">quick</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">quick</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">point</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">quick</governor>
          <dependent id="13">point</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">point</governor>
          <dependent id="14">this</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="13">point</governor>
          <dependent id="15">out</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Ms. Ono and her son have taken the path preferred by offended celebrities, they have hit the talk shows to display their wounds.</content>
      <tokens>
        <token id="1" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="2" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="path" lemma="path" stem="path" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="preferred" lemma="prefer" stem="prefer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="offended" lemma="offended" stem="offend" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="celebrities" lemma="celebrity" stem="celebr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="hit" lemma="hit" stem="hit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="talk" lemma="talk" stem="talk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="display" lemma="display" stem="displai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="wounds" lemma="wound" stem="wound" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Ms.) (NNP Ono)) (CC and) (NP (PRP$ her) (NN son))) (VP (VBP have) (VP (VBN taken) (NP (NP (DT the) (NN path)) (VP (VBN preferred) (PP (IN by) (NP (JJ offended) (NNS celebrities)))))))) (, ,) (NP (PRP they)) (VP (VBP have) (VP (VBN hit) (SBAR (S (NP (DT the) (NN talk)) (VP (VBZ shows) (S (VP (TO to) (VP (VB display) (NP (PRP$ their) (NNS wounds)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ms. Ono" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="2" string="preferred by offended celebrities" type="VP">
          <tokens>
            <token id="10" string="preferred" />
            <token id="11" string="by" />
            <token id="12" string="offended" />
            <token id="13" string="celebrities" />
          </tokens>
        </chunking>
        <chunking id="3" string="to display their wounds" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="display" />
            <token id="23" string="their" />
            <token id="24" string="wounds" />
          </tokens>
        </chunking>
        <chunking id="4" string="their wounds" type="NP">
          <tokens>
            <token id="23" string="their" />
            <token id="24" string="wounds" />
          </tokens>
        </chunking>
        <chunking id="5" string="offended celebrities" type="NP">
          <tokens>
            <token id="12" string="offended" />
            <token id="13" string="celebrities" />
          </tokens>
        </chunking>
        <chunking id="6" string="the talk shows to display their wounds" type="SBAR">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="talk" />
            <token id="20" string="shows" />
            <token id="21" string="to" />
            <token id="22" string="display" />
            <token id="23" string="their" />
            <token id="24" string="wounds" />
          </tokens>
        </chunking>
        <chunking id="7" string="they" type="NP">
          <tokens>
            <token id="15" string="they" />
          </tokens>
        </chunking>
        <chunking id="8" string="the path preferred by offended celebrities" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="path" />
            <token id="10" string="preferred" />
            <token id="11" string="by" />
            <token id="12" string="offended" />
            <token id="13" string="celebrities" />
          </tokens>
        </chunking>
        <chunking id="9" string="the path" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="path" />
          </tokens>
        </chunking>
        <chunking id="10" string="shows to display their wounds" type="VP">
          <tokens>
            <token id="20" string="shows" />
            <token id="21" string="to" />
            <token id="22" string="display" />
            <token id="23" string="their" />
            <token id="24" string="wounds" />
          </tokens>
        </chunking>
        <chunking id="11" string="have taken the path preferred by offended celebrities" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="taken" />
            <token id="8" string="the" />
            <token id="9" string="path" />
            <token id="10" string="preferred" />
            <token id="11" string="by" />
            <token id="12" string="offended" />
            <token id="13" string="celebrities" />
          </tokens>
        </chunking>
        <chunking id="12" string="have hit the talk shows to display their wounds" type="VP">
          <tokens>
            <token id="16" string="have" />
            <token id="17" string="hit" />
            <token id="18" string="the" />
            <token id="19" string="talk" />
            <token id="20" string="shows" />
            <token id="21" string="to" />
            <token id="22" string="display" />
            <token id="23" string="their" />
            <token id="24" string="wounds" />
          </tokens>
        </chunking>
        <chunking id="13" string="Ms. Ono and her son" type="NP">
          <tokens>
            <token id="1" string="Ms." />
            <token id="2" string="Ono" />
            <token id="3" string="and" />
            <token id="4" string="her" />
            <token id="5" string="son" />
          </tokens>
        </chunking>
        <chunking id="14" string="hit the talk shows to display their wounds" type="VP">
          <tokens>
            <token id="17" string="hit" />
            <token id="18" string="the" />
            <token id="19" string="talk" />
            <token id="20" string="shows" />
            <token id="21" string="to" />
            <token id="22" string="display" />
            <token id="23" string="their" />
            <token id="24" string="wounds" />
          </tokens>
        </chunking>
        <chunking id="15" string="the talk" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="talk" />
          </tokens>
        </chunking>
        <chunking id="16" string="display their wounds" type="VP">
          <tokens>
            <token id="22" string="display" />
            <token id="23" string="their" />
            <token id="24" string="wounds" />
          </tokens>
        </chunking>
        <chunking id="17" string="her son" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="son" />
          </tokens>
        </chunking>
        <chunking id="18" string="taken the path preferred by offended celebrities" type="VP">
          <tokens>
            <token id="7" string="taken" />
            <token id="8" string="the" />
            <token id="9" string="path" />
            <token id="10" string="preferred" />
            <token id="11" string="by" />
            <token id="12" string="offended" />
            <token id="13" string="celebrities" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Ono</governor>
          <dependent id="1">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">taken</governor>
          <dependent id="2">Ono</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Ono</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">son</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Ono</governor>
          <dependent id="5">son</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">taken</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">hit</governor>
          <dependent id="7">taken</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">path</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">taken</governor>
          <dependent id="9">path</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">path</governor>
          <dependent id="10">preferred</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">celebrities</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">celebrities</governor>
          <dependent id="12">offended</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">preferred</governor>
          <dependent id="13">celebrities</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">hit</governor>
          <dependent id="15">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">hit</governor>
          <dependent id="16">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">hit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">talk</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">shows</governor>
          <dependent id="19">talk</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">hit</governor>
          <dependent id="20">shows</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">display</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">shows</governor>
          <dependent id="22">display</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">wounds</governor>
          <dependent id="23">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">display</governor>
          <dependent id="24">wounds</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>And Rolling Stone magazine, long the house organ for the Lennon publicity machine, recently published an extensive rebuttal to the book, which was undercut by a tone of priggish indignation bordering on the comic.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Rolling" lemma="Rolling" stem="roll" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Stone" lemma="Stone" stem="stone" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="4" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="house" lemma="house" stem="hous" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="organ" lemma="organ" stem="organ" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="13" string="publicity" lemma="publicity" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="machine" lemma="machine" stem="machin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="recently" lemma="recently" stem="recent" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="published" lemma="publish" stem="publish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="extensive" lemma="extensive" stem="extens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="rebuttal" lemma="rebuttal" stem="rebutt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="undercut" lemma="undercut" stem="undercut" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="tone" lemma="tone" stem="tone" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="priggish" lemma="priggish" stem="priggish" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="indignation" lemma="indignation" stem="indign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="bordering" lemma="border" stem="border" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="comic" lemma="comic" stem="comic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (NNP Rolling) (NNP Stone) (NN magazine)) (, ,) (NP (NP (RB long) (DT the) (NN house) (NN organ)) (PP (IN for) (NP (DT the) (NNP Lennon) (NN publicity) (NN machine)))) (, ,)) (ADVP (RB recently)) (VP (VBD published) (NP (DT an) (JJ extensive) (NN rebuttal)) (PP (TO to) (NP (NP (DT the) (NN book)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD was) (VP (VBN undercut) (PP (IN by) (NP (NP (DT a) (NN tone)) (PP (IN of) (NP (NP (JJ priggish) (NN indignation) (VBG bordering)) (PP (IN on) (NP (DT the) (JJ comic)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was undercut by a tone of priggish indignation bordering on the comic" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="undercut" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="tone" />
            <token id="31" string="of" />
            <token id="32" string="priggish" />
            <token id="33" string="indignation" />
            <token id="34" string="bordering" />
            <token id="35" string="on" />
            <token id="36" string="the" />
            <token id="37" string="comic" />
          </tokens>
        </chunking>
        <chunking id="2" string="Rolling Stone magazine" type="NP">
          <tokens>
            <token id="2" string="Rolling" />
            <token id="3" string="Stone" />
            <token id="4" string="magazine" />
          </tokens>
        </chunking>
        <chunking id="3" string="an extensive rebuttal" type="NP">
          <tokens>
            <token id="18" string="an" />
            <token id="19" string="extensive" />
            <token id="20" string="rebuttal" />
          </tokens>
        </chunking>
        <chunking id="4" string="priggish indignation bordering on the comic" type="NP">
          <tokens>
            <token id="32" string="priggish" />
            <token id="33" string="indignation" />
            <token id="34" string="bordering" />
            <token id="35" string="on" />
            <token id="36" string="the" />
            <token id="37" string="comic" />
          </tokens>
        </chunking>
        <chunking id="5" string="the book , which was undercut by a tone of priggish indignation bordering on the comic" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="book" />
            <token id="24" string="," />
            <token id="25" string="which" />
            <token id="26" string="was" />
            <token id="27" string="undercut" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="tone" />
            <token id="31" string="of" />
            <token id="32" string="priggish" />
            <token id="33" string="indignation" />
            <token id="34" string="bordering" />
            <token id="35" string="on" />
            <token id="36" string="the" />
            <token id="37" string="comic" />
          </tokens>
        </chunking>
        <chunking id="6" string="priggish indignation bordering" type="NP">
          <tokens>
            <token id="32" string="priggish" />
            <token id="33" string="indignation" />
            <token id="34" string="bordering" />
          </tokens>
        </chunking>
        <chunking id="7" string="undercut by a tone of priggish indignation bordering on the comic" type="VP">
          <tokens>
            <token id="27" string="undercut" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="tone" />
            <token id="31" string="of" />
            <token id="32" string="priggish" />
            <token id="33" string="indignation" />
            <token id="34" string="bordering" />
            <token id="35" string="on" />
            <token id="36" string="the" />
            <token id="37" string="comic" />
          </tokens>
        </chunking>
        <chunking id="8" string="the book" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="9" string="a tone" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="tone" />
          </tokens>
        </chunking>
        <chunking id="10" string="Rolling Stone magazine , long the house organ for the Lennon publicity machine ," type="NP">
          <tokens>
            <token id="2" string="Rolling" />
            <token id="3" string="Stone" />
            <token id="4" string="magazine" />
            <token id="5" string="," />
            <token id="6" string="long" />
            <token id="7" string="the" />
            <token id="8" string="house" />
            <token id="9" string="organ" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="Lennon" />
            <token id="13" string="publicity" />
            <token id="14" string="machine" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="the Lennon publicity machine" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Lennon" />
            <token id="13" string="publicity" />
            <token id="14" string="machine" />
          </tokens>
        </chunking>
        <chunking id="12" string="published an extensive rebuttal to the book , which was undercut by a tone of priggish indignation bordering on the comic" type="VP">
          <tokens>
            <token id="17" string="published" />
            <token id="18" string="an" />
            <token id="19" string="extensive" />
            <token id="20" string="rebuttal" />
            <token id="21" string="to" />
            <token id="22" string="the" />
            <token id="23" string="book" />
            <token id="24" string="," />
            <token id="25" string="which" />
            <token id="26" string="was" />
            <token id="27" string="undercut" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="tone" />
            <token id="31" string="of" />
            <token id="32" string="priggish" />
            <token id="33" string="indignation" />
            <token id="34" string="bordering" />
            <token id="35" string="on" />
            <token id="36" string="the" />
            <token id="37" string="comic" />
          </tokens>
        </chunking>
        <chunking id="13" string="a tone of priggish indignation bordering on the comic" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="tone" />
            <token id="31" string="of" />
            <token id="32" string="priggish" />
            <token id="33" string="indignation" />
            <token id="34" string="bordering" />
            <token id="35" string="on" />
            <token id="36" string="the" />
            <token id="37" string="comic" />
          </tokens>
        </chunking>
        <chunking id="14" string="which was undercut by a tone of priggish indignation bordering on the comic" type="SBAR">
          <tokens>
            <token id="25" string="which" />
            <token id="26" string="was" />
            <token id="27" string="undercut" />
            <token id="28" string="by" />
            <token id="29" string="a" />
            <token id="30" string="tone" />
            <token id="31" string="of" />
            <token id="32" string="priggish" />
            <token id="33" string="indignation" />
            <token id="34" string="bordering" />
            <token id="35" string="on" />
            <token id="36" string="the" />
            <token id="37" string="comic" />
          </tokens>
        </chunking>
        <chunking id="15" string="long the house organ for the Lennon publicity machine" type="NP">
          <tokens>
            <token id="6" string="long" />
            <token id="7" string="the" />
            <token id="8" string="house" />
            <token id="9" string="organ" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="Lennon" />
            <token id="13" string="publicity" />
            <token id="14" string="machine" />
          </tokens>
        </chunking>
        <chunking id="16" string="long the house organ" type="NP">
          <tokens>
            <token id="6" string="long" />
            <token id="7" string="the" />
            <token id="8" string="house" />
            <token id="9" string="organ" />
          </tokens>
        </chunking>
        <chunking id="17" string="the comic" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="comic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="17">published</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">magazine</governor>
          <dependent id="2">Rolling</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">magazine</governor>
          <dependent id="3">Stone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">published</governor>
          <dependent id="4">magazine</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">organ</governor>
          <dependent id="6">long</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">organ</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">organ</governor>
          <dependent id="8">house</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">magazine</governor>
          <dependent id="9">organ</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">machine</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">machine</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">machine</governor>
          <dependent id="12">Lennon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">machine</governor>
          <dependent id="13">publicity</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">organ</governor>
          <dependent id="14">machine</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">published</governor>
          <dependent id="16">recently</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">published</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">rebuttal</governor>
          <dependent id="18">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">rebuttal</governor>
          <dependent id="19">extensive</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">published</governor>
          <dependent id="20">rebuttal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">book</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">book</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">published</governor>
          <dependent id="23">book</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="27">undercut</governor>
          <dependent id="25">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="27">undercut</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="23">book</governor>
          <dependent id="27">undercut</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">tone</governor>
          <dependent id="28">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">tone</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">undercut</governor>
          <dependent id="30">tone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">indignation</governor>
          <dependent id="31">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">indignation</governor>
          <dependent id="32">priggish</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">tone</governor>
          <dependent id="33">indignation</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">indignation</governor>
          <dependent id="34">bordering</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">comic</governor>
          <dependent id="35">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">comic</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">indignation</governor>
          <dependent id="37">comic</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rolling Stone" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="2" string="Rolling" />
            <token id="3" string="Stone" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="recently" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="recently" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Criticizing &amp;quot;The Lives of John Lennon&amp;quot; for insufficient respect to the fallen Beatle&amp;apost;s legacy is rather off the point -- like condemning Charles Manson for his bad table manners.</content>
      <tokens>
        <token id="1" string="Criticizing" lemma="criticize" stem="critic" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="insufficient" lemma="insufficient" stem="insuffici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="respect" lemma="respect" stem="respect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="fallen" lemma="fall" stem="fallen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Beatle" lemma="Beatle" stem="beatl" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="legacy" lemma="legacy" stem="legaci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="off" lemma="off" stem="off" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="condemning" lemma="condemn" stem="condemn" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Charles" lemma="Charles" stem="charl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="Manson" lemma="Manson" stem="manson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="table" lemma="table" stem="tabl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="manners" lemma="manners" stem="manner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Criticizing) (`` ``) (NP (NP (DT The) (NNS Lives)) (PP (IN of) (NP (NNP John) (NNP Lennon)))) ('' '') (PP (IN for) (NP (NP (JJ insufficient) (NN respect)) (PP (TO to) (NP (DT the) (VBN fallen))))))) (NP (NP (NNP Beatle) (POS 's)) (NN legacy)) (VP (VBZ is) (ADVP (RB rather) (PP (IN off) (NP (DT the) (NN point)))) (: --) (PP (IN like) (S (VP (VBG condemning) (NP (NP (NNP Charles) (NNP Manson)) (PP (IN for) (NP (PRP$ his) (JJ bad) (NN table) (NNS manners)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his bad table manners" type="NP">
          <tokens>
            <token id="29" string="his" />
            <token id="30" string="bad" />
            <token id="31" string="table" />
            <token id="32" string="manners" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Lives" type="NP">
          <tokens>
            <token id="3" string="The" />
            <token id="4" string="Lives" />
          </tokens>
        </chunking>
        <chunking id="3" string="the point" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="point" />
          </tokens>
        </chunking>
        <chunking id="4" string="insufficient respect" type="NP">
          <tokens>
            <token id="10" string="insufficient" />
            <token id="11" string="respect" />
          </tokens>
        </chunking>
        <chunking id="5" string="John Lennon" type="NP">
          <tokens>
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="6" string="The Lives of John Lennon" type="NP">
          <tokens>
            <token id="3" string="The" />
            <token id="4" string="Lives" />
            <token id="5" string="of" />
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="7" string="Charles Manson" type="NP">
          <tokens>
            <token id="26" string="Charles" />
            <token id="27" string="Manson" />
          </tokens>
        </chunking>
        <chunking id="8" string="Criticizing `` The Lives of John Lennon '' for insufficient respect to the fallen" type="VP">
          <tokens>
            <token id="1" string="Criticizing" />
            <token id="2" string="&quot;" />
            <token id="3" string="The" />
            <token id="4" string="Lives" />
            <token id="5" string="of" />
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
            <token id="8" string="&quot;" />
            <token id="9" string="for" />
            <token id="10" string="insufficient" />
            <token id="11" string="respect" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="fallen" />
          </tokens>
        </chunking>
        <chunking id="9" string="Beatle 's" type="NP">
          <tokens>
            <token id="15" string="Beatle" />
            <token id="16" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="the fallen" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="fallen" />
          </tokens>
        </chunking>
        <chunking id="11" string="is rather off the point -- like condemning Charles Manson for his bad table manners" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="rather" />
            <token id="20" string="off" />
            <token id="21" string="the" />
            <token id="22" string="point" />
            <token id="23" string="--" />
            <token id="24" string="like" />
            <token id="25" string="condemning" />
            <token id="26" string="Charles" />
            <token id="27" string="Manson" />
            <token id="28" string="for" />
            <token id="29" string="his" />
            <token id="30" string="bad" />
            <token id="31" string="table" />
            <token id="32" string="manners" />
          </tokens>
        </chunking>
        <chunking id="12" string="insufficient respect to the fallen" type="NP">
          <tokens>
            <token id="10" string="insufficient" />
            <token id="11" string="respect" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="fallen" />
          </tokens>
        </chunking>
        <chunking id="13" string="Charles Manson for his bad table manners" type="NP">
          <tokens>
            <token id="26" string="Charles" />
            <token id="27" string="Manson" />
            <token id="28" string="for" />
            <token id="29" string="his" />
            <token id="30" string="bad" />
            <token id="31" string="table" />
            <token id="32" string="manners" />
          </tokens>
        </chunking>
        <chunking id="14" string="condemning Charles Manson for his bad table manners" type="VP">
          <tokens>
            <token id="25" string="condemning" />
            <token id="26" string="Charles" />
            <token id="27" string="Manson" />
            <token id="28" string="for" />
            <token id="29" string="his" />
            <token id="30" string="bad" />
            <token id="31" string="table" />
            <token id="32" string="manners" />
          </tokens>
        </chunking>
        <chunking id="15" string="Beatle 's legacy" type="NP">
          <tokens>
            <token id="15" string="Beatle" />
            <token id="16" string="'s" />
            <token id="17" string="legacy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="25">condemning</governor>
          <dependent id="1">Criticizing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Lives</governor>
          <dependent id="3">The</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Criticizing</governor>
          <dependent id="4">Lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Lennon</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Lennon</governor>
          <dependent id="6">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">Lives</governor>
          <dependent id="7">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">respect</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">respect</governor>
          <dependent id="10">insufficient</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Criticizing</governor>
          <dependent id="11">respect</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">the</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">respect</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">the</governor>
          <dependent id="14">fallen</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">legacy</governor>
          <dependent id="15">Beatle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Beatle</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">condemning</governor>
          <dependent id="17">legacy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">condemning</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">condemning</governor>
          <dependent id="19">rather</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">point</governor>
          <dependent id="20">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">point</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">rather</governor>
          <dependent id="22">point</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">condemning</governor>
          <dependent id="24">like</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">condemning</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Manson</governor>
          <dependent id="26">Charles</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">condemning</governor>
          <dependent id="27">Manson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">manners</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="32">manners</governor>
          <dependent id="29">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">manners</governor>
          <dependent id="30">bad</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">manners</governor>
          <dependent id="31">table</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">Manson</governor>
          <dependent id="32">manners</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Charles Manson" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Charles" />
            <token id="27" string="Manson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="false">
      <content>The book may indeed be inaccurate, as critics have charged.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="indeed" lemma="indeed" stem="inde" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="inaccurate" lemma="inaccurate" stem="inaccur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="critics" lemma="critic" stem="critic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="charged" lemma="charge" stem="charg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN book)) (VP (MD may) (ADVP (RB indeed)) (VP (VB be) (ADJP (JJ inaccurate)) (, ,) (SBAR (IN as) (S (NP (NNS critics)) (VP (VBP have) (VP (VBN charged))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="may indeed be inaccurate , as critics have charged" type="VP">
          <tokens>
            <token id="3" string="may" />
            <token id="4" string="indeed" />
            <token id="5" string="be" />
            <token id="6" string="inaccurate" />
            <token id="7" string="," />
            <token id="8" string="as" />
            <token id="9" string="critics" />
            <token id="10" string="have" />
            <token id="11" string="charged" />
          </tokens>
        </chunking>
        <chunking id="2" string="critics" type="NP">
          <tokens>
            <token id="9" string="critics" />
          </tokens>
        </chunking>
        <chunking id="3" string="The book" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="book" />
          </tokens>
        </chunking>
        <chunking id="4" string="charged" type="VP">
          <tokens>
            <token id="11" string="charged" />
          </tokens>
        </chunking>
        <chunking id="5" string="be inaccurate , as critics have charged" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="inaccurate" />
            <token id="7" string="," />
            <token id="8" string="as" />
            <token id="9" string="critics" />
            <token id="10" string="have" />
            <token id="11" string="charged" />
          </tokens>
        </chunking>
        <chunking id="6" string="as critics have charged" type="SBAR">
          <tokens>
            <token id="8" string="as" />
            <token id="9" string="critics" />
            <token id="10" string="have" />
            <token id="11" string="charged" />
          </tokens>
        </chunking>
        <chunking id="7" string="have charged" type="VP">
          <tokens>
            <token id="10" string="have" />
            <token id="11" string="charged" />
          </tokens>
        </chunking>
        <chunking id="8" string="inaccurate" type="ADJP">
          <tokens>
            <token id="6" string="inaccurate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">book</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">inaccurate</governor>
          <dependent id="2">book</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">inaccurate</governor>
          <dependent id="3">may</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">inaccurate</governor>
          <dependent id="4">indeed</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">inaccurate</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">inaccurate</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">charged</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">charged</governor>
          <dependent id="9">critics</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">charged</governor>
          <dependent id="10">have</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">inaccurate</governor>
          <dependent id="11">charged</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>But one can only hope that quibbles about its veracity do not obscure the countless other reasons to hate Mr. Goldman&amp;apost;s book.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="PRP" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="hope" lemma="hope" stem="hope" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="quibbles" lemma="quibble" stem="quibbl" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="veracity" lemma="veracity" stem="verac" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="obscure" lemma="obscure" stem="obscur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="countless" lemma="countless" stem="countless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="reasons" lemma="reason" stem="reason" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="hate" lemma="hate" stem="hate" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP one)) (VP (MD can) (ADVP (RB only)) (VP (VB hope) (SBAR (IN that) (S (VP (VBZ quibbles) (SBAR (IN about) (S (NP (PRP$ its) (NN veracity)) (VP (VBP do) (RB not) (VP (VB obscure) (S (NP (DT the) (JJ countless) (JJ other) (NNS reasons)) (VP (TO to) (VP (VB hate) (NP (NP (NNP Mr.) (NNP Goldman) (POS 's)) (NN book)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="hope that quibbles about its veracity do not obscure the countless other reasons to hate Mr. Goldman 's book" type="VP">
          <tokens>
            <token id="5" string="hope" />
            <token id="6" string="that" />
            <token id="7" string="quibbles" />
            <token id="8" string="about" />
            <token id="9" string="its" />
            <token id="10" string="veracity" />
            <token id="11" string="do" />
            <token id="12" string="not" />
            <token id="13" string="obscure" />
            <token id="14" string="the" />
            <token id="15" string="countless" />
            <token id="16" string="other" />
            <token id="17" string="reasons" />
            <token id="18" string="to" />
            <token id="19" string="hate" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="2" string="one" type="NP">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="the countless other reasons" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="countless" />
            <token id="16" string="other" />
            <token id="17" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="4" string="to hate Mr. Goldman 's book" type="VP">
          <tokens>
            <token id="18" string="to" />
            <token id="19" string="hate" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="5" string="hate Mr. Goldman 's book" type="VP">
          <tokens>
            <token id="19" string="hate" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="6" string="can only hope that quibbles about its veracity do not obscure the countless other reasons to hate Mr. Goldman 's book" type="VP">
          <tokens>
            <token id="3" string="can" />
            <token id="4" string="only" />
            <token id="5" string="hope" />
            <token id="6" string="that" />
            <token id="7" string="quibbles" />
            <token id="8" string="about" />
            <token id="9" string="its" />
            <token id="10" string="veracity" />
            <token id="11" string="do" />
            <token id="12" string="not" />
            <token id="13" string="obscure" />
            <token id="14" string="the" />
            <token id="15" string="countless" />
            <token id="16" string="other" />
            <token id="17" string="reasons" />
            <token id="18" string="to" />
            <token id="19" string="hate" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="7" string="do not obscure the countless other reasons to hate Mr. Goldman 's book" type="VP">
          <tokens>
            <token id="11" string="do" />
            <token id="12" string="not" />
            <token id="13" string="obscure" />
            <token id="14" string="the" />
            <token id="15" string="countless" />
            <token id="16" string="other" />
            <token id="17" string="reasons" />
            <token id="18" string="to" />
            <token id="19" string="hate" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mr. Goldman 's book" type="NP">
          <tokens>
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="9" string="that quibbles about its veracity do not obscure the countless other reasons to hate Mr. Goldman 's book" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="quibbles" />
            <token id="8" string="about" />
            <token id="9" string="its" />
            <token id="10" string="veracity" />
            <token id="11" string="do" />
            <token id="12" string="not" />
            <token id="13" string="obscure" />
            <token id="14" string="the" />
            <token id="15" string="countless" />
            <token id="16" string="other" />
            <token id="17" string="reasons" />
            <token id="18" string="to" />
            <token id="19" string="hate" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="10" string="its veracity" type="NP">
          <tokens>
            <token id="9" string="its" />
            <token id="10" string="veracity" />
          </tokens>
        </chunking>
        <chunking id="11" string="Mr. Goldman 's" type="NP">
          <tokens>
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="about its veracity do not obscure the countless other reasons to hate Mr. Goldman 's book" type="SBAR">
          <tokens>
            <token id="8" string="about" />
            <token id="9" string="its" />
            <token id="10" string="veracity" />
            <token id="11" string="do" />
            <token id="12" string="not" />
            <token id="13" string="obscure" />
            <token id="14" string="the" />
            <token id="15" string="countless" />
            <token id="16" string="other" />
            <token id="17" string="reasons" />
            <token id="18" string="to" />
            <token id="19" string="hate" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="13" string="quibbles about its veracity do not obscure the countless other reasons to hate Mr. Goldman 's book" type="VP">
          <tokens>
            <token id="7" string="quibbles" />
            <token id="8" string="about" />
            <token id="9" string="its" />
            <token id="10" string="veracity" />
            <token id="11" string="do" />
            <token id="12" string="not" />
            <token id="13" string="obscure" />
            <token id="14" string="the" />
            <token id="15" string="countless" />
            <token id="16" string="other" />
            <token id="17" string="reasons" />
            <token id="18" string="to" />
            <token id="19" string="hate" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
        <chunking id="14" string="obscure the countless other reasons to hate Mr. Goldman 's book" type="VP">
          <tokens>
            <token id="13" string="obscure" />
            <token id="14" string="the" />
            <token id="15" string="countless" />
            <token id="16" string="other" />
            <token id="17" string="reasons" />
            <token id="18" string="to" />
            <token id="19" string="hate" />
            <token id="20" string="Mr." />
            <token id="21" string="Goldman" />
            <token id="22" string="'s" />
            <token id="23" string="book" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">hope</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">hope</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">hope</governor>
          <dependent id="3">can</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">hope</governor>
          <dependent id="4">only</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">hope</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">quibbles</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">hope</governor>
          <dependent id="7">quibbles</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">obscure</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">veracity</governor>
          <dependent id="9">its</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">obscure</governor>
          <dependent id="10">veracity</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">obscure</governor>
          <dependent id="11">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">obscure</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">quibbles</governor>
          <dependent id="13">obscure</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">reasons</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">reasons</governor>
          <dependent id="15">countless</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">reasons</governor>
          <dependent id="16">other</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">obscure</governor>
          <dependent id="17">reasons</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">hate</governor>
          <dependent id="18">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">obscure</governor>
          <dependent id="19">hate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Goldman</governor>
          <dependent id="20">Mr.</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">book</governor>
          <dependent id="21">Goldman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Goldman</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">hate</governor>
          <dependent id="23">book</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>There is, for starters, the sloppy, pompous prose, so suggestive of the grad-school smoking lounge -- Mr. Goldman is the sort of writer who refers to pop songs as &amp;quot;pieces,&amp;quot; as though they were concerti.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="starters" lemma="starter" stem="starter" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="sloppy" lemma="sloppy" stem="sloppi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="pompous" lemma="pompous" stem="pompou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="prose" lemma="prose" stem="prose" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="suggestive" lemma="suggestive" stem="suggest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="grad-school" lemma="grad-school" stem="grad-school" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="smoking" lemma="smoking" stem="smoke" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="19" string="lounge" lemma="lounge" stem="loung" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="sort" lemma="sort" stem="sort" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="writer" lemma="writer" stem="writer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="refers" lemma="refer" stem="refer" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="pop" lemma="pop" stem="pop" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="songs" lemma="song" stem="song" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="pieces" lemma="piece" stem="piec" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="concerti" lemma="concerto" stem="concerti" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (EX There)) (VP (VBZ is) (, ,) (PP (IN for) (NP (NP (NNS starters)) (, ,) (NP (DT the) (ADJP (JJ sloppy) (, ,) (JJ pompous)) (NN prose)))) (, ,) (ADJP (RB so) (JJ suggestive)) (PP (IN of) (NP (DT the) (JJ grad-school) (NN smoking) (NN lounge))))) (: --) (S (NP (NNP Mr.) (NNP Goldman)) (VP (VBZ is) (NP (NP (DT the) (NN sort)) (PP (IN of) (NP (NN writer))) (SBAR (WHNP (WP who)) (S (VP (VBZ refers) (S (VP (TO to) (VP (VB pop) (NP (NNS songs)) (PP (IN as) (NP (`` ``) (NP (NNS pieces)) (, ,) ('' '') (SBAR (IN as) (IN though) (S (NP (PRP they)) (VP (VBD were) (NP (NNS concerti)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the grad-school smoking lounge" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="grad-school" />
            <token id="18" string="smoking" />
            <token id="19" string="lounge" />
          </tokens>
        </chunking>
        <chunking id="2" string="to pop songs as `` pieces , '' as though they were concerti" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="pop" />
            <token id="32" string="songs" />
            <token id="33" string="as" />
            <token id="34" string="&quot;" />
            <token id="35" string="pieces" />
            <token id="36" string="," />
            <token id="37" string="&quot;" />
            <token id="38" string="as" />
            <token id="39" string="though" />
            <token id="40" string="they" />
            <token id="41" string="were" />
            <token id="42" string="concerti" />
          </tokens>
        </chunking>
        <chunking id="3" string="who refers to pop songs as `` pieces , '' as though they were concerti" type="SBAR">
          <tokens>
            <token id="28" string="who" />
            <token id="29" string="refers" />
            <token id="30" string="to" />
            <token id="31" string="pop" />
            <token id="32" string="songs" />
            <token id="33" string="as" />
            <token id="34" string="&quot;" />
            <token id="35" string="pieces" />
            <token id="36" string="," />
            <token id="37" string="&quot;" />
            <token id="38" string="as" />
            <token id="39" string="though" />
            <token id="40" string="they" />
            <token id="41" string="were" />
            <token id="42" string="concerti" />
          </tokens>
        </chunking>
        <chunking id="4" string="is the sort of writer who refers to pop songs as `` pieces , '' as though they were concerti" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="the" />
            <token id="25" string="sort" />
            <token id="26" string="of" />
            <token id="27" string="writer" />
            <token id="28" string="who" />
            <token id="29" string="refers" />
            <token id="30" string="to" />
            <token id="31" string="pop" />
            <token id="32" string="songs" />
            <token id="33" string="as" />
            <token id="34" string="&quot;" />
            <token id="35" string="pieces" />
            <token id="36" string="," />
            <token id="37" string="&quot;" />
            <token id="38" string="as" />
            <token id="39" string="though" />
            <token id="40" string="they" />
            <token id="41" string="were" />
            <token id="42" string="concerti" />
          </tokens>
        </chunking>
        <chunking id="5" string="so suggestive" type="ADJP">
          <tokens>
            <token id="13" string="so" />
            <token id="14" string="suggestive" />
          </tokens>
        </chunking>
        <chunking id="6" string="starters , the sloppy , pompous prose" type="NP">
          <tokens>
            <token id="5" string="starters" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="sloppy" />
            <token id="9" string="," />
            <token id="10" string="pompous" />
            <token id="11" string="prose" />
          </tokens>
        </chunking>
        <chunking id="7" string="`` pieces , '' as though they were concerti" type="NP">
          <tokens>
            <token id="34" string="&quot;" />
            <token id="35" string="pieces" />
            <token id="36" string="," />
            <token id="37" string="&quot;" />
            <token id="38" string="as" />
            <token id="39" string="though" />
            <token id="40" string="they" />
            <token id="41" string="were" />
            <token id="42" string="concerti" />
          </tokens>
        </chunking>
        <chunking id="8" string="sloppy , pompous" type="ADJP">
          <tokens>
            <token id="8" string="sloppy" />
            <token id="9" string="," />
            <token id="10" string="pompous" />
          </tokens>
        </chunking>
        <chunking id="9" string="the sort" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="sort" />
          </tokens>
        </chunking>
        <chunking id="10" string="is , for starters , the sloppy , pompous prose , so suggestive of the grad-school smoking lounge" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="," />
            <token id="4" string="for" />
            <token id="5" string="starters" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="sloppy" />
            <token id="9" string="," />
            <token id="10" string="pompous" />
            <token id="11" string="prose" />
            <token id="12" string="," />
            <token id="13" string="so" />
            <token id="14" string="suggestive" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="grad-school" />
            <token id="18" string="smoking" />
            <token id="19" string="lounge" />
          </tokens>
        </chunking>
        <chunking id="11" string="pieces" type="NP">
          <tokens>
            <token id="35" string="pieces" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="40" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="14" string="songs" type="NP">
          <tokens>
            <token id="32" string="songs" />
          </tokens>
        </chunking>
        <chunking id="15" string="Mr. Goldman" type="NP">
          <tokens>
            <token id="21" string="Mr." />
            <token id="22" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="16" string="as though they were concerti" type="SBAR">
          <tokens>
            <token id="38" string="as" />
            <token id="39" string="though" />
            <token id="40" string="they" />
            <token id="41" string="were" />
            <token id="42" string="concerti" />
          </tokens>
        </chunking>
        <chunking id="17" string="writer" type="NP">
          <tokens>
            <token id="27" string="writer" />
          </tokens>
        </chunking>
        <chunking id="18" string="the sort of writer who refers to pop songs as `` pieces , '' as though they were concerti" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="sort" />
            <token id="26" string="of" />
            <token id="27" string="writer" />
            <token id="28" string="who" />
            <token id="29" string="refers" />
            <token id="30" string="to" />
            <token id="31" string="pop" />
            <token id="32" string="songs" />
            <token id="33" string="as" />
            <token id="34" string="&quot;" />
            <token id="35" string="pieces" />
            <token id="36" string="," />
            <token id="37" string="&quot;" />
            <token id="38" string="as" />
            <token id="39" string="though" />
            <token id="40" string="they" />
            <token id="41" string="were" />
            <token id="42" string="concerti" />
          </tokens>
        </chunking>
        <chunking id="19" string="refers to pop songs as `` pieces , '' as though they were concerti" type="VP">
          <tokens>
            <token id="29" string="refers" />
            <token id="30" string="to" />
            <token id="31" string="pop" />
            <token id="32" string="songs" />
            <token id="33" string="as" />
            <token id="34" string="&quot;" />
            <token id="35" string="pieces" />
            <token id="36" string="," />
            <token id="37" string="&quot;" />
            <token id="38" string="as" />
            <token id="39" string="though" />
            <token id="40" string="they" />
            <token id="41" string="were" />
            <token id="42" string="concerti" />
          </tokens>
        </chunking>
        <chunking id="20" string="pop songs as `` pieces , '' as though they were concerti" type="VP">
          <tokens>
            <token id="31" string="pop" />
            <token id="32" string="songs" />
            <token id="33" string="as" />
            <token id="34" string="&quot;" />
            <token id="35" string="pieces" />
            <token id="36" string="," />
            <token id="37" string="&quot;" />
            <token id="38" string="as" />
            <token id="39" string="though" />
            <token id="40" string="they" />
            <token id="41" string="were" />
            <token id="42" string="concerti" />
          </tokens>
        </chunking>
        <chunking id="21" string="were concerti" type="VP">
          <tokens>
            <token id="41" string="were" />
            <token id="42" string="concerti" />
          </tokens>
        </chunking>
        <chunking id="22" string="the sloppy , pompous prose" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="sloppy" />
            <token id="9" string="," />
            <token id="10" string="pompous" />
            <token id="11" string="prose" />
          </tokens>
        </chunking>
        <chunking id="23" string="concerti" type="NP">
          <tokens>
            <token id="42" string="concerti" />
          </tokens>
        </chunking>
        <chunking id="24" string="starters" type="NP">
          <tokens>
            <token id="5" string="starters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">is</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">starters</governor>
          <dependent id="4">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">is</governor>
          <dependent id="5">starters</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">prose</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">pompous</governor>
          <dependent id="8">sloppy</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">prose</governor>
          <dependent id="10">pompous</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">starters</governor>
          <dependent id="11">prose</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">suggestive</governor>
          <dependent id="13">so</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">is</governor>
          <dependent id="14">suggestive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">lounge</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">lounge</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">lounge</governor>
          <dependent id="17">grad-school</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">lounge</governor>
          <dependent id="18">smoking</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">is</governor>
          <dependent id="19">lounge</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Goldman</governor>
          <dependent id="21">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">sort</governor>
          <dependent id="22">Goldman</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">sort</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">sort</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">is</governor>
          <dependent id="25">sort</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">writer</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">sort</governor>
          <dependent id="27">writer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">refers</governor>
          <dependent id="28">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="25">sort</governor>
          <dependent id="29">refers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">pop</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">refers</governor>
          <dependent id="31">pop</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">pop</governor>
          <dependent id="32">songs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">pieces</governor>
          <dependent id="33">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">pop</governor>
          <dependent id="35">pieces</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="42">concerti</governor>
          <dependent id="38">as</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="42">concerti</governor>
          <dependent id="39">though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">concerti</governor>
          <dependent id="40">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="42">concerti</governor>
          <dependent id="41">were</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="35">pieces</governor>
          <dependent id="42">concerti</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="smoking" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="18" string="smoking" />
          </tokens>
        </entity>
        <entity id="2" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>There is his knowing, hipper-than-thou approach -- toward drugs, sex, music -- that gives him license to second-guess Mr. Lennon&amp;apost;s every move.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="knowing" lemma="know" stem="know" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="hipper-than-thou" lemma="hipper-than-thou" stem="hipper-than-th" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="approach" lemma="approach" stem="approach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="toward" lemma="toward" stem="toward" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="drugs" lemma="drug" stem="drug" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="sex" lemma="sex" stem="sex" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="gives" lemma="give" stem="give" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="license" lemma="license" stem="licens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="second-guess" lemma="second-guess" stem="second-guess" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="move" lemma="move" stem="move" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBZ is) (NP (NP (NP (PRP$ his) (VBG knowing) (, ,) (JJ hipper-than-thou) (NN approach)) (PRN (: --) (PP (IN toward) (NP (NNS drugs))) (, ,) (NP (NP (NN sex)) (, ,) (NP (NN music))) (: --))) (SBAR (WHNP (IN that)) (S (VP (VBZ gives) (NP (PRP him)) (NP (NN license)) (S (VP (TO to) (VP (VB second-guess) (NP (NP (NNP Mr.) (NNP Lennon) (POS 's)) (NP (DT every) (NN move))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his knowing , hipper-than-thou approach -- toward drugs , sex , music -- that gives him license to second-guess Mr. Lennon 's every move" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="knowing" />
            <token id="5" string="," />
            <token id="6" string="hipper-than-thou" />
            <token id="7" string="approach" />
            <token id="8" string="--" />
            <token id="9" string="toward" />
            <token id="10" string="drugs" />
            <token id="11" string="," />
            <token id="12" string="sex" />
            <token id="13" string="," />
            <token id="14" string="music" />
            <token id="15" string="--" />
            <token id="16" string="that" />
            <token id="17" string="gives" />
            <token id="18" string="him" />
            <token id="19" string="license" />
            <token id="20" string="to" />
            <token id="21" string="second-guess" />
            <token id="22" string="Mr." />
            <token id="23" string="Lennon" />
            <token id="24" string="'s" />
            <token id="25" string="every" />
            <token id="26" string="move" />
          </tokens>
        </chunking>
        <chunking id="2" string="that gives him license to second-guess Mr. Lennon 's every move" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="gives" />
            <token id="18" string="him" />
            <token id="19" string="license" />
            <token id="20" string="to" />
            <token id="21" string="second-guess" />
            <token id="22" string="Mr." />
            <token id="23" string="Lennon" />
            <token id="24" string="'s" />
            <token id="25" string="every" />
            <token id="26" string="move" />
          </tokens>
        </chunking>
        <chunking id="3" string="drugs" type="NP">
          <tokens>
            <token id="10" string="drugs" />
          </tokens>
        </chunking>
        <chunking id="4" string="sex" type="NP">
          <tokens>
            <token id="12" string="sex" />
          </tokens>
        </chunking>
        <chunking id="5" string="second-guess Mr. Lennon 's every move" type="VP">
          <tokens>
            <token id="21" string="second-guess" />
            <token id="22" string="Mr." />
            <token id="23" string="Lennon" />
            <token id="24" string="'s" />
            <token id="25" string="every" />
            <token id="26" string="move" />
          </tokens>
        </chunking>
        <chunking id="6" string="sex , music" type="NP">
          <tokens>
            <token id="12" string="sex" />
            <token id="13" string="," />
            <token id="14" string="music" />
          </tokens>
        </chunking>
        <chunking id="7" string="every move" type="NP">
          <tokens>
            <token id="25" string="every" />
            <token id="26" string="move" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mr. Lennon 's every move" type="NP">
          <tokens>
            <token id="22" string="Mr." />
            <token id="23" string="Lennon" />
            <token id="24" string="'s" />
            <token id="25" string="every" />
            <token id="26" string="move" />
          </tokens>
        </chunking>
        <chunking id="9" string="him" type="NP">
          <tokens>
            <token id="18" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="his knowing , hipper-than-thou approach -- toward drugs , sex , music --" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="knowing" />
            <token id="5" string="," />
            <token id="6" string="hipper-than-thou" />
            <token id="7" string="approach" />
            <token id="8" string="--" />
            <token id="9" string="toward" />
            <token id="10" string="drugs" />
            <token id="11" string="," />
            <token id="12" string="sex" />
            <token id="13" string="," />
            <token id="14" string="music" />
            <token id="15" string="--" />
          </tokens>
        </chunking>
        <chunking id="11" string="is his knowing , hipper-than-thou approach -- toward drugs , sex , music -- that gives him license to second-guess Mr. Lennon 's every move" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="his" />
            <token id="4" string="knowing" />
            <token id="5" string="," />
            <token id="6" string="hipper-than-thou" />
            <token id="7" string="approach" />
            <token id="8" string="--" />
            <token id="9" string="toward" />
            <token id="10" string="drugs" />
            <token id="11" string="," />
            <token id="12" string="sex" />
            <token id="13" string="," />
            <token id="14" string="music" />
            <token id="15" string="--" />
            <token id="16" string="that" />
            <token id="17" string="gives" />
            <token id="18" string="him" />
            <token id="19" string="license" />
            <token id="20" string="to" />
            <token id="21" string="second-guess" />
            <token id="22" string="Mr." />
            <token id="23" string="Lennon" />
            <token id="24" string="'s" />
            <token id="25" string="every" />
            <token id="26" string="move" />
          </tokens>
        </chunking>
        <chunking id="12" string="his knowing , hipper-than-thou approach" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="knowing" />
            <token id="5" string="," />
            <token id="6" string="hipper-than-thou" />
            <token id="7" string="approach" />
          </tokens>
        </chunking>
        <chunking id="13" string="license" type="NP">
          <tokens>
            <token id="19" string="license" />
          </tokens>
        </chunking>
        <chunking id="14" string="music" type="NP">
          <tokens>
            <token id="14" string="music" />
          </tokens>
        </chunking>
        <chunking id="15" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="16" string="gives him license to second-guess Mr. Lennon 's every move" type="VP">
          <tokens>
            <token id="17" string="gives" />
            <token id="18" string="him" />
            <token id="19" string="license" />
            <token id="20" string="to" />
            <token id="21" string="second-guess" />
            <token id="22" string="Mr." />
            <token id="23" string="Lennon" />
            <token id="24" string="'s" />
            <token id="25" string="every" />
            <token id="26" string="move" />
          </tokens>
        </chunking>
        <chunking id="17" string="to second-guess Mr. Lennon 's every move" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="second-guess" />
            <token id="22" string="Mr." />
            <token id="23" string="Lennon" />
            <token id="24" string="'s" />
            <token id="25" string="every" />
            <token id="26" string="move" />
          </tokens>
        </chunking>
        <chunking id="18" string="Mr. Lennon 's" type="NP">
          <tokens>
            <token id="22" string="Mr." />
            <token id="23" string="Lennon" />
            <token id="24" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">is</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">approach</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">approach</governor>
          <dependent id="4">knowing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">approach</governor>
          <dependent id="6">hipper-than-thou</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">is</governor>
          <dependent id="7">approach</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">drugs</governor>
          <dependent id="9">toward</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">sex</governor>
          <dependent id="10">drugs</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">approach</governor>
          <dependent id="12">sex</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">sex</governor>
          <dependent id="14">music</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">gives</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">approach</governor>
          <dependent id="17">gives</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="17">gives</governor>
          <dependent id="18">him</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">gives</governor>
          <dependent id="19">license</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">second-guess</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">gives</governor>
          <dependent id="21">second-guess</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Lennon</governor>
          <dependent id="22">Mr.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">second-guess</governor>
          <dependent id="23">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Lennon</governor>
          <dependent id="24">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">move</governor>
          <dependent id="25">every</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">Lennon</governor>
          <dependent id="26">move</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="drugs" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="10" string="drugs" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>And there is the awkward organization, in which minor events assume large proportions for the simple reason that they reflect badly on Mr. Lennon, while major events are skipped over lightly because -- there goes the advance!</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="awkward" lemma="awkward" stem="awkward" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="organization" lemma="organization" stem="organ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="minor" lemma="minor" stem="minor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="events" lemma="event" stem="event" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="assume" lemma="assume" stem="assum" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="large" lemma="large" stem="larg" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="proportions" lemma="proportion" stem="proport" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="simple" lemma="simple" stem="simpl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="reason" lemma="reason" stem="reason" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="reflect" lemma="reflect" stem="reflect" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="badly" lemma="badly" stem="badli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="events" lemma="event" stem="event" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="skipped" lemma="skip" stem="skip" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="lightly" lemma="lightly" stem="lightli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="because" lemma="because" stem="becaus" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="goes" lemma="go" stem="goe" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="advance" lemma="advance" stem="advanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="!" lemma="!" stem="!" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (CC And) (NP (EX there)) (VP (VBZ is) (NP (NP (DT the) (JJ awkward) (NN organization)) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (JJ minor) (NNS events)) (VP (VB assume) (NP (NP (JJ large) (NNS proportions)) (PP (IN for) (NP (DT the) (JJ simple) (NN reason)))) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP reflect) (ADVP (RB badly)) (PP (IN on) (NP (NNP Mr.) (NNP Lennon)))))) (, ,) (SBAR (IN while) (S (NP (JJ major) (NNS events)) (VP (VBP are) (VP (VBN skipped) (PP (IN over) (ADVP (ADVP (RB lightly)) (RB because))))))))))))) (: --) (S (NP (EX there)) (VP (VBZ goes) (NP (DT the) (NN advance)))) (. !)))</syntactictree>
      <chunkings>
        <chunking id="1" string="minor events" type="NP">
          <tokens>
            <token id="10" string="minor" />
            <token id="11" string="events" />
          </tokens>
        </chunking>
        <chunking id="2" string="the simple reason" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="simple" />
            <token id="18" string="reason" />
          </tokens>
        </chunking>
        <chunking id="3" string="skipped over lightly because" type="VP">
          <tokens>
            <token id="31" string="skipped" />
            <token id="32" string="over" />
            <token id="33" string="lightly" />
            <token id="34" string="because" />
          </tokens>
        </chunking>
        <chunking id="4" string="the awkward organization" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="awkward" />
            <token id="6" string="organization" />
          </tokens>
        </chunking>
        <chunking id="5" string="assume large proportions for the simple reason that they reflect badly on Mr. Lennon , while major events are skipped over lightly because" type="VP">
          <tokens>
            <token id="12" string="assume" />
            <token id="13" string="large" />
            <token id="14" string="proportions" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="simple" />
            <token id="18" string="reason" />
            <token id="19" string="that" />
            <token id="20" string="they" />
            <token id="21" string="reflect" />
            <token id="22" string="badly" />
            <token id="23" string="on" />
            <token id="24" string="Mr." />
            <token id="25" string="Lennon" />
            <token id="26" string="," />
            <token id="27" string="while" />
            <token id="28" string="major" />
            <token id="29" string="events" />
            <token id="30" string="are" />
            <token id="31" string="skipped" />
            <token id="32" string="over" />
            <token id="33" string="lightly" />
            <token id="34" string="because" />
          </tokens>
        </chunking>
        <chunking id="6" string="are skipped over lightly because" type="VP">
          <tokens>
            <token id="30" string="are" />
            <token id="31" string="skipped" />
            <token id="32" string="over" />
            <token id="33" string="lightly" />
            <token id="34" string="because" />
          </tokens>
        </chunking>
        <chunking id="7" string="goes the advance" type="VP">
          <tokens>
            <token id="37" string="goes" />
            <token id="38" string="the" />
            <token id="39" string="advance" />
          </tokens>
        </chunking>
        <chunking id="8" string="major events" type="NP">
          <tokens>
            <token id="28" string="major" />
            <token id="29" string="events" />
          </tokens>
        </chunking>
        <chunking id="9" string="Mr. Lennon" type="NP">
          <tokens>
            <token id="24" string="Mr." />
            <token id="25" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="10" string="there" type="NP">
          <tokens>
            <token id="2" string="there" />
          </tokens>
        </chunking>
        <chunking id="11" string="is the awkward organization , in which minor events assume large proportions for the simple reason that they reflect badly on Mr. Lennon , while major events are skipped over lightly because" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="the" />
            <token id="5" string="awkward" />
            <token id="6" string="organization" />
            <token id="7" string="," />
            <token id="8" string="in" />
            <token id="9" string="which" />
            <token id="10" string="minor" />
            <token id="11" string="events" />
            <token id="12" string="assume" />
            <token id="13" string="large" />
            <token id="14" string="proportions" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="simple" />
            <token id="18" string="reason" />
            <token id="19" string="that" />
            <token id="20" string="they" />
            <token id="21" string="reflect" />
            <token id="22" string="badly" />
            <token id="23" string="on" />
            <token id="24" string="Mr." />
            <token id="25" string="Lennon" />
            <token id="26" string="," />
            <token id="27" string="while" />
            <token id="28" string="major" />
            <token id="29" string="events" />
            <token id="30" string="are" />
            <token id="31" string="skipped" />
            <token id="32" string="over" />
            <token id="33" string="lightly" />
            <token id="34" string="because" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="20" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="that they reflect badly on Mr. Lennon" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="they" />
            <token id="21" string="reflect" />
            <token id="22" string="badly" />
            <token id="23" string="on" />
            <token id="24" string="Mr." />
            <token id="25" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="14" string="while major events are skipped over lightly because" type="SBAR">
          <tokens>
            <token id="27" string="while" />
            <token id="28" string="major" />
            <token id="29" string="events" />
            <token id="30" string="are" />
            <token id="31" string="skipped" />
            <token id="32" string="over" />
            <token id="33" string="lightly" />
            <token id="34" string="because" />
          </tokens>
        </chunking>
        <chunking id="15" string="the advance" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="advance" />
          </tokens>
        </chunking>
        <chunking id="16" string="the awkward organization , in which minor events assume large proportions for the simple reason that they reflect badly on Mr. Lennon , while major events are skipped over lightly because" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="awkward" />
            <token id="6" string="organization" />
            <token id="7" string="," />
            <token id="8" string="in" />
            <token id="9" string="which" />
            <token id="10" string="minor" />
            <token id="11" string="events" />
            <token id="12" string="assume" />
            <token id="13" string="large" />
            <token id="14" string="proportions" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="simple" />
            <token id="18" string="reason" />
            <token id="19" string="that" />
            <token id="20" string="they" />
            <token id="21" string="reflect" />
            <token id="22" string="badly" />
            <token id="23" string="on" />
            <token id="24" string="Mr." />
            <token id="25" string="Lennon" />
            <token id="26" string="," />
            <token id="27" string="while" />
            <token id="28" string="major" />
            <token id="29" string="events" />
            <token id="30" string="are" />
            <token id="31" string="skipped" />
            <token id="32" string="over" />
            <token id="33" string="lightly" />
            <token id="34" string="because" />
          </tokens>
        </chunking>
        <chunking id="17" string="large proportions for the simple reason" type="NP">
          <tokens>
            <token id="13" string="large" />
            <token id="14" string="proportions" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="simple" />
            <token id="18" string="reason" />
          </tokens>
        </chunking>
        <chunking id="18" string="large proportions" type="NP">
          <tokens>
            <token id="13" string="large" />
            <token id="14" string="proportions" />
          </tokens>
        </chunking>
        <chunking id="19" string="reflect badly on Mr. Lennon" type="VP">
          <tokens>
            <token id="21" string="reflect" />
            <token id="22" string="badly" />
            <token id="23" string="on" />
            <token id="24" string="Mr." />
            <token id="25" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="20" string="in which minor events assume large proportions for the simple reason that they reflect badly on Mr. Lennon , while major events are skipped over lightly because" type="SBAR">
          <tokens>
            <token id="8" string="in" />
            <token id="9" string="which" />
            <token id="10" string="minor" />
            <token id="11" string="events" />
            <token id="12" string="assume" />
            <token id="13" string="large" />
            <token id="14" string="proportions" />
            <token id="15" string="for" />
            <token id="16" string="the" />
            <token id="17" string="simple" />
            <token id="18" string="reason" />
            <token id="19" string="that" />
            <token id="20" string="they" />
            <token id="21" string="reflect" />
            <token id="22" string="badly" />
            <token id="23" string="on" />
            <token id="24" string="Mr." />
            <token id="25" string="Lennon" />
            <token id="26" string="," />
            <token id="27" string="while" />
            <token id="28" string="major" />
            <token id="29" string="events" />
            <token id="30" string="are" />
            <token id="31" string="skipped" />
            <token id="32" string="over" />
            <token id="33" string="lightly" />
            <token id="34" string="because" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">is</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">organization</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">organization</governor>
          <dependent id="5">awkward</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="6">organization</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">which</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">assume</governor>
          <dependent id="9">which</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">events</governor>
          <dependent id="10">minor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">assume</governor>
          <dependent id="11">events</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">organization</governor>
          <dependent id="12">assume</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">proportions</governor>
          <dependent id="13">large</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">assume</governor>
          <dependent id="14">proportions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">reason</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">reason</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">reason</governor>
          <dependent id="17">simple</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">proportions</governor>
          <dependent id="18">reason</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">reflect</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">reflect</governor>
          <dependent id="20">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">assume</governor>
          <dependent id="21">reflect</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">reflect</governor>
          <dependent id="22">badly</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Lennon</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Lennon</governor>
          <dependent id="24">Mr.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">reflect</governor>
          <dependent id="25">Lennon</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">skipped</governor>
          <dependent id="27">while</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">events</governor>
          <dependent id="28">major</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">skipped</governor>
          <dependent id="29">events</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">skipped</governor>
          <dependent id="30">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">assume</governor>
          <dependent id="31">skipped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">because</governor>
          <dependent id="32">over</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">because</governor>
          <dependent id="33">lightly</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">skipped</governor>
          <dependent id="34">because</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="37">goes</governor>
          <dependent id="36">there</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">is</governor>
          <dependent id="37">goes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">advance</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">goes</governor>
          <dependent id="39">advance</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>-- they might reveal Mr. Lennon in a flattering light.</content>
      <tokens>
        <token id="1" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="reveal" lemma="reveal" stem="reveal" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="flattering" lemma="flattering" stem="flatter" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="light" lemma="light" stem="light" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: --) (NP (PRP they)) (VP (MD might) (VP (VB reveal) (NP (NP (NNP Mr.) (NNP Lennon)) (PP (IN in) (NP (DT a) (JJ flattering) (NN light)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="reveal Mr. Lennon in a flattering light" type="VP">
          <tokens>
            <token id="4" string="reveal" />
            <token id="5" string="Mr." />
            <token id="6" string="Lennon" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="flattering" />
            <token id="10" string="light" />
          </tokens>
        </chunking>
        <chunking id="3" string="a flattering light" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="flattering" />
            <token id="10" string="light" />
          </tokens>
        </chunking>
        <chunking id="4" string="Mr. Lennon in a flattering light" type="NP">
          <tokens>
            <token id="5" string="Mr." />
            <token id="6" string="Lennon" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="flattering" />
            <token id="10" string="light" />
          </tokens>
        </chunking>
        <chunking id="5" string="might reveal Mr. Lennon in a flattering light" type="VP">
          <tokens>
            <token id="3" string="might" />
            <token id="4" string="reveal" />
            <token id="5" string="Mr." />
            <token id="6" string="Lennon" />
            <token id="7" string="in" />
            <token id="8" string="a" />
            <token id="9" string="flattering" />
            <token id="10" string="light" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mr. Lennon" type="NP">
          <tokens>
            <token id="5" string="Mr." />
            <token id="6" string="Lennon" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">reveal</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">reveal</governor>
          <dependent id="3">might</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">reveal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Lennon</governor>
          <dependent id="5">Mr.</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">reveal</governor>
          <dependent id="6">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">light</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">light</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">light</governor>
          <dependent id="9">flattering</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">Lennon</governor>
          <dependent id="10">light</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>All of which indicates why &amp;quot;The Lives of John Lennon&amp;quot; is such a wretched book: not because it makes a good man look bad, but because it shows no other purpose than to make a man -- whether a good man or a bad one, we laymen will probably never know -- look bad.</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="indicates" lemma="indicate" stem="indic" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="wretched" lemma="wretched" stem="wretch" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="shows" lemma="show" stem="show" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="purpose" lemma="purpose" stem="purpos" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="50" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="laymen" lemma="laymen" stem="laymen" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="probably" lemma="probably" stem="probabl" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="56" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="57" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="look" lemma="look" stem="look" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="59" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="60" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT All)) (PP (IN of) (SBAR (WHNP (WDT which)) (S (VP (VBZ indicates) (SBAR (SBAR (WHADVP (WRB why)) (S (`` ``) (NP (NP (DT The) (NNS Lives)) (PP (IN of) (NP (NNP John) (NNP Lennon)))) ('' '') (VP (VBZ is) (NP (JJ such) (DT a) (JJ wretched) (NN book)) (: :) (SBAR (RB not) (IN because) (S (NP (PRP it)) (VP (VBZ makes) (S (NP (DT a) (JJ good) (NN man)) (VP (VB look) (ADJP (JJ bad)))))))))) (, ,) (CC but) (SBAR (IN because) (S (NP (PRP it)) (VP (VBZ shows) (NP (DT no) (JJ other) (NN purpose)) (PP (IN than) (NP (S (VP (TO to) (VP (VB make) (NP (DT a) (NN man))))) (PRN (: --) (SBAR (IN whether) (S (S (NP (NP (DT a) (JJ good) (NN man)) (CC or) (NP (DT a) (JJ bad) (CD one)))) (, ,) (NP (PRP we)) (VP (VBP laymen) (SBAR (S (VP (MD will) (VP (ADVP (RB probably)) (ADVP (RB never)) (VB know)))))))) (: --))))))))))))) (VP (VB look) (ADJP (JJ bad))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Lives" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="Lives" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="why `` The Lives of John Lennon '' is such a wretched book : not because it makes a good man look bad" type="SBAR">
          <tokens>
            <token id="5" string="why" />
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="Lives" />
            <token id="9" string="of" />
            <token id="10" string="John" />
            <token id="11" string="Lennon" />
            <token id="12" string="&quot;" />
            <token id="13" string="is" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="wretched" />
            <token id="17" string="book" />
            <token id="18" string=":" />
            <token id="19" string="not" />
            <token id="20" string="because" />
            <token id="21" string="it" />
            <token id="22" string="makes" />
            <token id="23" string="a" />
            <token id="24" string="good" />
            <token id="25" string="man" />
            <token id="26" string="look" />
            <token id="27" string="bad" />
          </tokens>
        </chunking>
        <chunking id="4" string="laymen will probably never know" type="VP">
          <tokens>
            <token id="52" string="laymen" />
            <token id="53" string="will" />
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
          </tokens>
        </chunking>
        <chunking id="5" string="John Lennon" type="NP">
          <tokens>
            <token id="10" string="John" />
            <token id="11" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="6" string="look bad" type="VP">
          <tokens>
            <token id="26" string="look" />
            <token id="27" string="bad" />
          </tokens>
        </chunking>
        <chunking id="7" string="The Lives of John Lennon" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="Lives" />
            <token id="9" string="of" />
            <token id="10" string="John" />
            <token id="11" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="8" string="why `` The Lives of John Lennon '' is such a wretched book : not because it makes a good man look bad , but because it shows no other purpose than to make a man -- whether a good man or a bad one , we laymen will probably never know --" type="SBAR">
          <tokens>
            <token id="5" string="why" />
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="Lives" />
            <token id="9" string="of" />
            <token id="10" string="John" />
            <token id="11" string="Lennon" />
            <token id="12" string="&quot;" />
            <token id="13" string="is" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="wretched" />
            <token id="17" string="book" />
            <token id="18" string=":" />
            <token id="19" string="not" />
            <token id="20" string="because" />
            <token id="21" string="it" />
            <token id="22" string="makes" />
            <token id="23" string="a" />
            <token id="24" string="good" />
            <token id="25" string="man" />
            <token id="26" string="look" />
            <token id="27" string="bad" />
            <token id="28" string="," />
            <token id="29" string="but" />
            <token id="30" string="because" />
            <token id="31" string="it" />
            <token id="32" string="shows" />
            <token id="33" string="no" />
            <token id="34" string="other" />
            <token id="35" string="purpose" />
            <token id="36" string="than" />
            <token id="37" string="to" />
            <token id="38" string="make" />
            <token id="39" string="a" />
            <token id="40" string="man" />
            <token id="41" string="--" />
            <token id="42" string="whether" />
            <token id="43" string="a" />
            <token id="44" string="good" />
            <token id="45" string="man" />
            <token id="46" string="or" />
            <token id="47" string="a" />
            <token id="48" string="bad" />
            <token id="49" string="one" />
            <token id="50" string="," />
            <token id="51" string="we" />
            <token id="52" string="laymen" />
            <token id="53" string="will" />
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
            <token id="57" string="--" />
          </tokens>
        </chunking>
        <chunking id="9" string="whether a good man or a bad one , we laymen will probably never know" type="SBAR">
          <tokens>
            <token id="42" string="whether" />
            <token id="43" string="a" />
            <token id="44" string="good" />
            <token id="45" string="man" />
            <token id="46" string="or" />
            <token id="47" string="a" />
            <token id="48" string="bad" />
            <token id="49" string="one" />
            <token id="50" string="," />
            <token id="51" string="we" />
            <token id="52" string="laymen" />
            <token id="53" string="will" />
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
          </tokens>
        </chunking>
        <chunking id="10" string="a man" type="NP">
          <tokens>
            <token id="39" string="a" />
            <token id="40" string="man" />
          </tokens>
        </chunking>
        <chunking id="11" string="to make a man -- whether a good man or a bad one , we laymen will probably never know --" type="NP">
          <tokens>
            <token id="37" string="to" />
            <token id="38" string="make" />
            <token id="39" string="a" />
            <token id="40" string="man" />
            <token id="41" string="--" />
            <token id="42" string="whether" />
            <token id="43" string="a" />
            <token id="44" string="good" />
            <token id="45" string="man" />
            <token id="46" string="or" />
            <token id="47" string="a" />
            <token id="48" string="bad" />
            <token id="49" string="one" />
            <token id="50" string="," />
            <token id="51" string="we" />
            <token id="52" string="laymen" />
            <token id="53" string="will" />
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
            <token id="57" string="--" />
          </tokens>
        </chunking>
        <chunking id="12" string="make a man" type="VP">
          <tokens>
            <token id="38" string="make" />
            <token id="39" string="a" />
            <token id="40" string="man" />
          </tokens>
        </chunking>
        <chunking id="13" string="a good man or a bad one" type="NP">
          <tokens>
            <token id="43" string="a" />
            <token id="44" string="good" />
            <token id="45" string="man" />
            <token id="46" string="or" />
            <token id="47" string="a" />
            <token id="48" string="bad" />
            <token id="49" string="one" />
          </tokens>
        </chunking>
        <chunking id="14" string="All" type="NP">
          <tokens>
            <token id="1" string="All" />
          </tokens>
        </chunking>
        <chunking id="15" string="not because it makes a good man look bad" type="SBAR">
          <tokens>
            <token id="19" string="not" />
            <token id="20" string="because" />
            <token id="21" string="it" />
            <token id="22" string="makes" />
            <token id="23" string="a" />
            <token id="24" string="good" />
            <token id="25" string="man" />
            <token id="26" string="look" />
            <token id="27" string="bad" />
          </tokens>
        </chunking>
        <chunking id="16" string="bad" type="ADJP">
          <tokens>
            <token id="27" string="bad" />
          </tokens>
        </chunking>
        <chunking id="17" string="shows no other purpose than to make a man -- whether a good man or a bad one , we laymen will probably never know --" type="VP">
          <tokens>
            <token id="32" string="shows" />
            <token id="33" string="no" />
            <token id="34" string="other" />
            <token id="35" string="purpose" />
            <token id="36" string="than" />
            <token id="37" string="to" />
            <token id="38" string="make" />
            <token id="39" string="a" />
            <token id="40" string="man" />
            <token id="41" string="--" />
            <token id="42" string="whether" />
            <token id="43" string="a" />
            <token id="44" string="good" />
            <token id="45" string="man" />
            <token id="46" string="or" />
            <token id="47" string="a" />
            <token id="48" string="bad" />
            <token id="49" string="one" />
            <token id="50" string="," />
            <token id="51" string="we" />
            <token id="52" string="laymen" />
            <token id="53" string="will" />
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
            <token id="57" string="--" />
          </tokens>
        </chunking>
        <chunking id="18" string="will probably never know" type="SBAR">
          <tokens>
            <token id="53" string="will" />
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
          </tokens>
        </chunking>
        <chunking id="19" string="why" type="WHADVP">
          <tokens>
            <token id="5" string="why" />
          </tokens>
        </chunking>
        <chunking id="20" string="a bad one" type="NP">
          <tokens>
            <token id="47" string="a" />
            <token id="48" string="bad" />
            <token id="49" string="one" />
          </tokens>
        </chunking>
        <chunking id="21" string="to make a man" type="VP">
          <tokens>
            <token id="37" string="to" />
            <token id="38" string="make" />
            <token id="39" string="a" />
            <token id="40" string="man" />
          </tokens>
        </chunking>
        <chunking id="22" string="makes a good man look bad" type="VP">
          <tokens>
            <token id="22" string="makes" />
            <token id="23" string="a" />
            <token id="24" string="good" />
            <token id="25" string="man" />
            <token id="26" string="look" />
            <token id="27" string="bad" />
          </tokens>
        </chunking>
        <chunking id="23" string="we" type="NP">
          <tokens>
            <token id="51" string="we" />
          </tokens>
        </chunking>
        <chunking id="24" string="All of which indicates why `` The Lives of John Lennon '' is such a wretched book : not because it makes a good man look bad , but because it shows no other purpose than to make a man -- whether a good man or a bad one , we laymen will probably never know --" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="of" />
            <token id="3" string="which" />
            <token id="4" string="indicates" />
            <token id="5" string="why" />
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="Lives" />
            <token id="9" string="of" />
            <token id="10" string="John" />
            <token id="11" string="Lennon" />
            <token id="12" string="&quot;" />
            <token id="13" string="is" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="wretched" />
            <token id="17" string="book" />
            <token id="18" string=":" />
            <token id="19" string="not" />
            <token id="20" string="because" />
            <token id="21" string="it" />
            <token id="22" string="makes" />
            <token id="23" string="a" />
            <token id="24" string="good" />
            <token id="25" string="man" />
            <token id="26" string="look" />
            <token id="27" string="bad" />
            <token id="28" string="," />
            <token id="29" string="but" />
            <token id="30" string="because" />
            <token id="31" string="it" />
            <token id="32" string="shows" />
            <token id="33" string="no" />
            <token id="34" string="other" />
            <token id="35" string="purpose" />
            <token id="36" string="than" />
            <token id="37" string="to" />
            <token id="38" string="make" />
            <token id="39" string="a" />
            <token id="40" string="man" />
            <token id="41" string="--" />
            <token id="42" string="whether" />
            <token id="43" string="a" />
            <token id="44" string="good" />
            <token id="45" string="man" />
            <token id="46" string="or" />
            <token id="47" string="a" />
            <token id="48" string="bad" />
            <token id="49" string="one" />
            <token id="50" string="," />
            <token id="51" string="we" />
            <token id="52" string="laymen" />
            <token id="53" string="will" />
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
            <token id="57" string="--" />
          </tokens>
        </chunking>
        <chunking id="25" string="probably never know" type="VP">
          <tokens>
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
          </tokens>
        </chunking>
        <chunking id="26" string="indicates why `` The Lives of John Lennon '' is such a wretched book : not because it makes a good man look bad , but because it shows no other purpose than to make a man -- whether a good man or a bad one , we laymen will probably never know --" type="VP">
          <tokens>
            <token id="4" string="indicates" />
            <token id="5" string="why" />
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="Lives" />
            <token id="9" string="of" />
            <token id="10" string="John" />
            <token id="11" string="Lennon" />
            <token id="12" string="&quot;" />
            <token id="13" string="is" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="wretched" />
            <token id="17" string="book" />
            <token id="18" string=":" />
            <token id="19" string="not" />
            <token id="20" string="because" />
            <token id="21" string="it" />
            <token id="22" string="makes" />
            <token id="23" string="a" />
            <token id="24" string="good" />
            <token id="25" string="man" />
            <token id="26" string="look" />
            <token id="27" string="bad" />
            <token id="28" string="," />
            <token id="29" string="but" />
            <token id="30" string="because" />
            <token id="31" string="it" />
            <token id="32" string="shows" />
            <token id="33" string="no" />
            <token id="34" string="other" />
            <token id="35" string="purpose" />
            <token id="36" string="than" />
            <token id="37" string="to" />
            <token id="38" string="make" />
            <token id="39" string="a" />
            <token id="40" string="man" />
            <token id="41" string="--" />
            <token id="42" string="whether" />
            <token id="43" string="a" />
            <token id="44" string="good" />
            <token id="45" string="man" />
            <token id="46" string="or" />
            <token id="47" string="a" />
            <token id="48" string="bad" />
            <token id="49" string="one" />
            <token id="50" string="," />
            <token id="51" string="we" />
            <token id="52" string="laymen" />
            <token id="53" string="will" />
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
            <token id="57" string="--" />
          </tokens>
        </chunking>
        <chunking id="27" string="because it shows no other purpose than to make a man -- whether a good man or a bad one , we laymen will probably never know --" type="SBAR">
          <tokens>
            <token id="30" string="because" />
            <token id="31" string="it" />
            <token id="32" string="shows" />
            <token id="33" string="no" />
            <token id="34" string="other" />
            <token id="35" string="purpose" />
            <token id="36" string="than" />
            <token id="37" string="to" />
            <token id="38" string="make" />
            <token id="39" string="a" />
            <token id="40" string="man" />
            <token id="41" string="--" />
            <token id="42" string="whether" />
            <token id="43" string="a" />
            <token id="44" string="good" />
            <token id="45" string="man" />
            <token id="46" string="or" />
            <token id="47" string="a" />
            <token id="48" string="bad" />
            <token id="49" string="one" />
            <token id="50" string="," />
            <token id="51" string="we" />
            <token id="52" string="laymen" />
            <token id="53" string="will" />
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
            <token id="57" string="--" />
          </tokens>
        </chunking>
        <chunking id="28" string="is such a wretched book : not because it makes a good man look bad" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="wretched" />
            <token id="17" string="book" />
            <token id="18" string=":" />
            <token id="19" string="not" />
            <token id="20" string="because" />
            <token id="21" string="it" />
            <token id="22" string="makes" />
            <token id="23" string="a" />
            <token id="24" string="good" />
            <token id="25" string="man" />
            <token id="26" string="look" />
            <token id="27" string="bad" />
          </tokens>
        </chunking>
        <chunking id="29" string="such a wretched book" type="NP">
          <tokens>
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="wretched" />
            <token id="17" string="book" />
          </tokens>
        </chunking>
        <chunking id="30" string="which indicates why `` The Lives of John Lennon '' is such a wretched book : not because it makes a good man look bad , but because it shows no other purpose than to make a man -- whether a good man or a bad one , we laymen will probably never know --" type="SBAR">
          <tokens>
            <token id="3" string="which" />
            <token id="4" string="indicates" />
            <token id="5" string="why" />
            <token id="6" string="&quot;" />
            <token id="7" string="The" />
            <token id="8" string="Lives" />
            <token id="9" string="of" />
            <token id="10" string="John" />
            <token id="11" string="Lennon" />
            <token id="12" string="&quot;" />
            <token id="13" string="is" />
            <token id="14" string="such" />
            <token id="15" string="a" />
            <token id="16" string="wretched" />
            <token id="17" string="book" />
            <token id="18" string=":" />
            <token id="19" string="not" />
            <token id="20" string="because" />
            <token id="21" string="it" />
            <token id="22" string="makes" />
            <token id="23" string="a" />
            <token id="24" string="good" />
            <token id="25" string="man" />
            <token id="26" string="look" />
            <token id="27" string="bad" />
            <token id="28" string="," />
            <token id="29" string="but" />
            <token id="30" string="because" />
            <token id="31" string="it" />
            <token id="32" string="shows" />
            <token id="33" string="no" />
            <token id="34" string="other" />
            <token id="35" string="purpose" />
            <token id="36" string="than" />
            <token id="37" string="to" />
            <token id="38" string="make" />
            <token id="39" string="a" />
            <token id="40" string="man" />
            <token id="41" string="--" />
            <token id="42" string="whether" />
            <token id="43" string="a" />
            <token id="44" string="good" />
            <token id="45" string="man" />
            <token id="46" string="or" />
            <token id="47" string="a" />
            <token id="48" string="bad" />
            <token id="49" string="one" />
            <token id="50" string="," />
            <token id="51" string="we" />
            <token id="52" string="laymen" />
            <token id="53" string="will" />
            <token id="54" string="probably" />
            <token id="55" string="never" />
            <token id="56" string="know" />
            <token id="57" string="--" />
          </tokens>
        </chunking>
        <chunking id="31" string="no other purpose" type="NP">
          <tokens>
            <token id="33" string="no" />
            <token id="34" string="other" />
            <token id="35" string="purpose" />
          </tokens>
        </chunking>
        <chunking id="32" string="a good man" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="good" />
            <token id="25" string="man" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="58">look</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">indicates</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">indicates</governor>
          <dependent id="3">which</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">All</governor>
          <dependent id="4">indicates</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">book</governor>
          <dependent id="5">why</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Lives</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">book</governor>
          <dependent id="8">Lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Lennon</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Lennon</governor>
          <dependent id="10">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">Lives</governor>
          <dependent id="11">Lennon</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">book</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">book</governor>
          <dependent id="14">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">book</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">book</governor>
          <dependent id="16">wretched</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">indicates</governor>
          <dependent id="17">book</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">makes</governor>
          <dependent id="19">not</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">makes</governor>
          <dependent id="20">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">makes</governor>
          <dependent id="21">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">book</governor>
          <dependent id="22">makes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">man</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">man</governor>
          <dependent id="24">good</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">look</governor>
          <dependent id="25">man</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">makes</governor>
          <dependent id="26">look</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">look</governor>
          <dependent id="27">bad</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">book</governor>
          <dependent id="29">but</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">shows</governor>
          <dependent id="30">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">shows</governor>
          <dependent id="31">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">book</governor>
          <dependent id="32">shows</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="35">purpose</governor>
          <dependent id="33">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">purpose</governor>
          <dependent id="34">other</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">shows</governor>
          <dependent id="35">purpose</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">laymen</governor>
          <dependent id="36">than</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">make</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="52">laymen</governor>
          <dependent id="38">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">man</governor>
          <dependent id="39">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">make</governor>
          <dependent id="40">man</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="52">laymen</governor>
          <dependent id="42">whether</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">man</governor>
          <dependent id="43">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="45">man</governor>
          <dependent id="44">good</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="52">laymen</governor>
          <dependent id="45">man</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="45">man</governor>
          <dependent id="46">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="49">one</governor>
          <dependent id="47">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="49">one</governor>
          <dependent id="48">bad</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="45">man</governor>
          <dependent id="49">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="52">laymen</governor>
          <dependent id="51">we</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">shows</governor>
          <dependent id="52">laymen</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="56">know</governor>
          <dependent id="53">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="56">know</governor>
          <dependent id="54">probably</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="56">know</governor>
          <dependent id="55">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="52">laymen</governor>
          <dependent id="56">know</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="58">look</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="58">look</governor>
          <dependent id="59">bad</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="John" />
            <token id="11" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="49" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>John Lennon, while he was alive, did enough of that himself to satisfy all but the lowest appetites.</content>
      <tokens>
        <token id="1" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="alive" lemma="alive" stem="aliv" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="enough" lemma="enough" stem="enough" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="satisfy" lemma="satisfy" stem="satisfi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="lowest" lemma="lowest" stem="lowest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="appetites" lemma="appetite" stem="appetit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP John) (NNP Lennon)) (, ,) (SBAR (IN while) (S (NP (PRP he)) (VP (VBD was) (ADJP (JJ alive))))) (, ,)) (VP (VBD did) (NP (NP (RB enough)) (PP (IN of) (SBAR (WHNP (DT that)) (S (NP (PRP himself)) (VP (TO to) (VP (VB satisfy) (ADVP (DT all) (CC but)) (NP (DT the) (JJS lowest) (NNS appetites))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="enough of that himself to satisfy all but the lowest appetites" type="NP">
          <tokens>
            <token id="10" string="enough" />
            <token id="11" string="of" />
            <token id="12" string="that" />
            <token id="13" string="himself" />
            <token id="14" string="to" />
            <token id="15" string="satisfy" />
            <token id="16" string="all" />
            <token id="17" string="but" />
            <token id="18" string="the" />
            <token id="19" string="lowest" />
            <token id="20" string="appetites" />
          </tokens>
        </chunking>
        <chunking id="2" string="that himself to satisfy all but the lowest appetites" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="himself" />
            <token id="14" string="to" />
            <token id="15" string="satisfy" />
            <token id="16" string="all" />
            <token id="17" string="but" />
            <token id="18" string="the" />
            <token id="19" string="lowest" />
            <token id="20" string="appetites" />
          </tokens>
        </chunking>
        <chunking id="3" string="to satisfy all but the lowest appetites" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="satisfy" />
            <token id="16" string="all" />
            <token id="17" string="but" />
            <token id="18" string="the" />
            <token id="19" string="lowest" />
            <token id="20" string="appetites" />
          </tokens>
        </chunking>
        <chunking id="4" string="alive" type="ADJP">
          <tokens>
            <token id="7" string="alive" />
          </tokens>
        </chunking>
        <chunking id="5" string="was alive" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="alive" />
          </tokens>
        </chunking>
        <chunking id="6" string="satisfy all but the lowest appetites" type="VP">
          <tokens>
            <token id="15" string="satisfy" />
            <token id="16" string="all" />
            <token id="17" string="but" />
            <token id="18" string="the" />
            <token id="19" string="lowest" />
            <token id="20" string="appetites" />
          </tokens>
        </chunking>
        <chunking id="7" string="the lowest appetites" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="lowest" />
            <token id="20" string="appetites" />
          </tokens>
        </chunking>
        <chunking id="8" string="John Lennon , while he was alive ," type="NP">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Lennon" />
            <token id="3" string="," />
            <token id="4" string="while" />
            <token id="5" string="he" />
            <token id="6" string="was" />
            <token id="7" string="alive" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="did enough of that himself to satisfy all but the lowest appetites" type="VP">
          <tokens>
            <token id="9" string="did" />
            <token id="10" string="enough" />
            <token id="11" string="of" />
            <token id="12" string="that" />
            <token id="13" string="himself" />
            <token id="14" string="to" />
            <token id="15" string="satisfy" />
            <token id="16" string="all" />
            <token id="17" string="but" />
            <token id="18" string="the" />
            <token id="19" string="lowest" />
            <token id="20" string="appetites" />
          </tokens>
        </chunking>
        <chunking id="10" string="John Lennon" type="NP">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="11" string="enough" type="NP">
          <tokens>
            <token id="10" string="enough" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="himself" type="NP">
          <tokens>
            <token id="13" string="himself" />
          </tokens>
        </chunking>
        <chunking id="14" string="while he was alive" type="SBAR">
          <tokens>
            <token id="4" string="while" />
            <token id="5" string="he" />
            <token id="6" string="was" />
            <token id="7" string="alive" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Lennon</governor>
          <dependent id="1">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">did</governor>
          <dependent id="2">Lennon</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">alive</governor>
          <dependent id="4">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">alive</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">alive</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">Lennon</governor>
          <dependent id="7">alive</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">did</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">did</governor>
          <dependent id="10">enough</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">satisfy</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">satisfy</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">satisfy</governor>
          <dependent id="13">himself</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">satisfy</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">enough</governor>
          <dependent id="15">satisfy</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">satisfy</governor>
          <dependent id="16">all</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">all</governor>
          <dependent id="17">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">appetites</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">appetites</governor>
          <dependent id="19">lowest</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">satisfy</governor>
          <dependent id="20">appetites</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="false">
      <content>--- Mr. Ferguson is assistant managing editor of The American Spectator.</content>
      <tokens>
        <token id="1" string="---" lemma="--" stem="---" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Mr." lemma="Mr." stem="mr." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Ferguson" lemma="Ferguson" stem="ferguson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="assistant" lemma="assistant" stem="assist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="managing" lemma="managing" stem="manag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="editor" lemma="editor" stem="editor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="11" string="Spectator" lemma="Spectator" stem="spectat" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: --) (NP (NNP Mr.) (NNP Ferguson)) (VP (VBZ is) (NP (NP (JJ assistant) (NN managing) (NN editor)) (PP (IN of) (NP (DT The) (JJ American) (NNP Spectator))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="assistant managing editor" type="NP">
          <tokens>
            <token id="5" string="assistant" />
            <token id="6" string="managing" />
            <token id="7" string="editor" />
          </tokens>
        </chunking>
        <chunking id="2" string="The American Spectator" type="NP">
          <tokens>
            <token id="9" string="The" />
            <token id="10" string="American" />
            <token id="11" string="Spectator" />
          </tokens>
        </chunking>
        <chunking id="3" string="assistant managing editor of The American Spectator" type="NP">
          <tokens>
            <token id="5" string="assistant" />
            <token id="6" string="managing" />
            <token id="7" string="editor" />
            <token id="8" string="of" />
            <token id="9" string="The" />
            <token id="10" string="American" />
            <token id="11" string="Spectator" />
          </tokens>
        </chunking>
        <chunking id="4" string="is assistant managing editor of The American Spectator" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="assistant" />
            <token id="6" string="managing" />
            <token id="7" string="editor" />
            <token id="8" string="of" />
            <token id="9" string="The" />
            <token id="10" string="American" />
            <token id="11" string="Spectator" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mr. Ferguson" type="NP">
          <tokens>
            <token id="2" string="Mr." />
            <token id="3" string="Ferguson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Ferguson</governor>
          <dependent id="2">Mr.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">editor</governor>
          <dependent id="3">Ferguson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">editor</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">editor</governor>
          <dependent id="5">assistant</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">editor</governor>
          <dependent id="6">managing</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">editor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Spectator</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Spectator</governor>
          <dependent id="9">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Spectator</governor>
          <dependent id="10">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">editor</governor>
          <dependent id="11">Spectator</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ferguson" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Ferguson" />
          </tokens>
        </entity>
        <entity id="2" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="10" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="6-7" string="Albert Goldman" id_sentence="1" />
      <mentions>
        <mention ids_tokens="1-3" string="Albert Goldman's" id_sentence="5" />
        <mention ids_tokens="20-22" string="Mr. Goldman's" id_sentence="6" />
        <mention ids_tokens="11-12" string="Mr. Goldman" id_sentence="8" />
        <mention ids_tokens="14-17" string="Mr. Goldman , hot" id_sentence="15" />
        <mention ids_tokens="14-15" string="Mr. Goldman" id_sentence="15" />
        <mention ids_tokens="15" string="Goldman" id_sentence="15" />
        <mention ids_tokens="22" string="his" id_sentence="15" />
        <mention ids_tokens="2-3" string="Mr. Goldman" id_sentence="17" />
        <mention ids_tokens="9" string="He" id_sentence="17" />
        <mention ids_tokens="12-14" string="Mr. Goldman's" id_sentence="20" />
        <mention ids_tokens="15-16" string="Mr. Goldman" id_sentence="21" />
        <mention ids_tokens="1-2" string="Mr. Goldman" id_sentence="22" />
        <mention ids_tokens="2" string="Goldman" id_sentence="22" />
        <mention ids_tokens="22" string="himself" id_sentence="22" />
        <mention ids_tokens="20-22" string="Mr. Goldman's" id_sentence="28" />
        <mention ids_tokens="21-22" string="Mr. Goldman" id_sentence="29" />
        <mention ids_tokens="3" string="his" id_sentence="30" />
        <mention ids_tokens="18" string="him" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="12-13-14-15-16" string="Mr. Goldman 's John Lennon" id_sentence="20" />
      <mentions>
        <mention ids_tokens="20-21" string="John Lennon" id_sentence="1" />
        <mention ids_tokens="4-9" string="Mr. Lennon as his next target" id_sentence="8" />
        <mention ids_tokens="4" string="his" id_sentence="9" />
        <mention ids_tokens="8-10" string="Mr. Lennon's" id_sentence="9" />
        <mention ids_tokens="18" string="he" id_sentence="9" />
        <mention ids_tokens="21" string="his" id_sentence="9" />
        <mention ids_tokens="26" string="His" id_sentence="9" />
        <mention ids_tokens="31" string="his" id_sentence="9" />
        <mention ids_tokens="36" string="his" id_sentence="9" />
        <mention ids_tokens="2" string="his" id_sentence="10" />
        <mention ids_tokens="8-9" string="Mr. Lennon" id_sentence="10" />
        <mention ids_tokens="1" string="His" id_sentence="11" />
        <mention ids_tokens="4" string="him" id_sentence="11" />
        <mention ids_tokens="1-2" string="Mr. Lennon" id_sentence="12" />
        <mention ids_tokens="1" string="His" id_sentence="14" />
        <mention ids_tokens="4-6" string="Mr. Lennon's" id_sentence="16" />
        <mention ids_tokens="10" string="his" id_sentence="16" />
        <mention ids_tokens="15" string="him" id_sentence="16" />
        <mention ids_tokens="22" string="he" id_sentence="16" />
        <mention ids_tokens="36-37" string="Mr. Lennon" id_sentence="18" />
        <mention ids_tokens="28-29" string="Mr. Lennon" id_sentence="21" />
        <mention ids_tokens="5" string="Lennon" id_sentence="23" />
        <mention ids_tokens="12" string="Lennon" id_sentence="25" />
        <mention ids_tokens="6-7" string="John Lennon" id_sentence="26" />
        <mention ids_tokens="29" string="his" id_sentence="26" />
        <mention ids_tokens="24-25" string="Mr. Lennon" id_sentence="31" />
        <mention ids_tokens="25" string="Lennon" id_sentence="31" />
        <mention ids_tokens="10-11" string="John Lennon" id_sentence="33" />
        <mention ids_tokens="1-7" string="John Lennon , while he was alive" id_sentence="34" />
        <mention ids_tokens="1-2" string="John Lennon" id_sentence="34" />
        <mention ids_tokens="5" string="he" id_sentence="34" />
        <mention ids_tokens="13" string="himself" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="3" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="the new biography" id_sentence="1" />
      <mentions>
        <mention ids_tokens="36-37" string="the biography" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="43-44-45" string="one ambitious sleazemonger" id_sentence="1" />
      <mentions>
        <mention ids_tokens="5-7" string="the sleazemonger's" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="19-20" string="the public" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1-2" string="His public" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="10-11" string="Elvis Presley" id_sentence="5" />
      <mentions>
        <mention ids_tokens="2-3" string="Mr. Presley" id_sentence="6" />
        <mention ids_tokens="1" string="His" id_sentence="7" />
        <mention ids_tokens="7" string="his" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="his own accounting" id_sentence="10" />
      <mentions>
        <mention ids_tokens="15" string="it" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="15" type="LIST">
      <referenced ids_tokens="8-9-10-11-12-13-14-15-16" string="it all -- or perhaps because of it all" id_sentence="11" />
      <mentions>
        <mention ids_tokens="3" string="their" id_sentence="13" />
        <mention ids_tokens="5" string="that" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15" string="a time when such transgressions as intemperance and adultery" id_sentence="12" />
      <mentions>
        <mention ids_tokens="8" string="it" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15" string="His candor -- if that 's what it was , and not simple logorrhea --" id_sentence="14" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="20-21" string="Yoko Ono" id_sentence="16" />
      <mentions>
        <mention ids_tokens="49-50" string="Ms. Ono" id_sentence="18" />
        <mention ids_tokens="11-38" string="Ms. Ono , whom Mr. Goldman portrays as a cynical manipulator whose major talent lay in exploiting Mr. Lennon to further her own craving for fame and wealth" id_sentence="21" />
        <mention ids_tokens="11-12" string="Ms. Ono" id_sentence="21" />
        <mention ids_tokens="12" string="Ono" id_sentence="21" />
        <mention ids_tokens="32" string="her" id_sentence="21" />
        <mention ids_tokens="1-2" string="Ms. Ono" id_sentence="24" />
        <mention ids_tokens="2" string="Ono" id_sentence="24" />
        <mention ids_tokens="4" string="her" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="16-17-18-19-20-21-22" string="a rather fine thumbnail sketch of himself" id_sentence="22" />
      <mentions>
        <mention ids_tokens="14" string="this" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="22-23" string="the book" id_sentence="25" />
      <mentions>
        <mention ids_tokens="9" string="its" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16-17-18" string="large proportions for the simple reason" id_sentence="31" />
      <mentions>
        <mention ids_tokens="2" string="they" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="8-9-10" string="a flattering light" id_sentence="32" />
      <mentions>
        <mention ids_tokens="21" string="it" id_sentence="33" />
        <mention ids_tokens="31" string="it" id_sentence="33" />
      </mentions>
    </coreference>
  </coreferences>
</document>
