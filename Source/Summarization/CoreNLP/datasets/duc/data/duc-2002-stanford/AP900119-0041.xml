<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP900119-0041">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>There was plenty of blame to go around at the end of the lengthy and traumatic McMartin Pre-School molestation trial, but no one was willing to accept it.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="plenty" lemma="plenty" stem="plenti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="blame" lemma="blame" stem="blame" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="around" lemma="around" stem="around" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="lengthy" lemma="lengthy" stem="lengthi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="traumatic" lemma="traumatic" stem="traumat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="18" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="25" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="willing" lemma="willing" stem="will" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="accept" lemma="accept" stem="accept" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (EX There)) (VP (VBD was) (NP (NP (NN plenty)) (PP (IN of) (NP (NN blame))) (S (VP (TO to) (VP (VB go) (ADVP (RB around)) (PP (IN at) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (NP (DT the) (JJ lengthy)) (CC and) (NP (JJ traumatic) (NNP McMartin) (NNP Pre-School) (NN molestation) (NN trial)))))))))))) (, ,) (CC but) (S (NP (DT no) (NN one)) (VP (VBD was) (ADJP (JJ willing) (S (VP (TO to) (VP (VB accept) (NP (PRP it)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the end" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="end" />
          </tokens>
        </chunking>
        <chunking id="2" string="the end of the lengthy and traumatic McMartin Pre-School molestation trial" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="end" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="lengthy" />
            <token id="15" string="and" />
            <token id="16" string="traumatic" />
            <token id="17" string="McMartin" />
            <token id="18" string="Pre-School" />
            <token id="19" string="molestation" />
            <token id="20" string="trial" />
          </tokens>
        </chunking>
        <chunking id="3" string="accept it" type="VP">
          <tokens>
            <token id="28" string="accept" />
            <token id="29" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="no one" type="NP">
          <tokens>
            <token id="23" string="no" />
            <token id="24" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="to accept it" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="accept" />
            <token id="29" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="the lengthy and traumatic McMartin Pre-School molestation trial" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="lengthy" />
            <token id="15" string="and" />
            <token id="16" string="traumatic" />
            <token id="17" string="McMartin" />
            <token id="18" string="Pre-School" />
            <token id="19" string="molestation" />
            <token id="20" string="trial" />
          </tokens>
        </chunking>
        <chunking id="7" string="willing to accept it" type="ADJP">
          <tokens>
            <token id="26" string="willing" />
            <token id="27" string="to" />
            <token id="28" string="accept" />
            <token id="29" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="plenty" type="NP">
          <tokens>
            <token id="3" string="plenty" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="29" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="11" string="was plenty of blame to go around at the end of the lengthy and traumatic McMartin Pre-School molestation trial" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="plenty" />
            <token id="4" string="of" />
            <token id="5" string="blame" />
            <token id="6" string="to" />
            <token id="7" string="go" />
            <token id="8" string="around" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="end" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="lengthy" />
            <token id="15" string="and" />
            <token id="16" string="traumatic" />
            <token id="17" string="McMartin" />
            <token id="18" string="Pre-School" />
            <token id="19" string="molestation" />
            <token id="20" string="trial" />
          </tokens>
        </chunking>
        <chunking id="12" string="the lengthy" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="lengthy" />
          </tokens>
        </chunking>
        <chunking id="13" string="plenty of blame to go around at the end of the lengthy and traumatic McMartin Pre-School molestation trial" type="NP">
          <tokens>
            <token id="3" string="plenty" />
            <token id="4" string="of" />
            <token id="5" string="blame" />
            <token id="6" string="to" />
            <token id="7" string="go" />
            <token id="8" string="around" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="end" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="lengthy" />
            <token id="15" string="and" />
            <token id="16" string="traumatic" />
            <token id="17" string="McMartin" />
            <token id="18" string="Pre-School" />
            <token id="19" string="molestation" />
            <token id="20" string="trial" />
          </tokens>
        </chunking>
        <chunking id="14" string="go around at the end of the lengthy and traumatic McMartin Pre-School molestation trial" type="VP">
          <tokens>
            <token id="7" string="go" />
            <token id="8" string="around" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="end" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="lengthy" />
            <token id="15" string="and" />
            <token id="16" string="traumatic" />
            <token id="17" string="McMartin" />
            <token id="18" string="Pre-School" />
            <token id="19" string="molestation" />
            <token id="20" string="trial" />
          </tokens>
        </chunking>
        <chunking id="15" string="blame" type="NP">
          <tokens>
            <token id="5" string="blame" />
          </tokens>
        </chunking>
        <chunking id="16" string="traumatic McMartin Pre-School molestation trial" type="NP">
          <tokens>
            <token id="16" string="traumatic" />
            <token id="17" string="McMartin" />
            <token id="18" string="Pre-School" />
            <token id="19" string="molestation" />
            <token id="20" string="trial" />
          </tokens>
        </chunking>
        <chunking id="17" string="to go around at the end of the lengthy and traumatic McMartin Pre-School molestation trial" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="go" />
            <token id="8" string="around" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="end" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="lengthy" />
            <token id="15" string="and" />
            <token id="16" string="traumatic" />
            <token id="17" string="McMartin" />
            <token id="18" string="Pre-School" />
            <token id="19" string="molestation" />
            <token id="20" string="trial" />
          </tokens>
        </chunking>
        <chunking id="18" string="was willing to accept it" type="VP">
          <tokens>
            <token id="25" string="was" />
            <token id="26" string="willing" />
            <token id="27" string="to" />
            <token id="28" string="accept" />
            <token id="29" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">was</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">was</governor>
          <dependent id="3">plenty</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">blame</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">plenty</governor>
          <dependent id="5">blame</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">go</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">plenty</governor>
          <dependent id="7">go</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">go</governor>
          <dependent id="8">around</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">end</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">end</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">go</governor>
          <dependent id="11">end</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">lengthy</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">lengthy</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">end</governor>
          <dependent id="14">lengthy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">lengthy</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">trial</governor>
          <dependent id="16">traumatic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">trial</governor>
          <dependent id="17">McMartin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">trial</governor>
          <dependent id="18">Pre-School</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">trial</governor>
          <dependent id="19">molestation</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">lengthy</governor>
          <dependent id="20">trial</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">was</governor>
          <dependent id="22">but</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="24">one</governor>
          <dependent id="23">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">willing</governor>
          <dependent id="24">one</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="26">willing</governor>
          <dependent id="25">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">was</governor>
          <dependent id="26">willing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">accept</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">willing</governor>
          <dependent id="28">accept</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">accept</governor>
          <dependent id="29">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="McMartin Pre-School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="McMartin" />
            <token id="18" string="Pre-School" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>In the nation&amp;apost;s longest and costliest trial, Raymond Buckey and his mother, Peggy McMartin Buckey, were acquitted Thursday on 52 child molestation charges.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="nation" lemma="nation" stem="nation" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="longest" lemma="longest" stem="longest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="costliest" lemma="costliest" stem="costliest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Raymond" lemma="Raymond" stem="raymond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="acquitted" lemma="acquit" stem="acquit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="52" lemma="52" stem="52" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="25" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT the) (NN nation) (POS 's)) (ADJP (JJS longest) (CC and) (JJS costliest)) (NN trial))) (, ,) (NP (NP (NP (NNP Raymond) (NNP Buckey)) (CC and) (NP (PRP$ his) (NN mother))) (, ,) (NP (NNP Peggy) (NNP McMartin) (NNP Buckey)) (, ,)) (VP (VBD were) (VP (VBN acquitted) (NP-TMP (NNP Thursday)) (PP (IN on) (NP (CD 52) (NN child) (NN molestation) (NNS charges))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="16" string="Peggy" />
            <token id="17" string="McMartin" />
            <token id="18" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="acquitted Thursday on 52 child molestation charges" type="VP">
          <tokens>
            <token id="21" string="acquitted" />
            <token id="22" string="Thursday" />
            <token id="23" string="on" />
            <token id="24" string="52" />
            <token id="25" string="child" />
            <token id="26" string="molestation" />
            <token id="27" string="charges" />
          </tokens>
        </chunking>
        <chunking id="3" string="the nation 's longest and costliest trial" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="nation" />
            <token id="4" string="'s" />
            <token id="5" string="longest" />
            <token id="6" string="and" />
            <token id="7" string="costliest" />
            <token id="8" string="trial" />
          </tokens>
        </chunking>
        <chunking id="4" string="Raymond Buckey and his mother" type="NP">
          <tokens>
            <token id="10" string="Raymond" />
            <token id="11" string="Buckey" />
            <token id="12" string="and" />
            <token id="13" string="his" />
            <token id="14" string="mother" />
          </tokens>
        </chunking>
        <chunking id="5" string="his mother" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="mother" />
          </tokens>
        </chunking>
        <chunking id="6" string="longest and costliest" type="ADJP">
          <tokens>
            <token id="5" string="longest" />
            <token id="6" string="and" />
            <token id="7" string="costliest" />
          </tokens>
        </chunking>
        <chunking id="7" string="were acquitted Thursday on 52 child molestation charges" type="VP">
          <tokens>
            <token id="20" string="were" />
            <token id="21" string="acquitted" />
            <token id="22" string="Thursday" />
            <token id="23" string="on" />
            <token id="24" string="52" />
            <token id="25" string="child" />
            <token id="26" string="molestation" />
            <token id="27" string="charges" />
          </tokens>
        </chunking>
        <chunking id="8" string="52 child molestation charges" type="NP">
          <tokens>
            <token id="24" string="52" />
            <token id="25" string="child" />
            <token id="26" string="molestation" />
            <token id="27" string="charges" />
          </tokens>
        </chunking>
        <chunking id="9" string="the nation 's" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="nation" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="Raymond Buckey and his mother , Peggy McMartin Buckey ," type="NP">
          <tokens>
            <token id="10" string="Raymond" />
            <token id="11" string="Buckey" />
            <token id="12" string="and" />
            <token id="13" string="his" />
            <token id="14" string="mother" />
            <token id="15" string="," />
            <token id="16" string="Peggy" />
            <token id="17" string="McMartin" />
            <token id="18" string="Buckey" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="Raymond Buckey" type="NP">
          <tokens>
            <token id="10" string="Raymond" />
            <token id="11" string="Buckey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="8">trial</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">nation</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">trial</governor>
          <dependent id="3">nation</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">nation</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">trial</governor>
          <dependent id="5">longest</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">longest</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">longest</governor>
          <dependent id="7">costliest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">acquitted</governor>
          <dependent id="8">trial</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Buckey</governor>
          <dependent id="10">Raymond</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">acquitted</governor>
          <dependent id="11">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">Buckey</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">mother</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">Buckey</governor>
          <dependent id="14">mother</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Buckey</governor>
          <dependent id="16">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Buckey</governor>
          <dependent id="17">McMartin</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">Buckey</governor>
          <dependent id="18">Buckey</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">acquitted</governor>
          <dependent id="20">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">acquitted</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="21">acquitted</governor>
          <dependent id="22">Thursday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">charges</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">charges</governor>
          <dependent id="24">52</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">charges</governor>
          <dependent id="25">child</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">charges</governor>
          <dependent id="26">molestation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">acquitted</governor>
          <dependent id="27">charges</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Peggy" />
            <token id="17" string="McMartin" />
            <token id="18" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="Thursday" />
          </tokens>
        </entity>
        <entity id="3" string="52" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="52" />
          </tokens>
        </entity>
        <entity id="4" string="Raymond Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Raymond" />
            <token id="11" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The jury deadlocked on 13 other charges.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="deadlocked" lemma="deadlock" stem="deadlock" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN jury)) (VP (VBN deadlocked) (PP (IN on) (NP (CD 13) (JJ other) (NNS charges)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="deadlocked on 13 other charges" type="VP">
          <tokens>
            <token id="3" string="deadlocked" />
            <token id="4" string="on" />
            <token id="5" string="13" />
            <token id="6" string="other" />
            <token id="7" string="charges" />
          </tokens>
        </chunking>
        <chunking id="2" string="13 other charges" type="NP">
          <tokens>
            <token id="5" string="13" />
            <token id="6" string="other" />
            <token id="7" string="charges" />
          </tokens>
        </chunking>
        <chunking id="3" string="The jury" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="jury" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">jury</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">deadlocked</governor>
          <dependent id="2">jury</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">deadlocked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">charges</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">charges</governor>
          <dependent id="5">13</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">charges</governor>
          <dependent id="6">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">deadlocked</governor>
          <dependent id="7">charges</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="13" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Afterward, the district attorney who filed the case criticized the current district attorney.</content>
      <tokens>
        <token id="1" string="Afterward" lemma="afterward" stem="afterward" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="filed" lemma="file" stem="file" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="criticized" lemma="criticize" stem="critic" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="13" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Afterward)) (, ,) (NP (NP (DT the) (NN district) (NN attorney)) (SBAR (WHNP (WP who)) (S (VP (VBD filed) (NP (DT the) (NN case)))))) (VP (VBD criticized) (NP (DT the) (JJ current) (NN district) (NN attorney))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the case" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="the district attorney" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="district" />
            <token id="5" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="3" string="filed the case" type="VP">
          <tokens>
            <token id="7" string="filed" />
            <token id="8" string="the" />
            <token id="9" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="who filed the case" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="filed" />
            <token id="8" string="the" />
            <token id="9" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="criticized the current district attorney" type="VP">
          <tokens>
            <token id="10" string="criticized" />
            <token id="11" string="the" />
            <token id="12" string="current" />
            <token id="13" string="district" />
            <token id="14" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="6" string="the current district attorney" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="current" />
            <token id="13" string="district" />
            <token id="14" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="7" string="the district attorney who filed the case" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="district" />
            <token id="5" string="attorney" />
            <token id="6" string="who" />
            <token id="7" string="filed" />
            <token id="8" string="the" />
            <token id="9" string="case" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="10">criticized</governor>
          <dependent id="1">Afterward</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">attorney</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">attorney</governor>
          <dependent id="4">district</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">criticized</governor>
          <dependent id="5">attorney</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">filed</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">attorney</governor>
          <dependent id="7">filed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">case</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">filed</governor>
          <dependent id="9">case</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">criticized</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">attorney</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">attorney</governor>
          <dependent id="12">current</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">attorney</governor>
          <dependent id="13">district</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">criticized</governor>
          <dependent id="14">attorney</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="current" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>The current district attorney blamed his predecessor and defense attorneys.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="blamed" lemma="blame" stem="blame" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="predecessor" lemma="predecessor" stem="predecessor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="defense" lemma="defense" stem="defens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="attorneys" lemma="attorney" stem="attornei" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ current) (NN district) (NN attorney)) (VP (VBD blamed) (NP (PRP$ his) (NN predecessor) (CC and) (NN defense) (NNS attorneys))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his predecessor and defense attorneys" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="predecessor" />
            <token id="8" string="and" />
            <token id="9" string="defense" />
            <token id="10" string="attorneys" />
          </tokens>
        </chunking>
        <chunking id="2" string="blamed his predecessor and defense attorneys" type="VP">
          <tokens>
            <token id="5" string="blamed" />
            <token id="6" string="his" />
            <token id="7" string="predecessor" />
            <token id="8" string="and" />
            <token id="9" string="defense" />
            <token id="10" string="attorneys" />
          </tokens>
        </chunking>
        <chunking id="3" string="The current district attorney" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="current" />
            <token id="3" string="district" />
            <token id="4" string="attorney" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">attorney</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">attorney</governor>
          <dependent id="2">current</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">attorney</governor>
          <dependent id="3">district</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">blamed</governor>
          <dependent id="4">attorney</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">blamed</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">predecessor</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">blamed</governor>
          <dependent id="7">predecessor</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">predecessor</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">attorneys</governor>
          <dependent id="9">defense</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">predecessor</governor>
          <dependent id="10">attorneys</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="current" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>And some of the parents of children who attended the school blamed everybody.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="attended" lemma="attend" stem="attend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="blamed" lemma="blame" stem="blame" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="everybody" lemma="everybody" stem="everybodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (DT some)) (PP (IN of) (NP (NP (DT the) (NNS parents)) (PP (IN of) (NP (NP (NNS children)) (SBAR (WHNP (WP who)) (S (VP (VBD attended) (NP (DT the) (NN school)))))))))) (VP (VBD blamed) (NP (NN everybody))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="attended the school" type="VP">
          <tokens>
            <token id="9" string="attended" />
            <token id="10" string="the" />
            <token id="11" string="school" />
          </tokens>
        </chunking>
        <chunking id="2" string="the school" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="school" />
          </tokens>
        </chunking>
        <chunking id="3" string="the parents of children who attended the school" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="parents" />
            <token id="6" string="of" />
            <token id="7" string="children" />
            <token id="8" string="who" />
            <token id="9" string="attended" />
            <token id="10" string="the" />
            <token id="11" string="school" />
          </tokens>
        </chunking>
        <chunking id="4" string="everybody" type="NP">
          <tokens>
            <token id="13" string="everybody" />
          </tokens>
        </chunking>
        <chunking id="5" string="children" type="NP">
          <tokens>
            <token id="7" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="blamed everybody" type="VP">
          <tokens>
            <token id="12" string="blamed" />
            <token id="13" string="everybody" />
          </tokens>
        </chunking>
        <chunking id="7" string="some" type="NP">
          <tokens>
            <token id="2" string="some" />
          </tokens>
        </chunking>
        <chunking id="8" string="some of the parents of children who attended the school" type="NP">
          <tokens>
            <token id="2" string="some" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="parents" />
            <token id="6" string="of" />
            <token id="7" string="children" />
            <token id="8" string="who" />
            <token id="9" string="attended" />
            <token id="10" string="the" />
            <token id="11" string="school" />
          </tokens>
        </chunking>
        <chunking id="9" string="the parents" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="parents" />
          </tokens>
        </chunking>
        <chunking id="10" string="children who attended the school" type="NP">
          <tokens>
            <token id="7" string="children" />
            <token id="8" string="who" />
            <token id="9" string="attended" />
            <token id="10" string="the" />
            <token id="11" string="school" />
          </tokens>
        </chunking>
        <chunking id="11" string="who attended the school" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="attended" />
            <token id="10" string="the" />
            <token id="11" string="school" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="12">blamed</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">blamed</governor>
          <dependent id="2">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">parents</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">parents</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">some</governor>
          <dependent id="5">parents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">children</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">parents</governor>
          <dependent id="7">children</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">attended</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">children</governor>
          <dependent id="9">attended</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">school</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">attended</governor>
          <dependent id="11">school</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">blamed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">blamed</governor>
          <dependent id="13">everybody</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``The system is not going to protect children,&amp;apost;&amp;apost; said Jackie McGauley, a parent who believes her child had been molested but didn&amp;apost;t testify in the case.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="protect" lemma="protect" stem="protect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Jackie" lemma="Jackie" stem="jacki" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="McGauley" lemma="McGauley" stem="mcgaulei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="parent" lemma="parent" stem="parent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="testify" lemma="testify" stem="testifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT The) (NN system)) (VP (VBZ is) (RB not) (VP (VBG going) (S (VP (TO to) (VP (VB protect) (NP (NNS children)))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Jackie) (NNP McGauley)) (, ,) (NP (NP (DT a) (NN parent)) (SBAR (WHNP (WP who)) (S (VP (VP (VBZ believes) (SBAR (S (NP (PRP$ her) (NN child)) (VP (VBD had) (VP (VBN been) (VP (VBN molested))))))) (CC but) (VP (VBD did) (RB n't) (VP (VB testify) (PP (IN in) (NP (DT the) (NN case)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who believes her child had been molested but did n't testify in the case" type="SBAR">
          <tokens>
            <token id="18" string="who" />
            <token id="19" string="believes" />
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
            <token id="25" string="but" />
            <token id="26" string="did" />
            <token id="27" string="n't" />
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="the case" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="had been molested" type="VP">
          <tokens>
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
          </tokens>
        </chunking>
        <chunking id="4" string="her child had been molested" type="SBAR">
          <tokens>
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jackie McGauley , a parent who believes her child had been molested but did n't testify in the case" type="NP">
          <tokens>
            <token id="13" string="Jackie" />
            <token id="14" string="McGauley" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="parent" />
            <token id="18" string="who" />
            <token id="19" string="believes" />
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
            <token id="25" string="but" />
            <token id="26" string="did" />
            <token id="27" string="n't" />
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="a parent" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="parent" />
          </tokens>
        </chunking>
        <chunking id="7" string="testify in the case" type="VP">
          <tokens>
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="is not going to protect children" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="not" />
            <token id="6" string="going" />
            <token id="7" string="to" />
            <token id="8" string="protect" />
            <token id="9" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="Jackie McGauley" type="NP">
          <tokens>
            <token id="13" string="Jackie" />
            <token id="14" string="McGauley" />
          </tokens>
        </chunking>
        <chunking id="10" string="a parent who believes her child had been molested but did n't testify in the case" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="parent" />
            <token id="18" string="who" />
            <token id="19" string="believes" />
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
            <token id="25" string="but" />
            <token id="26" string="did" />
            <token id="27" string="n't" />
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="11" string="to protect children" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="protect" />
            <token id="9" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="children" type="NP">
          <tokens>
            <token id="9" string="children" />
          </tokens>
        </chunking>
        <chunking id="13" string="been molested" type="VP">
          <tokens>
            <token id="23" string="been" />
            <token id="24" string="molested" />
          </tokens>
        </chunking>
        <chunking id="14" string="did n't testify in the case" type="VP">
          <tokens>
            <token id="26" string="did" />
            <token id="27" string="n't" />
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="15" string="going to protect children" type="VP">
          <tokens>
            <token id="6" string="going" />
            <token id="7" string="to" />
            <token id="8" string="protect" />
            <token id="9" string="children" />
          </tokens>
        </chunking>
        <chunking id="16" string="protect children" type="VP">
          <tokens>
            <token id="8" string="protect" />
            <token id="9" string="children" />
          </tokens>
        </chunking>
        <chunking id="17" string="her child" type="NP">
          <tokens>
            <token id="20" string="her" />
            <token id="21" string="child" />
          </tokens>
        </chunking>
        <chunking id="18" string="believes her child had been molested but did n't testify in the case" type="VP">
          <tokens>
            <token id="19" string="believes" />
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
            <token id="25" string="but" />
            <token id="26" string="did" />
            <token id="27" string="n't" />
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="19" string="The system" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="system" />
          </tokens>
        </chunking>
        <chunking id="20" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="21" string="believes her child had been molested" type="VP">
          <tokens>
            <token id="19" string="believes" />
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
          </tokens>
        </chunking>
        <chunking id="22" string="molested" type="VP">
          <tokens>
            <token id="24" string="molested" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">system</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">going</governor>
          <dependent id="3">system</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">going</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">going</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="6">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">protect</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">going</governor>
          <dependent id="8">protect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">protect</governor>
          <dependent id="9">children</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">McGauley</governor>
          <dependent id="13">Jackie</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="14">McGauley</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">parent</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">McGauley</governor>
          <dependent id="17">parent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">believes</governor>
          <dependent id="18">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">parent</governor>
          <dependent id="19">believes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">child</governor>
          <dependent id="20">her</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">molested</governor>
          <dependent id="21">child</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">molested</governor>
          <dependent id="22">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">molested</governor>
          <dependent id="23">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">believes</governor>
          <dependent id="24">molested</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">believes</governor>
          <dependent id="25">but</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">testify</governor>
          <dependent id="26">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="28">testify</governor>
          <dependent id="27">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">believes</governor>
          <dependent id="28">testify</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">case</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">case</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">testify</governor>
          <dependent id="31">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackie McGauley" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Jackie" />
            <token id="14" string="McGauley" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>``Life is not fair,&amp;apost;&amp;apost; said Robert Curry, whose son attended the McMartin school.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Life" lemma="Life" stem="life" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="Curry" lemma="Curry" stem="curri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="attended" lemma="attend" stem="attend" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NNP Life)) (VP (VBZ is) (RB not) (ADJP (JJ fair)))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Robert) (NNP Curry)) (, ,) (SBAR (WHNP (WP$ whose) (NN son)) (S (VP (VBD attended) (NP (DT the) (NNP McMartin) (NN school)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Robert Curry" type="NP">
          <tokens>
            <token id="9" string="Robert" />
            <token id="10" string="Curry" />
          </tokens>
        </chunking>
        <chunking id="2" string="Robert Curry , whose son attended the McMartin school" type="NP">
          <tokens>
            <token id="9" string="Robert" />
            <token id="10" string="Curry" />
            <token id="11" string="," />
            <token id="12" string="whose" />
            <token id="13" string="son" />
            <token id="14" string="attended" />
            <token id="15" string="the" />
            <token id="16" string="McMartin" />
            <token id="17" string="school" />
          </tokens>
        </chunking>
        <chunking id="3" string="attended the McMartin school" type="VP">
          <tokens>
            <token id="14" string="attended" />
            <token id="15" string="the" />
            <token id="16" string="McMartin" />
            <token id="17" string="school" />
          </tokens>
        </chunking>
        <chunking id="4" string="is not fair" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="not" />
            <token id="5" string="fair" />
          </tokens>
        </chunking>
        <chunking id="5" string="fair" type="ADJP">
          <tokens>
            <token id="5" string="fair" />
          </tokens>
        </chunking>
        <chunking id="6" string="the McMartin school" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="McMartin" />
            <token id="17" string="school" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="8" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="Life" type="NP">
          <tokens>
            <token id="2" string="Life" />
          </tokens>
        </chunking>
        <chunking id="9" string="whose son attended the McMartin school" type="SBAR">
          <tokens>
            <token id="12" string="whose" />
            <token id="13" string="son" />
            <token id="14" string="attended" />
            <token id="15" string="the" />
            <token id="16" string="McMartin" />
            <token id="17" string="school" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">fair</governor>
          <dependent id="2">Life</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">fair</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">fair</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="5">fair</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Curry</governor>
          <dependent id="9">Robert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="10">Curry</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">son</governor>
          <dependent id="12">whose</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">attended</governor>
          <dependent id="13">son</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">Curry</governor>
          <dependent id="14">attended</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">school</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">school</governor>
          <dependent id="16">McMartin</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">attended</governor>
          <dependent id="17">school</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Robert Curry" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Robert" />
            <token id="10" string="Curry" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>``I tell my children all the time ... there is no such thing as fair.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="tell" lemma="tell" stem="tell" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBP tell) (NP (PRP$ my) (NNS children)) (NP-TMP (PDT all) (DT the) (NN time)))) (: ...) (S (NP (EX there)) (VP (VBZ is) (NP (NP (DT no) (JJ such) (NN thing)) (PP (IN as) (ADJP (JJ fair)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="10" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="tell my children all the time" type="VP">
          <tokens>
            <token id="3" string="tell" />
            <token id="4" string="my" />
            <token id="5" string="children" />
            <token id="6" string="all" />
            <token id="7" string="the" />
            <token id="8" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="no such thing as fair" type="NP">
          <tokens>
            <token id="12" string="no" />
            <token id="13" string="such" />
            <token id="14" string="thing" />
            <token id="15" string="as" />
            <token id="16" string="fair" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="is no such thing as fair" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="no" />
            <token id="13" string="such" />
            <token id="14" string="thing" />
            <token id="15" string="as" />
            <token id="16" string="fair" />
          </tokens>
        </chunking>
        <chunking id="6" string="no such thing" type="NP">
          <tokens>
            <token id="12" string="no" />
            <token id="13" string="such" />
            <token id="14" string="thing" />
          </tokens>
        </chunking>
        <chunking id="7" string="my children" type="NP">
          <tokens>
            <token id="4" string="my" />
            <token id="5" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="fair" type="ADJP">
          <tokens>
            <token id="16" string="fair" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">tell</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">tell</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">children</governor>
          <dependent id="4">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">tell</governor>
          <dependent id="5">children</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="8">time</governor>
          <dependent id="6">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">time</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">tell</governor>
          <dependent id="8">time</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="11">is</governor>
          <dependent id="10">there</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">tell</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">thing</governor>
          <dependent id="12">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">thing</governor>
          <dependent id="13">such</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">is</governor>
          <dependent id="14">thing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">fair</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">thing</governor>
          <dependent id="16">fair</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>The district attorney who originally pursued the case said he would not have done anything differently.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="originally" lemma="originally" stem="origin" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="pursued" lemma="pursue" stem="pursu" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="differently" lemma="differently" stem="differ" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN district) (NN attorney)) (SBAR (WHNP (WP who)) (S (ADVP (RB originally)) (VP (VBD pursued) (NP (DT the) (NN case)))))) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (MD would) (RB not) (VP (VB have) (VP (VBN done) (NP (NN anything)) (ADVP (RB differently)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who originally pursued the case" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="originally" />
            <token id="6" string="pursued" />
            <token id="7" string="the" />
            <token id="8" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="the case" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="The district attorney" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="district" />
            <token id="3" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="4" string="said he would not have done anything differently" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="he" />
            <token id="11" string="would" />
            <token id="12" string="not" />
            <token id="13" string="have" />
            <token id="14" string="done" />
            <token id="15" string="anything" />
            <token id="16" string="differently" />
          </tokens>
        </chunking>
        <chunking id="5" string="would not have done anything differently" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="not" />
            <token id="13" string="have" />
            <token id="14" string="done" />
            <token id="15" string="anything" />
            <token id="16" string="differently" />
          </tokens>
        </chunking>
        <chunking id="6" string="done anything differently" type="VP">
          <tokens>
            <token id="14" string="done" />
            <token id="15" string="anything" />
            <token id="16" string="differently" />
          </tokens>
        </chunking>
        <chunking id="7" string="have done anything differently" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="done" />
            <token id="15" string="anything" />
            <token id="16" string="differently" />
          </tokens>
        </chunking>
        <chunking id="8" string="pursued the case" type="VP">
          <tokens>
            <token id="6" string="pursued" />
            <token id="7" string="the" />
            <token id="8" string="case" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="10" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="anything" type="NP">
          <tokens>
            <token id="15" string="anything" />
          </tokens>
        </chunking>
        <chunking id="11" string="he would not have done anything differently" type="SBAR">
          <tokens>
            <token id="10" string="he" />
            <token id="11" string="would" />
            <token id="12" string="not" />
            <token id="13" string="have" />
            <token id="14" string="done" />
            <token id="15" string="anything" />
            <token id="16" string="differently" />
          </tokens>
        </chunking>
        <chunking id="12" string="The district attorney who originally pursued the case" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="district" />
            <token id="3" string="attorney" />
            <token id="4" string="who" />
            <token id="5" string="originally" />
            <token id="6" string="pursued" />
            <token id="7" string="the" />
            <token id="8" string="case" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">attorney</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">attorney</governor>
          <dependent id="2">district</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="3">attorney</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">pursued</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">pursued</governor>
          <dependent id="5">originally</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">attorney</governor>
          <dependent id="6">pursued</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">case</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">pursued</governor>
          <dependent id="8">case</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">done</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">done</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">done</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">done</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="14">done</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">done</governor>
          <dependent id="15">anything</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">done</governor>
          <dependent id="16">differently</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Robert Philibosian, now in private practice, angrily dismissed accusations that he played up the McMartin case in 1984 _ with the news media acting as eager accomplices _ to boost his public profile as he ran for district attorney.</content>
      <tokens>
        <token id="1" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Philibosian" lemma="Philibosian" stem="philibosian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="practice" lemma="practice" stem="practic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="angrily" lemma="angrily" stem="angrili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="dismissed" lemma="dismiss" stem="dismiss" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="accusations" lemma="accusation" stem="accus" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="played" lemma="play" stem="plai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="18" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="21" string="_" lemma="_" stem="_" pos="CD" type="Symbol" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="acting" lemma="act" stem="act" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="eager" lemma="eager" stem="eager" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="accomplices" lemma="accomplice" stem="accomplic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="boost" lemma="boost" stem="boost" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="profile" lemma="profile" stem="profil" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="41" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Robert) (NNP Philibosian)) (, ,) (NP (NP (RB now)) (PP (IN in) (NP (JJ private) (NN practice)))) (, ,)) (ADVP (RB angrily)) (VP (VBD dismissed) (NP (NNS accusations)) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD played) (PRT (RP up)) (NP (NP (DT the) (NNP McMartin) (NN case)) (PP (IN in) (NP (CD 1984) (CD _)))) (PP (IN with) (S (NP (DT the) (NN news) (NNS media)) (VP (VBG acting) (SBAR (IN as) (S (NP (JJ eager) (NNS accomplices)) (VP (VBP _) (S (VP (TO to) (VP (VB boost) (NP (PRP$ his) (JJ public) (NN profile)) (SBAR (IN as) (S (NP (PRP he)) (VP (VBD ran) (PP (IN for) (NP (NN district) (NN attorney))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="private practice" type="NP">
          <tokens>
            <token id="6" string="private" />
            <token id="7" string="practice" />
          </tokens>
        </chunking>
        <chunking id="2" string="to boost his public profile as he ran for district attorney" type="VP">
          <tokens>
            <token id="31" string="to" />
            <token id="32" string="boost" />
            <token id="33" string="his" />
            <token id="34" string="public" />
            <token id="35" string="profile" />
            <token id="36" string="as" />
            <token id="37" string="he" />
            <token id="38" string="ran" />
            <token id="39" string="for" />
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="3" string="_ to boost his public profile as he ran for district attorney" type="VP">
          <tokens>
            <token id="30" string="_" />
            <token id="31" string="to" />
            <token id="32" string="boost" />
            <token id="33" string="his" />
            <token id="34" string="public" />
            <token id="35" string="profile" />
            <token id="36" string="as" />
            <token id="37" string="he" />
            <token id="38" string="ran" />
            <token id="39" string="for" />
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="4" string="Robert Philibosian" type="NP">
          <tokens>
            <token id="1" string="Robert" />
            <token id="2" string="Philibosian" />
          </tokens>
        </chunking>
        <chunking id="5" string="boost his public profile as he ran for district attorney" type="VP">
          <tokens>
            <token id="32" string="boost" />
            <token id="33" string="his" />
            <token id="34" string="public" />
            <token id="35" string="profile" />
            <token id="36" string="as" />
            <token id="37" string="he" />
            <token id="38" string="ran" />
            <token id="39" string="for" />
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="6" string="accusations" type="NP">
          <tokens>
            <token id="11" string="accusations" />
          </tokens>
        </chunking>
        <chunking id="7" string="now in private practice" type="NP">
          <tokens>
            <token id="4" string="now" />
            <token id="5" string="in" />
            <token id="6" string="private" />
            <token id="7" string="practice" />
          </tokens>
        </chunking>
        <chunking id="8" string="eager accomplices" type="NP">
          <tokens>
            <token id="28" string="eager" />
            <token id="29" string="accomplices" />
          </tokens>
        </chunking>
        <chunking id="9" string="his public profile" type="NP">
          <tokens>
            <token id="33" string="his" />
            <token id="34" string="public" />
            <token id="35" string="profile" />
          </tokens>
        </chunking>
        <chunking id="10" string="ran for district attorney" type="VP">
          <tokens>
            <token id="38" string="ran" />
            <token id="39" string="for" />
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="11" string="district attorney" type="NP">
          <tokens>
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="12" string="that he played up the McMartin case in 1984 _ with the news media acting as eager accomplices _ to boost his public profile as he ran for district attorney" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="he" />
            <token id="14" string="played" />
            <token id="15" string="up" />
            <token id="16" string="the" />
            <token id="17" string="McMartin" />
            <token id="18" string="case" />
            <token id="19" string="in" />
            <token id="20" string="1984" />
            <token id="21" string="_" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="news" />
            <token id="25" string="media" />
            <token id="26" string="acting" />
            <token id="27" string="as" />
            <token id="28" string="eager" />
            <token id="29" string="accomplices" />
            <token id="30" string="_" />
            <token id="31" string="to" />
            <token id="32" string="boost" />
            <token id="33" string="his" />
            <token id="34" string="public" />
            <token id="35" string="profile" />
            <token id="36" string="as" />
            <token id="37" string="he" />
            <token id="38" string="ran" />
            <token id="39" string="for" />
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="13" string="as eager accomplices _ to boost his public profile as he ran for district attorney" type="SBAR">
          <tokens>
            <token id="27" string="as" />
            <token id="28" string="eager" />
            <token id="29" string="accomplices" />
            <token id="30" string="_" />
            <token id="31" string="to" />
            <token id="32" string="boost" />
            <token id="33" string="his" />
            <token id="34" string="public" />
            <token id="35" string="profile" />
            <token id="36" string="as" />
            <token id="37" string="he" />
            <token id="38" string="ran" />
            <token id="39" string="for" />
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="14" string="dismissed accusations that he played up the McMartin case in 1984 _ with the news media acting as eager accomplices _ to boost his public profile as he ran for district attorney" type="VP">
          <tokens>
            <token id="10" string="dismissed" />
            <token id="11" string="accusations" />
            <token id="12" string="that" />
            <token id="13" string="he" />
            <token id="14" string="played" />
            <token id="15" string="up" />
            <token id="16" string="the" />
            <token id="17" string="McMartin" />
            <token id="18" string="case" />
            <token id="19" string="in" />
            <token id="20" string="1984" />
            <token id="21" string="_" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="news" />
            <token id="25" string="media" />
            <token id="26" string="acting" />
            <token id="27" string="as" />
            <token id="28" string="eager" />
            <token id="29" string="accomplices" />
            <token id="30" string="_" />
            <token id="31" string="to" />
            <token id="32" string="boost" />
            <token id="33" string="his" />
            <token id="34" string="public" />
            <token id="35" string="profile" />
            <token id="36" string="as" />
            <token id="37" string="he" />
            <token id="38" string="ran" />
            <token id="39" string="for" />
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="15" string="played up the McMartin case in 1984 _ with the news media acting as eager accomplices _ to boost his public profile as he ran for district attorney" type="VP">
          <tokens>
            <token id="14" string="played" />
            <token id="15" string="up" />
            <token id="16" string="the" />
            <token id="17" string="McMartin" />
            <token id="18" string="case" />
            <token id="19" string="in" />
            <token id="20" string="1984" />
            <token id="21" string="_" />
            <token id="22" string="with" />
            <token id="23" string="the" />
            <token id="24" string="news" />
            <token id="25" string="media" />
            <token id="26" string="acting" />
            <token id="27" string="as" />
            <token id="28" string="eager" />
            <token id="29" string="accomplices" />
            <token id="30" string="_" />
            <token id="31" string="to" />
            <token id="32" string="boost" />
            <token id="33" string="his" />
            <token id="34" string="public" />
            <token id="35" string="profile" />
            <token id="36" string="as" />
            <token id="37" string="he" />
            <token id="38" string="ran" />
            <token id="39" string="for" />
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="16" string="the news media" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="news" />
            <token id="25" string="media" />
          </tokens>
        </chunking>
        <chunking id="17" string="as he ran for district attorney" type="SBAR">
          <tokens>
            <token id="36" string="as" />
            <token id="37" string="he" />
            <token id="38" string="ran" />
            <token id="39" string="for" />
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="18" string="acting as eager accomplices _ to boost his public profile as he ran for district attorney" type="VP">
          <tokens>
            <token id="26" string="acting" />
            <token id="27" string="as" />
            <token id="28" string="eager" />
            <token id="29" string="accomplices" />
            <token id="30" string="_" />
            <token id="31" string="to" />
            <token id="32" string="boost" />
            <token id="33" string="his" />
            <token id="34" string="public" />
            <token id="35" string="profile" />
            <token id="36" string="as" />
            <token id="37" string="he" />
            <token id="38" string="ran" />
            <token id="39" string="for" />
            <token id="40" string="district" />
            <token id="41" string="attorney" />
          </tokens>
        </chunking>
        <chunking id="19" string="now" type="NP">
          <tokens>
            <token id="4" string="now" />
          </tokens>
        </chunking>
        <chunking id="20" string="Robert Philibosian , now in private practice ," type="NP">
          <tokens>
            <token id="1" string="Robert" />
            <token id="2" string="Philibosian" />
            <token id="3" string="," />
            <token id="4" string="now" />
            <token id="5" string="in" />
            <token id="6" string="private" />
            <token id="7" string="practice" />
            <token id="8" string="," />
          </tokens>
        </chunking>
        <chunking id="21" string="1984 _" type="NP">
          <tokens>
            <token id="20" string="1984" />
            <token id="21" string="_" />
          </tokens>
        </chunking>
        <chunking id="22" string="the McMartin case" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="McMartin" />
            <token id="18" string="case" />
          </tokens>
        </chunking>
        <chunking id="23" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="24" string="the McMartin case in 1984 _" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="McMartin" />
            <token id="18" string="case" />
            <token id="19" string="in" />
            <token id="20" string="1984" />
            <token id="21" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Philibosian</governor>
          <dependent id="1">Robert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">dismissed</governor>
          <dependent id="2">Philibosian</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Philibosian</governor>
          <dependent id="4">now</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">practice</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">practice</governor>
          <dependent id="6">private</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">now</governor>
          <dependent id="7">practice</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">dismissed</governor>
          <dependent id="9">angrily</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">dismissed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">dismissed</governor>
          <dependent id="11">accusations</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">played</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">played</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">dismissed</governor>
          <dependent id="14">played</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="14">played</governor>
          <dependent id="15">up</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">case</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">case</governor>
          <dependent id="17">McMartin</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">played</governor>
          <dependent id="18">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">_</governor>
          <dependent id="19">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">_</governor>
          <dependent id="20">1984</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">case</governor>
          <dependent id="21">_</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">acting</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">media</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">media</governor>
          <dependent id="24">news</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">acting</governor>
          <dependent id="25">media</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">played</governor>
          <dependent id="26">acting</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">_</governor>
          <dependent id="27">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">accomplices</governor>
          <dependent id="28">eager</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">_</governor>
          <dependent id="29">accomplices</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="26">acting</governor>
          <dependent id="30">_</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">boost</governor>
          <dependent id="31">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="30">_</governor>
          <dependent id="32">boost</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">profile</governor>
          <dependent id="33">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">profile</governor>
          <dependent id="34">public</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">boost</governor>
          <dependent id="35">profile</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">ran</governor>
          <dependent id="36">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">ran</governor>
          <dependent id="37">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="32">boost</governor>
          <dependent id="38">ran</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">attorney</governor>
          <dependent id="39">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">attorney</governor>
          <dependent id="40">district</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">ran</governor>
          <dependent id="41">attorney</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="1984" type="DATE" score="0.0">
          <tokens>
            <token id="20" string="1984" />
          </tokens>
        </entity>
        <entity id="3" string="Robert Philibosian" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Robert" />
            <token id="2" string="Philibosian" />
          </tokens>
        </entity>
        <entity id="4" string="McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="McMartin" />
          </tokens>
        </entity>
        <entity id="5" string="_" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="_" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>``I was a professional prosecutor for 16 years before this case was brought,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="professional" lemma="professional" stem="profession" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="prosecutor" lemma="prosecutor" stem="prosecutor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="16" lemma="16" stem="16" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="9" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="10" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="brought" lemma="bring" stem="brought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD was) (NP (NP (DT a) (JJ professional) (NN prosecutor)) (PP (IN for) (NP (CD 16) (NNS years)))) (SBAR (IN before) (S (NP (DT this) (NN case)) (VP (VBD was) (VP (VBN brought))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a professional prosecutor for 16 years" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="professional" />
            <token id="6" string="prosecutor" />
            <token id="7" string="for" />
            <token id="8" string="16" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="was brought" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="brought" />
          </tokens>
        </chunking>
        <chunking id="3" string="brought" type="VP">
          <tokens>
            <token id="14" string="brought" />
          </tokens>
        </chunking>
        <chunking id="4" string="a professional prosecutor" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="professional" />
            <token id="6" string="prosecutor" />
          </tokens>
        </chunking>
        <chunking id="5" string="before this case was brought" type="SBAR">
          <tokens>
            <token id="10" string="before" />
            <token id="11" string="this" />
            <token id="12" string="case" />
            <token id="13" string="was" />
            <token id="14" string="brought" />
          </tokens>
        </chunking>
        <chunking id="6" string="16 years" type="NP">
          <tokens>
            <token id="8" string="16" />
            <token id="9" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="was a professional prosecutor for 16 years before this case was brought" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="professional" />
            <token id="6" string="prosecutor" />
            <token id="7" string="for" />
            <token id="8" string="16" />
            <token id="9" string="years" />
            <token id="10" string="before" />
            <token id="11" string="this" />
            <token id="12" string="case" />
            <token id="13" string="was" />
            <token id="14" string="brought" />
          </tokens>
        </chunking>
        <chunking id="9" string="this case" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="17" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="18" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">prosecutor</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">prosecutor</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">prosecutor</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">prosecutor</governor>
          <dependent id="5">professional</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="6">prosecutor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">years</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">years</governor>
          <dependent id="8">16</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">prosecutor</governor>
          <dependent id="9">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">brought</governor>
          <dependent id="10">before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">case</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">brought</governor>
          <dependent id="12">case</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">brought</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">prosecutor</governor>
          <dependent id="14">brought</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="16 years" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="16" />
            <token id="9" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``To have people who know very little about professional or prosecutorial ethics, to criticize me personally that I have some political motive is totally unjustified.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="To" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="professional" lemma="professional" stem="profession" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="prosecutorial" lemma="prosecutorial" stem="prosecutori" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="ethics" lemma="ethic" stem="ethic" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="criticize" lemma="criticize" stem="critic" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="personally" lemma="personally" stem="person" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="21" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="motive" lemma="motive" stem="motiv" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="totally" lemma="totally" stem="total" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="unjustified" lemma="unjustified" stem="unjustifi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (S (VP (TO To) (VP (VB have) (NP (NP (NNS people)) (SBAR (WHNP (WP who)) (S (VP (VBP know) (ADJP (RB very) (JJ little) (PP (IN about) (NP (JJ professional) (CC or) (JJ prosecutorial) (NNS ethics)))) (, ,) (S (VP (TO to) (VP (VB criticize) (NP (PRP me)) (ADVP (RB personally)) (SBAR (IN that) (S (NP (PRP I)) (VP (VBP have) (NP (DT some) (JJ political) (NN motive)))))))))))))))) (VP (VBZ is) (ADJP (RB totally) (JJ unjustified))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="some political motive" type="NP">
          <tokens>
            <token id="22" string="some" />
            <token id="23" string="political" />
            <token id="24" string="motive" />
          </tokens>
        </chunking>
        <chunking id="2" string="have people who know very little about professional or prosecutorial ethics , to criticize me personally that I have some political motive" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="people" />
            <token id="5" string="who" />
            <token id="6" string="know" />
            <token id="7" string="very" />
            <token id="8" string="little" />
            <token id="9" string="about" />
            <token id="10" string="professional" />
            <token id="11" string="or" />
            <token id="12" string="prosecutorial" />
            <token id="13" string="ethics" />
            <token id="14" string="," />
            <token id="15" string="to" />
            <token id="16" string="criticize" />
            <token id="17" string="me" />
            <token id="18" string="personally" />
            <token id="19" string="that" />
            <token id="20" string="I" />
            <token id="21" string="have" />
            <token id="22" string="some" />
            <token id="23" string="political" />
            <token id="24" string="motive" />
          </tokens>
        </chunking>
        <chunking id="3" string="to criticize me personally that I have some political motive" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="criticize" />
            <token id="17" string="me" />
            <token id="18" string="personally" />
            <token id="19" string="that" />
            <token id="20" string="I" />
            <token id="21" string="have" />
            <token id="22" string="some" />
            <token id="23" string="political" />
            <token id="24" string="motive" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="20" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="To have people who know very little about professional or prosecutorial ethics , to criticize me personally that I have some political motive" type="NP">
          <tokens>
            <token id="2" string="To" />
            <token id="3" string="have" />
            <token id="4" string="people" />
            <token id="5" string="who" />
            <token id="6" string="know" />
            <token id="7" string="very" />
            <token id="8" string="little" />
            <token id="9" string="about" />
            <token id="10" string="professional" />
            <token id="11" string="or" />
            <token id="12" string="prosecutorial" />
            <token id="13" string="ethics" />
            <token id="14" string="," />
            <token id="15" string="to" />
            <token id="16" string="criticize" />
            <token id="17" string="me" />
            <token id="18" string="personally" />
            <token id="19" string="that" />
            <token id="20" string="I" />
            <token id="21" string="have" />
            <token id="22" string="some" />
            <token id="23" string="political" />
            <token id="24" string="motive" />
          </tokens>
        </chunking>
        <chunking id="6" string="who know very little about professional or prosecutorial ethics , to criticize me personally that I have some political motive" type="SBAR">
          <tokens>
            <token id="5" string="who" />
            <token id="6" string="know" />
            <token id="7" string="very" />
            <token id="8" string="little" />
            <token id="9" string="about" />
            <token id="10" string="professional" />
            <token id="11" string="or" />
            <token id="12" string="prosecutorial" />
            <token id="13" string="ethics" />
            <token id="14" string="," />
            <token id="15" string="to" />
            <token id="16" string="criticize" />
            <token id="17" string="me" />
            <token id="18" string="personally" />
            <token id="19" string="that" />
            <token id="20" string="I" />
            <token id="21" string="have" />
            <token id="22" string="some" />
            <token id="23" string="political" />
            <token id="24" string="motive" />
          </tokens>
        </chunking>
        <chunking id="7" string="people who know very little about professional or prosecutorial ethics , to criticize me personally that I have some political motive" type="NP">
          <tokens>
            <token id="4" string="people" />
            <token id="5" string="who" />
            <token id="6" string="know" />
            <token id="7" string="very" />
            <token id="8" string="little" />
            <token id="9" string="about" />
            <token id="10" string="professional" />
            <token id="11" string="or" />
            <token id="12" string="prosecutorial" />
            <token id="13" string="ethics" />
            <token id="14" string="," />
            <token id="15" string="to" />
            <token id="16" string="criticize" />
            <token id="17" string="me" />
            <token id="18" string="personally" />
            <token id="19" string="that" />
            <token id="20" string="I" />
            <token id="21" string="have" />
            <token id="22" string="some" />
            <token id="23" string="political" />
            <token id="24" string="motive" />
          </tokens>
        </chunking>
        <chunking id="8" string="people" type="NP">
          <tokens>
            <token id="4" string="people" />
          </tokens>
        </chunking>
        <chunking id="9" string="is totally unjustified" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="totally" />
            <token id="27" string="unjustified" />
          </tokens>
        </chunking>
        <chunking id="10" string="criticize me personally that I have some political motive" type="VP">
          <tokens>
            <token id="16" string="criticize" />
            <token id="17" string="me" />
            <token id="18" string="personally" />
            <token id="19" string="that" />
            <token id="20" string="I" />
            <token id="21" string="have" />
            <token id="22" string="some" />
            <token id="23" string="political" />
            <token id="24" string="motive" />
          </tokens>
        </chunking>
        <chunking id="11" string="have some political motive" type="VP">
          <tokens>
            <token id="21" string="have" />
            <token id="22" string="some" />
            <token id="23" string="political" />
            <token id="24" string="motive" />
          </tokens>
        </chunking>
        <chunking id="12" string="very little about professional or prosecutorial ethics" type="ADJP">
          <tokens>
            <token id="7" string="very" />
            <token id="8" string="little" />
            <token id="9" string="about" />
            <token id="10" string="professional" />
            <token id="11" string="or" />
            <token id="12" string="prosecutorial" />
            <token id="13" string="ethics" />
          </tokens>
        </chunking>
        <chunking id="13" string="me" type="NP">
          <tokens>
            <token id="17" string="me" />
          </tokens>
        </chunking>
        <chunking id="14" string="totally unjustified" type="ADJP">
          <tokens>
            <token id="26" string="totally" />
            <token id="27" string="unjustified" />
          </tokens>
        </chunking>
        <chunking id="15" string="know very little about professional or prosecutorial ethics , to criticize me personally that I have some political motive" type="VP">
          <tokens>
            <token id="6" string="know" />
            <token id="7" string="very" />
            <token id="8" string="little" />
            <token id="9" string="about" />
            <token id="10" string="professional" />
            <token id="11" string="or" />
            <token id="12" string="prosecutorial" />
            <token id="13" string="ethics" />
            <token id="14" string="," />
            <token id="15" string="to" />
            <token id="16" string="criticize" />
            <token id="17" string="me" />
            <token id="18" string="personally" />
            <token id="19" string="that" />
            <token id="20" string="I" />
            <token id="21" string="have" />
            <token id="22" string="some" />
            <token id="23" string="political" />
            <token id="24" string="motive" />
          </tokens>
        </chunking>
        <chunking id="16" string="professional or prosecutorial ethics" type="NP">
          <tokens>
            <token id="10" string="professional" />
            <token id="11" string="or" />
            <token id="12" string="prosecutorial" />
            <token id="13" string="ethics" />
          </tokens>
        </chunking>
        <chunking id="17" string="that I have some political motive" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="I" />
            <token id="21" string="have" />
            <token id="22" string="some" />
            <token id="23" string="political" />
            <token id="24" string="motive" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">have</governor>
          <dependent id="2">To</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">unjustified</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">have</governor>
          <dependent id="4">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">know</governor>
          <dependent id="5">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">people</governor>
          <dependent id="6">know</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">little</governor>
          <dependent id="7">very</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">know</governor>
          <dependent id="8">little</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">ethics</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">ethics</governor>
          <dependent id="10">professional</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">professional</governor>
          <dependent id="11">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">professional</governor>
          <dependent id="12">prosecutorial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">little</governor>
          <dependent id="13">ethics</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">criticize</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">know</governor>
          <dependent id="16">criticize</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">criticize</governor>
          <dependent id="17">me</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">criticize</governor>
          <dependent id="18">personally</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">have</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">have</governor>
          <dependent id="20">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">criticize</governor>
          <dependent id="21">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">motive</governor>
          <dependent id="22">some</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">motive</governor>
          <dependent id="23">political</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">have</governor>
          <dependent id="24">motive</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="27">unjustified</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">unjustified</governor>
          <dependent id="26">totally</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">unjustified</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Philibosian instead pointed the finger at the man who defeated him, current District Attorney Ira Reiner.</content>
      <tokens>
        <token id="1" string="Philibosian" lemma="philibosian" stem="philibosian" pos="JJ" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="instead" lemma="instead" stem="instead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="pointed" lemma="point" stem="point" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="finger" lemma="finger" stem="finger" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="defeated" lemma="defeat" stem="defeat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="14" string="District" lemma="District" stem="district" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="Attorney" lemma="Attorney" stem="attornei" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="16" string="Ira" lemma="Ira" stem="ira" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Philibosian)) (ADVP (RB instead)) (VP (VBD pointed) (NP (DT the) (NN finger)) (PP (IN at) (NP (NP (NP (DT the) (NN man)) (SBAR (WHNP (WP who)) (S (VP (VBD defeated) (NP (PRP him)))))) (, ,) (NP (JJ current) (NNP District) (NNP Attorney) (NNP Ira) (NNP Reiner))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the man" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="man" />
          </tokens>
        </chunking>
        <chunking id="2" string="who defeated him" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="defeated" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="Philibosian" type="NP">
          <tokens>
            <token id="1" string="Philibosian" />
          </tokens>
        </chunking>
        <chunking id="4" string="the man who defeated him" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="man" />
            <token id="9" string="who" />
            <token id="10" string="defeated" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="the finger" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="finger" />
          </tokens>
        </chunking>
        <chunking id="7" string="the man who defeated him , current District Attorney Ira Reiner" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="man" />
            <token id="9" string="who" />
            <token id="10" string="defeated" />
            <token id="11" string="him" />
            <token id="12" string="," />
            <token id="13" string="current" />
            <token id="14" string="District" />
            <token id="15" string="Attorney" />
            <token id="16" string="Ira" />
            <token id="17" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="8" string="defeated him" type="VP">
          <tokens>
            <token id="10" string="defeated" />
            <token id="11" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="current District Attorney Ira Reiner" type="NP">
          <tokens>
            <token id="13" string="current" />
            <token id="14" string="District" />
            <token id="15" string="Attorney" />
            <token id="16" string="Ira" />
            <token id="17" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="10" string="pointed the finger at the man who defeated him , current District Attorney Ira Reiner" type="VP">
          <tokens>
            <token id="3" string="pointed" />
            <token id="4" string="the" />
            <token id="5" string="finger" />
            <token id="6" string="at" />
            <token id="7" string="the" />
            <token id="8" string="man" />
            <token id="9" string="who" />
            <token id="10" string="defeated" />
            <token id="11" string="him" />
            <token id="12" string="," />
            <token id="13" string="current" />
            <token id="14" string="District" />
            <token id="15" string="Attorney" />
            <token id="16" string="Ira" />
            <token id="17" string="Reiner" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">pointed</governor>
          <dependent id="1">Philibosian</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">pointed</governor>
          <dependent id="2">instead</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">pointed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">finger</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">pointed</governor>
          <dependent id="5">finger</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">man</governor>
          <dependent id="6">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">man</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">pointed</governor>
          <dependent id="8">man</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">defeated</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">man</governor>
          <dependent id="10">defeated</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">defeated</governor>
          <dependent id="11">him</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">Reiner</governor>
          <dependent id="13">current</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Reiner</governor>
          <dependent id="14">District</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Reiner</governor>
          <dependent id="15">Attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Reiner</governor>
          <dependent id="16">Ira</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">man</governor>
          <dependent id="17">Reiner</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="current" />
          </tokens>
        </entity>
        <entity id="2" string="Philibosian" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Philibosian" />
          </tokens>
        </entity>
        <entity id="3" string="Attorney" type="TITLE" score="0.0">
          <tokens>
            <token id="15" string="Attorney" />
          </tokens>
        </entity>
        <entity id="4" string="Ira Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Ira" />
            <token id="17" string="Reiner" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Philibosian said Reiner hurt prosecutor&amp;apost;s chances by dismissing charges against five of the original seven defendants and criticizing the case in a 1986 ``60 Minutes&amp;apost;&amp;apost; interview.</content>
      <tokens>
        <token id="1" string="Philibosian" lemma="Philibosian" stem="philibosian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="hurt" lemma="hurt" stem="hurt" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="prosecutor" lemma="prosecutor" stem="prosecutor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="chances" lemma="chance" stem="chanc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="dismissing" lemma="dismiss" stem="dismiss" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="original" lemma="original" stem="origin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="criticizing" lemma="criticize" stem="critic" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="60" lemma="60" stem="60" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="27" string="Minutes" lemma="Minutes" stem="minut" pos="NNPS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="28" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Philibosian)) (VP (VBD said) (S (NP (NNP Reiner)) (VP (VB hurt) (NP (NP (NN prosecutor) (POS 's)) (NNS chances)) (PP (IN by) (S (VP (VP (VBG dismissing) (NP (NNS charges)) (PP (IN against) (NP (NP (CD five)) (PP (IN of) (NP (DT the) (JJ original) (CD seven) (NNS defendants)))))) (CC and) (VP (VBG criticizing) (NP (NP (DT the) (NN case)) (PP (IN in) (NP (NP (DT a) (CD 1986)) (`` ``) (NP (CD 60) (NNPS Minutes)) ('' ''))))) (NP (NN interview)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="prosecutor 's" type="NP">
          <tokens>
            <token id="5" string="prosecutor" />
            <token id="6" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="criticizing the case in a 1986 `` 60 Minutes ''" type="VP">
          <tokens>
            <token id="19" string="criticizing" />
            <token id="20" string="the" />
            <token id="21" string="case" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="1986" />
            <token id="25" string="``" />
            <token id="26" string="60" />
            <token id="27" string="Minutes" />
            <token id="28" string="''" />
          </tokens>
        </chunking>
        <chunking id="3" string="said Reiner hurt prosecutor 's chances by dismissing charges against five of the original seven defendants and criticizing the case in a 1986 `` 60 Minutes '' interview" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="Reiner" />
            <token id="4" string="hurt" />
            <token id="5" string="prosecutor" />
            <token id="6" string="'s" />
            <token id="7" string="chances" />
            <token id="8" string="by" />
            <token id="9" string="dismissing" />
            <token id="10" string="charges" />
            <token id="11" string="against" />
            <token id="12" string="five" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="original" />
            <token id="16" string="seven" />
            <token id="17" string="defendants" />
            <token id="18" string="and" />
            <token id="19" string="criticizing" />
            <token id="20" string="the" />
            <token id="21" string="case" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="1986" />
            <token id="25" string="``" />
            <token id="26" string="60" />
            <token id="27" string="Minutes" />
            <token id="28" string="''" />
            <token id="29" string="interview" />
          </tokens>
        </chunking>
        <chunking id="4" string="Philibosian" type="NP">
          <tokens>
            <token id="1" string="Philibosian" />
          </tokens>
        </chunking>
        <chunking id="5" string="a 1986" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="1986" />
          </tokens>
        </chunking>
        <chunking id="6" string="the case" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="five of the original seven defendants" type="NP">
          <tokens>
            <token id="12" string="five" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="original" />
            <token id="16" string="seven" />
            <token id="17" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="8" string="Reiner" type="NP">
          <tokens>
            <token id="3" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="9" string="a 1986 `` 60 Minutes ''" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="1986" />
            <token id="25" string="``" />
            <token id="26" string="60" />
            <token id="27" string="Minutes" />
            <token id="28" string="''" />
          </tokens>
        </chunking>
        <chunking id="10" string="hurt prosecutor 's chances by dismissing charges against five of the original seven defendants and criticizing the case in a 1986 `` 60 Minutes '' interview" type="VP">
          <tokens>
            <token id="4" string="hurt" />
            <token id="5" string="prosecutor" />
            <token id="6" string="'s" />
            <token id="7" string="chances" />
            <token id="8" string="by" />
            <token id="9" string="dismissing" />
            <token id="10" string="charges" />
            <token id="11" string="against" />
            <token id="12" string="five" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="original" />
            <token id="16" string="seven" />
            <token id="17" string="defendants" />
            <token id="18" string="and" />
            <token id="19" string="criticizing" />
            <token id="20" string="the" />
            <token id="21" string="case" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="1986" />
            <token id="25" string="``" />
            <token id="26" string="60" />
            <token id="27" string="Minutes" />
            <token id="28" string="''" />
            <token id="29" string="interview" />
          </tokens>
        </chunking>
        <chunking id="11" string="the original seven defendants" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="original" />
            <token id="16" string="seven" />
            <token id="17" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="12" string="60 Minutes" type="NP">
          <tokens>
            <token id="26" string="60" />
            <token id="27" string="Minutes" />
          </tokens>
        </chunking>
        <chunking id="13" string="charges" type="NP">
          <tokens>
            <token id="10" string="charges" />
          </tokens>
        </chunking>
        <chunking id="14" string="dismissing charges against five of the original seven defendants and criticizing the case in a 1986 `` 60 Minutes '' interview" type="VP">
          <tokens>
            <token id="9" string="dismissing" />
            <token id="10" string="charges" />
            <token id="11" string="against" />
            <token id="12" string="five" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="original" />
            <token id="16" string="seven" />
            <token id="17" string="defendants" />
            <token id="18" string="and" />
            <token id="19" string="criticizing" />
            <token id="20" string="the" />
            <token id="21" string="case" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="1986" />
            <token id="25" string="``" />
            <token id="26" string="60" />
            <token id="27" string="Minutes" />
            <token id="28" string="''" />
            <token id="29" string="interview" />
          </tokens>
        </chunking>
        <chunking id="15" string="interview" type="NP">
          <tokens>
            <token id="29" string="interview" />
          </tokens>
        </chunking>
        <chunking id="16" string="prosecutor 's chances" type="NP">
          <tokens>
            <token id="5" string="prosecutor" />
            <token id="6" string="'s" />
            <token id="7" string="chances" />
          </tokens>
        </chunking>
        <chunking id="17" string="dismissing charges against five of the original seven defendants" type="VP">
          <tokens>
            <token id="9" string="dismissing" />
            <token id="10" string="charges" />
            <token id="11" string="against" />
            <token id="12" string="five" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="original" />
            <token id="16" string="seven" />
            <token id="17" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="18" string="five" type="NP">
          <tokens>
            <token id="12" string="five" />
          </tokens>
        </chunking>
        <chunking id="19" string="the case in a 1986 `` 60 Minutes ''" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="case" />
            <token id="22" string="in" />
            <token id="23" string="a" />
            <token id="24" string="1986" />
            <token id="25" string="``" />
            <token id="26" string="60" />
            <token id="27" string="Minutes" />
            <token id="28" string="''" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Philibosian</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">hurt</governor>
          <dependent id="3">Reiner</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="4">hurt</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">chances</governor>
          <dependent id="5">prosecutor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">prosecutor</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">hurt</governor>
          <dependent id="7">chances</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">dismissing</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">hurt</governor>
          <dependent id="9">dismissing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">dismissing</governor>
          <dependent id="10">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">five</governor>
          <dependent id="11">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">dismissing</governor>
          <dependent id="12">five</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">defendants</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">defendants</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">defendants</governor>
          <dependent id="15">original</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">defendants</governor>
          <dependent id="16">seven</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">five</governor>
          <dependent id="17">defendants</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">dismissing</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">dismissing</governor>
          <dependent id="19">criticizing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">case</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">criticizing</governor>
          <dependent id="21">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">1986</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">1986</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">case</governor>
          <dependent id="24">1986</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="27">Minutes</governor>
          <dependent id="26">60</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="24">1986</governor>
          <dependent id="27">Minutes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">dismissing</governor>
          <dependent id="29">interview</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="60 Minutes" type="DURATION" score="0.0">
          <tokens>
            <token id="26" string="60" />
            <token id="27" string="Minutes" />
          </tokens>
        </entity>
        <entity id="2" string="1986" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="1986" />
          </tokens>
        </entity>
        <entity id="3" string="Philibosian" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Philibosian" />
          </tokens>
        </entity>
        <entity id="4" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="seven" />
          </tokens>
        </entity>
        <entity id="5" string="Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Reiner" />
          </tokens>
        </entity>
        <entity id="6" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>But Reiner, calling his dismissal of charges for lack of evidence ``the decision we&amp;apost;re proud of,&amp;apost;&amp;apost; said the trial took so long because of the state&amp;apost;s ponderous criminal justice system, delay tactics by defense attorneys and a mess left behind by Philibosian.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="calling" lemma="call" stem="call" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="dismissal" lemma="dismissal" stem="dismiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="proud" lemma="proud" stem="proud" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="ponderous" lemma="ponderous" stem="ponder" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="delay" lemma="delay" stem="delai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="tactics" lemma="tactic" stem="tactic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="defense" lemma="defense" stem="defens" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="42" string="attorneys" lemma="attorney" stem="attornei" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="43" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="mess" lemma="mess" stem="mess" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="47" string="behind" lemma="behind" stem="behind" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="Philibosian" lemma="Philibosian" stem="philibosian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="50" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NNP Reiner)) (, ,) (S (VP (VBG calling) (NP (NP (PRP$ his) (NN dismissal)) (PP (IN of) (NP (NP (NNS charges)) (PP (IN for) (NP (NP (NN lack)) (PP (IN of) (NP (NN evidence)))))))) (`` ``) (S (NP (NP (DT the) (NN decision)) (SBAR (S (NP (PRP we)) (VP (VBP 're) (ADJP (JJ proud) (PP (IN of)))))) (, ,) ('' '')) (VP (VBD said) (SBAR (S (NP (DT the) (NN trial)) (VP (VBD took) (ADVP (RB so) (RB long)) (PP (IN because) (PP (IN of) (NP (NP (DT the) (NN state) (POS 's)) (JJ ponderous) (JJ criminal) (NN justice) (NN system))))))))))) (, ,) (NP (NP (NN delay) (NNS tactics)) (PP (IN by) (NP (NP (NN defense) (NNS attorneys)) (CC and) (NP (DT a) (NN mess))))) (VP (VBD left) (PRT (RP behind)) (PP (IN by) (NP (NNP Philibosian)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said the trial took so long because of the state 's ponderous criminal justice system" type="VP">
          <tokens>
            <token id="22" string="said" />
            <token id="23" string="the" />
            <token id="24" string="trial" />
            <token id="25" string="took" />
            <token id="26" string="so" />
            <token id="27" string="long" />
            <token id="28" string="because" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="state" />
            <token id="32" string="'s" />
            <token id="33" string="ponderous" />
            <token id="34" string="criminal" />
            <token id="35" string="justice" />
            <token id="36" string="system" />
          </tokens>
        </chunking>
        <chunking id="2" string="defense attorneys and a mess" type="NP">
          <tokens>
            <token id="41" string="defense" />
            <token id="42" string="attorneys" />
            <token id="43" string="and" />
            <token id="44" string="a" />
            <token id="45" string="mess" />
          </tokens>
        </chunking>
        <chunking id="3" string="the trial" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="trial" />
          </tokens>
        </chunking>
        <chunking id="4" string="his dismissal" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="dismissal" />
          </tokens>
        </chunking>
        <chunking id="5" string="the decision we 're proud of , ''" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="decision" />
            <token id="16" string="we" />
            <token id="17" string="'re" />
            <token id="18" string="proud" />
            <token id="19" string="of" />
            <token id="20" string="," />
            <token id="21" string="''" />
          </tokens>
        </chunking>
        <chunking id="6" string="proud of" type="ADJP">
          <tokens>
            <token id="18" string="proud" />
            <token id="19" string="of" />
          </tokens>
        </chunking>
        <chunking id="7" string="the state 's" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="state" />
            <token id="32" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="a mess" type="NP">
          <tokens>
            <token id="44" string="a" />
            <token id="45" string="mess" />
          </tokens>
        </chunking>
        <chunking id="9" string="left behind by Philibosian" type="VP">
          <tokens>
            <token id="46" string="left" />
            <token id="47" string="behind" />
            <token id="48" string="by" />
            <token id="49" string="Philibosian" />
          </tokens>
        </chunking>
        <chunking id="10" string="lack" type="NP">
          <tokens>
            <token id="10" string="lack" />
          </tokens>
        </chunking>
        <chunking id="11" string="defense attorneys" type="NP">
          <tokens>
            <token id="41" string="defense" />
            <token id="42" string="attorneys" />
          </tokens>
        </chunking>
        <chunking id="12" string="delay tactics by defense attorneys and a mess" type="NP">
          <tokens>
            <token id="38" string="delay" />
            <token id="39" string="tactics" />
            <token id="40" string="by" />
            <token id="41" string="defense" />
            <token id="42" string="attorneys" />
            <token id="43" string="and" />
            <token id="44" string="a" />
            <token id="45" string="mess" />
          </tokens>
        </chunking>
        <chunking id="13" string="charges" type="NP">
          <tokens>
            <token id="8" string="charges" />
          </tokens>
        </chunking>
        <chunking id="14" string="we 're proud of" type="SBAR">
          <tokens>
            <token id="16" string="we" />
            <token id="17" string="'re" />
            <token id="18" string="proud" />
            <token id="19" string="of" />
          </tokens>
        </chunking>
        <chunking id="15" string="the trial took so long because of the state 's ponderous criminal justice system" type="SBAR">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="trial" />
            <token id="25" string="took" />
            <token id="26" string="so" />
            <token id="27" string="long" />
            <token id="28" string="because" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="state" />
            <token id="32" string="'s" />
            <token id="33" string="ponderous" />
            <token id="34" string="criminal" />
            <token id="35" string="justice" />
            <token id="36" string="system" />
          </tokens>
        </chunking>
        <chunking id="16" string="charges for lack of evidence" type="NP">
          <tokens>
            <token id="8" string="charges" />
            <token id="9" string="for" />
            <token id="10" string="lack" />
            <token id="11" string="of" />
            <token id="12" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="17" string="took so long because of the state 's ponderous criminal justice system" type="VP">
          <tokens>
            <token id="25" string="took" />
            <token id="26" string="so" />
            <token id="27" string="long" />
            <token id="28" string="because" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="state" />
            <token id="32" string="'s" />
            <token id="33" string="ponderous" />
            <token id="34" string="criminal" />
            <token id="35" string="justice" />
            <token id="36" string="system" />
          </tokens>
        </chunking>
        <chunking id="18" string="'re proud of" type="VP">
          <tokens>
            <token id="17" string="'re" />
            <token id="18" string="proud" />
            <token id="19" string="of" />
          </tokens>
        </chunking>
        <chunking id="19" string="calling his dismissal of charges for lack of evidence `` the decision we 're proud of , '' said the trial took so long because of the state 's ponderous criminal justice system" type="VP">
          <tokens>
            <token id="4" string="calling" />
            <token id="5" string="his" />
            <token id="6" string="dismissal" />
            <token id="7" string="of" />
            <token id="8" string="charges" />
            <token id="9" string="for" />
            <token id="10" string="lack" />
            <token id="11" string="of" />
            <token id="12" string="evidence" />
            <token id="13" string="``" />
            <token id="14" string="the" />
            <token id="15" string="decision" />
            <token id="16" string="we" />
            <token id="17" string="'re" />
            <token id="18" string="proud" />
            <token id="19" string="of" />
            <token id="20" string="," />
            <token id="21" string="''" />
            <token id="22" string="said" />
            <token id="23" string="the" />
            <token id="24" string="trial" />
            <token id="25" string="took" />
            <token id="26" string="so" />
            <token id="27" string="long" />
            <token id="28" string="because" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="state" />
            <token id="32" string="'s" />
            <token id="33" string="ponderous" />
            <token id="34" string="criminal" />
            <token id="35" string="justice" />
            <token id="36" string="system" />
          </tokens>
        </chunking>
        <chunking id="20" string="lack of evidence" type="NP">
          <tokens>
            <token id="10" string="lack" />
            <token id="11" string="of" />
            <token id="12" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="21" string="Philibosian" type="NP">
          <tokens>
            <token id="49" string="Philibosian" />
          </tokens>
        </chunking>
        <chunking id="22" string="evidence" type="NP">
          <tokens>
            <token id="12" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="23" string="the state 's ponderous criminal justice system" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="state" />
            <token id="32" string="'s" />
            <token id="33" string="ponderous" />
            <token id="34" string="criminal" />
            <token id="35" string="justice" />
            <token id="36" string="system" />
          </tokens>
        </chunking>
        <chunking id="24" string="delay tactics" type="NP">
          <tokens>
            <token id="38" string="delay" />
            <token id="39" string="tactics" />
          </tokens>
        </chunking>
        <chunking id="25" string="Reiner" type="NP">
          <tokens>
            <token id="2" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="26" string="the decision" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="decision" />
          </tokens>
        </chunking>
        <chunking id="27" string="we" type="NP">
          <tokens>
            <token id="16" string="we" />
          </tokens>
        </chunking>
        <chunking id="28" string="his dismissal of charges for lack of evidence" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="dismissal" />
            <token id="7" string="of" />
            <token id="8" string="charges" />
            <token id="9" string="for" />
            <token id="10" string="lack" />
            <token id="11" string="of" />
            <token id="12" string="evidence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="46">left</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">left</governor>
          <dependent id="2">Reiner</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="46">left</governor>
          <dependent id="4">calling</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">dismissal</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">calling</governor>
          <dependent id="6">dismissal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">charges</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">dismissal</governor>
          <dependent id="8">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">lack</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">charges</governor>
          <dependent id="10">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">evidence</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">lack</governor>
          <dependent id="12">evidence</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">decision</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">said</governor>
          <dependent id="15">decision</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">proud</governor>
          <dependent id="16">we</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">proud</governor>
          <dependent id="17">'re</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">decision</governor>
          <dependent id="18">proud</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">proud</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">calling</governor>
          <dependent id="22">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">trial</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">took</governor>
          <dependent id="24">trial</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">said</governor>
          <dependent id="25">took</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">long</governor>
          <dependent id="26">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">took</governor>
          <dependent id="27">long</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">system</governor>
          <dependent id="28">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">system</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">state</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">system</governor>
          <dependent id="31">state</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">state</governor>
          <dependent id="32">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">system</governor>
          <dependent id="33">ponderous</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">system</governor>
          <dependent id="34">criminal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">system</governor>
          <dependent id="35">justice</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">took</governor>
          <dependent id="36">system</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">tactics</governor>
          <dependent id="38">delay</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">left</governor>
          <dependent id="39">tactics</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">attorneys</governor>
          <dependent id="40">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">attorneys</governor>
          <dependent id="41">defense</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="39">tactics</governor>
          <dependent id="42">attorneys</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="42">attorneys</governor>
          <dependent id="43">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="45">mess</governor>
          <dependent id="44">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="42">attorneys</governor>
          <dependent id="45">mess</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="46">left</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="46">left</governor>
          <dependent id="47">behind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">Philibosian</governor>
          <dependent id="48">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">left</governor>
          <dependent id="49">Philibosian</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="46" string="left" />
          </tokens>
        </entity>
        <entity id="2" string="Philibosian" type="PERSON" score="0.0">
          <tokens>
            <token id="49" string="Philibosian" />
          </tokens>
        </entity>
        <entity id="3" string="Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Reiner" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>``This is a case I inherited,&amp;apost;&amp;apost; Reiner said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="7" string="inherited" lemma="inherit" stem="inherit" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT This)) (VP (VBZ is) (NP (NP (DT a) (NN case)) (SBAR (S (NP (PRP I)) (VP (VBD inherited))))))) (, ,) ('' '') (NP (NNP Reiner)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="I inherited" type="SBAR">
          <tokens>
            <token id="6" string="I" />
            <token id="7" string="inherited" />
          </tokens>
        </chunking>
        <chunking id="2" string="is a case I inherited" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="case" />
            <token id="6" string="I" />
            <token id="7" string="inherited" />
          </tokens>
        </chunking>
        <chunking id="3" string="inherited" type="VP">
          <tokens>
            <token id="7" string="inherited" />
          </tokens>
        </chunking>
        <chunking id="4" string="a case I inherited" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="case" />
            <token id="6" string="I" />
            <token id="7" string="inherited" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="a case" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="This" type="NP">
          <tokens>
            <token id="2" string="This" />
          </tokens>
        </chunking>
        <chunking id="8" string="Reiner" type="NP">
          <tokens>
            <token id="10" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">case</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">case</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">case</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="5">case</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">inherited</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">case</governor>
          <dependent id="7">inherited</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Reiner</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Reiner" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>In interviews, many jurors said they believed some of the children were molested, but the prosecution never established that the defendants were responsible.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="believed" lemma="believe" stem="believ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="prosecution" lemma="prosecution" stem="prosecut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="established" lemma="establish" stem="establish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="responsible" lemma="responsible" stem="respons" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN In) (NP (NNS interviews))) (, ,) (NP (JJ many) (NNS jurors)) (VP (VBD said) (SBAR (S (NP (PRP they)) (VP (VBD believed) (SBAR (S (NP (NP (DT some)) (PP (IN of) (NP (DT the) (NNS children)))) (VP (VBD were) (VP (VBN molested)))))))))) (, ,) (CC but) (S (NP (DT the) (NN prosecution)) (ADVP (RB never)) (VP (VBD established) (SBAR (IN that) (S (NP (DT the) (NNS defendants)) (VP (VBD were) (ADJP (JJ responsible))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they believed some of the children were molested" type="SBAR">
          <tokens>
            <token id="7" string="they" />
            <token id="8" string="believed" />
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="children" />
            <token id="13" string="were" />
            <token id="14" string="molested" />
          </tokens>
        </chunking>
        <chunking id="2" string="believed some of the children were molested" type="VP">
          <tokens>
            <token id="8" string="believed" />
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="children" />
            <token id="13" string="were" />
            <token id="14" string="molested" />
          </tokens>
        </chunking>
        <chunking id="3" string="some of the children" type="NP">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="children" />
          </tokens>
        </chunking>
        <chunking id="4" string="some" type="NP">
          <tokens>
            <token id="9" string="some" />
          </tokens>
        </chunking>
        <chunking id="5" string="said they believed some of the children were molested" type="VP">
          <tokens>
            <token id="6" string="said" />
            <token id="7" string="they" />
            <token id="8" string="believed" />
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="children" />
            <token id="13" string="were" />
            <token id="14" string="molested" />
          </tokens>
        </chunking>
        <chunking id="6" string="some of the children were molested" type="SBAR">
          <tokens>
            <token id="9" string="some" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="children" />
            <token id="13" string="were" />
            <token id="14" string="molested" />
          </tokens>
        </chunking>
        <chunking id="7" string="interviews" type="NP">
          <tokens>
            <token id="2" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="8" string="many jurors" type="NP">
          <tokens>
            <token id="4" string="many" />
            <token id="5" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="9" string="they" type="NP">
          <tokens>
            <token id="7" string="they" />
          </tokens>
        </chunking>
        <chunking id="10" string="that the defendants were responsible" type="SBAR">
          <tokens>
            <token id="21" string="that" />
            <token id="22" string="the" />
            <token id="23" string="defendants" />
            <token id="24" string="were" />
            <token id="25" string="responsible" />
          </tokens>
        </chunking>
        <chunking id="11" string="the children" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="responsible" type="ADJP">
          <tokens>
            <token id="25" string="responsible" />
          </tokens>
        </chunking>
        <chunking id="13" string="established that the defendants were responsible" type="VP">
          <tokens>
            <token id="20" string="established" />
            <token id="21" string="that" />
            <token id="22" string="the" />
            <token id="23" string="defendants" />
            <token id="24" string="were" />
            <token id="25" string="responsible" />
          </tokens>
        </chunking>
        <chunking id="14" string="the defendants" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="15" string="were molested" type="VP">
          <tokens>
            <token id="13" string="were" />
            <token id="14" string="molested" />
          </tokens>
        </chunking>
        <chunking id="16" string="the prosecution" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="17" string="were responsible" type="VP">
          <tokens>
            <token id="24" string="were" />
            <token id="25" string="responsible" />
          </tokens>
        </chunking>
        <chunking id="18" string="molested" type="VP">
          <tokens>
            <token id="14" string="molested" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">interviews</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">said</governor>
          <dependent id="2">interviews</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">jurors</governor>
          <dependent id="4">many</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="5">jurors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">believed</governor>
          <dependent id="7">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">said</governor>
          <dependent id="8">believed</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">molested</governor>
          <dependent id="9">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">children</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">children</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">some</governor>
          <dependent id="12">children</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">molested</governor>
          <dependent id="13">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">believed</governor>
          <dependent id="14">molested</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">said</governor>
          <dependent id="16">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">prosecution</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">established</governor>
          <dependent id="18">prosecution</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">established</governor>
          <dependent id="19">never</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">said</governor>
          <dependent id="20">established</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">responsible</governor>
          <dependent id="21">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">defendants</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">responsible</governor>
          <dependent id="23">defendants</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">responsible</governor>
          <dependent id="24">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">established</governor>
          <dependent id="25">responsible</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>``Even if you accept that the children were molested, it didn&amp;apost;t necessarily mean they were molested at the McMartin Pre-School,&amp;apost;&amp;apost; said juror Brenda Williams.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="accept" lemma="accept" stem="accept" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="necessarily" lemma="necessarily" stem="necessarili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="mean" lemma="mean" stem="mean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Brenda" lemma="Brenda" stem="brenda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="29" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (SBAR (RB Even) (IN if) (S (NP (PRP you)) (VP (VBP accept) (SBAR (IN that) (S (NP (DT the) (NNS children)) (VP (VBD were) (VP (VBN molested)))))))) (, ,) (NP (PRP it)) (VP (VBD did) (RB n't) (ADVP (RB necessarily)) (VP (VB mean) (SBAR (S (NP (PRP they)) (VP (VBD were) (VP (VBN molested) (PP (IN at) (NP (DT the) (NNP McMartin) (NNP Pre-School)))))))))) (, ,) ('' '') (VP (VBD said) (NP (NN juror))) (NP (NNP Brenda) (NNP Williams)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="juror" type="NP">
          <tokens>
            <token id="27" string="juror" />
          </tokens>
        </chunking>
        <chunking id="2" string="did n't necessarily mean they were molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="13" string="did" />
            <token id="14" string="n't" />
            <token id="15" string="necessarily" />
            <token id="16" string="mean" />
            <token id="17" string="they" />
            <token id="18" string="were" />
            <token id="19" string="molested" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="said juror" type="VP">
          <tokens>
            <token id="26" string="said" />
            <token id="27" string="juror" />
          </tokens>
        </chunking>
        <chunking id="5" string="Brenda Williams" type="NP">
          <tokens>
            <token id="28" string="Brenda" />
            <token id="29" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="6" string="they" type="NP">
          <tokens>
            <token id="17" string="they" />
          </tokens>
        </chunking>
        <chunking id="7" string="the children" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="were molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="18" string="were" />
            <token id="19" string="molested" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="9" string="that the children were molested" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="children" />
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="10" string="accept that the children were molested" type="VP">
          <tokens>
            <token id="5" string="accept" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="children" />
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="11" string="were molested" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="12" string="the McMartin Pre-School" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="13" string="Even if you accept that the children were molested" type="SBAR">
          <tokens>
            <token id="2" string="Even" />
            <token id="3" string="if" />
            <token id="4" string="you" />
            <token id="5" string="accept" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="children" />
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="14" string="molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="19" string="molested" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="15" string="molested" type="VP">
          <tokens>
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="16" string="you" type="NP">
          <tokens>
            <token id="4" string="you" />
          </tokens>
        </chunking>
        <chunking id="17" string="mean they were molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="16" string="mean" />
            <token id="17" string="they" />
            <token id="18" string="were" />
            <token id="19" string="molested" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="18" string="they were molested at the McMartin Pre-School" type="SBAR">
          <tokens>
            <token id="17" string="they" />
            <token id="18" string="were" />
            <token id="19" string="molested" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">accept</governor>
          <dependent id="2">Even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">accept</governor>
          <dependent id="3">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">accept</governor>
          <dependent id="4">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">mean</governor>
          <dependent id="5">accept</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">molested</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">children</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">molested</governor>
          <dependent id="8">children</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">molested</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">accept</governor>
          <dependent id="10">molested</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">mean</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">mean</governor>
          <dependent id="13">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">mean</governor>
          <dependent id="14">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">mean</governor>
          <dependent id="15">necessarily</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="26">said</governor>
          <dependent id="16">mean</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">molested</governor>
          <dependent id="17">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">molested</governor>
          <dependent id="18">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">mean</governor>
          <dependent id="19">molested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Pre-School</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Pre-School</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Pre-School</governor>
          <dependent id="22">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">molested</governor>
          <dependent id="23">Pre-School</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">said</governor>
          <dependent id="27">juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Williams</governor>
          <dependent id="28">Brenda</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">said</governor>
          <dependent id="29">Williams</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Brenda Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Brenda" />
            <token id="29" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="17-18" string="McMartin Pre-School" id_sentence="1" />
      <mentions>
        <mention ids_tokens="21-23" string="the McMartin Pre-School" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="23-24" string="the trial" id_sentence="16" />
      <mentions>
        <mention ids_tokens="2-8" string="the nation's longest and costliest trial" id_sentence="2" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="13 other charges" id_sentence="3" />
      <mentions>
        <mention ids_tokens="10" string="charges" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14" string="the current district attorney" id_sentence="4" />
      <mentions>
        <mention ids_tokens="6" string="his" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="41-42" string="defense attorneys" id_sentence="16" />
      <mentions>
        <mention ids_tokens="6-10" string="his predecessor and defense attorneys" id_sentence="5" />
        <mention ids_tokens="6" string="I" id_sentence="17" />
        <mention ids_tokens="4" string="you" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="4-5" string="my children" id_sentence="9" />
      <mentions>
        <mention ids_tokens="7-11" string="children who attended the school" id_sentence="6" />
        <mention ids_tokens="9" string="children" id_sentence="7" />
        <mention ids_tokens="11-12" string="the children" id_sentence="18" />
        <mention ids_tokens="7-8" string="the children" id_sentence="19" />
        <mention ids_tokens="17" string="they" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="9-10-11-12-13-14-15-16-17" string="Robert Curry , whose son attended the McMartin school" id_sentence="8" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="9" />
        <mention ids_tokens="4" string="my" id_sentence="9" />
        <mention ids_tokens="17" string="McMartin" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="15" string="Attorney" id_sentence="14" />
      <mentions>
        <mention ids_tokens="1-8" string="The district attorney who originally pursued the case" id_sentence="10" />
        <mention ids_tokens="10" string="he" id_sentence="10" />
        <mention ids_tokens="40-41" string="district attorney" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="1-2" string="Robert Philibosian" id_sentence="11" />
      <mentions>
        <mention ids_tokens="1" string="Philibosian" id_sentence="14" />
        <mention ids_tokens="11" string="him" id_sentence="14" />
        <mention ids_tokens="1" string="Philibosian" id_sentence="15" />
        <mention ids_tokens="49" string="Philibosian" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="14" type="NOMINAL">
      <referenced ids_tokens="16-17-18-19-20-21" string="the McMartin case in 1984 _" id_sentence="11" />
      <mentions>
        <mention ids_tokens="11-12" string="this case" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="8-9" string="16 years" id_sentence="12" />
      <mentions>
        <mention ids_tokens="17" string="me" id_sentence="13" />
        <mention ids_tokens="20" string="I" id_sentence="13" />
        <mention ids_tokens="5-6" string="prosecutor's" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24" string="To have people who know very little about professional or prosecutorial ethics , to criticize me personally that I have some political motive" id_sentence="13" />
      <mentions>
        <mention ids_tokens="16" string="we" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="13-14-15-16-17" string="current District Attorney Ira Reiner" id_sentence="14" />
      <mentions>
        <mention ids_tokens="3" string="Reiner" id_sentence="15" />
        <mention ids_tokens="2" string="Reiner" id_sentence="16" />
        <mention ids_tokens="5" string="his" id_sentence="16" />
        <mention ids_tokens="10" string="Reiner" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="9-10-11-12" string="some of the children" id_sentence="18" />
      <mentions>
        <mention ids_tokens="12" string="it" id_sentence="19" />
      </mentions>
    </coreference>
  </coreferences>
</document>
