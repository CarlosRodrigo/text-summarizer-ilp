<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="LA121090-0095">
  <sentences>
    <sentence id="1" has_coreference="false">
      <content>Their common ground pretty much ended when the miles of asphalt to the finish line did.</content>
      <tokens>
        <token id="1" string="Their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="common" lemma="common" stem="common" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="ground" lemma="ground" stem="ground" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="pretty" lemma="pretty" stem="pretti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="ended" lemma="end" stem="end" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="asphalt" lemma="asphalt" stem="asphalt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="finish" lemma="finish" stem="finish" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Their) (JJ common) (NN ground)) (VP (ADVP (RB pretty) (RB much)) (VBN ended) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (NNS miles)) (PP (IN of) (NP (NP (NN asphalt)) (PP (TO to) (NP (DT the) (NN finish) (NN line)))))) (VP (VBD did))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when the miles of asphalt to the finish line did" type="SBAR">
          <tokens>
            <token id="7" string="when" />
            <token id="8" string="the" />
            <token id="9" string="miles" />
            <token id="10" string="of" />
            <token id="11" string="asphalt" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="finish" />
            <token id="15" string="line" />
            <token id="16" string="did" />
          </tokens>
        </chunking>
        <chunking id="2" string="the miles" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="miles" />
          </tokens>
        </chunking>
        <chunking id="3" string="asphalt to the finish line" type="NP">
          <tokens>
            <token id="11" string="asphalt" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="finish" />
            <token id="15" string="line" />
          </tokens>
        </chunking>
        <chunking id="4" string="Their common ground" type="NP">
          <tokens>
            <token id="1" string="Their" />
            <token id="2" string="common" />
            <token id="3" string="ground" />
          </tokens>
        </chunking>
        <chunking id="5" string="the finish line" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="finish" />
            <token id="15" string="line" />
          </tokens>
        </chunking>
        <chunking id="6" string="asphalt" type="NP">
          <tokens>
            <token id="11" string="asphalt" />
          </tokens>
        </chunking>
        <chunking id="7" string="pretty much ended when the miles of asphalt to the finish line did" type="VP">
          <tokens>
            <token id="4" string="pretty" />
            <token id="5" string="much" />
            <token id="6" string="ended" />
            <token id="7" string="when" />
            <token id="8" string="the" />
            <token id="9" string="miles" />
            <token id="10" string="of" />
            <token id="11" string="asphalt" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="finish" />
            <token id="15" string="line" />
            <token id="16" string="did" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="7" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="the miles of asphalt to the finish line" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="miles" />
            <token id="10" string="of" />
            <token id="11" string="asphalt" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="finish" />
            <token id="15" string="line" />
          </tokens>
        </chunking>
        <chunking id="10" string="did" type="VP">
          <tokens>
            <token id="16" string="did" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">ground</governor>
          <dependent id="1">Their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">ground</governor>
          <dependent id="2">common</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">ended</governor>
          <dependent id="3">ground</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">much</governor>
          <dependent id="4">pretty</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">ended</governor>
          <dependent id="5">much</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">ended</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">did</governor>
          <dependent id="7">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">miles</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">did</governor>
          <dependent id="9">miles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">asphalt</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">miles</governor>
          <dependent id="11">asphalt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">line</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">line</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">line</governor>
          <dependent id="14">finish</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">asphalt</governor>
          <dependent id="15">line</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">ended</governor>
          <dependent id="16">did</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>By the time most people were starting their first cup of coffee Sunday morning, Benjamin Paredez Martinez of Ecatepec, Mexico, and Kathy Smith of Newport Beach were crowned winners in the San Diego Marathon at the Oceanside pier, efforts than earned them $2,000 apiece.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="starting" lemma="start" stem="start" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="10" string="cup" lemma="cup" stem="cup" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="coffee" lemma="coffee" stem="coffe" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string="morning" lemma="morning" stem="morn" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Benjamin" lemma="Benjamin" stem="benjamin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Paredez" lemma="Paredez" stem="paredez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Ecatepec" lemma="Ecatepec" stem="ecatepec" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Mexico" lemma="Mexico" stem="mexico" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Kathy" lemma="Kathy" stem="kathi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Newport" lemma="Newport" stem="newport" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="crowned" lemma="crown" stem="crown" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="winners" lemma="winner" stem="winner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="36" string="Diego" lemma="Diego" stem="diego" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="37" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="38" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="Oceanside" lemma="Oceanside" stem="oceansid" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="41" string="pier" lemma="pier" stem="pier" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="efforts" lemma="effort" stem="effort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="earned" lemma="earn" stem="earn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="48" string="2,000" lemma="2,000" stem="2,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="49" string="apiece" lemma="apiece" stem="apiec" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (NP (DT the) (NN time)) (SBAR (S (NP (JJS most) (NNS people)) (VP (VBD were) (VP (VBG starting) (NP (NP (PRP$ their) (JJ first) (NN cup)) (PP (IN of) (NP (NN coffee)))) (NP-TMP (NNP Sunday) (NN morning)))))))) (, ,) (NP (NP (NNP Benjamin) (NNP Paredez) (NNP Martinez)) (PP (IN of) (NP (NP (NNP Ecatepec) (, ,) (NNP Mexico) (, ,) (CC and) (NNP Kathy) (NNP Smith)) (PP (IN of) (NP (NNP Newport) (NNP Beach)))))) (VP (VBD were) (VP (VBN crowned) (NP (NP (NNS winners)) (PP (IN in) (NP (DT the) (NNP San) (NNP Diego) (NNP Marathon)))) (PP (IN at) (NP (NP (DT the) (NNP Oceanside) (NN pier)) (, ,) (NP (NNS efforts)))) (SBAR (IN than) (S (VP (VBD earned) (NP (PRP them)) (NP ($ $) (CD 2,000)) (ADVP (RB apiece))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="most people were starting their first cup of coffee Sunday morning" type="SBAR">
          <tokens>
            <token id="4" string="most" />
            <token id="5" string="people" />
            <token id="6" string="were" />
            <token id="7" string="starting" />
            <token id="8" string="their" />
            <token id="9" string="first" />
            <token id="10" string="cup" />
            <token id="11" string="of" />
            <token id="12" string="coffee" />
            <token id="13" string="Sunday" />
            <token id="14" string="morning" />
          </tokens>
        </chunking>
        <chunking id="2" string="the San Diego Marathon" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="San" />
            <token id="36" string="Diego" />
            <token id="37" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Oceanside pier" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="Oceanside" />
            <token id="41" string="pier" />
          </tokens>
        </chunking>
        <chunking id="4" string="Benjamin Paredez Martinez of Ecatepec , Mexico , and Kathy Smith of Newport Beach" type="NP">
          <tokens>
            <token id="16" string="Benjamin" />
            <token id="17" string="Paredez" />
            <token id="18" string="Martinez" />
            <token id="19" string="of" />
            <token id="20" string="Ecatepec" />
            <token id="21" string="," />
            <token id="22" string="Mexico" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="Kathy" />
            <token id="26" string="Smith" />
            <token id="27" string="of" />
            <token id="28" string="Newport" />
            <token id="29" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="5" string="winners" type="NP">
          <tokens>
            <token id="32" string="winners" />
          </tokens>
        </chunking>
        <chunking id="6" string="were crowned winners in the San Diego Marathon at the Oceanside pier , efforts than earned them $ 2,000 apiece" type="VP">
          <tokens>
            <token id="30" string="were" />
            <token id="31" string="crowned" />
            <token id="32" string="winners" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="San" />
            <token id="36" string="Diego" />
            <token id="37" string="Marathon" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="Oceanside" />
            <token id="41" string="pier" />
            <token id="42" string="," />
            <token id="43" string="efforts" />
            <token id="44" string="than" />
            <token id="45" string="earned" />
            <token id="46" string="them" />
            <token id="47" string="$" />
            <token id="48" string="2,000" />
            <token id="49" string="apiece" />
          </tokens>
        </chunking>
        <chunking id="7" string="$ 2,000" type="NP">
          <tokens>
            <token id="47" string="$" />
            <token id="48" string="2,000" />
          </tokens>
        </chunking>
        <chunking id="8" string="the time most people were starting their first cup of coffee Sunday morning" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="time" />
            <token id="4" string="most" />
            <token id="5" string="people" />
            <token id="6" string="were" />
            <token id="7" string="starting" />
            <token id="8" string="their" />
            <token id="9" string="first" />
            <token id="10" string="cup" />
            <token id="11" string="of" />
            <token id="12" string="coffee" />
            <token id="13" string="Sunday" />
            <token id="14" string="morning" />
          </tokens>
        </chunking>
        <chunking id="9" string="most people" type="NP">
          <tokens>
            <token id="4" string="most" />
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="46" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ecatepec , Mexico , and Kathy Smith of Newport Beach" type="NP">
          <tokens>
            <token id="20" string="Ecatepec" />
            <token id="21" string="," />
            <token id="22" string="Mexico" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="Kathy" />
            <token id="26" string="Smith" />
            <token id="27" string="of" />
            <token id="28" string="Newport" />
            <token id="29" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="12" string="coffee" type="NP">
          <tokens>
            <token id="12" string="coffee" />
          </tokens>
        </chunking>
        <chunking id="13" string="earned them $ 2,000 apiece" type="VP">
          <tokens>
            <token id="45" string="earned" />
            <token id="46" string="them" />
            <token id="47" string="$" />
            <token id="48" string="2,000" />
            <token id="49" string="apiece" />
          </tokens>
        </chunking>
        <chunking id="14" string="Benjamin Paredez Martinez" type="NP">
          <tokens>
            <token id="16" string="Benjamin" />
            <token id="17" string="Paredez" />
            <token id="18" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="15" string="efforts" type="NP">
          <tokens>
            <token id="43" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="16" string="crowned winners in the San Diego Marathon at the Oceanside pier , efforts than earned them $ 2,000 apiece" type="VP">
          <tokens>
            <token id="31" string="crowned" />
            <token id="32" string="winners" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="San" />
            <token id="36" string="Diego" />
            <token id="37" string="Marathon" />
            <token id="38" string="at" />
            <token id="39" string="the" />
            <token id="40" string="Oceanside" />
            <token id="41" string="pier" />
            <token id="42" string="," />
            <token id="43" string="efforts" />
            <token id="44" string="than" />
            <token id="45" string="earned" />
            <token id="46" string="them" />
            <token id="47" string="$" />
            <token id="48" string="2,000" />
            <token id="49" string="apiece" />
          </tokens>
        </chunking>
        <chunking id="17" string="their first cup" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="first" />
            <token id="10" string="cup" />
          </tokens>
        </chunking>
        <chunking id="18" string="the time" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="time" />
          </tokens>
        </chunking>
        <chunking id="19" string="than earned them $ 2,000 apiece" type="SBAR">
          <tokens>
            <token id="44" string="than" />
            <token id="45" string="earned" />
            <token id="46" string="them" />
            <token id="47" string="$" />
            <token id="48" string="2,000" />
            <token id="49" string="apiece" />
          </tokens>
        </chunking>
        <chunking id="20" string="were starting their first cup of coffee Sunday morning" type="VP">
          <tokens>
            <token id="6" string="were" />
            <token id="7" string="starting" />
            <token id="8" string="their" />
            <token id="9" string="first" />
            <token id="10" string="cup" />
            <token id="11" string="of" />
            <token id="12" string="coffee" />
            <token id="13" string="Sunday" />
            <token id="14" string="morning" />
          </tokens>
        </chunking>
        <chunking id="21" string="the Oceanside pier , efforts" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="Oceanside" />
            <token id="41" string="pier" />
            <token id="42" string="," />
            <token id="43" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="22" string="Newport Beach" type="NP">
          <tokens>
            <token id="28" string="Newport" />
            <token id="29" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="23" string="winners in the San Diego Marathon" type="NP">
          <tokens>
            <token id="32" string="winners" />
            <token id="33" string="in" />
            <token id="34" string="the" />
            <token id="35" string="San" />
            <token id="36" string="Diego" />
            <token id="37" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="24" string="their first cup of coffee" type="NP">
          <tokens>
            <token id="8" string="their" />
            <token id="9" string="first" />
            <token id="10" string="cup" />
            <token id="11" string="of" />
            <token id="12" string="coffee" />
          </tokens>
        </chunking>
        <chunking id="25" string="starting their first cup of coffee Sunday morning" type="VP">
          <tokens>
            <token id="7" string="starting" />
            <token id="8" string="their" />
            <token id="9" string="first" />
            <token id="10" string="cup" />
            <token id="11" string="of" />
            <token id="12" string="coffee" />
            <token id="13" string="Sunday" />
            <token id="14" string="morning" />
          </tokens>
        </chunking>
        <chunking id="26" string="Ecatepec , Mexico , and Kathy Smith" type="NP">
          <tokens>
            <token id="20" string="Ecatepec" />
            <token id="21" string="," />
            <token id="22" string="Mexico" />
            <token id="23" string="," />
            <token id="24" string="and" />
            <token id="25" string="Kathy" />
            <token id="26" string="Smith" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">time</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">time</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">crowned</governor>
          <dependent id="3">time</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">people</governor>
          <dependent id="4">most</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">starting</governor>
          <dependent id="5">people</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">starting</governor>
          <dependent id="6">were</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">time</governor>
          <dependent id="7">starting</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">cup</governor>
          <dependent id="8">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">cup</governor>
          <dependent id="9">first</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">starting</governor>
          <dependent id="10">cup</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">coffee</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">cup</governor>
          <dependent id="12">coffee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">morning</governor>
          <dependent id="13">Sunday</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">starting</governor>
          <dependent id="14">morning</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Martinez</governor>
          <dependent id="16">Benjamin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Martinez</governor>
          <dependent id="17">Paredez</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">crowned</governor>
          <dependent id="18">Martinez</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Mexico</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Mexico</governor>
          <dependent id="20">Ecatepec</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">Martinez</governor>
          <dependent id="22">Mexico</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">Mexico</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Smith</governor>
          <dependent id="25">Kathy</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="22">Mexico</governor>
          <dependent id="26">Smith</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Beach</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Beach</governor>
          <dependent id="28">Newport</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">Mexico</governor>
          <dependent id="29">Beach</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">crowned</governor>
          <dependent id="30">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">crowned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">crowned</governor>
          <dependent id="32">winners</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Marathon</governor>
          <dependent id="33">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">Marathon</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Marathon</governor>
          <dependent id="35">San</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Marathon</governor>
          <dependent id="36">Diego</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">winners</governor>
          <dependent id="37">Marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">pier</governor>
          <dependent id="38">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">pier</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">pier</governor>
          <dependent id="40">Oceanside</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">crowned</governor>
          <dependent id="41">pier</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="41">pier</governor>
          <dependent id="43">efforts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="45">earned</governor>
          <dependent id="44">than</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">crowned</governor>
          <dependent id="45">earned</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="45">earned</governor>
          <dependent id="46">them</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="48">2,000</governor>
          <dependent id="47">$</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="45">earned</governor>
          <dependent id="48">2,000</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="45">earned</governor>
          <dependent id="49">apiece</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="9" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Benjamin Paredez Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Benjamin" />
            <token id="17" string="Paredez" />
            <token id="18" string="Martinez" />
          </tokens>
        </entity>
        <entity id="3" string="Kathy Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Kathy" />
            <token id="26" string="Smith" />
          </tokens>
        </entity>
        <entity id="4" string="Oceanside" type="LOCATION" score="0.0">
          <tokens>
            <token id="40" string="Oceanside" />
          </tokens>
        </entity>
        <entity id="5" string="Newport Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="Newport" />
            <token id="29" string="Beach" />
          </tokens>
        </entity>
        <entity id="6" string="morning" type="TIME" score="0.0">
          <tokens>
            <token id="14" string="morning" />
          </tokens>
        </entity>
        <entity id="7" string="Mexico" type="LOCATION" score="0.0">
          <tokens>
            <token id="22" string="Mexico" />
          </tokens>
        </entity>
        <entity id="8" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="Sunday" />
          </tokens>
        </entity>
        <entity id="9" string="$ 2,000" type="MONEY" score="0.0">
          <tokens>
            <token id="47" string="$" />
            <token id="48" string="2,000" />
          </tokens>
        </entity>
        <entity id="10" string="San Diego Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="35" string="San" />
            <token id="36" string="Diego" />
            <token id="37" string="Marathon" />
          </tokens>
        </entity>
        <entity id="11" string="Ecatepec" type="LOCATION" score="0.0">
          <tokens>
            <token id="20" string="Ecatepec" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>The runs set records on the new North County course, but the times, even helped by warm breezes and clear, 74-degree conditions, were hardly blistering.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="runs" lemma="run" stem="run" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="set" lemma="set" stem="set" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="records" lemma="record" stem="record" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="North" lemma="North" stem="north" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="County" lemma="County" stem="counti" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="helped" lemma="help" stem="help" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="warm" lemma="warm" stem="warm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="breezes" lemma="breeze" stem="breez" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="clear" lemma="clear" stem="clear" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="74-degree" lemma="74-degree" stem="74-degre" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="conditions" lemma="condition" stem="condit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="hardly" lemma="hardly" stem="hardli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="blistering" lemma="blister" stem="blister" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NNS runs)) (VP (VBP set) (NP (NP (NNS records)) (PP (IN on) (NP (DT the) (JJ new) (NNP North) (NNP County) (NN course)))))) (, ,) (CC but) (S (NP (NP (DT the) (NNS times)) (, ,) (VP (ADVP (RB even)) (VBN helped) (PP (IN by) (NP (NP (JJ warm) (NNS breezes)) (CC and) (NP (JJ clear) (, ,) (JJ 74-degree) (NNS conditions))))) (, ,)) (VP (VBD were) (ADVP (RB hardly)) (VP (VBG blistering)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="warm breezes and clear , 74-degree conditions" type="NP">
          <tokens>
            <token id="19" string="warm" />
            <token id="20" string="breezes" />
            <token id="21" string="and" />
            <token id="22" string="clear" />
            <token id="23" string="," />
            <token id="24" string="74-degree" />
            <token id="25" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="2" string="the times , even helped by warm breezes and clear , 74-degree conditions ," type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="times" />
            <token id="15" string="," />
            <token id="16" string="even" />
            <token id="17" string="helped" />
            <token id="18" string="by" />
            <token id="19" string="warm" />
            <token id="20" string="breezes" />
            <token id="21" string="and" />
            <token id="22" string="clear" />
            <token id="23" string="," />
            <token id="24" string="74-degree" />
            <token id="25" string="conditions" />
            <token id="26" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="records" type="NP">
          <tokens>
            <token id="4" string="records" />
          </tokens>
        </chunking>
        <chunking id="4" string="records on the new North County course" type="NP">
          <tokens>
            <token id="4" string="records" />
            <token id="5" string="on" />
            <token id="6" string="the" />
            <token id="7" string="new" />
            <token id="8" string="North" />
            <token id="9" string="County" />
            <token id="10" string="course" />
          </tokens>
        </chunking>
        <chunking id="5" string="The runs" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="runs" />
          </tokens>
        </chunking>
        <chunking id="6" string="were hardly blistering" type="VP">
          <tokens>
            <token id="27" string="were" />
            <token id="28" string="hardly" />
            <token id="29" string="blistering" />
          </tokens>
        </chunking>
        <chunking id="7" string="clear , 74-degree conditions" type="NP">
          <tokens>
            <token id="22" string="clear" />
            <token id="23" string="," />
            <token id="24" string="74-degree" />
            <token id="25" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="8" string="blistering" type="VP">
          <tokens>
            <token id="29" string="blistering" />
          </tokens>
        </chunking>
        <chunking id="9" string="the new North County course" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="new" />
            <token id="8" string="North" />
            <token id="9" string="County" />
            <token id="10" string="course" />
          </tokens>
        </chunking>
        <chunking id="10" string="the times" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="times" />
          </tokens>
        </chunking>
        <chunking id="11" string="even helped by warm breezes and clear , 74-degree conditions" type="VP">
          <tokens>
            <token id="16" string="even" />
            <token id="17" string="helped" />
            <token id="18" string="by" />
            <token id="19" string="warm" />
            <token id="20" string="breezes" />
            <token id="21" string="and" />
            <token id="22" string="clear" />
            <token id="23" string="," />
            <token id="24" string="74-degree" />
            <token id="25" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="12" string="set records on the new North County course" type="VP">
          <tokens>
            <token id="3" string="set" />
            <token id="4" string="records" />
            <token id="5" string="on" />
            <token id="6" string="the" />
            <token id="7" string="new" />
            <token id="8" string="North" />
            <token id="9" string="County" />
            <token id="10" string="course" />
          </tokens>
        </chunking>
        <chunking id="13" string="warm breezes" type="NP">
          <tokens>
            <token id="19" string="warm" />
            <token id="20" string="breezes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">runs</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">set</governor>
          <dependent id="2">runs</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">set</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">set</governor>
          <dependent id="4">records</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">course</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">course</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">course</governor>
          <dependent id="7">new</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">course</governor>
          <dependent id="8">North</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">course</governor>
          <dependent id="9">County</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">records</governor>
          <dependent id="10">course</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">set</governor>
          <dependent id="12">but</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">times</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">blistering</governor>
          <dependent id="14">times</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">helped</governor>
          <dependent id="16">even</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">times</governor>
          <dependent id="17">helped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">breezes</governor>
          <dependent id="18">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">breezes</governor>
          <dependent id="19">warm</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">helped</governor>
          <dependent id="20">breezes</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">breezes</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">conditions</governor>
          <dependent id="22">clear</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">conditions</governor>
          <dependent id="24">74-degree</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">breezes</governor>
          <dependent id="25">conditions</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">blistering</governor>
          <dependent id="27">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">blistering</governor>
          <dependent id="28">hardly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">set</governor>
          <dependent id="29">blistering</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="North County" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="North" />
            <token id="9" string="County" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Martinez, 29, finished in 2 hours 19 minutes 3 seconds, 36 seconds faster than Doug Kurtis of Northville, Mich.</content>
      <tokens>
        <token id="1" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="29" lemma="29" stem="29" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="finished" lemma="finish" stem="finish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="8" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="9" string="19" lemma="19" stem="19" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="10" string="minutes" lemma="minute" stem="minut" pos="NNS" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="11" string="3" lemma="3" stem="3" pos="CD" type="Number" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="12" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="36" lemma="36" stem="36" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="15" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="16" string="faster" lemma="faster" stem="faster" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Doug" lemma="Doug" stem="doug" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="Kurtis" lemma="Kurtis" stem="kurti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Northville" lemma="Northville" stem="northvil" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="Mich" lemma="Mich." stem="mich" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Martinez)) (, ,) (NP (CD 29)) (, ,)) (VP (VBN finished) (PP (IN in) (NP (NP (CD 2) (NNS hours)) (NP (NP (CD 19) (NNS minutes)) (NP (CD 3) (NNS seconds)) (, ,) (ADVP (NP (CD 36) (NNS seconds)) (RBR faster))))) (PP (IN than) (NP (NP (NNP Doug) (NNP Kurtis)) (PP (IN of) (NP (NNP Northville) (, ,) (NNP Mich.)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="2 hours" type="NP">
          <tokens>
            <token id="7" string="2" />
            <token id="8" string="hours" />
          </tokens>
        </chunking>
        <chunking id="2" string="36 seconds" type="NP">
          <tokens>
            <token id="14" string="36" />
            <token id="15" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="3" string="2 hours 19 minutes 3 seconds , 36 seconds faster" type="NP">
          <tokens>
            <token id="7" string="2" />
            <token id="8" string="hours" />
            <token id="9" string="19" />
            <token id="10" string="minutes" />
            <token id="11" string="3" />
            <token id="12" string="seconds" />
            <token id="13" string="," />
            <token id="14" string="36" />
            <token id="15" string="seconds" />
            <token id="16" string="faster" />
          </tokens>
        </chunking>
        <chunking id="4" string="3 seconds" type="NP">
          <tokens>
            <token id="11" string="3" />
            <token id="12" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="5" string="29" type="NP">
          <tokens>
            <token id="3" string="29" />
          </tokens>
        </chunking>
        <chunking id="6" string="Northville , Mich." type="NP">
          <tokens>
            <token id="21" string="Northville" />
            <token id="22" string="," />
            <token id="23" string="Mich" />
          </tokens>
        </chunking>
        <chunking id="7" string="19 minutes" type="NP">
          <tokens>
            <token id="9" string="19" />
            <token id="10" string="minutes" />
          </tokens>
        </chunking>
        <chunking id="8" string="finished in 2 hours 19 minutes 3 seconds , 36 seconds faster than Doug Kurtis of Northville , Mich." type="VP">
          <tokens>
            <token id="5" string="finished" />
            <token id="6" string="in" />
            <token id="7" string="2" />
            <token id="8" string="hours" />
            <token id="9" string="19" />
            <token id="10" string="minutes" />
            <token id="11" string="3" />
            <token id="12" string="seconds" />
            <token id="13" string="," />
            <token id="14" string="36" />
            <token id="15" string="seconds" />
            <token id="16" string="faster" />
            <token id="17" string="than" />
            <token id="18" string="Doug" />
            <token id="19" string="Kurtis" />
            <token id="20" string="of" />
            <token id="21" string="Northville" />
            <token id="22" string="," />
            <token id="23" string="Mich" />
          </tokens>
        </chunking>
        <chunking id="9" string="Martinez , 29 ," type="NP">
          <tokens>
            <token id="1" string="Martinez" />
            <token id="2" string="," />
            <token id="3" string="29" />
            <token id="4" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="19 minutes 3 seconds , 36 seconds faster" type="NP">
          <tokens>
            <token id="9" string="19" />
            <token id="10" string="minutes" />
            <token id="11" string="3" />
            <token id="12" string="seconds" />
            <token id="13" string="," />
            <token id="14" string="36" />
            <token id="15" string="seconds" />
            <token id="16" string="faster" />
          </tokens>
        </chunking>
        <chunking id="11" string="Doug Kurtis of Northville , Mich." type="NP">
          <tokens>
            <token id="18" string="Doug" />
            <token id="19" string="Kurtis" />
            <token id="20" string="of" />
            <token id="21" string="Northville" />
            <token id="22" string="," />
            <token id="23" string="Mich" />
          </tokens>
        </chunking>
        <chunking id="12" string="Doug Kurtis" type="NP">
          <tokens>
            <token id="18" string="Doug" />
            <token id="19" string="Kurtis" />
          </tokens>
        </chunking>
        <chunking id="13" string="Martinez" type="NP">
          <tokens>
            <token id="1" string="Martinez" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">finished</governor>
          <dependent id="1">Martinez</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">Martinez</governor>
          <dependent id="3">29</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">finished</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">hours</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">hours</governor>
          <dependent id="7">2</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">finished</governor>
          <dependent id="8">hours</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">minutes</governor>
          <dependent id="9">19</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">hours</governor>
          <dependent id="10">minutes</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">seconds</governor>
          <dependent id="11">3</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">minutes</governor>
          <dependent id="12">seconds</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">seconds</governor>
          <dependent id="14">36</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="16">faster</governor>
          <dependent id="15">seconds</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">minutes</governor>
          <dependent id="16">faster</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Kurtis</governor>
          <dependent id="17">than</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Kurtis</governor>
          <dependent id="18">Doug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">finished</governor>
          <dependent id="19">Kurtis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Mich.</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Mich.</governor>
          <dependent id="21">Northville</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">Kurtis</governor>
          <dependent id="23">Mich.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Northville" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="21" string="Northville" />
          </tokens>
        </entity>
        <entity id="2" string="2 hours 19 minutes 3 seconds" type="TIME" score="0.0">
          <tokens>
            <token id="7" string="2" />
            <token id="8" string="hours" />
            <token id="9" string="19" />
            <token id="10" string="minutes" />
            <token id="11" string="3" />
            <token id="12" string="seconds" />
          </tokens>
        </entity>
        <entity id="3" string="36 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="36" />
            <token id="15" string="seconds" />
          </tokens>
        </entity>
        <entity id="4" string="Mich" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Mich" />
          </tokens>
        </entity>
        <entity id="5" string="29" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="29" />
          </tokens>
        </entity>
        <entity id="6" string="Doug Kurtis" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Doug" />
            <token id="19" string="Kurtis" />
          </tokens>
        </entity>
        <entity id="7" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Smith&amp;apost;s 2:43:05 seemed days quicker than the 2:52:12 posted by Escondido&amp;apost;s Mindy Ireland.</content>
      <tokens>
        <token id="1" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="2:43:05" lemma="2:43:05" stem="2:43:05" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="4" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="quicker" lemma="quicker" stem="quicker" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="2:52:12" lemma="2:52:12" stem="2:52:12" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="10" string="posted" lemma="post" stem="post" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Escondido" lemma="Escondido" stem="escondido" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="Mindy" lemma="Mindy" stem="mindi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Ireland" lemma="Ireland" stem="ireland" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Smith) (POS 's))) (NP (CD 2:43:05)) (VP (VBD seemed) (S (NP (NNS days)) (ADJP (JJR quicker) (PP (IN than) (NP (NP (DT the) (CD 2:52:12)) (VP (VBN posted) (PP (IN by) (NP (NP (NNP Escondido) (POS 's)) (NNP Mindy) (NNP Ireland))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Smith 's" type="NP">
          <tokens>
            <token id="1" string="Smith" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="2:43:05" type="NP">
          <tokens>
            <token id="3" string="2:43:05" />
          </tokens>
        </chunking>
        <chunking id="3" string="quicker than the 2:52:12 posted by Escondido 's Mindy Ireland" type="ADJP">
          <tokens>
            <token id="6" string="quicker" />
            <token id="7" string="than" />
            <token id="8" string="the" />
            <token id="9" string="2:52:12" />
            <token id="10" string="posted" />
            <token id="11" string="by" />
            <token id="12" string="Escondido" />
            <token id="13" string="'s" />
            <token id="14" string="Mindy" />
            <token id="15" string="Ireland" />
          </tokens>
        </chunking>
        <chunking id="4" string="Escondido 's Mindy Ireland" type="NP">
          <tokens>
            <token id="12" string="Escondido" />
            <token id="13" string="'s" />
            <token id="14" string="Mindy" />
            <token id="15" string="Ireland" />
          </tokens>
        </chunking>
        <chunking id="5" string="Escondido 's" type="NP">
          <tokens>
            <token id="12" string="Escondido" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="the 2:52:12 posted by Escondido 's Mindy Ireland" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="2:52:12" />
            <token id="10" string="posted" />
            <token id="11" string="by" />
            <token id="12" string="Escondido" />
            <token id="13" string="'s" />
            <token id="14" string="Mindy" />
            <token id="15" string="Ireland" />
          </tokens>
        </chunking>
        <chunking id="7" string="posted by Escondido 's Mindy Ireland" type="VP">
          <tokens>
            <token id="10" string="posted" />
            <token id="11" string="by" />
            <token id="12" string="Escondido" />
            <token id="13" string="'s" />
            <token id="14" string="Mindy" />
            <token id="15" string="Ireland" />
          </tokens>
        </chunking>
        <chunking id="8" string="days" type="NP">
          <tokens>
            <token id="5" string="days" />
          </tokens>
        </chunking>
        <chunking id="9" string="the 2:52:12" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="2:52:12" />
          </tokens>
        </chunking>
        <chunking id="10" string="seemed days quicker than the 2:52:12 posted by Escondido 's Mindy Ireland" type="VP">
          <tokens>
            <token id="4" string="seemed" />
            <token id="5" string="days" />
            <token id="6" string="quicker" />
            <token id="7" string="than" />
            <token id="8" string="the" />
            <token id="9" string="2:52:12" />
            <token id="10" string="posted" />
            <token id="11" string="by" />
            <token id="12" string="Escondido" />
            <token id="13" string="'s" />
            <token id="14" string="Mindy" />
            <token id="15" string="Ireland" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="4">seemed</governor>
          <dependent id="1">Smith</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Smith</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">seemed</governor>
          <dependent id="3">2:43:05</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">seemed</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">quicker</governor>
          <dependent id="5">days</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">seemed</governor>
          <dependent id="6">quicker</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">2:52:12</governor>
          <dependent id="7">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">2:52:12</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">quicker</governor>
          <dependent id="9">2:52:12</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">2:52:12</governor>
          <dependent id="10">posted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Ireland</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">Ireland</governor>
          <dependent id="12">Escondido</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Escondido</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Ireland</governor>
          <dependent id="14">Mindy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">posted</governor>
          <dependent id="15">Ireland</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2:43:05" type="TIME" score="0.0">
          <tokens>
            <token id="3" string="2:43:05" />
          </tokens>
        </entity>
        <entity id="2" string="Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Smith" />
          </tokens>
        </entity>
        <entity id="3" string="2:52:12" type="TIME" score="0.0">
          <tokens>
            <token id="9" string="2:52:12" />
          </tokens>
        </entity>
        <entity id="4" string="Mindy Ireland" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Mindy" />
            <token id="15" string="Ireland" />
          </tokens>
        </entity>
        <entity id="5" string="days" type="DURATION" score="0.0">
          <tokens>
            <token id="5" string="days" />
          </tokens>
        </entity>
        <entity id="6" string="Escondido" type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="Escondido" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>In years past, the marathon&amp;apost;s mystery often has been who the leader was, not how he got there.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="past" lemma="past" stem="past" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="mystery" lemma="mystery" stem="mysteri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (NNS years)) (ADJP (RB past)))) (, ,) (NP (NP (DT the) (NN marathon) (POS 's)) (NN mystery)) (ADVP (RB often)) (VP (VBZ has) (VP (VBN been) (SBAR (SBAR (WHNP (WP who)) (S (NP (DT the) (NN leader)) (VP (VBD was)))) (, ,) (RB not) (SBAR (WHADVP (WRB how)) (S (NP (PRP he)) (VP (VBD got) (ADVP (RB there)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has been who the leader was , not how he got there" type="VP">
          <tokens>
            <token id="10" string="has" />
            <token id="11" string="been" />
            <token id="12" string="who" />
            <token id="13" string="the" />
            <token id="14" string="leader" />
            <token id="15" string="was" />
            <token id="16" string="," />
            <token id="17" string="not" />
            <token id="18" string="how" />
            <token id="19" string="he" />
            <token id="20" string="got" />
            <token id="21" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="the marathon 's" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="marathon" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="how he got there" type="SBAR">
          <tokens>
            <token id="18" string="how" />
            <token id="19" string="he" />
            <token id="20" string="got" />
            <token id="21" string="there" />
          </tokens>
        </chunking>
        <chunking id="4" string="got there" type="VP">
          <tokens>
            <token id="20" string="got" />
            <token id="21" string="there" />
          </tokens>
        </chunking>
        <chunking id="5" string="past" type="ADJP">
          <tokens>
            <token id="3" string="past" />
          </tokens>
        </chunking>
        <chunking id="6" string="was" type="VP">
          <tokens>
            <token id="15" string="was" />
          </tokens>
        </chunking>
        <chunking id="7" string="years" type="NP">
          <tokens>
            <token id="2" string="years" />
          </tokens>
        </chunking>
        <chunking id="8" string="who the leader was , not how he got there" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="the" />
            <token id="14" string="leader" />
            <token id="15" string="was" />
            <token id="16" string="," />
            <token id="17" string="not" />
            <token id="18" string="how" />
            <token id="19" string="he" />
            <token id="20" string="got" />
            <token id="21" string="there" />
          </tokens>
        </chunking>
        <chunking id="9" string="the leader" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="leader" />
          </tokens>
        </chunking>
        <chunking id="10" string="how" type="WHADVP">
          <tokens>
            <token id="18" string="how" />
          </tokens>
        </chunking>
        <chunking id="11" string="who the leader was" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="the" />
            <token id="14" string="leader" />
            <token id="15" string="was" />
          </tokens>
        </chunking>
        <chunking id="12" string="been who the leader was , not how he got there" type="VP">
          <tokens>
            <token id="11" string="been" />
            <token id="12" string="who" />
            <token id="13" string="the" />
            <token id="14" string="leader" />
            <token id="15" string="was" />
            <token id="16" string="," />
            <token id="17" string="not" />
            <token id="18" string="how" />
            <token id="19" string="he" />
            <token id="20" string="got" />
            <token id="21" string="there" />
          </tokens>
        </chunking>
        <chunking id="13" string="years past" type="NP">
          <tokens>
            <token id="2" string="years" />
            <token id="3" string="past" />
          </tokens>
        </chunking>
        <chunking id="14" string="the marathon 's mystery" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="marathon" />
            <token id="7" string="'s" />
            <token id="8" string="mystery" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">years</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">been</governor>
          <dependent id="2">years</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="2">years</governor>
          <dependent id="3">past</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">marathon</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">mystery</governor>
          <dependent id="6">marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">marathon</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">been</governor>
          <dependent id="8">mystery</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">been</governor>
          <dependent id="9">often</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">been</governor>
          <dependent id="10">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">been</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">was</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">leader</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">was</governor>
          <dependent id="14">leader</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">been</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="20">got</governor>
          <dependent id="17">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">got</governor>
          <dependent id="18">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">got</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">was</governor>
          <dependent id="20">got</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">got</governor>
          <dependent id="21">there</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="past" />
          </tokens>
        </entity>
        <entity id="2" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="2" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Runners, often from Mexico, would register late, and race officials were at their wits end when the media screamed to know the identity of the leader.</content>
      <tokens>
        <token id="1" string="Runners" lemma="runner" stem="runner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="often" lemma="often" stem="often" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Mexico" lemma="Mexico" stem="mexico" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="register" lemma="register" stem="regist" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="late" lemma="late" stem="late" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="wits" lemma="wit" stem="wit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="end" lemma="end" stem="end" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="screamed" lemma="scream" stem="scream" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="identity" lemma="identity" stem="ident" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="leader" lemma="leader" stem="leader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Runners)) (PRN (, ,) (ADVP (RB often)) (PP (IN from) (NP (NNP Mexico))) (, ,)) (VP (MD would) (VP (VB register) (ADVP (RB late))))) (, ,) (CC and) (S (NP (NN race) (NNS officials)) (VP (VBD were) (PP (IN at) (NP (PRP$ their) (NNS wits) (S (VP (VB end) (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NNS media)) (VP (VBD screamed) (S (VP (TO to) (VP (VB know) (NP (NP (DT the) (NN identity)) (PP (IN of) (NP (DT the) (NN leader)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were at their wits end when the media screamed to know the identity of the leader" type="VP">
          <tokens>
            <token id="14" string="were" />
            <token id="15" string="at" />
            <token id="16" string="their" />
            <token id="17" string="wits" />
            <token id="18" string="end" />
            <token id="19" string="when" />
            <token id="20" string="the" />
            <token id="21" string="media" />
            <token id="22" string="screamed" />
            <token id="23" string="to" />
            <token id="24" string="know" />
            <token id="25" string="the" />
            <token id="26" string="identity" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="leader" />
          </tokens>
        </chunking>
        <chunking id="2" string="Runners" type="NP">
          <tokens>
            <token id="1" string="Runners" />
          </tokens>
        </chunking>
        <chunking id="3" string="the identity of the leader" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="identity" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="leader" />
          </tokens>
        </chunking>
        <chunking id="4" string="the media" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="media" />
          </tokens>
        </chunking>
        <chunking id="5" string="end when the media screamed to know the identity of the leader" type="VP">
          <tokens>
            <token id="18" string="end" />
            <token id="19" string="when" />
            <token id="20" string="the" />
            <token id="21" string="media" />
            <token id="22" string="screamed" />
            <token id="23" string="to" />
            <token id="24" string="know" />
            <token id="25" string="the" />
            <token id="26" string="identity" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="leader" />
          </tokens>
        </chunking>
        <chunking id="6" string="screamed to know the identity of the leader" type="VP">
          <tokens>
            <token id="22" string="screamed" />
            <token id="23" string="to" />
            <token id="24" string="know" />
            <token id="25" string="the" />
            <token id="26" string="identity" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="leader" />
          </tokens>
        </chunking>
        <chunking id="7" string="would register late" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="register" />
            <token id="9" string="late" />
          </tokens>
        </chunking>
        <chunking id="8" string="race officials" type="NP">
          <tokens>
            <token id="12" string="race" />
            <token id="13" string="officials" />
          </tokens>
        </chunking>
        <chunking id="9" string="the leader" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="leader" />
          </tokens>
        </chunking>
        <chunking id="10" string="register late" type="VP">
          <tokens>
            <token id="8" string="register" />
            <token id="9" string="late" />
          </tokens>
        </chunking>
        <chunking id="11" string="when" type="WHADVP">
          <tokens>
            <token id="19" string="when" />
          </tokens>
        </chunking>
        <chunking id="12" string="to know the identity of the leader" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="know" />
            <token id="25" string="the" />
            <token id="26" string="identity" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="leader" />
          </tokens>
        </chunking>
        <chunking id="13" string="know the identity of the leader" type="VP">
          <tokens>
            <token id="24" string="know" />
            <token id="25" string="the" />
            <token id="26" string="identity" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="leader" />
          </tokens>
        </chunking>
        <chunking id="14" string="Mexico" type="NP">
          <tokens>
            <token id="5" string="Mexico" />
          </tokens>
        </chunking>
        <chunking id="15" string="their wits end when the media screamed to know the identity of the leader" type="NP">
          <tokens>
            <token id="16" string="their" />
            <token id="17" string="wits" />
            <token id="18" string="end" />
            <token id="19" string="when" />
            <token id="20" string="the" />
            <token id="21" string="media" />
            <token id="22" string="screamed" />
            <token id="23" string="to" />
            <token id="24" string="know" />
            <token id="25" string="the" />
            <token id="26" string="identity" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="leader" />
          </tokens>
        </chunking>
        <chunking id="16" string="when the media screamed to know the identity of the leader" type="SBAR">
          <tokens>
            <token id="19" string="when" />
            <token id="20" string="the" />
            <token id="21" string="media" />
            <token id="22" string="screamed" />
            <token id="23" string="to" />
            <token id="24" string="know" />
            <token id="25" string="the" />
            <token id="26" string="identity" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="leader" />
          </tokens>
        </chunking>
        <chunking id="17" string="the identity" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="identity" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">register</governor>
          <dependent id="1">Runners</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">Mexico</governor>
          <dependent id="3">often</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Mexico</governor>
          <dependent id="4">from</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">register</governor>
          <dependent id="5">Mexico</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">register</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">register</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">register</governor>
          <dependent id="9">late</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">register</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">officials</governor>
          <dependent id="12">race</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">wits</governor>
          <dependent id="13">officials</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">wits</governor>
          <dependent id="14">were</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">wits</governor>
          <dependent id="15">at</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">wits</governor>
          <dependent id="16">their</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">register</governor>
          <dependent id="17">wits</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">wits</governor>
          <dependent id="18">end</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">screamed</governor>
          <dependent id="19">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">media</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">screamed</governor>
          <dependent id="21">media</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">end</governor>
          <dependent id="22">screamed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">know</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">screamed</governor>
          <dependent id="24">know</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">identity</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">know</governor>
          <dependent id="26">identity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">leader</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">leader</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">identity</governor>
          <dependent id="29">leader</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mexico" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Mexico" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>This year, officials made sure there were no mystery men out on the course.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="mystery" lemma="mystery" stem="mysteri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (DT This) (NN year)) (, ,) (NP (NNS officials)) (VP (VBD made) (ADJP (JJ sure) (SBAR (S (NP (EX there)) (VP (VBD were) (NP (DT no) (NN mystery) (NNS men)) (ADVP (RP out) (PP (IN on) (NP (DT the) (NN course))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="7" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="no mystery men" type="NP">
          <tokens>
            <token id="9" string="no" />
            <token id="10" string="mystery" />
            <token id="11" string="men" />
          </tokens>
        </chunking>
        <chunking id="3" string="made sure there were no mystery men out on the course" type="VP">
          <tokens>
            <token id="5" string="made" />
            <token id="6" string="sure" />
            <token id="7" string="there" />
            <token id="8" string="were" />
            <token id="9" string="no" />
            <token id="10" string="mystery" />
            <token id="11" string="men" />
            <token id="12" string="out" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="course" />
          </tokens>
        </chunking>
        <chunking id="4" string="were no mystery men out on the course" type="VP">
          <tokens>
            <token id="8" string="were" />
            <token id="9" string="no" />
            <token id="10" string="mystery" />
            <token id="11" string="men" />
            <token id="12" string="out" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="course" />
          </tokens>
        </chunking>
        <chunking id="5" string="officials" type="NP">
          <tokens>
            <token id="4" string="officials" />
          </tokens>
        </chunking>
        <chunking id="6" string="there were no mystery men out on the course" type="SBAR">
          <tokens>
            <token id="7" string="there" />
            <token id="8" string="were" />
            <token id="9" string="no" />
            <token id="10" string="mystery" />
            <token id="11" string="men" />
            <token id="12" string="out" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="course" />
          </tokens>
        </chunking>
        <chunking id="7" string="the course" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="course" />
          </tokens>
        </chunking>
        <chunking id="8" string="sure there were no mystery men out on the course" type="ADJP">
          <tokens>
            <token id="6" string="sure" />
            <token id="7" string="there" />
            <token id="8" string="were" />
            <token id="9" string="no" />
            <token id="10" string="mystery" />
            <token id="11" string="men" />
            <token id="12" string="out" />
            <token id="13" string="on" />
            <token id="14" string="the" />
            <token id="15" string="course" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">year</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">made</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">made</governor>
          <dependent id="4">officials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">made</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">made</governor>
          <dependent id="6">sure</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="8">were</governor>
          <dependent id="7">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">sure</governor>
          <dependent id="8">were</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">men</governor>
          <dependent id="9">no</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">men</governor>
          <dependent id="10">mystery</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">were</governor>
          <dependent id="11">men</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">were</governor>
          <dependent id="12">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">course</governor>
          <dependent id="13">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">course</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">out</governor>
          <dependent id="15">course</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="This year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>They knew who Martinez was, but no one was sure how he was able to practically appear out of nowhere to take the lead from Alfredo Rosas of San Pedro going into the 25-mile mark.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="sure" lemma="sure" stem="sure" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="practically" lemma="practically" stem="practic" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="appear" lemma="appear" stem="appear" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="nowhere" lemma="nowhere" stem="nowher" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="lead" lemma="lead" stem="lead" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Alfredo" lemma="Alfredo" stem="alfredo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="28" string="Rosas" lemma="Rosas" stem="rosa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="31" string="Pedro" lemma="Pedro" stem="pedro" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="32" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="25-mile" lemma="25-mile" stem="25-mile" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="mark" lemma="mark" stem="mark" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP They)) (VP (VBD knew) (SBAR (WHNP (WP who)) (S (NP (NNP Martinez)) (VP (VBD was)))))) (, ,) (CC but) (S (NP (DT no) (NN one)) (VP (VBD was) (ADJP (JJ sure)) (SBAR (WHADVP (WRB how)) (S (NP (PRP he)) (VP (VBD was) (ADJP (JJ able) (S (VP (TO to) (VP (ADVP (RB practically)) (VB appear) (ADVP (IN out) (PP (IN of) (NP (RB nowhere)))) (S (VP (TO to) (VP (VB take) (NP (DT the) (NN lead)) (PP (IN from) (NP (NP (NNP Alfredo) (NNP Rosas)) (PP (IN of) (NP (NP (NNP San) (NNP Pedro)) (VP (VBG going) (PP (IN into) (NP (DT the) (JJ 25-mile) (NN mark)))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="going into the 25-mile mark" type="VP">
          <tokens>
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="3" string="sure" type="ADJP">
          <tokens>
            <token id="11" string="sure" />
          </tokens>
        </chunking>
        <chunking id="4" string="practically appear out of nowhere to take the lead from Alfredo Rosas of San Pedro going into the 25-mile mark" type="VP">
          <tokens>
            <token id="17" string="practically" />
            <token id="18" string="appear" />
            <token id="19" string="out" />
            <token id="20" string="of" />
            <token id="21" string="nowhere" />
            <token id="22" string="to" />
            <token id="23" string="take" />
            <token id="24" string="the" />
            <token id="25" string="lead" />
            <token id="26" string="from" />
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
            <token id="29" string="of" />
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="5" string="Alfredo Rosas" type="NP">
          <tokens>
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
          </tokens>
        </chunking>
        <chunking id="6" string="to take the lead from Alfredo Rosas of San Pedro going into the 25-mile mark" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="take" />
            <token id="24" string="the" />
            <token id="25" string="lead" />
            <token id="26" string="from" />
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
            <token id="29" string="of" />
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="7" string="no one" type="NP">
          <tokens>
            <token id="8" string="no" />
            <token id="9" string="one" />
          </tokens>
        </chunking>
        <chunking id="8" string="was" type="VP">
          <tokens>
            <token id="5" string="was" />
          </tokens>
        </chunking>
        <chunking id="9" string="San Pedro" type="NP">
          <tokens>
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
          </tokens>
        </chunking>
        <chunking id="10" string="take the lead from Alfredo Rosas of San Pedro going into the 25-mile mark" type="VP">
          <tokens>
            <token id="23" string="take" />
            <token id="24" string="the" />
            <token id="25" string="lead" />
            <token id="26" string="from" />
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
            <token id="29" string="of" />
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="11" string="the lead" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="lead" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="the 25-mile mark" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="14" string="San Pedro going into the 25-mile mark" type="NP">
          <tokens>
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="15" string="able to practically appear out of nowhere to take the lead from Alfredo Rosas of San Pedro going into the 25-mile mark" type="ADJP">
          <tokens>
            <token id="15" string="able" />
            <token id="16" string="to" />
            <token id="17" string="practically" />
            <token id="18" string="appear" />
            <token id="19" string="out" />
            <token id="20" string="of" />
            <token id="21" string="nowhere" />
            <token id="22" string="to" />
            <token id="23" string="take" />
            <token id="24" string="the" />
            <token id="25" string="lead" />
            <token id="26" string="from" />
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
            <token id="29" string="of" />
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="16" string="was sure how he was able to practically appear out of nowhere to take the lead from Alfredo Rosas of San Pedro going into the 25-mile mark" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="sure" />
            <token id="12" string="how" />
            <token id="13" string="he" />
            <token id="14" string="was" />
            <token id="15" string="able" />
            <token id="16" string="to" />
            <token id="17" string="practically" />
            <token id="18" string="appear" />
            <token id="19" string="out" />
            <token id="20" string="of" />
            <token id="21" string="nowhere" />
            <token id="22" string="to" />
            <token id="23" string="take" />
            <token id="24" string="the" />
            <token id="25" string="lead" />
            <token id="26" string="from" />
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
            <token id="29" string="of" />
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="17" string="who Martinez was" type="SBAR">
          <tokens>
            <token id="3" string="who" />
            <token id="4" string="Martinez" />
            <token id="5" string="was" />
          </tokens>
        </chunking>
        <chunking id="18" string="was able to practically appear out of nowhere to take the lead from Alfredo Rosas of San Pedro going into the 25-mile mark" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="able" />
            <token id="16" string="to" />
            <token id="17" string="practically" />
            <token id="18" string="appear" />
            <token id="19" string="out" />
            <token id="20" string="of" />
            <token id="21" string="nowhere" />
            <token id="22" string="to" />
            <token id="23" string="take" />
            <token id="24" string="the" />
            <token id="25" string="lead" />
            <token id="26" string="from" />
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
            <token id="29" string="of" />
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="19" string="how" type="WHADVP">
          <tokens>
            <token id="12" string="how" />
          </tokens>
        </chunking>
        <chunking id="20" string="Alfredo Rosas of San Pedro going into the 25-mile mark" type="NP">
          <tokens>
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
            <token id="29" string="of" />
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="21" string="how he was able to practically appear out of nowhere to take the lead from Alfredo Rosas of San Pedro going into the 25-mile mark" type="SBAR">
          <tokens>
            <token id="12" string="how" />
            <token id="13" string="he" />
            <token id="14" string="was" />
            <token id="15" string="able" />
            <token id="16" string="to" />
            <token id="17" string="practically" />
            <token id="18" string="appear" />
            <token id="19" string="out" />
            <token id="20" string="of" />
            <token id="21" string="nowhere" />
            <token id="22" string="to" />
            <token id="23" string="take" />
            <token id="24" string="the" />
            <token id="25" string="lead" />
            <token id="26" string="from" />
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
            <token id="29" string="of" />
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
        <chunking id="22" string="nowhere" type="NP">
          <tokens>
            <token id="21" string="nowhere" />
          </tokens>
        </chunking>
        <chunking id="23" string="knew who Martinez was" type="VP">
          <tokens>
            <token id="2" string="knew" />
            <token id="3" string="who" />
            <token id="4" string="Martinez" />
            <token id="5" string="was" />
          </tokens>
        </chunking>
        <chunking id="24" string="Martinez" type="NP">
          <tokens>
            <token id="4" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="25" string="to practically appear out of nowhere to take the lead from Alfredo Rosas of San Pedro going into the 25-mile mark" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="practically" />
            <token id="18" string="appear" />
            <token id="19" string="out" />
            <token id="20" string="of" />
            <token id="21" string="nowhere" />
            <token id="22" string="to" />
            <token id="23" string="take" />
            <token id="24" string="the" />
            <token id="25" string="lead" />
            <token id="26" string="from" />
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
            <token id="29" string="of" />
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
            <token id="32" string="going" />
            <token id="33" string="into" />
            <token id="34" string="the" />
            <token id="35" string="25-mile" />
            <token id="36" string="mark" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">knew</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">knew</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">was</governor>
          <dependent id="3">who</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">was</governor>
          <dependent id="4">Martinez</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">knew</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">knew</governor>
          <dependent id="7">but</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">one</governor>
          <dependent id="8">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">sure</governor>
          <dependent id="9">one</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">sure</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">knew</governor>
          <dependent id="11">sure</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">able</governor>
          <dependent id="12">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">able</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">able</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">sure</governor>
          <dependent id="15">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">appear</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">appear</governor>
          <dependent id="17">practically</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">able</governor>
          <dependent id="18">appear</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">nowhere</governor>
          <dependent id="19">out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="19">out</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">appear</governor>
          <dependent id="21">nowhere</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">take</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">appear</governor>
          <dependent id="23">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">lead</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">take</governor>
          <dependent id="25">lead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Rosas</governor>
          <dependent id="26">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Rosas</governor>
          <dependent id="27">Alfredo</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">take</governor>
          <dependent id="28">Rosas</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Pedro</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Pedro</governor>
          <dependent id="30">San</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">Rosas</governor>
          <dependent id="31">Pedro</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="31">Pedro</governor>
          <dependent id="32">going</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">mark</governor>
          <dependent id="33">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">mark</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">mark</governor>
          <dependent id="35">25-mile</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">going</governor>
          <dependent id="36">mark</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Alfredo Rosas" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Alfredo" />
            <token id="28" string="Rosas" />
          </tokens>
        </entity>
        <entity id="3" string="San Pedro" type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="San" />
            <token id="31" string="Pedro" />
          </tokens>
        </entity>
        <entity id="4" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>What Martinez did, was start out slow and deliberate.</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="start" lemma="start" stem="start" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="slow" lemma="slow" stem="slow" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="deliberate" lemma="deliberate" stem="deliber" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHNP (WDT What)) (S (NP (NNP Martinez)) (VP (VP (VBD did)) (, ,) (VP (VBD was))))) (VP (VB start) (ADVP (RP out) (ADJP (JJ slow) (CC and) (JJ deliberate)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="start out slow and deliberate" type="VP">
          <tokens>
            <token id="6" string="start" />
            <token id="7" string="out" />
            <token id="8" string="slow" />
            <token id="9" string="and" />
            <token id="10" string="deliberate" />
          </tokens>
        </chunking>
        <chunking id="2" string="What Martinez did , was" type="SBAR">
          <tokens>
            <token id="1" string="What" />
            <token id="2" string="Martinez" />
            <token id="3" string="did" />
            <token id="4" string="," />
            <token id="5" string="was" />
          </tokens>
        </chunking>
        <chunking id="3" string="was" type="VP">
          <tokens>
            <token id="5" string="was" />
          </tokens>
        </chunking>
        <chunking id="4" string="Martinez" type="NP">
          <tokens>
            <token id="2" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="5" string="slow and deliberate" type="ADJP">
          <tokens>
            <token id="8" string="slow" />
            <token id="9" string="and" />
            <token id="10" string="deliberate" />
          </tokens>
        </chunking>
        <chunking id="6" string="did , was" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="," />
            <token id="5" string="was" />
          </tokens>
        </chunking>
        <chunking id="7" string="did" type="VP">
          <tokens>
            <token id="3" string="did" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dobj">
          <governor id="3">did</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">did</governor>
          <dependent id="2">Martinez</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="6">start</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">did</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">start</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">slow</governor>
          <dependent id="7">out</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">start</governor>
          <dependent id="8">slow</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">slow</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">slow</governor>
          <dependent id="10">deliberate</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Through an interpreter, Martinez said he started out running 5:15 or 5:20 miles.</content>
      <tokens>
        <token id="1" string="Through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="interpreter" lemma="interpreter" stem="interpret" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="5:15" lemma="5:15" stem="5:15" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="12" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="5:20" lemma="5:20" stem="5:20" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="14" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Through) (NP (DT an) (NN interpreter))) (, ,) (NP (NNP Martinez)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD started) (PRT (RP out)) (S (VP (VBG running) (NP (QP (CD 5:15) (CC or) (CD 5:20)) (NNS miles)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he started out running 5:15 or 5:20 miles" type="SBAR">
          <tokens>
            <token id="7" string="he" />
            <token id="8" string="started" />
            <token id="9" string="out" />
            <token id="10" string="running" />
            <token id="11" string="5:15" />
            <token id="12" string="or" />
            <token id="13" string="5:20" />
            <token id="14" string="miles" />
          </tokens>
        </chunking>
        <chunking id="2" string="started out running 5:15 or 5:20 miles" type="VP">
          <tokens>
            <token id="8" string="started" />
            <token id="9" string="out" />
            <token id="10" string="running" />
            <token id="11" string="5:15" />
            <token id="12" string="or" />
            <token id="13" string="5:20" />
            <token id="14" string="miles" />
          </tokens>
        </chunking>
        <chunking id="3" string="running 5:15 or 5:20 miles" type="VP">
          <tokens>
            <token id="10" string="running" />
            <token id="11" string="5:15" />
            <token id="12" string="or" />
            <token id="13" string="5:20" />
            <token id="14" string="miles" />
          </tokens>
        </chunking>
        <chunking id="4" string="Martinez" type="NP">
          <tokens>
            <token id="5" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="an interpreter" type="NP">
          <tokens>
            <token id="2" string="an" />
            <token id="3" string="interpreter" />
          </tokens>
        </chunking>
        <chunking id="7" string="5:15 or 5:20 miles" type="NP">
          <tokens>
            <token id="11" string="5:15" />
            <token id="12" string="or" />
            <token id="13" string="5:20" />
            <token id="14" string="miles" />
          </tokens>
        </chunking>
        <chunking id="8" string="said he started out running 5:15 or 5:20 miles" type="VP">
          <tokens>
            <token id="6" string="said" />
            <token id="7" string="he" />
            <token id="8" string="started" />
            <token id="9" string="out" />
            <token id="10" string="running" />
            <token id="11" string="5:15" />
            <token id="12" string="or" />
            <token id="13" string="5:20" />
            <token id="14" string="miles" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">interpreter</governor>
          <dependent id="1">Through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">interpreter</governor>
          <dependent id="2">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">said</governor>
          <dependent id="3">interpreter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="5">Martinez</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">started</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">said</governor>
          <dependent id="8">started</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">started</governor>
          <dependent id="9">out</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">started</governor>
          <dependent id="10">running</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">miles</governor>
          <dependent id="11">5:15</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">5:15</governor>
          <dependent id="12">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">5:15</governor>
          <dependent id="13">5:20</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">running</governor>
          <dependent id="14">miles</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="5:15" type="TIME" score="0.0">
          <tokens>
            <token id="11" string="5:15" />
          </tokens>
        </entity>
        <entity id="2" string="5:20" type="TIME" score="0.0">
          <tokens>
            <token id="13" string="5:20" />
          </tokens>
        </entity>
        <entity id="3" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Rosas and a pack of as many as eight came out at a pace seven to 10 seconds quicker per mile.</content>
      <tokens>
        <token id="1" string="Rosas" lemma="Rosas" stem="rosa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="pack" lemma="pack" stem="pack" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="10" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="pace" lemma="pace" stem="pace" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="17" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="18" string="seconds" lemma="seconds" stem="second" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="19" string="quicker" lemma="quicker" stem="quicker" pos="JJR" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="per" lemma="per" stem="per" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="mile" lemma="mile" stem="mile" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Rosas)) (CC and) (NP (NP (DT a) (NN pack)) (PP (IN of) (NP (QP (RB as) (JJ many) (IN as) (CD eight)))))) (VP (VBD came) (PRT (RP out)) (PP (IN at) (NP (NP (DT a) (NN pace)) (ADJP (NP (QP (CD seven) (TO to) (CD 10)) (NNS seconds)) (JJR quicker)) (PP (IN per) (NP (NN mile)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Rosas" type="NP">
          <tokens>
            <token id="1" string="Rosas" />
          </tokens>
        </chunking>
        <chunking id="2" string="a pack of as many as eight" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="pack" />
            <token id="5" string="of" />
            <token id="6" string="as" />
            <token id="7" string="many" />
            <token id="8" string="as" />
            <token id="9" string="eight" />
          </tokens>
        </chunking>
        <chunking id="3" string="a pace seven to 10 seconds quicker per mile" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="pace" />
            <token id="15" string="seven" />
            <token id="16" string="to" />
            <token id="17" string="10" />
            <token id="18" string="seconds" />
            <token id="19" string="quicker" />
            <token id="20" string="per" />
            <token id="21" string="mile" />
          </tokens>
        </chunking>
        <chunking id="4" string="Rosas and a pack of as many as eight" type="NP">
          <tokens>
            <token id="1" string="Rosas" />
            <token id="2" string="and" />
            <token id="3" string="a" />
            <token id="4" string="pack" />
            <token id="5" string="of" />
            <token id="6" string="as" />
            <token id="7" string="many" />
            <token id="8" string="as" />
            <token id="9" string="eight" />
          </tokens>
        </chunking>
        <chunking id="5" string="mile" type="NP">
          <tokens>
            <token id="21" string="mile" />
          </tokens>
        </chunking>
        <chunking id="6" string="as many as eight" type="NP">
          <tokens>
            <token id="6" string="as" />
            <token id="7" string="many" />
            <token id="8" string="as" />
            <token id="9" string="eight" />
          </tokens>
        </chunking>
        <chunking id="7" string="a pack" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="pack" />
          </tokens>
        </chunking>
        <chunking id="8" string="seven to 10 seconds quicker" type="ADJP">
          <tokens>
            <token id="15" string="seven" />
            <token id="16" string="to" />
            <token id="17" string="10" />
            <token id="18" string="seconds" />
            <token id="19" string="quicker" />
          </tokens>
        </chunking>
        <chunking id="9" string="seven to 10 seconds" type="NP">
          <tokens>
            <token id="15" string="seven" />
            <token id="16" string="to" />
            <token id="17" string="10" />
            <token id="18" string="seconds" />
          </tokens>
        </chunking>
        <chunking id="10" string="a pace" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="pace" />
          </tokens>
        </chunking>
        <chunking id="11" string="came out at a pace seven to 10 seconds quicker per mile" type="VP">
          <tokens>
            <token id="10" string="came" />
            <token id="11" string="out" />
            <token id="12" string="at" />
            <token id="13" string="a" />
            <token id="14" string="pace" />
            <token id="15" string="seven" />
            <token id="16" string="to" />
            <token id="17" string="10" />
            <token id="18" string="seconds" />
            <token id="19" string="quicker" />
            <token id="20" string="per" />
            <token id="21" string="mile" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="10">came</governor>
          <dependent id="1">Rosas</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Rosas</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">pack</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Rosas</governor>
          <dependent id="4">pack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">eight</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">eight</governor>
          <dependent id="6">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">eight</governor>
          <dependent id="7">many</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">eight</governor>
          <dependent id="8">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">pack</governor>
          <dependent id="9">eight</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">came</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="10">came</governor>
          <dependent id="11">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">pace</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">pace</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">came</governor>
          <dependent id="14">pace</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">10</governor>
          <dependent id="15">seven</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">10</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">seconds</governor>
          <dependent id="17">10</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="19">quicker</governor>
          <dependent id="18">seconds</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">pace</governor>
          <dependent id="19">quicker</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">mile</governor>
          <dependent id="20">per</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">pace</governor>
          <dependent id="21">mile</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rosas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Rosas" />
          </tokens>
        </entity>
        <entity id="2" string="seven to 10 seconds" type="DURATION" score="0.0">
          <tokens>
            <token id="15" string="seven" />
            <token id="16" string="to" />
            <token id="17" string="10" />
            <token id="18" string="seconds" />
          </tokens>
        </entity>
        <entity id="3" string="eight" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="eight" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>&amp;quot;I knew it would kill them, that they would never keep it up,&amp;quot; said Martinez, who won with a 5:18-mile pace.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="kill" lemma="kill" stem="kill" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="keep" lemma="keep" stem="keep" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="5:18" lemma="5:18" stem="5:18" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="true" />
        <token id="26" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="mile" lemma="mile" stem="mile" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="pace" lemma="pace" stem="pace" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (VBD knew) (SBAR (S (NP (PRP it)) (VP (MD would) (VP (VB kill) (NP (PRP them)) (, ,) (SBAR (IN that) (S (NP (PRP they)) (VP (MD would) (ADVP (RB never)) (VP (VB keep) (NP (PRP it)) (PRT (RP up)))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NP (NNP Martinez)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD won) (PP (IN with) (NP (DT a) (CD 5:18))))))) (: -) (NP (NN mile) (NN pace))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who won with a 5:18" type="SBAR">
          <tokens>
            <token id="21" string="who" />
            <token id="22" string="won" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="5:18" />
          </tokens>
        </chunking>
        <chunking id="2" string="knew it would kill them , that they would never keep it up" type="VP">
          <tokens>
            <token id="3" string="knew" />
            <token id="4" string="it" />
            <token id="5" string="would" />
            <token id="6" string="kill" />
            <token id="7" string="them" />
            <token id="8" string="," />
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="would" />
            <token id="12" string="never" />
            <token id="13" string="keep" />
            <token id="14" string="it" />
            <token id="15" string="up" />
          </tokens>
        </chunking>
        <chunking id="3" string="won with a 5:18" type="VP">
          <tokens>
            <token id="22" string="won" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="5:18" />
          </tokens>
        </chunking>
        <chunking id="4" string="that they would never keep it up" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="would" />
            <token id="12" string="never" />
            <token id="13" string="keep" />
            <token id="14" string="it" />
            <token id="15" string="up" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="Martinez , who won with a 5:18" type="NP">
          <tokens>
            <token id="19" string="Martinez" />
            <token id="20" string="," />
            <token id="21" string="who" />
            <token id="22" string="won" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="5:18" />
          </tokens>
        </chunking>
        <chunking id="8" string="a 5:18" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="5:18" />
          </tokens>
        </chunking>
        <chunking id="9" string="them" type="NP">
          <tokens>
            <token id="7" string="them" />
          </tokens>
        </chunking>
        <chunking id="10" string="mile pace" type="NP">
          <tokens>
            <token id="27" string="mile" />
            <token id="28" string="pace" />
          </tokens>
        </chunking>
        <chunking id="11" string="kill them , that they would never keep it up" type="VP">
          <tokens>
            <token id="6" string="kill" />
            <token id="7" string="them" />
            <token id="8" string="," />
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="would" />
            <token id="12" string="never" />
            <token id="13" string="keep" />
            <token id="14" string="it" />
            <token id="15" string="up" />
          </tokens>
        </chunking>
        <chunking id="12" string="keep it up" type="VP">
          <tokens>
            <token id="13" string="keep" />
            <token id="14" string="it" />
            <token id="15" string="up" />
          </tokens>
        </chunking>
        <chunking id="13" string="would kill them , that they would never keep it up" type="VP">
          <tokens>
            <token id="5" string="would" />
            <token id="6" string="kill" />
            <token id="7" string="them" />
            <token id="8" string="," />
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="would" />
            <token id="12" string="never" />
            <token id="13" string="keep" />
            <token id="14" string="it" />
            <token id="15" string="up" />
          </tokens>
        </chunking>
        <chunking id="14" string="it would kill them , that they would never keep it up" type="SBAR">
          <tokens>
            <token id="4" string="it" />
            <token id="5" string="would" />
            <token id="6" string="kill" />
            <token id="7" string="them" />
            <token id="8" string="," />
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="would" />
            <token id="12" string="never" />
            <token id="13" string="keep" />
            <token id="14" string="it" />
            <token id="15" string="up" />
          </tokens>
        </chunking>
        <chunking id="15" string="would never keep it up" type="VP">
          <tokens>
            <token id="11" string="would" />
            <token id="12" string="never" />
            <token id="13" string="keep" />
            <token id="14" string="it" />
            <token id="15" string="up" />
          </tokens>
        </chunking>
        <chunking id="16" string="they" type="NP">
          <tokens>
            <token id="10" string="they" />
          </tokens>
        </chunking>
        <chunking id="17" string="Martinez , who won with a 5:18 - mile pace" type="NP">
          <tokens>
            <token id="19" string="Martinez" />
            <token id="20" string="," />
            <token id="21" string="who" />
            <token id="22" string="won" />
            <token id="23" string="with" />
            <token id="24" string="a" />
            <token id="25" string="5:18" />
            <token id="26" string="-" />
            <token id="27" string="mile" />
            <token id="28" string="pace" />
          </tokens>
        </chunking>
        <chunking id="18" string="Martinez" type="NP">
          <tokens>
            <token id="19" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="19" string="said" type="VP">
          <tokens>
            <token id="18" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">knew</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="3">knew</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">kill</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">kill</governor>
          <dependent id="5">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">knew</governor>
          <dependent id="6">kill</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">kill</governor>
          <dependent id="7">them</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">keep</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">keep</governor>
          <dependent id="10">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">keep</governor>
          <dependent id="11">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">keep</governor>
          <dependent id="12">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">kill</governor>
          <dependent id="13">keep</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">keep</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="13">keep</governor>
          <dependent id="15">up</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="19">Martinez</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">won</governor>
          <dependent id="21">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="19">Martinez</governor>
          <dependent id="22">won</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">5:18</governor>
          <dependent id="23">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">5:18</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">won</governor>
          <dependent id="25">5:18</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">pace</governor>
          <dependent id="27">mile</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">Martinez</governor>
          <dependent id="28">pace</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="5:18" type="TIME" score="0.0">
          <tokens>
            <token id="25" string="5:18" />
          </tokens>
        </entity>
        <entity id="2" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>&amp;quot;I had to have patience and run from the back.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="patience" lemma="patience" stem="patienc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="run" lemma="run" stem="run" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="back" lemma="back" stem="back" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD had) (S (VP (TO to) (VP (VP (VB have) (NP (NN patience))) (CC and) (VP (VB run) (PP (IN from) (NP (DT the) (NN back)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="run from the back" type="VP">
          <tokens>
            <token id="8" string="run" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="back" />
          </tokens>
        </chunking>
        <chunking id="2" string="have patience and run from the back" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="patience" />
            <token id="7" string="and" />
            <token id="8" string="run" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="back" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="had to have patience and run from the back" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="to" />
            <token id="5" string="have" />
            <token id="6" string="patience" />
            <token id="7" string="and" />
            <token id="8" string="run" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="back" />
          </tokens>
        </chunking>
        <chunking id="5" string="patience" type="NP">
          <tokens>
            <token id="6" string="patience" />
          </tokens>
        </chunking>
        <chunking id="6" string="have patience" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="patience" />
          </tokens>
        </chunking>
        <chunking id="7" string="to have patience and run from the back" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="have" />
            <token id="6" string="patience" />
            <token id="7" string="and" />
            <token id="8" string="run" />
            <token id="9" string="from" />
            <token id="10" string="the" />
            <token id="11" string="back" />
          </tokens>
        </chunking>
        <chunking id="8" string="the back" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="back" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">had</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">have</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">had</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">have</governor>
          <dependent id="6">patience</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">have</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">have</governor>
          <dependent id="8">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">back</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">back</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">run</governor>
          <dependent id="11">back</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>After the 14-mile mark, the pack has already thinned to just Rosas, Danny Bustos, Doug Kurtis and Ernesto Gutierrez, who ran single file for a time.</content>
      <tokens>
        <token id="1" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="14-mile" lemma="14-mile" stem="14-mile" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="mark" lemma="mark" stem="mark" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="pack" lemma="pack" stem="pack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="thinned" lemma="thin" stem="thin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Rosas" lemma="Rosas" stem="rosa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="Danny" lemma="Danny" stem="danni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Bustos" lemma="Bustos" stem="busto" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="Doug" lemma="Doug" stem="doug" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="19" string="Kurtis" lemma="Kurtis" stem="kurti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Ernesto" lemma="Ernesto" stem="ernesto" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="Gutierrez" lemma="Gutierrez" stem="gutierrez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="single" lemma="single" stem="singl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="file" lemma="file" stem="file" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN After) (NP (DT the) (JJ 14-mile) (NN mark))) (, ,) (NP (DT the) (NN pack)) (VP (VBZ has) (ADVP (RB already)) (VP (VBN thinned) (PP (TO to) (NP (NP (RB just) (NNP Rosas)) (, ,) (NP (NNP Danny) (NNP Bustos)) (, ,) (NP (NNP Doug) (NNP Kurtis)) (CC and) (NP (NP (NNP Ernesto) (NNP Gutierrez)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD ran) (NP (JJ single) (NN file)) (PP (IN for) (NP (DT a) (NN time))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ernesto Gutierrez" type="NP">
          <tokens>
            <token id="21" string="Ernesto" />
            <token id="22" string="Gutierrez" />
          </tokens>
        </chunking>
        <chunking id="2" string="who ran single file for a time" type="SBAR">
          <tokens>
            <token id="24" string="who" />
            <token id="25" string="ran" />
            <token id="26" string="single" />
            <token id="27" string="file" />
            <token id="28" string="for" />
            <token id="29" string="a" />
            <token id="30" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="the pack" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="pack" />
          </tokens>
        </chunking>
        <chunking id="4" string="has already thinned to just Rosas , Danny Bustos , Doug Kurtis and Ernesto Gutierrez , who ran single file for a time" type="VP">
          <tokens>
            <token id="8" string="has" />
            <token id="9" string="already" />
            <token id="10" string="thinned" />
            <token id="11" string="to" />
            <token id="12" string="just" />
            <token id="13" string="Rosas" />
            <token id="14" string="," />
            <token id="15" string="Danny" />
            <token id="16" string="Bustos" />
            <token id="17" string="," />
            <token id="18" string="Doug" />
            <token id="19" string="Kurtis" />
            <token id="20" string="and" />
            <token id="21" string="Ernesto" />
            <token id="22" string="Gutierrez" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="ran" />
            <token id="26" string="single" />
            <token id="27" string="file" />
            <token id="28" string="for" />
            <token id="29" string="a" />
            <token id="30" string="time" />
          </tokens>
        </chunking>
        <chunking id="5" string="just Rosas , Danny Bustos , Doug Kurtis and Ernesto Gutierrez , who ran single file for a time" type="NP">
          <tokens>
            <token id="12" string="just" />
            <token id="13" string="Rosas" />
            <token id="14" string="," />
            <token id="15" string="Danny" />
            <token id="16" string="Bustos" />
            <token id="17" string="," />
            <token id="18" string="Doug" />
            <token id="19" string="Kurtis" />
            <token id="20" string="and" />
            <token id="21" string="Ernesto" />
            <token id="22" string="Gutierrez" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="ran" />
            <token id="26" string="single" />
            <token id="27" string="file" />
            <token id="28" string="for" />
            <token id="29" string="a" />
            <token id="30" string="time" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ernesto Gutierrez , who ran single file for a time" type="NP">
          <tokens>
            <token id="21" string="Ernesto" />
            <token id="22" string="Gutierrez" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="ran" />
            <token id="26" string="single" />
            <token id="27" string="file" />
            <token id="28" string="for" />
            <token id="29" string="a" />
            <token id="30" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="just Rosas" type="NP">
          <tokens>
            <token id="12" string="just" />
            <token id="13" string="Rosas" />
          </tokens>
        </chunking>
        <chunking id="8" string="Danny Bustos" type="NP">
          <tokens>
            <token id="15" string="Danny" />
            <token id="16" string="Bustos" />
          </tokens>
        </chunking>
        <chunking id="9" string="a time" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="time" />
          </tokens>
        </chunking>
        <chunking id="10" string="the 14-mile mark" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="14-mile" />
            <token id="4" string="mark" />
          </tokens>
        </chunking>
        <chunking id="11" string="ran single file for a time" type="VP">
          <tokens>
            <token id="25" string="ran" />
            <token id="26" string="single" />
            <token id="27" string="file" />
            <token id="28" string="for" />
            <token id="29" string="a" />
            <token id="30" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="Doug Kurtis" type="NP">
          <tokens>
            <token id="18" string="Doug" />
            <token id="19" string="Kurtis" />
          </tokens>
        </chunking>
        <chunking id="13" string="single file" type="NP">
          <tokens>
            <token id="26" string="single" />
            <token id="27" string="file" />
          </tokens>
        </chunking>
        <chunking id="14" string="thinned to just Rosas , Danny Bustos , Doug Kurtis and Ernesto Gutierrez , who ran single file for a time" type="VP">
          <tokens>
            <token id="10" string="thinned" />
            <token id="11" string="to" />
            <token id="12" string="just" />
            <token id="13" string="Rosas" />
            <token id="14" string="," />
            <token id="15" string="Danny" />
            <token id="16" string="Bustos" />
            <token id="17" string="," />
            <token id="18" string="Doug" />
            <token id="19" string="Kurtis" />
            <token id="20" string="and" />
            <token id="21" string="Ernesto" />
            <token id="22" string="Gutierrez" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="ran" />
            <token id="26" string="single" />
            <token id="27" string="file" />
            <token id="28" string="for" />
            <token id="29" string="a" />
            <token id="30" string="time" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">mark</governor>
          <dependent id="1">After</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">mark</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">mark</governor>
          <dependent id="3">14-mile</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">thinned</governor>
          <dependent id="4">mark</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">pack</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">thinned</governor>
          <dependent id="7">pack</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">thinned</governor>
          <dependent id="8">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">thinned</governor>
          <dependent id="9">already</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">thinned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Rosas</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">Rosas</governor>
          <dependent id="12">just</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">thinned</governor>
          <dependent id="13">Rosas</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Bustos</governor>
          <dependent id="15">Danny</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Rosas</governor>
          <dependent id="16">Bustos</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Kurtis</governor>
          <dependent id="18">Doug</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Rosas</governor>
          <dependent id="19">Kurtis</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Rosas</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Gutierrez</governor>
          <dependent id="21">Ernesto</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Rosas</governor>
          <dependent id="22">Gutierrez</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">ran</governor>
          <dependent id="24">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">Gutierrez</governor>
          <dependent id="25">ran</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">file</governor>
          <dependent id="26">single</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">ran</governor>
          <dependent id="27">file</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">time</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">time</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">ran</governor>
          <dependent id="30">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rosas" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Rosas" />
          </tokens>
        </entity>
        <entity id="2" string="Danny Bustos" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Danny" />
            <token id="16" string="Bustos" />
          </tokens>
        </entity>
        <entity id="3" string="Ernesto Gutierrez" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Ernesto" />
            <token id="22" string="Gutierrez" />
          </tokens>
        </entity>
        <entity id="4" string="Doug Kurtis" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Doug" />
            <token id="19" string="Kurtis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Martinez and Martin Rodriguez Rivera held back, but Martinez soon heard a little voice that told him to move or be removed from contention.</content>
      <tokens>
        <token id="1" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="Martin" lemma="Martin" stem="martin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="Rodriguez" lemma="Rodriguez" stem="rodriguez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="Rivera" lemma="Rivera" stem="rivera" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="held" lemma="hold" stem="held" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="soon" lemma="soon" stem="soon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="heard" lemma="hear" stem="heard" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="voice" lemma="voice" stem="voic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="move" lemma="move" stem="move" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="removed" lemma="remove" stem="remov" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="contention" lemma="contention" stem="content" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Martinez) (CC and) (NNP Martin) (NNP Rodriguez) (NNP Rivera)) (VP (VBD held) (ADVP (RB back)))) (, ,) (CC but) (S (NP (NNP Martinez)) (ADVP (RB soon)) (VP (VBD heard) (NP (NP (DT a) (JJ little) (NN voice)) (SBAR (WHNP (WDT that)) (S (VP (VBD told) (S (NP (PRP him)) (VP (TO to) (VP (VP (VB move)) (CC or) (VP (VB be) (VP (VBN removed) (PP (IN from) (NP (NN contention)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="move" type="VP">
          <tokens>
            <token id="20" string="move" />
          </tokens>
        </chunking>
        <chunking id="2" string="be removed from contention" type="VP">
          <tokens>
            <token id="22" string="be" />
            <token id="23" string="removed" />
            <token id="24" string="from" />
            <token id="25" string="contention" />
          </tokens>
        </chunking>
        <chunking id="3" string="Martinez and Martin Rodriguez Rivera" type="NP">
          <tokens>
            <token id="1" string="Martinez" />
            <token id="2" string="and" />
            <token id="3" string="Martin" />
            <token id="4" string="Rodriguez" />
            <token id="5" string="Rivera" />
          </tokens>
        </chunking>
        <chunking id="4" string="told him to move or be removed from contention" type="VP">
          <tokens>
            <token id="17" string="told" />
            <token id="18" string="him" />
            <token id="19" string="to" />
            <token id="20" string="move" />
            <token id="21" string="or" />
            <token id="22" string="be" />
            <token id="23" string="removed" />
            <token id="24" string="from" />
            <token id="25" string="contention" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="18" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="contention" type="NP">
          <tokens>
            <token id="25" string="contention" />
          </tokens>
        </chunking>
        <chunking id="7" string="held back" type="VP">
          <tokens>
            <token id="6" string="held" />
            <token id="7" string="back" />
          </tokens>
        </chunking>
        <chunking id="8" string="that told him to move or be removed from contention" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="told" />
            <token id="18" string="him" />
            <token id="19" string="to" />
            <token id="20" string="move" />
            <token id="21" string="or" />
            <token id="22" string="be" />
            <token id="23" string="removed" />
            <token id="24" string="from" />
            <token id="25" string="contention" />
          </tokens>
        </chunking>
        <chunking id="9" string="move or be removed from contention" type="VP">
          <tokens>
            <token id="20" string="move" />
            <token id="21" string="or" />
            <token id="22" string="be" />
            <token id="23" string="removed" />
            <token id="24" string="from" />
            <token id="25" string="contention" />
          </tokens>
        </chunking>
        <chunking id="10" string="a little voice" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="little" />
            <token id="15" string="voice" />
          </tokens>
        </chunking>
        <chunking id="11" string="removed from contention" type="VP">
          <tokens>
            <token id="23" string="removed" />
            <token id="24" string="from" />
            <token id="25" string="contention" />
          </tokens>
        </chunking>
        <chunking id="12" string="heard a little voice that told him to move or be removed from contention" type="VP">
          <tokens>
            <token id="12" string="heard" />
            <token id="13" string="a" />
            <token id="14" string="little" />
            <token id="15" string="voice" />
            <token id="16" string="that" />
            <token id="17" string="told" />
            <token id="18" string="him" />
            <token id="19" string="to" />
            <token id="20" string="move" />
            <token id="21" string="or" />
            <token id="22" string="be" />
            <token id="23" string="removed" />
            <token id="24" string="from" />
            <token id="25" string="contention" />
          </tokens>
        </chunking>
        <chunking id="13" string="Martinez" type="NP">
          <tokens>
            <token id="10" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="14" string="to move or be removed from contention" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="move" />
            <token id="21" string="or" />
            <token id="22" string="be" />
            <token id="23" string="removed" />
            <token id="24" string="from" />
            <token id="25" string="contention" />
          </tokens>
        </chunking>
        <chunking id="15" string="a little voice that told him to move or be removed from contention" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="little" />
            <token id="15" string="voice" />
            <token id="16" string="that" />
            <token id="17" string="told" />
            <token id="18" string="him" />
            <token id="19" string="to" />
            <token id="20" string="move" />
            <token id="21" string="or" />
            <token id="22" string="be" />
            <token id="23" string="removed" />
            <token id="24" string="from" />
            <token id="25" string="contention" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="5">Rivera</governor>
          <dependent id="1">Martinez</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Martinez</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Martinez</governor>
          <dependent id="3">Martin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Rivera</governor>
          <dependent id="4">Rodriguez</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">held</governor>
          <dependent id="5">Rivera</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">held</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">held</governor>
          <dependent id="7">back</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">held</governor>
          <dependent id="9">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">heard</governor>
          <dependent id="10">Martinez</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">heard</governor>
          <dependent id="11">soon</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">held</governor>
          <dependent id="12">heard</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">voice</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">voice</governor>
          <dependent id="14">little</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">heard</governor>
          <dependent id="15">voice</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">told</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">voice</governor>
          <dependent id="17">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">told</governor>
          <dependent id="18">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">move</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">told</governor>
          <dependent id="20">move</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">move</governor>
          <dependent id="21">or</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">removed</governor>
          <dependent id="22">be</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">move</governor>
          <dependent id="23">removed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">contention</governor>
          <dependent id="24">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">removed</governor>
          <dependent id="25">contention</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Martin Rodriguez Rivera" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Martin" />
            <token id="4" string="Rodriguez" />
            <token id="5" string="Rivera" />
          </tokens>
        </entity>
        <entity id="2" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>&amp;quot;The first 10-15 miles, I could have been in 1,000th place,&amp;quot; Martinez said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="4" string="10-15" lemma="10-15" stem="10-15" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="5" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="1,000" lemma="1,000" stem="1,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="th" lemma="th" stem="th" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (DT The) (JJ first) (CD 10-15) (NNS miles)) (, ,) (NP (PRP I)) (VP (MD could) (VP (VB have) (VP (VBN been) (PP (IN in) (NP (NP (CD 1,000)) (NP (DT th) (NN place)))))))) (, ,) ('' '') (NP (NNP Martinez)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="1,000 th place" type="NP">
          <tokens>
            <token id="12" string="1,000" />
            <token id="13" string="th" />
            <token id="14" string="place" />
          </tokens>
        </chunking>
        <chunking id="2" string="th place" type="NP">
          <tokens>
            <token id="13" string="th" />
            <token id="14" string="place" />
          </tokens>
        </chunking>
        <chunking id="3" string="1,000" type="NP">
          <tokens>
            <token id="12" string="1,000" />
          </tokens>
        </chunking>
        <chunking id="4" string="The first 10-15 miles" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="first" />
            <token id="4" string="10-15" />
            <token id="5" string="miles" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="7" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="have been in 1,000 th place" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="been" />
            <token id="11" string="in" />
            <token id="12" string="1,000" />
            <token id="13" string="th" />
            <token id="14" string="place" />
          </tokens>
        </chunking>
        <chunking id="7" string="Martinez" type="NP">
          <tokens>
            <token id="17" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="8" string="could have been in 1,000 th place" type="VP">
          <tokens>
            <token id="8" string="could" />
            <token id="9" string="have" />
            <token id="10" string="been" />
            <token id="11" string="in" />
            <token id="12" string="1,000" />
            <token id="13" string="th" />
            <token id="14" string="place" />
          </tokens>
        </chunking>
        <chunking id="9" string="been in 1,000 th place" type="VP">
          <tokens>
            <token id="10" string="been" />
            <token id="11" string="in" />
            <token id="12" string="1,000" />
            <token id="13" string="th" />
            <token id="14" string="place" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="18" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">miles</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">miles</governor>
          <dependent id="3">first</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">miles</governor>
          <dependent id="4">10-15</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">1,000</governor>
          <dependent id="5">miles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">1,000</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">1,000</governor>
          <dependent id="8">could</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">1,000</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">1,000</governor>
          <dependent id="10">been</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">1,000</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="12">1,000</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">place</governor>
          <dependent id="13">th</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">1,000</governor>
          <dependent id="14">place</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">Martinez</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="3" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="1,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="1,000" />
          </tokens>
        </entity>
        <entity id="3" string="10-15" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="10-15" />
          </tokens>
        </entity>
        <entity id="4" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>&amp;quot;I didn&amp;apost;t care.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="care" lemma="care" stem="care" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBD did) (RB n't) (VP (VB care))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="did n't care" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="n't" />
            <token id="5" string="care" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="care" type="VP">
          <tokens>
            <token id="5" string="care" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">care</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">care</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">care</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">care</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Then I got worried.&amp;quot;</content>
      <tokens>
        <token id="1" string="Then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="worried" lemma="worry" stem="worri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Then) (NP (PRP I)) (VP (VBD got) (ADJP (VBN worried))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="got worried" type="VP">
          <tokens>
            <token id="3" string="got" />
            <token id="4" string="worried" />
          </tokens>
        </chunking>
        <chunking id="2" string="worried" type="ADJP">
          <tokens>
            <token id="4" string="worried" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">got</governor>
          <dependent id="1">Then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">got</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">got</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">got</governor>
          <dependent id="4">worried</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Martinez left Rivera, and started on the chase.</content>
      <tokens>
        <token id="1" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="3" string="Rivera" lemma="Rivera" stem="rivera" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="chase" lemma="chase" stem="chase" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Martinez)) (VP (VP (VBD left) (NP (NNP Rivera))) (, ,) (CC and) (VP (VBD started) (PP (IN on) (NP (DT the) (NN chase))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="left Rivera , and started on the chase" type="VP">
          <tokens>
            <token id="2" string="left" />
            <token id="3" string="Rivera" />
            <token id="4" string="," />
            <token id="5" string="and" />
            <token id="6" string="started" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="chase" />
          </tokens>
        </chunking>
        <chunking id="2" string="started on the chase" type="VP">
          <tokens>
            <token id="6" string="started" />
            <token id="7" string="on" />
            <token id="8" string="the" />
            <token id="9" string="chase" />
          </tokens>
        </chunking>
        <chunking id="3" string="left Rivera" type="VP">
          <tokens>
            <token id="2" string="left" />
            <token id="3" string="Rivera" />
          </tokens>
        </chunking>
        <chunking id="4" string="Rivera" type="NP">
          <tokens>
            <token id="3" string="Rivera" />
          </tokens>
        </chunking>
        <chunking id="5" string="Martinez" type="NP">
          <tokens>
            <token id="1" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="6" string="the chase" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="chase" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">left</governor>
          <dependent id="1">Martinez</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">left</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">left</governor>
          <dependent id="3">Rivera</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">left</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">left</governor>
          <dependent id="6">started</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">chase</governor>
          <dependent id="7">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">chase</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">started</governor>
          <dependent id="9">chase</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="2" string="left" />
          </tokens>
        </entity>
        <entity id="2" string="Rivera" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="Rivera" />
          </tokens>
        </entity>
        <entity id="3" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Since Martinez hadn&amp;apost;t been seen earlier, it originally was thought the figure gainly ground slowly but methodically from Mile 21 to Mile 24 was San Diego&amp;apost;s Henry Chio.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="earlier" lemma="earlier" stem="earlier" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="originally" lemma="originally" stem="origin" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="thought" lemma="think" stem="thought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="figure" lemma="figure" stem="figur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="gainly" lemma="gainly" stem="gainli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="ground" lemma="ground" stem="ground" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="slowly" lemma="slowly" stem="slowli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="methodically" lemma="methodically" stem="method" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Mile" lemma="Mile" stem="mile" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="21" lemma="21" stem="21" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Mile" lemma="Mile" stem="mile" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="28" string="Diego" lemma="Diego" stem="diego" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="29" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="Henry" lemma="Henry" stem="henri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="Chio" lemma="Chio" stem="chio" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (SBAR (IN Since) (S (NP (NNP Martinez)) (VP (VBD had) (RB n't) (VP (VBN been) (VP (VBN seen) (ADVP (RBR earlier))))))) (, ,) (NP (PRP it)) (ADVP (RB originally)) (VP (VBD was) (VP (VBN thought) (NP (DT the) (NN figure)) (ADVP (RB gainly)) (ADVP (ADVP (NP (NN ground)) (RB slowly)) (PRN (CC but) (ADVP (RB methodically)) (PP (IN from) (NP (NNP Mile) (CD 21))))) (PP (TO to) (NP (NNP Mile) (CD 24)))))) (VP (VBD was)) (NP (NP (NNP San) (NNP Diego) (POS 's)) (NNP Henry) (NNP Chio)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had n't been seen earlier" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="n't" />
            <token id="5" string="been" />
            <token id="6" string="seen" />
            <token id="7" string="earlier" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mile 24" type="NP">
          <tokens>
            <token id="24" string="Mile" />
            <token id="25" string="24" />
          </tokens>
        </chunking>
        <chunking id="3" string="Mile 21" type="NP">
          <tokens>
            <token id="21" string="Mile" />
            <token id="22" string="21" />
          </tokens>
        </chunking>
        <chunking id="4" string="Since Martinez had n't been seen earlier" type="SBAR">
          <tokens>
            <token id="1" string="Since" />
            <token id="2" string="Martinez" />
            <token id="3" string="had" />
            <token id="4" string="n't" />
            <token id="5" string="been" />
            <token id="6" string="seen" />
            <token id="7" string="earlier" />
          </tokens>
        </chunking>
        <chunking id="5" string="thought the figure gainly ground slowly but methodically from Mile 21 to Mile 24" type="VP">
          <tokens>
            <token id="12" string="thought" />
            <token id="13" string="the" />
            <token id="14" string="figure" />
            <token id="15" string="gainly" />
            <token id="16" string="ground" />
            <token id="17" string="slowly" />
            <token id="18" string="but" />
            <token id="19" string="methodically" />
            <token id="20" string="from" />
            <token id="21" string="Mile" />
            <token id="22" string="21" />
            <token id="23" string="to" />
            <token id="24" string="Mile" />
            <token id="25" string="24" />
          </tokens>
        </chunking>
        <chunking id="6" string="was thought the figure gainly ground slowly but methodically from Mile 21 to Mile 24" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="thought" />
            <token id="13" string="the" />
            <token id="14" string="figure" />
            <token id="15" string="gainly" />
            <token id="16" string="ground" />
            <token id="17" string="slowly" />
            <token id="18" string="but" />
            <token id="19" string="methodically" />
            <token id="20" string="from" />
            <token id="21" string="Mile" />
            <token id="22" string="21" />
            <token id="23" string="to" />
            <token id="24" string="Mile" />
            <token id="25" string="24" />
          </tokens>
        </chunking>
        <chunking id="7" string="was" type="VP">
          <tokens>
            <token id="26" string="was" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="9" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="the figure" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="figure" />
          </tokens>
        </chunking>
        <chunking id="10" string="San Diego 's Henry Chio" type="NP">
          <tokens>
            <token id="27" string="San" />
            <token id="28" string="Diego" />
            <token id="29" string="'s" />
            <token id="30" string="Henry" />
            <token id="31" string="Chio" />
          </tokens>
        </chunking>
        <chunking id="11" string="San Diego 's" type="NP">
          <tokens>
            <token id="27" string="San" />
            <token id="28" string="Diego" />
            <token id="29" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="seen earlier" type="VP">
          <tokens>
            <token id="6" string="seen" />
            <token id="7" string="earlier" />
          </tokens>
        </chunking>
        <chunking id="13" string="been seen earlier" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="seen" />
            <token id="7" string="earlier" />
          </tokens>
        </chunking>
        <chunking id="14" string="ground" type="NP">
          <tokens>
            <token id="16" string="ground" />
          </tokens>
        </chunking>
        <chunking id="15" string="Martinez" type="NP">
          <tokens>
            <token id="2" string="Martinez" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">seen</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">seen</governor>
          <dependent id="2">Martinez</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">seen</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">seen</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">seen</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">thought</governor>
          <dependent id="6">seen</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">seen</governor>
          <dependent id="7">earlier</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">thought</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">thought</governor>
          <dependent id="10">originally</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">thought</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="26">was</governor>
          <dependent id="12">thought</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">figure</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">thought</governor>
          <dependent id="14">figure</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">thought</governor>
          <dependent id="15">gainly</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="17">slowly</governor>
          <dependent id="16">ground</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">thought</governor>
          <dependent id="17">slowly</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">Mile</governor>
          <dependent id="18">but</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">Mile</governor>
          <dependent id="19">methodically</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Mile</governor>
          <dependent id="20">from</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">slowly</governor>
          <dependent id="21">Mile</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">Mile</governor>
          <dependent id="22">21</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Mile</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">thought</governor>
          <dependent id="24">Mile</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="24">Mile</governor>
          <dependent id="25">24</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">Diego</governor>
          <dependent id="27">San</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">Chio</governor>
          <dependent id="28">Diego</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Diego</governor>
          <dependent id="29">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Chio</governor>
          <dependent id="30">Henry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">was</governor>
          <dependent id="31">Chio</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="24" type="NUMBER" score="0.0">
          <tokens>
            <token id="25" string="24" />
          </tokens>
        </entity>
        <entity id="2" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Martinez" />
          </tokens>
        </entity>
        <entity id="3" string="San Diego" type="LOCATION" score="0.0">
          <tokens>
            <token id="27" string="San" />
            <token id="28" string="Diego" />
          </tokens>
        </entity>
        <entity id="4" string="21" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="21" />
          </tokens>
        </entity>
        <entity id="5" string="Henry Chio" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Henry" />
            <token id="31" string="Chio" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>Wrong.</content>
      <tokens>
        <token id="1" string="Wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (ADJP (JJ Wrong)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Wrong" type="ADJP">
          <tokens>
            <token id="1" string="Wrong" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Wrong</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Martinez&amp;apost; late kick caught Rosas, who had broken away on his own for a three-mile lead at Mile 21, cramped and been surprised at the 23-mile mark.</content>
      <tokens>
        <token id="1" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="late" lemma="late" stem="late" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="kick" lemma="kick" stem="kick" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="caught" lemma="catch" stem="caught" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Rosas" lemma="Rosas" stem="rosa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="broken" lemma="break" stem="broken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="away" lemma="away" stem="awai" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="three-mile" lemma="three-mile" stem="three-mil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="lead" lemma="lead" stem="lead" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="Mile" lemma="Mile" stem="mile" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="21" lemma="21" stem="21" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="cramped" lemma="cramped" stem="cramp" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="surprised" lemma="surprise" stem="surpris" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="23-mile" lemma="23-mile" stem="23-mile" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="mark" lemma="mark" stem="mark" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Martinez) (POS ')) (JJ late) (NN kick)) (VP (VBD caught) (NP (NP (NNP Rosas)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD had) (VP (VP (VBN broken) (PRT (RP away)) (PP (IN on) (NP (PRP$ his) (JJ own))) (PP (IN for) (NP (NP (DT a) (JJ three-mile) (NN lead)) (PP (IN at) (NP (NNP Mile) (CD 21))))) (, ,) (ADJP (JJ cramped))) (CC and) (VP (VBN been) (VP (VBN surprised) (PP (IN at) (NP (DT the) (JJ 23-mile) (NN mark))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="broken away on his own for a three-mile lead at Mile 21 , cramped" type="VP">
          <tokens>
            <token id="10" string="broken" />
            <token id="11" string="away" />
            <token id="12" string="on" />
            <token id="13" string="his" />
            <token id="14" string="own" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="three-mile" />
            <token id="18" string="lead" />
            <token id="19" string="at" />
            <token id="20" string="Mile" />
            <token id="21" string="21" />
            <token id="22" string="," />
            <token id="23" string="cramped" />
          </tokens>
        </chunking>
        <chunking id="2" string="been surprised at the 23-mile mark" type="VP">
          <tokens>
            <token id="25" string="been" />
            <token id="26" string="surprised" />
            <token id="27" string="at" />
            <token id="28" string="the" />
            <token id="29" string="23-mile" />
            <token id="30" string="mark" />
          </tokens>
        </chunking>
        <chunking id="3" string="caught Rosas , who had broken away on his own for a three-mile lead at Mile 21 , cramped and been surprised at the 23-mile mark" type="VP">
          <tokens>
            <token id="5" string="caught" />
            <token id="6" string="Rosas" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="had" />
            <token id="10" string="broken" />
            <token id="11" string="away" />
            <token id="12" string="on" />
            <token id="13" string="his" />
            <token id="14" string="own" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="three-mile" />
            <token id="18" string="lead" />
            <token id="19" string="at" />
            <token id="20" string="Mile" />
            <token id="21" string="21" />
            <token id="22" string="," />
            <token id="23" string="cramped" />
            <token id="24" string="and" />
            <token id="25" string="been" />
            <token id="26" string="surprised" />
            <token id="27" string="at" />
            <token id="28" string="the" />
            <token id="29" string="23-mile" />
            <token id="30" string="mark" />
          </tokens>
        </chunking>
        <chunking id="4" string="surprised at the 23-mile mark" type="VP">
          <tokens>
            <token id="26" string="surprised" />
            <token id="27" string="at" />
            <token id="28" string="the" />
            <token id="29" string="23-mile" />
            <token id="30" string="mark" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mile 21" type="NP">
          <tokens>
            <token id="20" string="Mile" />
            <token id="21" string="21" />
          </tokens>
        </chunking>
        <chunking id="6" string="had broken away on his own for a three-mile lead at Mile 21 , cramped and been surprised at the 23-mile mark" type="VP">
          <tokens>
            <token id="9" string="had" />
            <token id="10" string="broken" />
            <token id="11" string="away" />
            <token id="12" string="on" />
            <token id="13" string="his" />
            <token id="14" string="own" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="three-mile" />
            <token id="18" string="lead" />
            <token id="19" string="at" />
            <token id="20" string="Mile" />
            <token id="21" string="21" />
            <token id="22" string="," />
            <token id="23" string="cramped" />
            <token id="24" string="and" />
            <token id="25" string="been" />
            <token id="26" string="surprised" />
            <token id="27" string="at" />
            <token id="28" string="the" />
            <token id="29" string="23-mile" />
            <token id="30" string="mark" />
          </tokens>
        </chunking>
        <chunking id="7" string="cramped" type="ADJP">
          <tokens>
            <token id="23" string="cramped" />
          </tokens>
        </chunking>
        <chunking id="8" string="a three-mile lead at Mile 21" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="three-mile" />
            <token id="18" string="lead" />
            <token id="19" string="at" />
            <token id="20" string="Mile" />
            <token id="21" string="21" />
          </tokens>
        </chunking>
        <chunking id="9" string="Rosas , who had broken away on his own for a three-mile lead at Mile 21 , cramped and been surprised at the 23-mile mark" type="NP">
          <tokens>
            <token id="6" string="Rosas" />
            <token id="7" string="," />
            <token id="8" string="who" />
            <token id="9" string="had" />
            <token id="10" string="broken" />
            <token id="11" string="away" />
            <token id="12" string="on" />
            <token id="13" string="his" />
            <token id="14" string="own" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="three-mile" />
            <token id="18" string="lead" />
            <token id="19" string="at" />
            <token id="20" string="Mile" />
            <token id="21" string="21" />
            <token id="22" string="," />
            <token id="23" string="cramped" />
            <token id="24" string="and" />
            <token id="25" string="been" />
            <token id="26" string="surprised" />
            <token id="27" string="at" />
            <token id="28" string="the" />
            <token id="29" string="23-mile" />
            <token id="30" string="mark" />
          </tokens>
        </chunking>
        <chunking id="10" string="the 23-mile mark" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="23-mile" />
            <token id="30" string="mark" />
          </tokens>
        </chunking>
        <chunking id="11" string="his own" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="own" />
          </tokens>
        </chunking>
        <chunking id="12" string="Rosas" type="NP">
          <tokens>
            <token id="6" string="Rosas" />
          </tokens>
        </chunking>
        <chunking id="13" string="Martinez ' late kick" type="NP">
          <tokens>
            <token id="1" string="Martinez" />
            <token id="2" string="'" />
            <token id="3" string="late" />
            <token id="4" string="kick" />
          </tokens>
        </chunking>
        <chunking id="14" string="broken away on his own for a three-mile lead at Mile 21 , cramped and been surprised at the 23-mile mark" type="VP">
          <tokens>
            <token id="10" string="broken" />
            <token id="11" string="away" />
            <token id="12" string="on" />
            <token id="13" string="his" />
            <token id="14" string="own" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="three-mile" />
            <token id="18" string="lead" />
            <token id="19" string="at" />
            <token id="20" string="Mile" />
            <token id="21" string="21" />
            <token id="22" string="," />
            <token id="23" string="cramped" />
            <token id="24" string="and" />
            <token id="25" string="been" />
            <token id="26" string="surprised" />
            <token id="27" string="at" />
            <token id="28" string="the" />
            <token id="29" string="23-mile" />
            <token id="30" string="mark" />
          </tokens>
        </chunking>
        <chunking id="15" string="a three-mile lead" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="three-mile" />
            <token id="18" string="lead" />
          </tokens>
        </chunking>
        <chunking id="16" string="who had broken away on his own for a three-mile lead at Mile 21 , cramped and been surprised at the 23-mile mark" type="SBAR">
          <tokens>
            <token id="8" string="who" />
            <token id="9" string="had" />
            <token id="10" string="broken" />
            <token id="11" string="away" />
            <token id="12" string="on" />
            <token id="13" string="his" />
            <token id="14" string="own" />
            <token id="15" string="for" />
            <token id="16" string="a" />
            <token id="17" string="three-mile" />
            <token id="18" string="lead" />
            <token id="19" string="at" />
            <token id="20" string="Mile" />
            <token id="21" string="21" />
            <token id="22" string="," />
            <token id="23" string="cramped" />
            <token id="24" string="and" />
            <token id="25" string="been" />
            <token id="26" string="surprised" />
            <token id="27" string="at" />
            <token id="28" string="the" />
            <token id="29" string="23-mile" />
            <token id="30" string="mark" />
          </tokens>
        </chunking>
        <chunking id="17" string="Martinez '" type="NP">
          <tokens>
            <token id="1" string="Martinez" />
            <token id="2" string="'" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">kick</governor>
          <dependent id="1">Martinez</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Martinez</governor>
          <dependent id="2">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">kick</governor>
          <dependent id="3">late</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">caught</governor>
          <dependent id="4">kick</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">caught</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">caught</governor>
          <dependent id="6">Rosas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">broken</governor>
          <dependent id="8">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">broken</governor>
          <dependent id="9">had</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">Rosas</governor>
          <dependent id="10">broken</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="10">broken</governor>
          <dependent id="11">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">own</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">own</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">broken</governor>
          <dependent id="14">own</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">lead</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">lead</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">lead</governor>
          <dependent id="17">three-mile</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">broken</governor>
          <dependent id="18">lead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Mile</governor>
          <dependent id="19">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">lead</governor>
          <dependent id="20">Mile</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">Mile</governor>
          <dependent id="21">21</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">broken</governor>
          <dependent id="23">cramped</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">broken</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">surprised</governor>
          <dependent id="25">been</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">broken</governor>
          <dependent id="26">surprised</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">mark</governor>
          <dependent id="27">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">mark</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">mark</governor>
          <dependent id="29">23-mile</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">surprised</governor>
          <dependent id="30">mark</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rosas" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Rosas" />
          </tokens>
        </entity>
        <entity id="2" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Martinez" />
          </tokens>
        </entity>
        <entity id="3" string="21" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="21" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>&amp;quot;I tied up, there was nothing I could do,&amp;quot; said Rosas, who was third in 2:19.49.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="tied" lemma="tie" stem="ti" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="Rosas" lemma="Rosas" stem="rosa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="third" lemma="third" stem="third" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="true" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="2:19.49" lemma="2:19.49" stem="2:19.49" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (S (NP (PRP I)) (VP (VBD tied) (PRT (RP up)))) (, ,) (S (NP (EX there)) (VP (VBD was) (NP (NP (NN nothing)) (SBAR (S (NP (PRP I)) (VP (MD could) (VP (VB do))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Rosas)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD was) (ADJP (JJ third) (PP (IN in) (NP (CD 2:19.49)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who was third in 2:19.49" type="SBAR">
          <tokens>
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="third" />
            <token id="20" string="in" />
            <token id="21" string="2:19.49" />
          </tokens>
        </chunking>
        <chunking id="2" string="Rosas , who was third in 2:19.49" type="NP">
          <tokens>
            <token id="15" string="Rosas" />
            <token id="16" string="," />
            <token id="17" string="who" />
            <token id="18" string="was" />
            <token id="19" string="third" />
            <token id="20" string="in" />
            <token id="21" string="2:19.49" />
          </tokens>
        </chunking>
        <chunking id="3" string="nothing" type="NP">
          <tokens>
            <token id="8" string="nothing" />
          </tokens>
        </chunking>
        <chunking id="4" string="nothing I could do" type="NP">
          <tokens>
            <token id="8" string="nothing" />
            <token id="9" string="I" />
            <token id="10" string="could" />
            <token id="11" string="do" />
          </tokens>
        </chunking>
        <chunking id="5" string="could do" type="VP">
          <tokens>
            <token id="10" string="could" />
            <token id="11" string="do" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="was third in 2:19.49" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="third" />
            <token id="20" string="in" />
            <token id="21" string="2:19.49" />
          </tokens>
        </chunking>
        <chunking id="8" string="do" type="VP">
          <tokens>
            <token id="11" string="do" />
          </tokens>
        </chunking>
        <chunking id="9" string="I could do" type="SBAR">
          <tokens>
            <token id="9" string="I" />
            <token id="10" string="could" />
            <token id="11" string="do" />
          </tokens>
        </chunking>
        <chunking id="10" string="there" type="NP">
          <tokens>
            <token id="6" string="there" />
          </tokens>
        </chunking>
        <chunking id="11" string="Rosas" type="NP">
          <tokens>
            <token id="15" string="Rosas" />
          </tokens>
        </chunking>
        <chunking id="12" string="third in 2:19.49" type="ADJP">
          <tokens>
            <token id="19" string="third" />
            <token id="20" string="in" />
            <token id="21" string="2:19.49" />
          </tokens>
        </chunking>
        <chunking id="13" string="was nothing I could do" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="nothing" />
            <token id="9" string="I" />
            <token id="10" string="could" />
            <token id="11" string="do" />
          </tokens>
        </chunking>
        <chunking id="14" string="tied up" type="VP">
          <tokens>
            <token id="3" string="tied" />
            <token id="4" string="up" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="14" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="2:19.49" type="NP">
          <tokens>
            <token id="21" string="2:19.49" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">tied</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="3">tied</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="3">tied</governor>
          <dependent id="4">up</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="7">was</governor>
          <dependent id="6">there</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">tied</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">was</governor>
          <dependent id="8">nothing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">do</governor>
          <dependent id="9">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">do</governor>
          <dependent id="10">could</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">nothing</governor>
          <dependent id="11">do</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="15">Rosas</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">third</governor>
          <dependent id="17">who</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="19">third</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">Rosas</governor>
          <dependent id="19">third</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">2:19.49</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">third</governor>
          <dependent id="21">2:19.49</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rosas" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Rosas" />
          </tokens>
        </entity>
        <entity id="2" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="19" string="third" />
          </tokens>
        </entity>
        <entity id="3" string="2:19.49" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="2:19.49" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>&amp;quot;As he started closing, that&amp;apost;s when my legs really started getting sore.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="closing" lemma="close" stem="close" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="legs" lemma="leg" stem="leg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="getting" lemma="get" stem="get" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="sore" lemma="sore" stem="sore" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN As) (S (NP (PRP he)) (VP (VBD started) (S (VP (VBG closing)))))) (, ,) (NP (DT that)) (VP (VBZ 's) (SBAR (WHADVP (WRB when)) (S (NP (PRP$ my) (NNS legs)) (ADVP (RB really)) (VP (VBD started) (S (VP (VBG getting) (NP (JJ sore)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="7" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="closing" type="VP">
          <tokens>
            <token id="5" string="closing" />
          </tokens>
        </chunking>
        <chunking id="3" string="started closing" type="VP">
          <tokens>
            <token id="4" string="started" />
            <token id="5" string="closing" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s when my legs really started getting sore" type="VP">
          <tokens>
            <token id="8" string="'s" />
            <token id="9" string="when" />
            <token id="10" string="my" />
            <token id="11" string="legs" />
            <token id="12" string="really" />
            <token id="13" string="started" />
            <token id="14" string="getting" />
            <token id="15" string="sore" />
          </tokens>
        </chunking>
        <chunking id="5" string="getting sore" type="VP">
          <tokens>
            <token id="14" string="getting" />
            <token id="15" string="sore" />
          </tokens>
        </chunking>
        <chunking id="6" string="started getting sore" type="VP">
          <tokens>
            <token id="13" string="started" />
            <token id="14" string="getting" />
            <token id="15" string="sore" />
          </tokens>
        </chunking>
        <chunking id="7" string="sore" type="NP">
          <tokens>
            <token id="15" string="sore" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="As he started closing" type="SBAR">
          <tokens>
            <token id="2" string="As" />
            <token id="3" string="he" />
            <token id="4" string="started" />
            <token id="5" string="closing" />
          </tokens>
        </chunking>
        <chunking id="10" string="when my legs really started getting sore" type="SBAR">
          <tokens>
            <token id="9" string="when" />
            <token id="10" string="my" />
            <token id="11" string="legs" />
            <token id="12" string="really" />
            <token id="13" string="started" />
            <token id="14" string="getting" />
            <token id="15" string="sore" />
          </tokens>
        </chunking>
        <chunking id="11" string="when" type="WHADVP">
          <tokens>
            <token id="9" string="when" />
          </tokens>
        </chunking>
        <chunking id="12" string="my legs" type="NP">
          <tokens>
            <token id="10" string="my" />
            <token id="11" string="legs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="4">started</governor>
          <dependent id="2">As</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">started</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">'s</governor>
          <dependent id="4">started</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">started</governor>
          <dependent id="5">closing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">'s</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">started</governor>
          <dependent id="9">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">legs</governor>
          <dependent id="10">my</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">started</governor>
          <dependent id="11">legs</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">started</governor>
          <dependent id="12">really</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">'s</governor>
          <dependent id="13">started</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">started</governor>
          <dependent id="14">getting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">getting</governor>
          <dependent id="15">sore</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>I tried to just hang on, to hang in there, but he shot ahead of me.&amp;quot;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="tried" lemma="try" stem="tri" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="hang" lemma="hang" stem="hang" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="hang" lemma="hang" stem="hang" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="shot" lemma="shoot" stem="shot" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="ahead" lemma="ahead" stem="ahead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBD tried) (S (VP (TO to) (VP (ADVP (RB just)) (VB hang) (PP (IN on))))) (, ,) (S (VP (TO to) (VP (VB hang) (PP (IN in) (NP (RB there)))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBD shot) (ADVP (RB ahead)) (PP (IN of) (NP (PRP me))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="11" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="to just hang on" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="just" />
            <token id="5" string="hang" />
            <token id="6" string="on" />
          </tokens>
        </chunking>
        <chunking id="3" string="tried to just hang on , to hang in there" type="VP">
          <tokens>
            <token id="2" string="tried" />
            <token id="3" string="to" />
            <token id="4" string="just" />
            <token id="5" string="hang" />
            <token id="6" string="on" />
            <token id="7" string="," />
            <token id="8" string="to" />
            <token id="9" string="hang" />
            <token id="10" string="in" />
            <token id="11" string="there" />
          </tokens>
        </chunking>
        <chunking id="4" string="to hang in there" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="hang" />
            <token id="10" string="in" />
            <token id="11" string="there" />
          </tokens>
        </chunking>
        <chunking id="5" string="hang in there" type="VP">
          <tokens>
            <token id="9" string="hang" />
            <token id="10" string="in" />
            <token id="11" string="there" />
          </tokens>
        </chunking>
        <chunking id="6" string="shot ahead of me" type="VP">
          <tokens>
            <token id="15" string="shot" />
            <token id="16" string="ahead" />
            <token id="17" string="of" />
            <token id="18" string="me" />
          </tokens>
        </chunking>
        <chunking id="7" string="me" type="NP">
          <tokens>
            <token id="18" string="me" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="14" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="just hang on" type="VP">
          <tokens>
            <token id="4" string="just" />
            <token id="5" string="hang" />
            <token id="6" string="on" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">tried</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">tried</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">hang</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">hang</governor>
          <dependent id="4">just</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">tried</governor>
          <dependent id="5">hang</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">hang</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">hang</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">tried</governor>
          <dependent id="9">hang</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">there</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">hang</governor>
          <dependent id="11">there</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">tried</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">shot</governor>
          <dependent id="14">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">tried</governor>
          <dependent id="15">shot</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">shot</governor>
          <dependent id="16">ahead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">me</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">shot</governor>
          <dependent id="18">me</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Before Martinez took the lead for good -- a uphill surge at Mile 25 -- it appeared Rosas was hearing footsteps and was looking over his shoulder to see who was gaining on him.</content>
      <tokens>
        <token id="1" string="Before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="lead" lemma="lead" stem="lead" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="uphill" lemma="uphill" stem="uphil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="surge" lemma="surge" stem="surg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Mile" lemma="Mile" stem="mile" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="25" lemma="25" stem="25" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="appeared" lemma="appear" stem="appear" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Rosas" lemma="Rosas" stem="rosa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="hearing" lemma="hear" stem="hear" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="footsteps" lemma="footstep" stem="footstep" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="looking" lemma="look" stem="look" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="shoulder" lemma="shoulder" stem="shoulder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="gaining" lemma="gain" stem="gain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Before) (S (NP (NNP Martinez)) (VP (VBD took) (NP (DT the) (NN lead)) (PP (IN for) (NP (NP (JJ good)) (PRN (: --) (NP (NP (DT a) (JJ uphill) (NN surge)) (PP (IN at) (NP (NNP Mile) (CD 25)))) (: --))))))) (NP (PRP it)) (VP (VP (VBD appeared) (SBAR (S (NP (NNP Rosas)) (VP (VBD was) (VP (VBG hearing) (NP (NNS footsteps))))))) (CC and) (VP (VBD was) (VP (VBG looking) (PP (IN over) (NP (PRP$ his) (NN shoulder) (S (VP (TO to) (VP (VB see) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBG gaining) (PP (IN on) (NP (PRP him))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to see who was gaining on him" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="see" />
            <token id="30" string="who" />
            <token id="31" string="was" />
            <token id="32" string="gaining" />
            <token id="33" string="on" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="appeared Rosas was hearing footsteps" type="VP">
          <tokens>
            <token id="17" string="appeared" />
            <token id="18" string="Rosas" />
            <token id="19" string="was" />
            <token id="20" string="hearing" />
            <token id="21" string="footsteps" />
          </tokens>
        </chunking>
        <chunking id="3" string="his shoulder to see who was gaining on him" type="NP">
          <tokens>
            <token id="26" string="his" />
            <token id="27" string="shoulder" />
            <token id="28" string="to" />
            <token id="29" string="see" />
            <token id="30" string="who" />
            <token id="31" string="was" />
            <token id="32" string="gaining" />
            <token id="33" string="on" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="was hearing footsteps" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="hearing" />
            <token id="21" string="footsteps" />
          </tokens>
        </chunking>
        <chunking id="6" string="looking over his shoulder to see who was gaining on him" type="VP">
          <tokens>
            <token id="24" string="looking" />
            <token id="25" string="over" />
            <token id="26" string="his" />
            <token id="27" string="shoulder" />
            <token id="28" string="to" />
            <token id="29" string="see" />
            <token id="30" string="who" />
            <token id="31" string="was" />
            <token id="32" string="gaining" />
            <token id="33" string="on" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="see who was gaining on him" type="VP">
          <tokens>
            <token id="29" string="see" />
            <token id="30" string="who" />
            <token id="31" string="was" />
            <token id="32" string="gaining" />
            <token id="33" string="on" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="8" string="the lead" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="lead" />
          </tokens>
        </chunking>
        <chunking id="9" string="gaining on him" type="VP">
          <tokens>
            <token id="32" string="gaining" />
            <token id="33" string="on" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="good -- a uphill surge at Mile 25 --" type="NP">
          <tokens>
            <token id="7" string="good" />
            <token id="8" string="--" />
            <token id="9" string="a" />
            <token id="10" string="uphill" />
            <token id="11" string="surge" />
            <token id="12" string="at" />
            <token id="13" string="Mile" />
            <token id="14" string="25" />
            <token id="15" string="--" />
          </tokens>
        </chunking>
        <chunking id="11" string="was looking over his shoulder to see who was gaining on him" type="VP">
          <tokens>
            <token id="23" string="was" />
            <token id="24" string="looking" />
            <token id="25" string="over" />
            <token id="26" string="his" />
            <token id="27" string="shoulder" />
            <token id="28" string="to" />
            <token id="29" string="see" />
            <token id="30" string="who" />
            <token id="31" string="was" />
            <token id="32" string="gaining" />
            <token id="33" string="on" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="took the lead for good -- a uphill surge at Mile 25 --" type="VP">
          <tokens>
            <token id="3" string="took" />
            <token id="4" string="the" />
            <token id="5" string="lead" />
            <token id="6" string="for" />
            <token id="7" string="good" />
            <token id="8" string="--" />
            <token id="9" string="a" />
            <token id="10" string="uphill" />
            <token id="11" string="surge" />
            <token id="12" string="at" />
            <token id="13" string="Mile" />
            <token id="14" string="25" />
            <token id="15" string="--" />
          </tokens>
        </chunking>
        <chunking id="13" string="hearing footsteps" type="VP">
          <tokens>
            <token id="20" string="hearing" />
            <token id="21" string="footsteps" />
          </tokens>
        </chunking>
        <chunking id="14" string="a uphill surge at Mile 25" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="uphill" />
            <token id="11" string="surge" />
            <token id="12" string="at" />
            <token id="13" string="Mile" />
            <token id="14" string="25" />
          </tokens>
        </chunking>
        <chunking id="15" string="Mile 25" type="NP">
          <tokens>
            <token id="13" string="Mile" />
            <token id="14" string="25" />
          </tokens>
        </chunking>
        <chunking id="16" string="Rosas was hearing footsteps" type="SBAR">
          <tokens>
            <token id="18" string="Rosas" />
            <token id="19" string="was" />
            <token id="20" string="hearing" />
            <token id="21" string="footsteps" />
          </tokens>
        </chunking>
        <chunking id="17" string="was gaining on him" type="VP">
          <tokens>
            <token id="31" string="was" />
            <token id="32" string="gaining" />
            <token id="33" string="on" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="18" string="him" type="NP">
          <tokens>
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="19" string="good" type="NP">
          <tokens>
            <token id="7" string="good" />
          </tokens>
        </chunking>
        <chunking id="20" string="footsteps" type="NP">
          <tokens>
            <token id="21" string="footsteps" />
          </tokens>
        </chunking>
        <chunking id="21" string="appeared Rosas was hearing footsteps and was looking over his shoulder to see who was gaining on him" type="VP">
          <tokens>
            <token id="17" string="appeared" />
            <token id="18" string="Rosas" />
            <token id="19" string="was" />
            <token id="20" string="hearing" />
            <token id="21" string="footsteps" />
            <token id="22" string="and" />
            <token id="23" string="was" />
            <token id="24" string="looking" />
            <token id="25" string="over" />
            <token id="26" string="his" />
            <token id="27" string="shoulder" />
            <token id="28" string="to" />
            <token id="29" string="see" />
            <token id="30" string="who" />
            <token id="31" string="was" />
            <token id="32" string="gaining" />
            <token id="33" string="on" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="22" string="Rosas" type="NP">
          <tokens>
            <token id="18" string="Rosas" />
          </tokens>
        </chunking>
        <chunking id="23" string="Before Martinez took the lead for good -- a uphill surge at Mile 25 --" type="SBAR">
          <tokens>
            <token id="1" string="Before" />
            <token id="2" string="Martinez" />
            <token id="3" string="took" />
            <token id="4" string="the" />
            <token id="5" string="lead" />
            <token id="6" string="for" />
            <token id="7" string="good" />
            <token id="8" string="--" />
            <token id="9" string="a" />
            <token id="10" string="uphill" />
            <token id="11" string="surge" />
            <token id="12" string="at" />
            <token id="13" string="Mile" />
            <token id="14" string="25" />
            <token id="15" string="--" />
          </tokens>
        </chunking>
        <chunking id="24" string="who was gaining on him" type="SBAR">
          <tokens>
            <token id="30" string="who" />
            <token id="31" string="was" />
            <token id="32" string="gaining" />
            <token id="33" string="on" />
            <token id="34" string="him" />
          </tokens>
        </chunking>
        <chunking id="25" string="Martinez" type="NP">
          <tokens>
            <token id="2" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="26" string="a uphill surge" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="uphill" />
            <token id="11" string="surge" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">took</governor>
          <dependent id="1">Before</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">took</governor>
          <dependent id="2">Martinez</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">appeared</governor>
          <dependent id="3">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">lead</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">took</governor>
          <dependent id="5">lead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">good</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">took</governor>
          <dependent id="7">good</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">surge</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">surge</governor>
          <dependent id="10">uphill</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">good</governor>
          <dependent id="11">surge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Mile</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">surge</governor>
          <dependent id="13">Mile</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">Mile</governor>
          <dependent id="14">25</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">appeared</governor>
          <dependent id="16">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">appeared</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">hearing</governor>
          <dependent id="18">Rosas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">hearing</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">appeared</governor>
          <dependent id="20">hearing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">hearing</governor>
          <dependent id="21">footsteps</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">appeared</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">looking</governor>
          <dependent id="23">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">appeared</governor>
          <dependent id="24">looking</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">shoulder</governor>
          <dependent id="25">over</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">shoulder</governor>
          <dependent id="26">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">looking</governor>
          <dependent id="27">shoulder</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">see</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="27">shoulder</governor>
          <dependent id="29">see</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">gaining</governor>
          <dependent id="30">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="32">gaining</governor>
          <dependent id="31">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">see</governor>
          <dependent id="32">gaining</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">him</governor>
          <dependent id="33">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">gaining</governor>
          <dependent id="34">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rosas" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Rosas" />
          </tokens>
        </entity>
        <entity id="2" string="25" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="25" />
          </tokens>
        </entity>
        <entity id="3" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Not so, said Rosas.</content>
      <tokens>
        <token id="1" string="Not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Rosas" lemma="Rosas" stem="rosa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Not) (ADVP (RB so)) (, ,) (VP (VBD said) (NP (NNP Rosas))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Rosas" type="NP">
          <tokens>
            <token id="5" string="Rosas" />
          </tokens>
        </chunking>
        <chunking id="2" string="said Rosas" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="Rosas" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="4">said</governor>
          <dependent id="1">Not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">said</governor>
          <dependent id="2">so</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">said</governor>
          <dependent id="5">Rosas</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rosas" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Rosas" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>&amp;quot;The police on the bikes were telling me how close he was,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="bikes" lemma="bike" stem="bike" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="telling" lemma="tell" stem="tell" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="close" lemma="close" stem="close" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (DT The) (NN police)) (PP (IN on) (NP (DT the) (NNS bikes)))) (VP (VBD were) (VP (VBG telling) (NP (PRP me)) (SBAR (WHADVP (WRB how)) (S (NP (RB close) (PRP he)) (VP (VBD was))))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the bikes" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="bikes" />
          </tokens>
        </chunking>
        <chunking id="2" string="telling me how close he was" type="VP">
          <tokens>
            <token id="8" string="telling" />
            <token id="9" string="me" />
            <token id="10" string="how" />
            <token id="11" string="close" />
            <token id="12" string="he" />
            <token id="13" string="was" />
          </tokens>
        </chunking>
        <chunking id="3" string="were telling me how close he was" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="telling" />
            <token id="9" string="me" />
            <token id="10" string="how" />
            <token id="11" string="close" />
            <token id="12" string="he" />
            <token id="13" string="was" />
          </tokens>
        </chunking>
        <chunking id="4" string="how close he was" type="SBAR">
          <tokens>
            <token id="10" string="how" />
            <token id="11" string="close" />
            <token id="12" string="he" />
            <token id="13" string="was" />
          </tokens>
        </chunking>
        <chunking id="5" string="close he" type="NP">
          <tokens>
            <token id="11" string="close" />
            <token id="12" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="me" type="NP">
          <tokens>
            <token id="9" string="me" />
          </tokens>
        </chunking>
        <chunking id="7" string="was" type="VP">
          <tokens>
            <token id="13" string="was" />
          </tokens>
        </chunking>
        <chunking id="8" string="The police on the bikes" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="police" />
            <token id="4" string="on" />
            <token id="5" string="the" />
            <token id="6" string="bikes" />
          </tokens>
        </chunking>
        <chunking id="9" string="he" type="NP">
          <tokens>
            <token id="16" string="he" />
          </tokens>
        </chunking>
        <chunking id="10" string="The police" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="police" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="17" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="how" type="WHADVP">
          <tokens>
            <token id="10" string="how" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">police</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">telling</governor>
          <dependent id="3">police</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">bikes</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">bikes</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">police</governor>
          <dependent id="6">bikes</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">telling</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">said</governor>
          <dependent id="8">telling</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">telling</governor>
          <dependent id="9">me</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">was</governor>
          <dependent id="10">how</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">he</governor>
          <dependent id="11">close</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">was</governor>
          <dependent id="12">he</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">telling</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">said</governor>
          <dependent id="16">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>It was the second marathon in two weeks that Kurtis, 38, has run, and almost won.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="5" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="8" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="Kurtis" lemma="Kurtis" stem="kurti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="38" lemma="38" stem="38" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="run" lemma="run" stem="run" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="almost" lemma="almost" stem="almost" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (NP (NP (DT the) (JJ second) (NN marathon)) (PP (IN in) (NP (NP (CD two) (NNS weeks)) (SBAR (WHNP (WDT that)) (S (NP (NP (NNP Kurtis)) (, ,) (NP (CD 38)) (, ,)) (VP (VP (VBZ has) (VP (VBN run))) (, ,) (CC and) (ADVP (RB almost)) (VP (VBD won))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that Kurtis , 38 , has run , and almost won" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="Kurtis" />
            <token id="11" string="," />
            <token id="12" string="38" />
            <token id="13" string="," />
            <token id="14" string="has" />
            <token id="15" string="run" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="almost" />
            <token id="19" string="won" />
          </tokens>
        </chunking>
        <chunking id="2" string="the second marathon" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="second" />
            <token id="5" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="3" string="38" type="NP">
          <tokens>
            <token id="12" string="38" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="run" type="VP">
          <tokens>
            <token id="15" string="run" />
          </tokens>
        </chunking>
        <chunking id="6" string="Kurtis , 38 ," type="NP">
          <tokens>
            <token id="10" string="Kurtis" />
            <token id="11" string="," />
            <token id="12" string="38" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="was the second marathon in two weeks that Kurtis , 38 , has run , and almost won" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="the" />
            <token id="4" string="second" />
            <token id="5" string="marathon" />
            <token id="6" string="in" />
            <token id="7" string="two" />
            <token id="8" string="weeks" />
            <token id="9" string="that" />
            <token id="10" string="Kurtis" />
            <token id="11" string="," />
            <token id="12" string="38" />
            <token id="13" string="," />
            <token id="14" string="has" />
            <token id="15" string="run" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="almost" />
            <token id="19" string="won" />
          </tokens>
        </chunking>
        <chunking id="8" string="the second marathon in two weeks that Kurtis , 38 , has run , and almost won" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="second" />
            <token id="5" string="marathon" />
            <token id="6" string="in" />
            <token id="7" string="two" />
            <token id="8" string="weeks" />
            <token id="9" string="that" />
            <token id="10" string="Kurtis" />
            <token id="11" string="," />
            <token id="12" string="38" />
            <token id="13" string="," />
            <token id="14" string="has" />
            <token id="15" string="run" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="almost" />
            <token id="19" string="won" />
          </tokens>
        </chunking>
        <chunking id="9" string="two weeks" type="NP">
          <tokens>
            <token id="7" string="two" />
            <token id="8" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="10" string="Kurtis" type="NP">
          <tokens>
            <token id="10" string="Kurtis" />
          </tokens>
        </chunking>
        <chunking id="11" string="won" type="VP">
          <tokens>
            <token id="19" string="won" />
          </tokens>
        </chunking>
        <chunking id="12" string="has run" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="run" />
          </tokens>
        </chunking>
        <chunking id="13" string="two weeks that Kurtis , 38 , has run , and almost won" type="NP">
          <tokens>
            <token id="7" string="two" />
            <token id="8" string="weeks" />
            <token id="9" string="that" />
            <token id="10" string="Kurtis" />
            <token id="11" string="," />
            <token id="12" string="38" />
            <token id="13" string="," />
            <token id="14" string="has" />
            <token id="15" string="run" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="almost" />
            <token id="19" string="won" />
          </tokens>
        </chunking>
        <chunking id="14" string="has run , and almost won" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="run" />
            <token id="16" string="," />
            <token id="17" string="and" />
            <token id="18" string="almost" />
            <token id="19" string="won" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">marathon</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">marathon</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">marathon</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">marathon</governor>
          <dependent id="4">second</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">weeks</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">weeks</governor>
          <dependent id="7">two</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">marathon</governor>
          <dependent id="8">weeks</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">run</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">run</governor>
          <dependent id="10">Kurtis</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">Kurtis</governor>
          <dependent id="12">38</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">run</governor>
          <dependent id="14">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">weeks</governor>
          <dependent id="15">run</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">run</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">won</governor>
          <dependent id="18">almost</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">run</governor>
          <dependent id="19">won</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two weeks" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="two" />
            <token id="8" string="weeks" />
          </tokens>
        </entity>
        <entity id="2" string="Kurtis" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Kurtis" />
          </tokens>
        </entity>
        <entity id="3" string="38" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="38" />
          </tokens>
        </entity>
        <entity id="4" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="4" string="second" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>The Bangkok Marathon in November was his 13th of the year, his 112th to date.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Bangkok" lemma="Bangkok" stem="bangkok" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="3" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="November" lemma="November" stem="novemb" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="13th" lemma="13th" stem="13th" pos="NN" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="11" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="112th" lemma="112th" stem="112th" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="date" lemma="date" stem="date" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NNP Bangkok) (NNP Marathon)) (PP (IN in) (NP (NNP November)))) (VP (VBD was) (NP (NP (PRP$ his) (NN 13th)) (PP (IN of) (NP (NP (DT the) (NN year)) (, ,) (NP (NP (PRP$ his) (NN 112th)) (PP (TO to) (NP (NN date)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Bangkok Marathon" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Bangkok" />
            <token id="3" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="2" string="his 112th to date" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="112th" />
            <token id="15" string="to" />
            <token id="16" string="date" />
          </tokens>
        </chunking>
        <chunking id="3" string="date" type="NP">
          <tokens>
            <token id="16" string="date" />
          </tokens>
        </chunking>
        <chunking id="4" string="was his 13th of the year , his 112th to date" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="his" />
            <token id="8" string="13th" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="year" />
            <token id="12" string="," />
            <token id="13" string="his" />
            <token id="14" string="112th" />
            <token id="15" string="to" />
            <token id="16" string="date" />
          </tokens>
        </chunking>
        <chunking id="5" string="The Bangkok Marathon in November" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Bangkok" />
            <token id="3" string="Marathon" />
            <token id="4" string="in" />
            <token id="5" string="November" />
          </tokens>
        </chunking>
        <chunking id="6" string="his 13th of the year , his 112th to date" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="13th" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="year" />
            <token id="12" string="," />
            <token id="13" string="his" />
            <token id="14" string="112th" />
            <token id="15" string="to" />
            <token id="16" string="date" />
          </tokens>
        </chunking>
        <chunking id="7" string="November" type="NP">
          <tokens>
            <token id="5" string="November" />
          </tokens>
        </chunking>
        <chunking id="8" string="his 13th" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="13th" />
          </tokens>
        </chunking>
        <chunking id="9" string="the year" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="year" />
          </tokens>
        </chunking>
        <chunking id="10" string="his 112th" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="112th" />
          </tokens>
        </chunking>
        <chunking id="11" string="the year , his 112th to date" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="year" />
            <token id="12" string="," />
            <token id="13" string="his" />
            <token id="14" string="112th" />
            <token id="15" string="to" />
            <token id="16" string="date" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">Marathon</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Marathon</governor>
          <dependent id="2">Bangkok</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">13th</governor>
          <dependent id="3">Marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">November</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">Marathon</governor>
          <dependent id="5">November</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">13th</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">13th</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">13th</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">year</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">year</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">13th</governor>
          <dependent id="11">year</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">112th</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">year</governor>
          <dependent id="14">112th</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">date</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">112th</governor>
          <dependent id="16">date</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13th" type="ORDINAL" score="0.0">
          <tokens>
            <token id="8" string="13th" />
          </tokens>
        </entity>
        <entity id="2" string="November" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="November" />
          </tokens>
        </entity>
        <entity id="3" string="the year" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="year" />
          </tokens>
        </entity>
        <entity id="4" string="Bangkok Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="2" string="Bangkok" />
            <token id="3" string="Marathon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>The only recurring theme in Martinez&amp;apost; and Smith&amp;apost;s backgrounds -- other than the 26.2 miles they ran -- was that they are novices at long-distance running, this was their first victory at this distance and that they are both teachers.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="recurring" lemma="recur" stem="recur" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="theme" lemma="theme" stem="theme" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="backgrounds" lemma="background" stem="background" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="26.2" lemma="26.2" stem="26.2" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="17" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="19" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="novices" lemma="novice" stem="novic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="long-distance" lemma="long-distance" stem="long-dist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="running" lemma="running" stem="run" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="34" string="victory" lemma="victory" stem="victori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="distance" lemma="distance" stem="distanc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="teachers" lemma="teacher" stem="teacher" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (DT The) (JJ only) (VBG recurring) (NN theme)) (PP (IN in) (NP (NNP Martinez) (POS ')))) (CC and) (NP (NP (NP (NNP Smith) (POS 's)) (NNS backgrounds)) (PRN (: --) (PP (JJ other) (IN than) (NP (NP (DT the) (CD 26.2) (NNS miles)) (SBAR (S (NP (PRP they)) (VP (VBD ran)))))) (: --)))) (VP (VBD was) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP are) (NP (NP (NNS novices)) (PP (IN at) (NP (JJ long-distance) (NN running)))) (, ,) (SBAR (SBAR (S (NP (DT this)) (VP (VBD was) (NP (NP (PRP$ their) (JJ first) (NN victory)) (PP (IN at) (NP (DT this) (NN distance))))))) (CC and) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP are) (NP (DT both) (NNS teachers)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="this was their first victory at this distance" type="SBAR">
          <tokens>
            <token id="30" string="this" />
            <token id="31" string="was" />
            <token id="32" string="their" />
            <token id="33" string="first" />
            <token id="34" string="victory" />
            <token id="35" string="at" />
            <token id="36" string="this" />
            <token id="37" string="distance" />
          </tokens>
        </chunking>
        <chunking id="2" string="this distance" type="NP">
          <tokens>
            <token id="36" string="this" />
            <token id="37" string="distance" />
          </tokens>
        </chunking>
        <chunking id="3" string="Smith 's backgrounds" type="NP">
          <tokens>
            <token id="9" string="Smith" />
            <token id="10" string="'s" />
            <token id="11" string="backgrounds" />
          </tokens>
        </chunking>
        <chunking id="4" string="this was their first victory at this distance and that they are both teachers" type="SBAR">
          <tokens>
            <token id="30" string="this" />
            <token id="31" string="was" />
            <token id="32" string="their" />
            <token id="33" string="first" />
            <token id="34" string="victory" />
            <token id="35" string="at" />
            <token id="36" string="this" />
            <token id="37" string="distance" />
            <token id="38" string="and" />
            <token id="39" string="that" />
            <token id="40" string="they" />
            <token id="41" string="are" />
            <token id="42" string="both" />
            <token id="43" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="5" string="that they are novices at long-distance running , this was their first victory at this distance and that they are both teachers" type="SBAR">
          <tokens>
            <token id="22" string="that" />
            <token id="23" string="they" />
            <token id="24" string="are" />
            <token id="25" string="novices" />
            <token id="26" string="at" />
            <token id="27" string="long-distance" />
            <token id="28" string="running" />
            <token id="29" string="," />
            <token id="30" string="this" />
            <token id="31" string="was" />
            <token id="32" string="their" />
            <token id="33" string="first" />
            <token id="34" string="victory" />
            <token id="35" string="at" />
            <token id="36" string="this" />
            <token id="37" string="distance" />
            <token id="38" string="and" />
            <token id="39" string="that" />
            <token id="40" string="they" />
            <token id="41" string="are" />
            <token id="42" string="both" />
            <token id="43" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="6" string="this" type="NP">
          <tokens>
            <token id="30" string="this" />
          </tokens>
        </chunking>
        <chunking id="7" string="novices at long-distance running" type="NP">
          <tokens>
            <token id="25" string="novices" />
            <token id="26" string="at" />
            <token id="27" string="long-distance" />
            <token id="28" string="running" />
          </tokens>
        </chunking>
        <chunking id="8" string="both teachers" type="NP">
          <tokens>
            <token id="42" string="both" />
            <token id="43" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="9" string="was their first victory at this distance" type="VP">
          <tokens>
            <token id="31" string="was" />
            <token id="32" string="their" />
            <token id="33" string="first" />
            <token id="34" string="victory" />
            <token id="35" string="at" />
            <token id="36" string="this" />
            <token id="37" string="distance" />
          </tokens>
        </chunking>
        <chunking id="10" string="Smith 's backgrounds -- other than the 26.2 miles they ran --" type="NP">
          <tokens>
            <token id="9" string="Smith" />
            <token id="10" string="'s" />
            <token id="11" string="backgrounds" />
            <token id="12" string="--" />
            <token id="13" string="other" />
            <token id="14" string="than" />
            <token id="15" string="the" />
            <token id="16" string="26.2" />
            <token id="17" string="miles" />
            <token id="18" string="they" />
            <token id="19" string="ran" />
            <token id="20" string="--" />
          </tokens>
        </chunking>
        <chunking id="11" string="their first victory at this distance" type="NP">
          <tokens>
            <token id="32" string="their" />
            <token id="33" string="first" />
            <token id="34" string="victory" />
            <token id="35" string="at" />
            <token id="36" string="this" />
            <token id="37" string="distance" />
          </tokens>
        </chunking>
        <chunking id="12" string="The only recurring theme" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="only" />
            <token id="3" string="recurring" />
            <token id="4" string="theme" />
          </tokens>
        </chunking>
        <chunking id="13" string="Smith 's" type="NP">
          <tokens>
            <token id="9" string="Smith" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="The only recurring theme in Martinez '" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="only" />
            <token id="3" string="recurring" />
            <token id="4" string="theme" />
            <token id="5" string="in" />
            <token id="6" string="Martinez" />
            <token id="7" string="'" />
          </tokens>
        </chunking>
        <chunking id="15" string="long-distance running" type="NP">
          <tokens>
            <token id="27" string="long-distance" />
            <token id="28" string="running" />
          </tokens>
        </chunking>
        <chunking id="16" string="they ran" type="SBAR">
          <tokens>
            <token id="18" string="they" />
            <token id="19" string="ran" />
          </tokens>
        </chunking>
        <chunking id="17" string="that they are both teachers" type="SBAR">
          <tokens>
            <token id="39" string="that" />
            <token id="40" string="they" />
            <token id="41" string="are" />
            <token id="42" string="both" />
            <token id="43" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="18" string="are novices at long-distance running , this was their first victory at this distance and that they are both teachers" type="VP">
          <tokens>
            <token id="24" string="are" />
            <token id="25" string="novices" />
            <token id="26" string="at" />
            <token id="27" string="long-distance" />
            <token id="28" string="running" />
            <token id="29" string="," />
            <token id="30" string="this" />
            <token id="31" string="was" />
            <token id="32" string="their" />
            <token id="33" string="first" />
            <token id="34" string="victory" />
            <token id="35" string="at" />
            <token id="36" string="this" />
            <token id="37" string="distance" />
            <token id="38" string="and" />
            <token id="39" string="that" />
            <token id="40" string="they" />
            <token id="41" string="are" />
            <token id="42" string="both" />
            <token id="43" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="19" string="they" type="NP">
          <tokens>
            <token id="18" string="they" />
          </tokens>
        </chunking>
        <chunking id="20" string="the 26.2 miles they ran" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="26.2" />
            <token id="17" string="miles" />
            <token id="18" string="they" />
            <token id="19" string="ran" />
          </tokens>
        </chunking>
        <chunking id="21" string="are both teachers" type="VP">
          <tokens>
            <token id="41" string="are" />
            <token id="42" string="both" />
            <token id="43" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="22" string="was that they are novices at long-distance running , this was their first victory at this distance and that they are both teachers" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="that" />
            <token id="23" string="they" />
            <token id="24" string="are" />
            <token id="25" string="novices" />
            <token id="26" string="at" />
            <token id="27" string="long-distance" />
            <token id="28" string="running" />
            <token id="29" string="," />
            <token id="30" string="this" />
            <token id="31" string="was" />
            <token id="32" string="their" />
            <token id="33" string="first" />
            <token id="34" string="victory" />
            <token id="35" string="at" />
            <token id="36" string="this" />
            <token id="37" string="distance" />
            <token id="38" string="and" />
            <token id="39" string="that" />
            <token id="40" string="they" />
            <token id="41" string="are" />
            <token id="42" string="both" />
            <token id="43" string="teachers" />
          </tokens>
        </chunking>
        <chunking id="23" string="their first victory" type="NP">
          <tokens>
            <token id="32" string="their" />
            <token id="33" string="first" />
            <token id="34" string="victory" />
          </tokens>
        </chunking>
        <chunking id="24" string="The only recurring theme in Martinez ' and Smith 's backgrounds -- other than the 26.2 miles they ran --" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="only" />
            <token id="3" string="recurring" />
            <token id="4" string="theme" />
            <token id="5" string="in" />
            <token id="6" string="Martinez" />
            <token id="7" string="'" />
            <token id="8" string="and" />
            <token id="9" string="Smith" />
            <token id="10" string="'s" />
            <token id="11" string="backgrounds" />
            <token id="12" string="--" />
            <token id="13" string="other" />
            <token id="14" string="than" />
            <token id="15" string="the" />
            <token id="16" string="26.2" />
            <token id="17" string="miles" />
            <token id="18" string="they" />
            <token id="19" string="ran" />
            <token id="20" string="--" />
          </tokens>
        </chunking>
        <chunking id="25" string="novices" type="NP">
          <tokens>
            <token id="25" string="novices" />
          </tokens>
        </chunking>
        <chunking id="26" string="the 26.2 miles" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="26.2" />
            <token id="17" string="miles" />
          </tokens>
        </chunking>
        <chunking id="27" string="Martinez '" type="NP">
          <tokens>
            <token id="6" string="Martinez" />
            <token id="7" string="'" />
          </tokens>
        </chunking>
        <chunking id="28" string="ran" type="VP">
          <tokens>
            <token id="19" string="ran" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">theme</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">theme</governor>
          <dependent id="2">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">theme</governor>
          <dependent id="3">recurring</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">was</governor>
          <dependent id="4">theme</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Martinez</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">theme</governor>
          <dependent id="6">Martinez</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Martinez</governor>
          <dependent id="7">'</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">theme</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">backgrounds</governor>
          <dependent id="9">Smith</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Smith</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">theme</governor>
          <dependent id="11">backgrounds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">miles</governor>
          <dependent id="13">other</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">miles</governor>
          <dependent id="14">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">miles</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">miles</governor>
          <dependent id="16">26.2</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">backgrounds</governor>
          <dependent id="17">miles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">ran</governor>
          <dependent id="18">they</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">miles</governor>
          <dependent id="19">ran</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">novices</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">novices</governor>
          <dependent id="23">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">novices</governor>
          <dependent id="24">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">was</governor>
          <dependent id="25">novices</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">running</governor>
          <dependent id="26">at</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">running</governor>
          <dependent id="27">long-distance</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">novices</governor>
          <dependent id="28">running</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">victory</governor>
          <dependent id="30">this</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="34">victory</governor>
          <dependent id="31">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">victory</governor>
          <dependent id="32">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">victory</governor>
          <dependent id="33">first</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">novices</governor>
          <dependent id="34">victory</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">distance</governor>
          <dependent id="35">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">distance</governor>
          <dependent id="36">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">victory</governor>
          <dependent id="37">distance</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="34">victory</governor>
          <dependent id="38">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="43">teachers</governor>
          <dependent id="39">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="43">teachers</governor>
          <dependent id="40">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="43">teachers</governor>
          <dependent id="41">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">teachers</governor>
          <dependent id="42">both</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">victory</governor>
          <dependent id="43">teachers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="26.2" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="26.2" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="33" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Smith" />
          </tokens>
        </entity>
        <entity id="4" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Martinez is a world-class biathlete who finished third at the World Duathlon Championship two weeks ago near Palm Springs.</content>
      <tokens>
        <token id="1" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="world-class" lemma="world-class" stem="world-class" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="biathlete" lemma="biathlete" stem="biathlet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="third" lemma="third" stem="third" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="World" lemma="World" stem="world" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="12" string="Duathlon" lemma="Duathlon" stem="duathlon" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="Championship" lemma="Championship" stem="championship" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="14" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="15" string="weeks" lemma="week" stem="week" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="16" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Palm" lemma="Palm" stem="palm" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="Springs" lemma="Springs" stem="spring" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Martinez)) (VP (VBZ is) (NP (NP (DT a) (JJ world-class) (NN biathlete)) (SBAR (WHNP (WP who)) (S (VP (VBD finished) (ADVP (RB third) (PP (IN at) (NP (DT the) (NNP World) (NNP Duathlon) (NNP Championship)) (ADVP (NP (CD two) (NNS weeks)) (RB ago)))) (PP (IN near) (NP (NNP Palm) (NNP Springs)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="finished third at the World Duathlon Championship two weeks ago near Palm Springs" type="VP">
          <tokens>
            <token id="7" string="finished" />
            <token id="8" string="third" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="World" />
            <token id="12" string="Duathlon" />
            <token id="13" string="Championship" />
            <token id="14" string="two" />
            <token id="15" string="weeks" />
            <token id="16" string="ago" />
            <token id="17" string="near" />
            <token id="18" string="Palm" />
            <token id="19" string="Springs" />
          </tokens>
        </chunking>
        <chunking id="2" string="two weeks" type="NP">
          <tokens>
            <token id="14" string="two" />
            <token id="15" string="weeks" />
          </tokens>
        </chunking>
        <chunking id="3" string="a world-class biathlete" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="world-class" />
            <token id="5" string="biathlete" />
          </tokens>
        </chunking>
        <chunking id="4" string="a world-class biathlete who finished third at the World Duathlon Championship two weeks ago near Palm Springs" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="world-class" />
            <token id="5" string="biathlete" />
            <token id="6" string="who" />
            <token id="7" string="finished" />
            <token id="8" string="third" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="World" />
            <token id="12" string="Duathlon" />
            <token id="13" string="Championship" />
            <token id="14" string="two" />
            <token id="15" string="weeks" />
            <token id="16" string="ago" />
            <token id="17" string="near" />
            <token id="18" string="Palm" />
            <token id="19" string="Springs" />
          </tokens>
        </chunking>
        <chunking id="5" string="who finished third at the World Duathlon Championship two weeks ago near Palm Springs" type="SBAR">
          <tokens>
            <token id="6" string="who" />
            <token id="7" string="finished" />
            <token id="8" string="third" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="World" />
            <token id="12" string="Duathlon" />
            <token id="13" string="Championship" />
            <token id="14" string="two" />
            <token id="15" string="weeks" />
            <token id="16" string="ago" />
            <token id="17" string="near" />
            <token id="18" string="Palm" />
            <token id="19" string="Springs" />
          </tokens>
        </chunking>
        <chunking id="6" string="is a world-class biathlete who finished third at the World Duathlon Championship two weeks ago near Palm Springs" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="world-class" />
            <token id="5" string="biathlete" />
            <token id="6" string="who" />
            <token id="7" string="finished" />
            <token id="8" string="third" />
            <token id="9" string="at" />
            <token id="10" string="the" />
            <token id="11" string="World" />
            <token id="12" string="Duathlon" />
            <token id="13" string="Championship" />
            <token id="14" string="two" />
            <token id="15" string="weeks" />
            <token id="16" string="ago" />
            <token id="17" string="near" />
            <token id="18" string="Palm" />
            <token id="19" string="Springs" />
          </tokens>
        </chunking>
        <chunking id="7" string="the World Duathlon Championship" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="World" />
            <token id="12" string="Duathlon" />
            <token id="13" string="Championship" />
          </tokens>
        </chunking>
        <chunking id="8" string="Martinez" type="NP">
          <tokens>
            <token id="1" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="9" string="Palm Springs" type="NP">
          <tokens>
            <token id="18" string="Palm" />
            <token id="19" string="Springs" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">biathlete</governor>
          <dependent id="1">Martinez</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">biathlete</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">biathlete</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">biathlete</governor>
          <dependent id="4">world-class</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">biathlete</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">finished</governor>
          <dependent id="6">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">biathlete</governor>
          <dependent id="7">finished</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">finished</governor>
          <dependent id="8">third</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Championship</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Championship</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Championship</governor>
          <dependent id="11">World</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Championship</governor>
          <dependent id="12">Duathlon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">third</governor>
          <dependent id="13">Championship</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">weeks</governor>
          <dependent id="14">two</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="16">ago</governor>
          <dependent id="15">weeks</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">Championship</governor>
          <dependent id="16">ago</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Springs</governor>
          <dependent id="17">near</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Springs</governor>
          <dependent id="18">Palm</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">finished</governor>
          <dependent id="19">Springs</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two weeks ago" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="two" />
            <token id="15" string="weeks" />
            <token id="16" string="ago" />
          </tokens>
        </entity>
        <entity id="2" string="third" type="ORDINAL" score="0.0">
          <tokens>
            <token id="8" string="third" />
          </tokens>
        </entity>
        <entity id="3" string="World Duathlon Championship" type="MISC" score="0.0">
          <tokens>
            <token id="11" string="World" />
            <token id="12" string="Duathlon" />
            <token id="13" string="Championship" />
          </tokens>
        </entity>
        <entity id="4" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Martinez" />
          </tokens>
        </entity>
        <entity id="5" string="Palm Springs" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Palm" />
            <token id="19" string="Springs" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>He has run only two marathons before Sunday.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="run" lemma="run" stem="run" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="marathons" lemma="marathon" stem="marathon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBZ has) (VP (VBN run) (ADVP (RB only) (NP (CD two) (NNS marathons)) (PP (IN before) (NP-TMP (NNP Sunday)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="run only two marathons before Sunday" type="VP">
          <tokens>
            <token id="3" string="run" />
            <token id="4" string="only" />
            <token id="5" string="two" />
            <token id="6" string="marathons" />
            <token id="7" string="before" />
            <token id="8" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="2" string="two marathons" type="NP">
          <tokens>
            <token id="5" string="two" />
            <token id="6" string="marathons" />
          </tokens>
        </chunking>
        <chunking id="3" string="has run only two marathons before Sunday" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="run" />
            <token id="4" string="only" />
            <token id="5" string="two" />
            <token id="6" string="marathons" />
            <token id="7" string="before" />
            <token id="8" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="4" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">run</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">run</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">run</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">run</governor>
          <dependent id="4">only</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">marathons</governor>
          <dependent id="5">two</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="4">only</governor>
          <dependent id="6">marathons</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Sunday</governor>
          <dependent id="7">before</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">only</governor>
          <dependent id="8">Sunday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="Sunday" />
          </tokens>
        </entity>
        <entity id="2" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>He teaches physical education in his hometown, 10-15 miles outside of Mexico City.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="teaches" lemma="teach" stem="teach" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="physical" lemma="physical" stem="physic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="education" lemma="education" stem="educ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="hometown" lemma="hometown" stem="hometown" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="10-15" lemma="10-15" stem="10-15" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="10" string="miles" lemma="mile" stem="mile" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="outside" lemma="outside" stem="outsid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Mexico" lemma="Mexico" stem="mexico" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="City" lemma="City" stem="citi" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBZ teaches) (NP (NP (NP (NP (JJ physical) (NN education)) (PP (IN in) (NP (PRP$ his) (NN hometown)))) (, ,) (ADVP (NP (CD 10-15) (NNS miles)) (IN outside))) (PP (IN of) (NP (NNP Mexico) (NNP City))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="physical education" type="NP">
          <tokens>
            <token id="3" string="physical" />
            <token id="4" string="education" />
          </tokens>
        </chunking>
        <chunking id="2" string="physical education in his hometown , 10-15 miles outside" type="NP">
          <tokens>
            <token id="3" string="physical" />
            <token id="4" string="education" />
            <token id="5" string="in" />
            <token id="6" string="his" />
            <token id="7" string="hometown" />
            <token id="8" string="," />
            <token id="9" string="10-15" />
            <token id="10" string="miles" />
            <token id="11" string="outside" />
          </tokens>
        </chunking>
        <chunking id="3" string="physical education in his hometown" type="NP">
          <tokens>
            <token id="3" string="physical" />
            <token id="4" string="education" />
            <token id="5" string="in" />
            <token id="6" string="his" />
            <token id="7" string="hometown" />
          </tokens>
        </chunking>
        <chunking id="4" string="his hometown" type="NP">
          <tokens>
            <token id="6" string="his" />
            <token id="7" string="hometown" />
          </tokens>
        </chunking>
        <chunking id="5" string="teaches physical education in his hometown , 10-15 miles outside of Mexico City" type="VP">
          <tokens>
            <token id="2" string="teaches" />
            <token id="3" string="physical" />
            <token id="4" string="education" />
            <token id="5" string="in" />
            <token id="6" string="his" />
            <token id="7" string="hometown" />
            <token id="8" string="," />
            <token id="9" string="10-15" />
            <token id="10" string="miles" />
            <token id="11" string="outside" />
            <token id="12" string="of" />
            <token id="13" string="Mexico" />
            <token id="14" string="City" />
          </tokens>
        </chunking>
        <chunking id="6" string="physical education in his hometown , 10-15 miles outside of Mexico City" type="NP">
          <tokens>
            <token id="3" string="physical" />
            <token id="4" string="education" />
            <token id="5" string="in" />
            <token id="6" string="his" />
            <token id="7" string="hometown" />
            <token id="8" string="," />
            <token id="9" string="10-15" />
            <token id="10" string="miles" />
            <token id="11" string="outside" />
            <token id="12" string="of" />
            <token id="13" string="Mexico" />
            <token id="14" string="City" />
          </tokens>
        </chunking>
        <chunking id="7" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="8" string="10-15 miles" type="NP">
          <tokens>
            <token id="9" string="10-15" />
            <token id="10" string="miles" />
          </tokens>
        </chunking>
        <chunking id="9" string="Mexico City" type="NP">
          <tokens>
            <token id="13" string="Mexico" />
            <token id="14" string="City" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">teaches</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">teaches</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">education</governor>
          <dependent id="3">physical</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">teaches</governor>
          <dependent id="4">education</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">hometown</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="7">hometown</governor>
          <dependent id="6">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">education</governor>
          <dependent id="7">hometown</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">miles</governor>
          <dependent id="9">10-15</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">education</governor>
          <dependent id="10">miles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">miles</governor>
          <dependent id="11">outside</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">City</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">City</governor>
          <dependent id="13">Mexico</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">education</governor>
          <dependent id="14">City</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="10-15" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="10-15" />
          </tokens>
        </entity>
        <entity id="2" string="Mexico City" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Mexico" />
            <token id="14" string="City" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Smith, 24, was a 5,000- and 10,000-meter specialist at Stanford but is now focusing on longer distances.</content>
      <tokens>
        <token id="1" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="5,000" lemma="5,000" stem="5,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="10,000-meter" lemma="10,000-meter" stem="10,000-meter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="specialist" lemma="specialist" stem="specialist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Stanford" lemma="Stanford" stem="stanford" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="focusing" lemma="focus" stem="focus" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="longer" lemma="longer" stem="longer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="distances" lemma="distance" stem="distanc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Smith)) (, ,) (NP (CD 24)) (, ,)) (VP (VP (VBD was) (NP (NP (DT a) (CD 5,000)) (: -) (CC and) (NP (JJ 10,000-meter) (NN specialist))) (PP (IN at) (NP (NNP Stanford)))) (CC but) (VP (VBZ is) (ADVP (RB now)) (VP (VBG focusing) (PP (IN on) (NP (JJR longer) (NNS distances)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Stanford" type="NP">
          <tokens>
            <token id="13" string="Stanford" />
          </tokens>
        </chunking>
        <chunking id="2" string="24" type="NP">
          <tokens>
            <token id="3" string="24" />
          </tokens>
        </chunking>
        <chunking id="3" string="10,000-meter specialist" type="NP">
          <tokens>
            <token id="10" string="10,000-meter" />
            <token id="11" string="specialist" />
          </tokens>
        </chunking>
        <chunking id="4" string="Smith , 24 ," type="NP">
          <tokens>
            <token id="1" string="Smith" />
            <token id="2" string="," />
            <token id="3" string="24" />
            <token id="4" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="Smith" type="NP">
          <tokens>
            <token id="1" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="6" string="was a 5,000 - and 10,000-meter specialist at Stanford but is now focusing on longer distances" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="5,000" />
            <token id="8" string="-" />
            <token id="9" string="and" />
            <token id="10" string="10,000-meter" />
            <token id="11" string="specialist" />
            <token id="12" string="at" />
            <token id="13" string="Stanford" />
            <token id="14" string="but" />
            <token id="15" string="is" />
            <token id="16" string="now" />
            <token id="17" string="focusing" />
            <token id="18" string="on" />
            <token id="19" string="longer" />
            <token id="20" string="distances" />
          </tokens>
        </chunking>
        <chunking id="7" string="was a 5,000 - and 10,000-meter specialist at Stanford" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="a" />
            <token id="7" string="5,000" />
            <token id="8" string="-" />
            <token id="9" string="and" />
            <token id="10" string="10,000-meter" />
            <token id="11" string="specialist" />
            <token id="12" string="at" />
            <token id="13" string="Stanford" />
          </tokens>
        </chunking>
        <chunking id="8" string="longer distances" type="NP">
          <tokens>
            <token id="19" string="longer" />
            <token id="20" string="distances" />
          </tokens>
        </chunking>
        <chunking id="9" string="is now focusing on longer distances" type="VP">
          <tokens>
            <token id="15" string="is" />
            <token id="16" string="now" />
            <token id="17" string="focusing" />
            <token id="18" string="on" />
            <token id="19" string="longer" />
            <token id="20" string="distances" />
          </tokens>
        </chunking>
        <chunking id="10" string="a 5,000 - and 10,000-meter specialist" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="5,000" />
            <token id="8" string="-" />
            <token id="9" string="and" />
            <token id="10" string="10,000-meter" />
            <token id="11" string="specialist" />
          </tokens>
        </chunking>
        <chunking id="11" string="focusing on longer distances" type="VP">
          <tokens>
            <token id="17" string="focusing" />
            <token id="18" string="on" />
            <token id="19" string="longer" />
            <token id="20" string="distances" />
          </tokens>
        </chunking>
        <chunking id="12" string="a 5,000" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="5,000" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">5,000</governor>
          <dependent id="1">Smith</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="1">Smith</governor>
          <dependent id="3">24</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">5,000</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">5,000</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">5,000</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">5,000</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">specialist</governor>
          <dependent id="10">10,000-meter</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">5,000</governor>
          <dependent id="11">specialist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Stanford</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">5,000</governor>
          <dependent id="13">Stanford</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">5,000</governor>
          <dependent id="14">but</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">focusing</governor>
          <dependent id="15">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">focusing</governor>
          <dependent id="16">now</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">5,000</governor>
          <dependent id="17">focusing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">distances</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">distances</governor>
          <dependent id="19">longer</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">focusing</governor>
          <dependent id="20">distances</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Stanford" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="13" string="Stanford" />
          </tokens>
        </entity>
        <entity id="2" string="24" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="24" />
          </tokens>
        </entity>
        <entity id="3" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="now" />
          </tokens>
        </entity>
        <entity id="4" string="Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Smith" />
          </tokens>
        </entity>
        <entity id="5" string="5,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="5,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>She is a fourth- through sixth-grade teacher at College Park in Irvine.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="fourth" lemma="fourth" stem="fourth" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="5" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="sixth-grade" lemma="sixth-grade" stem="sixth-grad" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="teacher" lemma="teacher" stem="teacher" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="College" lemma="College" stem="colleg" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Park" lemma="Park" stem="park" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Irvine" lemma="Irvine" stem="irvine" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBZ is) (NP (NP (DT a) (ADJP (ADJP (JJ fourth) (: -) (PP (IN through) (NP (JJ sixth-grade) (NN teacher)))) (PP (IN at) (NP (NNP College) (NNP Park))))) (PP (IN in) (NP (NNP Irvine))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a fourth - through sixth-grade teacher at College Park in Irvine" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="fourth" />
            <token id="5" string="-" />
            <token id="6" string="through" />
            <token id="7" string="sixth-grade" />
            <token id="8" string="teacher" />
            <token id="9" string="at" />
            <token id="10" string="College" />
            <token id="11" string="Park" />
            <token id="12" string="in" />
            <token id="13" string="Irvine" />
          </tokens>
        </chunking>
        <chunking id="2" string="a fourth - through sixth-grade teacher at College Park" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="fourth" />
            <token id="5" string="-" />
            <token id="6" string="through" />
            <token id="7" string="sixth-grade" />
            <token id="8" string="teacher" />
            <token id="9" string="at" />
            <token id="10" string="College" />
            <token id="11" string="Park" />
          </tokens>
        </chunking>
        <chunking id="3" string="fourth - through sixth-grade teacher at College Park" type="ADJP">
          <tokens>
            <token id="4" string="fourth" />
            <token id="5" string="-" />
            <token id="6" string="through" />
            <token id="7" string="sixth-grade" />
            <token id="8" string="teacher" />
            <token id="9" string="at" />
            <token id="10" string="College" />
            <token id="11" string="Park" />
          </tokens>
        </chunking>
        <chunking id="4" string="fourth - through sixth-grade teacher" type="ADJP">
          <tokens>
            <token id="4" string="fourth" />
            <token id="5" string="-" />
            <token id="6" string="through" />
            <token id="7" string="sixth-grade" />
            <token id="8" string="teacher" />
          </tokens>
        </chunking>
        <chunking id="5" string="sixth-grade teacher" type="NP">
          <tokens>
            <token id="7" string="sixth-grade" />
            <token id="8" string="teacher" />
          </tokens>
        </chunking>
        <chunking id="6" string="Irvine" type="NP">
          <tokens>
            <token id="13" string="Irvine" />
          </tokens>
        </chunking>
        <chunking id="7" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="8" string="is a fourth - through sixth-grade teacher at College Park in Irvine" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="fourth" />
            <token id="5" string="-" />
            <token id="6" string="through" />
            <token id="7" string="sixth-grade" />
            <token id="8" string="teacher" />
            <token id="9" string="at" />
            <token id="10" string="College" />
            <token id="11" string="Park" />
            <token id="12" string="in" />
            <token id="13" string="Irvine" />
          </tokens>
        </chunking>
        <chunking id="9" string="College Park" type="NP">
          <tokens>
            <token id="10" string="College" />
            <token id="11" string="Park" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">fourth</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">fourth</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">fourth</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">fourth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">teacher</governor>
          <dependent id="6">through</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">teacher</governor>
          <dependent id="7">sixth-grade</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">fourth</governor>
          <dependent id="8">teacher</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Park</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Park</governor>
          <dependent id="10">College</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">fourth</governor>
          <dependent id="11">Park</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Irvine</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">fourth</governor>
          <dependent id="13">Irvine</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="fourth" type="ORDINAL" score="0.0">
          <tokens>
            <token id="4" string="fourth" />
          </tokens>
        </entity>
        <entity id="2" string="Irvine" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Irvine" />
          </tokens>
        </entity>
        <entity id="3" string="College Park" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="College" />
            <token id="11" string="Park" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>She was holding class with reporters long before Ireland, 39, was carried into a room for mandatory drug testing -- the United States Olympic Committee Drug Testing Program randomly selected this race to administer tests to the top finishers.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="holding" lemma="hold" stem="hold" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="class" lemma="class" stem="class" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Ireland" lemma="Ireland" stem="ireland" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="39" lemma="39" stem="39" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="carried" lemma="carry" stem="carri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="mandatory" lemma="mandatory" stem="mandatori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="testing" lemma="testing" stem="test" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="States" lemma="States" stem="state" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="26" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="27" string="Committee" lemma="Committee" stem="committe" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="28" string="Drug" lemma="Drug" stem="drug" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="Testing" lemma="Testing" stem="test" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="30" string="Program" lemma="Program" stem="program" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="31" string="randomly" lemma="randomly" stem="randomli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="selected" lemma="select" stem="select" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="administer" lemma="administer" stem="administ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="tests" lemma="test" stem="test" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="top" lemma="top" stem="top" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="finishers" lemma="finisher" stem="finish" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP She)) (VP (VBD was) (VP (VBG holding) (NP (NN class)) (PP (IN with) (NP (NNS reporters))) (SBAR (RB long) (IN before) (S (NP (NP (NNP Ireland)) (, ,) (NP (CD 39)) (, ,)) (VP (VBD was) (VP (VBN carried) (PP (IN into) (NP (NP (DT a) (NN room)) (PP (IN for) (NP (JJ mandatory) (NN drug) (NN testing)))))))))))) (: --) (S (NP (DT the) (NNP United) (NNP States) (NNP Olympic) (NNP Committee) (NNP Drug) (NNP Testing) (NNP Program)) (ADVP (RB randomly)) (VP (VBD selected) (NP (DT this) (NN race) (S (VP (TO to) (VP (VB administer) (NP (NNS tests)) (PP (TO to) (NP (DT the) (JJ top) (NNS finishers))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reporters" type="NP">
          <tokens>
            <token id="6" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="2" string="holding class with reporters long before Ireland , 39 , was carried into a room for mandatory drug testing" type="VP">
          <tokens>
            <token id="3" string="holding" />
            <token id="4" string="class" />
            <token id="5" string="with" />
            <token id="6" string="reporters" />
            <token id="7" string="long" />
            <token id="8" string="before" />
            <token id="9" string="Ireland" />
            <token id="10" string="," />
            <token id="11" string="39" />
            <token id="12" string="," />
            <token id="13" string="was" />
            <token id="14" string="carried" />
            <token id="15" string="into" />
            <token id="16" string="a" />
            <token id="17" string="room" />
            <token id="18" string="for" />
            <token id="19" string="mandatory" />
            <token id="20" string="drug" />
            <token id="21" string="testing" />
          </tokens>
        </chunking>
        <chunking id="3" string="this race to administer tests to the top finishers" type="NP">
          <tokens>
            <token id="33" string="this" />
            <token id="34" string="race" />
            <token id="35" string="to" />
            <token id="36" string="administer" />
            <token id="37" string="tests" />
            <token id="38" string="to" />
            <token id="39" string="the" />
            <token id="40" string="top" />
            <token id="41" string="finishers" />
          </tokens>
        </chunking>
        <chunking id="4" string="39" type="NP">
          <tokens>
            <token id="11" string="39" />
          </tokens>
        </chunking>
        <chunking id="5" string="a room" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="room" />
          </tokens>
        </chunking>
        <chunking id="6" string="a room for mandatory drug testing" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="room" />
            <token id="18" string="for" />
            <token id="19" string="mandatory" />
            <token id="20" string="drug" />
            <token id="21" string="testing" />
          </tokens>
        </chunking>
        <chunking id="7" string="administer tests to the top finishers" type="VP">
          <tokens>
            <token id="36" string="administer" />
            <token id="37" string="tests" />
            <token id="38" string="to" />
            <token id="39" string="the" />
            <token id="40" string="top" />
            <token id="41" string="finishers" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="9" string="carried into a room for mandatory drug testing" type="VP">
          <tokens>
            <token id="14" string="carried" />
            <token id="15" string="into" />
            <token id="16" string="a" />
            <token id="17" string="room" />
            <token id="18" string="for" />
            <token id="19" string="mandatory" />
            <token id="20" string="drug" />
            <token id="21" string="testing" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ireland , 39 ," type="NP">
          <tokens>
            <token id="9" string="Ireland" />
            <token id="10" string="," />
            <token id="11" string="39" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="mandatory drug testing" type="NP">
          <tokens>
            <token id="19" string="mandatory" />
            <token id="20" string="drug" />
            <token id="21" string="testing" />
          </tokens>
        </chunking>
        <chunking id="12" string="was holding class with reporters long before Ireland , 39 , was carried into a room for mandatory drug testing" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="holding" />
            <token id="4" string="class" />
            <token id="5" string="with" />
            <token id="6" string="reporters" />
            <token id="7" string="long" />
            <token id="8" string="before" />
            <token id="9" string="Ireland" />
            <token id="10" string="," />
            <token id="11" string="39" />
            <token id="12" string="," />
            <token id="13" string="was" />
            <token id="14" string="carried" />
            <token id="15" string="into" />
            <token id="16" string="a" />
            <token id="17" string="room" />
            <token id="18" string="for" />
            <token id="19" string="mandatory" />
            <token id="20" string="drug" />
            <token id="21" string="testing" />
          </tokens>
        </chunking>
        <chunking id="13" string="class" type="NP">
          <tokens>
            <token id="4" string="class" />
          </tokens>
        </chunking>
        <chunking id="14" string="was carried into a room for mandatory drug testing" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="carried" />
            <token id="15" string="into" />
            <token id="16" string="a" />
            <token id="17" string="room" />
            <token id="18" string="for" />
            <token id="19" string="mandatory" />
            <token id="20" string="drug" />
            <token id="21" string="testing" />
          </tokens>
        </chunking>
        <chunking id="15" string="tests" type="NP">
          <tokens>
            <token id="37" string="tests" />
          </tokens>
        </chunking>
        <chunking id="16" string="the United States Olympic Committee Drug Testing Program" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="United" />
            <token id="25" string="States" />
            <token id="26" string="Olympic" />
            <token id="27" string="Committee" />
            <token id="28" string="Drug" />
            <token id="29" string="Testing" />
            <token id="30" string="Program" />
          </tokens>
        </chunking>
        <chunking id="17" string="to administer tests to the top finishers" type="VP">
          <tokens>
            <token id="35" string="to" />
            <token id="36" string="administer" />
            <token id="37" string="tests" />
            <token id="38" string="to" />
            <token id="39" string="the" />
            <token id="40" string="top" />
            <token id="41" string="finishers" />
          </tokens>
        </chunking>
        <chunking id="18" string="selected this race to administer tests to the top finishers" type="VP">
          <tokens>
            <token id="32" string="selected" />
            <token id="33" string="this" />
            <token id="34" string="race" />
            <token id="35" string="to" />
            <token id="36" string="administer" />
            <token id="37" string="tests" />
            <token id="38" string="to" />
            <token id="39" string="the" />
            <token id="40" string="top" />
            <token id="41" string="finishers" />
          </tokens>
        </chunking>
        <chunking id="19" string="Ireland" type="NP">
          <tokens>
            <token id="9" string="Ireland" />
          </tokens>
        </chunking>
        <chunking id="20" string="long before Ireland , 39 , was carried into a room for mandatory drug testing" type="SBAR">
          <tokens>
            <token id="7" string="long" />
            <token id="8" string="before" />
            <token id="9" string="Ireland" />
            <token id="10" string="," />
            <token id="11" string="39" />
            <token id="12" string="," />
            <token id="13" string="was" />
            <token id="14" string="carried" />
            <token id="15" string="into" />
            <token id="16" string="a" />
            <token id="17" string="room" />
            <token id="18" string="for" />
            <token id="19" string="mandatory" />
            <token id="20" string="drug" />
            <token id="21" string="testing" />
          </tokens>
        </chunking>
        <chunking id="21" string="the top finishers" type="NP">
          <tokens>
            <token id="39" string="the" />
            <token id="40" string="top" />
            <token id="41" string="finishers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">holding</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">holding</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">holding</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">holding</governor>
          <dependent id="4">class</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">reporters</governor>
          <dependent id="5">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">holding</governor>
          <dependent id="6">reporters</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">carried</governor>
          <dependent id="7">long</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">carried</governor>
          <dependent id="8">before</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">carried</governor>
          <dependent id="9">Ireland</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">Ireland</governor>
          <dependent id="11">39</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">carried</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">holding</governor>
          <dependent id="14">carried</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">room</governor>
          <dependent id="15">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">room</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">carried</governor>
          <dependent id="17">room</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">testing</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">testing</governor>
          <dependent id="19">mandatory</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">testing</governor>
          <dependent id="20">drug</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">room</governor>
          <dependent id="21">testing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">Program</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Program</governor>
          <dependent id="24">United</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Program</governor>
          <dependent id="25">States</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Program</governor>
          <dependent id="26">Olympic</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Program</governor>
          <dependent id="27">Committee</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Program</governor>
          <dependent id="28">Drug</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Program</governor>
          <dependent id="29">Testing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">selected</governor>
          <dependent id="30">Program</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="32">selected</governor>
          <dependent id="31">randomly</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">holding</governor>
          <dependent id="32">selected</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">race</governor>
          <dependent id="33">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">selected</governor>
          <dependent id="34">race</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">administer</governor>
          <dependent id="35">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="34">race</governor>
          <dependent id="36">administer</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">administer</governor>
          <dependent id="37">tests</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">finishers</governor>
          <dependent id="38">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">finishers</governor>
          <dependent id="39">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">finishers</governor>
          <dependent id="40">top</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">administer</governor>
          <dependent id="41">finishers</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="United States Olympic Committee Drug Testing Program" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="24" string="United" />
            <token id="25" string="States" />
            <token id="26" string="Olympic" />
            <token id="27" string="Committee" />
            <token id="28" string="Drug" />
            <token id="29" string="Testing" />
            <token id="30" string="Program" />
          </tokens>
        </entity>
        <entity id="2" string="39" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="39" />
          </tokens>
        </entity>
        <entity id="3" string="Ireland" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Ireland" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>&amp;quot;My goal was to come out here, be as low-key as possible and try to qualify for the trials,&amp;quot; said Smith, who finished fourth last year and ran a personal-best time Sunday.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="goal" lemma="goal" stem="goal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="low-key" lemma="low-key" stem="low-kei" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="possible" lemma="possible" stem="possibl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="try" lemma="try" stem="try" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="qualify" lemma="qualify" stem="qualifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="trials" lemma="trial" stem="trial" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="fourth" lemma="fourth" stem="fourth" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="true" />
        <token id="30" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="31" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="personal-best" lemma="personal-best" stem="personal-best" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="Sunday" lemma="Sunday" stem="sundai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP$ My) (NN goal)) (VP (VBD was) (S (VP (TO to) (VP (VP (VB come) (PRT (RP out)) (ADVP (RB here))) (, ,) (VP (VB be) (ADJP (IN as) (JJ low-key) (PP (IN as) (ADJP (JJ possible))))) (CC and) (VP (VB try) (S (VP (TO to) (VP (VB qualify) (PP (IN for) (NP (DT the) (NNS trials)))))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Smith)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VP (VBD finished) (NP-TMP (JJ fourth) (JJ last) (NN year))) (CC and) (VP (VBD ran) (NP (DT a) (JJ personal-best) (NN time)) (NP-TMP (NNP Sunday))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="come out here , be as low-key as possible and try to qualify for the trials" type="VP">
          <tokens>
            <token id="6" string="come" />
            <token id="7" string="out" />
            <token id="8" string="here" />
            <token id="9" string="," />
            <token id="10" string="be" />
            <token id="11" string="as" />
            <token id="12" string="low-key" />
            <token id="13" string="as" />
            <token id="14" string="possible" />
            <token id="15" string="and" />
            <token id="16" string="try" />
            <token id="17" string="to" />
            <token id="18" string="qualify" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="trials" />
          </tokens>
        </chunking>
        <chunking id="2" string="come out here" type="VP">
          <tokens>
            <token id="6" string="come" />
            <token id="7" string="out" />
            <token id="8" string="here" />
          </tokens>
        </chunking>
        <chunking id="3" string="Smith" type="NP">
          <tokens>
            <token id="25" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="4" string="finished fourth last year" type="VP">
          <tokens>
            <token id="28" string="finished" />
            <token id="29" string="fourth" />
            <token id="30" string="last" />
            <token id="31" string="year" />
          </tokens>
        </chunking>
        <chunking id="5" string="as low-key as possible" type="ADJP">
          <tokens>
            <token id="11" string="as" />
            <token id="12" string="low-key" />
            <token id="13" string="as" />
            <token id="14" string="possible" />
          </tokens>
        </chunking>
        <chunking id="6" string="who finished fourth last year and ran a personal-best time Sunday" type="SBAR">
          <tokens>
            <token id="27" string="who" />
            <token id="28" string="finished" />
            <token id="29" string="fourth" />
            <token id="30" string="last" />
            <token id="31" string="year" />
            <token id="32" string="and" />
            <token id="33" string="ran" />
            <token id="34" string="a" />
            <token id="35" string="personal-best" />
            <token id="36" string="time" />
            <token id="37" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="7" string="was to come out here , be as low-key as possible and try to qualify for the trials" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="to" />
            <token id="6" string="come" />
            <token id="7" string="out" />
            <token id="8" string="here" />
            <token id="9" string="," />
            <token id="10" string="be" />
            <token id="11" string="as" />
            <token id="12" string="low-key" />
            <token id="13" string="as" />
            <token id="14" string="possible" />
            <token id="15" string="and" />
            <token id="16" string="try" />
            <token id="17" string="to" />
            <token id="18" string="qualify" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="trials" />
          </tokens>
        </chunking>
        <chunking id="8" string="possible" type="ADJP">
          <tokens>
            <token id="14" string="possible" />
          </tokens>
        </chunking>
        <chunking id="9" string="My goal" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="goal" />
          </tokens>
        </chunking>
        <chunking id="10" string="Smith , who finished fourth last year and ran a personal-best time Sunday" type="NP">
          <tokens>
            <token id="25" string="Smith" />
            <token id="26" string="," />
            <token id="27" string="who" />
            <token id="28" string="finished" />
            <token id="29" string="fourth" />
            <token id="30" string="last" />
            <token id="31" string="year" />
            <token id="32" string="and" />
            <token id="33" string="ran" />
            <token id="34" string="a" />
            <token id="35" string="personal-best" />
            <token id="36" string="time" />
            <token id="37" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="11" string="to come out here , be as low-key as possible and try to qualify for the trials" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="come" />
            <token id="7" string="out" />
            <token id="8" string="here" />
            <token id="9" string="," />
            <token id="10" string="be" />
            <token id="11" string="as" />
            <token id="12" string="low-key" />
            <token id="13" string="as" />
            <token id="14" string="possible" />
            <token id="15" string="and" />
            <token id="16" string="try" />
            <token id="17" string="to" />
            <token id="18" string="qualify" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="trials" />
          </tokens>
        </chunking>
        <chunking id="12" string="finished fourth last year and ran a personal-best time Sunday" type="VP">
          <tokens>
            <token id="28" string="finished" />
            <token id="29" string="fourth" />
            <token id="30" string="last" />
            <token id="31" string="year" />
            <token id="32" string="and" />
            <token id="33" string="ran" />
            <token id="34" string="a" />
            <token id="35" string="personal-best" />
            <token id="36" string="time" />
            <token id="37" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="13" string="qualify for the trials" type="VP">
          <tokens>
            <token id="18" string="qualify" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="trials" />
          </tokens>
        </chunking>
        <chunking id="14" string="the trials" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="trials" />
          </tokens>
        </chunking>
        <chunking id="15" string="try to qualify for the trials" type="VP">
          <tokens>
            <token id="16" string="try" />
            <token id="17" string="to" />
            <token id="18" string="qualify" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="trials" />
          </tokens>
        </chunking>
        <chunking id="16" string="said" type="VP">
          <tokens>
            <token id="24" string="said" />
          </tokens>
        </chunking>
        <chunking id="17" string="a personal-best time" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="personal-best" />
            <token id="36" string="time" />
          </tokens>
        </chunking>
        <chunking id="18" string="be as low-key as possible" type="VP">
          <tokens>
            <token id="10" string="be" />
            <token id="11" string="as" />
            <token id="12" string="low-key" />
            <token id="13" string="as" />
            <token id="14" string="possible" />
          </tokens>
        </chunking>
        <chunking id="19" string="ran a personal-best time Sunday" type="VP">
          <tokens>
            <token id="33" string="ran" />
            <token id="34" string="a" />
            <token id="35" string="personal-best" />
            <token id="36" string="time" />
            <token id="37" string="Sunday" />
          </tokens>
        </chunking>
        <chunking id="20" string="to qualify for the trials" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="qualify" />
            <token id="19" string="for" />
            <token id="20" string="the" />
            <token id="21" string="trials" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">goal</governor>
          <dependent id="2">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">was</governor>
          <dependent id="3">goal</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">said</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">come</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">was</governor>
          <dependent id="6">come</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="6">come</governor>
          <dependent id="7">out</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">come</governor>
          <dependent id="8">here</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">low-key</governor>
          <dependent id="10">be</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">low-key</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">come</governor>
          <dependent id="12">low-key</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">possible</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">low-key</governor>
          <dependent id="14">possible</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">come</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">come</governor>
          <dependent id="16">try</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">qualify</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">try</governor>
          <dependent id="18">qualify</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">trials</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">trials</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">qualify</governor>
          <dependent id="21">trials</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">said</governor>
          <dependent id="25">Smith</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">finished</governor>
          <dependent id="27">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="25">Smith</governor>
          <dependent id="28">finished</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">year</governor>
          <dependent id="29">fourth</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">year</governor>
          <dependent id="30">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="28">finished</governor>
          <dependent id="31">year</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">finished</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">finished</governor>
          <dependent id="33">ran</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">time</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">time</governor>
          <dependent id="35">personal-best</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">ran</governor>
          <dependent id="36">time</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="33">ran</governor>
          <dependent id="37">Sunday</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Smith" />
          </tokens>
        </entity>
        <entity id="2" string="fourth" type="ORDINAL" score="0.0">
          <tokens>
            <token id="29" string="fourth" />
          </tokens>
        </entity>
        <entity id="3" string="Sunday" type="DATE" score="0.0">
          <tokens>
            <token id="37" string="Sunday" />
          </tokens>
        </entity>
        <entity id="4" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="last" />
            <token id="31" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="false">
      <content>She met and beat the Olympic Trials qualifying standard of 2:45.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="met" lemma="meet" stem="met" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="beat" lemma="beat" stem="beat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Olympic" lemma="Olympic" stem="olympic" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="7" string="Trials" lemma="Trials" stem="trial" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="qualifying" lemma="qualify" stem="qualifi" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="standard" lemma="standard" stem="standard" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="2:45" lemma="2:45" stem="2:45" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD met) (CC and) (VBD beat) (NP (NP (DT the) (NNP Olympic) (NNPS Trials)) (VP (VBG qualifying) (NP (NP (NN standard)) (PP (IN of) (NP (CD 2:45))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Olympic Trials" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Olympic" />
            <token id="7" string="Trials" />
          </tokens>
        </chunking>
        <chunking id="2" string="qualifying standard of 2:45" type="VP">
          <tokens>
            <token id="8" string="qualifying" />
            <token id="9" string="standard" />
            <token id="10" string="of" />
            <token id="11" string="2:45" />
          </tokens>
        </chunking>
        <chunking id="3" string="standard" type="NP">
          <tokens>
            <token id="9" string="standard" />
          </tokens>
        </chunking>
        <chunking id="4" string="standard of 2:45" type="NP">
          <tokens>
            <token id="9" string="standard" />
            <token id="10" string="of" />
            <token id="11" string="2:45" />
          </tokens>
        </chunking>
        <chunking id="5" string="met and beat the Olympic Trials qualifying standard of 2:45" type="VP">
          <tokens>
            <token id="2" string="met" />
            <token id="3" string="and" />
            <token id="4" string="beat" />
            <token id="5" string="the" />
            <token id="6" string="Olympic" />
            <token id="7" string="Trials" />
            <token id="8" string="qualifying" />
            <token id="9" string="standard" />
            <token id="10" string="of" />
            <token id="11" string="2:45" />
          </tokens>
        </chunking>
        <chunking id="6" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Olympic Trials qualifying standard of 2:45" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Olympic" />
            <token id="7" string="Trials" />
            <token id="8" string="qualifying" />
            <token id="9" string="standard" />
            <token id="10" string="of" />
            <token id="11" string="2:45" />
          </tokens>
        </chunking>
        <chunking id="8" string="2:45" type="NP">
          <tokens>
            <token id="11" string="2:45" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">met</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">met</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">met</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">met</governor>
          <dependent id="4">beat</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Trials</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Trials</governor>
          <dependent id="6">Olympic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">met</governor>
          <dependent id="7">Trials</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">Trials</governor>
          <dependent id="8">qualifying</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">qualifying</governor>
          <dependent id="9">standard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">2:45</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">standard</governor>
          <dependent id="11">2:45</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Olympic Trials" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="Olympic" />
            <token id="7" string="Trials" />
          </tokens>
        </entity>
        <entity id="2" string="2:45" type="TIME" score="0.0">
          <tokens>
            <token id="11" string="2:45" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Smith said she and Ireland ran together -- they even chatted -- through the 20-mile mark, until Smith got her feet working faster than her mouth.</content>
      <tokens>
        <token id="1" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Ireland" lemma="Ireland" stem="ireland" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="6" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="chatted" lemma="chat" stem="chat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="--" lemma="--" stem="--" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="20-mile" lemma="20-mile" stem="20-mile" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="mark" lemma="mark" stem="mark" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="until" lemma="until" stem="until" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="feet" lemma="foot" stem="feet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="faster" lemma="faster" stem="faster" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="mouth" lemma="mouth" stem="mouth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Smith)) (VP (VBD said) (SBAR (S (NP (PRP she) (CC and) (NNP Ireland)) (VP (VBD ran) (ADJP (RB together)) (PRN (: --) (S (NP (PRP they)) (ADVP (RB even)) (VP (VBD chatted))) (: --)) (PP (IN through) (NP (NP (DT the) (JJ 20-mile) (NN mark)) (, ,) (SBAR (IN until) (S (NP (NNP Smith)) (VP (VBD got) (NP (PRP$ her) (NNS feet)) (S (VP (VBG working) (ADVP (RBR faster)) (PP (IN than) (NP (PRP$ her) (NN mouth)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="until Smith got her feet working faster than her mouth" type="SBAR">
          <tokens>
            <token id="18" string="until" />
            <token id="19" string="Smith" />
            <token id="20" string="got" />
            <token id="21" string="her" />
            <token id="22" string="feet" />
            <token id="23" string="working" />
            <token id="24" string="faster" />
            <token id="25" string="than" />
            <token id="26" string="her" />
            <token id="27" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="2" string="her mouth" type="NP">
          <tokens>
            <token id="26" string="her" />
            <token id="27" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="3" string="working faster than her mouth" type="VP">
          <tokens>
            <token id="23" string="working" />
            <token id="24" string="faster" />
            <token id="25" string="than" />
            <token id="26" string="her" />
            <token id="27" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="4" string="Smith" type="NP">
          <tokens>
            <token id="1" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="5" string="said she and Ireland ran together -- they even chatted -- through the 20-mile mark , until Smith got her feet working faster than her mouth" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="she" />
            <token id="4" string="and" />
            <token id="5" string="Ireland" />
            <token id="6" string="ran" />
            <token id="7" string="together" />
            <token id="8" string="--" />
            <token id="9" string="they" />
            <token id="10" string="even" />
            <token id="11" string="chatted" />
            <token id="12" string="--" />
            <token id="13" string="through" />
            <token id="14" string="the" />
            <token id="15" string="20-mile" />
            <token id="16" string="mark" />
            <token id="17" string="," />
            <token id="18" string="until" />
            <token id="19" string="Smith" />
            <token id="20" string="got" />
            <token id="21" string="her" />
            <token id="22" string="feet" />
            <token id="23" string="working" />
            <token id="24" string="faster" />
            <token id="25" string="than" />
            <token id="26" string="her" />
            <token id="27" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="6" string="she and Ireland ran together -- they even chatted -- through the 20-mile mark , until Smith got her feet working faster than her mouth" type="SBAR">
          <tokens>
            <token id="3" string="she" />
            <token id="4" string="and" />
            <token id="5" string="Ireland" />
            <token id="6" string="ran" />
            <token id="7" string="together" />
            <token id="8" string="--" />
            <token id="9" string="they" />
            <token id="10" string="even" />
            <token id="11" string="chatted" />
            <token id="12" string="--" />
            <token id="13" string="through" />
            <token id="14" string="the" />
            <token id="15" string="20-mile" />
            <token id="16" string="mark" />
            <token id="17" string="," />
            <token id="18" string="until" />
            <token id="19" string="Smith" />
            <token id="20" string="got" />
            <token id="21" string="her" />
            <token id="22" string="feet" />
            <token id="23" string="working" />
            <token id="24" string="faster" />
            <token id="25" string="than" />
            <token id="26" string="her" />
            <token id="27" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="7" string="got her feet working faster than her mouth" type="VP">
          <tokens>
            <token id="20" string="got" />
            <token id="21" string="her" />
            <token id="22" string="feet" />
            <token id="23" string="working" />
            <token id="24" string="faster" />
            <token id="25" string="than" />
            <token id="26" string="her" />
            <token id="27" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="8" string="they" type="NP">
          <tokens>
            <token id="9" string="they" />
          </tokens>
        </chunking>
        <chunking id="9" string="her feet" type="NP">
          <tokens>
            <token id="21" string="her" />
            <token id="22" string="feet" />
          </tokens>
        </chunking>
        <chunking id="10" string="the 20-mile mark , until Smith got her feet working faster than her mouth" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="20-mile" />
            <token id="16" string="mark" />
            <token id="17" string="," />
            <token id="18" string="until" />
            <token id="19" string="Smith" />
            <token id="20" string="got" />
            <token id="21" string="her" />
            <token id="22" string="feet" />
            <token id="23" string="working" />
            <token id="24" string="faster" />
            <token id="25" string="than" />
            <token id="26" string="her" />
            <token id="27" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="11" string="she and Ireland" type="NP">
          <tokens>
            <token id="3" string="she" />
            <token id="4" string="and" />
            <token id="5" string="Ireland" />
          </tokens>
        </chunking>
        <chunking id="12" string="chatted" type="VP">
          <tokens>
            <token id="11" string="chatted" />
          </tokens>
        </chunking>
        <chunking id="13" string="ran together -- they even chatted -- through the 20-mile mark , until Smith got her feet working faster than her mouth" type="VP">
          <tokens>
            <token id="6" string="ran" />
            <token id="7" string="together" />
            <token id="8" string="--" />
            <token id="9" string="they" />
            <token id="10" string="even" />
            <token id="11" string="chatted" />
            <token id="12" string="--" />
            <token id="13" string="through" />
            <token id="14" string="the" />
            <token id="15" string="20-mile" />
            <token id="16" string="mark" />
            <token id="17" string="," />
            <token id="18" string="until" />
            <token id="19" string="Smith" />
            <token id="20" string="got" />
            <token id="21" string="her" />
            <token id="22" string="feet" />
            <token id="23" string="working" />
            <token id="24" string="faster" />
            <token id="25" string="than" />
            <token id="26" string="her" />
            <token id="27" string="mouth" />
          </tokens>
        </chunking>
        <chunking id="14" string="together" type="ADJP">
          <tokens>
            <token id="7" string="together" />
          </tokens>
        </chunking>
        <chunking id="15" string="the 20-mile mark" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="20-mile" />
            <token id="16" string="mark" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Smith</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">ran</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">she</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">she</governor>
          <dependent id="5">Ireland</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="6">ran</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">ran</governor>
          <dependent id="7">together</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">chatted</governor>
          <dependent id="9">they</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">chatted</governor>
          <dependent id="10">even</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">ran</governor>
          <dependent id="11">chatted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">mark</governor>
          <dependent id="13">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">mark</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">mark</governor>
          <dependent id="15">20-mile</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">ran</governor>
          <dependent id="16">mark</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">got</governor>
          <dependent id="18">until</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">got</governor>
          <dependent id="19">Smith</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">mark</governor>
          <dependent id="20">got</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">feet</governor>
          <dependent id="21">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">got</governor>
          <dependent id="22">feet</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">got</governor>
          <dependent id="23">working</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">working</governor>
          <dependent id="24">faster</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">mouth</governor>
          <dependent id="25">than</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">mouth</governor>
          <dependent id="26">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">working</governor>
          <dependent id="27">mouth</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Smith" />
          </tokens>
        </entity>
        <entity id="2" string="Ireland" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Ireland" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>Having run with Ireland last year in the San Diego Marathon, Smith knew a little of Ireland&amp;apost;s racing style.</content>
      <tokens>
        <token id="1" string="Having" lemma="have" stem="have" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="run" lemma="run" stem="run" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Ireland" lemma="Ireland" stem="ireland" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="5" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="6" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="10" string="Diego" lemma="Diego" stem="diego" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="11" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Ireland" lemma="Ireland" stem="ireland" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="racing" lemma="racing" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="style" lemma="style" stem="style" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Having) (VP (VBN run) (PP (IN with) (NP (NNP Ireland))) (NP-TMP (JJ last) (NN year)) (PP (IN in) (NP (DT the) (NNP San) (NNP Diego) (NNP Marathon)))))) (, ,) (NP (NNP Smith)) (VP (VBD knew) (NP (DT a) (JJ little)) (PP (IN of) (NP (NP (NNP Ireland) (POS 's)) (NN racing) (NN style)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="run with Ireland last year in the San Diego Marathon" type="VP">
          <tokens>
            <token id="2" string="run" />
            <token id="3" string="with" />
            <token id="4" string="Ireland" />
            <token id="5" string="last" />
            <token id="6" string="year" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="San" />
            <token id="10" string="Diego" />
            <token id="11" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ireland 's" type="NP">
          <tokens>
            <token id="18" string="Ireland" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="knew a little of Ireland 's racing style" type="VP">
          <tokens>
            <token id="14" string="knew" />
            <token id="15" string="a" />
            <token id="16" string="little" />
            <token id="17" string="of" />
            <token id="18" string="Ireland" />
            <token id="19" string="'s" />
            <token id="20" string="racing" />
            <token id="21" string="style" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ireland 's racing style" type="NP">
          <tokens>
            <token id="18" string="Ireland" />
            <token id="19" string="'s" />
            <token id="20" string="racing" />
            <token id="21" string="style" />
          </tokens>
        </chunking>
        <chunking id="5" string="Having run with Ireland last year in the San Diego Marathon" type="VP">
          <tokens>
            <token id="1" string="Having" />
            <token id="2" string="run" />
            <token id="3" string="with" />
            <token id="4" string="Ireland" />
            <token id="5" string="last" />
            <token id="6" string="year" />
            <token id="7" string="in" />
            <token id="8" string="the" />
            <token id="9" string="San" />
            <token id="10" string="Diego" />
            <token id="11" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="6" string="the San Diego Marathon" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="San" />
            <token id="10" string="Diego" />
            <token id="11" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="7" string="Smith" type="NP">
          <tokens>
            <token id="13" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="8" string="a little" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="little" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ireland" type="NP">
          <tokens>
            <token id="4" string="Ireland" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="aux">
          <governor id="2">run</governor>
          <dependent id="1">Having</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">knew</governor>
          <dependent id="2">run</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Ireland</governor>
          <dependent id="3">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">run</governor>
          <dependent id="4">Ireland</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">year</governor>
          <dependent id="5">last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">run</governor>
          <dependent id="6">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Marathon</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Marathon</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Marathon</governor>
          <dependent id="9">San</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Marathon</governor>
          <dependent id="10">Diego</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">run</governor>
          <dependent id="11">Marathon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">knew</governor>
          <dependent id="13">Smith</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">knew</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">little</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">knew</governor>
          <dependent id="16">little</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">style</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">style</governor>
          <dependent id="18">Ireland</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Ireland</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">style</governor>
          <dependent id="20">racing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">knew</governor>
          <dependent id="21">style</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Smith" />
          </tokens>
        </entity>
        <entity id="2" string="Ireland" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Ireland" />
          </tokens>
        </entity>
        <entity id="3" string="San Diego Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="San" />
            <token id="10" string="Diego" />
            <token id="11" string="Marathon" />
          </tokens>
        </entity>
        <entity id="4" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="last" />
            <token id="6" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>&amp;quot;She&amp;apost;s really tough in the latter part of a race,&amp;quot; Smith said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="tough" lemma="tough" stem="tough" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="latter" lemma="latter" stem="latter" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP She)) (VP (VBZ 's) (ADJP (RB really) (JJ tough) (PP (IN in) (NP (NP (DT the) (JJ latter) (NN part)) (PP (IN of) (NP (DT a) (NN race)))))))) (, ,) ('' '') (NP (NNP Smith)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a race" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="race" />
          </tokens>
        </chunking>
        <chunking id="2" string="the latter part of a race" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="latter" />
            <token id="9" string="part" />
            <token id="10" string="of" />
            <token id="11" string="a" />
            <token id="12" string="race" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s really tough in the latter part of a race" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="really" />
            <token id="5" string="tough" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="latter" />
            <token id="9" string="part" />
            <token id="10" string="of" />
            <token id="11" string="a" />
            <token id="12" string="race" />
          </tokens>
        </chunking>
        <chunking id="4" string="Smith" type="NP">
          <tokens>
            <token id="15" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="5" string="really tough in the latter part of a race" type="ADJP">
          <tokens>
            <token id="4" string="really" />
            <token id="5" string="tough" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="latter" />
            <token id="9" string="part" />
            <token id="10" string="of" />
            <token id="11" string="a" />
            <token id="12" string="race" />
          </tokens>
        </chunking>
        <chunking id="6" string="the latter part" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="latter" />
            <token id="9" string="part" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">tough</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">tough</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">tough</governor>
          <dependent id="4">really</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="5">tough</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">part</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">part</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">part</governor>
          <dependent id="8">latter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">tough</governor>
          <dependent id="9">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">race</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">race</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">part</governor>
          <dependent id="12">race</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="15">Smith</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Smith" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>&amp;quot;I wanted to hang back with her, so then she could carry me through the latter part.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="hang" lemma="hang" stem="hang" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="back" lemma="back" stem="back" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="carry" lemma="carry" stem="carri" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="latter" lemma="latter" stem="latter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (VBD wanted) (S (VP (TO to) (VP (VB hang) (PRT (RP back)) (PP (IN with) (NP (PRP her)))))))) (, ,) (RB so) (S (ADVP (RB then)) (NP (PRP she)) (VP (MD could) (VP (VB carry) (NP (PRP me)) (PP (IN through) (NP (DT the) (JJ latter) (NN part)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her" type="NP">
          <tokens>
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="2" string="me" type="NP">
          <tokens>
            <token id="15" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="wanted to hang back with her" type="VP">
          <tokens>
            <token id="3" string="wanted" />
            <token id="4" string="to" />
            <token id="5" string="hang" />
            <token id="6" string="back" />
            <token id="7" string="with" />
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="5" string="the latter part" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="latter" />
            <token id="19" string="part" />
          </tokens>
        </chunking>
        <chunking id="6" string="hang back with her" type="VP">
          <tokens>
            <token id="5" string="hang" />
            <token id="6" string="back" />
            <token id="7" string="with" />
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="7" string="could carry me through the latter part" type="VP">
          <tokens>
            <token id="13" string="could" />
            <token id="14" string="carry" />
            <token id="15" string="me" />
            <token id="16" string="through" />
            <token id="17" string="the" />
            <token id="18" string="latter" />
            <token id="19" string="part" />
          </tokens>
        </chunking>
        <chunking id="8" string="to hang back with her" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="hang" />
            <token id="6" string="back" />
            <token id="7" string="with" />
            <token id="8" string="her" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="12" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="carry me through the latter part" type="VP">
          <tokens>
            <token id="14" string="carry" />
            <token id="15" string="me" />
            <token id="16" string="through" />
            <token id="17" string="the" />
            <token id="18" string="latter" />
            <token id="19" string="part" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">wanted</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">hang</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">wanted</governor>
          <dependent id="5">hang</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">hang</governor>
          <dependent id="6">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">her</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">hang</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">wanted</governor>
          <dependent id="10">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">carry</governor>
          <dependent id="11">then</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">carry</governor>
          <dependent id="12">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">carry</governor>
          <dependent id="13">could</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">wanted</governor>
          <dependent id="14">carry</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">carry</governor>
          <dependent id="15">me</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">part</governor>
          <dependent id="16">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">part</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">part</governor>
          <dependent id="18">latter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">carry</governor>
          <dependent id="19">part</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>She hung in pretty well with me.&amp;quot;</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="hung" lemma="hang" stem="hung" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="pretty" lemma="pretty" stem="pretti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD hung) (PP (IN in) (ADVP (RB pretty) (RB well))) (PP (IN with) (NP (PRP me)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="me" type="NP">
          <tokens>
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="3" string="hung in pretty well with me" type="VP">
          <tokens>
            <token id="2" string="hung" />
            <token id="3" string="in" />
            <token id="4" string="pretty" />
            <token id="5" string="well" />
            <token id="6" string="with" />
            <token id="7" string="me" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">hung</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">hung</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">well</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">well</governor>
          <dependent id="4">pretty</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">hung</governor>
          <dependent id="5">well</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">me</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">hung</governor>
          <dependent id="7">me</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>Smith earlier this year ran the Long Beach Marathon, where she finished seventh but has been concentrating on this distance for just a year.</content>
      <tokens>
        <token id="1" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="earlier" lemma="earlier" stem="earlier" pos="RBR" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="3" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="4" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="5" string="ran" lemma="run" stem="ran" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Long" lemma="Long" stem="long" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="8" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Marathon" lemma="Marathon" stem="marathon" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="finished" lemma="finish" stem="finish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="seventh" lemma="seventh" stem="seventh" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="concentrating" lemma="concentrate" stem="concentr" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="distance" lemma="distance" stem="distanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="25" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Smith)) (NP-TMP (RBR earlier) (DT this) (NN year)) (VP (VBD ran) (NP (NP (DT the) (NNP Long) (NNP Beach) (NNP Marathon)) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (PRP she)) (VP (VP (VBD finished) (S (ADJP (JJ seventh)))) (CC but) (VP (VBZ has) (VP (VBN been) (VP (VBG concentrating) (PP (IN on) (NP (NP (DT this) (NN distance)) (PP (IN for) (NP (RB just) (DT a) (NN year))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been concentrating on this distance for just a year" type="VP">
          <tokens>
            <token id="17" string="been" />
            <token id="18" string="concentrating" />
            <token id="19" string="on" />
            <token id="20" string="this" />
            <token id="21" string="distance" />
            <token id="22" string="for" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="2" string="this distance" type="NP">
          <tokens>
            <token id="20" string="this" />
            <token id="21" string="distance" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Long Beach Marathon" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Long" />
            <token id="8" string="Beach" />
            <token id="9" string="Marathon" />
          </tokens>
        </chunking>
        <chunking id="4" string="Smith" type="NP">
          <tokens>
            <token id="1" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="5" string="this distance for just a year" type="NP">
          <tokens>
            <token id="20" string="this" />
            <token id="21" string="distance" />
            <token id="22" string="for" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="where she finished seventh but has been concentrating on this distance for just a year" type="SBAR">
          <tokens>
            <token id="11" string="where" />
            <token id="12" string="she" />
            <token id="13" string="finished" />
            <token id="14" string="seventh" />
            <token id="15" string="but" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="concentrating" />
            <token id="19" string="on" />
            <token id="20" string="this" />
            <token id="21" string="distance" />
            <token id="22" string="for" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="7" string="finished seventh but has been concentrating on this distance for just a year" type="VP">
          <tokens>
            <token id="13" string="finished" />
            <token id="14" string="seventh" />
            <token id="15" string="but" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="concentrating" />
            <token id="19" string="on" />
            <token id="20" string="this" />
            <token id="21" string="distance" />
            <token id="22" string="for" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="8" string="ran the Long Beach Marathon , where she finished seventh but has been concentrating on this distance for just a year" type="VP">
          <tokens>
            <token id="5" string="ran" />
            <token id="6" string="the" />
            <token id="7" string="Long" />
            <token id="8" string="Beach" />
            <token id="9" string="Marathon" />
            <token id="10" string="," />
            <token id="11" string="where" />
            <token id="12" string="she" />
            <token id="13" string="finished" />
            <token id="14" string="seventh" />
            <token id="15" string="but" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="concentrating" />
            <token id="19" string="on" />
            <token id="20" string="this" />
            <token id="21" string="distance" />
            <token id="22" string="for" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="9" string="has been concentrating on this distance for just a year" type="VP">
          <tokens>
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="concentrating" />
            <token id="19" string="on" />
            <token id="20" string="this" />
            <token id="21" string="distance" />
            <token id="22" string="for" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="10" string="concentrating on this distance for just a year" type="VP">
          <tokens>
            <token id="18" string="concentrating" />
            <token id="19" string="on" />
            <token id="20" string="this" />
            <token id="21" string="distance" />
            <token id="22" string="for" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="12" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Long Beach Marathon , where she finished seventh but has been concentrating on this distance for just a year" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Long" />
            <token id="8" string="Beach" />
            <token id="9" string="Marathon" />
            <token id="10" string="," />
            <token id="11" string="where" />
            <token id="12" string="she" />
            <token id="13" string="finished" />
            <token id="14" string="seventh" />
            <token id="15" string="but" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="concentrating" />
            <token id="19" string="on" />
            <token id="20" string="this" />
            <token id="21" string="distance" />
            <token id="22" string="for" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="13" string="seventh" type="ADJP">
          <tokens>
            <token id="14" string="seventh" />
          </tokens>
        </chunking>
        <chunking id="14" string="where" type="WHADVP">
          <tokens>
            <token id="11" string="where" />
          </tokens>
        </chunking>
        <chunking id="15" string="finished seventh" type="VP">
          <tokens>
            <token id="13" string="finished" />
            <token id="14" string="seventh" />
          </tokens>
        </chunking>
        <chunking id="16" string="just a year" type="NP">
          <tokens>
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">ran</governor>
          <dependent id="1">Smith</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">year</governor>
          <dependent id="2">earlier</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">year</governor>
          <dependent id="3">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">ran</governor>
          <dependent id="4">year</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">ran</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Marathon</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Marathon</governor>
          <dependent id="7">Long</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Marathon</governor>
          <dependent id="8">Beach</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">ran</governor>
          <dependent id="9">Marathon</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">finished</governor>
          <dependent id="11">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">finished</governor>
          <dependent id="12">she</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">Marathon</governor>
          <dependent id="13">finished</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">finished</governor>
          <dependent id="14">seventh</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">finished</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">concentrating</governor>
          <dependent id="16">has</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">concentrating</governor>
          <dependent id="17">been</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">finished</governor>
          <dependent id="18">concentrating</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">distance</governor>
          <dependent id="19">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">distance</governor>
          <dependent id="20">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">concentrating</governor>
          <dependent id="21">distance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">year</governor>
          <dependent id="22">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">year</governor>
          <dependent id="23">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">year</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">distance</governor>
          <dependent id="25">year</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="earlier this year" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="earlier" />
            <token id="3" string="this" />
            <token id="4" string="year" />
          </tokens>
        </entity>
        <entity id="2" string="seventh" type="ORDINAL" score="0.0">
          <tokens>
            <token id="14" string="seventh" />
          </tokens>
        </entity>
        <entity id="3" string="Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Smith" />
          </tokens>
        </entity>
        <entity id="4" string="Long Beach Marathon" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Long" />
            <token id="8" string="Beach" />
            <token id="9" string="Marathon" />
          </tokens>
        </entity>
        <entity id="5" string="a year" type="DURATION" score="0.0">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>She is getting smarter about it.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="getting" lemma="get" stem="get" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="smarter" lemma="smarter" stem="smarter" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBZ is) (VP (VBG getting) (ADVP (RBR smarter)) (PP (IN about) (NP (PRP it))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="getting smarter about it" type="VP">
          <tokens>
            <token id="3" string="getting" />
            <token id="4" string="smarter" />
            <token id="5" string="about" />
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="is getting smarter about it" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="getting" />
            <token id="4" string="smarter" />
            <token id="5" string="about" />
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">getting</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">getting</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">getting</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">getting</governor>
          <dependent id="4">smarter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">it</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">getting</governor>
          <dependent id="6">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>&amp;quot;Last year I led from Miles 13 to 22,&amp;quot; Smith said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="3" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="led" lemma="lead" stem="led" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Miles" lemma="Miles" stem="mile" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="22" lemma="22" stem="22" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Smith" lemma="Smith" stem="smith" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP-TMP (JJ Last) (NN year)) (NP (PRP I)) (VP (VBD led) (PP (IN from) (NP (NNP Miles) (CD 13))) (PP (TO to) (NP (CD 22))))) (, ,) ('' '') (NP (NNP Smith)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Smith" type="NP">
          <tokens>
            <token id="13" string="Smith" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="4" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="Miles 13" type="NP">
          <tokens>
            <token id="7" string="Miles" />
            <token id="8" string="13" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="14" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="led from Miles 13 to 22" type="VP">
          <tokens>
            <token id="5" string="led" />
            <token id="6" string="from" />
            <token id="7" string="Miles" />
            <token id="8" string="13" />
            <token id="9" string="to" />
            <token id="10" string="22" />
          </tokens>
        </chunking>
        <chunking id="6" string="22" type="NP">
          <tokens>
            <token id="10" string="22" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="3">year</governor>
          <dependent id="2">Last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="5">led</governor>
          <dependent id="3">year</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">led</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">said</governor>
          <dependent id="5">led</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Miles</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">led</governor>
          <dependent id="7">Miles</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">Miles</governor>
          <dependent id="8">13</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">22</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">led</governor>
          <dependent id="10">22</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">said</governor>
          <dependent id="13">Smith</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="13" />
          </tokens>
        </entity>
        <entity id="2" string="Smith" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Smith" />
          </tokens>
        </entity>
        <entity id="3" string="Last year" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Last" />
            <token id="3" string="year" />
          </tokens>
        </entity>
        <entity id="4" string="22" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="22" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>&amp;quot;This year&amp;apost;s it&amp;apost;s just a matter of maturity.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="3" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="maturity" lemma="maturity" stem="matur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT This) (NP (NP (NN year) (POS 's)) (NP (PRP it)))) (VP (VBZ 's) (ADVP (RB just)) (NP (NP (DT a) (NN matter)) (PP (IN of) (NP (NN maturity))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="This year 's it" type="NP">
          <tokens>
            <token id="2" string="This" />
            <token id="3" string="year" />
            <token id="4" string="'s" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="a matter of maturity" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="matter" />
            <token id="10" string="of" />
            <token id="11" string="maturity" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s just a matter of maturity" type="VP">
          <tokens>
            <token id="6" string="'s" />
            <token id="7" string="just" />
            <token id="8" string="a" />
            <token id="9" string="matter" />
            <token id="10" string="of" />
            <token id="11" string="maturity" />
          </tokens>
        </chunking>
        <chunking id="4" string="maturity" type="NP">
          <tokens>
            <token id="11" string="maturity" />
          </tokens>
        </chunking>
        <chunking id="5" string="year 's" type="NP">
          <tokens>
            <token id="3" string="year" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="a matter" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="matter" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="year 's it" type="NP">
          <tokens>
            <token id="3" string="year" />
            <token id="4" string="'s" />
            <token id="5" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">year</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">matter</governor>
          <dependent id="3">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">year</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">year</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">matter</governor>
          <dependent id="6">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">matter</governor>
          <dependent id="7">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">matter</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">matter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">maturity</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">matter</governor>
          <dependent id="11">maturity</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="This year" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="This" />
            <token id="3" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>And the hills were positive for me.&amp;quot;</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="hills" lemma="hill" stem="hill" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="positive" lemma="positive" stem="posit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (DT the) (NNS hills)) (VP (VBD were) (ADJP (JJ positive) (PP (IN for) (NP (PRP me))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="were positive for me" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="positive" />
            <token id="6" string="for" />
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="the hills" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="hills" />
          </tokens>
        </chunking>
        <chunking id="3" string="me" type="NP">
          <tokens>
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="positive for me" type="ADJP">
          <tokens>
            <token id="5" string="positive" />
            <token id="6" string="for" />
            <token id="7" string="me" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">positive</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">hills</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">positive</governor>
          <dependent id="3">hills</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">positive</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">positive</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">me</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">positive</governor>
          <dependent id="7">me</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>Martinez said entered this event because he knew the field was weak and his chances were good.</content>
      <tokens>
        <token id="1" string="Martinez" lemma="Martinez" stem="martinez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="entered" lemma="enter" stem="enter" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="event" lemma="event" stem="event" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="weak" lemma="weak" stem="weak" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="chances" lemma="chance" stem="chanc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Martinez)) (VP (VBD said) (VP (VBN entered) (NP (DT this) (NN event)) (SBAR (IN because) (S (NP (PRP he)) (VP (VBD knew) (SBAR (S (NP (DT the) (NN field)) (VP (VBD was) (ADJP (JJ weak))))))))))) (CC and) (S (NP (PRP$ his) (NNS chances)) (VP (VBD were) (ADJP (JJ good)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="weak" type="ADJP">
          <tokens>
            <token id="12" string="weak" />
          </tokens>
        </chunking>
        <chunking id="2" string="entered this event because he knew the field was weak" type="VP">
          <tokens>
            <token id="3" string="entered" />
            <token id="4" string="this" />
            <token id="5" string="event" />
            <token id="6" string="because" />
            <token id="7" string="he" />
            <token id="8" string="knew" />
            <token id="9" string="the" />
            <token id="10" string="field" />
            <token id="11" string="was" />
            <token id="12" string="weak" />
          </tokens>
        </chunking>
        <chunking id="3" string="the field was weak" type="SBAR">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="field" />
            <token id="11" string="was" />
            <token id="12" string="weak" />
          </tokens>
        </chunking>
        <chunking id="4" string="were good" type="VP">
          <tokens>
            <token id="16" string="were" />
            <token id="17" string="good" />
          </tokens>
        </chunking>
        <chunking id="5" string="his chances" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="chances" />
          </tokens>
        </chunking>
        <chunking id="6" string="said entered this event because he knew the field was weak" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="entered" />
            <token id="4" string="this" />
            <token id="5" string="event" />
            <token id="6" string="because" />
            <token id="7" string="he" />
            <token id="8" string="knew" />
            <token id="9" string="the" />
            <token id="10" string="field" />
            <token id="11" string="was" />
            <token id="12" string="weak" />
          </tokens>
        </chunking>
        <chunking id="7" string="this event" type="NP">
          <tokens>
            <token id="4" string="this" />
            <token id="5" string="event" />
          </tokens>
        </chunking>
        <chunking id="8" string="good" type="ADJP">
          <tokens>
            <token id="17" string="good" />
          </tokens>
        </chunking>
        <chunking id="9" string="because he knew the field was weak" type="SBAR">
          <tokens>
            <token id="6" string="because" />
            <token id="7" string="he" />
            <token id="8" string="knew" />
            <token id="9" string="the" />
            <token id="10" string="field" />
            <token id="11" string="was" />
            <token id="12" string="weak" />
          </tokens>
        </chunking>
        <chunking id="10" string="was weak" type="VP">
          <tokens>
            <token id="11" string="was" />
            <token id="12" string="weak" />
          </tokens>
        </chunking>
        <chunking id="11" string="the field" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="field" />
          </tokens>
        </chunking>
        <chunking id="12" string="Martinez" type="NP">
          <tokens>
            <token id="1" string="Martinez" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="14" string="knew the field was weak" type="VP">
          <tokens>
            <token id="8" string="knew" />
            <token id="9" string="the" />
            <token id="10" string="field" />
            <token id="11" string="was" />
            <token id="12" string="weak" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Martinez</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">said</governor>
          <dependent id="3">entered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">event</governor>
          <dependent id="4">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">entered</governor>
          <dependent id="5">event</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">knew</governor>
          <dependent id="6">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">knew</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">entered</governor>
          <dependent id="8">knew</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">field</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">weak</governor>
          <dependent id="10">field</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">weak</governor>
          <dependent id="11">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">knew</governor>
          <dependent id="12">weak</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">said</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">chances</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">good</governor>
          <dependent id="15">chances</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">good</governor>
          <dependent id="16">were</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">said</governor>
          <dependent id="17">good</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Martinez" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Martinez" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>&amp;quot;I knew Rosas and Kurtis were good, but it was a relatively weak field,&amp;quot; he said.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="Rosas" lemma="Rosas" stem="rosa" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Kurtis" lemma="Kurtis" stem="kurti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="relatively" lemma="relatively" stem="rel" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="weak" lemma="weak" stem="weak" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP I)) (VP (VBD knew) (SBAR (S (NP (NNP Rosas) (CC and) (NNP Kurtis)) (VP (VBD were) (ADJP (JJ good))))))) (, ,) (CC but) (S (NP (PRP it)) (VP (VBD was) (NP (DT a) (ADJP (RB relatively) (JJ weak)) (NN field))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were good" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="good" />
          </tokens>
        </chunking>
        <chunking id="2" string="a relatively weak field" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="relatively" />
            <token id="15" string="weak" />
            <token id="16" string="field" />
          </tokens>
        </chunking>
        <chunking id="3" string="Rosas and Kurtis were good" type="SBAR">
          <tokens>
            <token id="4" string="Rosas" />
            <token id="5" string="and" />
            <token id="6" string="Kurtis" />
            <token id="7" string="were" />
            <token id="8" string="good" />
          </tokens>
        </chunking>
        <chunking id="4" string="Rosas and Kurtis" type="NP">
          <tokens>
            <token id="4" string="Rosas" />
            <token id="5" string="and" />
            <token id="6" string="Kurtis" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="knew Rosas and Kurtis were good" type="VP">
          <tokens>
            <token id="3" string="knew" />
            <token id="4" string="Rosas" />
            <token id="5" string="and" />
            <token id="6" string="Kurtis" />
            <token id="7" string="were" />
            <token id="8" string="good" />
          </tokens>
        </chunking>
        <chunking id="7" string="was a relatively weak field" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="a" />
            <token id="14" string="relatively" />
            <token id="15" string="weak" />
            <token id="16" string="field" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="relatively weak" type="ADJP">
          <tokens>
            <token id="14" string="relatively" />
            <token id="15" string="weak" />
          </tokens>
        </chunking>
        <chunking id="10" string="good" type="ADJP">
          <tokens>
            <token id="8" string="good" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">knew</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="3">knew</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">good</governor>
          <dependent id="4">Rosas</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">Rosas</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Rosas</governor>
          <dependent id="6">Kurtis</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">good</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">knew</governor>
          <dependent id="8">good</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">knew</governor>
          <dependent id="10">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">field</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">field</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">field</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">weak</governor>
          <dependent id="14">relatively</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">field</governor>
          <dependent id="15">weak</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">knew</governor>
          <dependent id="16">field</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rosas" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Rosas" />
          </tokens>
        </entity>
        <entity id="2" string="Kurtis" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Kurtis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>But weak field or not, the 4,000-plus runners who participated in the event seemed to relish the experience, as all the problems the marathon has had to deal with faded as each runner crossed the finish line.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="weak" lemma="weak" stem="weak" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="field" lemma="field" stem="field" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="4,000-plus" lemma="4,000-plus" stem="4,000-plu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="runners" lemma="runner" stem="runner" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="participated" lemma="participate" stem="particip" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="event" lemma="event" stem="event" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="relish" lemma="relish" stem="relish" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="experience" lemma="experience" stem="experi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="deal" lemma="deal" stem="deal" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="faded" lemma="fade" stem="fade" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="each" lemma="each" stem="each" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="crossed" lemma="cross" stem="cross" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="finish" lemma="finish" stem="finish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (JJ weak) (NN field)) (CC or) (NP (NP (RB not)) (, ,) (NP (NP (DT the) (JJ 4,000-plus) (NNS runners)) (SBAR (WHNP (WP who)) (S (VP (VBD participated) (PP (IN in) (NP (DT the) (NN event))))))))) (VP (VBD seemed) (S (VP (TO to) (VP (VB relish) (NP (DT the) (NN experience))))) (, ,) (PP (IN as) (NP (NP (PDT all) (DT the) (NNS problems)) (SBAR (S (NP (DT the) (NN marathon)) (VP (VBZ has) (VP (VBN had) (S (VP (TO to) (VP (VB deal) (PP (IN with) (ADJP (VBN faded)))))) (SBAR (IN as) (S (NP (DT each) (NN runner)) (VP (VBD crossed) (NP (DT the) (NN finish) (NN line)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="weak field or not , the 4,000-plus runners who participated in the event" type="NP">
          <tokens>
            <token id="2" string="weak" />
            <token id="3" string="field" />
            <token id="4" string="or" />
            <token id="5" string="not" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="4,000-plus" />
            <token id="9" string="runners" />
            <token id="10" string="who" />
            <token id="11" string="participated" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="event" />
          </tokens>
        </chunking>
        <chunking id="2" string="seemed to relish the experience , as all the problems the marathon has had to deal with faded as each runner crossed the finish line" type="VP">
          <tokens>
            <token id="15" string="seemed" />
            <token id="16" string="to" />
            <token id="17" string="relish" />
            <token id="18" string="the" />
            <token id="19" string="experience" />
            <token id="20" string="," />
            <token id="21" string="as" />
            <token id="22" string="all" />
            <token id="23" string="the" />
            <token id="24" string="problems" />
            <token id="25" string="the" />
            <token id="26" string="marathon" />
            <token id="27" string="has" />
            <token id="28" string="had" />
            <token id="29" string="to" />
            <token id="30" string="deal" />
            <token id="31" string="with" />
            <token id="32" string="faded" />
            <token id="33" string="as" />
            <token id="34" string="each" />
            <token id="35" string="runner" />
            <token id="36" string="crossed" />
            <token id="37" string="the" />
            <token id="38" string="finish" />
            <token id="39" string="line" />
          </tokens>
        </chunking>
        <chunking id="3" string="all the problems" type="NP">
          <tokens>
            <token id="22" string="all" />
            <token id="23" string="the" />
            <token id="24" string="problems" />
          </tokens>
        </chunking>
        <chunking id="4" string="the 4,000-plus runners" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="4,000-plus" />
            <token id="9" string="runners" />
          </tokens>
        </chunking>
        <chunking id="5" string="to relish the experience" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="relish" />
            <token id="18" string="the" />
            <token id="19" string="experience" />
          </tokens>
        </chunking>
        <chunking id="6" string="faded" type="ADJP">
          <tokens>
            <token id="32" string="faded" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 4,000-plus runners who participated in the event" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="4,000-plus" />
            <token id="9" string="runners" />
            <token id="10" string="who" />
            <token id="11" string="participated" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="event" />
          </tokens>
        </chunking>
        <chunking id="8" string="as each runner crossed the finish line" type="SBAR">
          <tokens>
            <token id="33" string="as" />
            <token id="34" string="each" />
            <token id="35" string="runner" />
            <token id="36" string="crossed" />
            <token id="37" string="the" />
            <token id="38" string="finish" />
            <token id="39" string="line" />
          </tokens>
        </chunking>
        <chunking id="9" string="all the problems the marathon has had to deal with faded as each runner crossed the finish line" type="NP">
          <tokens>
            <token id="22" string="all" />
            <token id="23" string="the" />
            <token id="24" string="problems" />
            <token id="25" string="the" />
            <token id="26" string="marathon" />
            <token id="27" string="has" />
            <token id="28" string="had" />
            <token id="29" string="to" />
            <token id="30" string="deal" />
            <token id="31" string="with" />
            <token id="32" string="faded" />
            <token id="33" string="as" />
            <token id="34" string="each" />
            <token id="35" string="runner" />
            <token id="36" string="crossed" />
            <token id="37" string="the" />
            <token id="38" string="finish" />
            <token id="39" string="line" />
          </tokens>
        </chunking>
        <chunking id="10" string="the experience" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="experience" />
          </tokens>
        </chunking>
        <chunking id="11" string="participated in the event" type="VP">
          <tokens>
            <token id="11" string="participated" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="event" />
          </tokens>
        </chunking>
        <chunking id="12" string="the finish line" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="finish" />
            <token id="39" string="line" />
          </tokens>
        </chunking>
        <chunking id="13" string="who participated in the event" type="SBAR">
          <tokens>
            <token id="10" string="who" />
            <token id="11" string="participated" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="event" />
          </tokens>
        </chunking>
        <chunking id="14" string="the marathon" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="15" string="not , the 4,000-plus runners who participated in the event" type="NP">
          <tokens>
            <token id="5" string="not" />
            <token id="6" string="," />
            <token id="7" string="the" />
            <token id="8" string="4,000-plus" />
            <token id="9" string="runners" />
            <token id="10" string="who" />
            <token id="11" string="participated" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="event" />
          </tokens>
        </chunking>
        <chunking id="16" string="crossed the finish line" type="VP">
          <tokens>
            <token id="36" string="crossed" />
            <token id="37" string="the" />
            <token id="38" string="finish" />
            <token id="39" string="line" />
          </tokens>
        </chunking>
        <chunking id="17" string="weak field" type="NP">
          <tokens>
            <token id="2" string="weak" />
            <token id="3" string="field" />
          </tokens>
        </chunking>
        <chunking id="18" string="relish the experience" type="VP">
          <tokens>
            <token id="17" string="relish" />
            <token id="18" string="the" />
            <token id="19" string="experience" />
          </tokens>
        </chunking>
        <chunking id="19" string="has had to deal with faded as each runner crossed the finish line" type="VP">
          <tokens>
            <token id="27" string="has" />
            <token id="28" string="had" />
            <token id="29" string="to" />
            <token id="30" string="deal" />
            <token id="31" string="with" />
            <token id="32" string="faded" />
            <token id="33" string="as" />
            <token id="34" string="each" />
            <token id="35" string="runner" />
            <token id="36" string="crossed" />
            <token id="37" string="the" />
            <token id="38" string="finish" />
            <token id="39" string="line" />
          </tokens>
        </chunking>
        <chunking id="20" string="deal with faded" type="VP">
          <tokens>
            <token id="30" string="deal" />
            <token id="31" string="with" />
            <token id="32" string="faded" />
          </tokens>
        </chunking>
        <chunking id="21" string="to deal with faded" type="VP">
          <tokens>
            <token id="29" string="to" />
            <token id="30" string="deal" />
            <token id="31" string="with" />
            <token id="32" string="faded" />
          </tokens>
        </chunking>
        <chunking id="22" string="not" type="NP">
          <tokens>
            <token id="5" string="not" />
          </tokens>
        </chunking>
        <chunking id="23" string="the event" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="event" />
          </tokens>
        </chunking>
        <chunking id="24" string="had to deal with faded as each runner crossed the finish line" type="VP">
          <tokens>
            <token id="28" string="had" />
            <token id="29" string="to" />
            <token id="30" string="deal" />
            <token id="31" string="with" />
            <token id="32" string="faded" />
            <token id="33" string="as" />
            <token id="34" string="each" />
            <token id="35" string="runner" />
            <token id="36" string="crossed" />
            <token id="37" string="the" />
            <token id="38" string="finish" />
            <token id="39" string="line" />
          </tokens>
        </chunking>
        <chunking id="25" string="each runner" type="NP">
          <tokens>
            <token id="34" string="each" />
            <token id="35" string="runner" />
          </tokens>
        </chunking>
        <chunking id="26" string="the marathon has had to deal with faded as each runner crossed the finish line" type="SBAR">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="marathon" />
            <token id="27" string="has" />
            <token id="28" string="had" />
            <token id="29" string="to" />
            <token id="30" string="deal" />
            <token id="31" string="with" />
            <token id="32" string="faded" />
            <token id="33" string="as" />
            <token id="34" string="each" />
            <token id="35" string="runner" />
            <token id="36" string="crossed" />
            <token id="37" string="the" />
            <token id="38" string="finish" />
            <token id="39" string="line" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="15">seemed</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">field</governor>
          <dependent id="2">weak</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">seemed</governor>
          <dependent id="3">field</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">field</governor>
          <dependent id="4">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">field</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">runners</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">runners</governor>
          <dependent id="8">4,000-plus</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">not</governor>
          <dependent id="9">runners</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">participated</governor>
          <dependent id="10">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">runners</governor>
          <dependent id="11">participated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">event</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">event</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">participated</governor>
          <dependent id="14">event</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">seemed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">relish</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">seemed</governor>
          <dependent id="17">relish</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">experience</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">relish</governor>
          <dependent id="19">experience</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">problems</governor>
          <dependent id="21">as</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="24">problems</governor>
          <dependent id="22">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">problems</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">seemed</governor>
          <dependent id="24">problems</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">marathon</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">had</governor>
          <dependent id="26">marathon</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">had</governor>
          <dependent id="27">has</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="24">problems</governor>
          <dependent id="28">had</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">deal</governor>
          <dependent id="29">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">had</governor>
          <dependent id="30">deal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">faded</governor>
          <dependent id="31">with</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="30">deal</governor>
          <dependent id="32">faded</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">crossed</governor>
          <dependent id="33">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">runner</governor>
          <dependent id="34">each</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">crossed</governor>
          <dependent id="35">runner</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="28">had</governor>
          <dependent id="36">crossed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">line</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">line</governor>
          <dependent id="38">finish</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">crossed</governor>
          <dependent id="39">line</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>&amp;quot;It&amp;apost;s a beautiful course, and this was a great marathon,&amp;quot; one runner told race director Lynn Flanagan.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="beautiful" lemma="beautiful" stem="beauti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="runner" lemma="runner" stem="runner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="director" lemma="director" stem="director" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Lynn" lemma="Lynn" stem="lynn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="Flanagan" lemma="Flanagan" stem="flanagan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (S (NP (PRP It)) (VP (VBZ 's) (NP (DT a) (JJ beautiful) (NN course)))) (, ,) (CC and) (S (NP (DT this)) (VP (VBD was) (NP (DT a) (JJ great) (NN marathon))))) (, ,) ('' '') (NP (CD one) (NN runner)) (VP (VBD told) (NP (NN race) (NN director) (NNP Lynn) (NNP Flanagan))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one runner" type="NP">
          <tokens>
            <token id="16" string="one" />
            <token id="17" string="runner" />
          </tokens>
        </chunking>
        <chunking id="2" string="was a great marathon" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="a" />
            <token id="12" string="great" />
            <token id="13" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="3" string="told race director Lynn Flanagan" type="VP">
          <tokens>
            <token id="18" string="told" />
            <token id="19" string="race" />
            <token id="20" string="director" />
            <token id="21" string="Lynn" />
            <token id="22" string="Flanagan" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="this" type="NP">
          <tokens>
            <token id="9" string="this" />
          </tokens>
        </chunking>
        <chunking id="6" string="a great marathon" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="great" />
            <token id="13" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="7" string="race director Lynn Flanagan" type="NP">
          <tokens>
            <token id="19" string="race" />
            <token id="20" string="director" />
            <token id="21" string="Lynn" />
            <token id="22" string="Flanagan" />
          </tokens>
        </chunking>
        <chunking id="8" string="a beautiful course" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="beautiful" />
            <token id="6" string="course" />
          </tokens>
        </chunking>
        <chunking id="9" string="'s a beautiful course" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="a" />
            <token id="5" string="beautiful" />
            <token id="6" string="course" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">course</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">course</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">course</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">course</governor>
          <dependent id="5">beautiful</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">told</governor>
          <dependent id="6">course</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">course</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">marathon</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">marathon</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">marathon</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">marathon</governor>
          <dependent id="12">great</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">course</governor>
          <dependent id="13">marathon</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">runner</governor>
          <dependent id="16">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">told</governor>
          <dependent id="17">runner</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">told</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Flanagan</governor>
          <dependent id="19">race</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Flanagan</governor>
          <dependent id="20">director</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Flanagan</governor>
          <dependent id="21">Lynn</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">told</governor>
          <dependent id="22">Flanagan</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Lynn Flanagan" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Lynn" />
            <token id="22" string="Flanagan" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>&amp;quot;I can&amp;apost;t believe it went off so well,&amp;quot; said another to a volunteer.</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="off" lemma="off" stem="off" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="volunteer" lemma="volunteer" stem="volunt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (MD ca) (RB n't) (VP (VB believe) (SBAR (S (NP (PRP it)) (VP (VBD went) (ADVP (RB off) (RB so) (RB well)))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (DT another)) (PP (TO to) (NP (DT a) (NN volunteer)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="another to a volunteer" type="NP">
          <tokens>
            <token id="14" string="another" />
            <token id="15" string="to" />
            <token id="16" string="a" />
            <token id="17" string="volunteer" />
          </tokens>
        </chunking>
        <chunking id="2" string="went off so well" type="VP">
          <tokens>
            <token id="7" string="went" />
            <token id="8" string="off" />
            <token id="9" string="so" />
            <token id="10" string="well" />
          </tokens>
        </chunking>
        <chunking id="3" string="a volunteer" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="volunteer" />
          </tokens>
        </chunking>
        <chunking id="4" string="it went off so well" type="SBAR">
          <tokens>
            <token id="6" string="it" />
            <token id="7" string="went" />
            <token id="8" string="off" />
            <token id="9" string="so" />
            <token id="10" string="well" />
          </tokens>
        </chunking>
        <chunking id="5" string="another" type="NP">
          <tokens>
            <token id="14" string="another" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="ca n't believe it went off so well" type="VP">
          <tokens>
            <token id="3" string="ca" />
            <token id="4" string="n't" />
            <token id="5" string="believe" />
            <token id="6" string="it" />
            <token id="7" string="went" />
            <token id="8" string="off" />
            <token id="9" string="so" />
            <token id="10" string="well" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="13" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="believe it went off so well" type="VP">
          <tokens>
            <token id="5" string="believe" />
            <token id="6" string="it" />
            <token id="7" string="went" />
            <token id="8" string="off" />
            <token id="9" string="so" />
            <token id="10" string="well" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">believe</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">believe</governor>
          <dependent id="3">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">believe</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="5">believe</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">went</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">believe</governor>
          <dependent id="7">went</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">well</governor>
          <dependent id="8">off</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">well</governor>
          <dependent id="9">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">went</governor>
          <dependent id="10">well</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="14">another</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">volunteer</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">volunteer</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">another</governor>
          <dependent id="17">volunteer</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>&amp;quot;You&amp;apost;d never know anything had happened that was at all an inconvenience.&amp;quot;</content>
      <tokens>
        <token id="1" string="&quot;" lemma="``" stem="&quot;" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="'d" lemma="would" stem="'d" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="happened" lemma="happen" stem="happen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="inconvenience" lemma="inconvenience" stem="inconveni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="&quot;" lemma="''" stem="&quot;" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP You)) (VP (MD 'd) (ADVP (RB never)) (VP (VB know) (SBAR (S (NP (NN anything)) (VP (VBD had) (VP (VBN happened) (SBAR (S (NP (DT that)) (VP (VBD was) (ADVP (IN at) (DT all)) (NP (DT an) (NN inconvenience))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="9" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="'d never know anything had happened that was at all an inconvenience" type="VP">
          <tokens>
            <token id="3" string="'d" />
            <token id="4" string="never" />
            <token id="5" string="know" />
            <token id="6" string="anything" />
            <token id="7" string="had" />
            <token id="8" string="happened" />
            <token id="9" string="that" />
            <token id="10" string="was" />
            <token id="11" string="at" />
            <token id="12" string="all" />
            <token id="13" string="an" />
            <token id="14" string="inconvenience" />
          </tokens>
        </chunking>
        <chunking id="3" string="had happened that was at all an inconvenience" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="happened" />
            <token id="9" string="that" />
            <token id="10" string="was" />
            <token id="11" string="at" />
            <token id="12" string="all" />
            <token id="13" string="an" />
            <token id="14" string="inconvenience" />
          </tokens>
        </chunking>
        <chunking id="4" string="know anything had happened that was at all an inconvenience" type="VP">
          <tokens>
            <token id="5" string="know" />
            <token id="6" string="anything" />
            <token id="7" string="had" />
            <token id="8" string="happened" />
            <token id="9" string="that" />
            <token id="10" string="was" />
            <token id="11" string="at" />
            <token id="12" string="all" />
            <token id="13" string="an" />
            <token id="14" string="inconvenience" />
          </tokens>
        </chunking>
        <chunking id="5" string="happened that was at all an inconvenience" type="VP">
          <tokens>
            <token id="8" string="happened" />
            <token id="9" string="that" />
            <token id="10" string="was" />
            <token id="11" string="at" />
            <token id="12" string="all" />
            <token id="13" string="an" />
            <token id="14" string="inconvenience" />
          </tokens>
        </chunking>
        <chunking id="6" string="that was at all an inconvenience" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="was" />
            <token id="11" string="at" />
            <token id="12" string="all" />
            <token id="13" string="an" />
            <token id="14" string="inconvenience" />
          </tokens>
        </chunking>
        <chunking id="7" string="an inconvenience" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="inconvenience" />
          </tokens>
        </chunking>
        <chunking id="8" string="anything" type="NP">
          <tokens>
            <token id="6" string="anything" />
          </tokens>
        </chunking>
        <chunking id="9" string="was at all an inconvenience" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="at" />
            <token id="12" string="all" />
            <token id="13" string="an" />
            <token id="14" string="inconvenience" />
          </tokens>
        </chunking>
        <chunking id="10" string="anything had happened that was at all an inconvenience" type="SBAR">
          <tokens>
            <token id="6" string="anything" />
            <token id="7" string="had" />
            <token id="8" string="happened" />
            <token id="9" string="that" />
            <token id="10" string="was" />
            <token id="11" string="at" />
            <token id="12" string="all" />
            <token id="13" string="an" />
            <token id="14" string="inconvenience" />
          </tokens>
        </chunking>
        <chunking id="11" string="You" type="NP">
          <tokens>
            <token id="2" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">know</governor>
          <dependent id="2">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">know</governor>
          <dependent id="3">'d</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">know</governor>
          <dependent id="4">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">know</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">happened</governor>
          <dependent id="6">anything</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">happened</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">know</governor>
          <dependent id="8">happened</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">inconvenience</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">inconvenience</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">all</governor>
          <dependent id="11">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">inconvenience</governor>
          <dependent id="12">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">inconvenience</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">happened</governor>
          <dependent id="14">inconvenience</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="57" has_coreference="true">
      <content>DeAnna Sodoma of Escondido won her first marathon wheelchair race in 2:17:52; Saul Mendoza Hernandez of Mexico won the men&amp;apost;s division in 1:57:50.</content>
      <tokens>
        <token id="1" string="DeAnna" lemma="DeAnna" stem="deanna" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Sodoma" lemma="Sodoma" stem="sodoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="Escondido" lemma="Escondido" stem="escondido" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="true" />
        <token id="5" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="8" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="wheelchair" lemma="wheelchair" stem="wheelchair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="race" lemma="race" stem="race" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="2:17:52" lemma="2:17:52" stem="2:17:52" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="13" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Saul" lemma="Saul" stem="saul" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Mendoza" lemma="Mendoza" stem="mendoza" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Hernandez" lemma="Hernandez" stem="hernandez" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Mexico" lemma="Mexico" stem="mexico" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="19" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="division" lemma="division" stem="divis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="1:57:50" lemma="1:57:50" stem="1:57:50" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP DeAnna) (NNP Sodoma)) (PP (IN of) (NP (NNP Escondido)))) (VP (VBD won) (NP (PRP$ her) (JJ first) (NN marathon) (NN wheelchair) (NN race)) (PP (IN in) (NP (CD 2:17:52))))) (: ;) (S (NP (NP (NNP Saul) (NNP Mendoza) (NNP Hernandez)) (PP (IN of) (NP (NNP Mexico)))) (VP (VBD won) (NP (NP (DT the) (NNS men) (POS 's)) (NN division)) (PP (IN in) (NP (CD 1:57:50))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Saul Mendoza Hernandez" type="NP">
          <tokens>
            <token id="14" string="Saul" />
            <token id="15" string="Mendoza" />
            <token id="16" string="Hernandez" />
          </tokens>
        </chunking>
        <chunking id="2" string="the men 's division" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="men" />
            <token id="22" string="'s" />
            <token id="23" string="division" />
          </tokens>
        </chunking>
        <chunking id="3" string="1:57:50" type="NP">
          <tokens>
            <token id="25" string="1:57:50" />
          </tokens>
        </chunking>
        <chunking id="4" string="won the men 's division in 1:57:50" type="VP">
          <tokens>
            <token id="19" string="won" />
            <token id="20" string="the" />
            <token id="21" string="men" />
            <token id="22" string="'s" />
            <token id="23" string="division" />
            <token id="24" string="in" />
            <token id="25" string="1:57:50" />
          </tokens>
        </chunking>
        <chunking id="5" string="Escondido" type="NP">
          <tokens>
            <token id="4" string="Escondido" />
          </tokens>
        </chunking>
        <chunking id="6" string="DeAnna Sodoma" type="NP">
          <tokens>
            <token id="1" string="DeAnna" />
            <token id="2" string="Sodoma" />
          </tokens>
        </chunking>
        <chunking id="7" string="her first marathon wheelchair race" type="NP">
          <tokens>
            <token id="6" string="her" />
            <token id="7" string="first" />
            <token id="8" string="marathon" />
            <token id="9" string="wheelchair" />
            <token id="10" string="race" />
          </tokens>
        </chunking>
        <chunking id="8" string="DeAnna Sodoma of Escondido" type="NP">
          <tokens>
            <token id="1" string="DeAnna" />
            <token id="2" string="Sodoma" />
            <token id="3" string="of" />
            <token id="4" string="Escondido" />
          </tokens>
        </chunking>
        <chunking id="9" string="won her first marathon wheelchair race in 2:17:52" type="VP">
          <tokens>
            <token id="5" string="won" />
            <token id="6" string="her" />
            <token id="7" string="first" />
            <token id="8" string="marathon" />
            <token id="9" string="wheelchair" />
            <token id="10" string="race" />
            <token id="11" string="in" />
            <token id="12" string="2:17:52" />
          </tokens>
        </chunking>
        <chunking id="10" string="the men 's" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="men" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="2:17:52" type="NP">
          <tokens>
            <token id="12" string="2:17:52" />
          </tokens>
        </chunking>
        <chunking id="12" string="Saul Mendoza Hernandez of Mexico" type="NP">
          <tokens>
            <token id="14" string="Saul" />
            <token id="15" string="Mendoza" />
            <token id="16" string="Hernandez" />
            <token id="17" string="of" />
            <token id="18" string="Mexico" />
          </tokens>
        </chunking>
        <chunking id="13" string="Mexico" type="NP">
          <tokens>
            <token id="18" string="Mexico" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Sodoma</governor>
          <dependent id="1">DeAnna</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">won</governor>
          <dependent id="2">Sodoma</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Escondido</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Sodoma</governor>
          <dependent id="4">Escondido</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">won</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">race</governor>
          <dependent id="6">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">race</governor>
          <dependent id="7">first</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">race</governor>
          <dependent id="8">marathon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">race</governor>
          <dependent id="9">wheelchair</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">won</governor>
          <dependent id="10">race</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">2:17:52</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">won</governor>
          <dependent id="12">2:17:52</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Hernandez</governor>
          <dependent id="14">Saul</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Hernandez</governor>
          <dependent id="15">Mendoza</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">won</governor>
          <dependent id="16">Hernandez</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Mexico</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">Hernandez</governor>
          <dependent id="18">Mexico</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">won</governor>
          <dependent id="19">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">men</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">division</governor>
          <dependent id="21">men</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">men</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">won</governor>
          <dependent id="23">division</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">1:57:50</governor>
          <dependent id="24">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">won</governor>
          <dependent id="25">1:57:50</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="7" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Saul Mendoza Hernandez" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Saul" />
            <token id="15" string="Mendoza" />
            <token id="16" string="Hernandez" />
          </tokens>
        </entity>
        <entity id="3" string="2:17:52" type="TIME" score="0.0">
          <tokens>
            <token id="12" string="2:17:52" />
          </tokens>
        </entity>
        <entity id="4" string="1:57:50" type="TIME" score="0.0">
          <tokens>
            <token id="25" string="1:57:50" />
          </tokens>
        </entity>
        <entity id="5" string="Mexico" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="Mexico" />
          </tokens>
        </entity>
        <entity id="6" string="Escondido" type="LOCATION" score="0.0">
          <tokens>
            <token id="4" string="Escondido" />
          </tokens>
        </entity>
        <entity id="7" string="DeAnna Sodoma" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="DeAnna" />
            <token id="2" string="Sodoma" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="58" has_coreference="true">
      <content>James Sheremeta of San Diego won the men&amp;apost;s half marathon in 1:08:59; Jeanne Lassee-Johnson was the women&amp;apost;s half winner in 1:16:15.</content>
      <tokens>
        <token id="1" string="James" lemma="James" stem="jame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Sheremeta" lemma="Sheremeta" stem="sheremeta" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="San" lemma="San" stem="san" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="Diego" lemma="Diego" stem="diego" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="men" lemma="man" stem="men" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="half" lemma="half" stem="half" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="marathon" lemma="marathon" stem="marathon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="1:08:59" lemma="1:08:59" stem="1:08:59" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="14" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Jeanne" lemma="Jeanne" stem="jeann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Lassee-Johnson" lemma="Lassee-Johnson" stem="lassee-johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="women" lemma="woman" stem="women" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="half" lemma="half" stem="half" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="1:16:15" lemma="1:16:15" stem="1:16:15" pos="CD" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP James) (NNP Sheremeta)) (PP (IN of) (NP (NNP San) (NNP Diego)))) (VP (VBD won) (NP (NP (DT the) (NNS men) (POS 's)) (NN half) (NN marathon)) (PP (IN in) (NP (CD 1:08:59))))) (: ;) (S (NP (NNP Jeanne) (NNP Lassee-Johnson)) (VP (VBD was) (NP (NP (NP (DT the) (NNS women) (POS 's)) (NN half) (NN winner)) (PP (IN in) (NP (CD 1:16:15)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="James Sheremeta" type="NP">
          <tokens>
            <token id="1" string="James" />
            <token id="2" string="Sheremeta" />
          </tokens>
        </chunking>
        <chunking id="2" string="the women 's half winner in 1:16:15" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="women" />
            <token id="20" string="'s" />
            <token id="21" string="half" />
            <token id="22" string="winner" />
            <token id="23" string="in" />
            <token id="24" string="1:16:15" />
          </tokens>
        </chunking>
        <chunking id="3" string="1:08:59" type="NP">
          <tokens>
            <token id="13" string="1:08:59" />
          </tokens>
        </chunking>
        <chunking id="4" string="won the men 's half marathon in 1:08:59" type="VP">
          <tokens>
            <token id="6" string="won" />
            <token id="7" string="the" />
            <token id="8" string="men" />
            <token id="9" string="'s" />
            <token id="10" string="half" />
            <token id="11" string="marathon" />
            <token id="12" string="in" />
            <token id="13" string="1:08:59" />
          </tokens>
        </chunking>
        <chunking id="5" string="was the women 's half winner in 1:16:15" type="VP">
          <tokens>
            <token id="17" string="was" />
            <token id="18" string="the" />
            <token id="19" string="women" />
            <token id="20" string="'s" />
            <token id="21" string="half" />
            <token id="22" string="winner" />
            <token id="23" string="in" />
            <token id="24" string="1:16:15" />
          </tokens>
        </chunking>
        <chunking id="6" string="the women 's" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="women" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="the men 's" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="men" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="Jeanne Lassee-Johnson" type="NP">
          <tokens>
            <token id="15" string="Jeanne" />
            <token id="16" string="Lassee-Johnson" />
          </tokens>
        </chunking>
        <chunking id="9" string="the men 's half marathon" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="men" />
            <token id="9" string="'s" />
            <token id="10" string="half" />
            <token id="11" string="marathon" />
          </tokens>
        </chunking>
        <chunking id="10" string="James Sheremeta of San Diego" type="NP">
          <tokens>
            <token id="1" string="James" />
            <token id="2" string="Sheremeta" />
            <token id="3" string="of" />
            <token id="4" string="San" />
            <token id="5" string="Diego" />
          </tokens>
        </chunking>
        <chunking id="11" string="1:16:15" type="NP">
          <tokens>
            <token id="24" string="1:16:15" />
          </tokens>
        </chunking>
        <chunking id="12" string="the women 's half winner" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="women" />
            <token id="20" string="'s" />
            <token id="21" string="half" />
            <token id="22" string="winner" />
          </tokens>
        </chunking>
        <chunking id="13" string="San Diego" type="NP">
          <tokens>
            <token id="4" string="San" />
            <token id="5" string="Diego" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Sheremeta</governor>
          <dependent id="1">James</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">won</governor>
          <dependent id="2">Sheremeta</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Diego</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Diego</governor>
          <dependent id="4">San</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Sheremeta</governor>
          <dependent id="5">Diego</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">won</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">men</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">marathon</governor>
          <dependent id="8">men</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">men</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">marathon</governor>
          <dependent id="10">half</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">won</governor>
          <dependent id="11">marathon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">1:08:59</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">won</governor>
          <dependent id="13">1:08:59</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Lassee-Johnson</governor>
          <dependent id="15">Jeanne</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">winner</governor>
          <dependent id="16">Lassee-Johnson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">winner</governor>
          <dependent id="17">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">women</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">winner</governor>
          <dependent id="19">women</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">women</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">winner</governor>
          <dependent id="21">half</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="6">won</governor>
          <dependent id="22">winner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">1:16:15</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">winner</governor>
          <dependent id="24">1:16:15</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jeanne Lassee-Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Jeanne" />
            <token id="16" string="Lassee-Johnson" />
          </tokens>
        </entity>
        <entity id="2" string="James Sheremeta" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="James" />
            <token id="2" string="Sheremeta" />
          </tokens>
        </entity>
        <entity id="3" string="1:08:59" type="TIME" score="0.0">
          <tokens>
            <token id="13" string="1:08:59" />
          </tokens>
        </entity>
        <entity id="4" string="1:16:15" type="TIME" score="0.0">
          <tokens>
            <token id="24" string="1:16:15" />
          </tokens>
        </entity>
        <entity id="5" string="San Diego" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="San" />
            <token id="5" string="Diego" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="13-14" string="Mexico City" id_sentence="35" />
      <mentions>
        <mention ids_tokens="22" string="Mexico" id_sentence="2" />
        <mention ids_tokens="5" string="Mexico" id_sentence="7" />
        <mention ids_tokens="18" string="Mexico" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="34-35-36-37" string="the San Diego Marathon" id_sentence="2" />
      <mentions>
        <mention ids_tokens="5-7" string="the marathon's" id_sentence="6" />
        <mention ids_tokens="27-29" string="San Diego's" id_sentence="21" />
        <mention ids_tokens="9-11" string="San Diego Marathon" id_sentence="42" />
        <mention ids_tokens="2" string="I" id_sentence="44" />
        <mention ids_tokens="15" string="me" id_sentence="44" />
        <mention ids_tokens="7" string="me" id_sentence="45" />
        <mention ids_tokens="25-26" string="the marathon" id_sentence="53" />
        <mention ids_tokens="11-13" string="a great marathon" id_sentence="54" />
        <mention ids_tokens="4-5" string="San Diego" id_sentence="58" />
        <mention ids_tokens="7-11" string="the men's half marathon" id_sentence="58" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10" string="the new North County course" id_sentence="3" />
      <mentions>
        <mention ids_tokens="14-15" string="the course" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Martinez , 29" id_sentence="4" />
      <mentions>
        <mention ids_tokens="4" string="Martinez" id_sentence="9" />
        <mention ids_tokens="13" string="he" id_sentence="9" />
        <mention ids_tokens="2" string="Martinez" id_sentence="10" />
        <mention ids_tokens="5" string="Martinez" id_sentence="11" />
        <mention ids_tokens="19-28" string="Martinez , who won with a 5:18 - mile pace" id_sentence="13" />
        <mention ids_tokens="19" string="Martinez" id_sentence="13" />
        <mention ids_tokens="1" string="Martinez" id_sentence="16" />
        <mention ids_tokens="10" string="Martinez" id_sentence="16" />
        <mention ids_tokens="17" string="Martinez" id_sentence="17" />
        <mention ids_tokens="1" string="Martinez" id_sentence="20" />
        <mention ids_tokens="2" string="Martinez" id_sentence="21" />
        <mention ids_tokens="1-2" string="Martinez'" id_sentence="23" />
        <mention ids_tokens="13" string="his" id_sentence="23" />
        <mention ids_tokens="2" string="Martinez" id_sentence="27" />
        <mention ids_tokens="26" string="his" id_sentence="27" />
        <mention ids_tokens="34" string="him" id_sentence="27" />
        <mention ids_tokens="6-7" string="Martinez'" id_sentence="32" />
        <mention ids_tokens="1" string="Martinez" id_sentence="33" />
        <mention ids_tokens="1" string="He" id_sentence="34" />
        <mention ids_tokens="1" string="He" id_sentence="35" />
        <mention ids_tokens="6" string="his" id_sentence="35" />
        <mention ids_tokens="1" string="Martinez" id_sentence="51" />
        <mention ids_tokens="7" string="he" id_sentence="51" />
        <mention ids_tokens="14" string="his" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="18-19-20-21-22-23" string="Doug Kurtis of Northville , Mich" id_sentence="4" />
      <mentions>
        <mention ids_tokens="18-19" string="Doug Kurtis" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="1-2" string="Smith 's" id_sentence="5" />
      <mentions>
        <mention ids_tokens="1-3" string="Smith , 24" id_sentence="36" />
        <mention ids_tokens="1" string="Smith" id_sentence="36" />
        <mention ids_tokens="25-37" string="Smith , who finished fourth last year and ran a personal-best time Sunday" id_sentence="39" />
        <mention ids_tokens="25" string="Smith" id_sentence="39" />
        <mention ids_tokens="1" string="Smith" id_sentence="41" />
        <mention ids_tokens="19" string="Smith" id_sentence="41" />
        <mention ids_tokens="13" string="Smith" id_sentence="42" />
        <mention ids_tokens="15" string="Smith" id_sentence="43" />
        <mention ids_tokens="1" string="Smith" id_sentence="46" />
        <mention ids_tokens="13" string="Smith" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="12-13" string="Escondido 's" id_sentence="5" />
      <mentions>
        <mention ids_tokens="4" string="Escondido" id_sentence="57" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="12-13-14-15" string="Escondido 's Mindy Ireland" id_sentence="5" />
      <mentions>
        <mention ids_tokens="9" string="Ireland" id_sentence="38" />
        <mention ids_tokens="5" string="Ireland" id_sentence="41" />
        <mention ids_tokens="4" string="Ireland" id_sentence="42" />
        <mention ids_tokens="18-19" string="Ireland's" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="12-13" string="race officials" id_sentence="7" />
      <mentions>
        <mention ids_tokens="4" string="officials" id_sentence="8" />
        <mention ids_tokens="1" string="They" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="1-2" string="This year" id_sentence="8" />
      <mentions>
        <mention ids_tokens="10-11" string="the year" id_sentence="31" />
        <mention ids_tokens="13-16" string="his 112th to date" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="15" type="NOMINAL">
      <referenced ids_tokens="9-10-11" string="no mystery men" id_sentence="8" />
      <mentions>
        <mention ids_tokens="20-22" string="the men's" id_sentence="57" />
        <mention ids_tokens="7-9" string="the men's" id_sentence="58" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="24-25" string="the lead" id_sentence="9" />
      <mentions>
        <mention ids_tokens="16" string="it" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="18" type="PROPER">
      <referenced ids_tokens="12-13" string="just Rosas" id_sentence="15" />
      <mentions>
        <mention ids_tokens="1" string="Rosas" id_sentence="12" />
        <mention ids_tokens="2" string="I" id_sentence="13" />
        <mention ids_tokens="7" string="them" id_sentence="13" />
        <mention ids_tokens="2" string="I" id_sentence="14" />
        <mention ids_tokens="6-30" string="Rosas , who had broken away on his own for a three-mile lead at Mile 21 , cramped and been surprised at the 23-mile mark" id_sentence="23" />
        <mention ids_tokens="6" string="Rosas" id_sentence="23" />
        <mention ids_tokens="15-21" string="Rosas , who was third in 2:19.49" id_sentence="24" />
        <mention ids_tokens="15" string="Rosas" id_sentence="24" />
        <mention ids_tokens="3" string="he" id_sentence="25" />
        <mention ids_tokens="14" string="he" id_sentence="26" />
        <mention ids_tokens="18" string="Rosas" id_sentence="27" />
        <mention ids_tokens="5" string="Rosas" id_sentence="28" />
        <mention ids_tokens="4" string="Rosas" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="19" type="LIST">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9" string="Rosas and a pack of as many as eight" id_sentence="12" />
      <mentions>
        <mention ids_tokens="10" string="they" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8-9" string="a pack of as many as eight" id_sentence="12" />
      <mentions>
        <mention ids_tokens="4" string="it" id_sentence="13" />
        <mention ids_tokens="14" string="it" id_sentence="13" />
        <mention ids_tokens="6-7" string="the pack" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16-17-18-19-20-21" string="a pace seven to 10 seconds quicker per mile" id_sentence="12" />
      <mentions>
        <mention ids_tokens="27-28" string="mile pace" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="22" type="LIST">
      <referenced ids_tokens="12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30" string="just Rosas , Danny Bustos , Doug Kurtis and Ernesto Gutierrez , who ran single file for a time" id_sentence="15" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="52" />
        <mention ids_tokens="4-6" string="Rosas and Kurtis" id_sentence="52" />
        <mention ids_tokens="19" string="he" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="3" string="Rivera" id_sentence="20" />
      <mentions>
        <mention ids_tokens="1-5" string="Martinez and Martin Rodriguez Rivera" id_sentence="16" />
        <mention ids_tokens="18" string="him" id_sentence="16" />
        <mention ids_tokens="7" string="I" id_sentence="17" />
        <mention ids_tokens="2" string="I" id_sentence="18" />
        <mention ids_tokens="2" string="I" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="2-3-4-5" string="The first 10-15 miles" id_sentence="17" />
      <mentions>
        <mention ids_tokens="9-10" string="10-15 miles" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="26" type="PROPER">
      <referenced ids_tokens="2" string="left" id_sentence="20" />
      <mentions>
        <mention ids_tokens="9" string="it" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="19" string="third" id_sentence="24" />
      <mentions>
        <mention ids_tokens="10" string="my" id_sentence="25" />
        <mention ids_tokens="1" string="I" id_sentence="26" />
        <mention ids_tokens="18" string="me" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="31" type="PROPER">
      <referenced ids_tokens="21" string="2:19.49" id_sentence="24" />
      <mentions>
        <mention ids_tokens="7" string="that" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19" string="the second marathon in two weeks that Kurtis , 38 , has run , and almost won" id_sentence="30" />
      <mentions>
        <mention ids_tokens="5-6" string="the bikes" id_sentence="29" />
        <mention ids_tokens="9" string="me" id_sentence="29" />
        <mention ids_tokens="18" string="they" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="34" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17-18-19" string="two weeks that Kurtis , 38 , has run , and almost won" id_sentence="30" />
      <mentions>
        <mention ids_tokens="14-15" string="two weeks" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="10-11-12" string="Kurtis , 38" id_sentence="30" />
      <mentions>
        <mention ids_tokens="7" string="his" id_sentence="31" />
        <mention ids_tokens="13" string="his" id_sentence="31" />
        <mention ids_tokens="6" string="Kurtis" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="39" type="PRONOMINAL">
      <referenced ids_tokens="1" string="She" id_sentence="37" />
      <mentions>
        <mention ids_tokens="2" string="My" id_sentence="39" />
        <mention ids_tokens="21" string="her" id_sentence="41" />
        <mention ids_tokens="26" string="her" id_sentence="41" />
        <mention ids_tokens="8" string="her" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="40" type="PROPER">
      <referenced ids_tokens="3-4-5-6-7-8-9-10-11-12-13" string="a fourth - through sixth-grade teacher at College Park in Irvine" id_sentence="37" />
      <mentions>
        <mention ids_tokens="29" string="fourth" id_sentence="39" />
      </mentions>
    </coreference>
    <coreference id="41" type="PROPER">
      <referenced ids_tokens="29-30-31" string="fourth last year" id_sentence="39" />
      <mentions>
        <mention ids_tokens="5-6" string="last year" id_sentence="42" />
        <mention ids_tokens="2-4" string="earlier this year" id_sentence="46" />
        <mention ids_tokens="23-25" string="just a year" id_sentence="46" />
        <mention ids_tokens="2-3" string="Last year" id_sentence="48" />
        <mention ids_tokens="2-5" string="This year's it" id_sentence="49" />
        <mention ids_tokens="5" string="it" id_sentence="49" />
        <mention ids_tokens="8-11" string="a matter of maturity" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="43" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12" string="the latter part of a race" id_sentence="43" />
      <mentions>
        <mention ids_tokens="17-19" string="the latter part" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="44" type="PROPER">
      <referenced ids_tokens="7-8-9" string="Long Beach Marathon" id_sentence="46" />
      <mentions>
        <mention ids_tokens="6" string="it" id_sentence="47" />
        <mention ids_tokens="4" string="I" id_sentence="48" />
        <mention ids_tokens="7" string="me" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="13-14-15-16" string="a relatively weak field" id_sentence="52" />
      <mentions>
        <mention ids_tokens="4-5" string="this event" id_sentence="51" />
        <mention ids_tokens="13-14" string="the event" id_sentence="53" />
        <mention ids_tokens="2" string="It" id_sentence="54" />
        <mention ids_tokens="4-6" string="a beautiful course" id_sentence="54" />
        <mention ids_tokens="6" string="it" id_sentence="55" />
        <mention ids_tokens="9" string="that" id_sentence="56" />
        <mention ids_tokens="13-14" string="an inconvenience" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="46" type="NOMINAL">
      <referenced ids_tokens="9" string="this" id_sentence="54" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="55" />
      </mentions>
    </coreference>
  </coreferences>
</document>
