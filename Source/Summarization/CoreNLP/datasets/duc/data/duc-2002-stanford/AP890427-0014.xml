<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP890427-0014">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Bob Thomas has covered Hollywood for The Associated Press for 45 years.</content>
      <tokens>
        <token id="1" string="Bob" lemma="Bob" stem="bob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="covered" lemma="cover" stem="cover" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Associated" lemma="Associated" stem="associat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="9" string="Press" lemma="Press" stem="press" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="45" lemma="45" stem="45" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Bob) (NNP Thomas)) (VP (VBZ has) (VP (VBN covered) (NP (NP (NNP Hollywood)) (PP (IN for) (NP (DT The) (NNP Associated) (NNP Press)))) (PP (IN for) (NP (CD 45) (NNS years))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Hollywood" type="NP">
          <tokens>
            <token id="5" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="2" string="covered Hollywood for The Associated Press for 45 years" type="VP">
          <tokens>
            <token id="4" string="covered" />
            <token id="5" string="Hollywood" />
            <token id="6" string="for" />
            <token id="7" string="The" />
            <token id="8" string="Associated" />
            <token id="9" string="Press" />
            <token id="10" string="for" />
            <token id="11" string="45" />
            <token id="12" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="has covered Hollywood for The Associated Press for 45 years" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="covered" />
            <token id="5" string="Hollywood" />
            <token id="6" string="for" />
            <token id="7" string="The" />
            <token id="8" string="Associated" />
            <token id="9" string="Press" />
            <token id="10" string="for" />
            <token id="11" string="45" />
            <token id="12" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="Bob Thomas" type="NP">
          <tokens>
            <token id="1" string="Bob" />
            <token id="2" string="Thomas" />
          </tokens>
        </chunking>
        <chunking id="5" string="Hollywood for The Associated Press" type="NP">
          <tokens>
            <token id="5" string="Hollywood" />
            <token id="6" string="for" />
            <token id="7" string="The" />
            <token id="8" string="Associated" />
            <token id="9" string="Press" />
          </tokens>
        </chunking>
        <chunking id="6" string="The Associated Press" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="Associated" />
            <token id="9" string="Press" />
          </tokens>
        </chunking>
        <chunking id="7" string="45 years" type="NP">
          <tokens>
            <token id="11" string="45" />
            <token id="12" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Thomas</governor>
          <dependent id="1">Bob</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">covered</governor>
          <dependent id="2">Thomas</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">covered</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">covered</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">covered</governor>
          <dependent id="5">Hollywood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Press</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Press</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Press</governor>
          <dependent id="8">Associated</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">Hollywood</governor>
          <dependent id="9">Press</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">years</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">years</governor>
          <dependent id="11">45</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">covered</governor>
          <dependent id="12">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="5" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="2" string="Bob Thomas" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Bob" />
            <token id="2" string="Thomas" />
          </tokens>
        </entity>
        <entity id="3" string="Associated Press" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Associated" />
            <token id="9" string="Press" />
          </tokens>
        </entity>
        <entity id="4" string="45 years" type="DURATION" score="0.0">
          <tokens>
            <token id="11" string="45" />
            <token id="12" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>She never knew how great she was.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (ADVP (RB never)) (VP (VBD knew) (SBAR (WHADVP (WRB how) (ADJP (JJ great))) (S (NP (PRP she)) (VP (VBD was))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="how great she was" type="SBAR">
          <tokens>
            <token id="4" string="how" />
            <token id="5" string="great" />
            <token id="6" string="she" />
            <token id="7" string="was" />
          </tokens>
        </chunking>
        <chunking id="2" string="knew how great she was" type="VP">
          <tokens>
            <token id="3" string="knew" />
            <token id="4" string="how" />
            <token id="5" string="great" />
            <token id="6" string="she" />
            <token id="7" string="was" />
          </tokens>
        </chunking>
        <chunking id="3" string="was" type="VP">
          <tokens>
            <token id="7" string="was" />
          </tokens>
        </chunking>
        <chunking id="4" string="how great" type="WHADVP">
          <tokens>
            <token id="4" string="how" />
            <token id="5" string="great" />
          </tokens>
        </chunking>
        <chunking id="5" string="great" type="ADJP">
          <tokens>
            <token id="5" string="great" />
          </tokens>
        </chunking>
        <chunking id="6" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="6" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">knew</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">knew</governor>
          <dependent id="2">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">knew</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">was</governor>
          <dependent id="4">how</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">how</governor>
          <dependent id="5">great</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">was</governor>
          <dependent id="6">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">knew</governor>
          <dependent id="7">was</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Amid the blimp-size egos of the entertainment world, Lucille Ball stood out like an orange beacon.</content>
      <tokens>
        <token id="1" string="Amid" lemma="amid" stem="amid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="blimp-size" lemma="blimp-size" stem="blimp-siz" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="egos" lemma="ego" stem="ego" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="entertainment" lemma="entertainment" stem="entertain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="stood" lemma="stand" stem="stood" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="orange" lemma="orange" stem="orang" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="beacon" lemma="beacon" stem="beacon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Amid) (NP (NP (DT the) (JJ blimp-size) (NNS egos)) (PP (IN of) (NP (DT the) (NN entertainment) (NN world))))) (, ,) (NP (NNP Lucille) (NNP Ball)) (VP (VBD stood) (PRT (RP out)) (PP (IN like) (NP (DT an) (JJ orange) (NN beacon)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the entertainment world" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="entertainment" />
            <token id="8" string="world" />
          </tokens>
        </chunking>
        <chunking id="2" string="an orange beacon" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="orange" />
            <token id="17" string="beacon" />
          </tokens>
        </chunking>
        <chunking id="3" string="the blimp-size egos of the entertainment world" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="blimp-size" />
            <token id="4" string="egos" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="entertainment" />
            <token id="8" string="world" />
          </tokens>
        </chunking>
        <chunking id="4" string="the blimp-size egos" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="blimp-size" />
            <token id="4" string="egos" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lucille Ball" type="NP">
          <tokens>
            <token id="10" string="Lucille" />
            <token id="11" string="Ball" />
          </tokens>
        </chunking>
        <chunking id="6" string="stood out like an orange beacon" type="VP">
          <tokens>
            <token id="12" string="stood" />
            <token id="13" string="out" />
            <token id="14" string="like" />
            <token id="15" string="an" />
            <token id="16" string="orange" />
            <token id="17" string="beacon" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">egos</governor>
          <dependent id="1">Amid</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">egos</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">egos</governor>
          <dependent id="3">blimp-size</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">stood</governor>
          <dependent id="4">egos</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">world</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">world</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">world</governor>
          <dependent id="7">entertainment</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">egos</governor>
          <dependent id="8">world</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Ball</governor>
          <dependent id="10">Lucille</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">stood</governor>
          <dependent id="11">Ball</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">stood</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="12">stood</governor>
          <dependent id="13">out</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">beacon</governor>
          <dependent id="14">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">beacon</governor>
          <dependent id="15">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">beacon</governor>
          <dependent id="16">orange</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">stood</governor>
          <dependent id="17">beacon</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucille Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Lucille" />
            <token id="11" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>She never bragged.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="bragged" lemma="brag" stem="brag" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (ADVP (RB never)) (VP (VBD bragged)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="bragged" type="VP">
          <tokens>
            <token id="3" string="bragged" />
          </tokens>
        </chunking>
        <chunking id="2" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">bragged</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">bragged</governor>
          <dependent id="2">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">bragged</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>She never exercised her considerable power.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="exercised" lemma="exercise" stem="exercis" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="considerable" lemma="considerable" stem="consider" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (ADVP (RB never)) (VP (VBD exercised) (NP (PRP$ her) (JJ considerable) (NN power))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her considerable power" type="NP">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="considerable" />
            <token id="6" string="power" />
          </tokens>
        </chunking>
        <chunking id="2" string="exercised her considerable power" type="VP">
          <tokens>
            <token id="3" string="exercised" />
            <token id="4" string="her" />
            <token id="5" string="considerable" />
            <token id="6" string="power" />
          </tokens>
        </chunking>
        <chunking id="3" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">exercised</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">exercised</governor>
          <dependent id="2">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">exercised</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">power</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">power</governor>
          <dependent id="5">considerable</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">exercised</governor>
          <dependent id="6">power</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>She always seemed astonished, even embarrassed, when honors inevitably came her way.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="seemed" lemma="seem" stem="seem" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="astonished" lemma="astonished" stem="astonish" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="embarrassed" lemma="embarrassed" stem="embarrass" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="honors" lemma="honor" stem="honor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="inevitably" lemma="inevitably" stem="inevit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="14" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (ADVP (RB always)) (VP (VBD seemed) (ADJP (JJ astonished) (, ,) (RB even) (JJ embarrassed)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NNS honors)) (ADVP (RB inevitably)) (VP (VBD came) (NP (PRP$ her) (NN way)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="when honors inevitably came her way" type="SBAR">
          <tokens>
            <token id="9" string="when" />
            <token id="10" string="honors" />
            <token id="11" string="inevitably" />
            <token id="12" string="came" />
            <token id="13" string="her" />
            <token id="14" string="way" />
          </tokens>
        </chunking>
        <chunking id="2" string="came her way" type="VP">
          <tokens>
            <token id="12" string="came" />
            <token id="13" string="her" />
            <token id="14" string="way" />
          </tokens>
        </chunking>
        <chunking id="3" string="astonished , even embarrassed" type="ADJP">
          <tokens>
            <token id="4" string="astonished" />
            <token id="5" string="," />
            <token id="6" string="even" />
            <token id="7" string="embarrassed" />
          </tokens>
        </chunking>
        <chunking id="4" string="seemed astonished , even embarrassed , when honors inevitably came her way" type="VP">
          <tokens>
            <token id="3" string="seemed" />
            <token id="4" string="astonished" />
            <token id="5" string="," />
            <token id="6" string="even" />
            <token id="7" string="embarrassed" />
            <token id="8" string="," />
            <token id="9" string="when" />
            <token id="10" string="honors" />
            <token id="11" string="inevitably" />
            <token id="12" string="came" />
            <token id="13" string="her" />
            <token id="14" string="way" />
          </tokens>
        </chunking>
        <chunking id="5" string="her way" type="NP">
          <tokens>
            <token id="13" string="her" />
            <token id="14" string="way" />
          </tokens>
        </chunking>
        <chunking id="6" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="9" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="honors" type="NP">
          <tokens>
            <token id="10" string="honors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">seemed</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">seemed</governor>
          <dependent id="2">always</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">seemed</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">embarrassed</governor>
          <dependent id="4">astonished</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">embarrassed</governor>
          <dependent id="6">even</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">seemed</governor>
          <dependent id="7">embarrassed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">came</governor>
          <dependent id="9">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">came</governor>
          <dependent id="10">honors</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">came</governor>
          <dependent id="11">inevitably</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">seemed</governor>
          <dependent id="12">came</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">way</governor>
          <dependent id="13">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">came</governor>
          <dependent id="14">way</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>When she was to receive a humanitarian award from Variety Clubs on a CBS special five years ago, she told me: ``There comes a time in your life when you get a lot of plaques.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="receive" lemma="receive" stem="receiv" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="humanitarian" lemma="humanitarian" stem="humanitarian" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Variety" lemma="Variety" stem="varieti" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="Clubs" lemma="club" stem="club" pos="NNS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="CBS" lemma="CBS" stem="cbs" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="15" string="special" lemma="special" stem="special" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="17" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="18" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="plaques" lemma="plaque" stem="plaqu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (PRP she)) (VP (VBD was) (S (VP (TO to) (VP (VB receive) (NP (DT a) (JJ humanitarian) (NN award)) (PP (IN from) (NP (NNP Variety) (NNS Clubs))) (PP (IN on) (NP (NP (DT a) (NNP CBS)) (JJ special)) (ADVP (NP (CD five) (NNS years)) (RB ago))))))))) (, ,) (NP (PRP she)) (VP (VBD told) (NP (PRP me)) (: :) (`` ``) (S (NP (EX There)) (VP (VBZ comes) (NP (NP (DT a) (NN time)) (PP (IN in) (NP (PRP$ your) (NN life))) (SBAR (WHADVP (WRB when)) (S (NP (PRP you)) (VP (VBP get) (NP (NP (DT a) (NN lot)) (PP (IN of) (NP (NNS plaques))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="receive a humanitarian award from Variety Clubs on a CBS special five years ago" type="VP">
          <tokens>
            <token id="5" string="receive" />
            <token id="6" string="a" />
            <token id="7" string="humanitarian" />
            <token id="8" string="award" />
            <token id="9" string="from" />
            <token id="10" string="Variety" />
            <token id="11" string="Clubs" />
            <token id="12" string="on" />
            <token id="13" string="a" />
            <token id="14" string="CBS" />
            <token id="15" string="special" />
            <token id="16" string="five" />
            <token id="17" string="years" />
            <token id="18" string="ago" />
          </tokens>
        </chunking>
        <chunking id="2" string="comes a time in your life when you get a lot of plaques" type="VP">
          <tokens>
            <token id="26" string="comes" />
            <token id="27" string="a" />
            <token id="28" string="time" />
            <token id="29" string="in" />
            <token id="30" string="your" />
            <token id="31" string="life" />
            <token id="32" string="when" />
            <token id="33" string="you" />
            <token id="34" string="get" />
            <token id="35" string="a" />
            <token id="36" string="lot" />
            <token id="37" string="of" />
            <token id="38" string="plaques" />
          </tokens>
        </chunking>
        <chunking id="3" string="get a lot of plaques" type="VP">
          <tokens>
            <token id="34" string="get" />
            <token id="35" string="a" />
            <token id="36" string="lot" />
            <token id="37" string="of" />
            <token id="38" string="plaques" />
          </tokens>
        </chunking>
        <chunking id="4" string="was to receive a humanitarian award from Variety Clubs on a CBS special five years ago" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="to" />
            <token id="5" string="receive" />
            <token id="6" string="a" />
            <token id="7" string="humanitarian" />
            <token id="8" string="award" />
            <token id="9" string="from" />
            <token id="10" string="Variety" />
            <token id="11" string="Clubs" />
            <token id="12" string="on" />
            <token id="13" string="a" />
            <token id="14" string="CBS" />
            <token id="15" string="special" />
            <token id="16" string="five" />
            <token id="17" string="years" />
            <token id="18" string="ago" />
          </tokens>
        </chunking>
        <chunking id="5" string="plaques" type="NP">
          <tokens>
            <token id="38" string="plaques" />
          </tokens>
        </chunking>
        <chunking id="6" string="a humanitarian award" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="humanitarian" />
            <token id="8" string="award" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="a CBS special" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="CBS" />
            <token id="15" string="special" />
          </tokens>
        </chunking>
        <chunking id="9" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="10" string="a CBS" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="11" string="a lot" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="lot" />
          </tokens>
        </chunking>
        <chunking id="12" string="your life" type="NP">
          <tokens>
            <token id="30" string="your" />
            <token id="31" string="life" />
          </tokens>
        </chunking>
        <chunking id="13" string="to receive a humanitarian award from Variety Clubs on a CBS special five years ago" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="receive" />
            <token id="6" string="a" />
            <token id="7" string="humanitarian" />
            <token id="8" string="award" />
            <token id="9" string="from" />
            <token id="10" string="Variety" />
            <token id="11" string="Clubs" />
            <token id="12" string="on" />
            <token id="13" string="a" />
            <token id="14" string="CBS" />
            <token id="15" string="special" />
            <token id="16" string="five" />
            <token id="17" string="years" />
            <token id="18" string="ago" />
          </tokens>
        </chunking>
        <chunking id="14" string="told me : `` There comes a time in your life when you get a lot of plaques" type="VP">
          <tokens>
            <token id="21" string="told" />
            <token id="22" string="me" />
            <token id="23" string=":" />
            <token id="24" string="``" />
            <token id="25" string="There" />
            <token id="26" string="comes" />
            <token id="27" string="a" />
            <token id="28" string="time" />
            <token id="29" string="in" />
            <token id="30" string="your" />
            <token id="31" string="life" />
            <token id="32" string="when" />
            <token id="33" string="you" />
            <token id="34" string="get" />
            <token id="35" string="a" />
            <token id="36" string="lot" />
            <token id="37" string="of" />
            <token id="38" string="plaques" />
          </tokens>
        </chunking>
        <chunking id="15" string="a lot of plaques" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="lot" />
            <token id="37" string="of" />
            <token id="38" string="plaques" />
          </tokens>
        </chunking>
        <chunking id="16" string="a time in your life when you get a lot of plaques" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="time" />
            <token id="29" string="in" />
            <token id="30" string="your" />
            <token id="31" string="life" />
            <token id="32" string="when" />
            <token id="33" string="you" />
            <token id="34" string="get" />
            <token id="35" string="a" />
            <token id="36" string="lot" />
            <token id="37" string="of" />
            <token id="38" string="plaques" />
          </tokens>
        </chunking>
        <chunking id="17" string="Variety Clubs" type="NP">
          <tokens>
            <token id="10" string="Variety" />
            <token id="11" string="Clubs" />
          </tokens>
        </chunking>
        <chunking id="18" string="When she was to receive a humanitarian award from Variety Clubs on a CBS special five years ago" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="she" />
            <token id="3" string="was" />
            <token id="4" string="to" />
            <token id="5" string="receive" />
            <token id="6" string="a" />
            <token id="7" string="humanitarian" />
            <token id="8" string="award" />
            <token id="9" string="from" />
            <token id="10" string="Variety" />
            <token id="11" string="Clubs" />
            <token id="12" string="on" />
            <token id="13" string="a" />
            <token id="14" string="CBS" />
            <token id="15" string="special" />
            <token id="16" string="five" />
            <token id="17" string="years" />
            <token id="18" string="ago" />
          </tokens>
        </chunking>
        <chunking id="19" string="when" type="WHADVP">
          <tokens>
            <token id="32" string="when" />
          </tokens>
        </chunking>
        <chunking id="20" string="five years" type="NP">
          <tokens>
            <token id="16" string="five" />
            <token id="17" string="years" />
          </tokens>
        </chunking>
        <chunking id="21" string="There" type="NP">
          <tokens>
            <token id="25" string="There" />
          </tokens>
        </chunking>
        <chunking id="22" string="a time" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="time" />
          </tokens>
        </chunking>
        <chunking id="23" string="me" type="NP">
          <tokens>
            <token id="22" string="me" />
          </tokens>
        </chunking>
        <chunking id="24" string="when you get a lot of plaques" type="SBAR">
          <tokens>
            <token id="32" string="when" />
            <token id="33" string="you" />
            <token id="34" string="get" />
            <token id="35" string="a" />
            <token id="36" string="lot" />
            <token id="37" string="of" />
            <token id="38" string="plaques" />
          </tokens>
        </chunking>
        <chunking id="25" string="you" type="NP">
          <tokens>
            <token id="33" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">was</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">was</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">told</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">receive</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">was</governor>
          <dependent id="5">receive</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">award</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">award</governor>
          <dependent id="7">humanitarian</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">receive</governor>
          <dependent id="8">award</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Clubs</governor>
          <dependent id="9">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Clubs</governor>
          <dependent id="10">Variety</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">receive</governor>
          <dependent id="11">Clubs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">CBS</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">CBS</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">receive</governor>
          <dependent id="14">CBS</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">CBS</governor>
          <dependent id="15">special</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">years</governor>
          <dependent id="16">five</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="18">ago</governor>
          <dependent id="17">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">CBS</governor>
          <dependent id="18">ago</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">told</governor>
          <dependent id="20">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="21">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">told</governor>
          <dependent id="22">me</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="26">comes</governor>
          <dependent id="25">There</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">told</governor>
          <dependent id="26">comes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">time</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">comes</governor>
          <dependent id="28">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">life</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="31">life</governor>
          <dependent id="30">your</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">time</governor>
          <dependent id="31">life</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">get</governor>
          <dependent id="32">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">get</governor>
          <dependent id="33">you</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="28">time</governor>
          <dependent id="34">get</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">lot</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">get</governor>
          <dependent id="36">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">plaques</governor>
          <dependent id="37">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">lot</governor>
          <dependent id="38">plaques</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CBS" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="CBS" />
          </tokens>
        </entity>
        <entity id="2" string="Variety Clubs" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Variety" />
            <token id="11" string="Clubs" />
          </tokens>
        </entity>
        <entity id="3" string="five years ago" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="five" />
            <token id="17" string="years" />
            <token id="18" string="ago" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>It&amp;apost;s very flattering and I&amp;apost;ll go along with it, especially if it benefits children.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="flattering" lemma="flattering" stem="flatter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="'ll" lemma="will" stem="'ll" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="along" lemma="along" stem="along" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="benefits" lemma="benefit" stem="benefit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBZ 's) (ADJP (RB very) (JJ flattering)))) (CC and) (S (NP (PRP I)) (VP (MD 'll) (VP (VB go) (PRT (RP along)) (PP (IN with) (NP (PRP it))) (, ,) (SBAR (RB especially) (IN if) (S (NP (PRP it)) (VP (VBZ benefits) (NP (NNS children)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="especially if it benefits children" type="SBAR">
          <tokens>
            <token id="13" string="especially" />
            <token id="14" string="if" />
            <token id="15" string="it" />
            <token id="16" string="benefits" />
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="2" string="go along with it , especially if it benefits children" type="VP">
          <tokens>
            <token id="8" string="go" />
            <token id="9" string="along" />
            <token id="10" string="with" />
            <token id="11" string="it" />
            <token id="12" string="," />
            <token id="13" string="especially" />
            <token id="14" string="if" />
            <token id="15" string="it" />
            <token id="16" string="benefits" />
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s very flattering" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="very" />
            <token id="4" string="flattering" />
          </tokens>
        </chunking>
        <chunking id="4" string="very flattering" type="ADJP">
          <tokens>
            <token id="3" string="very" />
            <token id="4" string="flattering" />
          </tokens>
        </chunking>
        <chunking id="5" string="children" type="NP">
          <tokens>
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="'ll go along with it , especially if it benefits children" type="VP">
          <tokens>
            <token id="7" string="'ll" />
            <token id="8" string="go" />
            <token id="9" string="along" />
            <token id="10" string="with" />
            <token id="11" string="it" />
            <token id="12" string="," />
            <token id="13" string="especially" />
            <token id="14" string="if" />
            <token id="15" string="it" />
            <token id="16" string="benefits" />
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="benefits children" type="VP">
          <tokens>
            <token id="16" string="benefits" />
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="11" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">flattering</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">flattering</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">flattering</governor>
          <dependent id="3">very</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">flattering</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">flattering</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">go</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">go</governor>
          <dependent id="7">'ll</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">flattering</governor>
          <dependent id="8">go</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">go</governor>
          <dependent id="9">along</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">it</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">go</governor>
          <dependent id="11">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">benefits</governor>
          <dependent id="13">especially</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">benefits</governor>
          <dependent id="14">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">benefits</governor>
          <dependent id="15">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="8">go</governor>
          <dependent id="16">benefits</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">benefits</governor>
          <dependent id="17">children</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Whenever she was praised for ``I Love Lucy,&amp;apost;&amp;apost; she invariably replied: ``Well, all of the credit should go to (writers) Madelyn Pugh and Bob Carroll Jr.&amp;apost;&amp;apost; Or, ``Desi was a genius: He was responsible for the show&amp;apost;s success.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Whenever" lemma="Whenever" stem="whenev" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="praised" lemma="praise" stem="prais" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="invariably" lemma="invariably" stem="invari" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="replied" lemma="reply" stem="repli" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Well" lemma="well" stem="well" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="credit" lemma="credit" stem="credit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="should" lemma="should" stem="should" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="writers" lemma="writer" stem="writer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Madelyn" lemma="Madelyn" stem="madelyn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="30" string="Pugh" lemma="Pugh" stem="pugh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Bob" lemma="Bob" stem="bob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="33" string="Carroll" lemma="Carroll" stem="carrol" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="34" string="Jr." lemma="Jr." stem="jr." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="35" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="Desi" lemma="desi" stem="desi" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="40" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="genius" lemma="genius" stem="geniu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="responsible" lemma="responsible" stem="respons" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="49" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="50" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="51" string="success" lemma="success" stem="success" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Whenever) (PRP she)) (VP (VBD was) (VP (VBN praised) (PP (IN for) (`` ``) (NP (NP (PRP I)) (SBAR (S (NP (NNP Love) (NNP Lucy)) (, ,) ('' '') (NP (PRP she)) (ADVP (RB invariably)) (VP (VBD replied) (: :) (`` ``) (S (INTJ (UH Well)) (, ,) (NP (NP (DT all)) (PP (IN of) (NP (DT the) (NN credit)))) (VP (MD should) (VP (VB go) (PP (TO to) (NP (NP (PRN (-LRB- -LRB-) (NP (NNS writers)) (-RRB- -RRB-)) (NNP Madelyn) (NNP Pugh)) (CC and) (NP (NNP Bob) (NNP Carroll) (NNP Jr.))))))))))) ('' ''))))) (CC Or) (, ,) (`` ``) (S (NP (NN Desi)) (VP (VBD was) (NP (NP (DT a) (NN genius)) (: :) (S (NP (PRP He)) (VP (VBD was) (ADJP (JJ responsible) (PP (IN for) (NP (NP (DT the) (NN show) (POS 's)) (NN success))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="19" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="was praised for `` I Love Lucy , '' she invariably replied : `` Well , all of the credit should go to -LRB- writers -RRB- Madelyn Pugh and Bob Carroll Jr. ''" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="praised" />
            <token id="5" string="for" />
            <token id="6" string="``" />
            <token id="7" string="I" />
            <token id="8" string="Love" />
            <token id="9" string="Lucy" />
            <token id="10" string="," />
            <token id="11" string="''" />
            <token id="12" string="she" />
            <token id="13" string="invariably" />
            <token id="14" string="replied" />
            <token id="15" string=":" />
            <token id="16" string="``" />
            <token id="17" string="Well" />
            <token id="18" string="," />
            <token id="19" string="all" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="credit" />
            <token id="23" string="should" />
            <token id="24" string="go" />
            <token id="25" string="to" />
            <token id="26" string="(" />
            <token id="27" string="writers" />
            <token id="28" string=")" />
            <token id="29" string="Madelyn" />
            <token id="30" string="Pugh" />
            <token id="31" string="and" />
            <token id="32" string="Bob" />
            <token id="33" string="Carroll" />
            <token id="34" string="Jr." />
            <token id="35" string="''" />
          </tokens>
        </chunking>
        <chunking id="3" string="was a genius : He was responsible for the show 's success" type="VP">
          <tokens>
            <token id="40" string="was" />
            <token id="41" string="a" />
            <token id="42" string="genius" />
            <token id="43" string=":" />
            <token id="44" string="He" />
            <token id="45" string="was" />
            <token id="46" string="responsible" />
            <token id="47" string="for" />
            <token id="48" string="the" />
            <token id="49" string="show" />
            <token id="50" string="'s" />
            <token id="51" string="success" />
          </tokens>
        </chunking>
        <chunking id="4" string="-LRB- writers -RRB- Madelyn Pugh and Bob Carroll Jr." type="NP">
          <tokens>
            <token id="26" string="(" />
            <token id="27" string="writers" />
            <token id="28" string=")" />
            <token id="29" string="Madelyn" />
            <token id="30" string="Pugh" />
            <token id="31" string="and" />
            <token id="32" string="Bob" />
            <token id="33" string="Carroll" />
            <token id="34" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="5" string="responsible for the show 's success" type="ADJP">
          <tokens>
            <token id="46" string="responsible" />
            <token id="47" string="for" />
            <token id="48" string="the" />
            <token id="49" string="show" />
            <token id="50" string="'s" />
            <token id="51" string="success" />
          </tokens>
        </chunking>
        <chunking id="6" string="should go to -LRB- writers -RRB- Madelyn Pugh and Bob Carroll Jr." type="VP">
          <tokens>
            <token id="23" string="should" />
            <token id="24" string="go" />
            <token id="25" string="to" />
            <token id="26" string="(" />
            <token id="27" string="writers" />
            <token id="28" string=")" />
            <token id="29" string="Madelyn" />
            <token id="30" string="Pugh" />
            <token id="31" string="and" />
            <token id="32" string="Bob" />
            <token id="33" string="Carroll" />
            <token id="34" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="7" string="praised for `` I Love Lucy , '' she invariably replied : `` Well , all of the credit should go to -LRB- writers -RRB- Madelyn Pugh and Bob Carroll Jr. ''" type="VP">
          <tokens>
            <token id="4" string="praised" />
            <token id="5" string="for" />
            <token id="6" string="``" />
            <token id="7" string="I" />
            <token id="8" string="Love" />
            <token id="9" string="Lucy" />
            <token id="10" string="," />
            <token id="11" string="''" />
            <token id="12" string="she" />
            <token id="13" string="invariably" />
            <token id="14" string="replied" />
            <token id="15" string=":" />
            <token id="16" string="``" />
            <token id="17" string="Well" />
            <token id="18" string="," />
            <token id="19" string="all" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="credit" />
            <token id="23" string="should" />
            <token id="24" string="go" />
            <token id="25" string="to" />
            <token id="26" string="(" />
            <token id="27" string="writers" />
            <token id="28" string=")" />
            <token id="29" string="Madelyn" />
            <token id="30" string="Pugh" />
            <token id="31" string="and" />
            <token id="32" string="Bob" />
            <token id="33" string="Carroll" />
            <token id="34" string="Jr." />
            <token id="35" string="''" />
          </tokens>
        </chunking>
        <chunking id="8" string="Bob Carroll Jr." type="NP">
          <tokens>
            <token id="32" string="Bob" />
            <token id="33" string="Carroll" />
            <token id="34" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="9" string="the show 's" type="NP">
          <tokens>
            <token id="48" string="the" />
            <token id="49" string="show" />
            <token id="50" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="replied : `` Well , all of the credit should go to -LRB- writers -RRB- Madelyn Pugh and Bob Carroll Jr." type="VP">
          <tokens>
            <token id="14" string="replied" />
            <token id="15" string=":" />
            <token id="16" string="``" />
            <token id="17" string="Well" />
            <token id="18" string="," />
            <token id="19" string="all" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="credit" />
            <token id="23" string="should" />
            <token id="24" string="go" />
            <token id="25" string="to" />
            <token id="26" string="(" />
            <token id="27" string="writers" />
            <token id="28" string=")" />
            <token id="29" string="Madelyn" />
            <token id="30" string="Pugh" />
            <token id="31" string="and" />
            <token id="32" string="Bob" />
            <token id="33" string="Carroll" />
            <token id="34" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="12" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="was responsible for the show 's success" type="VP">
          <tokens>
            <token id="45" string="was" />
            <token id="46" string="responsible" />
            <token id="47" string="for" />
            <token id="48" string="the" />
            <token id="49" string="show" />
            <token id="50" string="'s" />
            <token id="51" string="success" />
          </tokens>
        </chunking>
        <chunking id="13" string="Love Lucy" type="NP">
          <tokens>
            <token id="8" string="Love" />
            <token id="9" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="14" string="Love Lucy , '' she invariably replied : `` Well , all of the credit should go to -LRB- writers -RRB- Madelyn Pugh and Bob Carroll Jr." type="SBAR">
          <tokens>
            <token id="8" string="Love" />
            <token id="9" string="Lucy" />
            <token id="10" string="," />
            <token id="11" string="''" />
            <token id="12" string="she" />
            <token id="13" string="invariably" />
            <token id="14" string="replied" />
            <token id="15" string=":" />
            <token id="16" string="``" />
            <token id="17" string="Well" />
            <token id="18" string="," />
            <token id="19" string="all" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="credit" />
            <token id="23" string="should" />
            <token id="24" string="go" />
            <token id="25" string="to" />
            <token id="26" string="(" />
            <token id="27" string="writers" />
            <token id="28" string=")" />
            <token id="29" string="Madelyn" />
            <token id="30" string="Pugh" />
            <token id="31" string="and" />
            <token id="32" string="Bob" />
            <token id="33" string="Carroll" />
            <token id="34" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="15" string="the show 's success" type="NP">
          <tokens>
            <token id="48" string="the" />
            <token id="49" string="show" />
            <token id="50" string="'s" />
            <token id="51" string="success" />
          </tokens>
        </chunking>
        <chunking id="16" string="all of the credit" type="NP">
          <tokens>
            <token id="19" string="all" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="credit" />
          </tokens>
        </chunking>
        <chunking id="17" string="Whenever she" type="NP">
          <tokens>
            <token id="1" string="Whenever" />
            <token id="2" string="she" />
          </tokens>
        </chunking>
        <chunking id="18" string="I" type="NP">
          <tokens>
            <token id="7" string="I" />
          </tokens>
        </chunking>
        <chunking id="19" string="a genius" type="NP">
          <tokens>
            <token id="41" string="a" />
            <token id="42" string="genius" />
          </tokens>
        </chunking>
        <chunking id="20" string="-LRB- writers -RRB- Madelyn Pugh" type="NP">
          <tokens>
            <token id="26" string="(" />
            <token id="27" string="writers" />
            <token id="28" string=")" />
            <token id="29" string="Madelyn" />
            <token id="30" string="Pugh" />
          </tokens>
        </chunking>
        <chunking id="21" string="writers" type="NP">
          <tokens>
            <token id="27" string="writers" />
          </tokens>
        </chunking>
        <chunking id="22" string="go to -LRB- writers -RRB- Madelyn Pugh and Bob Carroll Jr." type="VP">
          <tokens>
            <token id="24" string="go" />
            <token id="25" string="to" />
            <token id="26" string="(" />
            <token id="27" string="writers" />
            <token id="28" string=")" />
            <token id="29" string="Madelyn" />
            <token id="30" string="Pugh" />
            <token id="31" string="and" />
            <token id="32" string="Bob" />
            <token id="33" string="Carroll" />
            <token id="34" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="23" string="Desi" type="NP">
          <tokens>
            <token id="39" string="Desi" />
          </tokens>
        </chunking>
        <chunking id="24" string="I Love Lucy , '' she invariably replied : `` Well , all of the credit should go to -LRB- writers -RRB- Madelyn Pugh and Bob Carroll Jr." type="NP">
          <tokens>
            <token id="7" string="I" />
            <token id="8" string="Love" />
            <token id="9" string="Lucy" />
            <token id="10" string="," />
            <token id="11" string="''" />
            <token id="12" string="she" />
            <token id="13" string="invariably" />
            <token id="14" string="replied" />
            <token id="15" string=":" />
            <token id="16" string="``" />
            <token id="17" string="Well" />
            <token id="18" string="," />
            <token id="19" string="all" />
            <token id="20" string="of" />
            <token id="21" string="the" />
            <token id="22" string="credit" />
            <token id="23" string="should" />
            <token id="24" string="go" />
            <token id="25" string="to" />
            <token id="26" string="(" />
            <token id="27" string="writers" />
            <token id="28" string=")" />
            <token id="29" string="Madelyn" />
            <token id="30" string="Pugh" />
            <token id="31" string="and" />
            <token id="32" string="Bob" />
            <token id="33" string="Carroll" />
            <token id="34" string="Jr." />
          </tokens>
        </chunking>
        <chunking id="25" string="a genius : He was responsible for the show 's success" type="NP">
          <tokens>
            <token id="41" string="a" />
            <token id="42" string="genius" />
            <token id="43" string=":" />
            <token id="44" string="He" />
            <token id="45" string="was" />
            <token id="46" string="responsible" />
            <token id="47" string="for" />
            <token id="48" string="the" />
            <token id="49" string="show" />
            <token id="50" string="'s" />
            <token id="51" string="success" />
          </tokens>
        </chunking>
        <chunking id="26" string="He" type="NP">
          <tokens>
            <token id="44" string="He" />
          </tokens>
        </chunking>
        <chunking id="27" string="the credit" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="credit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">praised</governor>
          <dependent id="1">Whenever</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Whenever</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">praised</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">praised</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">I</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">praised</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Lucy</governor>
          <dependent id="8">Love</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">replied</governor>
          <dependent id="9">Lucy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">replied</governor>
          <dependent id="12">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">replied</governor>
          <dependent id="13">invariably</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">I</governor>
          <dependent id="14">replied</dependent>
        </dependency>
        <dependency type="discourse">
          <governor id="24">go</governor>
          <dependent id="17">Well</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">go</governor>
          <dependent id="19">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">credit</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">credit</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">all</governor>
          <dependent id="22">credit</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">go</governor>
          <dependent id="23">should</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">replied</governor>
          <dependent id="24">go</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Pugh</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="30">Pugh</governor>
          <dependent id="27">writers</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Pugh</governor>
          <dependent id="29">Madelyn</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">go</governor>
          <dependent id="30">Pugh</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">Pugh</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Jr.</governor>
          <dependent id="32">Bob</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Jr.</governor>
          <dependent id="33">Carroll</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">Pugh</governor>
          <dependent id="34">Jr.</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">praised</governor>
          <dependent id="36">Or</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">genius</governor>
          <dependent id="39">Desi</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="42">genius</governor>
          <dependent id="40">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">genius</governor>
          <dependent id="41">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">praised</governor>
          <dependent id="42">genius</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">responsible</governor>
          <dependent id="44">He</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="46">responsible</governor>
          <dependent id="45">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="42">genius</governor>
          <dependent id="46">responsible</dependent>
        </dependency>
        <dependency type="case">
          <governor id="51">success</governor>
          <dependent id="47">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="49">show</governor>
          <dependent id="48">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="51">success</governor>
          <dependent id="49">show</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">show</governor>
          <dependent id="50">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">responsible</governor>
          <dependent id="51">success</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Desi" type="PERSON" score="0.0">
          <tokens>
            <token id="39" string="Desi" />
          </tokens>
        </entity>
        <entity id="2" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Lucy" />
          </tokens>
        </entity>
        <entity id="3" string="Madelyn Pugh" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Madelyn" />
            <token id="30" string="Pugh" />
          </tokens>
        </entity>
        <entity id="4" string="Bob Carroll Jr." type="PERSON" score="0.0">
          <tokens>
            <token id="32" string="Bob" />
            <token id="33" string="Carroll" />
            <token id="34" string="Jr." />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Or she cited co-stars Desi, Vivian Vance and Bill Frawley.</content>
      <tokens>
        <token id="1" string="Or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="cited" lemma="cite" stem="cite" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="co-stars" lemma="co-star" stem="co-star" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Desi" lemma="desus" stem="desi" pos="NNS" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Vivian" lemma="Vivian" stem="vivian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="Vance" lemma="Vance" stem="vanc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Bill" lemma="Bill" stem="bill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="Frawley" lemma="Frawley" stem="frawlei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC Or) (NP (PRP she)) (VP (VBD cited) (NP (NP (NNS co-stars) (NNS Desi)) (, ,) (NP (NNP Vivian) (NNP Vance)) (CC and) (NP (NNP Bill) (NNP Frawley)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Bill Frawley" type="NP">
          <tokens>
            <token id="10" string="Bill" />
            <token id="11" string="Frawley" />
          </tokens>
        </chunking>
        <chunking id="2" string="co-stars Desi" type="NP">
          <tokens>
            <token id="4" string="co-stars" />
            <token id="5" string="Desi" />
          </tokens>
        </chunking>
        <chunking id="3" string="co-stars Desi , Vivian Vance and Bill Frawley" type="NP">
          <tokens>
            <token id="4" string="co-stars" />
            <token id="5" string="Desi" />
            <token id="6" string="," />
            <token id="7" string="Vivian" />
            <token id="8" string="Vance" />
            <token id="9" string="and" />
            <token id="10" string="Bill" />
            <token id="11" string="Frawley" />
          </tokens>
        </chunking>
        <chunking id="4" string="cited co-stars Desi , Vivian Vance and Bill Frawley" type="VP">
          <tokens>
            <token id="3" string="cited" />
            <token id="4" string="co-stars" />
            <token id="5" string="Desi" />
            <token id="6" string="," />
            <token id="7" string="Vivian" />
            <token id="8" string="Vance" />
            <token id="9" string="and" />
            <token id="10" string="Bill" />
            <token id="11" string="Frawley" />
          </tokens>
        </chunking>
        <chunking id="5" string="Vivian Vance" type="NP">
          <tokens>
            <token id="7" string="Vivian" />
            <token id="8" string="Vance" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="2" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">cited</governor>
          <dependent id="1">Or</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">cited</governor>
          <dependent id="2">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">cited</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Desi</governor>
          <dependent id="4">co-stars</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">cited</governor>
          <dependent id="5">Desi</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Vance</governor>
          <dependent id="7">Vivian</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">Desi</governor>
          <dependent id="8">Vance</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">Desi</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Frawley</governor>
          <dependent id="10">Bill</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">Desi</governor>
          <dependent id="11">Frawley</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bill Frawley" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Bill" />
            <token id="11" string="Frawley" />
          </tokens>
        </entity>
        <entity id="2" string="Desi" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Desi" />
          </tokens>
        </entity>
        <entity id="3" string="Vivian Vance" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Vivian" />
            <token id="8" string="Vance" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Yes, the writing and producing and casting of ``I Love Lucy&amp;apost;&amp;apost; were marvelous, but Lucy&amp;apost;s performance added the quantum force.</content>
      <tokens>
        <token id="1" string="Yes" lemma="yes" stem="ye" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="writing" lemma="writing" stem="write" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="producing" lemma="produce" stem="produc" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="casting" lemma="cast" stem="cast" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="marvelous" lemma="marvelous" stem="marvel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="21" string="performance" lemma="performance" stem="perform" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="quantum" lemma="quantum" stem="quantum" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="force" lemma="force" stem="forc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (INTJ (UH Yes)) (, ,) (S (UCP (NP (DT the) (NN writing)) (CC and) (VP (VBG producing) (CC and) (VBG casting) (PP (IN of) (`` ``) (NP (NP (PRP I)) (NX (NNP Love) (NNP Lucy))))))) ('' '') (VP (VBD were) (ADJP (JJ marvelous)))) (, ,) (CC but) (S (NP (NP (NNP Lucy) (POS 's)) (NN performance)) (VP (VBD added) (NP (DT the) (NN quantum) (NN force)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lucy 's performance" type="NP">
          <tokens>
            <token id="19" string="Lucy" />
            <token id="20" string="'s" />
            <token id="21" string="performance" />
          </tokens>
        </chunking>
        <chunking id="2" string="the writing" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="writing" />
          </tokens>
        </chunking>
        <chunking id="3" string="marvelous" type="ADJP">
          <tokens>
            <token id="16" string="marvelous" />
          </tokens>
        </chunking>
        <chunking id="4" string="were marvelous" type="VP">
          <tokens>
            <token id="15" string="were" />
            <token id="16" string="marvelous" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lucy 's" type="NP">
          <tokens>
            <token id="19" string="Lucy" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="the quantum force" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="quantum" />
            <token id="25" string="force" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="added the quantum force" type="VP">
          <tokens>
            <token id="22" string="added" />
            <token id="23" string="the" />
            <token id="24" string="quantum" />
            <token id="25" string="force" />
          </tokens>
        </chunking>
        <chunking id="9" string="I Love Lucy" type="NP">
          <tokens>
            <token id="11" string="I" />
            <token id="12" string="Love" />
            <token id="13" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="10" string="producing and casting of `` I Love Lucy" type="VP">
          <tokens>
            <token id="6" string="producing" />
            <token id="7" string="and" />
            <token id="8" string="casting" />
            <token id="9" string="of" />
            <token id="10" string="``" />
            <token id="11" string="I" />
            <token id="12" string="Love" />
            <token id="13" string="Lucy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="discourse">
          <governor id="16">marvelous</governor>
          <dependent id="1">Yes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">writing</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">marvelous</governor>
          <dependent id="4">writing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">writing</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">writing</governor>
          <dependent id="6">producing</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">producing</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">producing</governor>
          <dependent id="8">casting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Lucy</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">Lucy</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Lucy</governor>
          <dependent id="12">Love</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">producing</governor>
          <dependent id="13">Lucy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">marvelous</governor>
          <dependent id="15">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">marvelous</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">marvelous</governor>
          <dependent id="18">but</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">performance</governor>
          <dependent id="19">Lucy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Lucy</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">added</governor>
          <dependent id="21">performance</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">marvelous</governor>
          <dependent id="22">added</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">force</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">force</governor>
          <dependent id="24">quantum</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">added</governor>
          <dependent id="25">force</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Her inspired pantomime could be written by no one: the growing panic as the chocolate assembly line speeded up; her catalog of pained expressions after tasting the patent medicine she was demonstrating.</content>
      <tokens>
        <token id="1" string="Her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="inspired" lemma="inspired" stem="inspir" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="pantomime" lemma="pantomime" stem="pantomim" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="written" lemma="write" stem="written" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="growing" lemma="grow" stem="grow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="panic" lemma="panic" stem="panic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="chocolate" lemma="chocolate" stem="chocol" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="assembly" lemma="assembly" stem="assembli" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="line" lemma="line" stem="line" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="speeded" lemma="speed" stem="speed" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="catalog" lemma="catalog" stem="catalog" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="pained" lemma="pained" stem="pain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="expressions" lemma="expression" stem="express" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="tasting" lemma="tasting" stem="tast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="patent" lemma="patent" stem="patent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="medicine" lemma="medicine" stem="medicin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="demonstrating" lemma="demonstrate" stem="demonstr" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ Her) (ADJP (JJ inspired)) (NN pantomime)) (VP (MD could) (VP (VB be) (VP (VBN written) (PP (IN by) (NP (NP (DT no) (NN one)) (: :) (NP (NP (NP (NP (DT the) (VBG growing) (NN panic)) (SBAR (IN as) (S (NP (DT the) (NN chocolate) (NN assembly) (NN line)) (VP (VBD speeded) (PRT (RP up)))))) (: ;) (NP (NP (PRP$ her) (NN catalog)) (PP (IN of) (NP (NP (JJ pained) (NNS expressions)) (ADJP (IN after) (NN tasting)))))) (NP (NP (DT the) (NN patent) (NN medicine)) (SBAR (S (NP (PRP she)) (VP (VBD was) (VP (VBG demonstrating)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be written by no one : the growing panic as the chocolate assembly line speeded up ; her catalog of pained expressions after tasting the patent medicine she was demonstrating" type="VP">
          <tokens>
            <token id="5" string="be" />
            <token id="6" string="written" />
            <token id="7" string="by" />
            <token id="8" string="no" />
            <token id="9" string="one" />
            <token id="10" string=":" />
            <token id="11" string="the" />
            <token id="12" string="growing" />
            <token id="13" string="panic" />
            <token id="14" string="as" />
            <token id="15" string="the" />
            <token id="16" string="chocolate" />
            <token id="17" string="assembly" />
            <token id="18" string="line" />
            <token id="19" string="speeded" />
            <token id="20" string="up" />
            <token id="21" string=";" />
            <token id="22" string="her" />
            <token id="23" string="catalog" />
            <token id="24" string="of" />
            <token id="25" string="pained" />
            <token id="26" string="expressions" />
            <token id="27" string="after" />
            <token id="28" string="tasting" />
            <token id="29" string="the" />
            <token id="30" string="patent" />
            <token id="31" string="medicine" />
            <token id="32" string="she" />
            <token id="33" string="was" />
            <token id="34" string="demonstrating" />
          </tokens>
        </chunking>
        <chunking id="2" string="she was demonstrating" type="SBAR">
          <tokens>
            <token id="32" string="she" />
            <token id="33" string="was" />
            <token id="34" string="demonstrating" />
          </tokens>
        </chunking>
        <chunking id="3" string="could be written by no one : the growing panic as the chocolate assembly line speeded up ; her catalog of pained expressions after tasting the patent medicine she was demonstrating" type="VP">
          <tokens>
            <token id="4" string="could" />
            <token id="5" string="be" />
            <token id="6" string="written" />
            <token id="7" string="by" />
            <token id="8" string="no" />
            <token id="9" string="one" />
            <token id="10" string=":" />
            <token id="11" string="the" />
            <token id="12" string="growing" />
            <token id="13" string="panic" />
            <token id="14" string="as" />
            <token id="15" string="the" />
            <token id="16" string="chocolate" />
            <token id="17" string="assembly" />
            <token id="18" string="line" />
            <token id="19" string="speeded" />
            <token id="20" string="up" />
            <token id="21" string=";" />
            <token id="22" string="her" />
            <token id="23" string="catalog" />
            <token id="24" string="of" />
            <token id="25" string="pained" />
            <token id="26" string="expressions" />
            <token id="27" string="after" />
            <token id="28" string="tasting" />
            <token id="29" string="the" />
            <token id="30" string="patent" />
            <token id="31" string="medicine" />
            <token id="32" string="she" />
            <token id="33" string="was" />
            <token id="34" string="demonstrating" />
          </tokens>
        </chunking>
        <chunking id="4" string="no one" type="NP">
          <tokens>
            <token id="8" string="no" />
            <token id="9" string="one" />
          </tokens>
        </chunking>
        <chunking id="5" string="inspired" type="ADJP">
          <tokens>
            <token id="2" string="inspired" />
          </tokens>
        </chunking>
        <chunking id="6" string="speeded up" type="VP">
          <tokens>
            <token id="19" string="speeded" />
            <token id="20" string="up" />
          </tokens>
        </chunking>
        <chunking id="7" string="as the chocolate assembly line speeded up" type="SBAR">
          <tokens>
            <token id="14" string="as" />
            <token id="15" string="the" />
            <token id="16" string="chocolate" />
            <token id="17" string="assembly" />
            <token id="18" string="line" />
            <token id="19" string="speeded" />
            <token id="20" string="up" />
          </tokens>
        </chunking>
        <chunking id="8" string="no one : the growing panic as the chocolate assembly line speeded up ; her catalog of pained expressions after tasting the patent medicine she was demonstrating" type="NP">
          <tokens>
            <token id="8" string="no" />
            <token id="9" string="one" />
            <token id="10" string=":" />
            <token id="11" string="the" />
            <token id="12" string="growing" />
            <token id="13" string="panic" />
            <token id="14" string="as" />
            <token id="15" string="the" />
            <token id="16" string="chocolate" />
            <token id="17" string="assembly" />
            <token id="18" string="line" />
            <token id="19" string="speeded" />
            <token id="20" string="up" />
            <token id="21" string=";" />
            <token id="22" string="her" />
            <token id="23" string="catalog" />
            <token id="24" string="of" />
            <token id="25" string="pained" />
            <token id="26" string="expressions" />
            <token id="27" string="after" />
            <token id="28" string="tasting" />
            <token id="29" string="the" />
            <token id="30" string="patent" />
            <token id="31" string="medicine" />
            <token id="32" string="she" />
            <token id="33" string="was" />
            <token id="34" string="demonstrating" />
          </tokens>
        </chunking>
        <chunking id="9" string="her catalog" type="NP">
          <tokens>
            <token id="22" string="her" />
            <token id="23" string="catalog" />
          </tokens>
        </chunking>
        <chunking id="10" string="written by no one : the growing panic as the chocolate assembly line speeded up ; her catalog of pained expressions after tasting the patent medicine she was demonstrating" type="VP">
          <tokens>
            <token id="6" string="written" />
            <token id="7" string="by" />
            <token id="8" string="no" />
            <token id="9" string="one" />
            <token id="10" string=":" />
            <token id="11" string="the" />
            <token id="12" string="growing" />
            <token id="13" string="panic" />
            <token id="14" string="as" />
            <token id="15" string="the" />
            <token id="16" string="chocolate" />
            <token id="17" string="assembly" />
            <token id="18" string="line" />
            <token id="19" string="speeded" />
            <token id="20" string="up" />
            <token id="21" string=";" />
            <token id="22" string="her" />
            <token id="23" string="catalog" />
            <token id="24" string="of" />
            <token id="25" string="pained" />
            <token id="26" string="expressions" />
            <token id="27" string="after" />
            <token id="28" string="tasting" />
            <token id="29" string="the" />
            <token id="30" string="patent" />
            <token id="31" string="medicine" />
            <token id="32" string="she" />
            <token id="33" string="was" />
            <token id="34" string="demonstrating" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="32" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="the chocolate assembly line" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="chocolate" />
            <token id="17" string="assembly" />
            <token id="18" string="line" />
          </tokens>
        </chunking>
        <chunking id="13" string="the patent medicine she was demonstrating" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="patent" />
            <token id="31" string="medicine" />
            <token id="32" string="she" />
            <token id="33" string="was" />
            <token id="34" string="demonstrating" />
          </tokens>
        </chunking>
        <chunking id="14" string="the growing panic as the chocolate assembly line speeded up" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="growing" />
            <token id="13" string="panic" />
            <token id="14" string="as" />
            <token id="15" string="the" />
            <token id="16" string="chocolate" />
            <token id="17" string="assembly" />
            <token id="18" string="line" />
            <token id="19" string="speeded" />
            <token id="20" string="up" />
          </tokens>
        </chunking>
        <chunking id="15" string="the growing panic as the chocolate assembly line speeded up ; her catalog of pained expressions after tasting" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="growing" />
            <token id="13" string="panic" />
            <token id="14" string="as" />
            <token id="15" string="the" />
            <token id="16" string="chocolate" />
            <token id="17" string="assembly" />
            <token id="18" string="line" />
            <token id="19" string="speeded" />
            <token id="20" string="up" />
            <token id="21" string=";" />
            <token id="22" string="her" />
            <token id="23" string="catalog" />
            <token id="24" string="of" />
            <token id="25" string="pained" />
            <token id="26" string="expressions" />
            <token id="27" string="after" />
            <token id="28" string="tasting" />
          </tokens>
        </chunking>
        <chunking id="16" string="pained expressions after tasting" type="NP">
          <tokens>
            <token id="25" string="pained" />
            <token id="26" string="expressions" />
            <token id="27" string="after" />
            <token id="28" string="tasting" />
          </tokens>
        </chunking>
        <chunking id="17" string="the growing panic as the chocolate assembly line speeded up ; her catalog of pained expressions after tasting the patent medicine she was demonstrating" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="growing" />
            <token id="13" string="panic" />
            <token id="14" string="as" />
            <token id="15" string="the" />
            <token id="16" string="chocolate" />
            <token id="17" string="assembly" />
            <token id="18" string="line" />
            <token id="19" string="speeded" />
            <token id="20" string="up" />
            <token id="21" string=";" />
            <token id="22" string="her" />
            <token id="23" string="catalog" />
            <token id="24" string="of" />
            <token id="25" string="pained" />
            <token id="26" string="expressions" />
            <token id="27" string="after" />
            <token id="28" string="tasting" />
            <token id="29" string="the" />
            <token id="30" string="patent" />
            <token id="31" string="medicine" />
            <token id="32" string="she" />
            <token id="33" string="was" />
            <token id="34" string="demonstrating" />
          </tokens>
        </chunking>
        <chunking id="18" string="after tasting" type="ADJP">
          <tokens>
            <token id="27" string="after" />
            <token id="28" string="tasting" />
          </tokens>
        </chunking>
        <chunking id="19" string="Her inspired pantomime" type="NP">
          <tokens>
            <token id="1" string="Her" />
            <token id="2" string="inspired" />
            <token id="3" string="pantomime" />
          </tokens>
        </chunking>
        <chunking id="20" string="was demonstrating" type="VP">
          <tokens>
            <token id="33" string="was" />
            <token id="34" string="demonstrating" />
          </tokens>
        </chunking>
        <chunking id="21" string="pained expressions" type="NP">
          <tokens>
            <token id="25" string="pained" />
            <token id="26" string="expressions" />
          </tokens>
        </chunking>
        <chunking id="22" string="her catalog of pained expressions after tasting" type="NP">
          <tokens>
            <token id="22" string="her" />
            <token id="23" string="catalog" />
            <token id="24" string="of" />
            <token id="25" string="pained" />
            <token id="26" string="expressions" />
            <token id="27" string="after" />
            <token id="28" string="tasting" />
          </tokens>
        </chunking>
        <chunking id="23" string="the growing panic" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="growing" />
            <token id="13" string="panic" />
          </tokens>
        </chunking>
        <chunking id="24" string="demonstrating" type="VP">
          <tokens>
            <token id="34" string="demonstrating" />
          </tokens>
        </chunking>
        <chunking id="25" string="the patent medicine" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="patent" />
            <token id="31" string="medicine" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">pantomime</governor>
          <dependent id="1">Her</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">pantomime</governor>
          <dependent id="2">inspired</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">written</governor>
          <dependent id="3">pantomime</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">written</governor>
          <dependent id="4">could</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">written</governor>
          <dependent id="5">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">written</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">one</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="9">one</governor>
          <dependent id="8">no</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">written</governor>
          <dependent id="9">one</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">panic</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">panic</governor>
          <dependent id="12">growing</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">one</governor>
          <dependent id="13">panic</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="19">speeded</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">line</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">line</governor>
          <dependent id="16">chocolate</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">line</governor>
          <dependent id="17">assembly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">speeded</governor>
          <dependent id="18">line</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">panic</governor>
          <dependent id="19">speeded</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="19">speeded</governor>
          <dependent id="20">up</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">catalog</governor>
          <dependent id="22">her</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">panic</governor>
          <dependent id="23">catalog</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">expressions</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">expressions</governor>
          <dependent id="25">pained</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">catalog</governor>
          <dependent id="26">expressions</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="28">tasting</governor>
          <dependent id="27">after</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">expressions</governor>
          <dependent id="28">tasting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">medicine</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">medicine</governor>
          <dependent id="30">patent</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">panic</governor>
          <dependent id="31">medicine</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">demonstrating</governor>
          <dependent id="32">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">demonstrating</governor>
          <dependent id="33">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="31">medicine</governor>
          <dependent id="34">demonstrating</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>Unlike many stars, Lucille Ball rarely indulged in self-analysis.</content>
      <tokens>
        <token id="1" string="Unlike" lemma="unlike" stem="unlike" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="stars" lemma="star" stem="star" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Lucille" lemma="Lucille" stem="lucil" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="Ball" lemma="Ball" stem="ball" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="rarely" lemma="rarely" stem="rare" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="indulged" lemma="indulge" stem="indulg" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="self-analysis" lemma="self-analysis" stem="self-analysi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Unlike) (NP (JJ many) (NNS stars))) (, ,) (NP (NNP Lucille) (NNP Ball)) (ADVP (RB rarely)) (VP (VBD indulged) (PP (IN in) (NP (NN self-analysis)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="many stars" type="NP">
          <tokens>
            <token id="2" string="many" />
            <token id="3" string="stars" />
          </tokens>
        </chunking>
        <chunking id="2" string="self-analysis" type="NP">
          <tokens>
            <token id="10" string="self-analysis" />
          </tokens>
        </chunking>
        <chunking id="3" string="indulged in self-analysis" type="VP">
          <tokens>
            <token id="8" string="indulged" />
            <token id="9" string="in" />
            <token id="10" string="self-analysis" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lucille Ball" type="NP">
          <tokens>
            <token id="5" string="Lucille" />
            <token id="6" string="Ball" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">stars</governor>
          <dependent id="1">Unlike</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">stars</governor>
          <dependent id="2">many</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">indulged</governor>
          <dependent id="3">stars</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Ball</governor>
          <dependent id="5">Lucille</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">indulged</governor>
          <dependent id="6">Ball</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">indulged</governor>
          <dependent id="7">rarely</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">indulged</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">self-analysis</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">indulged</governor>
          <dependent id="10">self-analysis</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucille Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Lucille" />
            <token id="6" string="Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>But on one occasion she revealed why her feelings about the ``I Love Lucy&amp;apost;&amp;apost; triumph might have been ambivalent: Living through the last five years of the show, she said, ``took the edge off any enjoyment I might have had.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="occasion" lemma="occasion" stem="occas" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="revealed" lemma="reveal" stem="reveal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="feelings" lemma="feeling" stem="feel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="triumph" lemma="triumph" stem="triumph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="ambivalent" lemma="ambivalent" stem="ambival" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Living" lemma="live" stem="live" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="26" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="27" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="28" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="31" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="edge" lemma="edge" stem="edg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="enjoyment" lemma="enjoyment" stem="enjoy" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="might" lemma="might" stem="might" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (PP (IN on) (NP (CD one) (NN occasion))) (PRN (S (NP (PRP she)) (VP (VBD revealed) (SBAR (S (SBAR (WHADVP (WRB why)) (S (NP (NP (PRP$ her) (NNS feelings)) (PP (IN about) (NP (DT the) (NP (`` ``) (NP (PRP I)) (PP (NNP Love) (NP (NNP Lucy))) ('' '')) (NN triumph)))) (VP (MD might) (VP (VB have) (VP (VBN been) (ADJP (JJ ambivalent)) (: :) (S (VP (VBG Living) (PP (IN through) (NP (NP (DT the) (JJ last) (CD five) (NNS years)) (PP (IN of) (NP (DT the) (NN show)))))))))))) (, ,) (NP (PRP she)) (VP (VBD said)))))) (, ,)) (`` ``) (VP (VBD took) (NP (DT the) (NN edge)) (PP (RP off) (NP (NP (DT any) (NN enjoyment)) (SBAR (S (NP (PRP I)) (VP (MD might) (VP (VB have) (VP (VBN had))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="ambivalent" type="ADJP">
          <tokens>
            <token id="21" string="ambivalent" />
          </tokens>
        </chunking>
        <chunking id="2" string="have had" type="VP">
          <tokens>
            <token id="45" string="have" />
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="3" string="took the edge off any enjoyment I might have had" type="VP">
          <tokens>
            <token id="37" string="took" />
            <token id="38" string="the" />
            <token id="39" string="edge" />
            <token id="40" string="off" />
            <token id="41" string="any" />
            <token id="42" string="enjoyment" />
            <token id="43" string="I" />
            <token id="44" string="might" />
            <token id="45" string="have" />
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="4" string="any enjoyment" type="NP">
          <tokens>
            <token id="41" string="any" />
            <token id="42" string="enjoyment" />
          </tokens>
        </chunking>
        <chunking id="5" string="revealed why her feelings about the `` I Love Lucy '' triumph might have been ambivalent : Living through the last five years of the show , she said" type="VP">
          <tokens>
            <token id="6" string="revealed" />
            <token id="7" string="why" />
            <token id="8" string="her" />
            <token id="9" string="feelings" />
            <token id="10" string="about" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="triumph" />
            <token id="18" string="might" />
            <token id="19" string="have" />
            <token id="20" string="been" />
            <token id="21" string="ambivalent" />
            <token id="22" string=":" />
            <token id="23" string="Living" />
            <token id="24" string="through" />
            <token id="25" string="the" />
            <token id="26" string="last" />
            <token id="27" string="five" />
            <token id="28" string="years" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="show" />
            <token id="32" string="," />
            <token id="33" string="she" />
            <token id="34" string="said" />
          </tokens>
        </chunking>
        <chunking id="6" string="the show" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="show" />
          </tokens>
        </chunking>
        <chunking id="7" string="I might have had" type="SBAR">
          <tokens>
            <token id="43" string="I" />
            <token id="44" string="might" />
            <token id="45" string="have" />
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="8" string="why her feelings about the `` I Love Lucy '' triumph might have been ambivalent : Living through the last five years of the show , she said" type="SBAR">
          <tokens>
            <token id="7" string="why" />
            <token id="8" string="her" />
            <token id="9" string="feelings" />
            <token id="10" string="about" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="triumph" />
            <token id="18" string="might" />
            <token id="19" string="have" />
            <token id="20" string="been" />
            <token id="21" string="ambivalent" />
            <token id="22" string=":" />
            <token id="23" string="Living" />
            <token id="24" string="through" />
            <token id="25" string="the" />
            <token id="26" string="last" />
            <token id="27" string="five" />
            <token id="28" string="years" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="show" />
            <token id="32" string="," />
            <token id="33" string="she" />
            <token id="34" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="she" type="NP">
          <tokens>
            <token id="5" string="she" />
          </tokens>
        </chunking>
        <chunking id="10" string="the last five years" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="last" />
            <token id="27" string="five" />
            <token id="28" string="years" />
          </tokens>
        </chunking>
        <chunking id="11" string="might have had" type="VP">
          <tokens>
            <token id="44" string="might" />
            <token id="45" string="have" />
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="12" string="Lucy" type="NP">
          <tokens>
            <token id="15" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="13" string="the last five years of the show" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="last" />
            <token id="27" string="five" />
            <token id="28" string="years" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="show" />
          </tokens>
        </chunking>
        <chunking id="14" string="why" type="WHADVP">
          <tokens>
            <token id="7" string="why" />
          </tokens>
        </chunking>
        <chunking id="15" string="why her feelings about the `` I Love Lucy '' triumph might have been ambivalent : Living through the last five years of the show" type="SBAR">
          <tokens>
            <token id="7" string="why" />
            <token id="8" string="her" />
            <token id="9" string="feelings" />
            <token id="10" string="about" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="triumph" />
            <token id="18" string="might" />
            <token id="19" string="have" />
            <token id="20" string="been" />
            <token id="21" string="ambivalent" />
            <token id="22" string=":" />
            <token id="23" string="Living" />
            <token id="24" string="through" />
            <token id="25" string="the" />
            <token id="26" string="last" />
            <token id="27" string="five" />
            <token id="28" string="years" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="show" />
          </tokens>
        </chunking>
        <chunking id="16" string="I" type="NP">
          <tokens>
            <token id="13" string="I" />
          </tokens>
        </chunking>
        <chunking id="17" string="might have been ambivalent : Living through the last five years of the show" type="VP">
          <tokens>
            <token id="18" string="might" />
            <token id="19" string="have" />
            <token id="20" string="been" />
            <token id="21" string="ambivalent" />
            <token id="22" string=":" />
            <token id="23" string="Living" />
            <token id="24" string="through" />
            <token id="25" string="the" />
            <token id="26" string="last" />
            <token id="27" string="five" />
            <token id="28" string="years" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="show" />
          </tokens>
        </chunking>
        <chunking id="18" string="had" type="VP">
          <tokens>
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="19" string="`` I Love Lucy ''" type="NP">
          <tokens>
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
          </tokens>
        </chunking>
        <chunking id="20" string="been ambivalent : Living through the last five years of the show" type="VP">
          <tokens>
            <token id="20" string="been" />
            <token id="21" string="ambivalent" />
            <token id="22" string=":" />
            <token id="23" string="Living" />
            <token id="24" string="through" />
            <token id="25" string="the" />
            <token id="26" string="last" />
            <token id="27" string="five" />
            <token id="28" string="years" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="show" />
          </tokens>
        </chunking>
        <chunking id="21" string="her feelings" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="feelings" />
          </tokens>
        </chunking>
        <chunking id="22" string="any enjoyment I might have had" type="NP">
          <tokens>
            <token id="41" string="any" />
            <token id="42" string="enjoyment" />
            <token id="43" string="I" />
            <token id="44" string="might" />
            <token id="45" string="have" />
            <token id="46" string="had" />
          </tokens>
        </chunking>
        <chunking id="23" string="her feelings about the `` I Love Lucy '' triumph" type="NP">
          <tokens>
            <token id="8" string="her" />
            <token id="9" string="feelings" />
            <token id="10" string="about" />
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="triumph" />
          </tokens>
        </chunking>
        <chunking id="24" string="have been ambivalent : Living through the last five years of the show" type="VP">
          <tokens>
            <token id="19" string="have" />
            <token id="20" string="been" />
            <token id="21" string="ambivalent" />
            <token id="22" string=":" />
            <token id="23" string="Living" />
            <token id="24" string="through" />
            <token id="25" string="the" />
            <token id="26" string="last" />
            <token id="27" string="five" />
            <token id="28" string="years" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="show" />
          </tokens>
        </chunking>
        <chunking id="25" string="the edge" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="edge" />
          </tokens>
        </chunking>
        <chunking id="26" string="Living through the last five years of the show" type="VP">
          <tokens>
            <token id="23" string="Living" />
            <token id="24" string="through" />
            <token id="25" string="the" />
            <token id="26" string="last" />
            <token id="27" string="five" />
            <token id="28" string="years" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="show" />
          </tokens>
        </chunking>
        <chunking id="27" string="one occasion" type="NP">
          <tokens>
            <token id="3" string="one" />
            <token id="4" string="occasion" />
          </tokens>
        </chunking>
        <chunking id="28" string="said" type="VP">
          <tokens>
            <token id="34" string="said" />
          </tokens>
        </chunking>
        <chunking id="29" string="the `` I Love Lucy '' triumph" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="``" />
            <token id="13" string="I" />
            <token id="14" string="Love" />
            <token id="15" string="Lucy" />
            <token id="16" string="''" />
            <token id="17" string="triumph" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="37">took</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">occasion</governor>
          <dependent id="2">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">occasion</governor>
          <dependent id="3">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">took</governor>
          <dependent id="4">occasion</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">revealed</governor>
          <dependent id="5">she</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="37">took</governor>
          <dependent id="6">revealed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">ambivalent</governor>
          <dependent id="7">why</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">feelings</governor>
          <dependent id="8">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">ambivalent</governor>
          <dependent id="9">feelings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">triumph</governor>
          <dependent id="10">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">triumph</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">triumph</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">Lucy</governor>
          <dependent id="14">Love</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">I</governor>
          <dependent id="15">Lucy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">feelings</governor>
          <dependent id="17">triumph</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">ambivalent</governor>
          <dependent id="18">might</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">ambivalent</governor>
          <dependent id="19">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">ambivalent</governor>
          <dependent id="20">been</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="34">said</governor>
          <dependent id="21">ambivalent</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="21">ambivalent</governor>
          <dependent id="23">Living</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">years</governor>
          <dependent id="24">through</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">years</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">years</governor>
          <dependent id="26">last</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">years</governor>
          <dependent id="27">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">Living</governor>
          <dependent id="28">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">show</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">show</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">years</governor>
          <dependent id="31">show</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">said</governor>
          <dependent id="33">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">revealed</governor>
          <dependent id="34">said</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="37">took</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">edge</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="37">took</governor>
          <dependent id="39">edge</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="42">enjoyment</governor>
          <dependent id="40">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="42">enjoyment</governor>
          <dependent id="41">any</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">took</governor>
          <dependent id="42">enjoyment</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">had</governor>
          <dependent id="43">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="46">had</governor>
          <dependent id="44">might</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="46">had</governor>
          <dependent id="45">have</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="42">enjoyment</governor>
          <dependent id="46">had</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="the last five years" type="DURATION" score="0.0">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="last" />
            <token id="27" string="five" />
            <token id="28" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Desi&amp;apost;s drinking and carousing were a terrible embarrassment, bad for a woman&amp;apost;s self-esteem.</content>
      <tokens>
        <token id="1" string="Desi" lemma="desi" stem="desi" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="drinking" lemma="drinking" stem="drink" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="carousing" lemma="carousing" stem="carous" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="terrible" lemma="terrible" stem="terribl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="embarrassment" lemma="embarrassment" stem="embarrass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="woman" lemma="woman" stem="woman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="self-esteem" lemma="self-esteem" stem="self-esteem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Desi) (POS 's)) (NN drinking) (CC and) (NN carousing)) (VP (VBD were) (NP (NP (DT a) (JJ terrible) (NN embarrassment)) (, ,) (ADJP (JJ bad) (PP (IN for) (NP (NP (DT a) (NN woman) (POS 's)) (NN self-esteem)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Desi 's" type="NP">
          <tokens>
            <token id="1" string="Desi" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="bad for a woman 's self-esteem" type="ADJP">
          <tokens>
            <token id="11" string="bad" />
            <token id="12" string="for" />
            <token id="13" string="a" />
            <token id="14" string="woman" />
            <token id="15" string="'s" />
            <token id="16" string="self-esteem" />
          </tokens>
        </chunking>
        <chunking id="3" string="a woman 's" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="woman" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="a terrible embarrassment , bad for a woman 's self-esteem" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="terrible" />
            <token id="9" string="embarrassment" />
            <token id="10" string="," />
            <token id="11" string="bad" />
            <token id="12" string="for" />
            <token id="13" string="a" />
            <token id="14" string="woman" />
            <token id="15" string="'s" />
            <token id="16" string="self-esteem" />
          </tokens>
        </chunking>
        <chunking id="5" string="were a terrible embarrassment , bad for a woman 's self-esteem" type="VP">
          <tokens>
            <token id="6" string="were" />
            <token id="7" string="a" />
            <token id="8" string="terrible" />
            <token id="9" string="embarrassment" />
            <token id="10" string="," />
            <token id="11" string="bad" />
            <token id="12" string="for" />
            <token id="13" string="a" />
            <token id="14" string="woman" />
            <token id="15" string="'s" />
            <token id="16" string="self-esteem" />
          </tokens>
        </chunking>
        <chunking id="6" string="a terrible embarrassment" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="terrible" />
            <token id="9" string="embarrassment" />
          </tokens>
        </chunking>
        <chunking id="7" string="Desi 's drinking and carousing" type="NP">
          <tokens>
            <token id="1" string="Desi" />
            <token id="2" string="'s" />
            <token id="3" string="drinking" />
            <token id="4" string="and" />
            <token id="5" string="carousing" />
          </tokens>
        </chunking>
        <chunking id="8" string="a woman 's self-esteem" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="woman" />
            <token id="15" string="'s" />
            <token id="16" string="self-esteem" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">drinking</governor>
          <dependent id="1">Desi</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Desi</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">embarrassment</governor>
          <dependent id="3">drinking</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">drinking</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">drinking</governor>
          <dependent id="5">carousing</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">embarrassment</governor>
          <dependent id="6">were</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">embarrassment</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">embarrassment</governor>
          <dependent id="8">terrible</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">embarrassment</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">embarrassment</governor>
          <dependent id="11">bad</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">self-esteem</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">woman</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">self-esteem</governor>
          <dependent id="14">woman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">woman</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">bad</governor>
          <dependent id="16">self-esteem</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Desi" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Desi" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="false">
      <content>The talk around town was `poor Lucy.&amp;apost;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="talk" lemma="talk" stem="talk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="town" lemma="town" stem="town" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="poor" lemma="poor" stem="poor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN talk)) (PP (IN around) (NP (NN town)))) (VP (VBD was) (`` `) (NP (JJ poor) (NNP Lucy))) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="The talk around town" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="talk" />
            <token id="3" string="around" />
            <token id="4" string="town" />
          </tokens>
        </chunking>
        <chunking id="2" string="The talk" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="talk" />
          </tokens>
        </chunking>
        <chunking id="3" string="town" type="NP">
          <tokens>
            <token id="4" string="town" />
          </tokens>
        </chunking>
        <chunking id="4" string="was ` poor Lucy" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="`" />
            <token id="7" string="poor" />
            <token id="8" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="5" string="poor Lucy" type="NP">
          <tokens>
            <token id="7" string="poor" />
            <token id="8" string="Lucy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">talk</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">Lucy</governor>
          <dependent id="2">talk</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">town</governor>
          <dependent id="3">around</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">talk</governor>
          <dependent id="4">town</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">Lucy</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">Lucy</governor>
          <dependent id="7">poor</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">Lucy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Because I couldn&amp;apost;t face people, I became a recluse for more than 5{ years.</content>
      <tokens>
        <token id="1" string="Because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="face" lemma="face" stem="face" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="recluse" lemma="recluse" stem="reclus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="5" lemma="5" stem="5" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="{" lemma="-lcb-" stem="{" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Because) (S (NP (PRP I)) (VP (MD could) (RB n't) (VP (VB face) (NP (NNS people)))))) (, ,) (NP (PRP I)) (VP (VBD became) (NP (DT a) (NN recluse)) (PP (IN for) (NP (QP (JJR more) (IN than) (CD 5) (-LRB- -LCB-)) (NNS years)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a recluse" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="recluse" />
          </tokens>
        </chunking>
        <chunking id="2" string="Because I could n't face people" type="SBAR">
          <tokens>
            <token id="1" string="Because" />
            <token id="2" string="I" />
            <token id="3" string="could" />
            <token id="4" string="n't" />
            <token id="5" string="face" />
            <token id="6" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="face people" type="VP">
          <tokens>
            <token id="5" string="face" />
            <token id="6" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="people" type="NP">
          <tokens>
            <token id="6" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="more than 5 -LCB- years" type="NP">
          <tokens>
            <token id="13" string="more" />
            <token id="14" string="than" />
            <token id="15" string="5" />
            <token id="16" string="{" />
            <token id="17" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="became a recluse for more than 5 -LCB- years" type="VP">
          <tokens>
            <token id="9" string="became" />
            <token id="10" string="a" />
            <token id="11" string="recluse" />
            <token id="12" string="for" />
            <token id="13" string="more" />
            <token id="14" string="than" />
            <token id="15" string="5" />
            <token id="16" string="{" />
            <token id="17" string="years" />
          </tokens>
        </chunking>
        <chunking id="8" string="could n't face people" type="VP">
          <tokens>
            <token id="3" string="could" />
            <token id="4" string="n't" />
            <token id="5" string="face" />
            <token id="6" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">face</governor>
          <dependent id="1">Because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">face</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">face</governor>
          <dependent id="3">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">face</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">became</governor>
          <dependent id="5">face</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">face</governor>
          <dependent id="6">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">became</governor>
          <dependent id="8">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">became</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">recluse</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">became</governor>
          <dependent id="11">recluse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">years</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">5</governor>
          <dependent id="13">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="13">more</governor>
          <dependent id="14">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">years</governor>
          <dependent id="15">5</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">became</governor>
          <dependent id="17">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="5" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="5" />
          </tokens>
        </entity>
        <entity id="2" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="17" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>``I never demonstrated my unhappiness at the studio, and actually, working together was a blessing.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="demonstrated" lemma="demonstrate" stem="demonstr" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="unhappiness" lemma="unhappiness" stem="unhappi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="studio" lemma="studio" stem="studio" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="actually" lemma="actually" stem="actual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="working" lemma="work" stem="work" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="blessing" lemma="blessing" stem="bless" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP I)) (VP (ADVP (RB never)) (VP (VBD demonstrated) (NP (PRP$ my) (NN unhappiness)) (PP (IN at) (NP (DT the) (NN studio)))) (, ,) (CC and) (ADVP (RB actually)) (, ,) (S (VP (VBG working) (ADVP (RB together)))))) (VP (VBD was)) (NP (DT a) (NN blessing)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="my unhappiness" type="NP">
          <tokens>
            <token id="5" string="my" />
            <token id="6" string="unhappiness" />
          </tokens>
        </chunking>
        <chunking id="2" string="working together" type="VP">
          <tokens>
            <token id="14" string="working" />
            <token id="15" string="together" />
          </tokens>
        </chunking>
        <chunking id="3" string="never demonstrated my unhappiness at the studio , and actually , working together" type="VP">
          <tokens>
            <token id="3" string="never" />
            <token id="4" string="demonstrated" />
            <token id="5" string="my" />
            <token id="6" string="unhappiness" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="studio" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="actually" />
            <token id="13" string="," />
            <token id="14" string="working" />
            <token id="15" string="together" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="was" type="VP">
          <tokens>
            <token id="16" string="was" />
          </tokens>
        </chunking>
        <chunking id="6" string="a blessing" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="blessing" />
          </tokens>
        </chunking>
        <chunking id="7" string="the studio" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="studio" />
          </tokens>
        </chunking>
        <chunking id="8" string="demonstrated my unhappiness at the studio" type="VP">
          <tokens>
            <token id="4" string="demonstrated" />
            <token id="5" string="my" />
            <token id="6" string="unhappiness" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="studio" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">demonstrated</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">demonstrated</governor>
          <dependent id="3">never</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">was</governor>
          <dependent id="4">demonstrated</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">unhappiness</governor>
          <dependent id="5">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">demonstrated</governor>
          <dependent id="6">unhappiness</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">studio</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">studio</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">demonstrated</governor>
          <dependent id="9">studio</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">demonstrated</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">demonstrated</governor>
          <dependent id="12">actually</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">demonstrated</governor>
          <dependent id="14">working</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">working</governor>
          <dependent id="15">together</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">blessing</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">was</governor>
          <dependent id="18">blessing</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="false">
      <content>Desi had everything so well organized that it was easy to do the work.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Desi" lemma="desi" stem="desi" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="organized" lemma="organize" stem="organ" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="easy" lemma="easy" stem="easi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Desi)) (VP (VBD had) (NP (NN everything)) (ADVP (RB so) (RB well)) (VP (VBN organized) (SBAR (IN that) (S (NP (PRP it)) (VP (VBD was) (ADJP (JJ easy) (S (VP (TO to) (VP (VB do) (NP (DT the) (NN work))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="organized that it was easy to do the work" type="VP">
          <tokens>
            <token id="6" string="organized" />
            <token id="7" string="that" />
            <token id="8" string="it" />
            <token id="9" string="was" />
            <token id="10" string="easy" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="the" />
            <token id="14" string="work" />
          </tokens>
        </chunking>
        <chunking id="2" string="do the work" type="VP">
          <tokens>
            <token id="12" string="do" />
            <token id="13" string="the" />
            <token id="14" string="work" />
          </tokens>
        </chunking>
        <chunking id="3" string="Desi" type="NP">
          <tokens>
            <token id="1" string="Desi" />
          </tokens>
        </chunking>
        <chunking id="4" string="had everything so well organized that it was easy to do the work" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="everything" />
            <token id="4" string="so" />
            <token id="5" string="well" />
            <token id="6" string="organized" />
            <token id="7" string="that" />
            <token id="8" string="it" />
            <token id="9" string="was" />
            <token id="10" string="easy" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="the" />
            <token id="14" string="work" />
          </tokens>
        </chunking>
        <chunking id="5" string="that it was easy to do the work" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="it" />
            <token id="9" string="was" />
            <token id="10" string="easy" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="the" />
            <token id="14" string="work" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="8" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="was easy to do the work" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="easy" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="the" />
            <token id="14" string="work" />
          </tokens>
        </chunking>
        <chunking id="8" string="to do the work" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="the" />
            <token id="14" string="work" />
          </tokens>
        </chunking>
        <chunking id="9" string="the work" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="work" />
          </tokens>
        </chunking>
        <chunking id="10" string="easy to do the work" type="ADJP">
          <tokens>
            <token id="10" string="easy" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="the" />
            <token id="14" string="work" />
          </tokens>
        </chunking>
        <chunking id="11" string="everything" type="NP">
          <tokens>
            <token id="3" string="everything" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">organized</governor>
          <dependent id="1">Desi</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">organized</governor>
          <dependent id="2">had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">organized</governor>
          <dependent id="3">everything</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">well</governor>
          <dependent id="4">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">organized</governor>
          <dependent id="5">well</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">organized</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">easy</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">easy</governor>
          <dependent id="8">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">easy</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">organized</governor>
          <dependent id="10">easy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">do</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">easy</governor>
          <dependent id="12">do</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">work</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">do</governor>
          <dependent id="14">work</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Desi" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Desi" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Lucy was late in reaching her comedy potential.</content>
      <tokens>
        <token id="1" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="late" lemma="late" stem="late" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="reaching" lemma="reach" stem="reach" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="comedy" lemma="comedy" stem="comedi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="potential" lemma="potential" stem="potenti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lucy)) (VP (VBD was) (ADVP (RB late)) (PP (IN in) (S (VP (VBG reaching) (NP (PRP$ her) (NN comedy) (NN potential)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reaching her comedy potential" type="VP">
          <tokens>
            <token id="5" string="reaching" />
            <token id="6" string="her" />
            <token id="7" string="comedy" />
            <token id="8" string="potential" />
          </tokens>
        </chunking>
        <chunking id="2" string="her comedy potential" type="NP">
          <tokens>
            <token id="6" string="her" />
            <token id="7" string="comedy" />
            <token id="8" string="potential" />
          </tokens>
        </chunking>
        <chunking id="3" string="was late in reaching her comedy potential" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="late" />
            <token id="4" string="in" />
            <token id="5" string="reaching" />
            <token id="6" string="her" />
            <token id="7" string="comedy" />
            <token id="8" string="potential" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lucy" type="NP">
          <tokens>
            <token id="1" string="Lucy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">reaching</governor>
          <dependent id="1">Lucy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">reaching</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">reaching</governor>
          <dependent id="3">late</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">reaching</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">reaching</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">potential</governor>
          <dependent id="6">her</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">potential</governor>
          <dependent id="7">comedy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">reaching</governor>
          <dependent id="8">potential</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lucy" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lucy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>She was 40 when ``I Love Lucy&amp;apost;&amp;apost; started on CBS and revolutionized television.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="40" lemma="40" stem="40" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="Love" lemma="Love" stem="love" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="Lucy" lemma="Lucy" stem="luci" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="started" lemma="start" stem="start" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="CBS" lemma="CBS" stem="cbs" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="revolutionized" lemma="revolutionize" stem="revolution" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VBD was) (NP (NP (CD 40)) (SBAR (WHADVP (WRB when)) (S (`` ``) (NP (NP (PRP I)) (NP (NNP Love) (NNP Lucy))) ('' '') (VP (VP (VBD started) (PP (IN on) (NP (NNP CBS)))) (CC and) (VP (VBD revolutionized) (NP (NN television)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="started on CBS" type="VP">
          <tokens>
            <token id="10" string="started" />
            <token id="11" string="on" />
            <token id="12" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="2" string="when `` I Love Lucy '' started on CBS and revolutionized television" type="SBAR">
          <tokens>
            <token id="4" string="when" />
            <token id="5" string="``" />
            <token id="6" string="I" />
            <token id="7" string="Love" />
            <token id="8" string="Lucy" />
            <token id="9" string="''" />
            <token id="10" string="started" />
            <token id="11" string="on" />
            <token id="12" string="CBS" />
            <token id="13" string="and" />
            <token id="14" string="revolutionized" />
            <token id="15" string="television" />
          </tokens>
        </chunking>
        <chunking id="3" string="40 when `` I Love Lucy '' started on CBS and revolutionized television" type="NP">
          <tokens>
            <token id="3" string="40" />
            <token id="4" string="when" />
            <token id="5" string="``" />
            <token id="6" string="I" />
            <token id="7" string="Love" />
            <token id="8" string="Lucy" />
            <token id="9" string="''" />
            <token id="10" string="started" />
            <token id="11" string="on" />
            <token id="12" string="CBS" />
            <token id="13" string="and" />
            <token id="14" string="revolutionized" />
            <token id="15" string="television" />
          </tokens>
        </chunking>
        <chunking id="4" string="started on CBS and revolutionized television" type="VP">
          <tokens>
            <token id="10" string="started" />
            <token id="11" string="on" />
            <token id="12" string="CBS" />
            <token id="13" string="and" />
            <token id="14" string="revolutionized" />
            <token id="15" string="television" />
          </tokens>
        </chunking>
        <chunking id="5" string="television" type="NP">
          <tokens>
            <token id="15" string="television" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="6" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="I Love Lucy" type="NP">
          <tokens>
            <token id="6" string="I" />
            <token id="7" string="Love" />
            <token id="8" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="9" string="when" type="WHADVP">
          <tokens>
            <token id="4" string="when" />
          </tokens>
        </chunking>
        <chunking id="10" string="CBS" type="NP">
          <tokens>
            <token id="12" string="CBS" />
          </tokens>
        </chunking>
        <chunking id="11" string="was 40 when `` I Love Lucy '' started on CBS and revolutionized television" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="40" />
            <token id="4" string="when" />
            <token id="5" string="``" />
            <token id="6" string="I" />
            <token id="7" string="Love" />
            <token id="8" string="Lucy" />
            <token id="9" string="''" />
            <token id="10" string="started" />
            <token id="11" string="on" />
            <token id="12" string="CBS" />
            <token id="13" string="and" />
            <token id="14" string="revolutionized" />
            <token id="15" string="television" />
          </tokens>
        </chunking>
        <chunking id="12" string="40" type="NP">
          <tokens>
            <token id="3" string="40" />
          </tokens>
        </chunking>
        <chunking id="13" string="Love Lucy" type="NP">
          <tokens>
            <token id="7" string="Love" />
            <token id="8" string="Lucy" />
          </tokens>
        </chunking>
        <chunking id="14" string="revolutionized television" type="VP">
          <tokens>
            <token id="14" string="revolutionized" />
            <token id="15" string="television" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">40</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">40</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">40</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">started</governor>
          <dependent id="4">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">started</governor>
          <dependent id="6">I</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Lucy</governor>
          <dependent id="7">Love</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">I</governor>
          <dependent id="8">Lucy</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">40</governor>
          <dependent id="10">started</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">CBS</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">started</governor>
          <dependent id="12">CBS</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">started</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">started</governor>
          <dependent id="14">revolutionized</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">revolutionized</governor>
          <dependent id="15">television</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="CBS" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="CBS" />
          </tokens>
        </entity>
        <entity id="2" string="40" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="40" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>And although she spent many years in Hollywood, ``none of the studios ever designed comedies for me the way MGM did for Red Skelton, Paramount did for Bob Hope and Sam Goldwyn did for Danny Kaye,&amp;apost;&amp;apost; she once said.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="although" lemma="although" stem="although" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="spent" lemma="spend" stem="spent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="none" lemma="none" stem="none" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="studios" lemma="studio" stem="studio" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="designed" lemma="design" stem="design" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="comedies" lemma="comedy" stem="comedi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="MGM" lemma="MGM" stem="mgm" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Red" lemma="Red" stem="red" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="Skelton" lemma="Skelton" stem="skelton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Paramount" lemma="Paramount" stem="paramount" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Bob" lemma="Bob" stem="bob" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="Hope" lemma="Hope" stem="hope" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="35" string="Goldwyn" lemma="Goldwyn" stem="goldwyn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="36" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Danny" lemma="Danny" stem="danni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="39" string="Kaye" lemma="Kaye" stem="kay" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="43" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="44" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (SBAR (IN although) (S (NP (PRP she)) (VP (VBD spent) (NP (NP (JJ many) (NNS years)) (PP (IN in) (NP (NNP Hollywood)))) (, ,) (`` ``) (S (NP (NP (NN none)) (PP (IN of) (NP (DT the) (NNS studios)))) (VP (ADVP (RB ever)) (VBN designed) (NP (NP (NNS comedies)) (PP (IN for) (NP (NP (PRP me)) (NP (DT the) (NN way)))) (SBAR (S (NP (NNP MGM)) (VP (VBD did) (PP (IN for) (NP (NNP Red) (NNP Skelton)))))))))))) (, ,) (NP (NNP Paramount)) (VP (VBD did) (SBAR (S (SBAR (IN for) (S (NP (NNP Bob) (NNP Hope) (CC and) (NNP Sam) (NNP Goldwyn)) (VP (VBD did) (PP (IN for) (NP (NNP Danny) (NNP Kaye)))))) (, ,) ('' '') (NP (PRP she)) (ADVP (RB once)) (VP (VBD said))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="spent many years in Hollywood , `` none of the studios ever designed comedies for me the way MGM did for Red Skelton" type="VP">
          <tokens>
            <token id="4" string="spent" />
            <token id="5" string="many" />
            <token id="6" string="years" />
            <token id="7" string="in" />
            <token id="8" string="Hollywood" />
            <token id="9" string="," />
            <token id="10" string="``" />
            <token id="11" string="none" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="studios" />
            <token id="15" string="ever" />
            <token id="16" string="designed" />
            <token id="17" string="comedies" />
            <token id="18" string="for" />
            <token id="19" string="me" />
            <token id="20" string="the" />
            <token id="21" string="way" />
            <token id="22" string="MGM" />
            <token id="23" string="did" />
            <token id="24" string="for" />
            <token id="25" string="Red" />
            <token id="26" string="Skelton" />
          </tokens>
        </chunking>
        <chunking id="2" string="me the way" type="NP">
          <tokens>
            <token id="19" string="me" />
            <token id="20" string="the" />
            <token id="21" string="way" />
          </tokens>
        </chunking>
        <chunking id="3" string="Bob Hope and Sam Goldwyn" type="NP">
          <tokens>
            <token id="31" string="Bob" />
            <token id="32" string="Hope" />
            <token id="33" string="and" />
            <token id="34" string="Sam" />
            <token id="35" string="Goldwyn" />
          </tokens>
        </chunking>
        <chunking id="4" string="Paramount" type="NP">
          <tokens>
            <token id="28" string="Paramount" />
          </tokens>
        </chunking>
        <chunking id="5" string="did for Danny Kaye" type="VP">
          <tokens>
            <token id="36" string="did" />
            <token id="37" string="for" />
            <token id="38" string="Danny" />
            <token id="39" string="Kaye" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="3" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="many years" type="NP">
          <tokens>
            <token id="5" string="many" />
            <token id="6" string="years" />
          </tokens>
        </chunking>
        <chunking id="8" string="Hollywood" type="NP">
          <tokens>
            <token id="8" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="9" string="for Bob Hope and Sam Goldwyn did for Danny Kaye" type="SBAR">
          <tokens>
            <token id="30" string="for" />
            <token id="31" string="Bob" />
            <token id="32" string="Hope" />
            <token id="33" string="and" />
            <token id="34" string="Sam" />
            <token id="35" string="Goldwyn" />
            <token id="36" string="did" />
            <token id="37" string="for" />
            <token id="38" string="Danny" />
            <token id="39" string="Kaye" />
          </tokens>
        </chunking>
        <chunking id="10" string="MGM" type="NP">
          <tokens>
            <token id="22" string="MGM" />
          </tokens>
        </chunking>
        <chunking id="11" string="the studios" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="studios" />
          </tokens>
        </chunking>
        <chunking id="12" string="although she spent many years in Hollywood , `` none of the studios ever designed comedies for me the way MGM did for Red Skelton" type="SBAR">
          <tokens>
            <token id="2" string="although" />
            <token id="3" string="she" />
            <token id="4" string="spent" />
            <token id="5" string="many" />
            <token id="6" string="years" />
            <token id="7" string="in" />
            <token id="8" string="Hollywood" />
            <token id="9" string="," />
            <token id="10" string="``" />
            <token id="11" string="none" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="studios" />
            <token id="15" string="ever" />
            <token id="16" string="designed" />
            <token id="17" string="comedies" />
            <token id="18" string="for" />
            <token id="19" string="me" />
            <token id="20" string="the" />
            <token id="21" string="way" />
            <token id="22" string="MGM" />
            <token id="23" string="did" />
            <token id="24" string="for" />
            <token id="25" string="Red" />
            <token id="26" string="Skelton" />
          </tokens>
        </chunking>
        <chunking id="13" string="for Bob Hope and Sam Goldwyn did for Danny Kaye , '' she once said" type="SBAR">
          <tokens>
            <token id="30" string="for" />
            <token id="31" string="Bob" />
            <token id="32" string="Hope" />
            <token id="33" string="and" />
            <token id="34" string="Sam" />
            <token id="35" string="Goldwyn" />
            <token id="36" string="did" />
            <token id="37" string="for" />
            <token id="38" string="Danny" />
            <token id="39" string="Kaye" />
            <token id="40" string="," />
            <token id="41" string="''" />
            <token id="42" string="she" />
            <token id="43" string="once" />
            <token id="44" string="said" />
          </tokens>
        </chunking>
        <chunking id="14" string="did for Bob Hope and Sam Goldwyn did for Danny Kaye , '' she once said" type="VP">
          <tokens>
            <token id="29" string="did" />
            <token id="30" string="for" />
            <token id="31" string="Bob" />
            <token id="32" string="Hope" />
            <token id="33" string="and" />
            <token id="34" string="Sam" />
            <token id="35" string="Goldwyn" />
            <token id="36" string="did" />
            <token id="37" string="for" />
            <token id="38" string="Danny" />
            <token id="39" string="Kaye" />
            <token id="40" string="," />
            <token id="41" string="''" />
            <token id="42" string="she" />
            <token id="43" string="once" />
            <token id="44" string="said" />
          </tokens>
        </chunking>
        <chunking id="15" string="Red Skelton" type="NP">
          <tokens>
            <token id="25" string="Red" />
            <token id="26" string="Skelton" />
          </tokens>
        </chunking>
        <chunking id="16" string="ever designed comedies for me the way MGM did for Red Skelton" type="VP">
          <tokens>
            <token id="15" string="ever" />
            <token id="16" string="designed" />
            <token id="17" string="comedies" />
            <token id="18" string="for" />
            <token id="19" string="me" />
            <token id="20" string="the" />
            <token id="21" string="way" />
            <token id="22" string="MGM" />
            <token id="23" string="did" />
            <token id="24" string="for" />
            <token id="25" string="Red" />
            <token id="26" string="Skelton" />
          </tokens>
        </chunking>
        <chunking id="17" string="none" type="NP">
          <tokens>
            <token id="11" string="none" />
          </tokens>
        </chunking>
        <chunking id="18" string="MGM did for Red Skelton" type="SBAR">
          <tokens>
            <token id="22" string="MGM" />
            <token id="23" string="did" />
            <token id="24" string="for" />
            <token id="25" string="Red" />
            <token id="26" string="Skelton" />
          </tokens>
        </chunking>
        <chunking id="19" string="many years in Hollywood" type="NP">
          <tokens>
            <token id="5" string="many" />
            <token id="6" string="years" />
            <token id="7" string="in" />
            <token id="8" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="20" string="none of the studios" type="NP">
          <tokens>
            <token id="11" string="none" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="studios" />
          </tokens>
        </chunking>
        <chunking id="21" string="comedies" type="NP">
          <tokens>
            <token id="17" string="comedies" />
          </tokens>
        </chunking>
        <chunking id="22" string="comedies for me the way MGM did for Red Skelton" type="NP">
          <tokens>
            <token id="17" string="comedies" />
            <token id="18" string="for" />
            <token id="19" string="me" />
            <token id="20" string="the" />
            <token id="21" string="way" />
            <token id="22" string="MGM" />
            <token id="23" string="did" />
            <token id="24" string="for" />
            <token id="25" string="Red" />
            <token id="26" string="Skelton" />
          </tokens>
        </chunking>
        <chunking id="23" string="did for Red Skelton" type="VP">
          <tokens>
            <token id="23" string="did" />
            <token id="24" string="for" />
            <token id="25" string="Red" />
            <token id="26" string="Skelton" />
          </tokens>
        </chunking>
        <chunking id="24" string="the way" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="way" />
          </tokens>
        </chunking>
        <chunking id="25" string="me" type="NP">
          <tokens>
            <token id="19" string="me" />
          </tokens>
        </chunking>
        <chunking id="26" string="Danny Kaye" type="NP">
          <tokens>
            <token id="38" string="Danny" />
            <token id="39" string="Kaye" />
          </tokens>
        </chunking>
        <chunking id="27" string="said" type="VP">
          <tokens>
            <token id="44" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="29">did</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">spent</governor>
          <dependent id="2">although</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">spent</governor>
          <dependent id="3">she</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="29">did</governor>
          <dependent id="4">spent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">years</governor>
          <dependent id="5">many</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">spent</governor>
          <dependent id="6">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Hollywood</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">years</governor>
          <dependent id="8">Hollywood</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">designed</governor>
          <dependent id="11">none</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">studios</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">studios</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">none</governor>
          <dependent id="14">studios</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">designed</governor>
          <dependent id="15">ever</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">spent</governor>
          <dependent id="16">designed</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">designed</governor>
          <dependent id="17">comedies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">me</governor>
          <dependent id="18">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">comedies</governor>
          <dependent id="19">me</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">way</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">me</governor>
          <dependent id="21">way</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">did</governor>
          <dependent id="22">MGM</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">comedies</governor>
          <dependent id="23">did</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Skelton</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Skelton</governor>
          <dependent id="25">Red</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">did</governor>
          <dependent id="26">Skelton</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">did</governor>
          <dependent id="28">Paramount</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">did</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="36">did</governor>
          <dependent id="30">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Hope</governor>
          <dependent id="31">Bob</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">did</governor>
          <dependent id="32">Hope</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="32">Hope</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">Goldwyn</governor>
          <dependent id="34">Sam</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="32">Hope</governor>
          <dependent id="35">Goldwyn</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="44">said</governor>
          <dependent id="36">did</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">Kaye</governor>
          <dependent id="37">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Kaye</governor>
          <dependent id="38">Danny</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">did</governor>
          <dependent id="39">Kaye</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="44">said</governor>
          <dependent id="42">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="44">said</governor>
          <dependent id="43">once</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="29">did</governor>
          <dependent id="44">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="2" string="Sam Goldwyn" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Sam" />
            <token id="35" string="Goldwyn" />
          </tokens>
        </entity>
        <entity id="3" string="MGM" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="MGM" />
          </tokens>
        </entity>
        <entity id="4" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="43" string="once" />
          </tokens>
        </entity>
        <entity id="5" string="Bob Hope" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Bob" />
            <token id="32" string="Hope" />
          </tokens>
        </entity>
        <entity id="6" string="Danny Kaye" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="Danny" />
            <token id="39" string="Kaye" />
          </tokens>
        </entity>
        <entity id="7" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="6" string="years" />
          </tokens>
        </entity>
        <entity id="8" string="Red Skelton" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Red" />
            <token id="26" string="Skelton" />
          </tokens>
        </entity>
        <entity id="9" string="Paramount" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="28" string="Paramount" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>``Television was the medium for me, the medium for anyone who wanted to be well known a lot faster than waiting a year and a half for a movie to come out,&amp;apost;&amp;apost; she said in an interview late in life.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="medium" lemma="medium" stem="medium" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="medium" lemma="medium" stem="medium" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="anyone" lemma="anyone" stem="anyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="known" lemma="know" stem="known" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="faster" lemma="faster" stem="faster" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="waiting" lemma="wait" stem="wait" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="25" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="half" lemma="half" stem="half" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="movie" lemma="movie" stem="movi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="come" lemma="come" stem="come" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="late" lemma="late" stem="late" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NN Television)) (VP (VBD was) (NP (NP (NP (DT the) (NN medium)) (PP (IN for) (NP (PRP me)))) (, ,) (NP (NP (DT the) (NN medium)) (PP (IN for) (NP (NN anyone))) (SBAR (WHNP (WP who)) (S (VP (VBD wanted) (S (VP (TO to) (VP (VB be) (VP (ADVP (RB well)) (VBN known) (UCP (ADJP (ADJP (NP (DT a) (NN lot)) (JJR faster)) (PP (IN than) (S (VP (VBG waiting) (NP (DT a) (NN year)))))) (CC and) (NP (NP (DT a) (NN half)) (PP (IN for) (NP (DT a) (NN movie) (S (VP (TO to) (VP (VB come) (PRT (RP out)))))))))))))))))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said) (PP (IN in) (NP (DT an) (NN interview) (RB late))) (PP (IN in) (NP (NN life)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who wanted to be well known a lot faster than waiting a year and a half for a movie to come out" type="SBAR">
          <tokens>
            <token id="13" string="who" />
            <token id="14" string="wanted" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="well" />
            <token id="18" string="known" />
            <token id="19" string="a" />
            <token id="20" string="lot" />
            <token id="21" string="faster" />
            <token id="22" string="than" />
            <token id="23" string="waiting" />
            <token id="24" string="a" />
            <token id="25" string="year" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="half" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="movie" />
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="2" string="wanted to be well known a lot faster than waiting a year and a half for a movie to come out" type="VP">
          <tokens>
            <token id="14" string="wanted" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="well" />
            <token id="18" string="known" />
            <token id="19" string="a" />
            <token id="20" string="lot" />
            <token id="21" string="faster" />
            <token id="22" string="than" />
            <token id="23" string="waiting" />
            <token id="24" string="a" />
            <token id="25" string="year" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="half" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="movie" />
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="3" string="a half" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="half" />
          </tokens>
        </chunking>
        <chunking id="4" string="a movie to come out" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="movie" />
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="waiting a year" type="VP">
          <tokens>
            <token id="23" string="waiting" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="6" string="well known a lot faster than waiting a year and a half for a movie to come out" type="VP">
          <tokens>
            <token id="17" string="well" />
            <token id="18" string="known" />
            <token id="19" string="a" />
            <token id="20" string="lot" />
            <token id="21" string="faster" />
            <token id="22" string="than" />
            <token id="23" string="waiting" />
            <token id="24" string="a" />
            <token id="25" string="year" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="half" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="movie" />
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="7" string="a lot faster" type="ADJP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="lot" />
            <token id="21" string="faster" />
          </tokens>
        </chunking>
        <chunking id="8" string="she" type="NP">
          <tokens>
            <token id="37" string="she" />
          </tokens>
        </chunking>
        <chunking id="9" string="said in an interview late in life" type="VP">
          <tokens>
            <token id="38" string="said" />
            <token id="39" string="in" />
            <token id="40" string="an" />
            <token id="41" string="interview" />
            <token id="42" string="late" />
            <token id="43" string="in" />
            <token id="44" string="life" />
          </tokens>
        </chunking>
        <chunking id="10" string="the medium for me , the medium for anyone who wanted to be well known a lot faster than waiting a year and a half for a movie to come out" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="medium" />
            <token id="6" string="for" />
            <token id="7" string="me" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="medium" />
            <token id="11" string="for" />
            <token id="12" string="anyone" />
            <token id="13" string="who" />
            <token id="14" string="wanted" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="well" />
            <token id="18" string="known" />
            <token id="19" string="a" />
            <token id="20" string="lot" />
            <token id="21" string="faster" />
            <token id="22" string="than" />
            <token id="23" string="waiting" />
            <token id="24" string="a" />
            <token id="25" string="year" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="half" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="movie" />
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="11" string="the medium" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="medium" />
          </tokens>
        </chunking>
        <chunking id="12" string="anyone" type="NP">
          <tokens>
            <token id="12" string="anyone" />
          </tokens>
        </chunking>
        <chunking id="13" string="a lot" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="lot" />
          </tokens>
        </chunking>
        <chunking id="14" string="come out" type="VP">
          <tokens>
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="15" string="Television" type="NP">
          <tokens>
            <token id="2" string="Television" />
          </tokens>
        </chunking>
        <chunking id="16" string="to come out" type="VP">
          <tokens>
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="17" string="be well known a lot faster than waiting a year and a half for a movie to come out" type="VP">
          <tokens>
            <token id="16" string="be" />
            <token id="17" string="well" />
            <token id="18" string="known" />
            <token id="19" string="a" />
            <token id="20" string="lot" />
            <token id="21" string="faster" />
            <token id="22" string="than" />
            <token id="23" string="waiting" />
            <token id="24" string="a" />
            <token id="25" string="year" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="half" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="movie" />
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="18" string="was the medium for me , the medium for anyone who wanted to be well known a lot faster than waiting a year and a half for a movie to come out" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="medium" />
            <token id="6" string="for" />
            <token id="7" string="me" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="medium" />
            <token id="11" string="for" />
            <token id="12" string="anyone" />
            <token id="13" string="who" />
            <token id="14" string="wanted" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="well" />
            <token id="18" string="known" />
            <token id="19" string="a" />
            <token id="20" string="lot" />
            <token id="21" string="faster" />
            <token id="22" string="than" />
            <token id="23" string="waiting" />
            <token id="24" string="a" />
            <token id="25" string="year" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="half" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="movie" />
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="19" string="to be well known a lot faster than waiting a year and a half for a movie to come out" type="VP">
          <tokens>
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="well" />
            <token id="18" string="known" />
            <token id="19" string="a" />
            <token id="20" string="lot" />
            <token id="21" string="faster" />
            <token id="22" string="than" />
            <token id="23" string="waiting" />
            <token id="24" string="a" />
            <token id="25" string="year" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="half" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="movie" />
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="20" string="life" type="NP">
          <tokens>
            <token id="44" string="life" />
          </tokens>
        </chunking>
        <chunking id="21" string="the medium for me" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="medium" />
            <token id="6" string="for" />
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="22" string="a half for a movie to come out" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="half" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="movie" />
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="23" string="a lot faster than waiting a year" type="ADJP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="lot" />
            <token id="21" string="faster" />
            <token id="22" string="than" />
            <token id="23" string="waiting" />
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="24" string="the medium for anyone who wanted to be well known a lot faster than waiting a year and a half for a movie to come out" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="medium" />
            <token id="11" string="for" />
            <token id="12" string="anyone" />
            <token id="13" string="who" />
            <token id="14" string="wanted" />
            <token id="15" string="to" />
            <token id="16" string="be" />
            <token id="17" string="well" />
            <token id="18" string="known" />
            <token id="19" string="a" />
            <token id="20" string="lot" />
            <token id="21" string="faster" />
            <token id="22" string="than" />
            <token id="23" string="waiting" />
            <token id="24" string="a" />
            <token id="25" string="year" />
            <token id="26" string="and" />
            <token id="27" string="a" />
            <token id="28" string="half" />
            <token id="29" string="for" />
            <token id="30" string="a" />
            <token id="31" string="movie" />
            <token id="32" string="to" />
            <token id="33" string="come" />
            <token id="34" string="out" />
          </tokens>
        </chunking>
        <chunking id="25" string="me" type="NP">
          <tokens>
            <token id="7" string="me" />
          </tokens>
        </chunking>
        <chunking id="26" string="a year" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </chunking>
        <chunking id="27" string="an interview late" type="NP">
          <tokens>
            <token id="40" string="an" />
            <token id="41" string="interview" />
            <token id="42" string="late" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">medium</governor>
          <dependent id="2">Television</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">medium</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">medium</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="38">said</governor>
          <dependent id="5">medium</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">me</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">medium</governor>
          <dependent id="7">me</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">medium</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">medium</governor>
          <dependent id="10">medium</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">anyone</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">medium</governor>
          <dependent id="12">anyone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">wanted</governor>
          <dependent id="13">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">medium</governor>
          <dependent id="14">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">known</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">known</governor>
          <dependent id="16">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">known</governor>
          <dependent id="17">well</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="14">wanted</governor>
          <dependent id="18">known</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">lot</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="21">faster</governor>
          <dependent id="20">lot</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">known</governor>
          <dependent id="21">faster</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">waiting</governor>
          <dependent id="22">than</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="21">faster</governor>
          <dependent id="23">waiting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">year</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="23">waiting</governor>
          <dependent id="25">year</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">faster</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">half</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">faster</governor>
          <dependent id="28">half</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">movie</governor>
          <dependent id="29">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">movie</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">half</governor>
          <dependent id="31">movie</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">come</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="31">movie</governor>
          <dependent id="33">come</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="33">come</governor>
          <dependent id="34">out</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">said</governor>
          <dependent id="37">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="38">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">interview</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">interview</governor>
          <dependent id="40">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">said</governor>
          <dependent id="41">interview</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="41">interview</governor>
          <dependent id="42">late</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">life</governor>
          <dependent id="43">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">said</governor>
          <dependent id="44">life</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="a year" type="DURATION" score="0.0">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>``Television is an instant barometer, especially the way we did it.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="instant" lemma="instant" stem="instant" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="barometer" lemma="barometer" stem="baromet" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="especially" lemma="especially" stem="especi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NN Television)) (VP (VBZ is) (NP (NP (DT an) (JJ instant) (NN barometer)) (, ,) (RB especially) (NP (DT the) (NN way))))) (NP (PRP we)) (VP (VBD did) (NP (PRP it))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="did it" type="VP">
          <tokens>
            <token id="12" string="did" />
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="an instant barometer , especially the way" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="instant" />
            <token id="6" string="barometer" />
            <token id="7" string="," />
            <token id="8" string="especially" />
            <token id="9" string="the" />
            <token id="10" string="way" />
          </tokens>
        </chunking>
        <chunking id="3" string="the way" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="way" />
          </tokens>
        </chunking>
        <chunking id="4" string="an instant barometer" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="instant" />
            <token id="6" string="barometer" />
          </tokens>
        </chunking>
        <chunking id="5" string="Television" type="NP">
          <tokens>
            <token id="2" string="Television" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="is an instant barometer , especially the way" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="an" />
            <token id="5" string="instant" />
            <token id="6" string="barometer" />
            <token id="7" string="," />
            <token id="8" string="especially" />
            <token id="9" string="the" />
            <token id="10" string="way" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="11" string="we" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">barometer</governor>
          <dependent id="2">Television</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">barometer</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">barometer</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">barometer</governor>
          <dependent id="5">instant</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">did</governor>
          <dependent id="6">barometer</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">barometer</governor>
          <dependent id="8">especially</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">way</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">barometer</governor>
          <dependent id="10">way</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">did</governor>
          <dependent id="11">we</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">did</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">did</governor>
          <dependent id="13">it</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>``It was all new.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBD was) (NP (DT all) (JJ new))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was all new" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="all" />
            <token id="5" string="new" />
          </tokens>
        </chunking>
        <chunking id="2" string="all new" type="NP">
          <tokens>
            <token id="4" string="all" />
            <token id="5" string="new" />
          </tokens>
        </chunking>
        <chunking id="3" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">new</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">new</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">new</governor>
          <dependent id="4">all</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">new</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>Nobody knew anything about television.</content>
      <tokens>
        <token id="1" string="Nobody" lemma="nobody" stem="nobodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Nobody)) (VP (VBD knew) (NP (NN anything)) (PP (IN about) (NP (NN television)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="knew anything about television" type="VP">
          <tokens>
            <token id="2" string="knew" />
            <token id="3" string="anything" />
            <token id="4" string="about" />
            <token id="5" string="television" />
          </tokens>
        </chunking>
        <chunking id="2" string="television" type="NP">
          <tokens>
            <token id="5" string="television" />
          </tokens>
        </chunking>
        <chunking id="3" string="Nobody" type="NP">
          <tokens>
            <token id="1" string="Nobody" />
          </tokens>
        </chunking>
        <chunking id="4" string="anything" type="NP">
          <tokens>
            <token id="3" string="anything" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">knew</governor>
          <dependent id="1">Nobody</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">knew</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">knew</governor>
          <dependent id="3">anything</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">television</governor>
          <dependent id="4">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">knew</governor>
          <dependent id="5">television</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Nobody was there to say, `No, don&amp;apost;t do that, it&amp;apost;s wrong!&amp;apost;</content>
      <tokens>
        <token id="1" string="Nobody" lemma="nobody" stem="nobodi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="there" lemma="there" stem="there" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="No" lemma="no" stem="no" pos="UH" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="!" lemma="!" stem="!" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NN Nobody)) (VP (VBD was) (ADVP (RB there)) (S (VP (TO to) (VP (VB say)))))) (, ,) (`` `) (S (INTJ (UH No)) (, ,) (S (VP (VBP do) (RB n't) (VP (VB do) (NP (DT that))))) (, ,) (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ wrong)))) (. !) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="13" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="was there to say" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="there" />
            <token id="4" string="to" />
            <token id="5" string="say" />
          </tokens>
        </chunking>
        <chunking id="3" string="Nobody" type="NP">
          <tokens>
            <token id="1" string="Nobody" />
          </tokens>
        </chunking>
        <chunking id="4" string="do n't do that" type="VP">
          <tokens>
            <token id="10" string="do" />
            <token id="11" string="n't" />
            <token id="12" string="do" />
            <token id="13" string="that" />
          </tokens>
        </chunking>
        <chunking id="5" string="do that" type="VP">
          <tokens>
            <token id="12" string="do" />
            <token id="13" string="that" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="15" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="to say" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="say" />
          </tokens>
        </chunking>
        <chunking id="8" string="say" type="VP">
          <tokens>
            <token id="5" string="say" />
          </tokens>
        </chunking>
        <chunking id="9" string="wrong" type="ADJP">
          <tokens>
            <token id="17" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="10" string="'s wrong" type="VP">
          <tokens>
            <token id="16" string="'s" />
            <token id="17" string="wrong" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">was</governor>
          <dependent id="1">Nobody</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">was</governor>
          <dependent id="3">there</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">say</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">was</governor>
          <dependent id="5">say</dependent>
        </dependency>
        <dependency type="discourse">
          <governor id="17">wrong</governor>
          <dependent id="8">No</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">do</governor>
          <dependent id="10">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">do</governor>
          <dependent id="11">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">wrong</governor>
          <dependent id="12">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">do</governor>
          <dependent id="13">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">wrong</governor>
          <dependent id="15">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">wrong</governor>
          <dependent id="16">'s</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">was</governor>
          <dependent id="17">wrong</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>We never knew what was wrong and what was right.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="wrong" lemma="wrong" stem="wrong" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (ADVP (RB never)) (VP (VBD knew) (SBAR (SBAR (WHNP (WP what)) (S (VP (VBD was) (ADJP (JJ wrong))))) (CC and) (SBAR (WHNP (WP what)) (S (VP (VBD was) (ADJP (RB right))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="what was wrong" type="SBAR">
          <tokens>
            <token id="4" string="what" />
            <token id="5" string="was" />
            <token id="6" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="2" string="knew what was wrong and what was right" type="VP">
          <tokens>
            <token id="3" string="knew" />
            <token id="4" string="what" />
            <token id="5" string="was" />
            <token id="6" string="wrong" />
            <token id="7" string="and" />
            <token id="8" string="what" />
            <token id="9" string="was" />
            <token id="10" string="right" />
          </tokens>
        </chunking>
        <chunking id="3" string="was right" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="right" />
          </tokens>
        </chunking>
        <chunking id="4" string="what was right" type="SBAR">
          <tokens>
            <token id="8" string="what" />
            <token id="9" string="was" />
            <token id="10" string="right" />
          </tokens>
        </chunking>
        <chunking id="5" string="right" type="ADJP">
          <tokens>
            <token id="10" string="right" />
          </tokens>
        </chunking>
        <chunking id="6" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="7" string="what was wrong and what was right" type="SBAR">
          <tokens>
            <token id="4" string="what" />
            <token id="5" string="was" />
            <token id="6" string="wrong" />
            <token id="7" string="and" />
            <token id="8" string="what" />
            <token id="9" string="was" />
            <token id="10" string="right" />
          </tokens>
        </chunking>
        <chunking id="8" string="was wrong" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="wrong" />
          </tokens>
        </chunking>
        <chunking id="9" string="wrong" type="ADJP">
          <tokens>
            <token id="6" string="wrong" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">knew</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">knew</governor>
          <dependent id="2">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">knew</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">wrong</governor>
          <dependent id="4">what</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">wrong</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">knew</governor>
          <dependent id="6">wrong</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">wrong</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">right</governor>
          <dependent id="8">what</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">right</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">wrong</governor>
          <dependent id="10">right</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="10" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>We were all feeling our way.</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="feeling" lemma="feel" stem="feel" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP We)) (VP (VBD were) (ADVP (DT all)) (VP (VBG feeling) (NP (PRP$ our) (NN way)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="our way" type="NP">
          <tokens>
            <token id="5" string="our" />
            <token id="6" string="way" />
          </tokens>
        </chunking>
        <chunking id="2" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="3" string="feeling our way" type="VP">
          <tokens>
            <token id="4" string="feeling" />
            <token id="5" string="our" />
            <token id="6" string="way" />
          </tokens>
        </chunking>
        <chunking id="4" string="were all feeling our way" type="VP">
          <tokens>
            <token id="2" string="were" />
            <token id="3" string="all" />
            <token id="4" string="feeling" />
            <token id="5" string="our" />
            <token id="6" string="way" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">feeling</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">feeling</governor>
          <dependent id="2">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">feeling</governor>
          <dependent id="3">all</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">feeling</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">way</governor>
          <dependent id="5">our</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">feeling</governor>
          <dependent id="6">way</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Desi was very innovative and very showmanship-conscious and was very intent on going ahead and doing it: `That sounds all right, let&amp;apost;s go!&amp;apost;</content>
      <tokens>
        <token id="1" string="Desi" lemma="desi" stem="desi" pos="NN" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="innovative" lemma="innovative" stem="innov" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="showmanship-conscious" lemma="showmanship-conscious" stem="showmanship-consci" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="intent" lemma="intent" stem="intent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="ahead" lemma="ahead" stem="ahead" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="doing" lemma="do" stem="do" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="sounds" lemma="sound" stem="sound" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="all" lemma="all" stem="all" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="!" lemma="!" stem="!" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NN Desi)) (VP (VP (VBD was) (ADJP (ADJP (RB very) (JJ innovative)) (CC and) (ADJP (RB very) (JJ showmanship-conscious)))) (CC and) (VP (VBD was) (ADJP (RB very) (JJ intent) (PP (IN on) (S (VP (VP (VBG going) (ADVP (RB ahead))) (CC and) (VP (VBG doing) (NP (PRP it)))))))))) (: :) (`` `) (S (NP (DT That)) (VP (VBZ sounds) (S (ADVP (RB all) (RB right)) (, ,) (VP (VB let) (S (NP (POS 's)) (VP (VB go))))))) (. !) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="was very innovative and very showmanship-conscious" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="very" />
            <token id="4" string="innovative" />
            <token id="5" string="and" />
            <token id="6" string="very" />
            <token id="7" string="showmanship-conscious" />
          </tokens>
        </chunking>
        <chunking id="2" string="doing it" type="VP">
          <tokens>
            <token id="16" string="doing" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="going ahead and doing it" type="VP">
          <tokens>
            <token id="13" string="going" />
            <token id="14" string="ahead" />
            <token id="15" string="and" />
            <token id="16" string="doing" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="That" type="NP">
          <tokens>
            <token id="20" string="That" />
          </tokens>
        </chunking>
        <chunking id="5" string="very showmanship-conscious" type="ADJP">
          <tokens>
            <token id="6" string="very" />
            <token id="7" string="showmanship-conscious" />
          </tokens>
        </chunking>
        <chunking id="6" string="go" type="VP">
          <tokens>
            <token id="27" string="go" />
          </tokens>
        </chunking>
        <chunking id="7" string="going ahead" type="VP">
          <tokens>
            <token id="13" string="going" />
            <token id="14" string="ahead" />
          </tokens>
        </chunking>
        <chunking id="8" string="was very intent on going ahead and doing it" type="VP">
          <tokens>
            <token id="9" string="was" />
            <token id="10" string="very" />
            <token id="11" string="intent" />
            <token id="12" string="on" />
            <token id="13" string="going" />
            <token id="14" string="ahead" />
            <token id="15" string="and" />
            <token id="16" string="doing" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="let 's go" type="VP">
          <tokens>
            <token id="25" string="let" />
            <token id="26" string="'s" />
            <token id="27" string="go" />
          </tokens>
        </chunking>
        <chunking id="11" string="'s" type="NP">
          <tokens>
            <token id="26" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="very innovative and very showmanship-conscious" type="ADJP">
          <tokens>
            <token id="3" string="very" />
            <token id="4" string="innovative" />
            <token id="5" string="and" />
            <token id="6" string="very" />
            <token id="7" string="showmanship-conscious" />
          </tokens>
        </chunking>
        <chunking id="13" string="very intent on going ahead and doing it" type="ADJP">
          <tokens>
            <token id="10" string="very" />
            <token id="11" string="intent" />
            <token id="12" string="on" />
            <token id="13" string="going" />
            <token id="14" string="ahead" />
            <token id="15" string="and" />
            <token id="16" string="doing" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="very innovative" type="ADJP">
          <tokens>
            <token id="3" string="very" />
            <token id="4" string="innovative" />
          </tokens>
        </chunking>
        <chunking id="15" string="Desi" type="NP">
          <tokens>
            <token id="1" string="Desi" />
          </tokens>
        </chunking>
        <chunking id="16" string="was very innovative and very showmanship-conscious and was very intent on going ahead and doing it" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="very" />
            <token id="4" string="innovative" />
            <token id="5" string="and" />
            <token id="6" string="very" />
            <token id="7" string="showmanship-conscious" />
            <token id="8" string="and" />
            <token id="9" string="was" />
            <token id="10" string="very" />
            <token id="11" string="intent" />
            <token id="12" string="on" />
            <token id="13" string="going" />
            <token id="14" string="ahead" />
            <token id="15" string="and" />
            <token id="16" string="doing" />
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="17" string="sounds all right , let 's go" type="VP">
          <tokens>
            <token id="21" string="sounds" />
            <token id="22" string="all" />
            <token id="23" string="right" />
            <token id="24" string="," />
            <token id="25" string="let" />
            <token id="26" string="'s" />
            <token id="27" string="go" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">innovative</governor>
          <dependent id="1">Desi</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">innovative</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">innovative</governor>
          <dependent id="3">very</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">innovative</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">innovative</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">showmanship-conscious</governor>
          <dependent id="6">very</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">innovative</governor>
          <dependent id="7">showmanship-conscious</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">innovative</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">intent</governor>
          <dependent id="9">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">intent</governor>
          <dependent id="10">very</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">innovative</governor>
          <dependent id="11">intent</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">going</governor>
          <dependent id="12">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">intent</governor>
          <dependent id="13">going</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">going</governor>
          <dependent id="14">ahead</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">going</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">going</governor>
          <dependent id="16">doing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">doing</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">sounds</governor>
          <dependent id="20">That</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">innovative</governor>
          <dependent id="21">sounds</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">right</governor>
          <dependent id="22">all</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">let</governor>
          <dependent id="23">right</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="21">sounds</governor>
          <dependent id="25">let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">go</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="25">let</governor>
          <dependent id="27">go</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Desi" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Desi" />
          </tokens>
        </entity>
        <entity id="2" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="23" string="right" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="false">
      <content>So we went.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="So" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (IN So) (NP (PRP we)) (VP (VBD went)) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="went" type="VP">
          <tokens>
            <token id="3" string="went" />
          </tokens>
        </chunking>
        <chunking id="2" string="we" type="NP">
          <tokens>
            <token id="2" string="we" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="3">went</governor>
          <dependent id="1">So</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">went</governor>
          <dependent id="2">we</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">went</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="false">
      <content>Always the credit to someone else.</content>
      <tokens>
        <token id="1" string="Always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="credit" lemma="credit" stem="credit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="else" lemma="else" stem="els" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (ADVP (RB Always) (NP (DT the) (NN credit)) (PP (TO to) (NP (NN someone)))) (RB else) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="someone" type="NP">
          <tokens>
            <token id="5" string="someone" />
          </tokens>
        </chunking>
        <chunking id="2" string="the credit" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="credit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="6">else</governor>
          <dependent id="1">Always</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">credit</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="1">Always</governor>
          <dependent id="3">credit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">someone</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Always</governor>
          <dependent id="5">someone</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">else</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="false">
      <content>But millions upon millions of television watchers know otherwise.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="millions" lemma="million" stem="million" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="upon" lemma="upon" stem="upon" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="millions" lemma="million" stem="million" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="watchers" lemma="watcher" stem="watcher" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="otherwise" lemma="otherwise" stem="otherwis" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (NNS millions)) (PP (IN upon) (NP (NP (NNS millions)) (PP (IN of) (NP (NN television) (NNS watchers)))))) (VP (VBP know) (ADVP (RB otherwise))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="television watchers" type="NP">
          <tokens>
            <token id="6" string="television" />
            <token id="7" string="watchers" />
          </tokens>
        </chunking>
        <chunking id="2" string="know otherwise" type="VP">
          <tokens>
            <token id="8" string="know" />
            <token id="9" string="otherwise" />
          </tokens>
        </chunking>
        <chunking id="3" string="millions upon millions of television watchers" type="NP">
          <tokens>
            <token id="2" string="millions" />
            <token id="3" string="upon" />
            <token id="4" string="millions" />
            <token id="5" string="of" />
            <token id="6" string="television" />
            <token id="7" string="watchers" />
          </tokens>
        </chunking>
        <chunking id="4" string="millions of television watchers" type="NP">
          <tokens>
            <token id="4" string="millions" />
            <token id="5" string="of" />
            <token id="6" string="television" />
            <token id="7" string="watchers" />
          </tokens>
        </chunking>
        <chunking id="5" string="millions" type="NP">
          <tokens>
            <token id="2" string="millions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">know</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">know</governor>
          <dependent id="2">millions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">millions</governor>
          <dependent id="3">upon</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">millions</governor>
          <dependent id="4">millions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">watchers</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">watchers</governor>
          <dependent id="6">television</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">millions</governor>
          <dependent id="7">watchers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">know</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">know</governor>
          <dependent id="9">otherwise</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="LIST">
      <referenced ids_tokens="31-32-33-34-35" string="Bob Hope and Sam Goldwyn" id_sentence="22" />
      <mentions>
        <mention ids_tokens="11" string="we" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="5-6-7-8-9" string="Hollywood for The Associated Press" id_sentence="1" />
      <mentions>
        <mention ids_tokens="8" string="Hollywood" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="10-11" string="Lucille Ball" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1" string="She" id_sentence="4" />
        <mention ids_tokens="1" string="She" id_sentence="5" />
        <mention ids_tokens="4" string="her" id_sentence="5" />
        <mention ids_tokens="1" string="She" id_sentence="6" />
        <mention ids_tokens="13" string="her" id_sentence="6" />
        <mention ids_tokens="2" string="she" id_sentence="7" />
        <mention ids_tokens="20" string="she" id_sentence="7" />
        <mention ids_tokens="12-16" string="`` I Love Lucy''" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="an instant barometer" id_sentence="24" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="25" />
        <mention ids_tokens="13" string="that" id_sentence="27" />
        <mention ids_tokens="15" string="it" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="13-14" string="her way" id_sentence="6" />
      <mentions>
        <mention ids_tokens="20-21" string="the way" id_sentence="22" />
        <mention ids_tokens="9-10" string="the way" id_sentence="24" />
        <mention ids_tokens="5-6" string="our way" id_sentence="29" />
        <mention ids_tokens="17" string="it" id_sentence="30" />
        <mention ids_tokens="20" string="That" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="a humanitarian award" id_sentence="7" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="8" />
        <mention ids_tokens="11" string="it" id_sentence="8" />
        <mention ids_tokens="15" string="it" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="13-14-15" string="a CBS special" id_sentence="7" />
      <mentions>
        <mention ids_tokens="12" string="CBS" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="11" type="PRONOMINAL">
      <referenced ids_tokens="1" string="We" id_sentence="28" />
      <mentions>
        <mention ids_tokens="5" string="our" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="12" type="PROPER">
      <referenced ids_tokens="25-26-27-28-29-30-31" string="the last five years of the show" id_sentence="14" />
      <mentions>
        <mention ids_tokens="16-17" string="five years" id_sentence="7" />
        <mention ids_tokens="6" string="I" id_sentence="8" />
        <mention ids_tokens="2" string="she" id_sentence="9" />
        <mention ids_tokens="2" string="she" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="9" string="Lucy" id_sentence="9" />
      <mentions>
        <mention ids_tokens="19-20" string="Lucy's" id_sentence="11" />
        <mention ids_tokens="6" string="her" id_sentence="20" />
        <mention ids_tokens="1" string="She" id_sentence="21" />
        <mention ids_tokens="6-8" string="I Love Lucy" id_sentence="21" />
        <mention ids_tokens="3" string="she" id_sentence="22" />
        <mention ids_tokens="19-21" string="me the way" id_sentence="22" />
        <mention ids_tokens="42" string="she" id_sentence="22" />
        <mention ids_tokens="7" string="me" id_sentence="23" />
        <mention ids_tokens="37" string="she" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="17" type="PROPER">
      <referenced ids_tokens="8-9" string="Love Lucy" id_sentence="9" />
      <mentions>
        <mention ids_tokens="11-13" string="I Love Lucy" id_sentence="11" />
        <mention ids_tokens="1" string="Her" id_sentence="12" />
        <mention ids_tokens="22" string="her" id_sentence="12" />
        <mention ids_tokens="32" string="she" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="48-49-50" string="the show 's" id_sentence="9" />
      <mentions>
        <mention ids_tokens="30-31" string="the show" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="5" string="Desi" id_sentence="10" />
      <mentions>
        <mention ids_tokens="1-2" string="Desi's" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="3-4" string="one occasion" id_sentence="14" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="17" />
        <mention ids_tokens="8" string="I" id_sentence="17" />
        <mention ids_tokens="2" string="I" id_sentence="18" />
        <mention ids_tokens="5" string="my" id_sentence="18" />
      </mentions>
    </coreference>
  </coreferences>
</document>
