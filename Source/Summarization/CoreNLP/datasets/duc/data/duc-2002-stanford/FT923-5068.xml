<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="FT923-5068">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>MADE IN AMERICA: MY STORY By Sam Walton Doubleday, Dollars 22.50.</content>
      <tokens>
        <token id="1" string="MADE" lemma="MADE" stem="made" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="IN" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="AMERICA" lemma="AMERICA" stem="america" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="4" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="MY" lemma="MY" stem="my" pos="NNP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="STORY" lemma="STORY" stem="story" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="Doubleday" lemma="Doubleday" stem="doubledai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Dollars" lemma="Dollars" stem="dollar" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="22.50" lemma="22.50" stem="22.50" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP MADE)) (PP (IN IN) (NP (NNP AMERICA)))) (: :) (S (NP (NNP MY) (NNP STORY)) (PP (IN By) (NP (NP (NNP Sam) (NNP Walton) (NNP Doubleday)) (, ,) (NP (NNP Dollars) (CD 22.50))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Dollars 22.50" type="NP">
          <tokens>
            <token id="12" string="Dollars" />
            <token id="13" string="22.50" />
          </tokens>
        </chunking>
        <chunking id="2" string="AMERICA" type="NP">
          <tokens>
            <token id="3" string="AMERICA" />
          </tokens>
        </chunking>
        <chunking id="3" string="Sam Walton Doubleday , Dollars 22.50" type="NP">
          <tokens>
            <token id="8" string="Sam" />
            <token id="9" string="Walton" />
            <token id="10" string="Doubleday" />
            <token id="11" string="," />
            <token id="12" string="Dollars" />
            <token id="13" string="22.50" />
          </tokens>
        </chunking>
        <chunking id="4" string="MADE" type="NP">
          <tokens>
            <token id="1" string="MADE" />
          </tokens>
        </chunking>
        <chunking id="5" string="MY STORY" type="NP">
          <tokens>
            <token id="5" string="MY" />
            <token id="6" string="STORY" />
          </tokens>
        </chunking>
        <chunking id="6" string="Sam Walton Doubleday" type="NP">
          <tokens>
            <token id="8" string="Sam" />
            <token id="9" string="Walton" />
            <token id="10" string="Doubleday" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">MADE</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">AMERICA</governor>
          <dependent id="2">IN</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">MADE</governor>
          <dependent id="3">AMERICA</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">STORY</governor>
          <dependent id="5">MY</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">MADE</governor>
          <dependent id="6">STORY</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Doubleday</governor>
          <dependent id="7">By</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Doubleday</governor>
          <dependent id="8">Sam</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Doubleday</governor>
          <dependent id="9">Walton</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">STORY</governor>
          <dependent id="10">Doubleday</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">Doubleday</governor>
          <dependent id="12">Dollars</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">Dollars</governor>
          <dependent id="13">22.50</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="22.50" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="22.50" />
          </tokens>
        </entity>
        <entity id="2" string="AMERICA" type="LOCATION" score="0.0">
          <tokens>
            <token id="3" string="AMERICA" />
          </tokens>
        </entity>
        <entity id="3" string="Sam Walton Doubleday" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Sam" />
            <token id="9" string="Walton" />
            <token id="10" string="Doubleday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>269 pages Being an American folk hero is a tricky assignment, as Ross Perot found out.</content>
      <tokens>
        <token id="1" string="269" lemma="269" stem="269" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="pages" lemma="page" stem="page" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="6" string="folk" lemma="folk" stem="folk" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="hero" lemma="hero" stem="hero" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="tricky" lemma="tricky" stem="tricki" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="assignment" lemma="assignment" stem="assign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Ross" lemma="Ross" stem="ross" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Perot" lemma="Perot" stem="perot" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (CD 269) (NNS pages)) (SBAR (S (VP (VBG Being) (NP (DT an) (JJ American) (NN folk) (NN hero)))))) (VP (VBZ is) (NP (DT a) (JJ tricky) (NN assignment)) (, ,) (SBAR (IN as) (S (NP (NNP Ross) (NNP Perot)) (VP (VBD found) (PRT (RP out)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="269 pages Being an American folk hero" type="NP">
          <tokens>
            <token id="1" string="269" />
            <token id="2" string="pages" />
            <token id="3" string="Being" />
            <token id="4" string="an" />
            <token id="5" string="American" />
            <token id="6" string="folk" />
            <token id="7" string="hero" />
          </tokens>
        </chunking>
        <chunking id="2" string="as Ross Perot found out" type="SBAR">
          <tokens>
            <token id="13" string="as" />
            <token id="14" string="Ross" />
            <token id="15" string="Perot" />
            <token id="16" string="found" />
            <token id="17" string="out" />
          </tokens>
        </chunking>
        <chunking id="3" string="an American folk hero" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="American" />
            <token id="6" string="folk" />
            <token id="7" string="hero" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ross Perot" type="NP">
          <tokens>
            <token id="14" string="Ross" />
            <token id="15" string="Perot" />
          </tokens>
        </chunking>
        <chunking id="5" string="found out" type="VP">
          <tokens>
            <token id="16" string="found" />
            <token id="17" string="out" />
          </tokens>
        </chunking>
        <chunking id="6" string="is a tricky assignment , as Ross Perot found out" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="a" />
            <token id="10" string="tricky" />
            <token id="11" string="assignment" />
            <token id="12" string="," />
            <token id="13" string="as" />
            <token id="14" string="Ross" />
            <token id="15" string="Perot" />
            <token id="16" string="found" />
            <token id="17" string="out" />
          </tokens>
        </chunking>
        <chunking id="7" string="269 pages" type="NP">
          <tokens>
            <token id="1" string="269" />
            <token id="2" string="pages" />
          </tokens>
        </chunking>
        <chunking id="8" string="Being an American folk hero" type="SBAR">
          <tokens>
            <token id="3" string="Being" />
            <token id="4" string="an" />
            <token id="5" string="American" />
            <token id="6" string="folk" />
            <token id="7" string="hero" />
          </tokens>
        </chunking>
        <chunking id="9" string="a tricky assignment" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="tricky" />
            <token id="11" string="assignment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nummod">
          <governor id="2">pages</governor>
          <dependent id="1">269</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">assignment</governor>
          <dependent id="2">pages</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">hero</governor>
          <dependent id="3">Being</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">hero</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">hero</governor>
          <dependent id="5">American</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">hero</governor>
          <dependent id="6">folk</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">pages</governor>
          <dependent id="7">hero</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">assignment</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">assignment</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">assignment</governor>
          <dependent id="10">tricky</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">assignment</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">found</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Perot</governor>
          <dependent id="14">Ross</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">found</governor>
          <dependent id="15">Perot</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">assignment</governor>
          <dependent id="16">found</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">found</governor>
          <dependent id="17">out</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="269" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="269" />
          </tokens>
        </entity>
        <entity id="2" string="Ross Perot" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Ross" />
            <token id="15" string="Perot" />
          </tokens>
        </entity>
        <entity id="3" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="5" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>The problem is that the great American public likes its boot-strap entrepreneurs to be very rich and very upright.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="8" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="likes" lemma="like" stem="like" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="boot-strap" lemma="boot-strap" stem="boot-strap" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="entrepreneurs" lemma="entrepreneur" stem="entrepreneur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="rich" lemma="rich" stem="rich" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="upright" lemma="upright" stem="upright" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN problem)) (VP (VBZ is) (SBAR (IN that) (S (NP (NP (DT the) (JJ great)) (ADJP (JJ American) (JJ public))) (VP (VBZ likes) (NP (PRP$ its) (JJ boot-strap) (NNS entrepreneurs)) (S (VP (TO to) (VP (VB be) (ADJP (ADJP (RB very) (JJ rich)) (CC and) (ADJP (RB very) (JJ upright)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is that the great American public likes its boot-strap entrepreneurs to be very rich and very upright" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="great" />
            <token id="7" string="American" />
            <token id="8" string="public" />
            <token id="9" string="likes" />
            <token id="10" string="its" />
            <token id="11" string="boot-strap" />
            <token id="12" string="entrepreneurs" />
            <token id="13" string="to" />
            <token id="14" string="be" />
            <token id="15" string="very" />
            <token id="16" string="rich" />
            <token id="17" string="and" />
            <token id="18" string="very" />
            <token id="19" string="upright" />
          </tokens>
        </chunking>
        <chunking id="2" string="be very rich and very upright" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="very" />
            <token id="16" string="rich" />
            <token id="17" string="and" />
            <token id="18" string="very" />
            <token id="19" string="upright" />
          </tokens>
        </chunking>
        <chunking id="3" string="to be very rich and very upright" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="be" />
            <token id="15" string="very" />
            <token id="16" string="rich" />
            <token id="17" string="and" />
            <token id="18" string="very" />
            <token id="19" string="upright" />
          </tokens>
        </chunking>
        <chunking id="4" string="very upright" type="ADJP">
          <tokens>
            <token id="18" string="very" />
            <token id="19" string="upright" />
          </tokens>
        </chunking>
        <chunking id="5" string="its boot-strap entrepreneurs" type="NP">
          <tokens>
            <token id="10" string="its" />
            <token id="11" string="boot-strap" />
            <token id="12" string="entrepreneurs" />
          </tokens>
        </chunking>
        <chunking id="6" string="the great" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="great" />
          </tokens>
        </chunking>
        <chunking id="7" string="likes its boot-strap entrepreneurs to be very rich and very upright" type="VP">
          <tokens>
            <token id="9" string="likes" />
            <token id="10" string="its" />
            <token id="11" string="boot-strap" />
            <token id="12" string="entrepreneurs" />
            <token id="13" string="to" />
            <token id="14" string="be" />
            <token id="15" string="very" />
            <token id="16" string="rich" />
            <token id="17" string="and" />
            <token id="18" string="very" />
            <token id="19" string="upright" />
          </tokens>
        </chunking>
        <chunking id="8" string="American public" type="ADJP">
          <tokens>
            <token id="7" string="American" />
            <token id="8" string="public" />
          </tokens>
        </chunking>
        <chunking id="9" string="that the great American public likes its boot-strap entrepreneurs to be very rich and very upright" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="great" />
            <token id="7" string="American" />
            <token id="8" string="public" />
            <token id="9" string="likes" />
            <token id="10" string="its" />
            <token id="11" string="boot-strap" />
            <token id="12" string="entrepreneurs" />
            <token id="13" string="to" />
            <token id="14" string="be" />
            <token id="15" string="very" />
            <token id="16" string="rich" />
            <token id="17" string="and" />
            <token id="18" string="very" />
            <token id="19" string="upright" />
          </tokens>
        </chunking>
        <chunking id="10" string="very rich and very upright" type="ADJP">
          <tokens>
            <token id="15" string="very" />
            <token id="16" string="rich" />
            <token id="17" string="and" />
            <token id="18" string="very" />
            <token id="19" string="upright" />
          </tokens>
        </chunking>
        <chunking id="11" string="The problem" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="problem" />
          </tokens>
        </chunking>
        <chunking id="12" string="the great American public" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="great" />
            <token id="7" string="American" />
            <token id="8" string="public" />
          </tokens>
        </chunking>
        <chunking id="13" string="very rich" type="ADJP">
          <tokens>
            <token id="15" string="very" />
            <token id="16" string="rich" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">problem</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">is</governor>
          <dependent id="2">problem</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">likes</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">great</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">likes</governor>
          <dependent id="6">great</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">public</governor>
          <dependent id="7">American</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">great</governor>
          <dependent id="8">public</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">is</governor>
          <dependent id="9">likes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">entrepreneurs</governor>
          <dependent id="10">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">entrepreneurs</governor>
          <dependent id="11">boot-strap</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">likes</governor>
          <dependent id="12">entrepreneurs</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">rich</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">rich</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">rich</governor>
          <dependent id="15">very</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">likes</governor>
          <dependent id="16">rich</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">rich</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">upright</governor>
          <dependent id="18">very</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">rich</governor>
          <dependent id="19">upright</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="7" string="American" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>In a country where business practices are not overly genteel, this is a tough combination to achieve.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="country" lemma="country" stem="countri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="practices" lemma="practice" stem="practic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="overly" lemma="overly" stem="overli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="genteel" lemma="genteel" stem="genteel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="tough" lemma="tough" stem="tough" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="combination" lemma="combination" stem="combin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="achieve" lemma="achieve" stem="achiev" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT a) (NN country)) (SBAR (WHADVP (WRB where)) (S (NP (NN business) (NNS practices)) (VP (VBP are) (RB not) (ADJP (RB overly) (JJ genteel))))))) (, ,) (NP (DT this)) (VP (VBZ is) (NP (DT a) (JJ tough) (NN combination) (S (VP (TO to) (VP (VB achieve)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are not overly genteel" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="not" />
            <token id="9" string="overly" />
            <token id="10" string="genteel" />
          </tokens>
        </chunking>
        <chunking id="2" string="a tough combination to achieve" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="tough" />
            <token id="16" string="combination" />
            <token id="17" string="to" />
            <token id="18" string="achieve" />
          </tokens>
        </chunking>
        <chunking id="3" string="is a tough combination to achieve" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="tough" />
            <token id="16" string="combination" />
            <token id="17" string="to" />
            <token id="18" string="achieve" />
          </tokens>
        </chunking>
        <chunking id="4" string="a country where business practices are not overly genteel" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="country" />
            <token id="4" string="where" />
            <token id="5" string="business" />
            <token id="6" string="practices" />
            <token id="7" string="are" />
            <token id="8" string="not" />
            <token id="9" string="overly" />
            <token id="10" string="genteel" />
          </tokens>
        </chunking>
        <chunking id="5" string="achieve" type="VP">
          <tokens>
            <token id="18" string="achieve" />
          </tokens>
        </chunking>
        <chunking id="6" string="where" type="WHADVP">
          <tokens>
            <token id="4" string="where" />
          </tokens>
        </chunking>
        <chunking id="7" string="business practices" type="NP">
          <tokens>
            <token id="5" string="business" />
            <token id="6" string="practices" />
          </tokens>
        </chunking>
        <chunking id="8" string="this" type="NP">
          <tokens>
            <token id="12" string="this" />
          </tokens>
        </chunking>
        <chunking id="9" string="to achieve" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="achieve" />
          </tokens>
        </chunking>
        <chunking id="10" string="a country" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="country" />
          </tokens>
        </chunking>
        <chunking id="11" string="where business practices are not overly genteel" type="SBAR">
          <tokens>
            <token id="4" string="where" />
            <token id="5" string="business" />
            <token id="6" string="practices" />
            <token id="7" string="are" />
            <token id="8" string="not" />
            <token id="9" string="overly" />
            <token id="10" string="genteel" />
          </tokens>
        </chunking>
        <chunking id="12" string="overly genteel" type="ADJP">
          <tokens>
            <token id="9" string="overly" />
            <token id="10" string="genteel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">country</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">country</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">combination</governor>
          <dependent id="3">country</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">genteel</governor>
          <dependent id="4">where</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">practices</governor>
          <dependent id="5">business</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">genteel</governor>
          <dependent id="6">practices</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">genteel</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">genteel</governor>
          <dependent id="8">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">genteel</governor>
          <dependent id="9">overly</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">country</governor>
          <dependent id="10">genteel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">combination</governor>
          <dependent id="12">this</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">combination</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">combination</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">combination</governor>
          <dependent id="15">tough</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">combination</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">achieve</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">combination</governor>
          <dependent id="18">achieve</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="false">
      <content>A vast media circus, meanwhile, is quick to expose any flaws.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="vast" lemma="vast" stem="vast" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="media" lemma="media" stem="media" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="circus" lemma="circus" stem="circu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="quick" lemma="quick" stem="quick" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="expose" lemma="expose" stem="expos" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="flaws" lemma="flaw" stem="flaw" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (JJ vast) (NNS media) (NN circus)) (, ,) (ADVP (RB meanwhile)) (, ,) (VP (VBZ is) (ADJP (JJ quick) (S (VP (TO to) (VP (VB expose) (NP (DT any) (NNS flaws))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is quick to expose any flaws" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="quick" />
            <token id="10" string="to" />
            <token id="11" string="expose" />
            <token id="12" string="any" />
            <token id="13" string="flaws" />
          </tokens>
        </chunking>
        <chunking id="2" string="A vast media circus" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="vast" />
            <token id="3" string="media" />
            <token id="4" string="circus" />
          </tokens>
        </chunking>
        <chunking id="3" string="expose any flaws" type="VP">
          <tokens>
            <token id="11" string="expose" />
            <token id="12" string="any" />
            <token id="13" string="flaws" />
          </tokens>
        </chunking>
        <chunking id="4" string="quick to expose any flaws" type="ADJP">
          <tokens>
            <token id="9" string="quick" />
            <token id="10" string="to" />
            <token id="11" string="expose" />
            <token id="12" string="any" />
            <token id="13" string="flaws" />
          </tokens>
        </chunking>
        <chunking id="5" string="to expose any flaws" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="expose" />
            <token id="12" string="any" />
            <token id="13" string="flaws" />
          </tokens>
        </chunking>
        <chunking id="6" string="any flaws" type="NP">
          <tokens>
            <token id="12" string="any" />
            <token id="13" string="flaws" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">circus</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">circus</governor>
          <dependent id="2">vast</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">circus</governor>
          <dependent id="3">media</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">quick</governor>
          <dependent id="4">circus</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">quick</governor>
          <dependent id="6">meanwhile</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">quick</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">quick</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">expose</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">quick</governor>
          <dependent id="11">expose</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">flaws</governor>
          <dependent id="12">any</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">expose</governor>
          <dependent id="13">flaws</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Sam Walton, founder of the Wal-Mart chain of discount supermarkets who died of cancer in April, negotiated these pitfalls much better than most.</content>
      <tokens>
        <token id="1" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="founder" lemma="founder" stem="founder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Wal-Mart" lemma="Wal-Mart" stem="wal-mart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="chain" lemma="chain" stem="chain" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="discount" lemma="discount" stem="discount" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="supermarkets" lemma="supermarket" stem="supermarket" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="cancer" lemma="cancer" stem="cancer" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="negotiated" lemma="negotiate" stem="negoti" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="pitfalls" lemma="pitfall" stem="pitfal" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="better" lemma="better" stem="better" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Sam) (NNP Walton)) (, ,) (NP (NP (NN founder)) (PP (IN of) (NP (NP (DT the) (NNP Wal-Mart) (NN chain)) (PP (IN of) (NP (NN discount) (NNS supermarkets))))) (SBAR (WHNP (WP who)) (S (VP (VBD died) (PP (IN of) (NP (NN cancer))) (PP (IN in) (NP (NNP April))))))) (, ,)) (VP (VBD negotiated) (S (NP (DT these) (NNS pitfalls)) (ADJP (ADJP (RB much) (JJR better)) (PP (IN than) (ADJP (JJS most)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sam Walton , founder of the Wal-Mart chain of discount supermarkets who died of cancer in April ," type="NP">
          <tokens>
            <token id="1" string="Sam" />
            <token id="2" string="Walton" />
            <token id="3" string="," />
            <token id="4" string="founder" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="chain" />
            <token id="9" string="of" />
            <token id="10" string="discount" />
            <token id="11" string="supermarkets" />
            <token id="12" string="who" />
            <token id="13" string="died" />
            <token id="14" string="of" />
            <token id="15" string="cancer" />
            <token id="16" string="in" />
            <token id="17" string="April" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="cancer" type="NP">
          <tokens>
            <token id="15" string="cancer" />
          </tokens>
        </chunking>
        <chunking id="3" string="much better than most" type="ADJP">
          <tokens>
            <token id="22" string="much" />
            <token id="23" string="better" />
            <token id="24" string="than" />
            <token id="25" string="most" />
          </tokens>
        </chunking>
        <chunking id="4" string="founder of the Wal-Mart chain of discount supermarkets who died of cancer in April" type="NP">
          <tokens>
            <token id="4" string="founder" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="chain" />
            <token id="9" string="of" />
            <token id="10" string="discount" />
            <token id="11" string="supermarkets" />
            <token id="12" string="who" />
            <token id="13" string="died" />
            <token id="14" string="of" />
            <token id="15" string="cancer" />
            <token id="16" string="in" />
            <token id="17" string="April" />
          </tokens>
        </chunking>
        <chunking id="5" string="founder" type="NP">
          <tokens>
            <token id="4" string="founder" />
          </tokens>
        </chunking>
        <chunking id="6" string="negotiated these pitfalls much better than most" type="VP">
          <tokens>
            <token id="19" string="negotiated" />
            <token id="20" string="these" />
            <token id="21" string="pitfalls" />
            <token id="22" string="much" />
            <token id="23" string="better" />
            <token id="24" string="than" />
            <token id="25" string="most" />
          </tokens>
        </chunking>
        <chunking id="7" string="much better" type="ADJP">
          <tokens>
            <token id="22" string="much" />
            <token id="23" string="better" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Wal-Mart chain" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="chain" />
          </tokens>
        </chunking>
        <chunking id="9" string="April" type="NP">
          <tokens>
            <token id="17" string="April" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Wal-Mart chain of discount supermarkets" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="chain" />
            <token id="9" string="of" />
            <token id="10" string="discount" />
            <token id="11" string="supermarkets" />
          </tokens>
        </chunking>
        <chunking id="11" string="most" type="ADJP">
          <tokens>
            <token id="25" string="most" />
          </tokens>
        </chunking>
        <chunking id="12" string="who died of cancer in April" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="died" />
            <token id="14" string="of" />
            <token id="15" string="cancer" />
            <token id="16" string="in" />
            <token id="17" string="April" />
          </tokens>
        </chunking>
        <chunking id="13" string="died of cancer in April" type="VP">
          <tokens>
            <token id="13" string="died" />
            <token id="14" string="of" />
            <token id="15" string="cancer" />
            <token id="16" string="in" />
            <token id="17" string="April" />
          </tokens>
        </chunking>
        <chunking id="14" string="discount supermarkets" type="NP">
          <tokens>
            <token id="10" string="discount" />
            <token id="11" string="supermarkets" />
          </tokens>
        </chunking>
        <chunking id="15" string="Sam Walton" type="NP">
          <tokens>
            <token id="1" string="Sam" />
            <token id="2" string="Walton" />
          </tokens>
        </chunking>
        <chunking id="16" string="these pitfalls" type="NP">
          <tokens>
            <token id="20" string="these" />
            <token id="21" string="pitfalls" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Walton</governor>
          <dependent id="1">Sam</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">negotiated</governor>
          <dependent id="2">Walton</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Walton</governor>
          <dependent id="4">founder</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">chain</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">chain</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">chain</governor>
          <dependent id="7">Wal-Mart</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">founder</governor>
          <dependent id="8">chain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">supermarkets</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">supermarkets</governor>
          <dependent id="10">discount</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">chain</governor>
          <dependent id="11">supermarkets</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">died</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">founder</governor>
          <dependent id="13">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">cancer</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">died</governor>
          <dependent id="15">cancer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">April</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">died</governor>
          <dependent id="17">April</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">negotiated</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">pitfalls</governor>
          <dependent id="20">these</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">better</governor>
          <dependent id="21">pitfalls</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">better</governor>
          <dependent id="22">much</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="19">negotiated</governor>
          <dependent id="23">better</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">most</governor>
          <dependent id="24">than</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">better</governor>
          <dependent id="25">most</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sam Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Sam" />
            <token id="2" string="Walton" />
          </tokens>
        </entity>
        <entity id="2" string="cancer" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="15" string="cancer" />
          </tokens>
        </entity>
        <entity id="3" string="Wal-Mart" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Wal-Mart" />
          </tokens>
        </entity>
        <entity id="4" string="April" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="April" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>When, in 1985, Forbes magazine declared him America&amp;apost;s richest entrepreneur, the paparazzi descended on the obscure corner of Arkansas, mainly occupied by chicken farmers, where Walton made his home.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Forbes" lemma="Forbes" stem="forb" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="declared" lemma="declare" stem="declar" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="America" lemma="America" stem="america" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="richest" lemma="richest" stem="richest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="entrepreneur" lemma="entrepreneur" stem="entrepreneur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="paparazzi" lemma="paparazzi" stem="paparazzi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="descended" lemma="descend" stem="descend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="obscure" lemma="obscure" stem="obscur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="corner" lemma="corner" stem="corner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Arkansas" lemma="Arkansas" stem="arkansa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="mainly" lemma="mainly" stem="mainli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="occupied" lemma="occupy" stem="occupi" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="chicken" lemma="chicken" stem="chicken" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="farmers" lemma="farmer" stem="farmer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="33" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (, ,) (PP (IN in) (NP (CD 1985))) (, ,) (NP (NNP Forbes) (NN magazine)) (VP (VBD declared) (S (NP (PRP him)) (NP (NP (NNP America) (POS 's)) (JJS richest) (NN entrepreneur)))))) (, ,) (NP (DT the) (NN paparazzi)) (VP (VBD descended) (PP (IN on) (NP (NP (DT the) (JJ obscure) (NN corner)) (PP (IN of) (NP (NP (NNP Arkansas)) (, ,) (ADJP (RB mainly) (VBN occupied)))))) (PP (IN by) (NP (NN chicken) (NNS farmers))) (, ,) (SBAR (WHADVP (WRB where)) (S (NP (NNP Walton)) (VP (VBD made) (NP (PRP$ his) (NN home)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the paparazzi" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="paparazzi" />
          </tokens>
        </chunking>
        <chunking id="2" string="When , in 1985 , Forbes magazine declared him America 's richest entrepreneur" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="," />
            <token id="3" string="in" />
            <token id="4" string="1985" />
            <token id="5" string="," />
            <token id="6" string="Forbes" />
            <token id="7" string="magazine" />
            <token id="8" string="declared" />
            <token id="9" string="him" />
            <token id="10" string="America" />
            <token id="11" string="'s" />
            <token id="12" string="richest" />
            <token id="13" string="entrepreneur" />
          </tokens>
        </chunking>
        <chunking id="3" string="made his home" type="VP">
          <tokens>
            <token id="33" string="made" />
            <token id="34" string="his" />
            <token id="35" string="home" />
          </tokens>
        </chunking>
        <chunking id="4" string="America 's richest entrepreneur" type="NP">
          <tokens>
            <token id="10" string="America" />
            <token id="11" string="'s" />
            <token id="12" string="richest" />
            <token id="13" string="entrepreneur" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="9" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="descended on the obscure corner of Arkansas , mainly occupied by chicken farmers , where Walton made his home" type="VP">
          <tokens>
            <token id="17" string="descended" />
            <token id="18" string="on" />
            <token id="19" string="the" />
            <token id="20" string="obscure" />
            <token id="21" string="corner" />
            <token id="22" string="of" />
            <token id="23" string="Arkansas" />
            <token id="24" string="," />
            <token id="25" string="mainly" />
            <token id="26" string="occupied" />
            <token id="27" string="by" />
            <token id="28" string="chicken" />
            <token id="29" string="farmers" />
            <token id="30" string="," />
            <token id="31" string="where" />
            <token id="32" string="Walton" />
            <token id="33" string="made" />
            <token id="34" string="his" />
            <token id="35" string="home" />
          </tokens>
        </chunking>
        <chunking id="7" string="Arkansas" type="NP">
          <tokens>
            <token id="23" string="Arkansas" />
          </tokens>
        </chunking>
        <chunking id="8" string="America 's" type="NP">
          <tokens>
            <token id="10" string="America" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="the obscure corner" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="obscure" />
            <token id="21" string="corner" />
          </tokens>
        </chunking>
        <chunking id="10" string="Walton" type="NP">
          <tokens>
            <token id="32" string="Walton" />
          </tokens>
        </chunking>
        <chunking id="11" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="12" string="1985" type="NP">
          <tokens>
            <token id="4" string="1985" />
          </tokens>
        </chunking>
        <chunking id="13" string="declared him America 's richest entrepreneur" type="VP">
          <tokens>
            <token id="8" string="declared" />
            <token id="9" string="him" />
            <token id="10" string="America" />
            <token id="11" string="'s" />
            <token id="12" string="richest" />
            <token id="13" string="entrepreneur" />
          </tokens>
        </chunking>
        <chunking id="14" string="Forbes magazine" type="NP">
          <tokens>
            <token id="6" string="Forbes" />
            <token id="7" string="magazine" />
          </tokens>
        </chunking>
        <chunking id="15" string="his home" type="NP">
          <tokens>
            <token id="34" string="his" />
            <token id="35" string="home" />
          </tokens>
        </chunking>
        <chunking id="16" string="chicken farmers" type="NP">
          <tokens>
            <token id="28" string="chicken" />
            <token id="29" string="farmers" />
          </tokens>
        </chunking>
        <chunking id="17" string="the obscure corner of Arkansas , mainly occupied" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="obscure" />
            <token id="21" string="corner" />
            <token id="22" string="of" />
            <token id="23" string="Arkansas" />
            <token id="24" string="," />
            <token id="25" string="mainly" />
            <token id="26" string="occupied" />
          </tokens>
        </chunking>
        <chunking id="18" string="where" type="WHADVP">
          <tokens>
            <token id="31" string="where" />
          </tokens>
        </chunking>
        <chunking id="19" string="Arkansas , mainly occupied" type="NP">
          <tokens>
            <token id="23" string="Arkansas" />
            <token id="24" string="," />
            <token id="25" string="mainly" />
            <token id="26" string="occupied" />
          </tokens>
        </chunking>
        <chunking id="20" string="where Walton made his home" type="SBAR">
          <tokens>
            <token id="31" string="where" />
            <token id="32" string="Walton" />
            <token id="33" string="made" />
            <token id="34" string="his" />
            <token id="35" string="home" />
          </tokens>
        </chunking>
        <chunking id="21" string="mainly occupied" type="ADJP">
          <tokens>
            <token id="25" string="mainly" />
            <token id="26" string="occupied" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">declared</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">1985</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">declared</governor>
          <dependent id="4">1985</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">magazine</governor>
          <dependent id="6">Forbes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">declared</governor>
          <dependent id="7">magazine</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">descended</governor>
          <dependent id="8">declared</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">entrepreneur</governor>
          <dependent id="9">him</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">entrepreneur</governor>
          <dependent id="10">America</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">America</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">entrepreneur</governor>
          <dependent id="12">richest</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">declared</governor>
          <dependent id="13">entrepreneur</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">paparazzi</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">descended</governor>
          <dependent id="16">paparazzi</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">descended</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">corner</governor>
          <dependent id="18">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">corner</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">corner</governor>
          <dependent id="20">obscure</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">descended</governor>
          <dependent id="21">corner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Arkansas</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">corner</governor>
          <dependent id="23">Arkansas</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">occupied</governor>
          <dependent id="25">mainly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">Arkansas</governor>
          <dependent id="26">occupied</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">farmers</governor>
          <dependent id="27">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">farmers</governor>
          <dependent id="28">chicken</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">descended</governor>
          <dependent id="29">farmers</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">made</governor>
          <dependent id="31">where</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">made</governor>
          <dependent id="32">Walton</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">descended</governor>
          <dependent id="33">made</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">home</governor>
          <dependent id="34">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">made</governor>
          <dependent id="35">home</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Forbes" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="Forbes" />
          </tokens>
        </entity>
        <entity id="2" string="1985" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1985" />
          </tokens>
        </entity>
        <entity id="3" string="America" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="America" />
          </tokens>
        </entity>
        <entity id="4" string="Arkansas" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Arkansas" />
          </tokens>
        </entity>
        <entity id="5" string="Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="32" string="Walton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>What they found was a happily married, much-liked billionaire who enjoyed quail hunting, breakfasted at the local Holiday Inn, and drove a battered pick-up truck, minus two hub-caps.</content>
      <tokens>
        <token id="1" string="What" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="happily" lemma="happily" stem="happili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="married" lemma="marry" stem="marri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="much-liked" lemma="much-liked" stem="much-lik" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="billionaire" lemma="billionaire" stem="billionair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="enjoyed" lemma="enjoy" stem="enjoi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="quail" lemma="quail" stem="quail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="hunting" lemma="hunting" stem="hunt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="breakfasted" lemma="breakfast" stem="breakfast" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Holiday" lemma="Holiday" stem="holidai" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Inn" lemma="Inn" stem="inn" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="drove" lemma="drive" stem="drove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="battered" lemma="battered" stem="batter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="pick-up" lemma="pick-up" stem="pick-up" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="truck" lemma="truck" stem="truck" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="minus" lemma="minus" stem="minu" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="two" lemma="two" stem="two" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="32" string="hub-caps" lemma="hub-cap" stem="hub-cap" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHNP (WP What)) (S (NP (PRP they)) (VP (VBD found)))) (VP (VBD was) (NP (NP (DT a) (ADJP (ADVP (RB happily)) (VBN married))) (, ,) (NP (NP (JJ much-liked) (NN billionaire)) (SBAR (WHNP (WP who)) (S (VP (VP (VBD enjoyed) (NP (NN quail) (NN hunting))) (, ,) (VP (VBD breakfasted) (PP (IN at) (NP (DT the) (JJ local) (NNP Holiday) (NNP Inn)))) (, ,) (CC and) (VP (VBD drove) (NP (NP (DT a) (JJ battered) (JJ pick-up) (NN truck)) (, ,) (CC minus) (NP (CD two) (NNS hub-caps)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the local Holiday Inn" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="local" />
            <token id="20" string="Holiday" />
            <token id="21" string="Inn" />
          </tokens>
        </chunking>
        <chunking id="2" string="a battered pick-up truck , minus two hub-caps" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="battered" />
            <token id="27" string="pick-up" />
            <token id="28" string="truck" />
            <token id="29" string="," />
            <token id="30" string="minus" />
            <token id="31" string="two" />
            <token id="32" string="hub-caps" />
          </tokens>
        </chunking>
        <chunking id="3" string="much-liked billionaire who enjoyed quail hunting , breakfasted at the local Holiday Inn , and drove a battered pick-up truck , minus two hub-caps" type="NP">
          <tokens>
            <token id="9" string="much-liked" />
            <token id="10" string="billionaire" />
            <token id="11" string="who" />
            <token id="12" string="enjoyed" />
            <token id="13" string="quail" />
            <token id="14" string="hunting" />
            <token id="15" string="," />
            <token id="16" string="breakfasted" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="local" />
            <token id="20" string="Holiday" />
            <token id="21" string="Inn" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="drove" />
            <token id="25" string="a" />
            <token id="26" string="battered" />
            <token id="27" string="pick-up" />
            <token id="28" string="truck" />
            <token id="29" string="," />
            <token id="30" string="minus" />
            <token id="31" string="two" />
            <token id="32" string="hub-caps" />
          </tokens>
        </chunking>
        <chunking id="4" string="enjoyed quail hunting" type="VP">
          <tokens>
            <token id="12" string="enjoyed" />
            <token id="13" string="quail" />
            <token id="14" string="hunting" />
          </tokens>
        </chunking>
        <chunking id="5" string="two hub-caps" type="NP">
          <tokens>
            <token id="31" string="two" />
            <token id="32" string="hub-caps" />
          </tokens>
        </chunking>
        <chunking id="6" string="was a happily married , much-liked billionaire who enjoyed quail hunting , breakfasted at the local Holiday Inn , and drove a battered pick-up truck , minus two hub-caps" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="a" />
            <token id="6" string="happily" />
            <token id="7" string="married" />
            <token id="8" string="," />
            <token id="9" string="much-liked" />
            <token id="10" string="billionaire" />
            <token id="11" string="who" />
            <token id="12" string="enjoyed" />
            <token id="13" string="quail" />
            <token id="14" string="hunting" />
            <token id="15" string="," />
            <token id="16" string="breakfasted" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="local" />
            <token id="20" string="Holiday" />
            <token id="21" string="Inn" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="drove" />
            <token id="25" string="a" />
            <token id="26" string="battered" />
            <token id="27" string="pick-up" />
            <token id="28" string="truck" />
            <token id="29" string="," />
            <token id="30" string="minus" />
            <token id="31" string="two" />
            <token id="32" string="hub-caps" />
          </tokens>
        </chunking>
        <chunking id="7" string="drove a battered pick-up truck , minus two hub-caps" type="VP">
          <tokens>
            <token id="24" string="drove" />
            <token id="25" string="a" />
            <token id="26" string="battered" />
            <token id="27" string="pick-up" />
            <token id="28" string="truck" />
            <token id="29" string="," />
            <token id="30" string="minus" />
            <token id="31" string="two" />
            <token id="32" string="hub-caps" />
          </tokens>
        </chunking>
        <chunking id="8" string="What they found" type="SBAR">
          <tokens>
            <token id="1" string="What" />
            <token id="2" string="they" />
            <token id="3" string="found" />
          </tokens>
        </chunking>
        <chunking id="9" string="quail hunting" type="NP">
          <tokens>
            <token id="13" string="quail" />
            <token id="14" string="hunting" />
          </tokens>
        </chunking>
        <chunking id="10" string="who enjoyed quail hunting , breakfasted at the local Holiday Inn , and drove a battered pick-up truck , minus two hub-caps" type="SBAR">
          <tokens>
            <token id="11" string="who" />
            <token id="12" string="enjoyed" />
            <token id="13" string="quail" />
            <token id="14" string="hunting" />
            <token id="15" string="," />
            <token id="16" string="breakfasted" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="local" />
            <token id="20" string="Holiday" />
            <token id="21" string="Inn" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="drove" />
            <token id="25" string="a" />
            <token id="26" string="battered" />
            <token id="27" string="pick-up" />
            <token id="28" string="truck" />
            <token id="29" string="," />
            <token id="30" string="minus" />
            <token id="31" string="two" />
            <token id="32" string="hub-caps" />
          </tokens>
        </chunking>
        <chunking id="11" string="found" type="VP">
          <tokens>
            <token id="3" string="found" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="a happily married" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="happily" />
            <token id="7" string="married" />
          </tokens>
        </chunking>
        <chunking id="14" string="breakfasted at the local Holiday Inn" type="VP">
          <tokens>
            <token id="16" string="breakfasted" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="local" />
            <token id="20" string="Holiday" />
            <token id="21" string="Inn" />
          </tokens>
        </chunking>
        <chunking id="15" string="a battered pick-up truck" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="battered" />
            <token id="27" string="pick-up" />
            <token id="28" string="truck" />
          </tokens>
        </chunking>
        <chunking id="16" string="much-liked billionaire" type="NP">
          <tokens>
            <token id="9" string="much-liked" />
            <token id="10" string="billionaire" />
          </tokens>
        </chunking>
        <chunking id="17" string="happily married" type="ADJP">
          <tokens>
            <token id="6" string="happily" />
            <token id="7" string="married" />
          </tokens>
        </chunking>
        <chunking id="18" string="enjoyed quail hunting , breakfasted at the local Holiday Inn , and drove a battered pick-up truck , minus two hub-caps" type="VP">
          <tokens>
            <token id="12" string="enjoyed" />
            <token id="13" string="quail" />
            <token id="14" string="hunting" />
            <token id="15" string="," />
            <token id="16" string="breakfasted" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="local" />
            <token id="20" string="Holiday" />
            <token id="21" string="Inn" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="drove" />
            <token id="25" string="a" />
            <token id="26" string="battered" />
            <token id="27" string="pick-up" />
            <token id="28" string="truck" />
            <token id="29" string="," />
            <token id="30" string="minus" />
            <token id="31" string="two" />
            <token id="32" string="hub-caps" />
          </tokens>
        </chunking>
        <chunking id="19" string="a happily married , much-liked billionaire who enjoyed quail hunting , breakfasted at the local Holiday Inn , and drove a battered pick-up truck , minus two hub-caps" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="happily" />
            <token id="7" string="married" />
            <token id="8" string="," />
            <token id="9" string="much-liked" />
            <token id="10" string="billionaire" />
            <token id="11" string="who" />
            <token id="12" string="enjoyed" />
            <token id="13" string="quail" />
            <token id="14" string="hunting" />
            <token id="15" string="," />
            <token id="16" string="breakfasted" />
            <token id="17" string="at" />
            <token id="18" string="the" />
            <token id="19" string="local" />
            <token id="20" string="Holiday" />
            <token id="21" string="Inn" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="drove" />
            <token id="25" string="a" />
            <token id="26" string="battered" />
            <token id="27" string="pick-up" />
            <token id="28" string="truck" />
            <token id="29" string="," />
            <token id="30" string="minus" />
            <token id="31" string="two" />
            <token id="32" string="hub-caps" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dobj">
          <governor id="3">found</governor>
          <dependent id="1">What</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">found</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="7">married</governor>
          <dependent id="3">found</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">married</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">married</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">married</governor>
          <dependent id="6">happily</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">married</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">billionaire</governor>
          <dependent id="9">much-liked</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">married</governor>
          <dependent id="10">billionaire</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">enjoyed</governor>
          <dependent id="11">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">billionaire</governor>
          <dependent id="12">enjoyed</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">hunting</governor>
          <dependent id="13">quail</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">enjoyed</governor>
          <dependent id="14">hunting</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">enjoyed</governor>
          <dependent id="16">breakfasted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Inn</governor>
          <dependent id="17">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">Inn</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">Inn</governor>
          <dependent id="19">local</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Inn</governor>
          <dependent id="20">Holiday</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">breakfasted</governor>
          <dependent id="21">Inn</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">enjoyed</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">enjoyed</governor>
          <dependent id="24">drove</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">truck</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">truck</governor>
          <dependent id="26">battered</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">truck</governor>
          <dependent id="27">pick-up</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">drove</governor>
          <dependent id="28">truck</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">truck</governor>
          <dependent id="30">minus</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="32">hub-caps</governor>
          <dependent id="31">two</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">truck</governor>
          <dependent id="32">hub-caps</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="two" type="NUMBER" score="0.0">
          <tokens>
            <token id="31" string="two" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="false">
      <content>Folksy was an understatement.</content>
      <tokens>
        <token id="1" string="Folksy" lemma="folksy" stem="folksi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="understatement" lemma="understatement" stem="understat" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (JJ Folksy)) (VP (VBD was) (NP (DT an) (NN understatement))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an understatement" type="NP">
          <tokens>
            <token id="3" string="an" />
            <token id="4" string="understatement" />
          </tokens>
        </chunking>
        <chunking id="2" string="was an understatement" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="an" />
            <token id="4" string="understatement" />
          </tokens>
        </chunking>
        <chunking id="3" string="Folksy" type="NP">
          <tokens>
            <token id="1" string="Folksy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">understatement</governor>
          <dependent id="1">Folksy</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">understatement</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">understatement</governor>
          <dependent id="3">an</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">understatement</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Since then, some aspects of Wal-Mart&amp;apost;s business - its anti-union policies, the impact of its Dollars 40bn annual sales on hundreds of Mom-and-Pop shops -have been subject to critical scrutiny.</content>
      <tokens>
        <token id="1" string="Since" lemma="since" stem="sinc" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="aspects" lemma="aspect" stem="aspect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Wal-Mart" lemma="Wal-Mart" stem="wal-mart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="anti-union" lemma="anti-union" stem="anti-union" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="policies" lemma="policy" stem="polici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="impact" lemma="impact" stem="impact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Dollars" lemma="Dollars" stem="dollar" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="40bn" lemma="40bn" stem="40bn" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="annual" lemma="annual" stem="annual" pos="JJ" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="22" string="sales" lemma="sale" stem="sale" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="hundreds" lemma="hundred" stem="hundr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Mom-and-Pop" lemma="Mom-and-Pop" stem="mom-and-pop" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="shops" lemma="shop" stem="shop" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="subject" lemma="subject" stem="subject" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="critical" lemma="critical" stem="critic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="scrutiny" lemma="scrutiny" stem="scrutini" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Since) (NP (RB then))) (, ,) (NP (NP (NP (DT some) (NNS aspects)) (PP (IN of) (NP (NP (NNP Wal-Mart) (POS 's)) (NN business)))) (: -) (NP (PRP$ its) (JJ anti-union) (NNS policies)) (, ,) (NP (NP (DT the) (NN impact)) (PP (IN of) (NP (PRP$ its) (NP (NP (NNP Dollars) (JJ 40bn) (JJ annual) (NNS sales)) (PP (IN on) (NP (NP (NNS hundreds)) (PP (IN of) (NP (NNP Mom-and-Pop) (NNS shops))))))))) (: -)) (VP (VBP have) (VP (VBN been) (ADJP (JJ subject) (PP (TO to) (NP (JJ critical) (NN scrutiny)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="some aspects of Wal-Mart 's business - its anti-union policies , the impact of its Dollars 40bn annual sales on hundreds of Mom-and-Pop shops -" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="aspects" />
            <token id="6" string="of" />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="'s" />
            <token id="9" string="business" />
            <token id="10" string="-" />
            <token id="11" string="its" />
            <token id="12" string="anti-union" />
            <token id="13" string="policies" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="impact" />
            <token id="17" string="of" />
            <token id="18" string="its" />
            <token id="19" string="Dollars" />
            <token id="20" string="40bn" />
            <token id="21" string="annual" />
            <token id="22" string="sales" />
            <token id="23" string="on" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="Mom-and-Pop" />
            <token id="27" string="shops" />
            <token id="28" string="-" />
          </tokens>
        </chunking>
        <chunking id="2" string="the impact of its Dollars 40bn annual sales on hundreds of Mom-and-Pop shops" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="impact" />
            <token id="17" string="of" />
            <token id="18" string="its" />
            <token id="19" string="Dollars" />
            <token id="20" string="40bn" />
            <token id="21" string="annual" />
            <token id="22" string="sales" />
            <token id="23" string="on" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="Mom-and-Pop" />
            <token id="27" string="shops" />
          </tokens>
        </chunking>
        <chunking id="3" string="its Dollars 40bn annual sales on hundreds of Mom-and-Pop shops" type="NP">
          <tokens>
            <token id="18" string="its" />
            <token id="19" string="Dollars" />
            <token id="20" string="40bn" />
            <token id="21" string="annual" />
            <token id="22" string="sales" />
            <token id="23" string="on" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="Mom-and-Pop" />
            <token id="27" string="shops" />
          </tokens>
        </chunking>
        <chunking id="4" string="the impact" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="impact" />
          </tokens>
        </chunking>
        <chunking id="5" string="Dollars 40bn annual sales on hundreds of Mom-and-Pop shops" type="NP">
          <tokens>
            <token id="19" string="Dollars" />
            <token id="20" string="40bn" />
            <token id="21" string="annual" />
            <token id="22" string="sales" />
            <token id="23" string="on" />
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="Mom-and-Pop" />
            <token id="27" string="shops" />
          </tokens>
        </chunking>
        <chunking id="6" string="then" type="NP">
          <tokens>
            <token id="2" string="then" />
          </tokens>
        </chunking>
        <chunking id="7" string="Wal-Mart 's" type="NP">
          <tokens>
            <token id="7" string="Wal-Mart" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="Wal-Mart 's business" type="NP">
          <tokens>
            <token id="7" string="Wal-Mart" />
            <token id="8" string="'s" />
            <token id="9" string="business" />
          </tokens>
        </chunking>
        <chunking id="9" string="hundreds of Mom-and-Pop shops" type="NP">
          <tokens>
            <token id="24" string="hundreds" />
            <token id="25" string="of" />
            <token id="26" string="Mom-and-Pop" />
            <token id="27" string="shops" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mom-and-Pop shops" type="NP">
          <tokens>
            <token id="26" string="Mom-and-Pop" />
            <token id="27" string="shops" />
          </tokens>
        </chunking>
        <chunking id="11" string="its anti-union policies" type="NP">
          <tokens>
            <token id="11" string="its" />
            <token id="12" string="anti-union" />
            <token id="13" string="policies" />
          </tokens>
        </chunking>
        <chunking id="12" string="been subject to critical scrutiny" type="VP">
          <tokens>
            <token id="30" string="been" />
            <token id="31" string="subject" />
            <token id="32" string="to" />
            <token id="33" string="critical" />
            <token id="34" string="scrutiny" />
          </tokens>
        </chunking>
        <chunking id="13" string="critical scrutiny" type="NP">
          <tokens>
            <token id="33" string="critical" />
            <token id="34" string="scrutiny" />
          </tokens>
        </chunking>
        <chunking id="14" string="have been subject to critical scrutiny" type="VP">
          <tokens>
            <token id="29" string="have" />
            <token id="30" string="been" />
            <token id="31" string="subject" />
            <token id="32" string="to" />
            <token id="33" string="critical" />
            <token id="34" string="scrutiny" />
          </tokens>
        </chunking>
        <chunking id="15" string="some aspects of Wal-Mart 's business" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="aspects" />
            <token id="6" string="of" />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="'s" />
            <token id="9" string="business" />
          </tokens>
        </chunking>
        <chunking id="16" string="some aspects" type="NP">
          <tokens>
            <token id="4" string="some" />
            <token id="5" string="aspects" />
          </tokens>
        </chunking>
        <chunking id="17" string="hundreds" type="NP">
          <tokens>
            <token id="24" string="hundreds" />
          </tokens>
        </chunking>
        <chunking id="18" string="subject to critical scrutiny" type="ADJP">
          <tokens>
            <token id="31" string="subject" />
            <token id="32" string="to" />
            <token id="33" string="critical" />
            <token id="34" string="scrutiny" />
          </tokens>
        </chunking>
        <chunking id="19" string="Dollars 40bn annual sales" type="NP">
          <tokens>
            <token id="19" string="Dollars" />
            <token id="20" string="40bn" />
            <token id="21" string="annual" />
            <token id="22" string="sales" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">then</governor>
          <dependent id="1">Since</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">subject</governor>
          <dependent id="2">then</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">aspects</governor>
          <dependent id="4">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">subject</governor>
          <dependent id="5">aspects</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">business</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">business</governor>
          <dependent id="7">Wal-Mart</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Wal-Mart</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">aspects</governor>
          <dependent id="9">business</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">policies</governor>
          <dependent id="11">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">policies</governor>
          <dependent id="12">anti-union</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">aspects</governor>
          <dependent id="13">policies</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">impact</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">aspects</governor>
          <dependent id="16">impact</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">sales</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">sales</governor>
          <dependent id="18">its</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">sales</governor>
          <dependent id="19">Dollars</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">sales</governor>
          <dependent id="20">40bn</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">sales</governor>
          <dependent id="21">annual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">impact</governor>
          <dependent id="22">sales</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">hundreds</governor>
          <dependent id="23">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">sales</governor>
          <dependent id="24">hundreds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">shops</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">shops</governor>
          <dependent id="26">Mom-and-Pop</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">hundreds</governor>
          <dependent id="27">shops</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">subject</governor>
          <dependent id="29">have</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="31">subject</governor>
          <dependent id="30">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">subject</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">scrutiny</governor>
          <dependent id="32">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">scrutiny</governor>
          <dependent id="33">critical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">subject</governor>
          <dependent id="34">scrutiny</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="annual" type="SET" score="0.0">
          <tokens>
            <token id="21" string="annual" />
          </tokens>
        </entity>
        <entity id="2" string="Wal-Mart" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Wal-Mart" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>So, to an extent, have the less wholesome adventures of the four Walton children.</content>
      <tokens>
        <token id="1" string="So" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="extent" lemma="extent" stem="extent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="less" lemma="less" stem="less" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="wholesome" lemma="wholesome" stem="wholesom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="adventures" lemma="adventure" stem="adventur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="15" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB So)) (, ,) (PP (TO to) (NP (DT an) (NN extent))) (, ,) (VP (VBP have) (NP (NP (DT the) (ADJP (JJR less) (JJ wholesome)) (NNS adventures)) (PP (IN of) (NP (DT the) (CD four) (NNP Walton) (NNS children))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the four Walton children" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="four" />
            <token id="15" string="Walton" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="2" string="the less wholesome adventures of the four Walton children" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="less" />
            <token id="10" string="wholesome" />
            <token id="11" string="adventures" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="four" />
            <token id="15" string="Walton" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="the less wholesome adventures" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="less" />
            <token id="10" string="wholesome" />
            <token id="11" string="adventures" />
          </tokens>
        </chunking>
        <chunking id="4" string="less wholesome" type="ADJP">
          <tokens>
            <token id="9" string="less" />
            <token id="10" string="wholesome" />
          </tokens>
        </chunking>
        <chunking id="5" string="an extent" type="NP">
          <tokens>
            <token id="4" string="an" />
            <token id="5" string="extent" />
          </tokens>
        </chunking>
        <chunking id="6" string="have the less wholesome adventures of the four Walton children" type="VP">
          <tokens>
            <token id="7" string="have" />
            <token id="8" string="the" />
            <token id="9" string="less" />
            <token id="10" string="wholesome" />
            <token id="11" string="adventures" />
            <token id="12" string="of" />
            <token id="13" string="the" />
            <token id="14" string="four" />
            <token id="15" string="Walton" />
            <token id="16" string="children" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="7">have</governor>
          <dependent id="1">So</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">extent</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">extent</governor>
          <dependent id="4">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">have</governor>
          <dependent id="5">extent</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">adventures</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">wholesome</governor>
          <dependent id="9">less</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">adventures</governor>
          <dependent id="10">wholesome</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">have</governor>
          <dependent id="11">adventures</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">children</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">children</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">children</governor>
          <dependent id="14">four</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">children</governor>
          <dependent id="15">Walton</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">adventures</governor>
          <dependent id="16">children</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="four" type="NUMBER" score="0.0">
          <tokens>
            <token id="14" string="four" />
          </tokens>
        </entity>
        <entity id="2" string="Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Walton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>But no one has ever been able to make Sam himself look bad.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="able" lemma="able" stem="abl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="look" lemma="look" stem="look" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT no) (NN one)) (VP (VBZ has) (ADVP (RB ever)) (VP (VBN been) (ADJP (JJ able) (S (VP (TO to) (VP (VB make) (NP (NP (NNP Sam)) (SBAR (S (NP (PRP himself)) (VP (VBP look) (ADJP (JJ bad)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to make Sam himself look bad" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="make" />
            <token id="10" string="Sam" />
            <token id="11" string="himself" />
            <token id="12" string="look" />
            <token id="13" string="bad" />
          </tokens>
        </chunking>
        <chunking id="2" string="Sam himself look bad" type="NP">
          <tokens>
            <token id="10" string="Sam" />
            <token id="11" string="himself" />
            <token id="12" string="look" />
            <token id="13" string="bad" />
          </tokens>
        </chunking>
        <chunking id="3" string="look bad" type="VP">
          <tokens>
            <token id="12" string="look" />
            <token id="13" string="bad" />
          </tokens>
        </chunking>
        <chunking id="4" string="has ever been able to make Sam himself look bad" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="ever" />
            <token id="6" string="been" />
            <token id="7" string="able" />
            <token id="8" string="to" />
            <token id="9" string="make" />
            <token id="10" string="Sam" />
            <token id="11" string="himself" />
            <token id="12" string="look" />
            <token id="13" string="bad" />
          </tokens>
        </chunking>
        <chunking id="5" string="himself look bad" type="SBAR">
          <tokens>
            <token id="11" string="himself" />
            <token id="12" string="look" />
            <token id="13" string="bad" />
          </tokens>
        </chunking>
        <chunking id="6" string="bad" type="ADJP">
          <tokens>
            <token id="13" string="bad" />
          </tokens>
        </chunking>
        <chunking id="7" string="no one" type="NP">
          <tokens>
            <token id="2" string="no" />
            <token id="3" string="one" />
          </tokens>
        </chunking>
        <chunking id="8" string="able to make Sam himself look bad" type="ADJP">
          <tokens>
            <token id="7" string="able" />
            <token id="8" string="to" />
            <token id="9" string="make" />
            <token id="10" string="Sam" />
            <token id="11" string="himself" />
            <token id="12" string="look" />
            <token id="13" string="bad" />
          </tokens>
        </chunking>
        <chunking id="9" string="make Sam himself look bad" type="VP">
          <tokens>
            <token id="9" string="make" />
            <token id="10" string="Sam" />
            <token id="11" string="himself" />
            <token id="12" string="look" />
            <token id="13" string="bad" />
          </tokens>
        </chunking>
        <chunking id="10" string="himself" type="NP">
          <tokens>
            <token id="11" string="himself" />
          </tokens>
        </chunking>
        <chunking id="11" string="been able to make Sam himself look bad" type="VP">
          <tokens>
            <token id="6" string="been" />
            <token id="7" string="able" />
            <token id="8" string="to" />
            <token id="9" string="make" />
            <token id="10" string="Sam" />
            <token id="11" string="himself" />
            <token id="12" string="look" />
            <token id="13" string="bad" />
          </tokens>
        </chunking>
        <chunking id="12" string="Sam" type="NP">
          <tokens>
            <token id="10" string="Sam" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="7">able</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">one</governor>
          <dependent id="2">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">able</governor>
          <dependent id="3">one</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">able</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">able</governor>
          <dependent id="5">ever</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">able</governor>
          <dependent id="6">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">able</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">make</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">able</governor>
          <dependent id="9">make</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">make</governor>
          <dependent id="10">Sam</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">look</governor>
          <dependent id="11">himself</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">Sam</governor>
          <dependent id="12">look</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">look</governor>
          <dependent id="13">bad</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Sam" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Sam" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>The worst that has been said is that he was rather dull.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="worst" lemma="worst" stem="worst" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="dull" lemma="dull" stem="dull" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJS worst)) (SBAR (WHNP (WDT that)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN said))))))) (VP (VBZ is) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD was) (ADJP (RB rather) (JJ dull)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="been said" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="said" />
          </tokens>
        </chunking>
        <chunking id="2" string="The worst that has been said" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="worst" />
            <token id="3" string="that" />
            <token id="4" string="has" />
            <token id="5" string="been" />
            <token id="6" string="said" />
          </tokens>
        </chunking>
        <chunking id="3" string="that has been said" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="has" />
            <token id="5" string="been" />
            <token id="6" string="said" />
          </tokens>
        </chunking>
        <chunking id="4" string="is that he was rather dull" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="that" />
            <token id="9" string="he" />
            <token id="10" string="was" />
            <token id="11" string="rather" />
            <token id="12" string="dull" />
          </tokens>
        </chunking>
        <chunking id="5" string="has been said" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="been" />
            <token id="6" string="said" />
          </tokens>
        </chunking>
        <chunking id="6" string="that he was rather dull" type="SBAR">
          <tokens>
            <token id="8" string="that" />
            <token id="9" string="he" />
            <token id="10" string="was" />
            <token id="11" string="rather" />
            <token id="12" string="dull" />
          </tokens>
        </chunking>
        <chunking id="7" string="rather dull" type="ADJP">
          <tokens>
            <token id="11" string="rather" />
            <token id="12" string="dull" />
          </tokens>
        </chunking>
        <chunking id="8" string="was rather dull" type="VP">
          <tokens>
            <token id="10" string="was" />
            <token id="11" string="rather" />
            <token id="12" string="dull" />
          </tokens>
        </chunking>
        <chunking id="9" string="The worst" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="worst" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="9" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="6" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">worst</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">is</governor>
          <dependent id="2">worst</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">said</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">said</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">said</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="2">worst</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">dull</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">dull</governor>
          <dependent id="9">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">dull</governor>
          <dependent id="10">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">dull</governor>
          <dependent id="11">rather</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">is</governor>
          <dependent id="12">dull</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Walton is not about to dash anyone&amp;apost;s illusions.</content>
      <tokens>
        <token id="1" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="dash" lemma="dash" stem="dash" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="anyone" lemma="anyone" stem="anyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="illusions" lemma="illusion" stem="illus" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Walton)) (VP (VBZ is) (RB not) (ADJP (RB about) (S (VP (TO to) (VP (VB dash) (NP (NP (NN anyone) (POS 's)) (NNS illusions))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="about to dash anyone 's illusions" type="ADJP">
          <tokens>
            <token id="4" string="about" />
            <token id="5" string="to" />
            <token id="6" string="dash" />
            <token id="7" string="anyone" />
            <token id="8" string="'s" />
            <token id="9" string="illusions" />
          </tokens>
        </chunking>
        <chunking id="2" string="is not about to dash anyone 's illusions" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="not" />
            <token id="4" string="about" />
            <token id="5" string="to" />
            <token id="6" string="dash" />
            <token id="7" string="anyone" />
            <token id="8" string="'s" />
            <token id="9" string="illusions" />
          </tokens>
        </chunking>
        <chunking id="3" string="dash anyone 's illusions" type="VP">
          <tokens>
            <token id="6" string="dash" />
            <token id="7" string="anyone" />
            <token id="8" string="'s" />
            <token id="9" string="illusions" />
          </tokens>
        </chunking>
        <chunking id="4" string="anyone 's" type="NP">
          <tokens>
            <token id="7" string="anyone" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="anyone 's illusions" type="NP">
          <tokens>
            <token id="7" string="anyone" />
            <token id="8" string="'s" />
            <token id="9" string="illusions" />
          </tokens>
        </chunking>
        <chunking id="6" string="to dash anyone 's illusions" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="dash" />
            <token id="7" string="anyone" />
            <token id="8" string="'s" />
            <token id="9" string="illusions" />
          </tokens>
        </chunking>
        <chunking id="7" string="Walton" type="NP">
          <tokens>
            <token id="1" string="Walton" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">about</governor>
          <dependent id="1">Walton</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">about</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">about</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">about</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">dash</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">about</governor>
          <dependent id="6">dash</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">illusions</governor>
          <dependent id="7">anyone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">anyone</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">dash</governor>
          <dependent id="9">illusions</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Walton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Readers will either find his autobiography lashed with &amp;apost;good ol&amp;apost;&amp;apost; common-sense and a lot of harmless, if charming, anecdotes.</content>
      <tokens>
        <token id="1" string="Readers" lemma="reader" stem="reader" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="either" lemma="either" stem="either" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="autobiography" lemma="autobiography" stem="autobiographi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="lashed" lemma="lash" stem="lash" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="ol'" lemma="ol'" stem="ol'" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="common-sense" lemma="common-sense" stem="common-sens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="harmless" lemma="harmless" stem="harmless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="charming" lemma="charming" stem="charm" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="anecdotes" lemma="anecdote" stem="anecdot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NNS Readers)) (VP (MD will) (ADVP (CC either)) (VP (VB find) (NP (PRP$ his) (NN autobiography))))) (VP (VBD lashed) (PP (IN with) (`` `) (NP (JJ good) (NN ol')) ('' '))) (NP (NP (JJ common-sense) (CC and) (DT a) (NN lot)) (PP (IN of) (NP (ADJP (JJ harmless) (, ,) (IN if) (JJ charming) (, ,)) (NNS anecdotes)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="common-sense and a lot of harmless , if charming , anecdotes" type="NP">
          <tokens>
            <token id="13" string="common-sense" />
            <token id="14" string="and" />
            <token id="15" string="a" />
            <token id="16" string="lot" />
            <token id="17" string="of" />
            <token id="18" string="harmless" />
            <token id="19" string="," />
            <token id="20" string="if" />
            <token id="21" string="charming" />
            <token id="22" string="," />
            <token id="23" string="anecdotes" />
          </tokens>
        </chunking>
        <chunking id="2" string="common-sense and a lot" type="NP">
          <tokens>
            <token id="13" string="common-sense" />
            <token id="14" string="and" />
            <token id="15" string="a" />
            <token id="16" string="lot" />
          </tokens>
        </chunking>
        <chunking id="3" string="Readers" type="NP">
          <tokens>
            <token id="1" string="Readers" />
          </tokens>
        </chunking>
        <chunking id="4" string="lashed with ` good ol' '" type="VP">
          <tokens>
            <token id="7" string="lashed" />
            <token id="8" string="with" />
            <token id="9" string="'" />
            <token id="10" string="good" />
            <token id="11" string="ol'" />
            <token id="12" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="harmless , if charming , anecdotes" type="NP">
          <tokens>
            <token id="18" string="harmless" />
            <token id="19" string="," />
            <token id="20" string="if" />
            <token id="21" string="charming" />
            <token id="22" string="," />
            <token id="23" string="anecdotes" />
          </tokens>
        </chunking>
        <chunking id="6" string="will either find his autobiography" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="either" />
            <token id="4" string="find" />
            <token id="5" string="his" />
            <token id="6" string="autobiography" />
          </tokens>
        </chunking>
        <chunking id="7" string="his autobiography" type="NP">
          <tokens>
            <token id="5" string="his" />
            <token id="6" string="autobiography" />
          </tokens>
        </chunking>
        <chunking id="8" string="harmless , if charming ," type="ADJP">
          <tokens>
            <token id="18" string="harmless" />
            <token id="19" string="," />
            <token id="20" string="if" />
            <token id="21" string="charming" />
            <token id="22" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="good ol'" type="NP">
          <tokens>
            <token id="10" string="good" />
            <token id="11" string="ol'" />
          </tokens>
        </chunking>
        <chunking id="10" string="find his autobiography" type="VP">
          <tokens>
            <token id="4" string="find" />
            <token id="5" string="his" />
            <token id="6" string="autobiography" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">find</governor>
          <dependent id="1">Readers</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">find</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">find</governor>
          <dependent id="3">either</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">lashed</governor>
          <dependent id="4">find</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">autobiography</governor>
          <dependent id="5">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">find</governor>
          <dependent id="6">autobiography</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">lashed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">ol'</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">ol'</governor>
          <dependent id="10">good</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">lashed</governor>
          <dependent id="11">ol'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">lot</governor>
          <dependent id="13">common-sense</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">common-sense</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">common-sense</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">lashed</governor>
          <dependent id="16">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">anecdotes</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">charming</governor>
          <dependent id="18">harmless</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">charming</governor>
          <dependent id="20">if</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">anecdotes</governor>
          <dependent id="21">charming</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">lot</governor>
          <dependent id="23">anecdotes</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Or they will find it dreary and downbeat.</content>
      <tokens>
        <token id="1" string="Or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="find" lemma="find" stem="find" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="dreary" lemma="dreary" stem="dreari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="downbeat" lemma="downbeat" stem="downbeat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC Or) (NP (PRP they)) (VP (MD will) (VP (VB find) (S (NP (PRP it)) (ADJP (JJ dreary) (CC and) (JJ downbeat))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="2" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="find it dreary and downbeat" type="VP">
          <tokens>
            <token id="4" string="find" />
            <token id="5" string="it" />
            <token id="6" string="dreary" />
            <token id="7" string="and" />
            <token id="8" string="downbeat" />
          </tokens>
        </chunking>
        <chunking id="3" string="will find it dreary and downbeat" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="find" />
            <token id="5" string="it" />
            <token id="6" string="dreary" />
            <token id="7" string="and" />
            <token id="8" string="downbeat" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="dreary and downbeat" type="ADJP">
          <tokens>
            <token id="6" string="dreary" />
            <token id="7" string="and" />
            <token id="8" string="downbeat" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">find</governor>
          <dependent id="1">Or</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">find</governor>
          <dependent id="2">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">find</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">find</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">dreary</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">find</governor>
          <dependent id="6">dreary</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">dreary</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">dreary</governor>
          <dependent id="8">downbeat</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Walton makes no excuses: &amp;apost;I realise this may sound boring to most you,&amp;apost; he writes at one stage, &amp;apost;but one of my best items ever was a mattress pad called a Bedmate . . . .&amp;apost; A few snippets are more revealing about the character.</content>
      <tokens>
        <token id="1" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="excuses" lemma="excuse" stem="excus" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="realise" lemma="realise" stem="realis" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="sound" lemma="sound" stem="sound" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="boring" lemma="boring" stem="bore" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="writes" lemma="write" stem="write" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="stage" lemma="stage" stem="stage" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="items" lemma="item" stem="item" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="mattress" lemma="mattress" stem="mattress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="pad" lemma="pad" stem="pad" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Bedmate" lemma="Bedmate" stem="bedmat" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string=". . . ." lemma="..." stem=". . . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="snippets" lemma="snippet" stem="snippet" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="revealing" lemma="revealing" stem="reveal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="character" lemma="character" stem="charact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Walton)) (VP (VBZ makes) (NP (DT no) (NNS excuses)))) (: :) ('' ') (S (NP (PRP I)) (VP (VBP realise) (SBAR (S (NP (DT this)) (VP (MD may) (VP (VB sound) (ADJP (JJ boring) (PP (TO to) (NP (NP (JJS most)) (SBAR (S (NP (PRP you)) (PRN (, ,) ('' ') (S (NP (PRP he)) (VP (VBZ writes) (PP (IN at) (NP (NP (CD one) (NN stage)) (, ,) (`` `) (S (NP (NP (QP (CC but) (CD one))) (PP (IN of) (NP (PRP$ my) (JJS best) (NNS items))) (ADVP (RB ever))) (VP (VBD was) (NP (NP (DT a) (NN mattress) (NN pad)) (SBAR (S (VP (VBD called) (NP (DT a) (NNP Bedmate)))))))) (: ...) ('' ')))))) (NP (DT A) (JJ few) (NNS snippets)) (VP (VBP are) (ADJP (RBR more) (JJ revealing) (PP (IN about) (NP (DT the) (NN character)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sound boring to most you , ' he writes at one stage , ` but one of my best items ever was a mattress pad called a Bedmate ... ' A few snippets are more revealing about the character" type="VP">
          <tokens>
            <token id="11" string="sound" />
            <token id="12" string="boring" />
            <token id="13" string="to" />
            <token id="14" string="most" />
            <token id="15" string="you" />
            <token id="16" string="," />
            <token id="17" string="'" />
            <token id="18" string="he" />
            <token id="19" string="writes" />
            <token id="20" string="at" />
            <token id="21" string="one" />
            <token id="22" string="stage" />
            <token id="23" string="," />
            <token id="24" string="'" />
            <token id="25" string="but" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
            <token id="31" string="ever" />
            <token id="32" string="was" />
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
            <token id="39" string=". . . ." />
            <token id="40" string="'" />
            <token id="41" string="A" />
            <token id="42" string="few" />
            <token id="43" string="snippets" />
            <token id="44" string="are" />
            <token id="45" string="more" />
            <token id="46" string="revealing" />
            <token id="47" string="about" />
            <token id="48" string="the" />
            <token id="49" string="character" />
          </tokens>
        </chunking>
        <chunking id="2" string="this may sound boring to most you , ' he writes at one stage , ` but one of my best items ever was a mattress pad called a Bedmate ... ' A few snippets are more revealing about the character" type="SBAR">
          <tokens>
            <token id="9" string="this" />
            <token id="10" string="may" />
            <token id="11" string="sound" />
            <token id="12" string="boring" />
            <token id="13" string="to" />
            <token id="14" string="most" />
            <token id="15" string="you" />
            <token id="16" string="," />
            <token id="17" string="'" />
            <token id="18" string="he" />
            <token id="19" string="writes" />
            <token id="20" string="at" />
            <token id="21" string="one" />
            <token id="22" string="stage" />
            <token id="23" string="," />
            <token id="24" string="'" />
            <token id="25" string="but" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
            <token id="31" string="ever" />
            <token id="32" string="was" />
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
            <token id="39" string=". . . ." />
            <token id="40" string="'" />
            <token id="41" string="A" />
            <token id="42" string="few" />
            <token id="43" string="snippets" />
            <token id="44" string="are" />
            <token id="45" string="more" />
            <token id="46" string="revealing" />
            <token id="47" string="about" />
            <token id="48" string="the" />
            <token id="49" string="character" />
          </tokens>
        </chunking>
        <chunking id="3" string="this" type="NP">
          <tokens>
            <token id="9" string="this" />
          </tokens>
        </chunking>
        <chunking id="4" string="one stage" type="NP">
          <tokens>
            <token id="21" string="one" />
            <token id="22" string="stage" />
          </tokens>
        </chunking>
        <chunking id="5" string="realise this may sound boring to most you , ' he writes at one stage , ` but one of my best items ever was a mattress pad called a Bedmate ... ' A few snippets are more revealing about the character" type="VP">
          <tokens>
            <token id="8" string="realise" />
            <token id="9" string="this" />
            <token id="10" string="may" />
            <token id="11" string="sound" />
            <token id="12" string="boring" />
            <token id="13" string="to" />
            <token id="14" string="most" />
            <token id="15" string="you" />
            <token id="16" string="," />
            <token id="17" string="'" />
            <token id="18" string="he" />
            <token id="19" string="writes" />
            <token id="20" string="at" />
            <token id="21" string="one" />
            <token id="22" string="stage" />
            <token id="23" string="," />
            <token id="24" string="'" />
            <token id="25" string="but" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
            <token id="31" string="ever" />
            <token id="32" string="was" />
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
            <token id="39" string=". . . ." />
            <token id="40" string="'" />
            <token id="41" string="A" />
            <token id="42" string="few" />
            <token id="43" string="snippets" />
            <token id="44" string="are" />
            <token id="45" string="more" />
            <token id="46" string="revealing" />
            <token id="47" string="about" />
            <token id="48" string="the" />
            <token id="49" string="character" />
          </tokens>
        </chunking>
        <chunking id="6" string="you , ' he writes at one stage , ` but one of my best items ever was a mattress pad called a Bedmate ... ' A few snippets are more revealing about the character" type="SBAR">
          <tokens>
            <token id="15" string="you" />
            <token id="16" string="," />
            <token id="17" string="'" />
            <token id="18" string="he" />
            <token id="19" string="writes" />
            <token id="20" string="at" />
            <token id="21" string="one" />
            <token id="22" string="stage" />
            <token id="23" string="," />
            <token id="24" string="'" />
            <token id="25" string="but" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
            <token id="31" string="ever" />
            <token id="32" string="was" />
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
            <token id="39" string=". . . ." />
            <token id="40" string="'" />
            <token id="41" string="A" />
            <token id="42" string="few" />
            <token id="43" string="snippets" />
            <token id="44" string="are" />
            <token id="45" string="more" />
            <token id="46" string="revealing" />
            <token id="47" string="about" />
            <token id="48" string="the" />
            <token id="49" string="character" />
          </tokens>
        </chunking>
        <chunking id="7" string="Walton" type="NP">
          <tokens>
            <token id="1" string="Walton" />
          </tokens>
        </chunking>
        <chunking id="8" string="my best items" type="NP">
          <tokens>
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
          </tokens>
        </chunking>
        <chunking id="9" string="most" type="NP">
          <tokens>
            <token id="14" string="most" />
          </tokens>
        </chunking>
        <chunking id="10" string="boring to most you , ' he writes at one stage , ` but one of my best items ever was a mattress pad called a Bedmate ... ' A few snippets are more revealing about the character" type="ADJP">
          <tokens>
            <token id="12" string="boring" />
            <token id="13" string="to" />
            <token id="14" string="most" />
            <token id="15" string="you" />
            <token id="16" string="," />
            <token id="17" string="'" />
            <token id="18" string="he" />
            <token id="19" string="writes" />
            <token id="20" string="at" />
            <token id="21" string="one" />
            <token id="22" string="stage" />
            <token id="23" string="," />
            <token id="24" string="'" />
            <token id="25" string="but" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
            <token id="31" string="ever" />
            <token id="32" string="was" />
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
            <token id="39" string=". . . ." />
            <token id="40" string="'" />
            <token id="41" string="A" />
            <token id="42" string="few" />
            <token id="43" string="snippets" />
            <token id="44" string="are" />
            <token id="45" string="more" />
            <token id="46" string="revealing" />
            <token id="47" string="about" />
            <token id="48" string="the" />
            <token id="49" string="character" />
          </tokens>
        </chunking>
        <chunking id="11" string="are more revealing about the character" type="VP">
          <tokens>
            <token id="44" string="are" />
            <token id="45" string="more" />
            <token id="46" string="revealing" />
            <token id="47" string="about" />
            <token id="48" string="the" />
            <token id="49" string="character" />
          </tokens>
        </chunking>
        <chunking id="12" string="called a Bedmate" type="SBAR">
          <tokens>
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
          </tokens>
        </chunking>
        <chunking id="13" string="A few snippets" type="NP">
          <tokens>
            <token id="41" string="A" />
            <token id="42" string="few" />
            <token id="43" string="snippets" />
          </tokens>
        </chunking>
        <chunking id="14" string="but one" type="NP">
          <tokens>
            <token id="25" string="but" />
            <token id="26" string="one" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="18" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="a mattress pad" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
          </tokens>
        </chunking>
        <chunking id="17" string="one stage , ` but one of my best items ever was a mattress pad called a Bedmate ... '" type="NP">
          <tokens>
            <token id="21" string="one" />
            <token id="22" string="stage" />
            <token id="23" string="," />
            <token id="24" string="'" />
            <token id="25" string="but" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
            <token id="31" string="ever" />
            <token id="32" string="was" />
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
            <token id="39" string=". . . ." />
            <token id="40" string="'" />
          </tokens>
        </chunking>
        <chunking id="18" string="more revealing about the character" type="ADJP">
          <tokens>
            <token id="45" string="more" />
            <token id="46" string="revealing" />
            <token id="47" string="about" />
            <token id="48" string="the" />
            <token id="49" string="character" />
          </tokens>
        </chunking>
        <chunking id="19" string="I" type="NP">
          <tokens>
            <token id="7" string="I" />
          </tokens>
        </chunking>
        <chunking id="20" string="was a mattress pad called a Bedmate" type="VP">
          <tokens>
            <token id="32" string="was" />
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
          </tokens>
        </chunking>
        <chunking id="21" string="may sound boring to most you , ' he writes at one stage , ` but one of my best items ever was a mattress pad called a Bedmate ... ' A few snippets are more revealing about the character" type="VP">
          <tokens>
            <token id="10" string="may" />
            <token id="11" string="sound" />
            <token id="12" string="boring" />
            <token id="13" string="to" />
            <token id="14" string="most" />
            <token id="15" string="you" />
            <token id="16" string="," />
            <token id="17" string="'" />
            <token id="18" string="he" />
            <token id="19" string="writes" />
            <token id="20" string="at" />
            <token id="21" string="one" />
            <token id="22" string="stage" />
            <token id="23" string="," />
            <token id="24" string="'" />
            <token id="25" string="but" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
            <token id="31" string="ever" />
            <token id="32" string="was" />
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
            <token id="39" string=". . . ." />
            <token id="40" string="'" />
            <token id="41" string="A" />
            <token id="42" string="few" />
            <token id="43" string="snippets" />
            <token id="44" string="are" />
            <token id="45" string="more" />
            <token id="46" string="revealing" />
            <token id="47" string="about" />
            <token id="48" string="the" />
            <token id="49" string="character" />
          </tokens>
        </chunking>
        <chunking id="22" string="writes at one stage , ` but one of my best items ever was a mattress pad called a Bedmate ... '" type="VP">
          <tokens>
            <token id="19" string="writes" />
            <token id="20" string="at" />
            <token id="21" string="one" />
            <token id="22" string="stage" />
            <token id="23" string="," />
            <token id="24" string="'" />
            <token id="25" string="but" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
            <token id="31" string="ever" />
            <token id="32" string="was" />
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
            <token id="39" string=". . . ." />
            <token id="40" string="'" />
          </tokens>
        </chunking>
        <chunking id="23" string="but one of my best items ever" type="NP">
          <tokens>
            <token id="25" string="but" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
            <token id="31" string="ever" />
          </tokens>
        </chunking>
        <chunking id="24" string="most you , ' he writes at one stage , ` but one of my best items ever was a mattress pad called a Bedmate ... ' A few snippets are more revealing about the character" type="NP">
          <tokens>
            <token id="14" string="most" />
            <token id="15" string="you" />
            <token id="16" string="," />
            <token id="17" string="'" />
            <token id="18" string="he" />
            <token id="19" string="writes" />
            <token id="20" string="at" />
            <token id="21" string="one" />
            <token id="22" string="stage" />
            <token id="23" string="," />
            <token id="24" string="'" />
            <token id="25" string="but" />
            <token id="26" string="one" />
            <token id="27" string="of" />
            <token id="28" string="my" />
            <token id="29" string="best" />
            <token id="30" string="items" />
            <token id="31" string="ever" />
            <token id="32" string="was" />
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
            <token id="39" string=". . . ." />
            <token id="40" string="'" />
            <token id="41" string="A" />
            <token id="42" string="few" />
            <token id="43" string="snippets" />
            <token id="44" string="are" />
            <token id="45" string="more" />
            <token id="46" string="revealing" />
            <token id="47" string="about" />
            <token id="48" string="the" />
            <token id="49" string="character" />
          </tokens>
        </chunking>
        <chunking id="25" string="a mattress pad called a Bedmate" type="NP">
          <tokens>
            <token id="33" string="a" />
            <token id="34" string="mattress" />
            <token id="35" string="pad" />
            <token id="36" string="called" />
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
          </tokens>
        </chunking>
        <chunking id="26" string="the character" type="NP">
          <tokens>
            <token id="48" string="the" />
            <token id="49" string="character" />
          </tokens>
        </chunking>
        <chunking id="27" string="no excuses" type="NP">
          <tokens>
            <token id="3" string="no" />
            <token id="4" string="excuses" />
          </tokens>
        </chunking>
        <chunking id="28" string="a Bedmate" type="NP">
          <tokens>
            <token id="37" string="a" />
            <token id="38" string="Bedmate" />
          </tokens>
        </chunking>
        <chunking id="29" string="makes no excuses" type="VP">
          <tokens>
            <token id="2" string="makes" />
            <token id="3" string="no" />
            <token id="4" string="excuses" />
          </tokens>
        </chunking>
        <chunking id="30" string="you" type="NP">
          <tokens>
            <token id="15" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">makes</governor>
          <dependent id="1">Walton</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">makes</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">excuses</governor>
          <dependent id="3">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">makes</governor>
          <dependent id="4">excuses</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">realise</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">makes</governor>
          <dependent id="8">realise</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">sound</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">sound</governor>
          <dependent id="10">may</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">realise</governor>
          <dependent id="11">sound</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">sound</governor>
          <dependent id="12">boring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">most</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">boring</governor>
          <dependent id="14">most</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">revealing</governor>
          <dependent id="15">you</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">writes</governor>
          <dependent id="18">he</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="46">revealing</governor>
          <dependent id="19">writes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">stage</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="22">stage</governor>
          <dependent id="21">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">writes</governor>
          <dependent id="22">stage</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">one</governor>
          <dependent id="25">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">pad</governor>
          <dependent id="26">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">items</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">items</governor>
          <dependent id="28">my</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">items</governor>
          <dependent id="29">best</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">one</governor>
          <dependent id="30">items</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="26">one</governor>
          <dependent id="31">ever</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="35">pad</governor>
          <dependent id="32">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">pad</governor>
          <dependent id="33">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">pad</governor>
          <dependent id="34">mattress</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">stage</governor>
          <dependent id="35">pad</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="35">pad</governor>
          <dependent id="36">called</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">Bedmate</governor>
          <dependent id="37">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">called</governor>
          <dependent id="38">Bedmate</dependent>
        </dependency>
        <dependency type="det">
          <governor id="43">snippets</governor>
          <dependent id="41">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">snippets</governor>
          <dependent id="42">few</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="46">revealing</governor>
          <dependent id="43">snippets</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="46">revealing</governor>
          <dependent id="44">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="46">revealing</governor>
          <dependent id="45">more</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">most</governor>
          <dependent id="46">revealing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">character</governor>
          <dependent id="47">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="49">character</governor>
          <dependent id="48">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="46">revealing</governor>
          <dependent id="49">character</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="this may" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="this" />
            <token id="10" string="may" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Walton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>There cannot be many billionaires who admit that they &amp;apost;never learned handwriting too well&amp;apost; - and have the guts to include a photograph which demonstrates the point.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="billionaires" lemma="billionaire" stem="billionair" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="admit" lemma="admit" stem="admit" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="learned" lemma="learn" stem="learn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="handwriting" lemma="handwriting" stem="handwrit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="guts" lemma="gut" stem="gut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="include" lemma="include" stem="includ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="photograph" lemma="photograph" stem="photograph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="demonstrates" lemma="demonstrate" stem="demonstr" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (MD can) (RB not) (VP (VB be) (NP (NP (JJ many) (NNS billionaires)) (SBAR (WHNP (WP who)) (S (VP (VBP admit) (SBAR (IN that) (S (NP (PRP they)) (`` `) (VP (VP (ADVP (RB never)) (VBN learned) (NP (NN handwriting)) (ADVP (RB too)) (ADVP (RB well)) ('' ')) (: -) (CC and) (VP (VBP have) (NP (DT the) (NNS guts) (S (VP (TO to) (VP (VB include) (NP (NP (DT a) (NN photograph)) (SBAR (WHNP (WDT which)) (S (VP (VBZ demonstrates) (NP (DT the) (NN point)))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a photograph which demonstrates the point" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="2" string="who admit that they ` never learned handwriting too well ' - and have the guts to include a photograph which demonstrates the point" type="SBAR">
          <tokens>
            <token id="7" string="who" />
            <token id="8" string="admit" />
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="'" />
            <token id="12" string="never" />
            <token id="13" string="learned" />
            <token id="14" string="handwriting" />
            <token id="15" string="too" />
            <token id="16" string="well" />
            <token id="17" string="'" />
            <token id="18" string="-" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="the" />
            <token id="22" string="guts" />
            <token id="23" string="to" />
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="3" string="handwriting" type="NP">
          <tokens>
            <token id="14" string="handwriting" />
          </tokens>
        </chunking>
        <chunking id="4" string="the point" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="5" string="admit that they ` never learned handwriting too well ' - and have the guts to include a photograph which demonstrates the point" type="VP">
          <tokens>
            <token id="8" string="admit" />
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="'" />
            <token id="12" string="never" />
            <token id="13" string="learned" />
            <token id="14" string="handwriting" />
            <token id="15" string="too" />
            <token id="16" string="well" />
            <token id="17" string="'" />
            <token id="18" string="-" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="the" />
            <token id="22" string="guts" />
            <token id="23" string="to" />
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="6" string="never learned handwriting too well '" type="VP">
          <tokens>
            <token id="12" string="never" />
            <token id="13" string="learned" />
            <token id="14" string="handwriting" />
            <token id="15" string="too" />
            <token id="16" string="well" />
            <token id="17" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="a photograph" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="photograph" />
          </tokens>
        </chunking>
        <chunking id="8" string="never learned handwriting too well ' - and have the guts to include a photograph which demonstrates the point" type="VP">
          <tokens>
            <token id="12" string="never" />
            <token id="13" string="learned" />
            <token id="14" string="handwriting" />
            <token id="15" string="too" />
            <token id="16" string="well" />
            <token id="17" string="'" />
            <token id="18" string="-" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="the" />
            <token id="22" string="guts" />
            <token id="23" string="to" />
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="9" string="can not be many billionaires who admit that they ` never learned handwriting too well ' - and have the guts to include a photograph which demonstrates the point" type="VP">
          <tokens>
            <token id="2" string="can" />
            <token id="3" string="not" />
            <token id="4" string="be" />
            <token id="5" string="many" />
            <token id="6" string="billionaires" />
            <token id="7" string="who" />
            <token id="8" string="admit" />
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="'" />
            <token id="12" string="never" />
            <token id="13" string="learned" />
            <token id="14" string="handwriting" />
            <token id="15" string="too" />
            <token id="16" string="well" />
            <token id="17" string="'" />
            <token id="18" string="-" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="the" />
            <token id="22" string="guts" />
            <token id="23" string="to" />
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="10" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="have the guts to include a photograph which demonstrates the point" type="VP">
          <tokens>
            <token id="20" string="have" />
            <token id="21" string="the" />
            <token id="22" string="guts" />
            <token id="23" string="to" />
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="12" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="13" string="include a photograph which demonstrates the point" type="VP">
          <tokens>
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="14" string="which demonstrates the point" type="SBAR">
          <tokens>
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="15" string="many billionaires who admit that they ` never learned handwriting too well ' - and have the guts to include a photograph which demonstrates the point" type="NP">
          <tokens>
            <token id="5" string="many" />
            <token id="6" string="billionaires" />
            <token id="7" string="who" />
            <token id="8" string="admit" />
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="'" />
            <token id="12" string="never" />
            <token id="13" string="learned" />
            <token id="14" string="handwriting" />
            <token id="15" string="too" />
            <token id="16" string="well" />
            <token id="17" string="'" />
            <token id="18" string="-" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="the" />
            <token id="22" string="guts" />
            <token id="23" string="to" />
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="16" string="demonstrates the point" type="VP">
          <tokens>
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="17" string="that they ` never learned handwriting too well ' - and have the guts to include a photograph which demonstrates the point" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="'" />
            <token id="12" string="never" />
            <token id="13" string="learned" />
            <token id="14" string="handwriting" />
            <token id="15" string="too" />
            <token id="16" string="well" />
            <token id="17" string="'" />
            <token id="18" string="-" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="the" />
            <token id="22" string="guts" />
            <token id="23" string="to" />
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="18" string="be many billionaires who admit that they ` never learned handwriting too well ' - and have the guts to include a photograph which demonstrates the point" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="many" />
            <token id="6" string="billionaires" />
            <token id="7" string="who" />
            <token id="8" string="admit" />
            <token id="9" string="that" />
            <token id="10" string="they" />
            <token id="11" string="'" />
            <token id="12" string="never" />
            <token id="13" string="learned" />
            <token id="14" string="handwriting" />
            <token id="15" string="too" />
            <token id="16" string="well" />
            <token id="17" string="'" />
            <token id="18" string="-" />
            <token id="19" string="and" />
            <token id="20" string="have" />
            <token id="21" string="the" />
            <token id="22" string="guts" />
            <token id="23" string="to" />
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="19" string="many billionaires" type="NP">
          <tokens>
            <token id="5" string="many" />
            <token id="6" string="billionaires" />
          </tokens>
        </chunking>
        <chunking id="20" string="the guts to include a photograph which demonstrates the point" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="guts" />
            <token id="23" string="to" />
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
        <chunking id="21" string="to include a photograph which demonstrates the point" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="include" />
            <token id="25" string="a" />
            <token id="26" string="photograph" />
            <token id="27" string="which" />
            <token id="28" string="demonstrates" />
            <token id="29" string="the" />
            <token id="30" string="point" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="6">billionaires</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">billionaires</governor>
          <dependent id="2">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">billionaires</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">billionaires</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">billionaires</governor>
          <dependent id="5">many</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">billionaires</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">admit</governor>
          <dependent id="7">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">billionaires</governor>
          <dependent id="8">admit</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">learned</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">learned</governor>
          <dependent id="10">they</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">learned</governor>
          <dependent id="12">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">admit</governor>
          <dependent id="13">learned</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">learned</governor>
          <dependent id="14">handwriting</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">learned</governor>
          <dependent id="15">too</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">learned</governor>
          <dependent id="16">well</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">learned</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">learned</governor>
          <dependent id="20">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">guts</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">have</governor>
          <dependent id="22">guts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">include</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">guts</governor>
          <dependent id="24">include</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">photograph</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">include</governor>
          <dependent id="26">photograph</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">demonstrates</governor>
          <dependent id="27">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="26">photograph</governor>
          <dependent id="28">demonstrates</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">point</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">demonstrates</governor>
          <dependent id="30">point</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>Meanwhile, the competitive energy which Sam Walton applied to his business is inescapable.</content>
      <tokens>
        <token id="1" string="Meanwhile" lemma="meanwhile" stem="meanwhil" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="competitive" lemma="competitive" stem="competit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="energy" lemma="energy" stem="energi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="applied" lemma="apply" stem="appli" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="inescapable" lemma="inescapable" stem="inescap" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Meanwhile)) (, ,) (NP (NP (DT the) (JJ competitive) (NN energy)) (SBAR (WHNP (WDT which)) (S (NP (NNP Sam) (NNP Walton)) (VP (VBD applied) (PP (TO to) (NP (PRP$ his) (NN business))))))) (VP (VBZ is) (ADJP (JJ inescapable))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is inescapable" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="inescapable" />
          </tokens>
        </chunking>
        <chunking id="2" string="inescapable" type="ADJP">
          <tokens>
            <token id="14" string="inescapable" />
          </tokens>
        </chunking>
        <chunking id="3" string="which Sam Walton applied to his business" type="SBAR">
          <tokens>
            <token id="6" string="which" />
            <token id="7" string="Sam" />
            <token id="8" string="Walton" />
            <token id="9" string="applied" />
            <token id="10" string="to" />
            <token id="11" string="his" />
            <token id="12" string="business" />
          </tokens>
        </chunking>
        <chunking id="4" string="Sam Walton" type="NP">
          <tokens>
            <token id="7" string="Sam" />
            <token id="8" string="Walton" />
          </tokens>
        </chunking>
        <chunking id="5" string="his business" type="NP">
          <tokens>
            <token id="11" string="his" />
            <token id="12" string="business" />
          </tokens>
        </chunking>
        <chunking id="6" string="the competitive energy which Sam Walton applied to his business" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="competitive" />
            <token id="5" string="energy" />
            <token id="6" string="which" />
            <token id="7" string="Sam" />
            <token id="8" string="Walton" />
            <token id="9" string="applied" />
            <token id="10" string="to" />
            <token id="11" string="his" />
            <token id="12" string="business" />
          </tokens>
        </chunking>
        <chunking id="7" string="applied to his business" type="VP">
          <tokens>
            <token id="9" string="applied" />
            <token id="10" string="to" />
            <token id="11" string="his" />
            <token id="12" string="business" />
          </tokens>
        </chunking>
        <chunking id="8" string="the competitive energy" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="competitive" />
            <token id="5" string="energy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="14">inescapable</governor>
          <dependent id="1">Meanwhile</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">energy</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">energy</governor>
          <dependent id="4">competitive</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">inescapable</governor>
          <dependent id="5">energy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">applied</governor>
          <dependent id="6">which</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Walton</governor>
          <dependent id="7">Sam</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">applied</governor>
          <dependent id="8">Walton</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">energy</governor>
          <dependent id="9">applied</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">business</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">business</governor>
          <dependent id="11">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">applied</governor>
          <dependent id="12">business</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">inescapable</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">inescapable</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sam Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Sam" />
            <token id="8" string="Walton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>In one of many contributions from friends and family, Don Soderquist, Wal-Mart&amp;apost;s chief operating officer, tells of finding Sam one Saturday morning on his hand and knees at the local Kmart store, analysing his rival&amp;apost;s stock.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="contributions" lemma="contribution" stem="contribut" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Don" lemma="Don" stem="don" pos="NNP" type="Word" isStopWord="true" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Soderquist" lemma="Soderquist" stem="soderquist" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Wal-Mart" lemma="Wal-Mart" stem="wal-mart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="chief" lemma="chief" stem="chief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="operating" lemma="operate" stem="oper" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="tells" lemma="tell" stem="tell" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="finding" lemma="find" stem="find" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="25" string="Saturday" lemma="Saturday" stem="saturdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="morning" lemma="morning" stem="morn" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="27" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="knees" lemma="knee" stem="knee" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="local" lemma="local" stem="local" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="Kmart" lemma="Kmart" stem="kmart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="36" string="store" lemma="store" stem="store" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="analysing" lemma="analyse" stem="analys" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="rival" lemma="rival" stem="rival" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="stock" lemma="stock" stem="stock" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (CD one)) (PP (IN of) (NP (NP (JJ many) (NNS contributions)) (PP (IN from) (NP (NNS friends) (CC and) (NN family))))))) (, ,) (NP (NP (NNP Don) (NNP Soderquist)) (, ,) (NP (NP (NNP Wal-Mart) (POS 's)) (NN chief) (VBG operating) (NN officer)) (, ,)) (VP (VBZ tells) (PP (IN of) (S (VP (VBG finding) (NP (NNP Sam) (CD one)) (NP-TMP (NNP Saturday) (NN morning)) (PP (IN on) (NP (PRP$ his) (NN hand) (CC and) (NNS knees))) (PP (IN at) (NP (DT the) (JJ local) (NNP Kmart) (NN store))) (, ,) (S (VP (VBG analysing) (NP (NP (PRP$ his) (NN rival) (POS 's)) (NN stock)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the local Kmart store" type="NP">
          <tokens>
            <token id="33" string="the" />
            <token id="34" string="local" />
            <token id="35" string="Kmart" />
            <token id="36" string="store" />
          </tokens>
        </chunking>
        <chunking id="2" string="Don Soderquist , Wal-Mart 's chief operating officer ," type="NP">
          <tokens>
            <token id="11" string="Don" />
            <token id="12" string="Soderquist" />
            <token id="13" string="," />
            <token id="14" string="Wal-Mart" />
            <token id="15" string="'s" />
            <token id="16" string="chief" />
            <token id="17" string="operating" />
            <token id="18" string="officer" />
            <token id="19" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="tells of finding Sam one Saturday morning on his hand and knees at the local Kmart store , analysing his rival 's stock" type="VP">
          <tokens>
            <token id="20" string="tells" />
            <token id="21" string="of" />
            <token id="22" string="finding" />
            <token id="23" string="Sam" />
            <token id="24" string="one" />
            <token id="25" string="Saturday" />
            <token id="26" string="morning" />
            <token id="27" string="on" />
            <token id="28" string="his" />
            <token id="29" string="hand" />
            <token id="30" string="and" />
            <token id="31" string="knees" />
            <token id="32" string="at" />
            <token id="33" string="the" />
            <token id="34" string="local" />
            <token id="35" string="Kmart" />
            <token id="36" string="store" />
            <token id="37" string="," />
            <token id="38" string="analysing" />
            <token id="39" string="his" />
            <token id="40" string="rival" />
            <token id="41" string="'s" />
            <token id="42" string="stock" />
          </tokens>
        </chunking>
        <chunking id="5" string="many contributions" type="NP">
          <tokens>
            <token id="4" string="many" />
            <token id="5" string="contributions" />
          </tokens>
        </chunking>
        <chunking id="6" string="analysing his rival 's stock" type="VP">
          <tokens>
            <token id="38" string="analysing" />
            <token id="39" string="his" />
            <token id="40" string="rival" />
            <token id="41" string="'s" />
            <token id="42" string="stock" />
          </tokens>
        </chunking>
        <chunking id="7" string="Wal-Mart 's" type="NP">
          <tokens>
            <token id="14" string="Wal-Mart" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="friends and family" type="NP">
          <tokens>
            <token id="7" string="friends" />
            <token id="8" string="and" />
            <token id="9" string="family" />
          </tokens>
        </chunking>
        <chunking id="9" string="Don Soderquist" type="NP">
          <tokens>
            <token id="11" string="Don" />
            <token id="12" string="Soderquist" />
          </tokens>
        </chunking>
        <chunking id="10" string="his hand and knees" type="NP">
          <tokens>
            <token id="28" string="his" />
            <token id="29" string="hand" />
            <token id="30" string="and" />
            <token id="31" string="knees" />
          </tokens>
        </chunking>
        <chunking id="11" string="his rival 's" type="NP">
          <tokens>
            <token id="39" string="his" />
            <token id="40" string="rival" />
            <token id="41" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="Wal-Mart 's chief operating officer" type="NP">
          <tokens>
            <token id="14" string="Wal-Mart" />
            <token id="15" string="'s" />
            <token id="16" string="chief" />
            <token id="17" string="operating" />
            <token id="18" string="officer" />
          </tokens>
        </chunking>
        <chunking id="13" string="one of many contributions from friends and family" type="NP">
          <tokens>
            <token id="2" string="one" />
            <token id="3" string="of" />
            <token id="4" string="many" />
            <token id="5" string="contributions" />
            <token id="6" string="from" />
            <token id="7" string="friends" />
            <token id="8" string="and" />
            <token id="9" string="family" />
          </tokens>
        </chunking>
        <chunking id="14" string="many contributions from friends and family" type="NP">
          <tokens>
            <token id="4" string="many" />
            <token id="5" string="contributions" />
            <token id="6" string="from" />
            <token id="7" string="friends" />
            <token id="8" string="and" />
            <token id="9" string="family" />
          </tokens>
        </chunking>
        <chunking id="15" string="his rival 's stock" type="NP">
          <tokens>
            <token id="39" string="his" />
            <token id="40" string="rival" />
            <token id="41" string="'s" />
            <token id="42" string="stock" />
          </tokens>
        </chunking>
        <chunking id="16" string="finding Sam one Saturday morning on his hand and knees at the local Kmart store , analysing his rival 's stock" type="VP">
          <tokens>
            <token id="22" string="finding" />
            <token id="23" string="Sam" />
            <token id="24" string="one" />
            <token id="25" string="Saturday" />
            <token id="26" string="morning" />
            <token id="27" string="on" />
            <token id="28" string="his" />
            <token id="29" string="hand" />
            <token id="30" string="and" />
            <token id="31" string="knees" />
            <token id="32" string="at" />
            <token id="33" string="the" />
            <token id="34" string="local" />
            <token id="35" string="Kmart" />
            <token id="36" string="store" />
            <token id="37" string="," />
            <token id="38" string="analysing" />
            <token id="39" string="his" />
            <token id="40" string="rival" />
            <token id="41" string="'s" />
            <token id="42" string="stock" />
          </tokens>
        </chunking>
        <chunking id="17" string="Sam one" type="NP">
          <tokens>
            <token id="23" string="Sam" />
            <token id="24" string="one" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">one</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">tells</governor>
          <dependent id="2">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">contributions</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">contributions</governor>
          <dependent id="4">many</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">one</governor>
          <dependent id="5">contributions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">friends</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">contributions</governor>
          <dependent id="7">friends</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">friends</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">friends</governor>
          <dependent id="9">family</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Soderquist</governor>
          <dependent id="11">Don</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">tells</governor>
          <dependent id="12">Soderquist</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">officer</governor>
          <dependent id="14">Wal-Mart</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Wal-Mart</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">officer</governor>
          <dependent id="16">chief</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">officer</governor>
          <dependent id="17">operating</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">Soderquist</governor>
          <dependent id="18">officer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">tells</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">finding</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">tells</governor>
          <dependent id="22">finding</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">finding</governor>
          <dependent id="23">Sam</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="23">Sam</governor>
          <dependent id="24">one</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">morning</governor>
          <dependent id="25">Saturday</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="22">finding</governor>
          <dependent id="26">morning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">hand</governor>
          <dependent id="27">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">hand</governor>
          <dependent id="28">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">finding</governor>
          <dependent id="29">hand</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">hand</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">hand</governor>
          <dependent id="31">knees</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">store</governor>
          <dependent id="32">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">store</governor>
          <dependent id="33">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">store</governor>
          <dependent id="34">local</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">store</governor>
          <dependent id="35">Kmart</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">finding</governor>
          <dependent id="36">store</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">finding</governor>
          <dependent id="38">analysing</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="40">rival</governor>
          <dependent id="39">his</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="42">stock</governor>
          <dependent id="40">rival</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">rival</governor>
          <dependent id="41">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">analysing</governor>
          <dependent id="42">stock</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Kmart" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="35" string="Kmart" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="2" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="morning" type="TIME" score="0.0">
          <tokens>
            <token id="26" string="morning" />
          </tokens>
        </entity>
        <entity id="4" string="Wal-Mart" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Wal-Mart" />
          </tokens>
        </entity>
        <entity id="5" string="Don Soderquist" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Don" />
            <token id="12" string="Soderquist" />
          </tokens>
        </entity>
        <entity id="6" string="Saturday" type="DATE" score="0.0">
          <tokens>
            <token id="25" string="Saturday" />
          </tokens>
        </entity>
        <entity id="7" string="Sam" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Sam" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>And his wife, in a casual aside, notes that when the couple was on holiday in Italy their luggage vanished while her husband was off on a similar scouting mission.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="casual" lemma="casual" stem="casual" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="aside" lemma="aside" stem="asid" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="notes" lemma="note" stem="note" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="couple" lemma="couple" stem="coupl" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="holiday" lemma="holiday" stem="holidai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Italy" lemma="Italy" stem="itali" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="luggage" lemma="luggage" stem="luggag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="vanished" lemma="vanish" stem="vanish" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="off" lemma="off" stem="off" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="scouting" lemma="scout" stem="scout" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="mission" lemma="mission" stem="mission" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NP (PRP$ his) (NN wife)) (, ,) (PP (IN in) (NP (NP (DT a) (JJ casual)) (ADVP (RB aside)))) (, ,)) (VP (VBZ notes) (SBAR (IN that) (S (SBAR (WHADVP (WRB when)) (S (NP (DT the) (NN couple)) (VP (VBD was) (PP (IN on) (NP (NP (NN holiday)) (PP (IN in) (NP (NNP Italy)))))))) (NP (PRP$ their) (NN luggage)) (VP (VBD vanished) (SBAR (IN while) (S (NP (PRP$ her) (NN husband)) (VP (VBD was) (ADVP (RB off) (PP (IN on) (NP (DT a) (JJ similar)))) (VP (VBG scouting) (NP (NN mission)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was on holiday in Italy" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="on" />
            <token id="17" string="holiday" />
            <token id="18" string="in" />
            <token id="19" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="2" string="holiday" type="NP">
          <tokens>
            <token id="17" string="holiday" />
          </tokens>
        </chunking>
        <chunking id="3" string="notes that when the couple was on holiday in Italy their luggage vanished while her husband was off on a similar scouting mission" type="VP">
          <tokens>
            <token id="10" string="notes" />
            <token id="11" string="that" />
            <token id="12" string="when" />
            <token id="13" string="the" />
            <token id="14" string="couple" />
            <token id="15" string="was" />
            <token id="16" string="on" />
            <token id="17" string="holiday" />
            <token id="18" string="in" />
            <token id="19" string="Italy" />
            <token id="20" string="their" />
            <token id="21" string="luggage" />
            <token id="22" string="vanished" />
            <token id="23" string="while" />
            <token id="24" string="her" />
            <token id="25" string="husband" />
            <token id="26" string="was" />
            <token id="27" string="off" />
            <token id="28" string="on" />
            <token id="29" string="a" />
            <token id="30" string="similar" />
            <token id="31" string="scouting" />
            <token id="32" string="mission" />
          </tokens>
        </chunking>
        <chunking id="4" string="vanished while her husband was off on a similar scouting mission" type="VP">
          <tokens>
            <token id="22" string="vanished" />
            <token id="23" string="while" />
            <token id="24" string="her" />
            <token id="25" string="husband" />
            <token id="26" string="was" />
            <token id="27" string="off" />
            <token id="28" string="on" />
            <token id="29" string="a" />
            <token id="30" string="similar" />
            <token id="31" string="scouting" />
            <token id="32" string="mission" />
          </tokens>
        </chunking>
        <chunking id="5" string="a casual aside" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="casual" />
            <token id="8" string="aside" />
          </tokens>
        </chunking>
        <chunking id="6" string="his wife , in a casual aside ," type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="wife" />
            <token id="4" string="," />
            <token id="5" string="in" />
            <token id="6" string="a" />
            <token id="7" string="casual" />
            <token id="8" string="aside" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="their luggage" type="NP">
          <tokens>
            <token id="20" string="their" />
            <token id="21" string="luggage" />
          </tokens>
        </chunking>
        <chunking id="8" string="was off on a similar scouting mission" type="VP">
          <tokens>
            <token id="26" string="was" />
            <token id="27" string="off" />
            <token id="28" string="on" />
            <token id="29" string="a" />
            <token id="30" string="similar" />
            <token id="31" string="scouting" />
            <token id="32" string="mission" />
          </tokens>
        </chunking>
        <chunking id="9" string="holiday in Italy" type="NP">
          <tokens>
            <token id="17" string="holiday" />
            <token id="18" string="in" />
            <token id="19" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="12" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="while her husband was off on a similar scouting mission" type="SBAR">
          <tokens>
            <token id="23" string="while" />
            <token id="24" string="her" />
            <token id="25" string="husband" />
            <token id="26" string="was" />
            <token id="27" string="off" />
            <token id="28" string="on" />
            <token id="29" string="a" />
            <token id="30" string="similar" />
            <token id="31" string="scouting" />
            <token id="32" string="mission" />
          </tokens>
        </chunking>
        <chunking id="12" string="a similar" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="similar" />
          </tokens>
        </chunking>
        <chunking id="13" string="mission" type="NP">
          <tokens>
            <token id="32" string="mission" />
          </tokens>
        </chunking>
        <chunking id="14" string="when the couple was on holiday in Italy" type="SBAR">
          <tokens>
            <token id="12" string="when" />
            <token id="13" string="the" />
            <token id="14" string="couple" />
            <token id="15" string="was" />
            <token id="16" string="on" />
            <token id="17" string="holiday" />
            <token id="18" string="in" />
            <token id="19" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="15" string="Italy" type="NP">
          <tokens>
            <token id="19" string="Italy" />
          </tokens>
        </chunking>
        <chunking id="16" string="the couple" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="couple" />
          </tokens>
        </chunking>
        <chunking id="17" string="scouting mission" type="VP">
          <tokens>
            <token id="31" string="scouting" />
            <token id="32" string="mission" />
          </tokens>
        </chunking>
        <chunking id="18" string="her husband" type="NP">
          <tokens>
            <token id="24" string="her" />
            <token id="25" string="husband" />
          </tokens>
        </chunking>
        <chunking id="19" string="his wife" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="wife" />
          </tokens>
        </chunking>
        <chunking id="20" string="a casual" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="casual" />
          </tokens>
        </chunking>
        <chunking id="21" string="that when the couple was on holiday in Italy their luggage vanished while her husband was off on a similar scouting mission" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="when" />
            <token id="13" string="the" />
            <token id="14" string="couple" />
            <token id="15" string="was" />
            <token id="16" string="on" />
            <token id="17" string="holiday" />
            <token id="18" string="in" />
            <token id="19" string="Italy" />
            <token id="20" string="their" />
            <token id="21" string="luggage" />
            <token id="22" string="vanished" />
            <token id="23" string="while" />
            <token id="24" string="her" />
            <token id="25" string="husband" />
            <token id="26" string="was" />
            <token id="27" string="off" />
            <token id="28" string="on" />
            <token id="29" string="a" />
            <token id="30" string="similar" />
            <token id="31" string="scouting" />
            <token id="32" string="mission" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="10">notes</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">wife</governor>
          <dependent id="2">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">notes</governor>
          <dependent id="3">wife</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">casual</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">casual</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">wife</governor>
          <dependent id="7">casual</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">casual</governor>
          <dependent id="8">aside</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">notes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">vanished</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">holiday</governor>
          <dependent id="12">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">couple</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">holiday</governor>
          <dependent id="14">couple</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">holiday</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">holiday</governor>
          <dependent id="16">on</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">vanished</governor>
          <dependent id="17">holiday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Italy</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">holiday</governor>
          <dependent id="19">Italy</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">luggage</governor>
          <dependent id="20">their</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">vanished</governor>
          <dependent id="21">luggage</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">notes</governor>
          <dependent id="22">vanished</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">scouting</governor>
          <dependent id="23">while</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">husband</governor>
          <dependent id="24">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">scouting</governor>
          <dependent id="25">husband</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">scouting</governor>
          <dependent id="26">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">scouting</governor>
          <dependent id="27">off</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">similar</governor>
          <dependent id="28">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">similar</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">off</governor>
          <dependent id="30">similar</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">vanished</governor>
          <dependent id="31">scouting</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">scouting</governor>
          <dependent id="32">mission</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Italy" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Italy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>But it is David Glass, Wal-Mart&amp;apost;s current chief executive, who perhaps captures the entrepreneurial Walton spirit best.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="David" lemma="David" stem="david" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Glass" lemma="Glass" stem="glass" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Wal-Mart" lemma="Wal-Mart" stem="wal-mart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="chief" lemma="chief" stem="chief" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="executive" lemma="executive" stem="execut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="captures" lemma="capture" stem="captur" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="entrepreneurial" lemma="entrepreneurial" stem="entrepreneuri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="spirit" lemma="spirit" stem="spirit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP it)) (VP (VBZ is) (NP (NP (NNP David) (NNP Glass)) (, ,) (NP (NP (NP (NNP Wal-Mart) (POS 's)) (JJ current) (JJ chief) (NN executive)) (, ,) (SBAR (WHNP (WP who)) (S (ADVP (RB perhaps)) (VP (VBZ captures) (S (NP (DT the) (JJ entrepreneurial) (NNP Walton) (NN spirit)) (ADJP (JJS best))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="David Glass" type="NP">
          <tokens>
            <token id="4" string="David" />
            <token id="5" string="Glass" />
          </tokens>
        </chunking>
        <chunking id="2" string="Wal-Mart 's current chief executive" type="NP">
          <tokens>
            <token id="7" string="Wal-Mart" />
            <token id="8" string="'s" />
            <token id="9" string="current" />
            <token id="10" string="chief" />
            <token id="11" string="executive" />
          </tokens>
        </chunking>
        <chunking id="3" string="Wal-Mart 's current chief executive , who perhaps captures the entrepreneurial Walton spirit best" type="NP">
          <tokens>
            <token id="7" string="Wal-Mart" />
            <token id="8" string="'s" />
            <token id="9" string="current" />
            <token id="10" string="chief" />
            <token id="11" string="executive" />
            <token id="12" string="," />
            <token id="13" string="who" />
            <token id="14" string="perhaps" />
            <token id="15" string="captures" />
            <token id="16" string="the" />
            <token id="17" string="entrepreneurial" />
            <token id="18" string="Walton" />
            <token id="19" string="spirit" />
            <token id="20" string="best" />
          </tokens>
        </chunking>
        <chunking id="4" string="captures the entrepreneurial Walton spirit best" type="VP">
          <tokens>
            <token id="15" string="captures" />
            <token id="16" string="the" />
            <token id="17" string="entrepreneurial" />
            <token id="18" string="Walton" />
            <token id="19" string="spirit" />
            <token id="20" string="best" />
          </tokens>
        </chunking>
        <chunking id="5" string="is David Glass , Wal-Mart 's current chief executive , who perhaps captures the entrepreneurial Walton spirit best" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="David" />
            <token id="5" string="Glass" />
            <token id="6" string="," />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="'s" />
            <token id="9" string="current" />
            <token id="10" string="chief" />
            <token id="11" string="executive" />
            <token id="12" string="," />
            <token id="13" string="who" />
            <token id="14" string="perhaps" />
            <token id="15" string="captures" />
            <token id="16" string="the" />
            <token id="17" string="entrepreneurial" />
            <token id="18" string="Walton" />
            <token id="19" string="spirit" />
            <token id="20" string="best" />
          </tokens>
        </chunking>
        <chunking id="6" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="David Glass , Wal-Mart 's current chief executive , who perhaps captures the entrepreneurial Walton spirit best" type="NP">
          <tokens>
            <token id="4" string="David" />
            <token id="5" string="Glass" />
            <token id="6" string="," />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="'s" />
            <token id="9" string="current" />
            <token id="10" string="chief" />
            <token id="11" string="executive" />
            <token id="12" string="," />
            <token id="13" string="who" />
            <token id="14" string="perhaps" />
            <token id="15" string="captures" />
            <token id="16" string="the" />
            <token id="17" string="entrepreneurial" />
            <token id="18" string="Walton" />
            <token id="19" string="spirit" />
            <token id="20" string="best" />
          </tokens>
        </chunking>
        <chunking id="8" string="the entrepreneurial Walton spirit" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="entrepreneurial" />
            <token id="18" string="Walton" />
            <token id="19" string="spirit" />
          </tokens>
        </chunking>
        <chunking id="9" string="Wal-Mart 's" type="NP">
          <tokens>
            <token id="7" string="Wal-Mart" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="best" type="ADJP">
          <tokens>
            <token id="20" string="best" />
          </tokens>
        </chunking>
        <chunking id="11" string="who perhaps captures the entrepreneurial Walton spirit best" type="SBAR">
          <tokens>
            <token id="13" string="who" />
            <token id="14" string="perhaps" />
            <token id="15" string="captures" />
            <token id="16" string="the" />
            <token id="17" string="entrepreneurial" />
            <token id="18" string="Walton" />
            <token id="19" string="spirit" />
            <token id="20" string="best" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">Glass</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">Glass</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">Glass</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Glass</governor>
          <dependent id="4">David</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">Glass</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">executive</governor>
          <dependent id="7">Wal-Mart</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Wal-Mart</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">executive</governor>
          <dependent id="9">current</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">executive</governor>
          <dependent id="10">chief</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Glass</governor>
          <dependent id="11">executive</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">captures</governor>
          <dependent id="13">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">captures</governor>
          <dependent id="14">perhaps</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">executive</governor>
          <dependent id="15">captures</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">spirit</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">spirit</governor>
          <dependent id="17">entrepreneurial</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">spirit</governor>
          <dependent id="18">Walton</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">best</governor>
          <dependent id="19">spirit</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">captures</governor>
          <dependent id="20">best</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="David Glass" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="David" />
            <token id="5" string="Glass" />
          </tokens>
        </entity>
        <entity id="2" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="current" />
          </tokens>
        </entity>
        <entity id="3" string="Wal-Mart" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Wal-Mart" />
          </tokens>
        </entity>
        <entity id="4" string="Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Walton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Explaining the annual contest in which Wal-Mart executives choose one &amp;apost;volume producing item&amp;apost; to promote, he recalls the time Sam (who usually won) selected minnow buckets for carrying bait.</content>
      <tokens>
        <token id="1" string="Explaining" lemma="explain" stem="explain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="annual" lemma="annual" stem="annual" pos="JJ" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="4" string="contest" lemma="contest" stem="contest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Wal-Mart" lemma="Wal-Mart" stem="wal-mart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="executives" lemma="executive" stem="execut" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="choose" lemma="choose" stem="choos" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="volume" lemma="volume" stem="volum" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="producing" lemma="produce" stem="produc" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="item" lemma="item" stem="item" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="promote" lemma="promote" stem="promot" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="recalls" lemma="recall" stem="recal" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="usually" lemma="usually" stem="usual" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="selected" lemma="select" stem="select" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="minnow" lemma="minnow" stem="minnow" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="buckets" lemma="bucket" stem="bucket" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="carrying" lemma="carry" stem="carri" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="bait" lemma="bait" stem="bait" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Explaining) (NP (NP (DT the) (JJ annual) (NN contest)) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (NNP Wal-Mart) (NNS executives)) (VP (VB choose) (S (NP (NP (CD one)) (`` `) (S (NP (NN volume)) (VP (VBG producing) (NP (NN item)))) ('' ')) (VP (TO to) (VP (VB promote)))))))))) (, ,) (NP (PRP he)) (VP (VBZ recalls) (NP (NP (DT the) (NN time) (NNP Sam)) (PRN (-LRB- -LRB-) (SBAR (WHNP (WP who)) (S (ADVP (RB usually)) (VP (VBD won)))) (-RRB- -RRB-)) (VP (VBN selected) (NP (NN minnow) (NNS buckets)) (PP (IN for) (S (VP (VBG carrying) (NP (NN bait)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="in which Wal-Mart executives choose one ` volume producing item ' to promote" type="SBAR">
          <tokens>
            <token id="5" string="in" />
            <token id="6" string="which" />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="executives" />
            <token id="9" string="choose" />
            <token id="10" string="one" />
            <token id="11" string="'" />
            <token id="12" string="volume" />
            <token id="13" string="producing" />
            <token id="14" string="item" />
            <token id="15" string="'" />
            <token id="16" string="to" />
            <token id="17" string="promote" />
          </tokens>
        </chunking>
        <chunking id="2" string="item" type="NP">
          <tokens>
            <token id="14" string="item" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="10" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="bait" type="NP">
          <tokens>
            <token id="34" string="bait" />
          </tokens>
        </chunking>
        <chunking id="5" string="the annual contest in which Wal-Mart executives choose one ` volume producing item ' to promote" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="annual" />
            <token id="4" string="contest" />
            <token id="5" string="in" />
            <token id="6" string="which" />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="executives" />
            <token id="9" string="choose" />
            <token id="10" string="one" />
            <token id="11" string="'" />
            <token id="12" string="volume" />
            <token id="13" string="producing" />
            <token id="14" string="item" />
            <token id="15" string="'" />
            <token id="16" string="to" />
            <token id="17" string="promote" />
          </tokens>
        </chunking>
        <chunking id="6" string="promote" type="VP">
          <tokens>
            <token id="17" string="promote" />
          </tokens>
        </chunking>
        <chunking id="7" string="minnow buckets" type="NP">
          <tokens>
            <token id="30" string="minnow" />
            <token id="31" string="buckets" />
          </tokens>
        </chunking>
        <chunking id="8" string="the time Sam -LRB- who usually won -RRB- selected minnow buckets for carrying bait" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="time" />
            <token id="23" string="Sam" />
            <token id="24" string="(" />
            <token id="25" string="who" />
            <token id="26" string="usually" />
            <token id="27" string="won" />
            <token id="28" string=")" />
            <token id="29" string="selected" />
            <token id="30" string="minnow" />
            <token id="31" string="buckets" />
            <token id="32" string="for" />
            <token id="33" string="carrying" />
            <token id="34" string="bait" />
          </tokens>
        </chunking>
        <chunking id="9" string="producing item" type="VP">
          <tokens>
            <token id="13" string="producing" />
            <token id="14" string="item" />
          </tokens>
        </chunking>
        <chunking id="10" string="to promote" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="promote" />
          </tokens>
        </chunking>
        <chunking id="11" string="Wal-Mart executives" type="NP">
          <tokens>
            <token id="7" string="Wal-Mart" />
            <token id="8" string="executives" />
          </tokens>
        </chunking>
        <chunking id="12" string="volume" type="NP">
          <tokens>
            <token id="12" string="volume" />
          </tokens>
        </chunking>
        <chunking id="13" string="selected minnow buckets for carrying bait" type="VP">
          <tokens>
            <token id="29" string="selected" />
            <token id="30" string="minnow" />
            <token id="31" string="buckets" />
            <token id="32" string="for" />
            <token id="33" string="carrying" />
            <token id="34" string="bait" />
          </tokens>
        </chunking>
        <chunking id="14" string="choose one ` volume producing item ' to promote" type="VP">
          <tokens>
            <token id="9" string="choose" />
            <token id="10" string="one" />
            <token id="11" string="'" />
            <token id="12" string="volume" />
            <token id="13" string="producing" />
            <token id="14" string="item" />
            <token id="15" string="'" />
            <token id="16" string="to" />
            <token id="17" string="promote" />
          </tokens>
        </chunking>
        <chunking id="15" string="won" type="VP">
          <tokens>
            <token id="27" string="won" />
          </tokens>
        </chunking>
        <chunking id="16" string="Explaining the annual contest in which Wal-Mart executives choose one ` volume producing item ' to promote" type="VP">
          <tokens>
            <token id="1" string="Explaining" />
            <token id="2" string="the" />
            <token id="3" string="annual" />
            <token id="4" string="contest" />
            <token id="5" string="in" />
            <token id="6" string="which" />
            <token id="7" string="Wal-Mart" />
            <token id="8" string="executives" />
            <token id="9" string="choose" />
            <token id="10" string="one" />
            <token id="11" string="'" />
            <token id="12" string="volume" />
            <token id="13" string="producing" />
            <token id="14" string="item" />
            <token id="15" string="'" />
            <token id="16" string="to" />
            <token id="17" string="promote" />
          </tokens>
        </chunking>
        <chunking id="17" string="one ` volume producing item '" type="NP">
          <tokens>
            <token id="10" string="one" />
            <token id="11" string="'" />
            <token id="12" string="volume" />
            <token id="13" string="producing" />
            <token id="14" string="item" />
            <token id="15" string="'" />
          </tokens>
        </chunking>
        <chunking id="18" string="the annual contest" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="annual" />
            <token id="4" string="contest" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="19" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="who usually won" type="SBAR">
          <tokens>
            <token id="25" string="who" />
            <token id="26" string="usually" />
            <token id="27" string="won" />
          </tokens>
        </chunking>
        <chunking id="21" string="recalls the time Sam -LRB- who usually won -RRB- selected minnow buckets for carrying bait" type="VP">
          <tokens>
            <token id="20" string="recalls" />
            <token id="21" string="the" />
            <token id="22" string="time" />
            <token id="23" string="Sam" />
            <token id="24" string="(" />
            <token id="25" string="who" />
            <token id="26" string="usually" />
            <token id="27" string="won" />
            <token id="28" string=")" />
            <token id="29" string="selected" />
            <token id="30" string="minnow" />
            <token id="31" string="buckets" />
            <token id="32" string="for" />
            <token id="33" string="carrying" />
            <token id="34" string="bait" />
          </tokens>
        </chunking>
        <chunking id="22" string="carrying bait" type="VP">
          <tokens>
            <token id="33" string="carrying" />
            <token id="34" string="bait" />
          </tokens>
        </chunking>
        <chunking id="23" string="the time Sam" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="time" />
            <token id="23" string="Sam" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="20">recalls</governor>
          <dependent id="1">Explaining</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">contest</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">contest</governor>
          <dependent id="3">annual</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Explaining</governor>
          <dependent id="4">contest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">which</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">choose</governor>
          <dependent id="6">which</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">executives</governor>
          <dependent id="7">Wal-Mart</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">choose</governor>
          <dependent id="8">executives</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">contest</governor>
          <dependent id="9">choose</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">choose</governor>
          <dependent id="10">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">producing</governor>
          <dependent id="12">volume</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">one</governor>
          <dependent id="13">producing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">producing</governor>
          <dependent id="14">item</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">promote</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">choose</governor>
          <dependent id="17">promote</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">recalls</governor>
          <dependent id="19">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">recalls</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Sam</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Sam</governor>
          <dependent id="22">time</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">recalls</governor>
          <dependent id="23">Sam</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">won</governor>
          <dependent id="25">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">won</governor>
          <dependent id="26">usually</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="29">selected</governor>
          <dependent id="27">won</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="23">Sam</governor>
          <dependent id="29">selected</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">buckets</governor>
          <dependent id="30">minnow</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">selected</governor>
          <dependent id="31">buckets</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">carrying</governor>
          <dependent id="32">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="29">selected</governor>
          <dependent id="33">carrying</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">carrying</governor>
          <dependent id="34">bait</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="annual" type="SET" score="0.0">
          <tokens>
            <token id="3" string="annual" />
          </tokens>
        </entity>
        <entity id="3" string="Wal-Mart" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Wal-Mart" />
          </tokens>
        </entity>
        <entity id="4" string="Sam" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Sam" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Glass was more happily teamed with apple juice.</content>
      <tokens>
        <token id="1" string="Glass" lemma="glass" stem="glass" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="happily" lemma="happily" stem="happili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="teamed" lemma="team" stem="team" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="apple" lemma="apple" stem="appl" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="juice" lemma="juice" stem="juic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Glass)) (VP (VBD was) (ADVP (RBR more)) (VP (ADVP (RB happily)) (VBN teamed) (PP (IN with) (NP (NN apple) (NN juice))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Glass" type="NP">
          <tokens>
            <token id="1" string="Glass" />
          </tokens>
        </chunking>
        <chunking id="2" string="happily teamed with apple juice" type="VP">
          <tokens>
            <token id="4" string="happily" />
            <token id="5" string="teamed" />
            <token id="6" string="with" />
            <token id="7" string="apple" />
            <token id="8" string="juice" />
          </tokens>
        </chunking>
        <chunking id="3" string="was more happily teamed with apple juice" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="more" />
            <token id="4" string="happily" />
            <token id="5" string="teamed" />
            <token id="6" string="with" />
            <token id="7" string="apple" />
            <token id="8" string="juice" />
          </tokens>
        </chunking>
        <chunking id="4" string="apple juice" type="NP">
          <tokens>
            <token id="7" string="apple" />
            <token id="8" string="juice" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">teamed</governor>
          <dependent id="1">Glass</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">teamed</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">teamed</governor>
          <dependent id="3">more</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">teamed</governor>
          <dependent id="4">happily</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">teamed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">juice</governor>
          <dependent id="6">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">juice</governor>
          <dependent id="7">apple</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">teamed</governor>
          <dependent id="8">juice</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>&amp;apost;So I would go down to the stores, and get them to take that minnow bucket . . . put ice in it, ice down the juice and give away samples out of his minnow bucket.</content>
      <tokens>
        <token id="1" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="So" lemma="so" stem="so" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="go" lemma="go" stem="go" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="down" lemma="down" stem="down" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="stores" lemma="store" stem="store" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="minnow" lemma="minnow" stem="minnow" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="bucket" lemma="bucket" stem="bucket" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="put" lemma="put" stem="put" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="ice" lemma="ice" stem="ic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="ice" lemma="ice" stem="ic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="down" lemma="down" stem="down" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="juice" lemma="juice" stem="juic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="give" lemma="give" stem="give" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="away" lemma="away" stem="awai" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="samples" lemma="sample" stem="sampl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="minnow" lemma="minnow" stem="minnow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="bucket" lemma="bucket" stem="bucket" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (`` `) (IN So) (NP (PRP I)) (VP (MD would) (VP (VP (VB go) (ADVP (RB down) (PP (TO to) (NP (DT the) (NNS stores))))) (, ,) (CC and) (VP (VB get) (S (NP (PRP them)) (VP (TO to) (VP (VB take) (NP (DT that) (NN minnow) (NN bucket))))))))) (: ...) (S (VP (VP (VB put) (NP (NN ice)) (PP (IN in) (NP (NP (PRP it)) (, ,) (NP (NN ice)))) (PP (IN down) (NP (DT the) (NN juice)))) (CC and) (VP (VB give) (PRT (RP away)) (NP (NNS samples)) (ADVP (IN out) (PP (IN of) (NP (PRP$ his) (NN minnow) (NN bucket))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="put ice in it , ice down the juice" type="VP">
          <tokens>
            <token id="20" string="put" />
            <token id="21" string="ice" />
            <token id="22" string="in" />
            <token id="23" string="it" />
            <token id="24" string="," />
            <token id="25" string="ice" />
            <token id="26" string="down" />
            <token id="27" string="the" />
            <token id="28" string="juice" />
          </tokens>
        </chunking>
        <chunking id="2" string="it , ice" type="NP">
          <tokens>
            <token id="23" string="it" />
            <token id="24" string="," />
            <token id="25" string="ice" />
          </tokens>
        </chunking>
        <chunking id="3" string="give away samples out of his minnow bucket" type="VP">
          <tokens>
            <token id="30" string="give" />
            <token id="31" string="away" />
            <token id="32" string="samples" />
            <token id="33" string="out" />
            <token id="34" string="of" />
            <token id="35" string="his" />
            <token id="36" string="minnow" />
            <token id="37" string="bucket" />
          </tokens>
        </chunking>
        <chunking id="4" string="his minnow bucket" type="NP">
          <tokens>
            <token id="35" string="his" />
            <token id="36" string="minnow" />
            <token id="37" string="bucket" />
          </tokens>
        </chunking>
        <chunking id="5" string="get them to take that minnow bucket" type="VP">
          <tokens>
            <token id="12" string="get" />
            <token id="13" string="them" />
            <token id="14" string="to" />
            <token id="15" string="take" />
            <token id="16" string="that" />
            <token id="17" string="minnow" />
            <token id="18" string="bucket" />
          </tokens>
        </chunking>
        <chunking id="6" string="the stores" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="stores" />
          </tokens>
        </chunking>
        <chunking id="7" string="go down to the stores" type="VP">
          <tokens>
            <token id="5" string="go" />
            <token id="6" string="down" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="stores" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="the juice" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="juice" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="23" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="ice" type="NP">
          <tokens>
            <token id="21" string="ice" />
          </tokens>
        </chunking>
        <chunking id="12" string="them" type="NP">
          <tokens>
            <token id="13" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="samples" type="NP">
          <tokens>
            <token id="32" string="samples" />
          </tokens>
        </chunking>
        <chunking id="14" string="to take that minnow bucket" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="take" />
            <token id="16" string="that" />
            <token id="17" string="minnow" />
            <token id="18" string="bucket" />
          </tokens>
        </chunking>
        <chunking id="15" string="take that minnow bucket" type="VP">
          <tokens>
            <token id="15" string="take" />
            <token id="16" string="that" />
            <token id="17" string="minnow" />
            <token id="18" string="bucket" />
          </tokens>
        </chunking>
        <chunking id="16" string="put ice in it , ice down the juice and give away samples out of his minnow bucket" type="VP">
          <tokens>
            <token id="20" string="put" />
            <token id="21" string="ice" />
            <token id="22" string="in" />
            <token id="23" string="it" />
            <token id="24" string="," />
            <token id="25" string="ice" />
            <token id="26" string="down" />
            <token id="27" string="the" />
            <token id="28" string="juice" />
            <token id="29" string="and" />
            <token id="30" string="give" />
            <token id="31" string="away" />
            <token id="32" string="samples" />
            <token id="33" string="out" />
            <token id="34" string="of" />
            <token id="35" string="his" />
            <token id="36" string="minnow" />
            <token id="37" string="bucket" />
          </tokens>
        </chunking>
        <chunking id="17" string="that minnow bucket" type="NP">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="minnow" />
            <token id="18" string="bucket" />
          </tokens>
        </chunking>
        <chunking id="18" string="go down to the stores , and get them to take that minnow bucket" type="VP">
          <tokens>
            <token id="5" string="go" />
            <token id="6" string="down" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="stores" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="get" />
            <token id="13" string="them" />
            <token id="14" string="to" />
            <token id="15" string="take" />
            <token id="16" string="that" />
            <token id="17" string="minnow" />
            <token id="18" string="bucket" />
          </tokens>
        </chunking>
        <chunking id="19" string="would go down to the stores , and get them to take that minnow bucket" type="VP">
          <tokens>
            <token id="4" string="would" />
            <token id="5" string="go" />
            <token id="6" string="down" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="stores" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="get" />
            <token id="13" string="them" />
            <token id="14" string="to" />
            <token id="15" string="take" />
            <token id="16" string="that" />
            <token id="17" string="minnow" />
            <token id="18" string="bucket" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="5">go</governor>
          <dependent id="2">So</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">go</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">go</governor>
          <dependent id="4">would</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">go</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">go</governor>
          <dependent id="6">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">stores</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">stores</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">down</governor>
          <dependent id="9">stores</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">go</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">go</governor>
          <dependent id="12">get</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">get</governor>
          <dependent id="13">them</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">take</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">get</governor>
          <dependent id="15">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">bucket</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">bucket</governor>
          <dependent id="17">minnow</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">take</governor>
          <dependent id="18">bucket</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="5">go</governor>
          <dependent id="20">put</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">put</governor>
          <dependent id="21">ice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">it</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">put</governor>
          <dependent id="23">it</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="23">it</governor>
          <dependent id="25">ice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">juice</governor>
          <dependent id="26">down</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">juice</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">put</governor>
          <dependent id="28">juice</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">put</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">put</governor>
          <dependent id="30">give</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="30">give</governor>
          <dependent id="31">away</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">give</governor>
          <dependent id="32">samples</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">bucket</governor>
          <dependent id="33">out</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="33">out</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="37">bucket</governor>
          <dependent id="35">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">bucket</governor>
          <dependent id="36">minnow</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">give</governor>
          <dependent id="37">bucket</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>I particularly did it in stores I knew (Sam) was going to visit.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="particularly" lemma="particularly" stem="particularli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="stores" lemma="store" stem="store" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="visit" lemma="visit" stem="visit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (ADVP (RB particularly)) (VP (VBD did) (NP (PRP it)) (PP (IN in) (NP (NP (NNS stores)) (SBAR (S (NP (PRP I)) (VP (VBD knew) (SBAR (S (-LRB- -LRB-) (NP (NNP Sam)) (-RRB- -RRB-) (VP (VBD was) (VP (VBG going) (S (VP (TO to) (VP (VB visit)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to visit" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="visit" />
          </tokens>
        </chunking>
        <chunking id="2" string="going to visit" type="VP">
          <tokens>
            <token id="13" string="going" />
            <token id="14" string="to" />
            <token id="15" string="visit" />
          </tokens>
        </chunking>
        <chunking id="3" string="stores" type="NP">
          <tokens>
            <token id="6" string="stores" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="knew -LRB- Sam -RRB- was going to visit" type="VP">
          <tokens>
            <token id="8" string="knew" />
            <token id="9" string="(" />
            <token id="10" string="Sam" />
            <token id="11" string=")" />
            <token id="12" string="was" />
            <token id="13" string="going" />
            <token id="14" string="to" />
            <token id="15" string="visit" />
          </tokens>
        </chunking>
        <chunking id="7" string="stores I knew -LRB- Sam -RRB- was going to visit" type="NP">
          <tokens>
            <token id="6" string="stores" />
            <token id="7" string="I" />
            <token id="8" string="knew" />
            <token id="9" string="(" />
            <token id="10" string="Sam" />
            <token id="11" string=")" />
            <token id="12" string="was" />
            <token id="13" string="going" />
            <token id="14" string="to" />
            <token id="15" string="visit" />
          </tokens>
        </chunking>
        <chunking id="8" string="-LRB- Sam -RRB- was going to visit" type="SBAR">
          <tokens>
            <token id="9" string="(" />
            <token id="10" string="Sam" />
            <token id="11" string=")" />
            <token id="12" string="was" />
            <token id="13" string="going" />
            <token id="14" string="to" />
            <token id="15" string="visit" />
          </tokens>
        </chunking>
        <chunking id="9" string="was going to visit" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="going" />
            <token id="14" string="to" />
            <token id="15" string="visit" />
          </tokens>
        </chunking>
        <chunking id="10" string="did it in stores I knew -LRB- Sam -RRB- was going to visit" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="it" />
            <token id="5" string="in" />
            <token id="6" string="stores" />
            <token id="7" string="I" />
            <token id="8" string="knew" />
            <token id="9" string="(" />
            <token id="10" string="Sam" />
            <token id="11" string=")" />
            <token id="12" string="was" />
            <token id="13" string="going" />
            <token id="14" string="to" />
            <token id="15" string="visit" />
          </tokens>
        </chunking>
        <chunking id="11" string="visit" type="VP">
          <tokens>
            <token id="15" string="visit" />
          </tokens>
        </chunking>
        <chunking id="12" string="I knew -LRB- Sam -RRB- was going to visit" type="SBAR">
          <tokens>
            <token id="7" string="I" />
            <token id="8" string="knew" />
            <token id="9" string="(" />
            <token id="10" string="Sam" />
            <token id="11" string=")" />
            <token id="12" string="was" />
            <token id="13" string="going" />
            <token id="14" string="to" />
            <token id="15" string="visit" />
          </tokens>
        </chunking>
        <chunking id="13" string="Sam" type="NP">
          <tokens>
            <token id="10" string="Sam" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">did</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">did</governor>
          <dependent id="2">particularly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">did</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">stores</governor>
          <dependent id="5">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">did</governor>
          <dependent id="6">stores</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">knew</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">stores</governor>
          <dependent id="8">knew</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">going</governor>
          <dependent id="10">Sam</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">going</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">knew</governor>
          <dependent id="13">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">visit</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">going</governor>
          <dependent id="15">visit</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sam" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Sam" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>It drove him crazy, and he got off that minnow bucket pretty quick . . . .&amp;apost; But the reader can&amp;apost;t help feeling that the cosy yarns tell only half the truth.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="drove" lemma="drive" stem="drove" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="crazy" lemma="crazy" stem="crazi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="off" lemma="off" stem="off" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="minnow" lemma="minnow" stem="minnow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="bucket" lemma="bucket" stem="bucket" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="pretty" lemma="pretty" stem="pretti" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="quick" lemma="quick" stem="quick" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string=". . . ." lemma="..." stem=". . . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="reader" lemma="reader" stem="reader" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="help" lemma="help" stem="help" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="feeling" lemma="feeling" stem="feel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="cosy" lemma="cosy" stem="cosi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="yarns" lemma="yarn" stem="yarn" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="tell" lemma="tell" stem="tell" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="half" lemma="half" stem="half" pos="PDT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="truth" lemma="truth" stem="truth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (NP (PRP It)) (VP (VBD drove) (S (NP (PRP him)) (ADJP (JJ crazy))))) (, ,) (CC and) (S (NP (PRP he)) (VP (VBD got) (PRT (RP off)) (NP (NP (DT that) (NN minnow) (NN bucket)) (ADJP (RB pretty) (JJ quick)))))) (: ...) ('' ') (S (CC But) (NP (DT the) (NN reader)) (VP (MD ca) (RB n't) (VP (VB help) (NP (NN feeling)) (SBAR (IN that) (S (NP (DT the) (JJ cosy) (NNS yarns)) (VP (VBP tell) (NP (QP (RB only) (PDT half)) (DT the) (NN truth)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that minnow bucket pretty quick" type="NP">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="minnow" />
            <token id="12" string="bucket" />
            <token id="13" string="pretty" />
            <token id="14" string="quick" />
          </tokens>
        </chunking>
        <chunking id="2" string="the reader" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="reader" />
          </tokens>
        </chunking>
        <chunking id="3" string="that the cosy yarns tell only half the truth" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="the" />
            <token id="26" string="cosy" />
            <token id="27" string="yarns" />
            <token id="28" string="tell" />
            <token id="29" string="only" />
            <token id="30" string="half" />
            <token id="31" string="the" />
            <token id="32" string="truth" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="3" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="drove him crazy" type="VP">
          <tokens>
            <token id="2" string="drove" />
            <token id="3" string="him" />
            <token id="4" string="crazy" />
          </tokens>
        </chunking>
        <chunking id="7" string="got off that minnow bucket pretty quick" type="VP">
          <tokens>
            <token id="8" string="got" />
            <token id="9" string="off" />
            <token id="10" string="that" />
            <token id="11" string="minnow" />
            <token id="12" string="bucket" />
            <token id="13" string="pretty" />
            <token id="14" string="quick" />
          </tokens>
        </chunking>
        <chunking id="8" string="help feeling that the cosy yarns tell only half the truth" type="VP">
          <tokens>
            <token id="22" string="help" />
            <token id="23" string="feeling" />
            <token id="24" string="that" />
            <token id="25" string="the" />
            <token id="26" string="cosy" />
            <token id="27" string="yarns" />
            <token id="28" string="tell" />
            <token id="29" string="only" />
            <token id="30" string="half" />
            <token id="31" string="the" />
            <token id="32" string="truth" />
          </tokens>
        </chunking>
        <chunking id="9" string="the cosy yarns" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="cosy" />
            <token id="27" string="yarns" />
          </tokens>
        </chunking>
        <chunking id="10" string="feeling" type="NP">
          <tokens>
            <token id="23" string="feeling" />
          </tokens>
        </chunking>
        <chunking id="11" string="pretty quick" type="ADJP">
          <tokens>
            <token id="13" string="pretty" />
            <token id="14" string="quick" />
          </tokens>
        </chunking>
        <chunking id="12" string="that minnow bucket" type="NP">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="minnow" />
            <token id="12" string="bucket" />
          </tokens>
        </chunking>
        <chunking id="13" string="crazy" type="ADJP">
          <tokens>
            <token id="4" string="crazy" />
          </tokens>
        </chunking>
        <chunking id="14" string="ca n't help feeling that the cosy yarns tell only half the truth" type="VP">
          <tokens>
            <token id="20" string="ca" />
            <token id="21" string="n't" />
            <token id="22" string="help" />
            <token id="23" string="feeling" />
            <token id="24" string="that" />
            <token id="25" string="the" />
            <token id="26" string="cosy" />
            <token id="27" string="yarns" />
            <token id="28" string="tell" />
            <token id="29" string="only" />
            <token id="30" string="half" />
            <token id="31" string="the" />
            <token id="32" string="truth" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="tell only half the truth" type="VP">
          <tokens>
            <token id="28" string="tell" />
            <token id="29" string="only" />
            <token id="30" string="half" />
            <token id="31" string="the" />
            <token id="32" string="truth" />
          </tokens>
        </chunking>
        <chunking id="17" string="only half the truth" type="NP">
          <tokens>
            <token id="29" string="only" />
            <token id="30" string="half" />
            <token id="31" string="the" />
            <token id="32" string="truth" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">drove</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">drove</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">crazy</governor>
          <dependent id="3">him</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">drove</governor>
          <dependent id="4">crazy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">drove</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">got</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">drove</governor>
          <dependent id="8">got</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">got</governor>
          <dependent id="9">off</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">bucket</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">bucket</governor>
          <dependent id="11">minnow</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">got</governor>
          <dependent id="12">bucket</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">quick</governor>
          <dependent id="13">pretty</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">bucket</governor>
          <dependent id="14">quick</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="22">help</governor>
          <dependent id="17">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">reader</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">help</governor>
          <dependent id="19">reader</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">help</governor>
          <dependent id="20">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="22">help</governor>
          <dependent id="21">n't</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">drove</governor>
          <dependent id="22">help</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">help</governor>
          <dependent id="23">feeling</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">tell</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">yarns</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">yarns</governor>
          <dependent id="26">cosy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">tell</governor>
          <dependent id="27">yarns</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="22">help</governor>
          <dependent id="28">tell</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">half</governor>
          <dependent id="29">only</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="32">truth</governor>
          <dependent id="30">half</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">truth</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">tell</governor>
          <dependent id="32">truth</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Sam Walton was a salesman to the core, and seems to have packaged himself with all the skill that he once applied to selling a gooey southern sweet called Moon Pies.</content>
      <tokens>
        <token id="1" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="salesman" lemma="salesman" stem="salesman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="core" lemma="core" stem="core" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="packaged" lemma="package" stem="packag" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="skill" lemma="skill" stem="skill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="applied" lemma="apply" stem="appli" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="selling" lemma="sell" stem="sell" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="gooey" lemma="gooey" stem="gooei" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="southern" lemma="southern" stem="southern" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="sweet" lemma="sweet" stem="sweet" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="Moon" lemma="Moon" stem="moon" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="Pies" lemma="Pies" stem="pi" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Sam) (NNP Walton)) (VP (VP (VBD was) (NP (DT a) (NN salesman)) (PP (TO to) (NP (DT the) (NN core)))) (, ,) (CC and) (VP (VBZ seems) (S (VP (TO to) (VP (VB have) (VP (VBN packaged) (NP (PRP himself)) (PP (IN with) (NP (PDT all) (DT the) (NN skill))))))) (SBAR (IN that) (S (NP (PRP he)) (ADVP (RB once)) (VP (VBD applied) (PP (TO to) (S (VP (VBG selling) (S (NP (DT a) (JJ gooey) (JJ southern)) (ADJP (JJ sweet)) (S (VP (VBN called) (NP (NNP Moon) (NNPS Pies))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was a salesman to the core" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="salesman" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="core" />
          </tokens>
        </chunking>
        <chunking id="2" string="packaged himself with all the skill" type="VP">
          <tokens>
            <token id="14" string="packaged" />
            <token id="15" string="himself" />
            <token id="16" string="with" />
            <token id="17" string="all" />
            <token id="18" string="the" />
            <token id="19" string="skill" />
          </tokens>
        </chunking>
        <chunking id="3" string="sweet" type="ADJP">
          <tokens>
            <token id="29" string="sweet" />
          </tokens>
        </chunking>
        <chunking id="4" string="called Moon Pies" type="VP">
          <tokens>
            <token id="30" string="called" />
            <token id="31" string="Moon" />
            <token id="32" string="Pies" />
          </tokens>
        </chunking>
        <chunking id="5" string="to have packaged himself with all the skill" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="have" />
            <token id="14" string="packaged" />
            <token id="15" string="himself" />
            <token id="16" string="with" />
            <token id="17" string="all" />
            <token id="18" string="the" />
            <token id="19" string="skill" />
          </tokens>
        </chunking>
        <chunking id="6" string="Moon Pies" type="NP">
          <tokens>
            <token id="31" string="Moon" />
            <token id="32" string="Pies" />
          </tokens>
        </chunking>
        <chunking id="7" string="that he once applied to selling a gooey southern sweet called Moon Pies" type="SBAR">
          <tokens>
            <token id="20" string="that" />
            <token id="21" string="he" />
            <token id="22" string="once" />
            <token id="23" string="applied" />
            <token id="24" string="to" />
            <token id="25" string="selling" />
            <token id="26" string="a" />
            <token id="27" string="gooey" />
            <token id="28" string="southern" />
            <token id="29" string="sweet" />
            <token id="30" string="called" />
            <token id="31" string="Moon" />
            <token id="32" string="Pies" />
          </tokens>
        </chunking>
        <chunking id="8" string="a gooey southern" type="NP">
          <tokens>
            <token id="26" string="a" />
            <token id="27" string="gooey" />
            <token id="28" string="southern" />
          </tokens>
        </chunking>
        <chunking id="9" string="Sam Walton" type="NP">
          <tokens>
            <token id="1" string="Sam" />
            <token id="2" string="Walton" />
          </tokens>
        </chunking>
        <chunking id="10" string="the core" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="core" />
          </tokens>
        </chunking>
        <chunking id="11" string="have packaged himself with all the skill" type="VP">
          <tokens>
            <token id="13" string="have" />
            <token id="14" string="packaged" />
            <token id="15" string="himself" />
            <token id="16" string="with" />
            <token id="17" string="all" />
            <token id="18" string="the" />
            <token id="19" string="skill" />
          </tokens>
        </chunking>
        <chunking id="12" string="all the skill" type="NP">
          <tokens>
            <token id="17" string="all" />
            <token id="18" string="the" />
            <token id="19" string="skill" />
          </tokens>
        </chunking>
        <chunking id="13" string="a salesman" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="salesman" />
          </tokens>
        </chunking>
        <chunking id="14" string="seems to have packaged himself with all the skill that he once applied to selling a gooey southern sweet called Moon Pies" type="VP">
          <tokens>
            <token id="11" string="seems" />
            <token id="12" string="to" />
            <token id="13" string="have" />
            <token id="14" string="packaged" />
            <token id="15" string="himself" />
            <token id="16" string="with" />
            <token id="17" string="all" />
            <token id="18" string="the" />
            <token id="19" string="skill" />
            <token id="20" string="that" />
            <token id="21" string="he" />
            <token id="22" string="once" />
            <token id="23" string="applied" />
            <token id="24" string="to" />
            <token id="25" string="selling" />
            <token id="26" string="a" />
            <token id="27" string="gooey" />
            <token id="28" string="southern" />
            <token id="29" string="sweet" />
            <token id="30" string="called" />
            <token id="31" string="Moon" />
            <token id="32" string="Pies" />
          </tokens>
        </chunking>
        <chunking id="15" string="applied to selling a gooey southern sweet called Moon Pies" type="VP">
          <tokens>
            <token id="23" string="applied" />
            <token id="24" string="to" />
            <token id="25" string="selling" />
            <token id="26" string="a" />
            <token id="27" string="gooey" />
            <token id="28" string="southern" />
            <token id="29" string="sweet" />
            <token id="30" string="called" />
            <token id="31" string="Moon" />
            <token id="32" string="Pies" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="21" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="was a salesman to the core , and seems to have packaged himself with all the skill that he once applied to selling a gooey southern sweet called Moon Pies" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="salesman" />
            <token id="6" string="to" />
            <token id="7" string="the" />
            <token id="8" string="core" />
            <token id="9" string="," />
            <token id="10" string="and" />
            <token id="11" string="seems" />
            <token id="12" string="to" />
            <token id="13" string="have" />
            <token id="14" string="packaged" />
            <token id="15" string="himself" />
            <token id="16" string="with" />
            <token id="17" string="all" />
            <token id="18" string="the" />
            <token id="19" string="skill" />
            <token id="20" string="that" />
            <token id="21" string="he" />
            <token id="22" string="once" />
            <token id="23" string="applied" />
            <token id="24" string="to" />
            <token id="25" string="selling" />
            <token id="26" string="a" />
            <token id="27" string="gooey" />
            <token id="28" string="southern" />
            <token id="29" string="sweet" />
            <token id="30" string="called" />
            <token id="31" string="Moon" />
            <token id="32" string="Pies" />
          </tokens>
        </chunking>
        <chunking id="18" string="himself" type="NP">
          <tokens>
            <token id="15" string="himself" />
          </tokens>
        </chunking>
        <chunking id="19" string="selling a gooey southern sweet called Moon Pies" type="VP">
          <tokens>
            <token id="25" string="selling" />
            <token id="26" string="a" />
            <token id="27" string="gooey" />
            <token id="28" string="southern" />
            <token id="29" string="sweet" />
            <token id="30" string="called" />
            <token id="31" string="Moon" />
            <token id="32" string="Pies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Walton</governor>
          <dependent id="1">Sam</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">salesman</governor>
          <dependent id="2">Walton</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">salesman</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">salesman</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">salesman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">core</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">core</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">salesman</governor>
          <dependent id="8">core</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">salesman</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">salesman</governor>
          <dependent id="11">seems</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">packaged</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">packaged</governor>
          <dependent id="13">have</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">seems</governor>
          <dependent id="14">packaged</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">packaged</governor>
          <dependent id="15">himself</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">skill</governor>
          <dependent id="16">with</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="19">skill</governor>
          <dependent id="17">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">skill</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">packaged</governor>
          <dependent id="19">skill</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">applied</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">applied</governor>
          <dependent id="21">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">applied</governor>
          <dependent id="22">once</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">seems</governor>
          <dependent id="23">applied</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">selling</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">applied</governor>
          <dependent id="25">selling</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">southern</governor>
          <dependent id="26">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">southern</governor>
          <dependent id="27">gooey</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">called</governor>
          <dependent id="28">southern</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="30">called</governor>
          <dependent id="29">sweet</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">selling</governor>
          <dependent id="30">called</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Pies</governor>
          <dependent id="31">Moon</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">called</governor>
          <dependent id="32">Pies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="once" />
          </tokens>
        </entity>
        <entity id="2" string="Sam Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Sam" />
            <token id="2" string="Walton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>For the most part, this makes for an engaging, if one-dimensional, portrait.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="engaging" lemma="engaging" stem="engag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="one-dimensional" lemma="one-dimensional" stem="one-dimension" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="portrait" lemma="portrait" stem="portrait" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (DT the) (JJS most) (NN part))) (, ,) (NP (DT this)) (VP (VBZ makes) (PP (IN for) (NP (DT an) (ADJP (JJ engaging) (, ,) (IN if) (JJ one-dimensional) (, ,)) (NN portrait)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="makes for an engaging , if one-dimensional , portrait" type="VP">
          <tokens>
            <token id="7" string="makes" />
            <token id="8" string="for" />
            <token id="9" string="an" />
            <token id="10" string="engaging" />
            <token id="11" string="," />
            <token id="12" string="if" />
            <token id="13" string="one-dimensional" />
            <token id="14" string="," />
            <token id="15" string="portrait" />
          </tokens>
        </chunking>
        <chunking id="2" string="an engaging , if one-dimensional , portrait" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="engaging" />
            <token id="11" string="," />
            <token id="12" string="if" />
            <token id="13" string="one-dimensional" />
            <token id="14" string="," />
            <token id="15" string="portrait" />
          </tokens>
        </chunking>
        <chunking id="3" string="engaging , if one-dimensional ," type="ADJP">
          <tokens>
            <token id="10" string="engaging" />
            <token id="11" string="," />
            <token id="12" string="if" />
            <token id="13" string="one-dimensional" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="this" type="NP">
          <tokens>
            <token id="6" string="this" />
          </tokens>
        </chunking>
        <chunking id="5" string="the most part" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="most" />
            <token id="4" string="part" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">part</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">part</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">part</governor>
          <dependent id="3">most</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">makes</governor>
          <dependent id="4">part</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">makes</governor>
          <dependent id="6">this</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">makes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">portrait</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">portrait</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">one-dimensional</governor>
          <dependent id="10">engaging</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="13">one-dimensional</governor>
          <dependent id="12">if</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">portrait</governor>
          <dependent id="13">one-dimensional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">makes</governor>
          <dependent id="15">portrait</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Occasionally, it just grates. &amp;apost;</content>
      <tokens>
        <token id="1" string="Occasionally" lemma="occasionally" stem="occasion" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="grates" lemma="grate" stem="grate" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Occasionally)) (, ,) (NP (PRP it)) (ADVP (RB just)) (VP (VBZ grates)) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="2" string="grates" type="VP">
          <tokens>
            <token id="5" string="grates" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">grates</governor>
          <dependent id="1">Occasionally</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">grates</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">grates</governor>
          <dependent id="4">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">grates</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>I had bought a bank in Bentonville, for about about Dollars 300,000,&amp;apost; Walton remarks, for example, &amp;apost;just a little old bank with only about Dollars 3.5m in deposits.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="bought" lemma="buy" stem="bought" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="bank" lemma="bank" stem="bank" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Bentonville" lemma="Bentonville" stem="bentonvil" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Dollars" lemma="Dollars" stem="dollar" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="300,000" lemma="300,000" stem="300,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="remarks" lemma="remark" stem="remark" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="bank" lemma="bank" stem="bank" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Dollars" lemma="Dollars" stem="dollar" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="3.5" lemma="3.5" stem="3.5" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="33" string="m" lemma="m" stem="m" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="deposits" lemma="deposit" stem="deposit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD had) (VP (VBN bought) (NP (DT a) (NN bank)) (PP (IN in) (NP (NNP Bentonville))) (, ,) (PP (IN for) (IN about) (NP (NP (NP (RB about) (NNPS Dollars)) (NP (CD 300,000)) (, ,) ('' ')) (NP (NNP Walton) (NNS remarks)) (, ,) (PP (IN for) (NP (NP (NN example)) (, ,) (NP (NP (`` `) (RB just) (DT a) (JJ little) (JJ old) (NN bank)) (PP (IN with) (NP (NP (ADVP (RB only) (PP (IN about) (NP (NNP Dollars) (CD 3.5)))) (NN m)) (PP (IN in) (NP (NNS deposits)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="about Dollars 300,000 , ' Walton remarks , for example , ` just a little old bank with only about Dollars 3.5 m in deposits" type="NP">
          <tokens>
            <token id="11" string="about" />
            <token id="12" string="Dollars" />
            <token id="13" string="300,000" />
            <token id="14" string="," />
            <token id="15" string="'" />
            <token id="16" string="Walton" />
            <token id="17" string="remarks" />
            <token id="18" string="," />
            <token id="19" string="for" />
            <token id="20" string="example" />
            <token id="21" string="," />
            <token id="22" string="'" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="little" />
            <token id="26" string="old" />
            <token id="27" string="bank" />
            <token id="28" string="with" />
            <token id="29" string="only" />
            <token id="30" string="about" />
            <token id="31" string="Dollars" />
            <token id="32" string="3.5" />
            <token id="33" string="m" />
            <token id="34" string="in" />
            <token id="35" string="deposits" />
          </tokens>
        </chunking>
        <chunking id="2" string="` just a little old bank" type="NP">
          <tokens>
            <token id="22" string="'" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="little" />
            <token id="26" string="old" />
            <token id="27" string="bank" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="300,000" type="NP">
          <tokens>
            <token id="13" string="300,000" />
          </tokens>
        </chunking>
        <chunking id="5" string="Walton remarks" type="NP">
          <tokens>
            <token id="16" string="Walton" />
            <token id="17" string="remarks" />
          </tokens>
        </chunking>
        <chunking id="6" string="only about Dollars 3.5 m in deposits" type="NP">
          <tokens>
            <token id="29" string="only" />
            <token id="30" string="about" />
            <token id="31" string="Dollars" />
            <token id="32" string="3.5" />
            <token id="33" string="m" />
            <token id="34" string="in" />
            <token id="35" string="deposits" />
          </tokens>
        </chunking>
        <chunking id="7" string="example" type="NP">
          <tokens>
            <token id="20" string="example" />
          </tokens>
        </chunking>
        <chunking id="8" string="a bank" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="bank" />
          </tokens>
        </chunking>
        <chunking id="9" string="only about Dollars 3.5 m" type="NP">
          <tokens>
            <token id="29" string="only" />
            <token id="30" string="about" />
            <token id="31" string="Dollars" />
            <token id="32" string="3.5" />
            <token id="33" string="m" />
          </tokens>
        </chunking>
        <chunking id="10" string="Dollars 3.5" type="NP">
          <tokens>
            <token id="31" string="Dollars" />
            <token id="32" string="3.5" />
          </tokens>
        </chunking>
        <chunking id="11" string="had bought a bank in Bentonville , for about about Dollars 300,000 , ' Walton remarks , for example , ` just a little old bank with only about Dollars 3.5 m in deposits" type="VP">
          <tokens>
            <token id="2" string="had" />
            <token id="3" string="bought" />
            <token id="4" string="a" />
            <token id="5" string="bank" />
            <token id="6" string="in" />
            <token id="7" string="Bentonville" />
            <token id="8" string="," />
            <token id="9" string="for" />
            <token id="10" string="about" />
            <token id="11" string="about" />
            <token id="12" string="Dollars" />
            <token id="13" string="300,000" />
            <token id="14" string="," />
            <token id="15" string="'" />
            <token id="16" string="Walton" />
            <token id="17" string="remarks" />
            <token id="18" string="," />
            <token id="19" string="for" />
            <token id="20" string="example" />
            <token id="21" string="," />
            <token id="22" string="'" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="little" />
            <token id="26" string="old" />
            <token id="27" string="bank" />
            <token id="28" string="with" />
            <token id="29" string="only" />
            <token id="30" string="about" />
            <token id="31" string="Dollars" />
            <token id="32" string="3.5" />
            <token id="33" string="m" />
            <token id="34" string="in" />
            <token id="35" string="deposits" />
          </tokens>
        </chunking>
        <chunking id="12" string="bought a bank in Bentonville , for about about Dollars 300,000 , ' Walton remarks , for example , ` just a little old bank with only about Dollars 3.5 m in deposits" type="VP">
          <tokens>
            <token id="3" string="bought" />
            <token id="4" string="a" />
            <token id="5" string="bank" />
            <token id="6" string="in" />
            <token id="7" string="Bentonville" />
            <token id="8" string="," />
            <token id="9" string="for" />
            <token id="10" string="about" />
            <token id="11" string="about" />
            <token id="12" string="Dollars" />
            <token id="13" string="300,000" />
            <token id="14" string="," />
            <token id="15" string="'" />
            <token id="16" string="Walton" />
            <token id="17" string="remarks" />
            <token id="18" string="," />
            <token id="19" string="for" />
            <token id="20" string="example" />
            <token id="21" string="," />
            <token id="22" string="'" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="little" />
            <token id="26" string="old" />
            <token id="27" string="bank" />
            <token id="28" string="with" />
            <token id="29" string="only" />
            <token id="30" string="about" />
            <token id="31" string="Dollars" />
            <token id="32" string="3.5" />
            <token id="33" string="m" />
            <token id="34" string="in" />
            <token id="35" string="deposits" />
          </tokens>
        </chunking>
        <chunking id="13" string="about Dollars 300,000 , '" type="NP">
          <tokens>
            <token id="11" string="about" />
            <token id="12" string="Dollars" />
            <token id="13" string="300,000" />
            <token id="14" string="," />
            <token id="15" string="'" />
          </tokens>
        </chunking>
        <chunking id="14" string="deposits" type="NP">
          <tokens>
            <token id="35" string="deposits" />
          </tokens>
        </chunking>
        <chunking id="15" string="example , ` just a little old bank with only about Dollars 3.5 m in deposits" type="NP">
          <tokens>
            <token id="20" string="example" />
            <token id="21" string="," />
            <token id="22" string="'" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="little" />
            <token id="26" string="old" />
            <token id="27" string="bank" />
            <token id="28" string="with" />
            <token id="29" string="only" />
            <token id="30" string="about" />
            <token id="31" string="Dollars" />
            <token id="32" string="3.5" />
            <token id="33" string="m" />
            <token id="34" string="in" />
            <token id="35" string="deposits" />
          </tokens>
        </chunking>
        <chunking id="16" string="Bentonville" type="NP">
          <tokens>
            <token id="7" string="Bentonville" />
          </tokens>
        </chunking>
        <chunking id="17" string="about Dollars" type="NP">
          <tokens>
            <token id="11" string="about" />
            <token id="12" string="Dollars" />
          </tokens>
        </chunking>
        <chunking id="18" string="` just a little old bank with only about Dollars 3.5 m in deposits" type="NP">
          <tokens>
            <token id="22" string="'" />
            <token id="23" string="just" />
            <token id="24" string="a" />
            <token id="25" string="little" />
            <token id="26" string="old" />
            <token id="27" string="bank" />
            <token id="28" string="with" />
            <token id="29" string="only" />
            <token id="30" string="about" />
            <token id="31" string="Dollars" />
            <token id="32" string="3.5" />
            <token id="33" string="m" />
            <token id="34" string="in" />
            <token id="35" string="deposits" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">bought</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">bought</governor>
          <dependent id="2">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">bought</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">bank</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">bought</governor>
          <dependent id="5">bank</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Bentonville</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">bought</governor>
          <dependent id="7">Bentonville</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Dollars</governor>
          <dependent id="9">for</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Dollars</governor>
          <dependent id="10">about</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">Dollars</governor>
          <dependent id="11">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">bought</governor>
          <dependent id="12">Dollars</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">Dollars</governor>
          <dependent id="13">300,000</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">remarks</governor>
          <dependent id="16">Walton</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">Dollars</governor>
          <dependent id="17">remarks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">example</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">Dollars</governor>
          <dependent id="20">example</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">bank</governor>
          <dependent id="23">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">bank</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">bank</governor>
          <dependent id="25">little</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">bank</governor>
          <dependent id="26">old</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="20">example</governor>
          <dependent id="27">bank</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">m</governor>
          <dependent id="28">with</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="33">m</governor>
          <dependent id="29">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Dollars</governor>
          <dependent id="30">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">only</governor>
          <dependent id="31">Dollars</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="31">Dollars</governor>
          <dependent id="32">3.5</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">bank</governor>
          <dependent id="33">m</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">deposits</governor>
          <dependent id="34">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">m</governor>
          <dependent id="35">deposits</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Bentonville" type="LOCATION" score="0.0">
          <tokens>
            <token id="7" string="Bentonville" />
          </tokens>
        </entity>
        <entity id="2" string="300,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="300,000" />
          </tokens>
        </entity>
        <entity id="3" string="3.5" type="NUMBER" score="0.0">
          <tokens>
            <token id="32" string="3.5" />
          </tokens>
        </entity>
        <entity id="4" string="Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="16" string="Walton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>But it helped me learn a lot about financing things.&amp;apost;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="helped" lemma="help" stem="help" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="learn" lemma="learn" stem="learn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="financing" lemma="finance" stem="financ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP it)) (VP (VBD helped) (S (NP (PRP me)) (VP (VB learn) (NP (NP (DT a) (NN lot)) (PP (IN about) (NP (VBG financing) (NNS things))))))) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="financing things" type="NP">
          <tokens>
            <token id="9" string="financing" />
            <token id="10" string="things" />
          </tokens>
        </chunking>
        <chunking id="2" string="a lot" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="lot" />
          </tokens>
        </chunking>
        <chunking id="3" string="me" type="NP">
          <tokens>
            <token id="4" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="helped me learn a lot about financing things" type="VP">
          <tokens>
            <token id="3" string="helped" />
            <token id="4" string="me" />
            <token id="5" string="learn" />
            <token id="6" string="a" />
            <token id="7" string="lot" />
            <token id="8" string="about" />
            <token id="9" string="financing" />
            <token id="10" string="things" />
          </tokens>
        </chunking>
        <chunking id="6" string="learn a lot about financing things" type="VP">
          <tokens>
            <token id="5" string="learn" />
            <token id="6" string="a" />
            <token id="7" string="lot" />
            <token id="8" string="about" />
            <token id="9" string="financing" />
            <token id="10" string="things" />
          </tokens>
        </chunking>
        <chunking id="7" string="a lot about financing things" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="lot" />
            <token id="8" string="about" />
            <token id="9" string="financing" />
            <token id="10" string="things" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">helped</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">helped</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">helped</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">learn</governor>
          <dependent id="4">me</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">helped</governor>
          <dependent id="5">learn</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">lot</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">learn</governor>
          <dependent id="7">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">things</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">things</governor>
          <dependent id="9">financing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">lot</governor>
          <dependent id="10">things</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Oh, come on Sam, is that the whole story?</content>
      <tokens>
        <token id="1" string="Oh" lemma="oh" stem="oh" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="come" lemma="come" stem="come" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="whole" lemma="whole" stem="whole" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (INTJ (UH Oh)) (, ,) (S (VP (VBN come) (PP (IN on) (NP (NNP Sam))))) (, ,) (VP (VBZ is) (ADVP (IN that)) (NP (DT the) (JJ whole) (NN story)))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is that the whole story" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="that" />
            <token id="9" string="the" />
            <token id="10" string="whole" />
            <token id="11" string="story" />
          </tokens>
        </chunking>
        <chunking id="2" string="come on Sam" type="VP">
          <tokens>
            <token id="3" string="come" />
            <token id="4" string="on" />
            <token id="5" string="Sam" />
          </tokens>
        </chunking>
        <chunking id="3" string="the whole story" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="whole" />
            <token id="11" string="story" />
          </tokens>
        </chunking>
        <chunking id="4" string="Sam" type="NP">
          <tokens>
            <token id="5" string="Sam" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="discourse">
          <governor id="11">story</governor>
          <dependent id="1">Oh</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">story</governor>
          <dependent id="3">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Sam</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">come</governor>
          <dependent id="5">Sam</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">story</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">story</governor>
          <dependent id="8">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">story</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">story</governor>
          <dependent id="10">whole</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">story</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sam" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Sam" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>The real truth, one suspects, comes right at the end of the book - when Walton admits that &amp;apost;if I hadn&amp;apost;t gotten sick, I doubt I would have written this book&amp;apost;.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="real" lemma="real" stem="real" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="truth" lemma="truth" stem="truth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="suspects" lemma="suspect" stem="suspect" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="right" lemma="right" stem="right" pos="RB" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="10" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="admits" lemma="admit" stem="admit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="gotten" lemma="get" stem="gotten" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="sick" lemma="sick" stem="sick" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="doubt" lemma="doubt" stem="doubt" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="written" lemma="write" stem="written" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (JJ real) (NN truth)) (, ,) (NP (CD one) (NNS suspects)) (, ,)) (VP (VBZ comes) (ADVP (RB right)) (PP (IN at) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (DT the) (NN book))) (PRN (: -) (SBAR (WHADVP (WRB when)) (S (NP (NNP Walton)) (VP (VBZ admits) (ADVP (IN that)))))) (`` `) (S (SBAR (IN if) (S (NP (PRP I)) (VP (VBD had) (RB n't) (VP (VBN gotten) (S (ADJP (JJ sick))))))) (, ,) (NP (PRP I)) (VP (VBP doubt) (SBAR (S (NP (PRP I)) (VP (MD would) (VP (VB have) (VP (VBN written) (NP (DT this) (NN book)))))))) ('' '))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="would have written this book" type="VP">
          <tokens>
            <token id="32" string="would" />
            <token id="33" string="have" />
            <token id="34" string="written" />
            <token id="35" string="this" />
            <token id="36" string="book" />
          </tokens>
        </chunking>
        <chunking id="2" string="the end" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="end" />
          </tokens>
        </chunking>
        <chunking id="3" string="comes right at the end of the book - when Walton admits that ` if I had n't gotten sick , I doubt I would have written this book '" type="VP">
          <tokens>
            <token id="8" string="comes" />
            <token id="9" string="right" />
            <token id="10" string="at" />
            <token id="11" string="the" />
            <token id="12" string="end" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="book" />
            <token id="16" string="-" />
            <token id="17" string="when" />
            <token id="18" string="Walton" />
            <token id="19" string="admits" />
            <token id="20" string="that" />
            <token id="21" string="'" />
            <token id="22" string="if" />
            <token id="23" string="I" />
            <token id="24" string="had" />
            <token id="25" string="n't" />
            <token id="26" string="gotten" />
            <token id="27" string="sick" />
            <token id="28" string="," />
            <token id="29" string="I" />
            <token id="30" string="doubt" />
            <token id="31" string="I" />
            <token id="32" string="would" />
            <token id="33" string="have" />
            <token id="34" string="written" />
            <token id="35" string="this" />
            <token id="36" string="book" />
            <token id="37" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="if I had n't gotten sick" type="SBAR">
          <tokens>
            <token id="22" string="if" />
            <token id="23" string="I" />
            <token id="24" string="had" />
            <token id="25" string="n't" />
            <token id="26" string="gotten" />
            <token id="27" string="sick" />
          </tokens>
        </chunking>
        <chunking id="5" string="The real truth , one suspects ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="real" />
            <token id="3" string="truth" />
            <token id="4" string="," />
            <token id="5" string="one" />
            <token id="6" string="suspects" />
            <token id="7" string="," />
          </tokens>
        </chunking>
        <chunking id="6" string="doubt I would have written this book" type="VP">
          <tokens>
            <token id="30" string="doubt" />
            <token id="31" string="I" />
            <token id="32" string="would" />
            <token id="33" string="have" />
            <token id="34" string="written" />
            <token id="35" string="this" />
            <token id="36" string="book" />
          </tokens>
        </chunking>
        <chunking id="7" string="gotten sick" type="VP">
          <tokens>
            <token id="26" string="gotten" />
            <token id="27" string="sick" />
          </tokens>
        </chunking>
        <chunking id="8" string="I would have written this book" type="SBAR">
          <tokens>
            <token id="31" string="I" />
            <token id="32" string="would" />
            <token id="33" string="have" />
            <token id="34" string="written" />
            <token id="35" string="this" />
            <token id="36" string="book" />
          </tokens>
        </chunking>
        <chunking id="9" string="I" type="NP">
          <tokens>
            <token id="23" string="I" />
          </tokens>
        </chunking>
        <chunking id="10" string="sick" type="ADJP">
          <tokens>
            <token id="27" string="sick" />
          </tokens>
        </chunking>
        <chunking id="11" string="have written this book" type="VP">
          <tokens>
            <token id="33" string="have" />
            <token id="34" string="written" />
            <token id="35" string="this" />
            <token id="36" string="book" />
          </tokens>
        </chunking>
        <chunking id="12" string="written this book" type="VP">
          <tokens>
            <token id="34" string="written" />
            <token id="35" string="this" />
            <token id="36" string="book" />
          </tokens>
        </chunking>
        <chunking id="13" string="the book" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="book" />
          </tokens>
        </chunking>
        <chunking id="14" string="when" type="WHADVP">
          <tokens>
            <token id="17" string="when" />
          </tokens>
        </chunking>
        <chunking id="15" string="Walton" type="NP">
          <tokens>
            <token id="18" string="Walton" />
          </tokens>
        </chunking>
        <chunking id="16" string="The real truth" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="real" />
            <token id="3" string="truth" />
          </tokens>
        </chunking>
        <chunking id="17" string="had n't gotten sick" type="VP">
          <tokens>
            <token id="24" string="had" />
            <token id="25" string="n't" />
            <token id="26" string="gotten" />
            <token id="27" string="sick" />
          </tokens>
        </chunking>
        <chunking id="18" string="this book" type="NP">
          <tokens>
            <token id="35" string="this" />
            <token id="36" string="book" />
          </tokens>
        </chunking>
        <chunking id="19" string="admits that" type="VP">
          <tokens>
            <token id="19" string="admits" />
            <token id="20" string="that" />
          </tokens>
        </chunking>
        <chunking id="20" string="when Walton admits that" type="SBAR">
          <tokens>
            <token id="17" string="when" />
            <token id="18" string="Walton" />
            <token id="19" string="admits" />
            <token id="20" string="that" />
          </tokens>
        </chunking>
        <chunking id="21" string="the end of the book - when Walton admits that ` if I had n't gotten sick , I doubt I would have written this book '" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="end" />
            <token id="13" string="of" />
            <token id="14" string="the" />
            <token id="15" string="book" />
            <token id="16" string="-" />
            <token id="17" string="when" />
            <token id="18" string="Walton" />
            <token id="19" string="admits" />
            <token id="20" string="that" />
            <token id="21" string="'" />
            <token id="22" string="if" />
            <token id="23" string="I" />
            <token id="24" string="had" />
            <token id="25" string="n't" />
            <token id="26" string="gotten" />
            <token id="27" string="sick" />
            <token id="28" string="," />
            <token id="29" string="I" />
            <token id="30" string="doubt" />
            <token id="31" string="I" />
            <token id="32" string="would" />
            <token id="33" string="have" />
            <token id="34" string="written" />
            <token id="35" string="this" />
            <token id="36" string="book" />
            <token id="37" string="'" />
          </tokens>
        </chunking>
        <chunking id="22" string="one suspects" type="NP">
          <tokens>
            <token id="5" string="one" />
            <token id="6" string="suspects" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">truth</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">truth</governor>
          <dependent id="2">real</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">comes</governor>
          <dependent id="3">truth</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">suspects</governor>
          <dependent id="5">one</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">truth</governor>
          <dependent id="6">suspects</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">comes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">comes</governor>
          <dependent id="9">right</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">end</governor>
          <dependent id="10">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">end</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">comes</governor>
          <dependent id="12">end</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">book</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">book</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">end</governor>
          <dependent id="15">book</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">admits</governor>
          <dependent id="17">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">admits</governor>
          <dependent id="18">Walton</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">end</governor>
          <dependent id="19">admits</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">admits</governor>
          <dependent id="20">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">gotten</governor>
          <dependent id="22">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">gotten</governor>
          <dependent id="23">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="26">gotten</governor>
          <dependent id="24">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="26">gotten</governor>
          <dependent id="25">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="30">doubt</governor>
          <dependent id="26">gotten</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="26">gotten</governor>
          <dependent id="27">sick</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">doubt</governor>
          <dependent id="29">I</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">end</governor>
          <dependent id="30">doubt</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">written</governor>
          <dependent id="31">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">written</governor>
          <dependent id="32">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">written</governor>
          <dependent id="33">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="30">doubt</governor>
          <dependent id="34">written</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">book</governor>
          <dependent id="35">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">written</governor>
          <dependent id="36">book</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="right" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="9" string="right" />
          </tokens>
        </entity>
        <entity id="3" string="Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Walton" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Given the pleadings of publishers - Doubleday paid about Dollars 4m for the manuscript - and a rather natural desire to have a final say, he can hardly be blamed for agreeing to write it.</content>
      <tokens>
        <token id="1" string="Given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="pleadings" lemma="pleading" stem="plead" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="publishers" lemma="publisher" stem="publish" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Doubleday" lemma="Doubleday" stem="doubledai" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="8" string="paid" lemma="pay" stem="paid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Dollars" lemma="Dollars" stem="dollar" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="4m" lemma="4m" stem="4m" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="manuscript" lemma="manuscript" stem="manuscript" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="rather" lemma="rather" stem="rather" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="desire" lemma="desire" stem="desir" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="final" lemma="final" stem="final" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="say" lemma="say" stem="sai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="hardly" lemma="hardly" stem="hardli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="blamed" lemma="blame" stem="blame" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="agreeing" lemma="agree" stem="agre" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="write" lemma="write" stem="write" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBN Given) (NP (NP (NP (DT the) (NNS pleadings)) (PP (IN of) (NP (NNS publishers)))) (PRN (: -) (S (NP (NNP Doubleday)) (VP (VBD paid) (PP (IN about) (NP (NNP Dollars) (NN 4m))) (PP (IN for) (NP (DT the) (NN manuscript))))) (: -)) (CC and) (NP (NP (DT a) (ADJP (RB rather) (JJ natural)) (NN desire)) (SBAR (S (VP (TO to) (VP (VB have) (NP (DT a) (JJ final) (NN say))))))))) (, ,) (NP (PRP he)) (VP (MD can) (ADVP (RB hardly)) (VP (VB be) (VP (VBN blamed) (PP (IN for) (S (VP (VBG agreeing) (S (VP (TO to) (VP (VB write) (NP (PRP it))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="paid about Dollars 4m for the manuscript" type="VP">
          <tokens>
            <token id="8" string="paid" />
            <token id="9" string="about" />
            <token id="10" string="Dollars" />
            <token id="11" string="4m" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="manuscript" />
          </tokens>
        </chunking>
        <chunking id="2" string="to write it" type="VP">
          <tokens>
            <token id="34" string="to" />
            <token id="35" string="write" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="a final say" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="final" />
            <token id="25" string="say" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="the pleadings of publishers" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="pleadings" />
            <token id="4" string="of" />
            <token id="5" string="publishers" />
          </tokens>
        </chunking>
        <chunking id="6" string="a rather natural desire" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="rather" />
            <token id="19" string="natural" />
            <token id="20" string="desire" />
          </tokens>
        </chunking>
        <chunking id="7" string="to have a final say" type="SBAR">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="have" />
            <token id="23" string="a" />
            <token id="24" string="final" />
            <token id="25" string="say" />
          </tokens>
        </chunking>
        <chunking id="8" string="the manuscript" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="manuscript" />
          </tokens>
        </chunking>
        <chunking id="9" string="Dollars 4m" type="NP">
          <tokens>
            <token id="10" string="Dollars" />
            <token id="11" string="4m" />
          </tokens>
        </chunking>
        <chunking id="10" string="rather natural" type="ADJP">
          <tokens>
            <token id="18" string="rather" />
            <token id="19" string="natural" />
          </tokens>
        </chunking>
        <chunking id="11" string="blamed for agreeing to write it" type="VP">
          <tokens>
            <token id="31" string="blamed" />
            <token id="32" string="for" />
            <token id="33" string="agreeing" />
            <token id="34" string="to" />
            <token id="35" string="write" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="12" string="Doubleday" type="NP">
          <tokens>
            <token id="7" string="Doubleday" />
          </tokens>
        </chunking>
        <chunking id="13" string="a rather natural desire to have a final say" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="rather" />
            <token id="19" string="natural" />
            <token id="20" string="desire" />
            <token id="21" string="to" />
            <token id="22" string="have" />
            <token id="23" string="a" />
            <token id="24" string="final" />
            <token id="25" string="say" />
          </tokens>
        </chunking>
        <chunking id="14" string="agreeing to write it" type="VP">
          <tokens>
            <token id="33" string="agreeing" />
            <token id="34" string="to" />
            <token id="35" string="write" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="15" string="the pleadings of publishers - Doubleday paid about Dollars 4m for the manuscript - and a rather natural desire to have a final say" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="pleadings" />
            <token id="4" string="of" />
            <token id="5" string="publishers" />
            <token id="6" string="-" />
            <token id="7" string="Doubleday" />
            <token id="8" string="paid" />
            <token id="9" string="about" />
            <token id="10" string="Dollars" />
            <token id="11" string="4m" />
            <token id="12" string="for" />
            <token id="13" string="the" />
            <token id="14" string="manuscript" />
            <token id="15" string="-" />
            <token id="16" string="and" />
            <token id="17" string="a" />
            <token id="18" string="rather" />
            <token id="19" string="natural" />
            <token id="20" string="desire" />
            <token id="21" string="to" />
            <token id="22" string="have" />
            <token id="23" string="a" />
            <token id="24" string="final" />
            <token id="25" string="say" />
          </tokens>
        </chunking>
        <chunking id="16" string="publishers" type="NP">
          <tokens>
            <token id="5" string="publishers" />
          </tokens>
        </chunking>
        <chunking id="17" string="have a final say" type="VP">
          <tokens>
            <token id="22" string="have" />
            <token id="23" string="a" />
            <token id="24" string="final" />
            <token id="25" string="say" />
          </tokens>
        </chunking>
        <chunking id="18" string="write it" type="VP">
          <tokens>
            <token id="35" string="write" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="19" string="he" type="NP">
          <tokens>
            <token id="27" string="he" />
          </tokens>
        </chunking>
        <chunking id="20" string="the pleadings" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="pleadings" />
          </tokens>
        </chunking>
        <chunking id="21" string="can hardly be blamed for agreeing to write it" type="VP">
          <tokens>
            <token id="28" string="can" />
            <token id="29" string="hardly" />
            <token id="30" string="be" />
            <token id="31" string="blamed" />
            <token id="32" string="for" />
            <token id="33" string="agreeing" />
            <token id="34" string="to" />
            <token id="35" string="write" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
        <chunking id="22" string="be blamed for agreeing to write it" type="VP">
          <tokens>
            <token id="30" string="be" />
            <token id="31" string="blamed" />
            <token id="32" string="for" />
            <token id="33" string="agreeing" />
            <token id="34" string="to" />
            <token id="35" string="write" />
            <token id="36" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">pleadings</governor>
          <dependent id="1">Given</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">pleadings</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">blamed</governor>
          <dependent id="3">pleadings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">publishers</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">pleadings</governor>
          <dependent id="5">publishers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">paid</governor>
          <dependent id="7">Doubleday</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">pleadings</governor>
          <dependent id="8">paid</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">4m</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">4m</governor>
          <dependent id="10">Dollars</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">paid</governor>
          <dependent id="11">4m</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">manuscript</governor>
          <dependent id="12">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">manuscript</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">paid</governor>
          <dependent id="14">manuscript</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">pleadings</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">desire</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">natural</governor>
          <dependent id="18">rather</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">desire</governor>
          <dependent id="19">natural</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">pleadings</governor>
          <dependent id="20">desire</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">have</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="20">desire</governor>
          <dependent id="22">have</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">say</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">say</governor>
          <dependent id="24">final</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">have</governor>
          <dependent id="25">say</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">blamed</governor>
          <dependent id="27">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">blamed</governor>
          <dependent id="28">can</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="31">blamed</governor>
          <dependent id="29">hardly</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">blamed</governor>
          <dependent id="30">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">blamed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">agreeing</governor>
          <dependent id="32">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="31">blamed</governor>
          <dependent id="33">agreeing</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">write</governor>
          <dependent id="34">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="33">agreeing</governor>
          <dependent id="35">write</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="35">write</governor>
          <dependent id="36">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Doubleday" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="Doubleday" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="false">
      <content>But these are unlikely to be circumstances which make for the most critical self-analysis.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="unlikely" lemma="unlikely" stem="unlik" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="circumstances" lemma="circumstance" stem="circumst" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="make" lemma="make" stem="make" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="critical" lemma="critical" stem="critic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="self-analysis" lemma="self-analysis" stem="self-analysi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT these)) (VP (VBP are) (ADJP (JJ unlikely) (S (VP (TO to) (VP (VB be) (NP (NP (NNS circumstances)) (SBAR (WHNP (WDT which)) (S (VP (VBP make) (PP (IN for) (NP (DT the) (ADJP (RBS most) (JJ critical)) (NN self-analysis)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="these" type="NP">
          <tokens>
            <token id="2" string="these" />
          </tokens>
        </chunking>
        <chunking id="2" string="which make for the most critical self-analysis" type="SBAR">
          <tokens>
            <token id="8" string="which" />
            <token id="9" string="make" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="most" />
            <token id="13" string="critical" />
            <token id="14" string="self-analysis" />
          </tokens>
        </chunking>
        <chunking id="3" string="circumstances" type="NP">
          <tokens>
            <token id="7" string="circumstances" />
          </tokens>
        </chunking>
        <chunking id="4" string="are unlikely to be circumstances which make for the most critical self-analysis" type="VP">
          <tokens>
            <token id="3" string="are" />
            <token id="4" string="unlikely" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="circumstances" />
            <token id="8" string="which" />
            <token id="9" string="make" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="most" />
            <token id="13" string="critical" />
            <token id="14" string="self-analysis" />
          </tokens>
        </chunking>
        <chunking id="5" string="make for the most critical self-analysis" type="VP">
          <tokens>
            <token id="9" string="make" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="most" />
            <token id="13" string="critical" />
            <token id="14" string="self-analysis" />
          </tokens>
        </chunking>
        <chunking id="6" string="most critical" type="ADJP">
          <tokens>
            <token id="12" string="most" />
            <token id="13" string="critical" />
          </tokens>
        </chunking>
        <chunking id="7" string="be circumstances which make for the most critical self-analysis" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="circumstances" />
            <token id="8" string="which" />
            <token id="9" string="make" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="most" />
            <token id="13" string="critical" />
            <token id="14" string="self-analysis" />
          </tokens>
        </chunking>
        <chunking id="8" string="circumstances which make for the most critical self-analysis" type="NP">
          <tokens>
            <token id="7" string="circumstances" />
            <token id="8" string="which" />
            <token id="9" string="make" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="most" />
            <token id="13" string="critical" />
            <token id="14" string="self-analysis" />
          </tokens>
        </chunking>
        <chunking id="9" string="unlikely to be circumstances which make for the most critical self-analysis" type="ADJP">
          <tokens>
            <token id="4" string="unlikely" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="circumstances" />
            <token id="8" string="which" />
            <token id="9" string="make" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="most" />
            <token id="13" string="critical" />
            <token id="14" string="self-analysis" />
          </tokens>
        </chunking>
        <chunking id="10" string="to be circumstances which make for the most critical self-analysis" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="circumstances" />
            <token id="8" string="which" />
            <token id="9" string="make" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="most" />
            <token id="13" string="critical" />
            <token id="14" string="self-analysis" />
          </tokens>
        </chunking>
        <chunking id="11" string="the most critical self-analysis" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="most" />
            <token id="13" string="critical" />
            <token id="14" string="self-analysis" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">unlikely</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">unlikely</governor>
          <dependent id="2">these</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">unlikely</governor>
          <dependent id="3">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">unlikely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">circumstances</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">circumstances</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">unlikely</governor>
          <dependent id="7">circumstances</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">make</governor>
          <dependent id="8">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">circumstances</governor>
          <dependent id="9">make</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">self-analysis</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">self-analysis</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">critical</governor>
          <dependent id="12">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">self-analysis</governor>
          <dependent id="13">critical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">make</governor>
          <dependent id="14">self-analysis</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>At the end of the day, Sam Walton&amp;apost;s heritage is in the shopping malls, not the bookstores.</content>
      <tokens>
        <token id="1" string="At" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Sam" lemma="Sam" stem="sam" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="Walton" lemma="Walton" stem="walton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="heritage" lemma="heritage" stem="heritag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="shopping" lemma="shopping" stem="shop" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="malls" lemma="mall" stem="mall" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="bookstores" lemma="bookstore" stem="bookstor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN At) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (DT the) (NN day))))) (, ,) (NP (NP (NNP Sam) (NNP Walton) (POS 's)) (NN heritage)) (VP (VBZ is) (PP (IN in) (NP (NP (DT the) (NN shopping) (NNS malls)) (, ,) (RB not) (NP (DT the) (NNS bookstores))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the end" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="end" />
          </tokens>
        </chunking>
        <chunking id="2" string="is in the shopping malls , not the bookstores" type="VP">
          <tokens>
            <token id="12" string="is" />
            <token id="13" string="in" />
            <token id="14" string="the" />
            <token id="15" string="shopping" />
            <token id="16" string="malls" />
            <token id="17" string="," />
            <token id="18" string="not" />
            <token id="19" string="the" />
            <token id="20" string="bookstores" />
          </tokens>
        </chunking>
        <chunking id="3" string="the shopping malls" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="shopping" />
            <token id="16" string="malls" />
          </tokens>
        </chunking>
        <chunking id="4" string="Sam Walton 's heritage" type="NP">
          <tokens>
            <token id="8" string="Sam" />
            <token id="9" string="Walton" />
            <token id="10" string="'s" />
            <token id="11" string="heritage" />
          </tokens>
        </chunking>
        <chunking id="5" string="the day" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="day" />
          </tokens>
        </chunking>
        <chunking id="6" string="Sam Walton 's" type="NP">
          <tokens>
            <token id="8" string="Sam" />
            <token id="9" string="Walton" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="the bookstores" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="bookstores" />
          </tokens>
        </chunking>
        <chunking id="8" string="the end of the day" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="end" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="day" />
          </tokens>
        </chunking>
        <chunking id="9" string="the shopping malls , not the bookstores" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="shopping" />
            <token id="16" string="malls" />
            <token id="17" string="," />
            <token id="18" string="not" />
            <token id="19" string="the" />
            <token id="20" string="bookstores" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">end</governor>
          <dependent id="1">At</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">end</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">malls</governor>
          <dependent id="3">end</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">day</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">day</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">end</governor>
          <dependent id="6">day</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Walton</governor>
          <dependent id="8">Sam</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">heritage</governor>
          <dependent id="9">Walton</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Walton</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">malls</governor>
          <dependent id="11">heritage</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">malls</governor>
          <dependent id="12">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">malls</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">malls</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">malls</governor>
          <dependent id="15">shopping</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">malls</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">bookstores</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">bookstores</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="16">malls</governor>
          <dependent id="20">bookstores</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Sam Walton" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Sam" />
            <token id="9" string="Walton" />
          </tokens>
        </entity>
        <entity id="2" string="the end of the day" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="end" />
            <token id="4" string="of" />
            <token id="5" string="the" />
            <token id="6" string="day" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="3" string="AMERICA" id_sentence="1" />
      <mentions>
        <mention ids_tokens="10-11" string="America's" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="8-9-10" string="Sam Walton Doubleday" id_sentence="1" />
      <mentions>
        <mention ids_tokens="7" string="Doubleday" id_sentence="35" />
        <mention ids_tokens="27" string="he" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="7" string="Wal-Mart" id_sentence="6" />
      <mentions>
        <mention ids_tokens="7-8" string="Wal-Mart's" id_sentence="10" />
        <mention ids_tokens="14-15" string="Wal-Mart's" id_sentence="20" />
        <mention ids_tokens="7-8" string="Wal-Mart's" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="1-2" string="Sam Walton" id_sentence="6" />
      <mentions>
        <mention ids_tokens="9" string="him" id_sentence="7" />
        <mention ids_tokens="32" string="Walton" id_sentence="7" />
        <mention ids_tokens="34" string="his" id_sentence="7" />
        <mention ids_tokens="15" string="Walton" id_sentence="11" />
        <mention ids_tokens="11" string="himself" id_sentence="12" />
        <mention ids_tokens="1" string="Walton" id_sentence="14" />
        <mention ids_tokens="5" string="his" id_sentence="15" />
        <mention ids_tokens="1" string="Walton" id_sentence="17" />
        <mention ids_tokens="18" string="he" id_sentence="17" />
        <mention ids_tokens="11" string="his" id_sentence="19" />
        <mention ids_tokens="18" string="Walton" id_sentence="22" />
        <mention ids_tokens="15" string="himself" id_sentence="28" />
        <mention ids_tokens="21" string="he" id_sentence="28" />
        <mention ids_tokens="16" string="Walton" id_sentence="31" />
        <mention ids_tokens="18" string="Walton" id_sentence="34" />
        <mention ids_tokens="8-10" string="Sam Walton's" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="28-29" string="chicken farmers" id_sentence="7" />
      <mentions>
        <mention ids_tokens="2" string="they" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="Wal-Mart 's business" id_sentence="10" />
      <mentions>
        <mention ids_tokens="11-12" string="his business" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="10-11-12-13" string="Sam himself look bad" id_sentence="12" />
      <mentions>
        <mention ids_tokens="9" string="he" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6" string="The worst that has been said" id_sentence="13" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="1" string="Readers" id_sentence="15" />
      <mentions>
        <mention ids_tokens="2" string="they" id_sentence="16" />
        <mention ids_tokens="10" string="they" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="14" type="PRONOMINAL">
      <referenced ids_tokens="7" string="I" id_sentence="17" />
      <mentions>
        <mention ids_tokens="4" string="me" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="16" type="PROPER">
      <referenced ids_tokens="11-12" string="Don Soderquist" id_sentence="20" />
      <mentions>
        <mention ids_tokens="2" string="his" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="17" type="LIST">
      <referenced ids_tokens="7-8-9" string="friends and family" id_sentence="20" />
      <mentions>
        <mention ids_tokens="20" string="their" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="6-7-8" string="a casual aside" id_sentence="21" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="4-5" string="David Glass" id_sentence="22" />
      <mentions>
        <mention ids_tokens="19" string="he" id_sentence="23" />
        <mention ids_tokens="35" string="his" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="7-8" string="Wal-Mart executives" id_sentence="23" />
      <mentions>
        <mention ids_tokens="13" string="them" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="21-22-23-24-25-26-27-28-29-30-31-32-33-34" string="the time Sam ( who usually won ) selected minnow buckets for carrying bait" id_sentence="23" />
      <mentions>
        <mention ids_tokens="10" string="Sam" id_sentence="26" />
        <mention ids_tokens="3" string="him" id_sentence="27" />
        <mention ids_tokens="7" string="he" id_sentence="27" />
        <mention ids_tokens="5" string="Sam" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="7-8" string="apple juice" id_sentence="24" />
      <mentions>
        <mention ids_tokens="27-28" string="the juice" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="16-17-18" string="that minnow bucket" id_sentence="25" />
      <mentions>
        <mention ids_tokens="4" string="it" id_sentence="26" />
        <mention ids_tokens="1" string="It" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="the most part" id_sentence="29" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="27" type="NOMINAL">
      <referenced ids_tokens="4-5" string="a bank" id_sentence="31" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="32" />
      </mentions>
    </coreference>
  </coreferences>
</document>
