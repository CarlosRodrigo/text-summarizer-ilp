<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP900118-0205">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>The McMartin Pre-school molestation case was the longest criminal trial in U.S. history.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="true" />
        <token id="3" string="Pre-school" lemma="pre-school" stem="pre-school" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="true" />
        <token id="4" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="longest" lemma="longest" stem="longest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="13" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNP McMartin) (NN Pre-school) (NN molestation) (NN case)) (VP (VBD was) (NP (NP (DT the) (JJS longest) (JJ criminal) (NN trial)) (PP (IN in) (NP (NNP U.S.) (NN history))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="U.S. history" type="NP">
          <tokens>
            <token id="12" string="U.S." />
            <token id="13" string="history" />
          </tokens>
        </chunking>
        <chunking id="2" string="The McMartin Pre-school molestation case" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="McMartin" />
            <token id="3" string="Pre-school" />
            <token id="4" string="molestation" />
            <token id="5" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="the longest criminal trial" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="longest" />
            <token id="9" string="criminal" />
            <token id="10" string="trial" />
          </tokens>
        </chunking>
        <chunking id="4" string="the longest criminal trial in U.S. history" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="longest" />
            <token id="9" string="criminal" />
            <token id="10" string="trial" />
            <token id="11" string="in" />
            <token id="12" string="U.S." />
            <token id="13" string="history" />
          </tokens>
        </chunking>
        <chunking id="5" string="was the longest criminal trial in U.S. history" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="the" />
            <token id="8" string="longest" />
            <token id="9" string="criminal" />
            <token id="10" string="trial" />
            <token id="11" string="in" />
            <token id="12" string="U.S." />
            <token id="13" string="history" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">case</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">case</governor>
          <dependent id="2">McMartin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">case</governor>
          <dependent id="3">Pre-school</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">case</governor>
          <dependent id="4">molestation</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">trial</governor>
          <dependent id="5">case</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">trial</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">trial</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">trial</governor>
          <dependent id="8">longest</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">trial</governor>
          <dependent id="9">criminal</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">trial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">history</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">history</governor>
          <dependent id="12">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">trial</governor>
          <dependent id="13">history</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="12" string="U.S." />
          </tokens>
        </entity>
        <entity id="2" string="McMartin Pre-school" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="McMartin" />
            <token id="3" string="Pre-school" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Here is a chronology of the case:  _Aug. 12, 1983: Judy Johnson makes a phone call to Manhattan Beach Police Department and tells Detective Jane Hoag that she believes her 2{-year-old son was molested by Raymond Buckey at the McMartin Pre-School.</content>
      <tokens>
        <token id="1" string="Here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="chronology" lemma="chronology" stem="chronologi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="_" lemma="_" stem="_" pos="CD" type="Symbol" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="10" string="Aug." lemma="Aug." stem="aug." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="14" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Judy" lemma="Judy" stem="judi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="makes" lemma="make" stem="make" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="phone" lemma="phone" stem="phone" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="call" lemma="call" stem="call" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Manhattan" lemma="Manhattan" stem="manhattan" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="23" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="Police" lemma="Police" stem="polic" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="Department" lemma="Department" stem="depart" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="tells" lemma="tell" stem="tell" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Detective" lemma="Detective" stem="detect" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="29" string="Jane" lemma="Jane" stem="jane" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="30" string="Hoag" lemma="Hoag" stem="hoag" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="31" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="36" string="{" lemma="-lcb-" stem="{" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="year-old" lemma="year-old" stem="year-old" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="Raymond" lemma="Raymond" stem="raymond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="44" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="45" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="46" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="47" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="48" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="true" />
        <token id="49" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Here)) (VP (VBZ is) (NP (NP (NP (NP (DT a) (NN chronology)) (PP (IN of) (NP (DT the) (NN case)))) (: :) (NP (NP (CD _)) (NP-TMP (NNP Aug.) (CD 12) (, ,) (CD 1983)))) (: :) (S (NP (NNP Judy) (NNP Johnson)) (VP (VP (VBZ makes) (NP (DT a) (NN phone) (NN call)) (PP (TO to) (NP (NNP Manhattan) (NNP Beach) (NNP Police) (NNP Department)))) (CC and) (VP (VBZ tells)))))) (NP (NP (NNP Detective) (NNP Jane) (NNP Hoag)) (SBAR (IN that) (S (NP (PRP she)) (VP (VBZ believes) (NP (PRP$ her) (CD 2) (-LRB- -LCB-))))))) (: -) (S (NP (JJ year-old) (NN son)) (VP (VBD was) (VP (VBN molested) (PP (IN by) (NP (NP (NNP Raymond) (NNP Buckey)) (PP (IN at) (NP (DT the) (NNP McMartin) (NNP Pre-School)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her 2 -LCB-" type="NP">
          <tokens>
            <token id="34" string="her" />
            <token id="35" string="2" />
            <token id="36" string="{" />
          </tokens>
        </chunking>
        <chunking id="2" string="the case" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="molested by Raymond Buckey at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="41" string="molested" />
            <token id="42" string="by" />
            <token id="43" string="Raymond" />
            <token id="44" string="Buckey" />
            <token id="45" string="at" />
            <token id="46" string="the" />
            <token id="47" string="McMartin" />
            <token id="48" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="4" string="a chronology of the case : _ Aug. 12 , 1983 : Judy Johnson makes a phone call to Manhattan Beach Police Department and tells" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="chronology" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="case" />
            <token id="8" string=":" />
            <token id="9" string="_" />
            <token id="10" string="Aug." />
            <token id="11" string="12" />
            <token id="12" string="," />
            <token id="13" string="1983" />
            <token id="14" string=":" />
            <token id="15" string="Judy" />
            <token id="16" string="Johnson" />
            <token id="17" string="makes" />
            <token id="18" string="a" />
            <token id="19" string="phone" />
            <token id="20" string="call" />
            <token id="21" string="to" />
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
            <token id="24" string="Police" />
            <token id="25" string="Department" />
            <token id="26" string="and" />
            <token id="27" string="tells" />
          </tokens>
        </chunking>
        <chunking id="5" string="is a chronology of the case : _ Aug. 12 , 1983 : Judy Johnson makes a phone call to Manhattan Beach Police Department and tells" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="chronology" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="case" />
            <token id="8" string=":" />
            <token id="9" string="_" />
            <token id="10" string="Aug." />
            <token id="11" string="12" />
            <token id="12" string="," />
            <token id="13" string="1983" />
            <token id="14" string=":" />
            <token id="15" string="Judy" />
            <token id="16" string="Johnson" />
            <token id="17" string="makes" />
            <token id="18" string="a" />
            <token id="19" string="phone" />
            <token id="20" string="call" />
            <token id="21" string="to" />
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
            <token id="24" string="Police" />
            <token id="25" string="Department" />
            <token id="26" string="and" />
            <token id="27" string="tells" />
          </tokens>
        </chunking>
        <chunking id="6" string="Detective Jane Hoag that she believes her 2 -LCB-" type="NP">
          <tokens>
            <token id="28" string="Detective" />
            <token id="29" string="Jane" />
            <token id="30" string="Hoag" />
            <token id="31" string="that" />
            <token id="32" string="she" />
            <token id="33" string="believes" />
            <token id="34" string="her" />
            <token id="35" string="2" />
            <token id="36" string="{" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="32" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="a chronology of the case" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="chronology" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="9" string="tells" type="VP">
          <tokens>
            <token id="27" string="tells" />
          </tokens>
        </chunking>
        <chunking id="10" string="that she believes her 2 -LCB-" type="SBAR">
          <tokens>
            <token id="31" string="that" />
            <token id="32" string="she" />
            <token id="33" string="believes" />
            <token id="34" string="her" />
            <token id="35" string="2" />
            <token id="36" string="{" />
          </tokens>
        </chunking>
        <chunking id="11" string="a chronology of the case : _ Aug. 12 , 1983" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="chronology" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="case" />
            <token id="8" string=":" />
            <token id="9" string="_" />
            <token id="10" string="Aug." />
            <token id="11" string="12" />
            <token id="12" string="," />
            <token id="13" string="1983" />
          </tokens>
        </chunking>
        <chunking id="12" string="_ Aug. 12 , 1983" type="NP">
          <tokens>
            <token id="9" string="_" />
            <token id="10" string="Aug." />
            <token id="11" string="12" />
            <token id="12" string="," />
            <token id="13" string="1983" />
          </tokens>
        </chunking>
        <chunking id="13" string="Raymond Buckey at the McMartin Pre-School" type="NP">
          <tokens>
            <token id="43" string="Raymond" />
            <token id="44" string="Buckey" />
            <token id="45" string="at" />
            <token id="46" string="the" />
            <token id="47" string="McMartin" />
            <token id="48" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="14" string="a chronology" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="chronology" />
          </tokens>
        </chunking>
        <chunking id="15" string="a phone call" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="phone" />
            <token id="20" string="call" />
          </tokens>
        </chunking>
        <chunking id="16" string="believes her 2 -LCB-" type="VP">
          <tokens>
            <token id="33" string="believes" />
            <token id="34" string="her" />
            <token id="35" string="2" />
            <token id="36" string="{" />
          </tokens>
        </chunking>
        <chunking id="17" string="year-old son" type="NP">
          <tokens>
            <token id="38" string="year-old" />
            <token id="39" string="son" />
          </tokens>
        </chunking>
        <chunking id="18" string="Manhattan Beach Police Department" type="NP">
          <tokens>
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
            <token id="24" string="Police" />
            <token id="25" string="Department" />
          </tokens>
        </chunking>
        <chunking id="19" string="Detective Jane Hoag" type="NP">
          <tokens>
            <token id="28" string="Detective" />
            <token id="29" string="Jane" />
            <token id="30" string="Hoag" />
          </tokens>
        </chunking>
        <chunking id="20" string="Raymond Buckey" type="NP">
          <tokens>
            <token id="43" string="Raymond" />
            <token id="44" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="21" string="Judy Johnson" type="NP">
          <tokens>
            <token id="15" string="Judy" />
            <token id="16" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="22" string="was molested by Raymond Buckey at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="40" string="was" />
            <token id="41" string="molested" />
            <token id="42" string="by" />
            <token id="43" string="Raymond" />
            <token id="44" string="Buckey" />
            <token id="45" string="at" />
            <token id="46" string="the" />
            <token id="47" string="McMartin" />
            <token id="48" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="23" string="the McMartin Pre-School" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="McMartin" />
            <token id="48" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="24" string="makes a phone call to Manhattan Beach Police Department and tells" type="VP">
          <tokens>
            <token id="17" string="makes" />
            <token id="18" string="a" />
            <token id="19" string="phone" />
            <token id="20" string="call" />
            <token id="21" string="to" />
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
            <token id="24" string="Police" />
            <token id="25" string="Department" />
            <token id="26" string="and" />
            <token id="27" string="tells" />
          </tokens>
        </chunking>
        <chunking id="25" string="_" type="NP">
          <tokens>
            <token id="9" string="_" />
          </tokens>
        </chunking>
        <chunking id="26" string="makes a phone call to Manhattan Beach Police Department" type="VP">
          <tokens>
            <token id="17" string="makes" />
            <token id="18" string="a" />
            <token id="19" string="phone" />
            <token id="20" string="call" />
            <token id="21" string="to" />
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
            <token id="24" string="Police" />
            <token id="25" string="Department" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">chronology</governor>
          <dependent id="1">Here</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">chronology</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">chronology</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">chronology</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">case</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">case</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">chronology</governor>
          <dependent id="7">case</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">chronology</governor>
          <dependent id="9">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="9">_</governor>
          <dependent id="10">Aug.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">Aug.</governor>
          <dependent id="11">12</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">Aug.</governor>
          <dependent id="13">1983</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Johnson</governor>
          <dependent id="15">Judy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">makes</governor>
          <dependent id="16">Johnson</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">chronology</governor>
          <dependent id="17">makes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">call</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">call</governor>
          <dependent id="19">phone</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">makes</governor>
          <dependent id="20">call</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Department</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Department</governor>
          <dependent id="22">Manhattan</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Department</governor>
          <dependent id="23">Beach</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Department</governor>
          <dependent id="24">Police</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">makes</governor>
          <dependent id="25">Department</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">makes</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">makes</governor>
          <dependent id="27">tells</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Hoag</governor>
          <dependent id="28">Detective</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">Hoag</governor>
          <dependent id="29">Jane</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">chronology</governor>
          <dependent id="30">Hoag</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="33">believes</governor>
          <dependent id="31">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">believes</governor>
          <dependent id="32">she</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="30">Hoag</governor>
          <dependent id="33">believes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="35">2</governor>
          <dependent id="34">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="33">believes</governor>
          <dependent id="35">2</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">son</governor>
          <dependent id="38">year-old</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="41">molested</governor>
          <dependent id="39">son</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="41">molested</governor>
          <dependent id="40">was</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">chronology</governor>
          <dependent id="41">molested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">Buckey</governor>
          <dependent id="42">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">Buckey</governor>
          <dependent id="43">Raymond</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">molested</governor>
          <dependent id="44">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">Pre-School</governor>
          <dependent id="45">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">Pre-School</governor>
          <dependent id="46">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="48">Pre-School</governor>
          <dependent id="47">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="44">Buckey</governor>
          <dependent id="48">Pre-School</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2" type="NUMBER" score="0.0">
          <tokens>
            <token id="35" string="2" />
          </tokens>
        </entity>
        <entity id="2" string="Judy Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Judy" />
            <token id="16" string="Johnson" />
          </tokens>
        </entity>
        <entity id="3" string="Jane Hoag" type="PERSON" score="0.0">
          <tokens>
            <token id="29" string="Jane" />
            <token id="30" string="Hoag" />
          </tokens>
        </entity>
        <entity id="4" string="McMartin Pre-School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="47" string="McMartin" />
            <token id="48" string="Pre-School" />
          </tokens>
        </entity>
        <entity id="5" string="Aug. 12 , 1983" type="DATE" score="0.0">
          <tokens>
            <token id="10" string="Aug." />
            <token id="11" string="12" />
            <token id="12" string="," />
            <token id="13" string="1983" />
          </tokens>
        </entity>
        <entity id="6" string="Manhattan Beach Police Department" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="22" string="Manhattan" />
            <token id="23" string="Beach" />
            <token id="24" string="Police" />
            <token id="25" string="Department" />
          </tokens>
        </entity>
        <entity id="7" string="Detective" type="TITLE" score="0.0">
          <tokens>
            <token id="28" string="Detective" />
          </tokens>
        </entity>
        <entity id="8" string="_" type="NUMBER" score="0.0">
          <tokens>
            <token id="9" string="_" />
          </tokens>
        </entity>
        <entity id="9" string="Raymond Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="43" string="Raymond" />
            <token id="44" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>_Sept. 7, 1983: Ms. Hoag arrests Buckey, but he is released later that day for lack of evidence.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Sept." lemma="Sept." stem="sept." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="7" lemma="7" stem="7" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="Hoag" lemma="Hoag" stem="hoag" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="9" string="arrests" lemma="arrest" stem="arrest" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="released" lemma="release" stem="releas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="lack" lemma="lack" stem="lack" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NP (NN _)) (NP-TMP (NNP Sept.) (CD 7) (, ,) (CD 1983))) (: :) (NP (NP (NNP Ms.) (NNP Hoag) (NNS arrests)) (NP (NNP Buckey))) (, ,)) (PP (CC but) (NP (PRP he)))) (VP (VBZ is) (VP (VBN released) (NP-TMP (RB later) (DT that) (NN day)) (PP (IN for) (NP (NP (NN lack)) (PP (IN of) (NP (NN evidence))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="lack of evidence" type="NP">
          <tokens>
            <token id="20" string="lack" />
            <token id="21" string="of" />
            <token id="22" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="2" string="evidence" type="NP">
          <tokens>
            <token id="22" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="3" string="_ Sept. 7 , 1983 : Ms. Hoag arrests Buckey ," type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Sept." />
            <token id="3" string="7" />
            <token id="4" string="," />
            <token id="5" string="1983" />
            <token id="6" string=":" />
            <token id="7" string="Ms." />
            <token id="8" string="Hoag" />
            <token id="9" string="arrests" />
            <token id="10" string="Buckey" />
            <token id="11" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="lack" type="NP">
          <tokens>
            <token id="20" string="lack" />
          </tokens>
        </chunking>
        <chunking id="5" string="_ Sept. 7 , 1983" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Sept." />
            <token id="3" string="7" />
            <token id="4" string="," />
            <token id="5" string="1983" />
          </tokens>
        </chunking>
        <chunking id="6" string="Buckey" type="NP">
          <tokens>
            <token id="10" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="7" string="released later that day for lack of evidence" type="VP">
          <tokens>
            <token id="15" string="released" />
            <token id="16" string="later" />
            <token id="17" string="that" />
            <token id="18" string="day" />
            <token id="19" string="for" />
            <token id="20" string="lack" />
            <token id="21" string="of" />
            <token id="22" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="8" string="_ Sept. 7 , 1983 : Ms. Hoag arrests Buckey , but he" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Sept." />
            <token id="3" string="7" />
            <token id="4" string="," />
            <token id="5" string="1983" />
            <token id="6" string=":" />
            <token id="7" string="Ms." />
            <token id="8" string="Hoag" />
            <token id="9" string="arrests" />
            <token id="10" string="Buckey" />
            <token id="11" string="," />
            <token id="12" string="but" />
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ms. Hoag arrests Buckey" type="NP">
          <tokens>
            <token id="7" string="Ms." />
            <token id="8" string="Hoag" />
            <token id="9" string="arrests" />
            <token id="10" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="10" string="Ms. Hoag arrests" type="NP">
          <tokens>
            <token id="7" string="Ms." />
            <token id="8" string="Hoag" />
            <token id="9" string="arrests" />
          </tokens>
        </chunking>
        <chunking id="11" string="is released later that day for lack of evidence" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="released" />
            <token id="16" string="later" />
            <token id="17" string="that" />
            <token id="18" string="day" />
            <token id="19" string="for" />
            <token id="20" string="lack" />
            <token id="21" string="of" />
            <token id="22" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="15">released</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Sept.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Sept.</governor>
          <dependent id="3">7</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Sept.</governor>
          <dependent id="5">1983</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">arrests</governor>
          <dependent id="7">Ms.</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">arrests</governor>
          <dependent id="8">Hoag</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="9">arrests</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">arrests</governor>
          <dependent id="10">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">he</governor>
          <dependent id="12">but</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">_</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">released</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">released</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">day</governor>
          <dependent id="16">later</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">day</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="15">released</governor>
          <dependent id="18">day</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">lack</governor>
          <dependent id="19">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">released</governor>
          <dependent id="20">lack</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">evidence</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">lack</governor>
          <dependent id="22">evidence</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="day" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="day" />
          </tokens>
        </entity>
        <entity id="3" string="Sept. 7 , 1983" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Sept." />
            <token id="3" string="7" />
            <token id="4" string="," />
            <token id="5" string="1983" />
          </tokens>
        </entity>
        <entity id="4" string="Hoag" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Hoag" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Police continue the investigation and stir controversy by sending letters to 200 parents naming Buckey as a child molestation suspect and asking them to interrogate their children about oral sex, fondling of genitals and sodomy.</content>
      <tokens>
        <token id="1" string="Police" lemma="police" stem="polic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="continue" lemma="continue" stem="continu" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="investigation" lemma="investigation" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="stir" lemma="stir" stem="stir" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="controversy" lemma="controversy" stem="controversi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="sending" lemma="send" stem="send" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="letters" lemma="letter" stem="letter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="200" lemma="200" stem="200" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="naming" lemma="name" stem="name" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="suspect" lemma="suspect" stem="suspect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="asking" lemma="ask" stem="ask" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="interrogate" lemma="interrogate" stem="interrog" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="oral" lemma="oral" stem="oral" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="sex" lemma="sex" stem="sex" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="fondling" lemma="fondling" stem="fondl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="genitals" lemma="genitals" stem="genit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="35" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="sodomy" lemma="sodomy" stem="sodomi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Police)) (VP (VP (VBP continue) (NP (DT the) (NN investigation))) (CC and) (VP (VB stir) (NP (NN controversy)) (PP (IN by) (S (VP (VP (VBG sending) (NP (NNS letters)) (PP (TO to) (NP (NP (CD 200) (NNS parents)) (VP (VBG naming) (NP (NP (NNP Buckey)) (PP (IN as) (NP (DT a) (NN child) (NN molestation) (NN suspect)))))))) (CC and) (VP (VBG asking) (S (NP (PRP them)) (VP (TO to) (VP (VB interrogate) (NP (PRP$ their) (NNS children)) (PP (IN about) (NP (NP (JJ oral) (NN sex)) (, ,) (NP (NP (NN fondling)) (PP (IN of) (NP (NNS genitals) (CC and) (NN sodomy))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Buckey as a child molestation suspect" type="NP">
          <tokens>
            <token id="15" string="Buckey" />
            <token id="16" string="as" />
            <token id="17" string="a" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="2" string="oral sex" type="NP">
          <tokens>
            <token id="29" string="oral" />
            <token id="30" string="sex" />
          </tokens>
        </chunking>
        <chunking id="3" string="genitals and sodomy" type="NP">
          <tokens>
            <token id="34" string="genitals" />
            <token id="35" string="and" />
            <token id="36" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="4" string="sending letters to 200 parents naming Buckey as a child molestation suspect" type="VP">
          <tokens>
            <token id="9" string="sending" />
            <token id="10" string="letters" />
            <token id="11" string="to" />
            <token id="12" string="200" />
            <token id="13" string="parents" />
            <token id="14" string="naming" />
            <token id="15" string="Buckey" />
            <token id="16" string="as" />
            <token id="17" string="a" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="5" string="them" type="NP">
          <tokens>
            <token id="23" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="controversy" type="NP">
          <tokens>
            <token id="7" string="controversy" />
          </tokens>
        </chunking>
        <chunking id="7" string="asking them to interrogate their children about oral sex , fondling of genitals and sodomy" type="VP">
          <tokens>
            <token id="22" string="asking" />
            <token id="23" string="them" />
            <token id="24" string="to" />
            <token id="25" string="interrogate" />
            <token id="26" string="their" />
            <token id="27" string="children" />
            <token id="28" string="about" />
            <token id="29" string="oral" />
            <token id="30" string="sex" />
            <token id="31" string="," />
            <token id="32" string="fondling" />
            <token id="33" string="of" />
            <token id="34" string="genitals" />
            <token id="35" string="and" />
            <token id="36" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="8" string="Police" type="NP">
          <tokens>
            <token id="1" string="Police" />
          </tokens>
        </chunking>
        <chunking id="9" string="Buckey" type="NP">
          <tokens>
            <token id="15" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="10" string="oral sex , fondling of genitals and sodomy" type="NP">
          <tokens>
            <token id="29" string="oral" />
            <token id="30" string="sex" />
            <token id="31" string="," />
            <token id="32" string="fondling" />
            <token id="33" string="of" />
            <token id="34" string="genitals" />
            <token id="35" string="and" />
            <token id="36" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="11" string="continue the investigation" type="VP">
          <tokens>
            <token id="2" string="continue" />
            <token id="3" string="the" />
            <token id="4" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="12" string="a child molestation suspect" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="13" string="200 parents" type="NP">
          <tokens>
            <token id="12" string="200" />
            <token id="13" string="parents" />
          </tokens>
        </chunking>
        <chunking id="14" string="interrogate their children about oral sex , fondling of genitals and sodomy" type="VP">
          <tokens>
            <token id="25" string="interrogate" />
            <token id="26" string="their" />
            <token id="27" string="children" />
            <token id="28" string="about" />
            <token id="29" string="oral" />
            <token id="30" string="sex" />
            <token id="31" string="," />
            <token id="32" string="fondling" />
            <token id="33" string="of" />
            <token id="34" string="genitals" />
            <token id="35" string="and" />
            <token id="36" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="15" string="fondling" type="NP">
          <tokens>
            <token id="32" string="fondling" />
          </tokens>
        </chunking>
        <chunking id="16" string="200 parents naming Buckey as a child molestation suspect" type="NP">
          <tokens>
            <token id="12" string="200" />
            <token id="13" string="parents" />
            <token id="14" string="naming" />
            <token id="15" string="Buckey" />
            <token id="16" string="as" />
            <token id="17" string="a" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="17" string="stir controversy by sending letters to 200 parents naming Buckey as a child molestation suspect and asking them to interrogate their children about oral sex , fondling of genitals and sodomy" type="VP">
          <tokens>
            <token id="6" string="stir" />
            <token id="7" string="controversy" />
            <token id="8" string="by" />
            <token id="9" string="sending" />
            <token id="10" string="letters" />
            <token id="11" string="to" />
            <token id="12" string="200" />
            <token id="13" string="parents" />
            <token id="14" string="naming" />
            <token id="15" string="Buckey" />
            <token id="16" string="as" />
            <token id="17" string="a" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="suspect" />
            <token id="21" string="and" />
            <token id="22" string="asking" />
            <token id="23" string="them" />
            <token id="24" string="to" />
            <token id="25" string="interrogate" />
            <token id="26" string="their" />
            <token id="27" string="children" />
            <token id="28" string="about" />
            <token id="29" string="oral" />
            <token id="30" string="sex" />
            <token id="31" string="," />
            <token id="32" string="fondling" />
            <token id="33" string="of" />
            <token id="34" string="genitals" />
            <token id="35" string="and" />
            <token id="36" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="18" string="sending letters to 200 parents naming Buckey as a child molestation suspect and asking them to interrogate their children about oral sex , fondling of genitals and sodomy" type="VP">
          <tokens>
            <token id="9" string="sending" />
            <token id="10" string="letters" />
            <token id="11" string="to" />
            <token id="12" string="200" />
            <token id="13" string="parents" />
            <token id="14" string="naming" />
            <token id="15" string="Buckey" />
            <token id="16" string="as" />
            <token id="17" string="a" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="suspect" />
            <token id="21" string="and" />
            <token id="22" string="asking" />
            <token id="23" string="them" />
            <token id="24" string="to" />
            <token id="25" string="interrogate" />
            <token id="26" string="their" />
            <token id="27" string="children" />
            <token id="28" string="about" />
            <token id="29" string="oral" />
            <token id="30" string="sex" />
            <token id="31" string="," />
            <token id="32" string="fondling" />
            <token id="33" string="of" />
            <token id="34" string="genitals" />
            <token id="35" string="and" />
            <token id="36" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="19" string="fondling of genitals and sodomy" type="NP">
          <tokens>
            <token id="32" string="fondling" />
            <token id="33" string="of" />
            <token id="34" string="genitals" />
            <token id="35" string="and" />
            <token id="36" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="20" string="their children" type="NP">
          <tokens>
            <token id="26" string="their" />
            <token id="27" string="children" />
          </tokens>
        </chunking>
        <chunking id="21" string="continue the investigation and stir controversy by sending letters to 200 parents naming Buckey as a child molestation suspect and asking them to interrogate their children about oral sex , fondling of genitals and sodomy" type="VP">
          <tokens>
            <token id="2" string="continue" />
            <token id="3" string="the" />
            <token id="4" string="investigation" />
            <token id="5" string="and" />
            <token id="6" string="stir" />
            <token id="7" string="controversy" />
            <token id="8" string="by" />
            <token id="9" string="sending" />
            <token id="10" string="letters" />
            <token id="11" string="to" />
            <token id="12" string="200" />
            <token id="13" string="parents" />
            <token id="14" string="naming" />
            <token id="15" string="Buckey" />
            <token id="16" string="as" />
            <token id="17" string="a" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="suspect" />
            <token id="21" string="and" />
            <token id="22" string="asking" />
            <token id="23" string="them" />
            <token id="24" string="to" />
            <token id="25" string="interrogate" />
            <token id="26" string="their" />
            <token id="27" string="children" />
            <token id="28" string="about" />
            <token id="29" string="oral" />
            <token id="30" string="sex" />
            <token id="31" string="," />
            <token id="32" string="fondling" />
            <token id="33" string="of" />
            <token id="34" string="genitals" />
            <token id="35" string="and" />
            <token id="36" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="22" string="the investigation" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="investigation" />
          </tokens>
        </chunking>
        <chunking id="23" string="to interrogate their children about oral sex , fondling of genitals and sodomy" type="VP">
          <tokens>
            <token id="24" string="to" />
            <token id="25" string="interrogate" />
            <token id="26" string="their" />
            <token id="27" string="children" />
            <token id="28" string="about" />
            <token id="29" string="oral" />
            <token id="30" string="sex" />
            <token id="31" string="," />
            <token id="32" string="fondling" />
            <token id="33" string="of" />
            <token id="34" string="genitals" />
            <token id="35" string="and" />
            <token id="36" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="24" string="naming Buckey as a child molestation suspect" type="VP">
          <tokens>
            <token id="14" string="naming" />
            <token id="15" string="Buckey" />
            <token id="16" string="as" />
            <token id="17" string="a" />
            <token id="18" string="child" />
            <token id="19" string="molestation" />
            <token id="20" string="suspect" />
          </tokens>
        </chunking>
        <chunking id="25" string="letters" type="NP">
          <tokens>
            <token id="10" string="letters" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">continue</governor>
          <dependent id="1">Police</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">continue</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">investigation</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">continue</governor>
          <dependent id="4">investigation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">continue</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">continue</governor>
          <dependent id="6">stir</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">stir</governor>
          <dependent id="7">controversy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">sending</governor>
          <dependent id="8">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">stir</governor>
          <dependent id="9">sending</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">sending</governor>
          <dependent id="10">letters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">parents</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">parents</governor>
          <dependent id="12">200</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">sending</governor>
          <dependent id="13">parents</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">parents</governor>
          <dependent id="14">naming</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">naming</governor>
          <dependent id="15">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">suspect</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">suspect</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">suspect</governor>
          <dependent id="18">child</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">suspect</governor>
          <dependent id="19">molestation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">Buckey</governor>
          <dependent id="20">suspect</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">sending</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">sending</governor>
          <dependent id="22">asking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">asking</governor>
          <dependent id="23">them</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">interrogate</governor>
          <dependent id="24">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">asking</governor>
          <dependent id="25">interrogate</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">children</governor>
          <dependent id="26">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">interrogate</governor>
          <dependent id="27">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">sex</governor>
          <dependent id="28">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">sex</governor>
          <dependent id="29">oral</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">interrogate</governor>
          <dependent id="30">sex</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="30">sex</governor>
          <dependent id="32">fondling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">genitals</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">fondling</governor>
          <dependent id="34">genitals</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="34">genitals</governor>
          <dependent id="35">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="34">genitals</governor>
          <dependent id="36">sodomy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="200" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="200" />
          </tokens>
        </entity>
        <entity id="2" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>_Fall of 1983 to spring of 1984: Nearly 400 children are interviewed by Children&amp;apost;s Institute International, and 41 are listed as victims in a complaint filed by the state.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Fall" lemma="fall" stem="fall" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="1983" lemma="1983" stem="1983" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="spring" lemma="spring" stem="spring" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="8" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="400" lemma="400" stem="400" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="12" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="interviewed" lemma="interview" stem="interview" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Children" lemma="Children" stem="children" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="18" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="International" lemma="International" stem="internat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="41" lemma="41" stem="41" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="23" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="listed" lemma="list" stem="list" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="state" lemma="state" stem="state" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NP (NN _) (NN Fall)) (PP (IN of) (NP (CD 1983))) (PP (TO to) (NP (NP (NN spring)) (PP (IN of) (NP (CD 1984)))))) (: :) (S (S (NP (QP (RB Nearly) (CD 400)) (NNS children)) (VP (VBP are) (VP (VBN interviewed) (PP (IN by) (NP (NP (NNP Children) (POS 's)) (NNP Institute) (NNP International)))))) (, ,) (CC and) (S (NP (CD 41)) (VP (VBP are) (VP (VBN listed) (PP (IN as) (NP (NP (NNS victims)) (PP (IN in) (NP (NP (DT a) (NN complaint)) (VP (VBN filed) (PP (IN by) (NP (DT the) (NN state)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="_ Fall of 1983 to spring of 1984" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Fall" />
            <token id="3" string="of" />
            <token id="4" string="1983" />
            <token id="5" string="to" />
            <token id="6" string="spring" />
            <token id="7" string="of" />
            <token id="8" string="1984" />
          </tokens>
        </chunking>
        <chunking id="2" string="a complaint filed by the state" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="complaint" />
            <token id="30" string="filed" />
            <token id="31" string="by" />
            <token id="32" string="the" />
            <token id="33" string="state" />
          </tokens>
        </chunking>
        <chunking id="3" string="listed as victims in a complaint filed by the state" type="VP">
          <tokens>
            <token id="24" string="listed" />
            <token id="25" string="as" />
            <token id="26" string="victims" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="complaint" />
            <token id="30" string="filed" />
            <token id="31" string="by" />
            <token id="32" string="the" />
            <token id="33" string="state" />
          </tokens>
        </chunking>
        <chunking id="4" string="spring of 1984" type="NP">
          <tokens>
            <token id="6" string="spring" />
            <token id="7" string="of" />
            <token id="8" string="1984" />
          </tokens>
        </chunking>
        <chunking id="5" string="are interviewed by Children 's Institute International" type="VP">
          <tokens>
            <token id="13" string="are" />
            <token id="14" string="interviewed" />
            <token id="15" string="by" />
            <token id="16" string="Children" />
            <token id="17" string="'s" />
            <token id="18" string="Institute" />
            <token id="19" string="International" />
          </tokens>
        </chunking>
        <chunking id="6" string="spring" type="NP">
          <tokens>
            <token id="6" string="spring" />
          </tokens>
        </chunking>
        <chunking id="7" string="Nearly 400 children" type="NP">
          <tokens>
            <token id="10" string="Nearly" />
            <token id="11" string="400" />
            <token id="12" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="Children 's Institute International" type="NP">
          <tokens>
            <token id="16" string="Children" />
            <token id="17" string="'s" />
            <token id="18" string="Institute" />
            <token id="19" string="International" />
          </tokens>
        </chunking>
        <chunking id="9" string="1984" type="NP">
          <tokens>
            <token id="8" string="1984" />
          </tokens>
        </chunking>
        <chunking id="10" string="1983" type="NP">
          <tokens>
            <token id="4" string="1983" />
          </tokens>
        </chunking>
        <chunking id="11" string="Children 's" type="NP">
          <tokens>
            <token id="16" string="Children" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="the state" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="state" />
          </tokens>
        </chunking>
        <chunking id="13" string="are listed as victims in a complaint filed by the state" type="VP">
          <tokens>
            <token id="23" string="are" />
            <token id="24" string="listed" />
            <token id="25" string="as" />
            <token id="26" string="victims" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="complaint" />
            <token id="30" string="filed" />
            <token id="31" string="by" />
            <token id="32" string="the" />
            <token id="33" string="state" />
          </tokens>
        </chunking>
        <chunking id="14" string="victims in a complaint filed by the state" type="NP">
          <tokens>
            <token id="26" string="victims" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="complaint" />
            <token id="30" string="filed" />
            <token id="31" string="by" />
            <token id="32" string="the" />
            <token id="33" string="state" />
          </tokens>
        </chunking>
        <chunking id="15" string="filed by the state" type="VP">
          <tokens>
            <token id="30" string="filed" />
            <token id="31" string="by" />
            <token id="32" string="the" />
            <token id="33" string="state" />
          </tokens>
        </chunking>
        <chunking id="16" string="_ Fall" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Fall" />
          </tokens>
        </chunking>
        <chunking id="17" string="41" type="NP">
          <tokens>
            <token id="22" string="41" />
          </tokens>
        </chunking>
        <chunking id="18" string="interviewed by Children 's Institute International" type="VP">
          <tokens>
            <token id="14" string="interviewed" />
            <token id="15" string="by" />
            <token id="16" string="Children" />
            <token id="17" string="'s" />
            <token id="18" string="Institute" />
            <token id="19" string="International" />
          </tokens>
        </chunking>
        <chunking id="19" string="victims" type="NP">
          <tokens>
            <token id="26" string="victims" />
          </tokens>
        </chunking>
        <chunking id="20" string="a complaint" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="complaint" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Fall</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">Fall</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">1983</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Fall</governor>
          <dependent id="4">1983</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">spring</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Fall</governor>
          <dependent id="6">spring</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1984</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">spring</governor>
          <dependent id="8">1984</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">400</governor>
          <dependent id="10">Nearly</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">children</governor>
          <dependent id="11">400</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">interviewed</governor>
          <dependent id="12">children</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">interviewed</governor>
          <dependent id="13">are</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">Fall</governor>
          <dependent id="14">interviewed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">International</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">International</governor>
          <dependent id="16">Children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Children</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">International</governor>
          <dependent id="18">Institute</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">interviewed</governor>
          <dependent id="19">International</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">interviewed</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">listed</governor>
          <dependent id="22">41</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">listed</governor>
          <dependent id="23">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">interviewed</governor>
          <dependent id="24">listed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">victims</governor>
          <dependent id="25">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">listed</governor>
          <dependent id="26">victims</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">complaint</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">complaint</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">victims</governor>
          <dependent id="29">complaint</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="29">complaint</governor>
          <dependent id="30">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">state</governor>
          <dependent id="31">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">state</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">filed</governor>
          <dependent id="33">state</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Fall of 1983" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Fall" />
            <token id="3" string="of" />
            <token id="4" string="1983" />
          </tokens>
        </entity>
        <entity id="2" string="Children 's Institute International" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="Children" />
            <token id="17" string="'s" />
            <token id="18" string="Institute" />
            <token id="19" string="International" />
          </tokens>
        </entity>
        <entity id="3" string="400" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="400" />
          </tokens>
        </entity>
        <entity id="4" string="41" type="NUMBER" score="0.0">
          <tokens>
            <token id="22" string="41" />
          </tokens>
        </entity>
        <entity id="5" string="spring of 1984" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="spring" />
            <token id="7" string="of" />
            <token id="8" string="1984" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>_Feb. 2, 1984: KABC-TV reporter Wayne Satz, in a newscast, describes dozens of alleged acts of oral copulation and sodomy with children.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Feb." lemma="Feb." stem="feb." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="KABC-TV" lemma="kabc-tv" stem="kabc-tv" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="reporter" lemma="reporter" stem="report" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Wayne" lemma="Wayne" stem="wayn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="Satz" lemma="Satz" stem="satz" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="newscast" lemma="newscast" stem="newscast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="describes" lemma="describe" stem="describ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="dozens" lemma="dozen" stem="dozen" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="alleged" lemma="alleged" stem="alleg" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="acts" lemma="act" stem="act" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="oral" lemma="oral" stem="oral" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="copulation" lemma="copulation" stem="copul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="sodomy" lemma="sodomy" stem="sodomi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NN _)) (NP-TMP (NNP Feb.) (CD 2) (, ,) (CD 1984))) (: :) (NP (NN KABC-TV) (NN reporter) (NNP Wayne) (NNP Satz)) (, ,) (PP (IN in) (NP (DT a) (NN newscast))) (, ,)) (VP (VBZ describes) (NP (NP (NNS dozens)) (PP (IN of) (NP (NP (JJ alleged) (NNS acts)) (PP (IN of) (NP (JJ oral) (NN copulation) (CC and) (NN sodomy)))))) (PP (IN with) (NP (NNS children)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="alleged acts of oral copulation and sodomy" type="NP">
          <tokens>
            <token id="19" string="alleged" />
            <token id="20" string="acts" />
            <token id="21" string="of" />
            <token id="22" string="oral" />
            <token id="23" string="copulation" />
            <token id="24" string="and" />
            <token id="25" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="2" string="dozens" type="NP">
          <tokens>
            <token id="17" string="dozens" />
          </tokens>
        </chunking>
        <chunking id="3" string="_ Feb. 2 , 1984" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Feb." />
            <token id="3" string="2" />
            <token id="4" string="," />
            <token id="5" string="1984" />
          </tokens>
        </chunking>
        <chunking id="4" string="dozens of alleged acts of oral copulation and sodomy" type="NP">
          <tokens>
            <token id="17" string="dozens" />
            <token id="18" string="of" />
            <token id="19" string="alleged" />
            <token id="20" string="acts" />
            <token id="21" string="of" />
            <token id="22" string="oral" />
            <token id="23" string="copulation" />
            <token id="24" string="and" />
            <token id="25" string="sodomy" />
          </tokens>
        </chunking>
        <chunking id="5" string="alleged acts" type="NP">
          <tokens>
            <token id="19" string="alleged" />
            <token id="20" string="acts" />
          </tokens>
        </chunking>
        <chunking id="6" string="children" type="NP">
          <tokens>
            <token id="27" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="a newscast" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="newscast" />
          </tokens>
        </chunking>
        <chunking id="8" string="KABC-TV reporter Wayne Satz" type="NP">
          <tokens>
            <token id="7" string="KABC-TV" />
            <token id="8" string="reporter" />
            <token id="9" string="Wayne" />
            <token id="10" string="Satz" />
          </tokens>
        </chunking>
        <chunking id="9" string="describes dozens of alleged acts of oral copulation and sodomy with children" type="VP">
          <tokens>
            <token id="16" string="describes" />
            <token id="17" string="dozens" />
            <token id="18" string="of" />
            <token id="19" string="alleged" />
            <token id="20" string="acts" />
            <token id="21" string="of" />
            <token id="22" string="oral" />
            <token id="23" string="copulation" />
            <token id="24" string="and" />
            <token id="25" string="sodomy" />
            <token id="26" string="with" />
            <token id="27" string="children" />
          </tokens>
        </chunking>
        <chunking id="10" string="_ Feb. 2 , 1984 : KABC-TV reporter Wayne Satz , in a newscast ," type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Feb." />
            <token id="3" string="2" />
            <token id="4" string="," />
            <token id="5" string="1984" />
            <token id="6" string=":" />
            <token id="7" string="KABC-TV" />
            <token id="8" string="reporter" />
            <token id="9" string="Wayne" />
            <token id="10" string="Satz" />
            <token id="11" string="," />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="newscast" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="12" string="oral copulation and sodomy" type="NP">
          <tokens>
            <token id="22" string="oral" />
            <token id="23" string="copulation" />
            <token id="24" string="and" />
            <token id="25" string="sodomy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="16">describes</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Feb.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Feb.</governor>
          <dependent id="3">2</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Feb.</governor>
          <dependent id="5">1984</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Satz</governor>
          <dependent id="7">KABC-TV</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Satz</governor>
          <dependent id="8">reporter</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Satz</governor>
          <dependent id="9">Wayne</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="10">Satz</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">newscast</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">newscast</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">_</governor>
          <dependent id="14">newscast</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">describes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">describes</governor>
          <dependent id="17">dozens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">acts</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">acts</governor>
          <dependent id="19">alleged</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">dozens</governor>
          <dependent id="20">acts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">copulation</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">copulation</governor>
          <dependent id="22">oral</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">acts</governor>
          <dependent id="23">copulation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">copulation</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">copulation</governor>
          <dependent id="25">sodomy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">children</governor>
          <dependent id="26">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">describes</governor>
          <dependent id="27">children</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Feb. 2 , 1984" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Feb." />
            <token id="3" string="2" />
            <token id="4" string="," />
            <token id="5" string="1984" />
          </tokens>
        </entity>
        <entity id="2" string="KABC-TV" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="7" string="KABC-TV" />
          </tokens>
        </entity>
        <entity id="3" string="Wayne Satz" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Wayne" />
            <token id="10" string="Satz" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>_March 22, 1984: Public outcry prompts Los Angeles District Attorney Robert Philibosian to send the case to grand jurors, who indict Buckey; his mother, Peggy McMartin Buckey; his sister, Peggy Ann Buckey; his grandmother Virginia McMartin, and three employees, Mary Ann Jackson, Babette Spitler and Betty Raidor, on 115 charges of child molestation.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="22" lemma="22" stem="22" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Public" lemma="Public" stem="public" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="outcry" lemma="outcry" stem="outcri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="prompts" lemma="prompt" stem="prompt" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Los" lemma="Los" stem="lo" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="11" string="Angeles" lemma="Angeles" stem="angele" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="District" lemma="District" stem="district" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="Attorney" lemma="Attorney" stem="attornei" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="14" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="Philibosian" lemma="Philibosian" stem="philibosian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="send" lemma="send" stem="send" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="grand" lemma="grand" stem="grand" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="indict" lemma="indict" stem="indict" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="33" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="34" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="sister" lemma="sister" stem="sister" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="39" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="40" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="41" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="grandmother" lemma="grandmother" stem="grandmoth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="45" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="46" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="three" lemma="three" stem="three" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="49" string="employees" lemma="employee" stem="employe" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="50" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="Mary" lemma="Mary" stem="mari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="52" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="53" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="54" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="55" string="Babette" lemma="Babette" stem="babett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="56" string="Spitler" lemma="Spitler" stem="spitler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="57" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="Betty" lemma="Betty" stem="betti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="59" string="Raidor" lemma="Raidor" stem="raidor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="60" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="61" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="62" string="115" lemma="115" stem="115" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="63" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="64" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="65" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="66" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="67" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP March) (CD 22) (, ,) (CD 1984))) (: :) (S (NP (NNP Public) (NN outcry)) (VP (VBZ prompts) (S (NP (NNP Los) (NNP Angeles) (NNP District) (NNP Attorney) (NNP Robert) (NNP Philibosian)) (VP (TO to) (VP (VB send) (NP (NP (NP (DT the) (NN case)) (PP (TO to) (NP (NP (JJ grand) (NNS jurors)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VB indict) (NP (NNP Buckey)))))))) (: ;) (NP (NP (PRP$ his) (NN mother)) (, ,) (NP (NNP Peggy) (NNP McMartin) (NNP Buckey))) (: ;) (NP (NP (PRP$ his) (NN sister)) (, ,) (NP (NNP Peggy) (NNP Ann) (NNP Buckey))) (: ;) (NP (NP (PRP$ his) (NN grandmother)) (NP (NNP Virginia) (NNP McMartin))) (, ,) (CC and) (NP (NP (CD three) (NNS employees)) (, ,) (NP (NNP Mary) (NNP Ann) (NNP Jackson)) (, ,) (NP (NNP Babette) (NNP Spitler)) (CC and) (NP (NNP Betty) (NNP Raidor))))))))) (, ,) (PP (IN on) (NP (NP (CD 115) (NNS charges)) (PP (IN of) (NP (NN child) (NN molestation))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his sister" type="NP">
          <tokens>
            <token id="35" string="his" />
            <token id="36" string="sister" />
          </tokens>
        </chunking>
        <chunking id="2" string="Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="31" string="Peggy" />
            <token id="32" string="McMartin" />
            <token id="33" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="3" string="Mary Ann Jackson" type="NP">
          <tokens>
            <token id="51" string="Mary" />
            <token id="52" string="Ann" />
            <token id="53" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="4" string="the case to grand jurors , who indict Buckey ; his mother , Peggy McMartin Buckey ; his sister , Peggy Ann Buckey ; his grandmother Virginia McMartin , and three employees , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="case" />
            <token id="20" string="to" />
            <token id="21" string="grand" />
            <token id="22" string="jurors" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="indict" />
            <token id="26" string="Buckey" />
            <token id="27" string=";" />
            <token id="28" string="his" />
            <token id="29" string="mother" />
            <token id="30" string="," />
            <token id="31" string="Peggy" />
            <token id="32" string="McMartin" />
            <token id="33" string="Buckey" />
            <token id="34" string=";" />
            <token id="35" string="his" />
            <token id="36" string="sister" />
            <token id="37" string="," />
            <token id="38" string="Peggy" />
            <token id="39" string="Ann" />
            <token id="40" string="Buckey" />
            <token id="41" string=";" />
            <token id="42" string="his" />
            <token id="43" string="grandmother" />
            <token id="44" string="Virginia" />
            <token id="45" string="McMartin" />
            <token id="46" string="," />
            <token id="47" string="and" />
            <token id="48" string="three" />
            <token id="49" string="employees" />
            <token id="50" string="," />
            <token id="51" string="Mary" />
            <token id="52" string="Ann" />
            <token id="53" string="Jackson" />
            <token id="54" string="," />
            <token id="55" string="Babette" />
            <token id="56" string="Spitler" />
            <token id="57" string="and" />
            <token id="58" string="Betty" />
            <token id="59" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="5" string="the case" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="_ March 22 , 1984 : Public outcry prompts Los Angeles District Attorney Robert Philibosian to send the case to grand jurors , who indict Buckey ; his mother , Peggy McMartin Buckey ; his sister , Peggy Ann Buckey ; his grandmother Virginia McMartin , and three employees , Mary Ann Jackson , Babette Spitler and Betty Raidor , on 115 charges of child molestation ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="March" />
            <token id="3" string="22" />
            <token id="4" string="," />
            <token id="5" string="1984" />
            <token id="6" string=":" />
            <token id="7" string="Public" />
            <token id="8" string="outcry" />
            <token id="9" string="prompts" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="District" />
            <token id="13" string="Attorney" />
            <token id="14" string="Robert" />
            <token id="15" string="Philibosian" />
            <token id="16" string="to" />
            <token id="17" string="send" />
            <token id="18" string="the" />
            <token id="19" string="case" />
            <token id="20" string="to" />
            <token id="21" string="grand" />
            <token id="22" string="jurors" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="indict" />
            <token id="26" string="Buckey" />
            <token id="27" string=";" />
            <token id="28" string="his" />
            <token id="29" string="mother" />
            <token id="30" string="," />
            <token id="31" string="Peggy" />
            <token id="32" string="McMartin" />
            <token id="33" string="Buckey" />
            <token id="34" string=";" />
            <token id="35" string="his" />
            <token id="36" string="sister" />
            <token id="37" string="," />
            <token id="38" string="Peggy" />
            <token id="39" string="Ann" />
            <token id="40" string="Buckey" />
            <token id="41" string=";" />
            <token id="42" string="his" />
            <token id="43" string="grandmother" />
            <token id="44" string="Virginia" />
            <token id="45" string="McMartin" />
            <token id="46" string="," />
            <token id="47" string="and" />
            <token id="48" string="three" />
            <token id="49" string="employees" />
            <token id="50" string="," />
            <token id="51" string="Mary" />
            <token id="52" string="Ann" />
            <token id="53" string="Jackson" />
            <token id="54" string="," />
            <token id="55" string="Babette" />
            <token id="56" string="Spitler" />
            <token id="57" string="and" />
            <token id="58" string="Betty" />
            <token id="59" string="Raidor" />
            <token id="60" string="," />
            <token id="61" string="on" />
            <token id="62" string="115" />
            <token id="63" string="charges" />
            <token id="64" string="of" />
            <token id="65" string="child" />
            <token id="66" string="molestation" />
            <token id="67" string="." />
          </tokens>
        </chunking>
        <chunking id="7" string="send the case to grand jurors , who indict Buckey ; his mother , Peggy McMartin Buckey ; his sister , Peggy Ann Buckey ; his grandmother Virginia McMartin , and three employees , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="VP">
          <tokens>
            <token id="17" string="send" />
            <token id="18" string="the" />
            <token id="19" string="case" />
            <token id="20" string="to" />
            <token id="21" string="grand" />
            <token id="22" string="jurors" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="indict" />
            <token id="26" string="Buckey" />
            <token id="27" string=";" />
            <token id="28" string="his" />
            <token id="29" string="mother" />
            <token id="30" string="," />
            <token id="31" string="Peggy" />
            <token id="32" string="McMartin" />
            <token id="33" string="Buckey" />
            <token id="34" string=";" />
            <token id="35" string="his" />
            <token id="36" string="sister" />
            <token id="37" string="," />
            <token id="38" string="Peggy" />
            <token id="39" string="Ann" />
            <token id="40" string="Buckey" />
            <token id="41" string=";" />
            <token id="42" string="his" />
            <token id="43" string="grandmother" />
            <token id="44" string="Virginia" />
            <token id="45" string="McMartin" />
            <token id="46" string="," />
            <token id="47" string="and" />
            <token id="48" string="three" />
            <token id="49" string="employees" />
            <token id="50" string="," />
            <token id="51" string="Mary" />
            <token id="52" string="Ann" />
            <token id="53" string="Jackson" />
            <token id="54" string="," />
            <token id="55" string="Babette" />
            <token id="56" string="Spitler" />
            <token id="57" string="and" />
            <token id="58" string="Betty" />
            <token id="59" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="8" string="Buckey" type="NP">
          <tokens>
            <token id="26" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="9" string="the case to grand jurors , who indict Buckey" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="case" />
            <token id="20" string="to" />
            <token id="21" string="grand" />
            <token id="22" string="jurors" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="indict" />
            <token id="26" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="10" string="who indict Buckey" type="SBAR">
          <tokens>
            <token id="24" string="who" />
            <token id="25" string="indict" />
            <token id="26" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="11" string="three employees , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="NP">
          <tokens>
            <token id="48" string="three" />
            <token id="49" string="employees" />
            <token id="50" string="," />
            <token id="51" string="Mary" />
            <token id="52" string="Ann" />
            <token id="53" string="Jackson" />
            <token id="54" string="," />
            <token id="55" string="Babette" />
            <token id="56" string="Spitler" />
            <token id="57" string="and" />
            <token id="58" string="Betty" />
            <token id="59" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="12" string="Peggy Ann Buckey" type="NP">
          <tokens>
            <token id="38" string="Peggy" />
            <token id="39" string="Ann" />
            <token id="40" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="13" string="his mother , Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="28" string="his" />
            <token id="29" string="mother" />
            <token id="30" string="," />
            <token id="31" string="Peggy" />
            <token id="32" string="McMartin" />
            <token id="33" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="14" string="his mother" type="NP">
          <tokens>
            <token id="28" string="his" />
            <token id="29" string="mother" />
          </tokens>
        </chunking>
        <chunking id="15" string="Public outcry" type="NP">
          <tokens>
            <token id="7" string="Public" />
            <token id="8" string="outcry" />
          </tokens>
        </chunking>
        <chunking id="16" string="Babette Spitler" type="NP">
          <tokens>
            <token id="55" string="Babette" />
            <token id="56" string="Spitler" />
          </tokens>
        </chunking>
        <chunking id="17" string="indict Buckey" type="VP">
          <tokens>
            <token id="25" string="indict" />
            <token id="26" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="18" string="115 charges" type="NP">
          <tokens>
            <token id="62" string="115" />
            <token id="63" string="charges" />
          </tokens>
        </chunking>
        <chunking id="19" string="115 charges of child molestation" type="NP">
          <tokens>
            <token id="62" string="115" />
            <token id="63" string="charges" />
            <token id="64" string="of" />
            <token id="65" string="child" />
            <token id="66" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="20" string="_ March 22 , 1984" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="March" />
            <token id="3" string="22" />
            <token id="4" string="," />
            <token id="5" string="1984" />
          </tokens>
        </chunking>
        <chunking id="21" string="Virginia McMartin" type="NP">
          <tokens>
            <token id="44" string="Virginia" />
            <token id="45" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="22" string="child molestation" type="NP">
          <tokens>
            <token id="65" string="child" />
            <token id="66" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="23" string="grand jurors" type="NP">
          <tokens>
            <token id="21" string="grand" />
            <token id="22" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="24" string="Betty Raidor" type="NP">
          <tokens>
            <token id="58" string="Betty" />
            <token id="59" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="25" string="his grandmother" type="NP">
          <tokens>
            <token id="42" string="his" />
            <token id="43" string="grandmother" />
          </tokens>
        </chunking>
        <chunking id="26" string="Los Angeles District Attorney Robert Philibosian" type="NP">
          <tokens>
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="District" />
            <token id="13" string="Attorney" />
            <token id="14" string="Robert" />
            <token id="15" string="Philibosian" />
          </tokens>
        </chunking>
        <chunking id="27" string="his sister , Peggy Ann Buckey" type="NP">
          <tokens>
            <token id="35" string="his" />
            <token id="36" string="sister" />
            <token id="37" string="," />
            <token id="38" string="Peggy" />
            <token id="39" string="Ann" />
            <token id="40" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="28" string="three employees" type="NP">
          <tokens>
            <token id="48" string="three" />
            <token id="49" string="employees" />
          </tokens>
        </chunking>
        <chunking id="29" string="prompts Los Angeles District Attorney Robert Philibosian to send the case to grand jurors , who indict Buckey ; his mother , Peggy McMartin Buckey ; his sister , Peggy Ann Buckey ; his grandmother Virginia McMartin , and three employees , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="VP">
          <tokens>
            <token id="9" string="prompts" />
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
            <token id="12" string="District" />
            <token id="13" string="Attorney" />
            <token id="14" string="Robert" />
            <token id="15" string="Philibosian" />
            <token id="16" string="to" />
            <token id="17" string="send" />
            <token id="18" string="the" />
            <token id="19" string="case" />
            <token id="20" string="to" />
            <token id="21" string="grand" />
            <token id="22" string="jurors" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="indict" />
            <token id="26" string="Buckey" />
            <token id="27" string=";" />
            <token id="28" string="his" />
            <token id="29" string="mother" />
            <token id="30" string="," />
            <token id="31" string="Peggy" />
            <token id="32" string="McMartin" />
            <token id="33" string="Buckey" />
            <token id="34" string=";" />
            <token id="35" string="his" />
            <token id="36" string="sister" />
            <token id="37" string="," />
            <token id="38" string="Peggy" />
            <token id="39" string="Ann" />
            <token id="40" string="Buckey" />
            <token id="41" string=";" />
            <token id="42" string="his" />
            <token id="43" string="grandmother" />
            <token id="44" string="Virginia" />
            <token id="45" string="McMartin" />
            <token id="46" string="," />
            <token id="47" string="and" />
            <token id="48" string="three" />
            <token id="49" string="employees" />
            <token id="50" string="," />
            <token id="51" string="Mary" />
            <token id="52" string="Ann" />
            <token id="53" string="Jackson" />
            <token id="54" string="," />
            <token id="55" string="Babette" />
            <token id="56" string="Spitler" />
            <token id="57" string="and" />
            <token id="58" string="Betty" />
            <token id="59" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="30" string="to send the case to grand jurors , who indict Buckey ; his mother , Peggy McMartin Buckey ; his sister , Peggy Ann Buckey ; his grandmother Virginia McMartin , and three employees , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="send" />
            <token id="18" string="the" />
            <token id="19" string="case" />
            <token id="20" string="to" />
            <token id="21" string="grand" />
            <token id="22" string="jurors" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="indict" />
            <token id="26" string="Buckey" />
            <token id="27" string=";" />
            <token id="28" string="his" />
            <token id="29" string="mother" />
            <token id="30" string="," />
            <token id="31" string="Peggy" />
            <token id="32" string="McMartin" />
            <token id="33" string="Buckey" />
            <token id="34" string=";" />
            <token id="35" string="his" />
            <token id="36" string="sister" />
            <token id="37" string="," />
            <token id="38" string="Peggy" />
            <token id="39" string="Ann" />
            <token id="40" string="Buckey" />
            <token id="41" string=";" />
            <token id="42" string="his" />
            <token id="43" string="grandmother" />
            <token id="44" string="Virginia" />
            <token id="45" string="McMartin" />
            <token id="46" string="," />
            <token id="47" string="and" />
            <token id="48" string="three" />
            <token id="49" string="employees" />
            <token id="50" string="," />
            <token id="51" string="Mary" />
            <token id="52" string="Ann" />
            <token id="53" string="Jackson" />
            <token id="54" string="," />
            <token id="55" string="Babette" />
            <token id="56" string="Spitler" />
            <token id="57" string="and" />
            <token id="58" string="Betty" />
            <token id="59" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="31" string="his grandmother Virginia McMartin" type="NP">
          <tokens>
            <token id="42" string="his" />
            <token id="43" string="grandmother" />
            <token id="44" string="Virginia" />
            <token id="45" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="32" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="33" string="grand jurors , who indict Buckey" type="NP">
          <tokens>
            <token id="21" string="grand" />
            <token id="22" string="jurors" />
            <token id="23" string="," />
            <token id="24" string="who" />
            <token id="25" string="indict" />
            <token id="26" string="Buckey" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">March</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">March</governor>
          <dependent id="3">22</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">March</governor>
          <dependent id="5">1984</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">outcry</governor>
          <dependent id="7">Public</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">prompts</governor>
          <dependent id="8">outcry</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">_</governor>
          <dependent id="9">prompts</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Philibosian</governor>
          <dependent id="10">Los</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Philibosian</governor>
          <dependent id="11">Angeles</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Philibosian</governor>
          <dependent id="12">District</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Philibosian</governor>
          <dependent id="13">Attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Philibosian</governor>
          <dependent id="14">Robert</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">prompts</governor>
          <dependent id="15">Philibosian</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">send</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">prompts</governor>
          <dependent id="17">send</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">case</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">send</governor>
          <dependent id="19">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">jurors</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">jurors</governor>
          <dependent id="21">grand</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">case</governor>
          <dependent id="22">jurors</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">indict</governor>
          <dependent id="24">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">jurors</governor>
          <dependent id="25">indict</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">indict</governor>
          <dependent id="26">Buckey</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">mother</governor>
          <dependent id="28">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">case</governor>
          <dependent id="29">mother</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Buckey</governor>
          <dependent id="31">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">Buckey</governor>
          <dependent id="32">McMartin</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="29">mother</governor>
          <dependent id="33">Buckey</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="36">sister</governor>
          <dependent id="35">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">case</governor>
          <dependent id="36">sister</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">Buckey</governor>
          <dependent id="38">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">Buckey</governor>
          <dependent id="39">Ann</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="36">sister</governor>
          <dependent id="40">Buckey</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="43">grandmother</governor>
          <dependent id="42">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">case</governor>
          <dependent id="43">grandmother</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="45">McMartin</governor>
          <dependent id="44">Virginia</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="43">grandmother</governor>
          <dependent id="45">McMartin</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">case</governor>
          <dependent id="47">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="49">employees</governor>
          <dependent id="48">three</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">case</governor>
          <dependent id="49">employees</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="53">Jackson</governor>
          <dependent id="51">Mary</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="53">Jackson</governor>
          <dependent id="52">Ann</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="49">employees</governor>
          <dependent id="53">Jackson</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="56">Spitler</governor>
          <dependent id="55">Babette</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="49">employees</governor>
          <dependent id="56">Spitler</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="49">employees</governor>
          <dependent id="57">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="59">Raidor</governor>
          <dependent id="58">Betty</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="49">employees</governor>
          <dependent id="59">Raidor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="63">charges</governor>
          <dependent id="61">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="63">charges</governor>
          <dependent id="62">115</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">_</governor>
          <dependent id="63">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="66">molestation</governor>
          <dependent id="64">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="66">molestation</governor>
          <dependent id="65">child</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="63">charges</governor>
          <dependent id="66">molestation</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="March 22 , 1984" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="March" />
            <token id="3" string="22" />
            <token id="4" string="," />
            <token id="5" string="1984" />
          </tokens>
        </entity>
        <entity id="2" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Peggy" />
            <token id="32" string="McMartin" />
            <token id="33" string="Buckey" />
          </tokens>
        </entity>
        <entity id="3" string="Mary Ann Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="51" string="Mary" />
            <token id="52" string="Ann" />
            <token id="53" string="Jackson" />
          </tokens>
        </entity>
        <entity id="4" string="Robert Philibosian" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Robert" />
            <token id="15" string="Philibosian" />
          </tokens>
        </entity>
        <entity id="5" string="Virginia McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="44" string="Virginia" />
            <token id="45" string="McMartin" />
          </tokens>
        </entity>
        <entity id="6" string="Betty Raidor" type="PERSON" score="0.0">
          <tokens>
            <token id="58" string="Betty" />
            <token id="59" string="Raidor" />
          </tokens>
        </entity>
        <entity id="7" string="three" type="NUMBER" score="0.0">
          <tokens>
            <token id="48" string="three" />
          </tokens>
        </entity>
        <entity id="8" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Buckey" />
          </tokens>
        </entity>
        <entity id="9" string="115" type="NUMBER" score="0.0">
          <tokens>
            <token id="62" string="115" />
          </tokens>
        </entity>
        <entity id="10" string="Peggy Ann Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="Peggy" />
            <token id="39" string="Ann" />
            <token id="40" string="Buckey" />
          </tokens>
        </entity>
        <entity id="11" string="Babette Spitler" type="PERSON" score="0.0">
          <tokens>
            <token id="55" string="Babette" />
            <token id="56" string="Spitler" />
          </tokens>
        </entity>
        <entity id="12" string="Los Angeles" type="LOCATION" score="0.0">
          <tokens>
            <token id="10" string="Los" />
            <token id="11" string="Angeles" />
          </tokens>
        </entity>
        <entity id="13" string="Attorney" type="TITLE" score="0.0">
          <tokens>
            <token id="13" string="Attorney" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="false">
      <content>_March 24, 1984: All seven defendants are arrested and jailed.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="March" lemma="March" stem="march" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="24" lemma="24" stem="24" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="All" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="arrested" lemma="arrest" stem="arrest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="jailed" lemma="jail" stem="jail" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP March) (CD 24) (, ,) (CD 1984))) (: :) (NP (NP (DT All) (CD seven) (NNS defendants)) (SBAR (S (VP (VBP are) (VP (VBN arrested) (CC and) (VBN jailed)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="_ March 24 , 1984 : All seven defendants are arrested and jailed ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="March" />
            <token id="3" string="24" />
            <token id="4" string="," />
            <token id="5" string="1984" />
            <token id="6" string=":" />
            <token id="7" string="All" />
            <token id="8" string="seven" />
            <token id="9" string="defendants" />
            <token id="10" string="are" />
            <token id="11" string="arrested" />
            <token id="12" string="and" />
            <token id="13" string="jailed" />
            <token id="14" string="." />
          </tokens>
        </chunking>
        <chunking id="2" string="All seven defendants" type="NP">
          <tokens>
            <token id="7" string="All" />
            <token id="8" string="seven" />
            <token id="9" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="3" string="are arrested and jailed" type="SBAR">
          <tokens>
            <token id="10" string="are" />
            <token id="11" string="arrested" />
            <token id="12" string="and" />
            <token id="13" string="jailed" />
          </tokens>
        </chunking>
        <chunking id="4" string="All seven defendants are arrested and jailed" type="NP">
          <tokens>
            <token id="7" string="All" />
            <token id="8" string="seven" />
            <token id="9" string="defendants" />
            <token id="10" string="are" />
            <token id="11" string="arrested" />
            <token id="12" string="and" />
            <token id="13" string="jailed" />
          </tokens>
        </chunking>
        <chunking id="5" string="_ March 24 , 1984" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="March" />
            <token id="3" string="24" />
            <token id="4" string="," />
            <token id="5" string="1984" />
          </tokens>
        </chunking>
        <chunking id="6" string="arrested and jailed" type="VP">
          <tokens>
            <token id="11" string="arrested" />
            <token id="12" string="and" />
            <token id="13" string="jailed" />
          </tokens>
        </chunking>
        <chunking id="7" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">March</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">March</governor>
          <dependent id="3">24</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">March</governor>
          <dependent id="5">1984</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">defendants</governor>
          <dependent id="7">All</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">defendants</governor>
          <dependent id="8">seven</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="9">defendants</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">arrested</governor>
          <dependent id="10">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">defendants</governor>
          <dependent id="11">arrested</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">arrested</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">arrested</governor>
          <dependent id="13">jailed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="March 24 , 1984" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="March" />
            <token id="3" string="24" />
            <token id="4" string="," />
            <token id="5" string="1984" />
          </tokens>
        </entity>
        <entity id="2" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="seven" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Buckey and his mother are held without bail.</content>
      <tokens>
        <token id="1" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="5" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="held" lemma="hold" stem="held" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="bail" lemma="bail" stem="bail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Buckey)) (CC and) (NP (PRP$ his) (NN mother))) (VP (VBP are) (VP (VBN held) (PP (IN without) (NP (NN bail))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Buckey" type="NP">
          <tokens>
            <token id="1" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="held without bail" type="VP">
          <tokens>
            <token id="6" string="held" />
            <token id="7" string="without" />
            <token id="8" string="bail" />
          </tokens>
        </chunking>
        <chunking id="3" string="his mother" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="mother" />
          </tokens>
        </chunking>
        <chunking id="4" string="are held without bail" type="VP">
          <tokens>
            <token id="5" string="are" />
            <token id="6" string="held" />
            <token id="7" string="without" />
            <token id="8" string="bail" />
          </tokens>
        </chunking>
        <chunking id="5" string="Buckey and his mother" type="NP">
          <tokens>
            <token id="1" string="Buckey" />
            <token id="2" string="and" />
            <token id="3" string="his" />
            <token id="4" string="mother" />
          </tokens>
        </chunking>
        <chunking id="6" string="bail" type="NP">
          <tokens>
            <token id="8" string="bail" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="6">held</governor>
          <dependent id="1">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Buckey</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">mother</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Buckey</governor>
          <dependent id="4">mother</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">held</governor>
          <dependent id="5">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">held</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">bail</governor>
          <dependent id="7">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">held</governor>
          <dependent id="8">bail</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Bail for he others ranges from $50,000 to $350,000.</content>
      <tokens>
        <token id="1" string="Bail" lemma="bail" stem="bail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="ranges" lemma="range" stem="rang" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="8" string="50,000" lemma="50,000" stem="50,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="11" string="350,000" lemma="350,000" stem="350,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Bail)) (PP (IN for) (NP (PRP he) (NNS others)))) (VP (VBZ ranges) (PP (IN from) (NP (QP ($ $) (CD 50,000) (TO to) ($ $) (CD 350,000))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Bail for he others" type="NP">
          <tokens>
            <token id="1" string="Bail" />
            <token id="2" string="for" />
            <token id="3" string="he" />
            <token id="4" string="others" />
          </tokens>
        </chunking>
        <chunking id="2" string="$ 50,000 to $ 350,000" type="NP">
          <tokens>
            <token id="7" string="$" />
            <token id="8" string="50,000" />
            <token id="9" string="to" />
            <token id="10" string="$" />
            <token id="11" string="350,000" />
          </tokens>
        </chunking>
        <chunking id="3" string="ranges from $ 50,000 to $ 350,000" type="VP">
          <tokens>
            <token id="5" string="ranges" />
            <token id="6" string="from" />
            <token id="7" string="$" />
            <token id="8" string="50,000" />
            <token id="9" string="to" />
            <token id="10" string="$" />
            <token id="11" string="350,000" />
          </tokens>
        </chunking>
        <chunking id="4" string="he others" type="NP">
          <tokens>
            <token id="3" string="he" />
            <token id="4" string="others" />
          </tokens>
        </chunking>
        <chunking id="5" string="Bail" type="NP">
          <tokens>
            <token id="1" string="Bail" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">ranges</governor>
          <dependent id="1">Bail</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">others</governor>
          <dependent id="2">for</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">others</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Bail</governor>
          <dependent id="4">others</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">ranges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">$</governor>
          <dependent id="6">from</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">$</governor>
          <dependent id="7">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">$</governor>
          <dependent id="8">50,000</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">$</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">ranges</governor>
          <dependent id="10">$</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">$</governor>
          <dependent id="11">350,000</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 50,000" type="MONEY" score="0.0">
          <tokens>
            <token id="7" string="$" />
            <token id="8" string="50,000" />
          </tokens>
        </entity>
        <entity id="2" string="$ 350,000" type="MONEY" score="0.0">
          <tokens>
            <token id="10" string="$" />
            <token id="11" string="350,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Lael Rubin, Christine Johnston and Glenn Stevens are assigned to the prosecution team.</content>
      <tokens>
        <token id="1" string="Lael" lemma="Lael" stem="lael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Rubin" lemma="Rubin" stem="rubin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Christine" lemma="Christine" stem="christin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Johnston" lemma="Johnston" stem="johnston" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Glenn" lemma="Glenn" stem="glenn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Stevens" lemma="Stevens" stem="steven" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="assigned" lemma="assign" stem="assign" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="prosecution" lemma="prosecution" stem="prosecut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="team" lemma="team" stem="team" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Lael) (NNP Rubin)) (, ,) (NP (NNP Christine) (NNP Johnston)) (CC and) (NP (NNP Glenn) (NNP Stevens))) (VP (VBP are) (VP (VBN assigned) (PP (TO to) (NP (DT the) (NN prosecution) (NN team))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are assigned to the prosecution team" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="assigned" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="prosecution" />
            <token id="14" string="team" />
          </tokens>
        </chunking>
        <chunking id="2" string="Christine Johnston" type="NP">
          <tokens>
            <token id="4" string="Christine" />
            <token id="5" string="Johnston" />
          </tokens>
        </chunking>
        <chunking id="3" string="assigned to the prosecution team" type="VP">
          <tokens>
            <token id="10" string="assigned" />
            <token id="11" string="to" />
            <token id="12" string="the" />
            <token id="13" string="prosecution" />
            <token id="14" string="team" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lael Rubin" type="NP">
          <tokens>
            <token id="1" string="Lael" />
            <token id="2" string="Rubin" />
          </tokens>
        </chunking>
        <chunking id="5" string="Glenn Stevens" type="NP">
          <tokens>
            <token id="7" string="Glenn" />
            <token id="8" string="Stevens" />
          </tokens>
        </chunking>
        <chunking id="6" string="the prosecution team" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="prosecution" />
            <token id="14" string="team" />
          </tokens>
        </chunking>
        <chunking id="7" string="Lael Rubin , Christine Johnston and Glenn Stevens" type="NP">
          <tokens>
            <token id="1" string="Lael" />
            <token id="2" string="Rubin" />
            <token id="3" string="," />
            <token id="4" string="Christine" />
            <token id="5" string="Johnston" />
            <token id="6" string="and" />
            <token id="7" string="Glenn" />
            <token id="8" string="Stevens" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Rubin</governor>
          <dependent id="1">Lael</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">assigned</governor>
          <dependent id="2">Rubin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Johnston</governor>
          <dependent id="4">Christine</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Rubin</governor>
          <dependent id="5">Johnston</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">Rubin</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Stevens</governor>
          <dependent id="7">Glenn</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">Rubin</governor>
          <dependent id="8">Stevens</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">assigned</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">assigned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">team</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">team</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">team</governor>
          <dependent id="13">prosecution</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">assigned</governor>
          <dependent id="14">team</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Christine Johnston" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Christine" />
            <token id="5" string="Johnston" />
          </tokens>
        </entity>
        <entity id="2" string="Lael Rubin" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lael" />
            <token id="2" string="Rubin" />
          </tokens>
        </entity>
        <entity id="3" string="Glenn Stevens" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Glenn" />
            <token id="8" string="Stevens" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Stevens is later removed for expressing doubts about evidence, and Ms. Johnston asks for reassignment.</content>
      <tokens>
        <token id="1" string="Stevens" lemma="Stevens" stem="steven" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="removed" lemma="remove" stem="remov" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="expressing" lemma="express" stem="express" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="doubts" lemma="doubt" stem="doubt" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="Johnston" lemma="Johnston" stem="johnston" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="asks" lemma="ask" stem="ask" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="reassignment" lemma="reassignment" stem="reassign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Stevens)) (VP (VBZ is) (ADVP (RB later)) (VP (VBN removed) (PP (IN for) (S (VP (VBG expressing) (NP (NNS doubts)) (PP (IN about) (NP (NN evidence))))))))) (, ,) (CC and) (S (NP (NNP Ms.) (NNP Johnston)) (VP (VBZ asks) (PP (IN for) (NP (NN reassignment))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ms. Johnston" type="NP">
          <tokens>
            <token id="12" string="Ms." />
            <token id="13" string="Johnston" />
          </tokens>
        </chunking>
        <chunking id="2" string="doubts" type="NP">
          <tokens>
            <token id="7" string="doubts" />
          </tokens>
        </chunking>
        <chunking id="3" string="expressing doubts about evidence" type="VP">
          <tokens>
            <token id="6" string="expressing" />
            <token id="7" string="doubts" />
            <token id="8" string="about" />
            <token id="9" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="4" string="removed for expressing doubts about evidence" type="VP">
          <tokens>
            <token id="4" string="removed" />
            <token id="5" string="for" />
            <token id="6" string="expressing" />
            <token id="7" string="doubts" />
            <token id="8" string="about" />
            <token id="9" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="5" string="evidence" type="NP">
          <tokens>
            <token id="9" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="6" string="asks for reassignment" type="VP">
          <tokens>
            <token id="14" string="asks" />
            <token id="15" string="for" />
            <token id="16" string="reassignment" />
          </tokens>
        </chunking>
        <chunking id="7" string="Stevens" type="NP">
          <tokens>
            <token id="1" string="Stevens" />
          </tokens>
        </chunking>
        <chunking id="8" string="is later removed for expressing doubts about evidence" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="later" />
            <token id="4" string="removed" />
            <token id="5" string="for" />
            <token id="6" string="expressing" />
            <token id="7" string="doubts" />
            <token id="8" string="about" />
            <token id="9" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="9" string="reassignment" type="NP">
          <tokens>
            <token id="16" string="reassignment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">removed</governor>
          <dependent id="1">Stevens</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">removed</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">removed</governor>
          <dependent id="3">later</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">removed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">expressing</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">removed</governor>
          <dependent id="6">expressing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">expressing</governor>
          <dependent id="7">doubts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">evidence</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">expressing</governor>
          <dependent id="9">evidence</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">removed</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Johnston</governor>
          <dependent id="12">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">asks</governor>
          <dependent id="13">Johnston</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">removed</governor>
          <dependent id="14">asks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">reassignment</governor>
          <dependent id="15">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">asks</governor>
          <dependent id="16">reassignment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Stevens" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Stevens" />
          </tokens>
        </entity>
        <entity id="2" string="Johnston" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Johnston" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>_April 20, 1984: The seven defendants plead innocent at an arraignment, during which they are charged with sexually abusing 18 children over 10 years and using death threats to silence them.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="9" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="plead" lemma="plead" stem="plead" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="innocent" lemma="innocent" stem="innoc" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="arraignment" lemma="arraignment" stem="arraign" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="charged" lemma="charge" stem="charg" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="sexually" lemma="sexually" stem="sexual" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="abusing" lemma="abuse" stem="abus" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="18" lemma="18" stem="18" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="25" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="28" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="death" lemma="death" stem="death" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="threats" lemma="threat" stem="threat" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="silence" lemma="silence" stem="silenc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP April) (CD 20) (, ,) (CD 1984))) (: :) (S (NP (DT The) (CD seven) (NNS defendants)) (VP (VB plead) (ADJP (JJ innocent) (PP (IN at) (NP (NP (DT an) (NN arraignment)) (, ,) (SBAR (WHPP (IN during) (WHNP (WDT which))) (S (NP (PRP they)) (VP (VBP are) (VP (VBN charged) (PP (IN with) (S (VP (VP (ADVP (RB sexually)) (VBG abusing) (NP (NP (CD 18) (NNS children)) (PP (IN over) (NP (CD 10) (NNS years))))) (CC and) (VP (VBG using) (NP (NN death) (NNS threats)) (PP (TO to) (NP (NN silence)))) (NP (PRP them)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an arraignment , during which they are charged with sexually abusing 18 children over 10 years and using death threats to silence them" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="arraignment" />
            <token id="15" string="," />
            <token id="16" string="during" />
            <token id="17" string="which" />
            <token id="18" string="they" />
            <token id="19" string="are" />
            <token id="20" string="charged" />
            <token id="21" string="with" />
            <token id="22" string="sexually" />
            <token id="23" string="abusing" />
            <token id="24" string="18" />
            <token id="25" string="children" />
            <token id="26" string="over" />
            <token id="27" string="10" />
            <token id="28" string="years" />
            <token id="29" string="and" />
            <token id="30" string="using" />
            <token id="31" string="death" />
            <token id="32" string="threats" />
            <token id="33" string="to" />
            <token id="34" string="silence" />
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="2" string="_ April 20 , 1984 : The seven defendants plead innocent at an arraignment , during which they are charged with sexually abusing 18 children over 10 years and using death threats to silence them ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="April" />
            <token id="3" string="20" />
            <token id="4" string="," />
            <token id="5" string="1984" />
            <token id="6" string=":" />
            <token id="7" string="The" />
            <token id="8" string="seven" />
            <token id="9" string="defendants" />
            <token id="10" string="plead" />
            <token id="11" string="innocent" />
            <token id="12" string="at" />
            <token id="13" string="an" />
            <token id="14" string="arraignment" />
            <token id="15" string="," />
            <token id="16" string="during" />
            <token id="17" string="which" />
            <token id="18" string="they" />
            <token id="19" string="are" />
            <token id="20" string="charged" />
            <token id="21" string="with" />
            <token id="22" string="sexually" />
            <token id="23" string="abusing" />
            <token id="24" string="18" />
            <token id="25" string="children" />
            <token id="26" string="over" />
            <token id="27" string="10" />
            <token id="28" string="years" />
            <token id="29" string="and" />
            <token id="30" string="using" />
            <token id="31" string="death" />
            <token id="32" string="threats" />
            <token id="33" string="to" />
            <token id="34" string="silence" />
            <token id="35" string="them" />
            <token id="36" string="." />
          </tokens>
        </chunking>
        <chunking id="3" string="18 children over 10 years" type="NP">
          <tokens>
            <token id="24" string="18" />
            <token id="25" string="children" />
            <token id="26" string="over" />
            <token id="27" string="10" />
            <token id="28" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="using death threats to silence" type="VP">
          <tokens>
            <token id="30" string="using" />
            <token id="31" string="death" />
            <token id="32" string="threats" />
            <token id="33" string="to" />
            <token id="34" string="silence" />
          </tokens>
        </chunking>
        <chunking id="5" string="are charged with sexually abusing 18 children over 10 years and using death threats to silence them" type="VP">
          <tokens>
            <token id="19" string="are" />
            <token id="20" string="charged" />
            <token id="21" string="with" />
            <token id="22" string="sexually" />
            <token id="23" string="abusing" />
            <token id="24" string="18" />
            <token id="25" string="children" />
            <token id="26" string="over" />
            <token id="27" string="10" />
            <token id="28" string="years" />
            <token id="29" string="and" />
            <token id="30" string="using" />
            <token id="31" string="death" />
            <token id="32" string="threats" />
            <token id="33" string="to" />
            <token id="34" string="silence" />
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="death threats" type="NP">
          <tokens>
            <token id="31" string="death" />
            <token id="32" string="threats" />
          </tokens>
        </chunking>
        <chunking id="7" string="10 years" type="NP">
          <tokens>
            <token id="27" string="10" />
            <token id="28" string="years" />
          </tokens>
        </chunking>
        <chunking id="8" string="them" type="NP">
          <tokens>
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="The seven defendants" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="seven" />
            <token id="9" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="10" string="_ April 20 , 1984" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="April" />
            <token id="3" string="20" />
            <token id="4" string="," />
            <token id="5" string="1984" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="18" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="innocent at an arraignment , during which they are charged with sexually abusing 18 children over 10 years and using death threats to silence them" type="ADJP">
          <tokens>
            <token id="11" string="innocent" />
            <token id="12" string="at" />
            <token id="13" string="an" />
            <token id="14" string="arraignment" />
            <token id="15" string="," />
            <token id="16" string="during" />
            <token id="17" string="which" />
            <token id="18" string="they" />
            <token id="19" string="are" />
            <token id="20" string="charged" />
            <token id="21" string="with" />
            <token id="22" string="sexually" />
            <token id="23" string="abusing" />
            <token id="24" string="18" />
            <token id="25" string="children" />
            <token id="26" string="over" />
            <token id="27" string="10" />
            <token id="28" string="years" />
            <token id="29" string="and" />
            <token id="30" string="using" />
            <token id="31" string="death" />
            <token id="32" string="threats" />
            <token id="33" string="to" />
            <token id="34" string="silence" />
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="13" string="plead innocent at an arraignment , during which they are charged with sexually abusing 18 children over 10 years and using death threats to silence them" type="VP">
          <tokens>
            <token id="10" string="plead" />
            <token id="11" string="innocent" />
            <token id="12" string="at" />
            <token id="13" string="an" />
            <token id="14" string="arraignment" />
            <token id="15" string="," />
            <token id="16" string="during" />
            <token id="17" string="which" />
            <token id="18" string="they" />
            <token id="19" string="are" />
            <token id="20" string="charged" />
            <token id="21" string="with" />
            <token id="22" string="sexually" />
            <token id="23" string="abusing" />
            <token id="24" string="18" />
            <token id="25" string="children" />
            <token id="26" string="over" />
            <token id="27" string="10" />
            <token id="28" string="years" />
            <token id="29" string="and" />
            <token id="30" string="using" />
            <token id="31" string="death" />
            <token id="32" string="threats" />
            <token id="33" string="to" />
            <token id="34" string="silence" />
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="14" string="sexually abusing 18 children over 10 years and using death threats to silence them" type="VP">
          <tokens>
            <token id="22" string="sexually" />
            <token id="23" string="abusing" />
            <token id="24" string="18" />
            <token id="25" string="children" />
            <token id="26" string="over" />
            <token id="27" string="10" />
            <token id="28" string="years" />
            <token id="29" string="and" />
            <token id="30" string="using" />
            <token id="31" string="death" />
            <token id="32" string="threats" />
            <token id="33" string="to" />
            <token id="34" string="silence" />
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="15" string="18 children" type="NP">
          <tokens>
            <token id="24" string="18" />
            <token id="25" string="children" />
          </tokens>
        </chunking>
        <chunking id="16" string="during which they are charged with sexually abusing 18 children over 10 years and using death threats to silence them" type="SBAR">
          <tokens>
            <token id="16" string="during" />
            <token id="17" string="which" />
            <token id="18" string="they" />
            <token id="19" string="are" />
            <token id="20" string="charged" />
            <token id="21" string="with" />
            <token id="22" string="sexually" />
            <token id="23" string="abusing" />
            <token id="24" string="18" />
            <token id="25" string="children" />
            <token id="26" string="over" />
            <token id="27" string="10" />
            <token id="28" string="years" />
            <token id="29" string="and" />
            <token id="30" string="using" />
            <token id="31" string="death" />
            <token id="32" string="threats" />
            <token id="33" string="to" />
            <token id="34" string="silence" />
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="17" string="sexually abusing 18 children over 10 years" type="VP">
          <tokens>
            <token id="22" string="sexually" />
            <token id="23" string="abusing" />
            <token id="24" string="18" />
            <token id="25" string="children" />
            <token id="26" string="over" />
            <token id="27" string="10" />
            <token id="28" string="years" />
          </tokens>
        </chunking>
        <chunking id="18" string="silence" type="NP">
          <tokens>
            <token id="34" string="silence" />
          </tokens>
        </chunking>
        <chunking id="19" string="charged with sexually abusing 18 children over 10 years and using death threats to silence them" type="VP">
          <tokens>
            <token id="20" string="charged" />
            <token id="21" string="with" />
            <token id="22" string="sexually" />
            <token id="23" string="abusing" />
            <token id="24" string="18" />
            <token id="25" string="children" />
            <token id="26" string="over" />
            <token id="27" string="10" />
            <token id="28" string="years" />
            <token id="29" string="and" />
            <token id="30" string="using" />
            <token id="31" string="death" />
            <token id="32" string="threats" />
            <token id="33" string="to" />
            <token id="34" string="silence" />
            <token id="35" string="them" />
          </tokens>
        </chunking>
        <chunking id="20" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="21" string="an arraignment" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="arraignment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">April</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">April</governor>
          <dependent id="3">20</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">April</governor>
          <dependent id="5">1984</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">defendants</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">defendants</governor>
          <dependent id="8">seven</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">plead</governor>
          <dependent id="9">defendants</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">_</governor>
          <dependent id="10">plead</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">plead</governor>
          <dependent id="11">innocent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">arraignment</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">arraignment</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">innocent</governor>
          <dependent id="14">arraignment</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">which</governor>
          <dependent id="16">during</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">charged</governor>
          <dependent id="17">which</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">charged</governor>
          <dependent id="18">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">charged</governor>
          <dependent id="19">are</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="14">arraignment</governor>
          <dependent id="20">charged</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">abusing</governor>
          <dependent id="21">with</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">abusing</governor>
          <dependent id="22">sexually</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">charged</governor>
          <dependent id="23">abusing</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="25">children</governor>
          <dependent id="24">18</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">abusing</governor>
          <dependent id="25">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">years</governor>
          <dependent id="26">over</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">years</governor>
          <dependent id="27">10</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">children</governor>
          <dependent id="28">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">abusing</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">abusing</governor>
          <dependent id="30">using</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">threats</governor>
          <dependent id="31">death</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">using</governor>
          <dependent id="32">threats</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">silence</governor>
          <dependent id="33">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">using</governor>
          <dependent id="34">silence</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">abusing</governor>
          <dependent id="35">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="April 20 , 1984" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="April" />
            <token id="3" string="20" />
            <token id="4" string="," />
            <token id="5" string="1984" />
          </tokens>
        </entity>
        <entity id="2" string="18" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="18" />
          </tokens>
        </entity>
        <entity id="3" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="seven" />
          </tokens>
        </entity>
        <entity id="4" string="10 years" type="DURATION" score="0.0">
          <tokens>
            <token id="27" string="10" />
            <token id="28" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>_June 6, 1984: A preliminary hearing starts with Municipal Judge Aviva K. Bobb presiding.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="June" lemma="June" stem="june" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="6" lemma="6" stem="6" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1984" lemma="1984" stem="1984" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="preliminary" lemma="preliminary" stem="preliminari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="starts" lemma="start" stem="start" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Municipal" lemma="municipal" stem="municip" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="Judge" lemma="Judge" stem="judg" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="14" string="Aviva" lemma="Aviva" stem="aviva" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="K." lemma="K." stem="k." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Bobb" lemma="Bobb" stem="bobb" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="presiding" lemma="preside" stem="presid" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP June) (CD 6) (, ,) (CD 1984))) (: :) (NP (NP (DT A) (JJ preliminary) (NN hearing)) (SBAR (S (VP (VBZ starts) (PP (IN with) (NP (NP (JJ Municipal) (NNP Judge) (NNP Aviva) (NNP K.) (NNP Bobb)) (VP (VBG presiding)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A preliminary hearing starts with Municipal Judge Aviva K. Bobb presiding" type="NP">
          <tokens>
            <token id="7" string="A" />
            <token id="8" string="preliminary" />
            <token id="9" string="hearing" />
            <token id="10" string="starts" />
            <token id="11" string="with" />
            <token id="12" string="Municipal" />
            <token id="13" string="Judge" />
            <token id="14" string="Aviva" />
            <token id="15" string="K." />
            <token id="16" string="Bobb" />
            <token id="17" string="presiding" />
          </tokens>
        </chunking>
        <chunking id="2" string="A preliminary hearing" type="NP">
          <tokens>
            <token id="7" string="A" />
            <token id="8" string="preliminary" />
            <token id="9" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="3" string="Municipal Judge Aviva K. Bobb" type="NP">
          <tokens>
            <token id="12" string="Municipal" />
            <token id="13" string="Judge" />
            <token id="14" string="Aviva" />
            <token id="15" string="K." />
            <token id="16" string="Bobb" />
          </tokens>
        </chunking>
        <chunking id="4" string="starts with Municipal Judge Aviva K. Bobb presiding" type="SBAR">
          <tokens>
            <token id="10" string="starts" />
            <token id="11" string="with" />
            <token id="12" string="Municipal" />
            <token id="13" string="Judge" />
            <token id="14" string="Aviva" />
            <token id="15" string="K." />
            <token id="16" string="Bobb" />
            <token id="17" string="presiding" />
          </tokens>
        </chunking>
        <chunking id="5" string="_ June 6 , 1984" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="June" />
            <token id="3" string="6" />
            <token id="4" string="," />
            <token id="5" string="1984" />
          </tokens>
        </chunking>
        <chunking id="6" string="Municipal Judge Aviva K. Bobb presiding" type="NP">
          <tokens>
            <token id="12" string="Municipal" />
            <token id="13" string="Judge" />
            <token id="14" string="Aviva" />
            <token id="15" string="K." />
            <token id="16" string="Bobb" />
            <token id="17" string="presiding" />
          </tokens>
        </chunking>
        <chunking id="7" string="presiding" type="VP">
          <tokens>
            <token id="17" string="presiding" />
          </tokens>
        </chunking>
        <chunking id="8" string="_ June 6 , 1984 : A preliminary hearing starts with Municipal Judge Aviva K. Bobb presiding ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="June" />
            <token id="3" string="6" />
            <token id="4" string="," />
            <token id="5" string="1984" />
            <token id="6" string=":" />
            <token id="7" string="A" />
            <token id="8" string="preliminary" />
            <token id="9" string="hearing" />
            <token id="10" string="starts" />
            <token id="11" string="with" />
            <token id="12" string="Municipal" />
            <token id="13" string="Judge" />
            <token id="14" string="Aviva" />
            <token id="15" string="K." />
            <token id="16" string="Bobb" />
            <token id="17" string="presiding" />
            <token id="18" string="." />
          </tokens>
        </chunking>
        <chunking id="9" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">June</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">June</governor>
          <dependent id="3">6</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">June</governor>
          <dependent id="5">1984</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">hearing</governor>
          <dependent id="7">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">hearing</governor>
          <dependent id="8">preliminary</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="9">hearing</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="9">hearing</governor>
          <dependent id="10">starts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Bobb</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">Bobb</governor>
          <dependent id="12">Municipal</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Bobb</governor>
          <dependent id="13">Judge</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Bobb</governor>
          <dependent id="14">Aviva</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Bobb</governor>
          <dependent id="15">K.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">starts</governor>
          <dependent id="16">Bobb</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">Bobb</governor>
          <dependent id="17">presiding</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="June 6 , 1984" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="June" />
            <token id="3" string="6" />
            <token id="4" string="," />
            <token id="5" string="1984" />
          </tokens>
        </entity>
        <entity id="2" string="Aviva K. Bobb" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Aviva" />
            <token id="15" string="K." />
            <token id="16" string="Bobb" />
          </tokens>
        </entity>
        <entity id="3" string="Judge" type="TITLE" score="0.0">
          <tokens>
            <token id="13" string="Judge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>Thirteen of the 41 alleged victims chosen from CII interviews take the stand during the 18-month hearing.</content>
      <tokens>
        <token id="1" string="Thirteen" lemma="thirteen" stem="thirteen" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="41" lemma="41" stem="41" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="alleged" lemma="allege" stem="alleg" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="victims" lemma="victim" stem="victim" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="chosen" lemma="choose" stem="chosen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="CII" lemma="CII" stem="cii" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="10" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="take" lemma="take" stem="take" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="stand" lemma="stand" stem="stand" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="18-month" lemma="18-month" stem="18-month" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="17" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (CD Thirteen)) (PP (IN of) (NP (NP (DT the) (CD 41) (VBN alleged) (NNS victims)) (VP (VBN chosen) (PP (IN from) (NP (NNP CII) (NNS interviews))))))) (VP (VBP take) (NP (DT the) (NN stand)) (PP (IN during) (NP (DT the) (JJ 18-month) (NN hearing)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the 41 alleged victims" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="41" />
            <token id="5" string="alleged" />
            <token id="6" string="victims" />
          </tokens>
        </chunking>
        <chunking id="2" string="take the stand during the 18-month hearing" type="VP">
          <tokens>
            <token id="11" string="take" />
            <token id="12" string="the" />
            <token id="13" string="stand" />
            <token id="14" string="during" />
            <token id="15" string="the" />
            <token id="16" string="18-month" />
            <token id="17" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="3" string="Thirteen of the 41 alleged victims chosen from CII interviews" type="NP">
          <tokens>
            <token id="1" string="Thirteen" />
            <token id="2" string="of" />
            <token id="3" string="the" />
            <token id="4" string="41" />
            <token id="5" string="alleged" />
            <token id="6" string="victims" />
            <token id="7" string="chosen" />
            <token id="8" string="from" />
            <token id="9" string="CII" />
            <token id="10" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="4" string="the stand" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="stand" />
          </tokens>
        </chunking>
        <chunking id="5" string="Thirteen" type="NP">
          <tokens>
            <token id="1" string="Thirteen" />
          </tokens>
        </chunking>
        <chunking id="6" string="chosen from CII interviews" type="VP">
          <tokens>
            <token id="7" string="chosen" />
            <token id="8" string="from" />
            <token id="9" string="CII" />
            <token id="10" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="7" string="the 18-month hearing" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="18-month" />
            <token id="17" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 41 alleged victims chosen from CII interviews" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="41" />
            <token id="5" string="alleged" />
            <token id="6" string="victims" />
            <token id="7" string="chosen" />
            <token id="8" string="from" />
            <token id="9" string="CII" />
            <token id="10" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="9" string="CII interviews" type="NP">
          <tokens>
            <token id="9" string="CII" />
            <token id="10" string="interviews" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="11">take</governor>
          <dependent id="1">Thirteen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">victims</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">victims</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">victims</governor>
          <dependent id="4">41</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">victims</governor>
          <dependent id="5">alleged</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Thirteen</governor>
          <dependent id="6">victims</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">victims</governor>
          <dependent id="7">chosen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">interviews</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">interviews</governor>
          <dependent id="9">CII</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">chosen</governor>
          <dependent id="10">interviews</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">stand</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">take</governor>
          <dependent id="13">stand</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">hearing</governor>
          <dependent id="14">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">hearing</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">hearing</governor>
          <dependent id="16">18-month</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">take</governor>
          <dependent id="17">hearing</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thirteen" type="NUMBER" score="0.0">
          <tokens>
            <token id="1" string="Thirteen" />
          </tokens>
        </entity>
        <entity id="2" string="CII" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="9" string="CII" />
          </tokens>
        </entity>
        <entity id="3" string="41" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="41" />
          </tokens>
        </entity>
        <entity id="4" string="18-month" type="DURATION" score="0.0">
          <tokens>
            <token id="16" string="18-month" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>_Jan. 22, 1985: The first child witness in the preliminary hearing testifies that he and other pupils played ``naked games&amp;apost;&amp;apost; and that he had been touched on his genitals by some of the defendants.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="22" lemma="22" stem="22" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="1985" lemma="1985" stem="1985" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="9" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="witness" lemma="witness" stem="wit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="preliminary" lemma="preliminary" stem="preliminari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="14" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="15" string="testifies" lemma="testify" stem="testifi" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="pupils" lemma="pupil" stem="pupil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="played" lemma="play" stem="plai" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="naked" lemma="naked" stem="nake" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="games" lemma="game" stem="game" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="touched" lemma="touch" stem="touch" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="genitals" lemma="genitals" stem="genit" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="39" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NN _)) (NP-TMP (NNP Jan.) (CD 22) (, ,) (CD 1985))) (: :) (NP (NP (DT The) (JJ first) (NN child) (NN witness)) (PP (IN in) (NP (DT the) (JJ preliminary) (NN hearing))))) (VP (VBZ testifies) (SBAR (SBAR (IN that) (S (NP (NP (PRP he)) (CC and) (NP (JJ other) (NNS pupils))) (VP (VBD played) (`` ``) (NP (JJ naked) (NNS games)) ('' '')))) (CC and) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD had) (VP (VBN been) (VP (VBN touched) (PP (IN on) (NP (PRP$ his) (NNS genitals))) (PP (IN by) (NP (NP (DT some)) (PP (IN of) (NP (DT the) (NNS defendants)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he and other pupils" type="NP">
          <tokens>
            <token id="17" string="he" />
            <token id="18" string="and" />
            <token id="19" string="other" />
            <token id="20" string="pupils" />
          </tokens>
        </chunking>
        <chunking id="2" string="the preliminary hearing" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="preliminary" />
            <token id="14" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="3" string="some" type="NP">
          <tokens>
            <token id="36" string="some" />
          </tokens>
        </chunking>
        <chunking id="4" string="that he and other pupils played `` naked games ''" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="he" />
            <token id="18" string="and" />
            <token id="19" string="other" />
            <token id="20" string="pupils" />
            <token id="21" string="played" />
            <token id="22" string="``" />
            <token id="23" string="naked" />
            <token id="24" string="games" />
            <token id="25" string="''" />
          </tokens>
        </chunking>
        <chunking id="5" string="had been touched on his genitals by some of the defendants" type="VP">
          <tokens>
            <token id="29" string="had" />
            <token id="30" string="been" />
            <token id="31" string="touched" />
            <token id="32" string="on" />
            <token id="33" string="his" />
            <token id="34" string="genitals" />
            <token id="35" string="by" />
            <token id="36" string="some" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="6" string="_ Jan. 22 , 1985" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Jan." />
            <token id="3" string="22" />
            <token id="4" string="," />
            <token id="5" string="1985" />
          </tokens>
        </chunking>
        <chunking id="7" string="_ Jan. 22 , 1985 : The first child witness in the preliminary hearing" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Jan." />
            <token id="3" string="22" />
            <token id="4" string="," />
            <token id="5" string="1985" />
            <token id="6" string=":" />
            <token id="7" string="The" />
            <token id="8" string="first" />
            <token id="9" string="child" />
            <token id="10" string="witness" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="preliminary" />
            <token id="14" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="8" string="that he and other pupils played `` naked games '' and that he had been touched on his genitals by some of the defendants" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="he" />
            <token id="18" string="and" />
            <token id="19" string="other" />
            <token id="20" string="pupils" />
            <token id="21" string="played" />
            <token id="22" string="``" />
            <token id="23" string="naked" />
            <token id="24" string="games" />
            <token id="25" string="''" />
            <token id="26" string="and" />
            <token id="27" string="that" />
            <token id="28" string="he" />
            <token id="29" string="had" />
            <token id="30" string="been" />
            <token id="31" string="touched" />
            <token id="32" string="on" />
            <token id="33" string="his" />
            <token id="34" string="genitals" />
            <token id="35" string="by" />
            <token id="36" string="some" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="9" string="some of the defendants" type="NP">
          <tokens>
            <token id="36" string="some" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="10" string="been touched on his genitals by some of the defendants" type="VP">
          <tokens>
            <token id="30" string="been" />
            <token id="31" string="touched" />
            <token id="32" string="on" />
            <token id="33" string="his" />
            <token id="34" string="genitals" />
            <token id="35" string="by" />
            <token id="36" string="some" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="11" string="The first child witness" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="first" />
            <token id="9" string="child" />
            <token id="10" string="witness" />
          </tokens>
        </chunking>
        <chunking id="12" string="played `` naked games ''" type="VP">
          <tokens>
            <token id="21" string="played" />
            <token id="22" string="``" />
            <token id="23" string="naked" />
            <token id="24" string="games" />
            <token id="25" string="''" />
          </tokens>
        </chunking>
        <chunking id="13" string="the defendants" type="NP">
          <tokens>
            <token id="38" string="the" />
            <token id="39" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="14" string="other pupils" type="NP">
          <tokens>
            <token id="19" string="other" />
            <token id="20" string="pupils" />
          </tokens>
        </chunking>
        <chunking id="15" string="naked games" type="NP">
          <tokens>
            <token id="23" string="naked" />
            <token id="24" string="games" />
          </tokens>
        </chunking>
        <chunking id="16" string="he" type="NP">
          <tokens>
            <token id="17" string="he" />
          </tokens>
        </chunking>
        <chunking id="17" string="that he had been touched on his genitals by some of the defendants" type="SBAR">
          <tokens>
            <token id="27" string="that" />
            <token id="28" string="he" />
            <token id="29" string="had" />
            <token id="30" string="been" />
            <token id="31" string="touched" />
            <token id="32" string="on" />
            <token id="33" string="his" />
            <token id="34" string="genitals" />
            <token id="35" string="by" />
            <token id="36" string="some" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="18" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="19" string="touched on his genitals by some of the defendants" type="VP">
          <tokens>
            <token id="31" string="touched" />
            <token id="32" string="on" />
            <token id="33" string="his" />
            <token id="34" string="genitals" />
            <token id="35" string="by" />
            <token id="36" string="some" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="20" string="The first child witness in the preliminary hearing" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="first" />
            <token id="9" string="child" />
            <token id="10" string="witness" />
            <token id="11" string="in" />
            <token id="12" string="the" />
            <token id="13" string="preliminary" />
            <token id="14" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="21" string="testifies that he and other pupils played `` naked games '' and that he had been touched on his genitals by some of the defendants" type="VP">
          <tokens>
            <token id="15" string="testifies" />
            <token id="16" string="that" />
            <token id="17" string="he" />
            <token id="18" string="and" />
            <token id="19" string="other" />
            <token id="20" string="pupils" />
            <token id="21" string="played" />
            <token id="22" string="``" />
            <token id="23" string="naked" />
            <token id="24" string="games" />
            <token id="25" string="''" />
            <token id="26" string="and" />
            <token id="27" string="that" />
            <token id="28" string="he" />
            <token id="29" string="had" />
            <token id="30" string="been" />
            <token id="31" string="touched" />
            <token id="32" string="on" />
            <token id="33" string="his" />
            <token id="34" string="genitals" />
            <token id="35" string="by" />
            <token id="36" string="some" />
            <token id="37" string="of" />
            <token id="38" string="the" />
            <token id="39" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="22" string="his genitals" type="NP">
          <tokens>
            <token id="33" string="his" />
            <token id="34" string="genitals" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="15">testifies</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Jan.</governor>
          <dependent id="3">22</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Jan.</governor>
          <dependent id="5">1985</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">witness</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">witness</governor>
          <dependent id="8">first</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">witness</governor>
          <dependent id="9">child</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="10">witness</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">hearing</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">hearing</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">hearing</governor>
          <dependent id="13">preliminary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">witness</governor>
          <dependent id="14">hearing</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">testifies</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="21">played</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">played</governor>
          <dependent id="17">he</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">he</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">pupils</governor>
          <dependent id="19">other</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">he</governor>
          <dependent id="20">pupils</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">testifies</governor>
          <dependent id="21">played</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">games</governor>
          <dependent id="23">naked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">played</governor>
          <dependent id="24">games</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">played</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">touched</governor>
          <dependent id="27">that</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">touched</governor>
          <dependent id="28">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">touched</governor>
          <dependent id="29">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">touched</governor>
          <dependent id="30">been</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">played</governor>
          <dependent id="31">touched</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">genitals</governor>
          <dependent id="32">on</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">genitals</governor>
          <dependent id="33">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">touched</governor>
          <dependent id="34">genitals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">some</governor>
          <dependent id="35">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">touched</governor>
          <dependent id="36">some</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">defendants</governor>
          <dependent id="37">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">defendants</governor>
          <dependent id="38">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">some</governor>
          <dependent id="39">defendants</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="8" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Jan. 22 , 1985" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Jan." />
            <token id="3" string="22" />
            <token id="4" string="," />
            <token id="5" string="1985" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>_Jan. 9, 1986: Judge Bobb orders all seven defendants to stand trial in Superior Court on 135 counts of molestation and conspiracy, ending the longest preliminary hearing in California history.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="9" lemma="9" stem="9" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Judge" lemma="Judge" stem="judg" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="8" string="Bobb" lemma="Bobb" stem="bobb" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="orders" lemma="order" stem="order" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="stand" lemma="stand" stem="stand" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Superior" lemma="Superior" stem="superior" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="18" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="135" lemma="135" stem="135" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="21" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="conspiracy" lemma="conspiracy" stem="conspiraci" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="ending" lemma="end" stem="end" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="longest" lemma="longest" stem="longest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="preliminary" lemma="preliminary" stem="preliminari" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="34" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP Jan.) (CD 9) (, ,) (CD 1986))) (: :) (NP (NP (NNP Judge) (NNP Bobb) (NNS orders)) (SBAR (S (NP (DT all) (CD seven) (NNS defendants)) (VP (TO to) (VP (VB stand) (NP (NN trial)) (PP (IN in) (NP (NP (NNP Superior) (NNP Court)) (PP (IN on) (NP (NP (CD 135) (NNS counts)) (PP (IN of) (NP (NN molestation) (CC and) (NN conspiracy)))))))))))) (, ,) (VP (VBG ending) (NP (DT the) (JJS longest) (JJ preliminary) (NN hearing))) (PP (IN in) (NP (NNP California) (NN history))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="135 counts of molestation and conspiracy" type="NP">
          <tokens>
            <token id="20" string="135" />
            <token id="21" string="counts" />
            <token id="22" string="of" />
            <token id="23" string="molestation" />
            <token id="24" string="and" />
            <token id="25" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="2" string="135 counts" type="NP">
          <tokens>
            <token id="20" string="135" />
            <token id="21" string="counts" />
          </tokens>
        </chunking>
        <chunking id="3" string="trial" type="NP">
          <tokens>
            <token id="15" string="trial" />
          </tokens>
        </chunking>
        <chunking id="4" string="ending the longest preliminary hearing" type="VP">
          <tokens>
            <token id="27" string="ending" />
            <token id="28" string="the" />
            <token id="29" string="longest" />
            <token id="30" string="preliminary" />
            <token id="31" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="5" string="Superior Court" type="NP">
          <tokens>
            <token id="17" string="Superior" />
            <token id="18" string="Court" />
          </tokens>
        </chunking>
        <chunking id="6" string="to stand trial in Superior Court on 135 counts of molestation and conspiracy" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="stand" />
            <token id="15" string="trial" />
            <token id="16" string="in" />
            <token id="17" string="Superior" />
            <token id="18" string="Court" />
            <token id="19" string="on" />
            <token id="20" string="135" />
            <token id="21" string="counts" />
            <token id="22" string="of" />
            <token id="23" string="molestation" />
            <token id="24" string="and" />
            <token id="25" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="7" string="Superior Court on 135 counts of molestation and conspiracy" type="NP">
          <tokens>
            <token id="17" string="Superior" />
            <token id="18" string="Court" />
            <token id="19" string="on" />
            <token id="20" string="135" />
            <token id="21" string="counts" />
            <token id="22" string="of" />
            <token id="23" string="molestation" />
            <token id="24" string="and" />
            <token id="25" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="8" string="all seven defendants" type="NP">
          <tokens>
            <token id="10" string="all" />
            <token id="11" string="seven" />
            <token id="12" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="9" string="the longest preliminary hearing" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="longest" />
            <token id="30" string="preliminary" />
            <token id="31" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="10" string="Judge Bobb orders" type="NP">
          <tokens>
            <token id="7" string="Judge" />
            <token id="8" string="Bobb" />
            <token id="9" string="orders" />
          </tokens>
        </chunking>
        <chunking id="11" string="_ Jan. 9 , 1986" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Jan." />
            <token id="3" string="9" />
            <token id="4" string="," />
            <token id="5" string="1986" />
          </tokens>
        </chunking>
        <chunking id="12" string="all seven defendants to stand trial in Superior Court on 135 counts of molestation and conspiracy" type="SBAR">
          <tokens>
            <token id="10" string="all" />
            <token id="11" string="seven" />
            <token id="12" string="defendants" />
            <token id="13" string="to" />
            <token id="14" string="stand" />
            <token id="15" string="trial" />
            <token id="16" string="in" />
            <token id="17" string="Superior" />
            <token id="18" string="Court" />
            <token id="19" string="on" />
            <token id="20" string="135" />
            <token id="21" string="counts" />
            <token id="22" string="of" />
            <token id="23" string="molestation" />
            <token id="24" string="and" />
            <token id="25" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="13" string="_ Jan. 9 , 1986 : Judge Bobb orders all seven defendants to stand trial in Superior Court on 135 counts of molestation and conspiracy , ending the longest preliminary hearing in California history ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Jan." />
            <token id="3" string="9" />
            <token id="4" string="," />
            <token id="5" string="1986" />
            <token id="6" string=":" />
            <token id="7" string="Judge" />
            <token id="8" string="Bobb" />
            <token id="9" string="orders" />
            <token id="10" string="all" />
            <token id="11" string="seven" />
            <token id="12" string="defendants" />
            <token id="13" string="to" />
            <token id="14" string="stand" />
            <token id="15" string="trial" />
            <token id="16" string="in" />
            <token id="17" string="Superior" />
            <token id="18" string="Court" />
            <token id="19" string="on" />
            <token id="20" string="135" />
            <token id="21" string="counts" />
            <token id="22" string="of" />
            <token id="23" string="molestation" />
            <token id="24" string="and" />
            <token id="25" string="conspiracy" />
            <token id="26" string="," />
            <token id="27" string="ending" />
            <token id="28" string="the" />
            <token id="29" string="longest" />
            <token id="30" string="preliminary" />
            <token id="31" string="hearing" />
            <token id="32" string="in" />
            <token id="33" string="California" />
            <token id="34" string="history" />
            <token id="35" string="." />
          </tokens>
        </chunking>
        <chunking id="14" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="15" string="stand trial in Superior Court on 135 counts of molestation and conspiracy" type="VP">
          <tokens>
            <token id="14" string="stand" />
            <token id="15" string="trial" />
            <token id="16" string="in" />
            <token id="17" string="Superior" />
            <token id="18" string="Court" />
            <token id="19" string="on" />
            <token id="20" string="135" />
            <token id="21" string="counts" />
            <token id="22" string="of" />
            <token id="23" string="molestation" />
            <token id="24" string="and" />
            <token id="25" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="16" string="California history" type="NP">
          <tokens>
            <token id="33" string="California" />
            <token id="34" string="history" />
          </tokens>
        </chunking>
        <chunking id="17" string="Judge Bobb orders all seven defendants to stand trial in Superior Court on 135 counts of molestation and conspiracy" type="NP">
          <tokens>
            <token id="7" string="Judge" />
            <token id="8" string="Bobb" />
            <token id="9" string="orders" />
            <token id="10" string="all" />
            <token id="11" string="seven" />
            <token id="12" string="defendants" />
            <token id="13" string="to" />
            <token id="14" string="stand" />
            <token id="15" string="trial" />
            <token id="16" string="in" />
            <token id="17" string="Superior" />
            <token id="18" string="Court" />
            <token id="19" string="on" />
            <token id="20" string="135" />
            <token id="21" string="counts" />
            <token id="22" string="of" />
            <token id="23" string="molestation" />
            <token id="24" string="and" />
            <token id="25" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="18" string="molestation and conspiracy" type="NP">
          <tokens>
            <token id="23" string="molestation" />
            <token id="24" string="and" />
            <token id="25" string="conspiracy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Jan.</governor>
          <dependent id="3">9</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Jan.</governor>
          <dependent id="5">1986</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">orders</governor>
          <dependent id="7">Judge</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">orders</governor>
          <dependent id="8">Bobb</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="9">orders</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">defendants</governor>
          <dependent id="10">all</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">defendants</governor>
          <dependent id="11">seven</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">stand</governor>
          <dependent id="12">defendants</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">stand</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">orders</governor>
          <dependent id="14">stand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">stand</governor>
          <dependent id="15">trial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Court</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Court</governor>
          <dependent id="17">Superior</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">stand</governor>
          <dependent id="18">Court</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">counts</governor>
          <dependent id="19">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">counts</governor>
          <dependent id="20">135</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">Court</governor>
          <dependent id="21">counts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">molestation</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">counts</governor>
          <dependent id="23">molestation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">molestation</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">molestation</governor>
          <dependent id="25">conspiracy</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">_</governor>
          <dependent id="27">ending</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">hearing</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">hearing</governor>
          <dependent id="29">longest</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">hearing</governor>
          <dependent id="30">preliminary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">ending</governor>
          <dependent id="31">hearing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">history</governor>
          <dependent id="32">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">history</governor>
          <dependent id="33">California</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">_</governor>
          <dependent id="34">history</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Superior Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="17" string="Superior" />
            <token id="18" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="135" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="135" />
          </tokens>
        </entity>
        <entity id="3" string="Bobb" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Bobb" />
          </tokens>
        </entity>
        <entity id="4" string="California" type="LOCATION" score="0.0">
          <tokens>
            <token id="33" string="California" />
          </tokens>
        </entity>
        <entity id="5" string="Jan. 9 , 1986" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Jan." />
            <token id="3" string="9" />
            <token id="4" string="," />
            <token id="5" string="1986" />
          </tokens>
        </entity>
        <entity id="6" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="seven" />
          </tokens>
        </entity>
        <entity id="7" string="Judge" type="TITLE" score="0.0">
          <tokens>
            <token id="7" string="Judge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>The cost of the hearing was estimated at $4 million.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="estimated" lemma="estimate" stem="estim" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="10" string="4" lemma="4" stem="4" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="11" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN cost)) (PP (IN of) (NP (DT the) (NN hearing)))) (VP (VBD was) (VP (VBN estimated) (PP (IN at) (NP (QP ($ $) (CD 4) (CD million)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The cost of the hearing" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="cost" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="2" string="estimated at $ 4 million" type="VP">
          <tokens>
            <token id="7" string="estimated" />
            <token id="8" string="at" />
            <token id="9" string="$" />
            <token id="10" string="4" />
            <token id="11" string="million" />
          </tokens>
        </chunking>
        <chunking id="3" string="was estimated at $ 4 million" type="VP">
          <tokens>
            <token id="6" string="was" />
            <token id="7" string="estimated" />
            <token id="8" string="at" />
            <token id="9" string="$" />
            <token id="10" string="4" />
            <token id="11" string="million" />
          </tokens>
        </chunking>
        <chunking id="4" string="The cost" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="cost" />
          </tokens>
        </chunking>
        <chunking id="5" string="the hearing" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="6" string="$ 4 million" type="NP">
          <tokens>
            <token id="9" string="$" />
            <token id="10" string="4" />
            <token id="11" string="million" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">cost</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">estimated</governor>
          <dependent id="2">cost</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">hearing</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">hearing</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">cost</governor>
          <dependent id="5">hearing</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">estimated</governor>
          <dependent id="6">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">estimated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">$</governor>
          <dependent id="8">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">estimated</governor>
          <dependent id="9">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">million</governor>
          <dependent id="10">4</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">$</governor>
          <dependent id="11">million</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 4 million" type="MONEY" score="0.0">
          <tokens>
            <token id="9" string="$" />
            <token id="10" string="4" />
            <token id="11" string="million" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>_Jan. 17, 1986: District Attorney Ira Reiner says there is insufficient evidence to warrant a trial for five of the seven defendants and asks dismissal of charges against Virginia McMartin, Peggy Ann Buckey, Mary Ann Jackson, Babette Spitler and Betty Raidor.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="17" lemma="17" stem="17" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="District" lemma="District" stem="district" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Attorney" lemma="Attorney" stem="attornei" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="9" string="Ira" lemma="Ira" stem="ira" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="insufficient" lemma="insufficient" stem="insuffici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="warrant" lemma="warrant" stem="warrant" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="25" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="asks" lemma="ask" stem="ask" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="dismissal" lemma="dismissal" stem="dismiss" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="33" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="34" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="36" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="37" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="Mary" lemma="Mary" stem="mari" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="40" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="41" string="Jackson" lemma="Jackson" stem="jackson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="42" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="Babette" lemma="Babette" stem="babett" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="44" string="Spitler" lemma="Spitler" stem="spitler" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="45" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="Betty" lemma="Betty" stem="betti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="47" string="Raidor" lemma="Raidor" stem="raidor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="48" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP Jan.) (CD 17) (, ,) (CD 1986))) (: :) (NP (NP (NNP District) (NNP Attorney) (NNP Ira) (NNP Reiner)) (SBAR (S (VP (VP (VBZ says) (SBAR (S (NP (EX there)) (VP (VBZ is) (NP (JJ insufficient) (NN evidence) (S (VP (TO to) (VP (VB warrant) (NP (DT a) (NN trial)) (PP (IN for) (NP (NP (CD five)) (PP (IN of) (NP (DT the) (CD seven) (NNS defendants))))))))))))) (CC and) (VP (VBZ asks) (NP (NP (NN dismissal)) (PP (IN of) (NP (NP (NNS charges)) (PP (IN against) (NP (NP (NNP Virginia) (NNP McMartin)) (, ,) (NP (NNP Peggy) (NNP Ann) (NNP Buckey)) (, ,) (NP (NNP Mary) (NNP Ann) (NNP Jackson)) (, ,) (NP (NNP Babette) (NNP Spitler)) (CC and) (NP (NNP Betty) (NNP Raidor)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="District Attorney Ira Reiner" type="NP">
          <tokens>
            <token id="7" string="District" />
            <token id="8" string="Attorney" />
            <token id="9" string="Ira" />
            <token id="10" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="2" string="says there is insufficient evidence to warrant a trial for five of the seven defendants" type="VP">
          <tokens>
            <token id="11" string="says" />
            <token id="12" string="there" />
            <token id="13" string="is" />
            <token id="14" string="insufficient" />
            <token id="15" string="evidence" />
            <token id="16" string="to" />
            <token id="17" string="warrant" />
            <token id="18" string="a" />
            <token id="19" string="trial" />
            <token id="20" string="for" />
            <token id="21" string="five" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="3" string="Mary Ann Jackson" type="NP">
          <tokens>
            <token id="39" string="Mary" />
            <token id="40" string="Ann" />
            <token id="41" string="Jackson" />
          </tokens>
        </chunking>
        <chunking id="4" string="to warrant a trial for five of the seven defendants" type="VP">
          <tokens>
            <token id="16" string="to" />
            <token id="17" string="warrant" />
            <token id="18" string="a" />
            <token id="19" string="trial" />
            <token id="20" string="for" />
            <token id="21" string="five" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="5" string="there" type="NP">
          <tokens>
            <token id="12" string="there" />
          </tokens>
        </chunking>
        <chunking id="6" string="charges" type="NP">
          <tokens>
            <token id="30" string="charges" />
          </tokens>
        </chunking>
        <chunking id="7" string="dismissal" type="NP">
          <tokens>
            <token id="28" string="dismissal" />
          </tokens>
        </chunking>
        <chunking id="8" string="Peggy Ann Buckey" type="NP">
          <tokens>
            <token id="35" string="Peggy" />
            <token id="36" string="Ann" />
            <token id="37" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="9" string="_ Jan. 17 , 1986" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Jan." />
            <token id="3" string="17" />
            <token id="4" string="," />
            <token id="5" string="1986" />
          </tokens>
        </chunking>
        <chunking id="10" string="Virginia McMartin , Peggy Ann Buckey , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="NP">
          <tokens>
            <token id="32" string="Virginia" />
            <token id="33" string="McMartin" />
            <token id="34" string="," />
            <token id="35" string="Peggy" />
            <token id="36" string="Ann" />
            <token id="37" string="Buckey" />
            <token id="38" string="," />
            <token id="39" string="Mary" />
            <token id="40" string="Ann" />
            <token id="41" string="Jackson" />
            <token id="42" string="," />
            <token id="43" string="Babette" />
            <token id="44" string="Spitler" />
            <token id="45" string="and" />
            <token id="46" string="Betty" />
            <token id="47" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="11" string="dismissal of charges against Virginia McMartin , Peggy Ann Buckey , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="NP">
          <tokens>
            <token id="28" string="dismissal" />
            <token id="29" string="of" />
            <token id="30" string="charges" />
            <token id="31" string="against" />
            <token id="32" string="Virginia" />
            <token id="33" string="McMartin" />
            <token id="34" string="," />
            <token id="35" string="Peggy" />
            <token id="36" string="Ann" />
            <token id="37" string="Buckey" />
            <token id="38" string="," />
            <token id="39" string="Mary" />
            <token id="40" string="Ann" />
            <token id="41" string="Jackson" />
            <token id="42" string="," />
            <token id="43" string="Babette" />
            <token id="44" string="Spitler" />
            <token id="45" string="and" />
            <token id="46" string="Betty" />
            <token id="47" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="12" string="a trial" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="trial" />
          </tokens>
        </chunking>
        <chunking id="13" string="insufficient evidence to warrant a trial for five of the seven defendants" type="NP">
          <tokens>
            <token id="14" string="insufficient" />
            <token id="15" string="evidence" />
            <token id="16" string="to" />
            <token id="17" string="warrant" />
            <token id="18" string="a" />
            <token id="19" string="trial" />
            <token id="20" string="for" />
            <token id="21" string="five" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="14" string="Babette Spitler" type="NP">
          <tokens>
            <token id="43" string="Babette" />
            <token id="44" string="Spitler" />
          </tokens>
        </chunking>
        <chunking id="15" string="the seven defendants" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="16" string="Virginia McMartin" type="NP">
          <tokens>
            <token id="32" string="Virginia" />
            <token id="33" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="17" string="_ Jan. 17 , 1986 : District Attorney Ira Reiner says there is insufficient evidence to warrant a trial for five of the seven defendants and asks dismissal of charges against Virginia McMartin , Peggy Ann Buckey , Mary Ann Jackson , Babette Spitler and Betty Raidor ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Jan." />
            <token id="3" string="17" />
            <token id="4" string="," />
            <token id="5" string="1986" />
            <token id="6" string=":" />
            <token id="7" string="District" />
            <token id="8" string="Attorney" />
            <token id="9" string="Ira" />
            <token id="10" string="Reiner" />
            <token id="11" string="says" />
            <token id="12" string="there" />
            <token id="13" string="is" />
            <token id="14" string="insufficient" />
            <token id="15" string="evidence" />
            <token id="16" string="to" />
            <token id="17" string="warrant" />
            <token id="18" string="a" />
            <token id="19" string="trial" />
            <token id="20" string="for" />
            <token id="21" string="five" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
            <token id="26" string="and" />
            <token id="27" string="asks" />
            <token id="28" string="dismissal" />
            <token id="29" string="of" />
            <token id="30" string="charges" />
            <token id="31" string="against" />
            <token id="32" string="Virginia" />
            <token id="33" string="McMartin" />
            <token id="34" string="," />
            <token id="35" string="Peggy" />
            <token id="36" string="Ann" />
            <token id="37" string="Buckey" />
            <token id="38" string="," />
            <token id="39" string="Mary" />
            <token id="40" string="Ann" />
            <token id="41" string="Jackson" />
            <token id="42" string="," />
            <token id="43" string="Babette" />
            <token id="44" string="Spitler" />
            <token id="45" string="and" />
            <token id="46" string="Betty" />
            <token id="47" string="Raidor" />
            <token id="48" string="." />
          </tokens>
        </chunking>
        <chunking id="18" string="charges against Virginia McMartin , Peggy Ann Buckey , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="NP">
          <tokens>
            <token id="30" string="charges" />
            <token id="31" string="against" />
            <token id="32" string="Virginia" />
            <token id="33" string="McMartin" />
            <token id="34" string="," />
            <token id="35" string="Peggy" />
            <token id="36" string="Ann" />
            <token id="37" string="Buckey" />
            <token id="38" string="," />
            <token id="39" string="Mary" />
            <token id="40" string="Ann" />
            <token id="41" string="Jackson" />
            <token id="42" string="," />
            <token id="43" string="Babette" />
            <token id="44" string="Spitler" />
            <token id="45" string="and" />
            <token id="46" string="Betty" />
            <token id="47" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="19" string="Betty Raidor" type="NP">
          <tokens>
            <token id="46" string="Betty" />
            <token id="47" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="20" string="says there is insufficient evidence to warrant a trial for five of the seven defendants and asks dismissal of charges against Virginia McMartin , Peggy Ann Buckey , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="SBAR">
          <tokens>
            <token id="11" string="says" />
            <token id="12" string="there" />
            <token id="13" string="is" />
            <token id="14" string="insufficient" />
            <token id="15" string="evidence" />
            <token id="16" string="to" />
            <token id="17" string="warrant" />
            <token id="18" string="a" />
            <token id="19" string="trial" />
            <token id="20" string="for" />
            <token id="21" string="five" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
            <token id="26" string="and" />
            <token id="27" string="asks" />
            <token id="28" string="dismissal" />
            <token id="29" string="of" />
            <token id="30" string="charges" />
            <token id="31" string="against" />
            <token id="32" string="Virginia" />
            <token id="33" string="McMartin" />
            <token id="34" string="," />
            <token id="35" string="Peggy" />
            <token id="36" string="Ann" />
            <token id="37" string="Buckey" />
            <token id="38" string="," />
            <token id="39" string="Mary" />
            <token id="40" string="Ann" />
            <token id="41" string="Jackson" />
            <token id="42" string="," />
            <token id="43" string="Babette" />
            <token id="44" string="Spitler" />
            <token id="45" string="and" />
            <token id="46" string="Betty" />
            <token id="47" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="21" string="asks dismissal of charges against Virginia McMartin , Peggy Ann Buckey , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="VP">
          <tokens>
            <token id="27" string="asks" />
            <token id="28" string="dismissal" />
            <token id="29" string="of" />
            <token id="30" string="charges" />
            <token id="31" string="against" />
            <token id="32" string="Virginia" />
            <token id="33" string="McMartin" />
            <token id="34" string="," />
            <token id="35" string="Peggy" />
            <token id="36" string="Ann" />
            <token id="37" string="Buckey" />
            <token id="38" string="," />
            <token id="39" string="Mary" />
            <token id="40" string="Ann" />
            <token id="41" string="Jackson" />
            <token id="42" string="," />
            <token id="43" string="Babette" />
            <token id="44" string="Spitler" />
            <token id="45" string="and" />
            <token id="46" string="Betty" />
            <token id="47" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="22" string="District Attorney Ira Reiner says there is insufficient evidence to warrant a trial for five of the seven defendants and asks dismissal of charges against Virginia McMartin , Peggy Ann Buckey , Mary Ann Jackson , Babette Spitler and Betty Raidor" type="NP">
          <tokens>
            <token id="7" string="District" />
            <token id="8" string="Attorney" />
            <token id="9" string="Ira" />
            <token id="10" string="Reiner" />
            <token id="11" string="says" />
            <token id="12" string="there" />
            <token id="13" string="is" />
            <token id="14" string="insufficient" />
            <token id="15" string="evidence" />
            <token id="16" string="to" />
            <token id="17" string="warrant" />
            <token id="18" string="a" />
            <token id="19" string="trial" />
            <token id="20" string="for" />
            <token id="21" string="five" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
            <token id="26" string="and" />
            <token id="27" string="asks" />
            <token id="28" string="dismissal" />
            <token id="29" string="of" />
            <token id="30" string="charges" />
            <token id="31" string="against" />
            <token id="32" string="Virginia" />
            <token id="33" string="McMartin" />
            <token id="34" string="," />
            <token id="35" string="Peggy" />
            <token id="36" string="Ann" />
            <token id="37" string="Buckey" />
            <token id="38" string="," />
            <token id="39" string="Mary" />
            <token id="40" string="Ann" />
            <token id="41" string="Jackson" />
            <token id="42" string="," />
            <token id="43" string="Babette" />
            <token id="44" string="Spitler" />
            <token id="45" string="and" />
            <token id="46" string="Betty" />
            <token id="47" string="Raidor" />
          </tokens>
        </chunking>
        <chunking id="23" string="is insufficient evidence to warrant a trial for five of the seven defendants" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="insufficient" />
            <token id="15" string="evidence" />
            <token id="16" string="to" />
            <token id="17" string="warrant" />
            <token id="18" string="a" />
            <token id="19" string="trial" />
            <token id="20" string="for" />
            <token id="21" string="five" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="24" string="five of the seven defendants" type="NP">
          <tokens>
            <token id="21" string="five" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="25" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="26" string="there is insufficient evidence to warrant a trial for five of the seven defendants" type="SBAR">
          <tokens>
            <token id="12" string="there" />
            <token id="13" string="is" />
            <token id="14" string="insufficient" />
            <token id="15" string="evidence" />
            <token id="16" string="to" />
            <token id="17" string="warrant" />
            <token id="18" string="a" />
            <token id="19" string="trial" />
            <token id="20" string="for" />
            <token id="21" string="five" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="27" string="five" type="NP">
          <tokens>
            <token id="21" string="five" />
          </tokens>
        </chunking>
        <chunking id="28" string="warrant a trial for five of the seven defendants" type="VP">
          <tokens>
            <token id="17" string="warrant" />
            <token id="18" string="a" />
            <token id="19" string="trial" />
            <token id="20" string="for" />
            <token id="21" string="five" />
            <token id="22" string="of" />
            <token id="23" string="the" />
            <token id="24" string="seven" />
            <token id="25" string="defendants" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Jan.</governor>
          <dependent id="3">17</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Jan.</governor>
          <dependent id="5">1986</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Reiner</governor>
          <dependent id="7">District</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Reiner</governor>
          <dependent id="8">Attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Reiner</governor>
          <dependent id="9">Ira</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="10">Reiner</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="10">Reiner</governor>
          <dependent id="11">says</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="13">is</governor>
          <dependent id="12">there</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">says</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">evidence</governor>
          <dependent id="14">insufficient</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">is</governor>
          <dependent id="15">evidence</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">warrant</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="15">evidence</governor>
          <dependent id="17">warrant</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">trial</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">warrant</governor>
          <dependent id="19">trial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">five</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">warrant</governor>
          <dependent id="21">five</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">defendants</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">defendants</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="25">defendants</governor>
          <dependent id="24">seven</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">five</governor>
          <dependent id="25">defendants</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">says</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">says</governor>
          <dependent id="27">asks</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">asks</governor>
          <dependent id="28">dismissal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">charges</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">dismissal</governor>
          <dependent id="30">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">McMartin</governor>
          <dependent id="31">against</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">McMartin</governor>
          <dependent id="32">Virginia</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">charges</governor>
          <dependent id="33">McMartin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Buckey</governor>
          <dependent id="35">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Buckey</governor>
          <dependent id="36">Ann</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">McMartin</governor>
          <dependent id="37">Buckey</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">Jackson</governor>
          <dependent id="39">Mary</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">Jackson</governor>
          <dependent id="40">Ann</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">McMartin</governor>
          <dependent id="41">Jackson</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="44">Spitler</governor>
          <dependent id="43">Babette</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">McMartin</governor>
          <dependent id="44">Spitler</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="33">McMartin</governor>
          <dependent id="45">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">Raidor</governor>
          <dependent id="46">Betty</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="33">McMartin</governor>
          <dependent id="47">Raidor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mary Ann Jackson" type="PERSON" score="0.0">
          <tokens>
            <token id="39" string="Mary" />
            <token id="40" string="Ann" />
            <token id="41" string="Jackson" />
          </tokens>
        </entity>
        <entity id="2" string="Peggy Ann Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="35" string="Peggy" />
            <token id="36" string="Ann" />
            <token id="37" string="Buckey" />
          </tokens>
        </entity>
        <entity id="3" string="Jan. 17 , 1986" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Jan." />
            <token id="3" string="17" />
            <token id="4" string="," />
            <token id="5" string="1986" />
          </tokens>
        </entity>
        <entity id="4" string="Virginia McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="32" string="Virginia" />
            <token id="33" string="McMartin" />
          </tokens>
        </entity>
        <entity id="5" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="24" string="seven" />
          </tokens>
        </entity>
        <entity id="6" string="Babette Spitler" type="PERSON" score="0.0">
          <tokens>
            <token id="43" string="Babette" />
            <token id="44" string="Spitler" />
          </tokens>
        </entity>
        <entity id="7" string="Betty Raidor" type="PERSON" score="0.0">
          <tokens>
            <token id="46" string="Betty" />
            <token id="47" string="Raidor" />
          </tokens>
        </entity>
        <entity id="8" string="Attorney" type="TITLE" score="0.0">
          <tokens>
            <token id="8" string="Attorney" />
          </tokens>
        </entity>
        <entity id="9" string="Ira Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Ira" />
            <token id="10" string="Reiner" />
          </tokens>
        </entity>
        <entity id="10" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="21" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>The remaining defendants, Buckey and his mother, still face 100 counts of molestation and conspiracy.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="remaining" lemma="remain" stem="remain" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="face" lemma="face" stem="face" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="13" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="conspiracy" lemma="conspiracy" stem="conspiraci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (VBG remaining) (NNS defendants)) (, ,) (NP (NP (NNP Buckey)) (CC and) (NP (PRP$ his) (NN mother))) (, ,)) (ADVP (RB still)) (VP (VBP face) (NP (NP (CD 100) (NNS counts)) (PP (IN of) (NP (NN molestation) (CC and) (NN conspiracy))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Buckey" type="NP">
          <tokens>
            <token id="5" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="100 counts of molestation and conspiracy" type="NP">
          <tokens>
            <token id="12" string="100" />
            <token id="13" string="counts" />
            <token id="14" string="of" />
            <token id="15" string="molestation" />
            <token id="16" string="and" />
            <token id="17" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="3" string="face 100 counts of molestation and conspiracy" type="VP">
          <tokens>
            <token id="11" string="face" />
            <token id="12" string="100" />
            <token id="13" string="counts" />
            <token id="14" string="of" />
            <token id="15" string="molestation" />
            <token id="16" string="and" />
            <token id="17" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="4" string="100 counts" type="NP">
          <tokens>
            <token id="12" string="100" />
            <token id="13" string="counts" />
          </tokens>
        </chunking>
        <chunking id="5" string="his mother" type="NP">
          <tokens>
            <token id="7" string="his" />
            <token id="8" string="mother" />
          </tokens>
        </chunking>
        <chunking id="6" string="The remaining defendants , Buckey and his mother ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="remaining" />
            <token id="3" string="defendants" />
            <token id="4" string="," />
            <token id="5" string="Buckey" />
            <token id="6" string="and" />
            <token id="7" string="his" />
            <token id="8" string="mother" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="The remaining defendants" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="remaining" />
            <token id="3" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="8" string="Buckey and his mother" type="NP">
          <tokens>
            <token id="5" string="Buckey" />
            <token id="6" string="and" />
            <token id="7" string="his" />
            <token id="8" string="mother" />
          </tokens>
        </chunking>
        <chunking id="9" string="molestation and conspiracy" type="NP">
          <tokens>
            <token id="15" string="molestation" />
            <token id="16" string="and" />
            <token id="17" string="conspiracy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">defendants</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">defendants</governor>
          <dependent id="2">remaining</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">face</governor>
          <dependent id="3">defendants</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">defendants</governor>
          <dependent id="5">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">Buckey</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">mother</governor>
          <dependent id="7">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">Buckey</governor>
          <dependent id="8">mother</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">face</governor>
          <dependent id="10">still</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">face</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">counts</governor>
          <dependent id="12">100</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">face</governor>
          <dependent id="13">counts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">molestation</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">counts</governor>
          <dependent id="15">molestation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">molestation</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">molestation</governor>
          <dependent id="17">conspiracy</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="100" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="100" />
          </tokens>
        </entity>
        <entity id="2" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>_Jan. 23, 1986: Mrs. Buckey is released on $295,000 bail, reduced from $495,000.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="23" lemma="23" stem="23" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="8" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="released" lemma="release" stem="releas" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="13" string="295,000" lemma="295,000" stem="295,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="14" string="bail" lemma="bail" stem="bail" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="reduced" lemma="reduce" stem="reduc" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="19" string="495,000" lemma="495,000" stem="495,000" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="true" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP Jan.) (CD 23) (, ,) (CD 1986))) (: :) (S (NP (NNP Mrs.) (NNP Buckey)) (VP (VBZ is) (VP (VBN released) (PP (IN on) (NP (NP ($ $) (CD 295,000) (NN bail)) (, ,) (VP (VBN reduced) (PP (IN from) (NP ($ $) (CD 495,000))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is released on $ 295,000 bail , reduced from $ 495,000" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="released" />
            <token id="11" string="on" />
            <token id="12" string="$" />
            <token id="13" string="295,000" />
            <token id="14" string="bail" />
            <token id="15" string="," />
            <token id="16" string="reduced" />
            <token id="17" string="from" />
            <token id="18" string="$" />
            <token id="19" string="495,000" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mrs. Buckey" type="NP">
          <tokens>
            <token id="7" string="Mrs." />
            <token id="8" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="3" string="released on $ 295,000 bail , reduced from $ 495,000" type="VP">
          <tokens>
            <token id="10" string="released" />
            <token id="11" string="on" />
            <token id="12" string="$" />
            <token id="13" string="295,000" />
            <token id="14" string="bail" />
            <token id="15" string="," />
            <token id="16" string="reduced" />
            <token id="17" string="from" />
            <token id="18" string="$" />
            <token id="19" string="495,000" />
          </tokens>
        </chunking>
        <chunking id="4" string="_ Jan. 23 , 1986 : Mrs. Buckey is released on $ 295,000 bail , reduced from $ 495,000 ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Jan." />
            <token id="3" string="23" />
            <token id="4" string="," />
            <token id="5" string="1986" />
            <token id="6" string=":" />
            <token id="7" string="Mrs." />
            <token id="8" string="Buckey" />
            <token id="9" string="is" />
            <token id="10" string="released" />
            <token id="11" string="on" />
            <token id="12" string="$" />
            <token id="13" string="295,000" />
            <token id="14" string="bail" />
            <token id="15" string="," />
            <token id="16" string="reduced" />
            <token id="17" string="from" />
            <token id="18" string="$" />
            <token id="19" string="495,000" />
            <token id="20" string="." />
          </tokens>
        </chunking>
        <chunking id="5" string="$ 295,000 bail" type="NP">
          <tokens>
            <token id="12" string="$" />
            <token id="13" string="295,000" />
            <token id="14" string="bail" />
          </tokens>
        </chunking>
        <chunking id="6" string="$ 495,000" type="NP">
          <tokens>
            <token id="18" string="$" />
            <token id="19" string="495,000" />
          </tokens>
        </chunking>
        <chunking id="7" string="_ Jan. 23 , 1986" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Jan." />
            <token id="3" string="23" />
            <token id="4" string="," />
            <token id="5" string="1986" />
          </tokens>
        </chunking>
        <chunking id="8" string="$ 295,000 bail , reduced from $ 495,000" type="NP">
          <tokens>
            <token id="12" string="$" />
            <token id="13" string="295,000" />
            <token id="14" string="bail" />
            <token id="15" string="," />
            <token id="16" string="reduced" />
            <token id="17" string="from" />
            <token id="18" string="$" />
            <token id="19" string="495,000" />
          </tokens>
        </chunking>
        <chunking id="9" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="10" string="reduced from $ 495,000" type="VP">
          <tokens>
            <token id="16" string="reduced" />
            <token id="17" string="from" />
            <token id="18" string="$" />
            <token id="19" string="495,000" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Jan.</governor>
          <dependent id="3">23</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Jan.</governor>
          <dependent id="5">1986</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Buckey</governor>
          <dependent id="7">Mrs.</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">released</governor>
          <dependent id="8">Buckey</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">released</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">_</governor>
          <dependent id="10">released</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">bail</governor>
          <dependent id="11">on</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">bail</governor>
          <dependent id="12">$</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">bail</governor>
          <dependent id="13">295,000</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">released</governor>
          <dependent id="14">bail</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">bail</governor>
          <dependent id="16">reduced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">495,000</governor>
          <dependent id="17">from</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="19">495,000</governor>
          <dependent id="18">$</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">reduced</governor>
          <dependent id="19">495,000</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Jan. 23 , 1986" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Jan." />
            <token id="3" string="23" />
            <token id="4" string="," />
            <token id="5" string="1986" />
          </tokens>
        </entity>
        <entity id="3" string="$ 295,000" type="MONEY" score="0.0">
          <tokens>
            <token id="12" string="$" />
            <token id="13" string="295,000" />
          </tokens>
        </entity>
        <entity id="4" string="$ 495,000" type="MONEY" score="0.0">
          <tokens>
            <token id="18" string="$" />
            <token id="19" string="495,000" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>_Dec. 19, 1986: Judy Johnson, the mother who made the first allegations against Buckey, is found dead, naked and face down in her home, at age 44.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Dec." lemma="Dec." stem="dec." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="19" lemma="19" stem="19" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="1986" lemma="1986" stem="1986" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Judy" lemma="Judy" stem="judi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="8" string="Johnson" lemma="Johnson" stem="johnson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="true" />
        <token id="16" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="17" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="18" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="21" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="22" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="24" string="naked" lemma="naked" stem="nake" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="26" string="face" lemma="face" stem="face" pos="VBP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="27" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="29" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="home" lemma="home" stem="home" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="age" lemma="age" stem="ag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="44" lemma="44" stem="44" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP Dec.) (CD 19) (, ,) (CD 1986))) (: :) (NP (NP (NNP Judy) (NNP Johnson)) (, ,) (NP (NP (DT the) (NN mother)) (SBAR (WHNP (WP who)) (S (VP (VP (VBD made) (NP (DT the) (JJ first) (NNS allegations)) (PP (IN against) (NP (NNP Buckey)))) (, ,) (VP (VBZ is) (VP (VBN found) (S (ADJP (JJ dead))) (, ,) (ADJP (JJ naked)))) (CC and) (VP (VBP face) (PRT (RP down)) (PP (IN in) (NP (PRP$ her) (NN home))))))))) (, ,) (PP (IN at) (NP (NN age) (CD 44))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="her home" type="NP">
          <tokens>
            <token id="29" string="her" />
            <token id="30" string="home" />
          </tokens>
        </chunking>
        <chunking id="2" string="the first allegations" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="3" string="the mother who made the first allegations against Buckey , is found dead , naked and face down in her home" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="mother" />
            <token id="12" string="who" />
            <token id="13" string="made" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="allegations" />
            <token id="17" string="against" />
            <token id="18" string="Buckey" />
            <token id="19" string="," />
            <token id="20" string="is" />
            <token id="21" string="found" />
            <token id="22" string="dead" />
            <token id="23" string="," />
            <token id="24" string="naked" />
            <token id="25" string="and" />
            <token id="26" string="face" />
            <token id="27" string="down" />
            <token id="28" string="in" />
            <token id="29" string="her" />
            <token id="30" string="home" />
          </tokens>
        </chunking>
        <chunking id="4" string="made the first allegations against Buckey" type="VP">
          <tokens>
            <token id="13" string="made" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="allegations" />
            <token id="17" string="against" />
            <token id="18" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="5" string="_ Dec. 19 , 1986" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Dec." />
            <token id="3" string="19" />
            <token id="4" string="," />
            <token id="5" string="1986" />
          </tokens>
        </chunking>
        <chunking id="6" string="is found dead , naked" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="found" />
            <token id="22" string="dead" />
            <token id="23" string="," />
            <token id="24" string="naked" />
          </tokens>
        </chunking>
        <chunking id="7" string="dead" type="ADJP">
          <tokens>
            <token id="22" string="dead" />
          </tokens>
        </chunking>
        <chunking id="8" string="naked" type="ADJP">
          <tokens>
            <token id="24" string="naked" />
          </tokens>
        </chunking>
        <chunking id="9" string="Buckey" type="NP">
          <tokens>
            <token id="18" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="10" string="Judy Johnson" type="NP">
          <tokens>
            <token id="7" string="Judy" />
            <token id="8" string="Johnson" />
          </tokens>
        </chunking>
        <chunking id="11" string="the mother" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="mother" />
          </tokens>
        </chunking>
        <chunking id="12" string="_ Dec. 19 , 1986 : Judy Johnson , the mother who made the first allegations against Buckey , is found dead , naked and face down in her home , at age 44 ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Dec." />
            <token id="3" string="19" />
            <token id="4" string="," />
            <token id="5" string="1986" />
            <token id="6" string=":" />
            <token id="7" string="Judy" />
            <token id="8" string="Johnson" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="mother" />
            <token id="12" string="who" />
            <token id="13" string="made" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="allegations" />
            <token id="17" string="against" />
            <token id="18" string="Buckey" />
            <token id="19" string="," />
            <token id="20" string="is" />
            <token id="21" string="found" />
            <token id="22" string="dead" />
            <token id="23" string="," />
            <token id="24" string="naked" />
            <token id="25" string="and" />
            <token id="26" string="face" />
            <token id="27" string="down" />
            <token id="28" string="in" />
            <token id="29" string="her" />
            <token id="30" string="home" />
            <token id="31" string="," />
            <token id="32" string="at" />
            <token id="33" string="age" />
            <token id="34" string="44" />
            <token id="35" string="." />
          </tokens>
        </chunking>
        <chunking id="13" string="face down in her home" type="VP">
          <tokens>
            <token id="26" string="face" />
            <token id="27" string="down" />
            <token id="28" string="in" />
            <token id="29" string="her" />
            <token id="30" string="home" />
          </tokens>
        </chunking>
        <chunking id="14" string="made the first allegations against Buckey , is found dead , naked and face down in her home" type="VP">
          <tokens>
            <token id="13" string="made" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="allegations" />
            <token id="17" string="against" />
            <token id="18" string="Buckey" />
            <token id="19" string="," />
            <token id="20" string="is" />
            <token id="21" string="found" />
            <token id="22" string="dead" />
            <token id="23" string="," />
            <token id="24" string="naked" />
            <token id="25" string="and" />
            <token id="26" string="face" />
            <token id="27" string="down" />
            <token id="28" string="in" />
            <token id="29" string="her" />
            <token id="30" string="home" />
          </tokens>
        </chunking>
        <chunking id="15" string="who made the first allegations against Buckey , is found dead , naked and face down in her home" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="made" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="allegations" />
            <token id="17" string="against" />
            <token id="18" string="Buckey" />
            <token id="19" string="," />
            <token id="20" string="is" />
            <token id="21" string="found" />
            <token id="22" string="dead" />
            <token id="23" string="," />
            <token id="24" string="naked" />
            <token id="25" string="and" />
            <token id="26" string="face" />
            <token id="27" string="down" />
            <token id="28" string="in" />
            <token id="29" string="her" />
            <token id="30" string="home" />
          </tokens>
        </chunking>
        <chunking id="16" string="Judy Johnson , the mother who made the first allegations against Buckey , is found dead , naked and face down in her home" type="NP">
          <tokens>
            <token id="7" string="Judy" />
            <token id="8" string="Johnson" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="mother" />
            <token id="12" string="who" />
            <token id="13" string="made" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="allegations" />
            <token id="17" string="against" />
            <token id="18" string="Buckey" />
            <token id="19" string="," />
            <token id="20" string="is" />
            <token id="21" string="found" />
            <token id="22" string="dead" />
            <token id="23" string="," />
            <token id="24" string="naked" />
            <token id="25" string="and" />
            <token id="26" string="face" />
            <token id="27" string="down" />
            <token id="28" string="in" />
            <token id="29" string="her" />
            <token id="30" string="home" />
          </tokens>
        </chunking>
        <chunking id="17" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="18" string="found dead , naked" type="VP">
          <tokens>
            <token id="21" string="found" />
            <token id="22" string="dead" />
            <token id="23" string="," />
            <token id="24" string="naked" />
          </tokens>
        </chunking>
        <chunking id="19" string="age 44" type="NP">
          <tokens>
            <token id="33" string="age" />
            <token id="34" string="44" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Dec.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Dec.</governor>
          <dependent id="3">19</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Dec.</governor>
          <dependent id="5">1986</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Johnson</governor>
          <dependent id="7">Judy</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="8">Johnson</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">mother</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">Johnson</governor>
          <dependent id="11">mother</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">made</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">mother</governor>
          <dependent id="13">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">allegations</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">allegations</governor>
          <dependent id="15">first</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">made</governor>
          <dependent id="16">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Buckey</governor>
          <dependent id="17">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">made</governor>
          <dependent id="18">Buckey</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">found</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">made</governor>
          <dependent id="21">found</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">found</governor>
          <dependent id="22">dead</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="21">found</governor>
          <dependent id="24">naked</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">made</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">made</governor>
          <dependent id="26">face</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="26">face</governor>
          <dependent id="27">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">home</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">home</governor>
          <dependent id="29">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">face</governor>
          <dependent id="30">home</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">age</governor>
          <dependent id="32">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">_</governor>
          <dependent id="33">age</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="33">age</governor>
          <dependent id="34">44</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="15" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Buckey" />
          </tokens>
        </entity>
        <entity id="3" string="Judy Johnson" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Judy" />
            <token id="8" string="Johnson" />
          </tokens>
        </entity>
        <entity id="4" string="Dec. 19 , 1986" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Dec." />
            <token id="3" string="19" />
            <token id="4" string="," />
            <token id="5" string="1986" />
          </tokens>
        </entity>
        <entity id="5" string="44" type="NUMBER" score="0.0">
          <tokens>
            <token id="34" string="44" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>The coroner says she died of fatty metamorphosis of the liver, an ailment commonly found in alcoholics.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="coroner" lemma="coroner" stem="coron" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="fatty" lemma="fatty" stem="fatti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="metamorphosis" lemma="metamorphosis" stem="metamorphosi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="liver" lemma="liver" stem="liver" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="ailment" lemma="ailment" stem="ailment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="commonly" lemma="commonly" stem="commonli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="alcoholics" lemma="alcoholic" stem="alcohol" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN coroner)) (VP (VBZ says) (SBAR (S (NP (PRP she)) (VP (VBD died) (PP (IN of) (NP (NP (NN fatty) (NN metamorphosis)) (PP (IN of) (NP (NP (DT the) (NN liver)) (, ,) (NP (NP (DT an) (NN ailment)) (VP (ADVP (RB commonly)) (VBN found) (PP (IN in) (NP (NNS alcoholics))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an ailment" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="ailment" />
          </tokens>
        </chunking>
        <chunking id="2" string="died of fatty metamorphosis of the liver , an ailment commonly found in alcoholics" type="VP">
          <tokens>
            <token id="5" string="died" />
            <token id="6" string="of" />
            <token id="7" string="fatty" />
            <token id="8" string="metamorphosis" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="liver" />
            <token id="12" string="," />
            <token id="13" string="an" />
            <token id="14" string="ailment" />
            <token id="15" string="commonly" />
            <token id="16" string="found" />
            <token id="17" string="in" />
            <token id="18" string="alcoholics" />
          </tokens>
        </chunking>
        <chunking id="3" string="the liver" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="liver" />
          </tokens>
        </chunking>
        <chunking id="4" string="alcoholics" type="NP">
          <tokens>
            <token id="18" string="alcoholics" />
          </tokens>
        </chunking>
        <chunking id="5" string="says she died of fatty metamorphosis of the liver , an ailment commonly found in alcoholics" type="VP">
          <tokens>
            <token id="3" string="says" />
            <token id="4" string="she" />
            <token id="5" string="died" />
            <token id="6" string="of" />
            <token id="7" string="fatty" />
            <token id="8" string="metamorphosis" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="liver" />
            <token id="12" string="," />
            <token id="13" string="an" />
            <token id="14" string="ailment" />
            <token id="15" string="commonly" />
            <token id="16" string="found" />
            <token id="17" string="in" />
            <token id="18" string="alcoholics" />
          </tokens>
        </chunking>
        <chunking id="6" string="she" type="NP">
          <tokens>
            <token id="4" string="she" />
          </tokens>
        </chunking>
        <chunking id="7" string="commonly found in alcoholics" type="VP">
          <tokens>
            <token id="15" string="commonly" />
            <token id="16" string="found" />
            <token id="17" string="in" />
            <token id="18" string="alcoholics" />
          </tokens>
        </chunking>
        <chunking id="8" string="The coroner" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="coroner" />
          </tokens>
        </chunking>
        <chunking id="9" string="the liver , an ailment commonly found in alcoholics" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="liver" />
            <token id="12" string="," />
            <token id="13" string="an" />
            <token id="14" string="ailment" />
            <token id="15" string="commonly" />
            <token id="16" string="found" />
            <token id="17" string="in" />
            <token id="18" string="alcoholics" />
          </tokens>
        </chunking>
        <chunking id="10" string="fatty metamorphosis" type="NP">
          <tokens>
            <token id="7" string="fatty" />
            <token id="8" string="metamorphosis" />
          </tokens>
        </chunking>
        <chunking id="11" string="she died of fatty metamorphosis of the liver , an ailment commonly found in alcoholics" type="SBAR">
          <tokens>
            <token id="4" string="she" />
            <token id="5" string="died" />
            <token id="6" string="of" />
            <token id="7" string="fatty" />
            <token id="8" string="metamorphosis" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="liver" />
            <token id="12" string="," />
            <token id="13" string="an" />
            <token id="14" string="ailment" />
            <token id="15" string="commonly" />
            <token id="16" string="found" />
            <token id="17" string="in" />
            <token id="18" string="alcoholics" />
          </tokens>
        </chunking>
        <chunking id="12" string="fatty metamorphosis of the liver , an ailment commonly found in alcoholics" type="NP">
          <tokens>
            <token id="7" string="fatty" />
            <token id="8" string="metamorphosis" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="liver" />
            <token id="12" string="," />
            <token id="13" string="an" />
            <token id="14" string="ailment" />
            <token id="15" string="commonly" />
            <token id="16" string="found" />
            <token id="17" string="in" />
            <token id="18" string="alcoholics" />
          </tokens>
        </chunking>
        <chunking id="13" string="an ailment commonly found in alcoholics" type="NP">
          <tokens>
            <token id="13" string="an" />
            <token id="14" string="ailment" />
            <token id="15" string="commonly" />
            <token id="16" string="found" />
            <token id="17" string="in" />
            <token id="18" string="alcoholics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">coroner</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">says</governor>
          <dependent id="2">coroner</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">died</governor>
          <dependent id="4">she</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">says</governor>
          <dependent id="5">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">metamorphosis</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">metamorphosis</governor>
          <dependent id="7">fatty</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">died</governor>
          <dependent id="8">metamorphosis</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">liver</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">liver</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">metamorphosis</governor>
          <dependent id="11">liver</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">ailment</governor>
          <dependent id="13">an</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">liver</governor>
          <dependent id="14">ailment</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">found</governor>
          <dependent id="15">commonly</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="14">ailment</governor>
          <dependent id="16">found</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">alcoholics</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">found</governor>
          <dependent id="18">alcoholics</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>_April 20, 1987: The trial begins with jury selection.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="3" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="5" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="begins" lemma="begin" stem="begin" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="selection" lemma="selection" stem="select" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP April) (CD 20) (, ,) (CD 1987))) (: :) (NP (NP (DT The) (NN trial)) (SBAR (S (VP (VBZ begins) (PP (IN with) (NP (NN jury) (NN selection))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The trial" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="trial" />
          </tokens>
        </chunking>
        <chunking id="2" string="begins with jury selection" type="SBAR">
          <tokens>
            <token id="9" string="begins" />
            <token id="10" string="with" />
            <token id="11" string="jury" />
            <token id="12" string="selection" />
          </tokens>
        </chunking>
        <chunking id="3" string="The trial begins with jury selection" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="trial" />
            <token id="9" string="begins" />
            <token id="10" string="with" />
            <token id="11" string="jury" />
            <token id="12" string="selection" />
          </tokens>
        </chunking>
        <chunking id="4" string="_ April 20 , 1987 : The trial begins with jury selection ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="April" />
            <token id="3" string="20" />
            <token id="4" string="," />
            <token id="5" string="1987" />
            <token id="6" string=":" />
            <token id="7" string="The" />
            <token id="8" string="trial" />
            <token id="9" string="begins" />
            <token id="10" string="with" />
            <token id="11" string="jury" />
            <token id="12" string="selection" />
            <token id="13" string="." />
          </tokens>
        </chunking>
        <chunking id="5" string="_ April 20 , 1987" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="April" />
            <token id="3" string="20" />
            <token id="4" string="," />
            <token id="5" string="1987" />
          </tokens>
        </chunking>
        <chunking id="6" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="7" string="jury selection" type="NP">
          <tokens>
            <token id="11" string="jury" />
            <token id="12" string="selection" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">April</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">April</governor>
          <dependent id="3">20</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">April</governor>
          <dependent id="5">1987</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">trial</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="8">trial</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">trial</governor>
          <dependent id="9">begins</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">selection</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">selection</governor>
          <dependent id="11">jury</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">begins</governor>
          <dependent id="12">selection</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="April 20 , 1987" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="April" />
            <token id="3" string="20" />
            <token id="4" string="," />
            <token id="5" string="1987" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>By July 1, 12 jurors and six alternates are chosen from 500 prospective panelists.</content>
      <tokens>
        <token id="1" string="By" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="July" lemma="July" stem="juli" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="1" lemma="1" stem="1" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="6" string="jurors" lemma="juror" stem="juror" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="alternates" lemma="alternate" stem="altern" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="chosen" lemma="choose" stem="chosen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="500" lemma="500" stem="500" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="prospective" lemma="prospective" stem="prospect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="panelists" lemma="panelist" stem="panelist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN By) (NP (NNP July) (CD 1))) (, ,) (NP (NP (CD 12) (NNS jurors)) (CC and) (NP (CD six) (NNS alternates))) (VP (VBP are) (VP (VBN chosen) (PP (IN from) (NP (CD 500) (JJ prospective) (NNS panelists))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="July 1" type="NP">
          <tokens>
            <token id="2" string="July" />
            <token id="3" string="1" />
          </tokens>
        </chunking>
        <chunking id="2" string="12 jurors and six alternates" type="NP">
          <tokens>
            <token id="5" string="12" />
            <token id="6" string="jurors" />
            <token id="7" string="and" />
            <token id="8" string="six" />
            <token id="9" string="alternates" />
          </tokens>
        </chunking>
        <chunking id="3" string="12 jurors" type="NP">
          <tokens>
            <token id="5" string="12" />
            <token id="6" string="jurors" />
          </tokens>
        </chunking>
        <chunking id="4" string="six alternates" type="NP">
          <tokens>
            <token id="8" string="six" />
            <token id="9" string="alternates" />
          </tokens>
        </chunking>
        <chunking id="5" string="chosen from 500 prospective panelists" type="VP">
          <tokens>
            <token id="11" string="chosen" />
            <token id="12" string="from" />
            <token id="13" string="500" />
            <token id="14" string="prospective" />
            <token id="15" string="panelists" />
          </tokens>
        </chunking>
        <chunking id="6" string="500 prospective panelists" type="NP">
          <tokens>
            <token id="13" string="500" />
            <token id="14" string="prospective" />
            <token id="15" string="panelists" />
          </tokens>
        </chunking>
        <chunking id="7" string="are chosen from 500 prospective panelists" type="VP">
          <tokens>
            <token id="10" string="are" />
            <token id="11" string="chosen" />
            <token id="12" string="from" />
            <token id="13" string="500" />
            <token id="14" string="prospective" />
            <token id="15" string="panelists" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">July</governor>
          <dependent id="1">By</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">chosen</governor>
          <dependent id="2">July</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">July</governor>
          <dependent id="3">1</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">jurors</governor>
          <dependent id="5">12</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="11">chosen</governor>
          <dependent id="6">jurors</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">jurors</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">alternates</governor>
          <dependent id="8">six</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">jurors</governor>
          <dependent id="9">alternates</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="11">chosen</governor>
          <dependent id="10">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">chosen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">panelists</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="15">panelists</governor>
          <dependent id="13">500</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">panelists</governor>
          <dependent id="14">prospective</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">chosen</governor>
          <dependent id="15">panelists</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="12" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="12" />
          </tokens>
        </entity>
        <entity id="2" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="six" />
          </tokens>
        </entity>
        <entity id="3" string="July 1" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="July" />
            <token id="3" string="1" />
          </tokens>
        </entity>
        <entity id="4" string="500" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="500" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>_July 13, 1987: Opening statements begin after efforts to move the case elsewhere are quashed by Superior Court Judge William R. Pounders.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="July" lemma="July" stem="juli" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Opening" lemma="open" stem="opene" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="statements" lemma="statement" stem="statement" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="begin" lemma="begin" stem="begin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="efforts" lemma="effort" stem="effort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="move" lemma="move" stem="move" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="elsewhere" lemma="elsewhere" stem="elsewher" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="quashed" lemma="quash" stem="quash" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Superior" lemma="Superior" stem="superior" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="21" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="22" string="Judge" lemma="Judge" stem="judg" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="23" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="R." lemma="R." stem="r." pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="Pounders" lemma="Pounders" stem="pounder" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP July) (CD 13) (, ,) (CD 1987))) (: :) (S (NP (VBG Opening) (NNS statements)) (VP (VB begin) (SBAR (IN after) (S (NP (NNS efforts) (S (VP (TO to) (VP (VB move) (NP (DT the) (NN case)) (ADVP (RB elsewhere)))))) (VP (VBP are) (VP (VBN quashed) (PP (IN by) (NP (NNP Superior) (NNP Court) (NNP Judge) (NNP William) (NNP R.) (NNP Pounders))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="_ July 13 , 1987" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="July" />
            <token id="3" string="13" />
            <token id="4" string="," />
            <token id="5" string="1987" />
          </tokens>
        </chunking>
        <chunking id="2" string="to move the case elsewhere" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="move" />
            <token id="14" string="the" />
            <token id="15" string="case" />
            <token id="16" string="elsewhere" />
          </tokens>
        </chunking>
        <chunking id="3" string="move the case elsewhere" type="VP">
          <tokens>
            <token id="13" string="move" />
            <token id="14" string="the" />
            <token id="15" string="case" />
            <token id="16" string="elsewhere" />
          </tokens>
        </chunking>
        <chunking id="4" string="the case" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="Opening statements" type="NP">
          <tokens>
            <token id="7" string="Opening" />
            <token id="8" string="statements" />
          </tokens>
        </chunking>
        <chunking id="6" string="Superior Court Judge William R. Pounders" type="NP">
          <tokens>
            <token id="20" string="Superior" />
            <token id="21" string="Court" />
            <token id="22" string="Judge" />
            <token id="23" string="William" />
            <token id="24" string="R." />
            <token id="25" string="Pounders" />
          </tokens>
        </chunking>
        <chunking id="7" string="are quashed by Superior Court Judge William R. Pounders" type="VP">
          <tokens>
            <token id="17" string="are" />
            <token id="18" string="quashed" />
            <token id="19" string="by" />
            <token id="20" string="Superior" />
            <token id="21" string="Court" />
            <token id="22" string="Judge" />
            <token id="23" string="William" />
            <token id="24" string="R." />
            <token id="25" string="Pounders" />
          </tokens>
        </chunking>
        <chunking id="8" string="after efforts to move the case elsewhere are quashed by Superior Court Judge William R. Pounders" type="SBAR">
          <tokens>
            <token id="10" string="after" />
            <token id="11" string="efforts" />
            <token id="12" string="to" />
            <token id="13" string="move" />
            <token id="14" string="the" />
            <token id="15" string="case" />
            <token id="16" string="elsewhere" />
            <token id="17" string="are" />
            <token id="18" string="quashed" />
            <token id="19" string="by" />
            <token id="20" string="Superior" />
            <token id="21" string="Court" />
            <token id="22" string="Judge" />
            <token id="23" string="William" />
            <token id="24" string="R." />
            <token id="25" string="Pounders" />
          </tokens>
        </chunking>
        <chunking id="9" string="efforts to move the case elsewhere" type="NP">
          <tokens>
            <token id="11" string="efforts" />
            <token id="12" string="to" />
            <token id="13" string="move" />
            <token id="14" string="the" />
            <token id="15" string="case" />
            <token id="16" string="elsewhere" />
          </tokens>
        </chunking>
        <chunking id="10" string="begin after efforts to move the case elsewhere are quashed by Superior Court Judge William R. Pounders" type="VP">
          <tokens>
            <token id="9" string="begin" />
            <token id="10" string="after" />
            <token id="11" string="efforts" />
            <token id="12" string="to" />
            <token id="13" string="move" />
            <token id="14" string="the" />
            <token id="15" string="case" />
            <token id="16" string="elsewhere" />
            <token id="17" string="are" />
            <token id="18" string="quashed" />
            <token id="19" string="by" />
            <token id="20" string="Superior" />
            <token id="21" string="Court" />
            <token id="22" string="Judge" />
            <token id="23" string="William" />
            <token id="24" string="R." />
            <token id="25" string="Pounders" />
          </tokens>
        </chunking>
        <chunking id="11" string="quashed by Superior Court Judge William R. Pounders" type="VP">
          <tokens>
            <token id="18" string="quashed" />
            <token id="19" string="by" />
            <token id="20" string="Superior" />
            <token id="21" string="Court" />
            <token id="22" string="Judge" />
            <token id="23" string="William" />
            <token id="24" string="R." />
            <token id="25" string="Pounders" />
          </tokens>
        </chunking>
        <chunking id="12" string="_ July 13 , 1987 : Opening statements begin after efforts to move the case elsewhere are quashed by Superior Court Judge William R. Pounders ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="July" />
            <token id="3" string="13" />
            <token id="4" string="," />
            <token id="5" string="1987" />
            <token id="6" string=":" />
            <token id="7" string="Opening" />
            <token id="8" string="statements" />
            <token id="9" string="begin" />
            <token id="10" string="after" />
            <token id="11" string="efforts" />
            <token id="12" string="to" />
            <token id="13" string="move" />
            <token id="14" string="the" />
            <token id="15" string="case" />
            <token id="16" string="elsewhere" />
            <token id="17" string="are" />
            <token id="18" string="quashed" />
            <token id="19" string="by" />
            <token id="20" string="Superior" />
            <token id="21" string="Court" />
            <token id="22" string="Judge" />
            <token id="23" string="William" />
            <token id="24" string="R." />
            <token id="25" string="Pounders" />
            <token id="26" string="." />
          </tokens>
        </chunking>
        <chunking id="13" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">July</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">July</governor>
          <dependent id="3">13</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">July</governor>
          <dependent id="5">1987</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">statements</governor>
          <dependent id="7">Opening</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">begin</governor>
          <dependent id="8">statements</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">_</governor>
          <dependent id="9">begin</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">quashed</governor>
          <dependent id="10">after</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">quashed</governor>
          <dependent id="11">efforts</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">move</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="11">efforts</governor>
          <dependent id="13">move</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">case</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">move</governor>
          <dependent id="15">case</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">move</governor>
          <dependent id="16">elsewhere</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">quashed</governor>
          <dependent id="17">are</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">begin</governor>
          <dependent id="18">quashed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Pounders</governor>
          <dependent id="19">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Pounders</governor>
          <dependent id="20">Superior</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Pounders</governor>
          <dependent id="21">Court</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Pounders</governor>
          <dependent id="22">Judge</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Pounders</governor>
          <dependent id="23">William</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Pounders</governor>
          <dependent id="24">R.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">quashed</governor>
          <dependent id="25">Pounders</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Superior Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="20" string="Superior" />
            <token id="21" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="July 13 , 1987" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="July" />
            <token id="3" string="13" />
            <token id="4" string="," />
            <token id="5" string="1987" />
          </tokens>
        </entity>
        <entity id="3" string="William R. Pounders" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="William" />
            <token id="24" string="R." />
            <token id="25" string="Pounders" />
          </tokens>
        </entity>
        <entity id="4" string="Judge" type="TITLE" score="0.0">
          <tokens>
            <token id="22" string="Judge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="false">
      <content>_July 29, 1987: The first parent to testify says his daughter&amp;apost;s behavior indicates she may have been abused at the school, but he didn&amp;apost;t recognize the warning signs at the time.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="July" lemma="July" stem="juli" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="29" lemma="29" stem="29" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="9" string="parent" lemma="parent" stem="parent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="testify" lemma="testify" stem="testifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="daughter" lemma="daughter" stem="daughter" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="behavior" lemma="behavior" stem="behavior" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="indicates" lemma="indicate" stem="indic" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="abused" lemma="abuse" stem="abus" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="recognize" lemma="recognize" stem="recogn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="warning" lemma="warning" stem="warn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="signs" lemma="sign" stem="sign" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN _)) (NP-TMP (NNP July) (CD 29) (, ,) (CD 1987))) (: :) (NP (DT The) (JJ first) (NN parent) (S (VP (TO to) (VP (VB testify))))) (VP (VBZ says) (SBAR (S (S (NP (NP (PRP$ his) (NN daughter) (POS 's)) (NN behavior)) (VP (VBZ indicates) (SBAR (S (NP (PRP she)) (VP (MD may) (VP (VB have) (VP (VBN been) (VP (VBN abused) (PP (IN at) (NP (DT the) (NN school))))))))))) (, ,) (CC but) (S (NP (PRP he)) (VP (VBD did) (RB n't) (VP (VB recognize) (NP (DT the) (NN warning) (NNS signs)) (PP (IN at) (NP (DT the) (NN time))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The first parent to testify" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="first" />
            <token id="9" string="parent" />
            <token id="10" string="to" />
            <token id="11" string="testify" />
          </tokens>
        </chunking>
        <chunking id="2" string="his daughter 's" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="daughter" />
            <token id="15" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="may have been abused at the school" type="VP">
          <tokens>
            <token id="19" string="may" />
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="abused" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="4" string="his daughter 's behavior indicates she may have been abused at the school , but he did n't recognize the warning signs at the time" type="SBAR">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="daughter" />
            <token id="15" string="'s" />
            <token id="16" string="behavior" />
            <token id="17" string="indicates" />
            <token id="18" string="she" />
            <token id="19" string="may" />
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="abused" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
            <token id="26" string="," />
            <token id="27" string="but" />
            <token id="28" string="he" />
            <token id="29" string="did" />
            <token id="30" string="n't" />
            <token id="31" string="recognize" />
            <token id="32" string="the" />
            <token id="33" string="warning" />
            <token id="34" string="signs" />
            <token id="35" string="at" />
            <token id="36" string="the" />
            <token id="37" string="time" />
          </tokens>
        </chunking>
        <chunking id="5" string="she" type="NP">
          <tokens>
            <token id="18" string="she" />
          </tokens>
        </chunking>
        <chunking id="6" string="she may have been abused at the school" type="SBAR">
          <tokens>
            <token id="18" string="she" />
            <token id="19" string="may" />
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="abused" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="7" string="_ July 29 , 1987" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="July" />
            <token id="3" string="29" />
            <token id="4" string="," />
            <token id="5" string="1987" />
          </tokens>
        </chunking>
        <chunking id="8" string="been abused at the school" type="VP">
          <tokens>
            <token id="21" string="been" />
            <token id="22" string="abused" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="9" string="the school" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="10" string="says his daughter 's behavior indicates she may have been abused at the school , but he did n't recognize the warning signs at the time" type="VP">
          <tokens>
            <token id="12" string="says" />
            <token id="13" string="his" />
            <token id="14" string="daughter" />
            <token id="15" string="'s" />
            <token id="16" string="behavior" />
            <token id="17" string="indicates" />
            <token id="18" string="she" />
            <token id="19" string="may" />
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="abused" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
            <token id="26" string="," />
            <token id="27" string="but" />
            <token id="28" string="he" />
            <token id="29" string="did" />
            <token id="30" string="n't" />
            <token id="31" string="recognize" />
            <token id="32" string="the" />
            <token id="33" string="warning" />
            <token id="34" string="signs" />
            <token id="35" string="at" />
            <token id="36" string="the" />
            <token id="37" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="did n't recognize the warning signs at the time" type="VP">
          <tokens>
            <token id="29" string="did" />
            <token id="30" string="n't" />
            <token id="31" string="recognize" />
            <token id="32" string="the" />
            <token id="33" string="warning" />
            <token id="34" string="signs" />
            <token id="35" string="at" />
            <token id="36" string="the" />
            <token id="37" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="to testify" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="testify" />
          </tokens>
        </chunking>
        <chunking id="13" string="indicates she may have been abused at the school" type="VP">
          <tokens>
            <token id="17" string="indicates" />
            <token id="18" string="she" />
            <token id="19" string="may" />
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="abused" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="14" string="have been abused at the school" type="VP">
          <tokens>
            <token id="20" string="have" />
            <token id="21" string="been" />
            <token id="22" string="abused" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="15" string="recognize the warning signs at the time" type="VP">
          <tokens>
            <token id="31" string="recognize" />
            <token id="32" string="the" />
            <token id="33" string="warning" />
            <token id="34" string="signs" />
            <token id="35" string="at" />
            <token id="36" string="the" />
            <token id="37" string="time" />
          </tokens>
        </chunking>
        <chunking id="16" string="the time" type="NP">
          <tokens>
            <token id="36" string="the" />
            <token id="37" string="time" />
          </tokens>
        </chunking>
        <chunking id="17" string="the warning signs" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="warning" />
            <token id="34" string="signs" />
          </tokens>
        </chunking>
        <chunking id="18" string="he" type="NP">
          <tokens>
            <token id="28" string="he" />
          </tokens>
        </chunking>
        <chunking id="19" string="abused at the school" type="VP">
          <tokens>
            <token id="22" string="abused" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="20" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="21" string="testify" type="VP">
          <tokens>
            <token id="11" string="testify" />
          </tokens>
        </chunking>
        <chunking id="22" string="his daughter 's behavior" type="NP">
          <tokens>
            <token id="13" string="his" />
            <token id="14" string="daughter" />
            <token id="15" string="'s" />
            <token id="16" string="behavior" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="12">says</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">July</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">July</governor>
          <dependent id="3">29</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">July</governor>
          <dependent id="5">1987</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">parent</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">parent</governor>
          <dependent id="8">first</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">says</governor>
          <dependent id="9">parent</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">testify</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">parent</governor>
          <dependent id="11">testify</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">says</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">daughter</governor>
          <dependent id="13">his</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">behavior</governor>
          <dependent id="14">daughter</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">daughter</governor>
          <dependent id="15">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">indicates</governor>
          <dependent id="16">behavior</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">says</governor>
          <dependent id="17">indicates</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="22">abused</governor>
          <dependent id="18">she</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">abused</governor>
          <dependent id="19">may</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">abused</governor>
          <dependent id="20">have</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="22">abused</governor>
          <dependent id="21">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">indicates</governor>
          <dependent id="22">abused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">school</governor>
          <dependent id="23">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">school</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">abused</governor>
          <dependent id="25">school</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">indicates</governor>
          <dependent id="27">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">recognize</governor>
          <dependent id="28">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">recognize</governor>
          <dependent id="29">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="31">recognize</governor>
          <dependent id="30">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">indicates</governor>
          <dependent id="31">recognize</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">signs</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">signs</governor>
          <dependent id="33">warning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">recognize</governor>
          <dependent id="34">signs</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">time</governor>
          <dependent id="35">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">time</governor>
          <dependent id="36">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">recognize</governor>
          <dependent id="37">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="8" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="July 29 , 1987" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="July" />
            <token id="3" string="29" />
            <token id="4" string="," />
            <token id="5" string="1987" />
          </tokens>
        </entity>
        <entity id="3" string="time" type="DATE" score="0.0">
          <tokens>
            <token id="37" string="time" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>_Dec. 10, 1987: Paul Bynum, 39, a former police officer who once served as a defense investigator in the case, is found dead from an apparent self-inflicted gunshot wound.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="Dec." lemma="Dec." stem="dec." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="1987" lemma="1987" stem="1987" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Paul" lemma="Paul" stem="paul" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Bynum" lemma="Bynum" stem="bynum" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="39" lemma="39" stem="39" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="police" lemma="police" stem="polic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="officer" lemma="officer" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="18" string="served" lemma="serve" stem="serv" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="defense" lemma="defense" stem="defens" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="investigator" lemma="investigator" stem="investig" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="25" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="apparent" lemma="apparent" stem="appar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="self-inflicted" lemma="self-inflicted" stem="self-inflict" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="gunshot" lemma="gunshot" stem="gunshot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="wound" lemma="wound" stem="wound" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NN _)) (NP-TMP (NNP Dec.) (CD 10) (, ,) (CD 1987))) (: :) (NP (NP (NNP Paul) (NNP Bynum)) (, ,) (NP (CD 39)) (, ,) (NP (NP (DT a) (JJ former) (NN police) (NN officer)) (SBAR (WHNP (WP who)) (S (ADVP (RB once)) (VP (VBD served) (PP (IN as) (NP (DT a) (NN defense) (NN investigator))) (PP (IN in) (NP (DT the) (NN case)))))))) (, ,)) (VP (VBZ is) (VP (VBN found) (ADJP (JJ dead)) (PP (IN from) (NP (DT an) (JJ apparent) (JJ self-inflicted) (NN gunshot) (NN wound))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="_ Dec. 10 , 1987" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Dec." />
            <token id="3" string="10" />
            <token id="4" string="," />
            <token id="5" string="1987" />
          </tokens>
        </chunking>
        <chunking id="2" string="39" type="NP">
          <tokens>
            <token id="10" string="39" />
          </tokens>
        </chunking>
        <chunking id="3" string="the case" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="who once served as a defense investigator in the case" type="SBAR">
          <tokens>
            <token id="16" string="who" />
            <token id="17" string="once" />
            <token id="18" string="served" />
            <token id="19" string="as" />
            <token id="20" string="a" />
            <token id="21" string="defense" />
            <token id="22" string="investigator" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="found dead from an apparent self-inflicted gunshot wound" type="VP">
          <tokens>
            <token id="28" string="found" />
            <token id="29" string="dead" />
            <token id="30" string="from" />
            <token id="31" string="an" />
            <token id="32" string="apparent" />
            <token id="33" string="self-inflicted" />
            <token id="34" string="gunshot" />
            <token id="35" string="wound" />
          </tokens>
        </chunking>
        <chunking id="6" string="a former police officer who once served as a defense investigator in the case" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="former" />
            <token id="14" string="police" />
            <token id="15" string="officer" />
            <token id="16" string="who" />
            <token id="17" string="once" />
            <token id="18" string="served" />
            <token id="19" string="as" />
            <token id="20" string="a" />
            <token id="21" string="defense" />
            <token id="22" string="investigator" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="is found dead from an apparent self-inflicted gunshot wound" type="VP">
          <tokens>
            <token id="27" string="is" />
            <token id="28" string="found" />
            <token id="29" string="dead" />
            <token id="30" string="from" />
            <token id="31" string="an" />
            <token id="32" string="apparent" />
            <token id="33" string="self-inflicted" />
            <token id="34" string="gunshot" />
            <token id="35" string="wound" />
          </tokens>
        </chunking>
        <chunking id="8" string="dead" type="ADJP">
          <tokens>
            <token id="29" string="dead" />
          </tokens>
        </chunking>
        <chunking id="9" string="a former police officer" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="former" />
            <token id="14" string="police" />
            <token id="15" string="officer" />
          </tokens>
        </chunking>
        <chunking id="10" string="_ Dec. 10 , 1987 : Paul Bynum , 39 , a former police officer who once served as a defense investigator in the case ," type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Dec." />
            <token id="3" string="10" />
            <token id="4" string="," />
            <token id="5" string="1987" />
            <token id="6" string=":" />
            <token id="7" string="Paul" />
            <token id="8" string="Bynum" />
            <token id="9" string="," />
            <token id="10" string="39" />
            <token id="11" string="," />
            <token id="12" string="a" />
            <token id="13" string="former" />
            <token id="14" string="police" />
            <token id="15" string="officer" />
            <token id="16" string="who" />
            <token id="17" string="once" />
            <token id="18" string="served" />
            <token id="19" string="as" />
            <token id="20" string="a" />
            <token id="21" string="defense" />
            <token id="22" string="investigator" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="case" />
            <token id="26" string="," />
          </tokens>
        </chunking>
        <chunking id="11" string="Paul Bynum" type="NP">
          <tokens>
            <token id="7" string="Paul" />
            <token id="8" string="Bynum" />
          </tokens>
        </chunking>
        <chunking id="12" string="served as a defense investigator in the case" type="VP">
          <tokens>
            <token id="18" string="served" />
            <token id="19" string="as" />
            <token id="20" string="a" />
            <token id="21" string="defense" />
            <token id="22" string="investigator" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="13" string="an apparent self-inflicted gunshot wound" type="NP">
          <tokens>
            <token id="31" string="an" />
            <token id="32" string="apparent" />
            <token id="33" string="self-inflicted" />
            <token id="34" string="gunshot" />
            <token id="35" string="wound" />
          </tokens>
        </chunking>
        <chunking id="14" string="a defense investigator" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="defense" />
            <token id="22" string="investigator" />
          </tokens>
        </chunking>
        <chunking id="15" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="16" string="Paul Bynum , 39 , a former police officer who once served as a defense investigator in the case" type="NP">
          <tokens>
            <token id="7" string="Paul" />
            <token id="8" string="Bynum" />
            <token id="9" string="," />
            <token id="10" string="39" />
            <token id="11" string="," />
            <token id="12" string="a" />
            <token id="13" string="former" />
            <token id="14" string="police" />
            <token id="15" string="officer" />
            <token id="16" string="who" />
            <token id="17" string="once" />
            <token id="18" string="served" />
            <token id="19" string="as" />
            <token id="20" string="a" />
            <token id="21" string="defense" />
            <token id="22" string="investigator" />
            <token id="23" string="in" />
            <token id="24" string="the" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="28">found</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Dec.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Dec.</governor>
          <dependent id="3">10</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Dec.</governor>
          <dependent id="5">1987</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Bynum</governor>
          <dependent id="7">Paul</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="8">Bynum</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">Bynum</governor>
          <dependent id="10">39</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">officer</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">officer</governor>
          <dependent id="13">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">officer</governor>
          <dependent id="14">police</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">Bynum</governor>
          <dependent id="15">officer</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">served</governor>
          <dependent id="16">who</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">served</governor>
          <dependent id="17">once</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">officer</governor>
          <dependent id="18">served</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">investigator</governor>
          <dependent id="19">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">investigator</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">investigator</governor>
          <dependent id="21">defense</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">served</governor>
          <dependent id="22">investigator</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">case</governor>
          <dependent id="23">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">case</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">served</governor>
          <dependent id="25">case</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="28">found</governor>
          <dependent id="27">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">found</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="28">found</governor>
          <dependent id="29">dead</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">wound</governor>
          <dependent id="30">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">wound</governor>
          <dependent id="31">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">wound</governor>
          <dependent id="32">apparent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">wound</governor>
          <dependent id="33">self-inflicted</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="35">wound</governor>
          <dependent id="34">gunshot</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">found</governor>
          <dependent id="35">wound</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="17" string="once" />
          </tokens>
        </entity>
        <entity id="2" string="39" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="39" />
          </tokens>
        </entity>
        <entity id="3" string="Paul Bynum" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Paul" />
            <token id="8" string="Bynum" />
          </tokens>
        </entity>
        <entity id="4" string="Dec. 10 , 1987" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Dec." />
            <token id="3" string="10" />
            <token id="4" string="," />
            <token id="5" string="1987" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>_Oct. 17, 1988: The judge dismisses eight molestation counts against Buckey and his mother.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Oct." lemma="Oct." stem="oct." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="17" lemma="17" stem="17" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1988" lemma="1988" stem="1988" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="dismisses" lemma="dismiss" stem="dismiss" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="11" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP Oct.) (CD 17) (, ,) (CD 1988))) (: :) (NP (NP (DT The) (NN judge)) (VP (VBZ dismisses) (NP (CD eight) (NN molestation) (NNS counts)) (PP (IN against) (NP (NP (NNP Buckey)) (CC and) (NP (PRP$ his) (NN mother)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Buckey" type="NP">
          <tokens>
            <token id="14" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="_ Oct. 17 , 1988 : The judge dismisses eight molestation counts against Buckey and his mother ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Oct." />
            <token id="3" string="17" />
            <token id="4" string="," />
            <token id="5" string="1988" />
            <token id="6" string=":" />
            <token id="7" string="The" />
            <token id="8" string="judge" />
            <token id="9" string="dismisses" />
            <token id="10" string="eight" />
            <token id="11" string="molestation" />
            <token id="12" string="counts" />
            <token id="13" string="against" />
            <token id="14" string="Buckey" />
            <token id="15" string="and" />
            <token id="16" string="his" />
            <token id="17" string="mother" />
            <token id="18" string="." />
          </tokens>
        </chunking>
        <chunking id="3" string="eight molestation counts" type="NP">
          <tokens>
            <token id="10" string="eight" />
            <token id="11" string="molestation" />
            <token id="12" string="counts" />
          </tokens>
        </chunking>
        <chunking id="4" string="_ Oct. 17 , 1988" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Oct." />
            <token id="3" string="17" />
            <token id="4" string="," />
            <token id="5" string="1988" />
          </tokens>
        </chunking>
        <chunking id="5" string="dismisses eight molestation counts against Buckey and his mother" type="VP">
          <tokens>
            <token id="9" string="dismisses" />
            <token id="10" string="eight" />
            <token id="11" string="molestation" />
            <token id="12" string="counts" />
            <token id="13" string="against" />
            <token id="14" string="Buckey" />
            <token id="15" string="and" />
            <token id="16" string="his" />
            <token id="17" string="mother" />
          </tokens>
        </chunking>
        <chunking id="6" string="his mother" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="mother" />
          </tokens>
        </chunking>
        <chunking id="7" string="The judge dismisses eight molestation counts against Buckey and his mother" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="judge" />
            <token id="9" string="dismisses" />
            <token id="10" string="eight" />
            <token id="11" string="molestation" />
            <token id="12" string="counts" />
            <token id="13" string="against" />
            <token id="14" string="Buckey" />
            <token id="15" string="and" />
            <token id="16" string="his" />
            <token id="17" string="mother" />
          </tokens>
        </chunking>
        <chunking id="8" string="Buckey and his mother" type="NP">
          <tokens>
            <token id="14" string="Buckey" />
            <token id="15" string="and" />
            <token id="16" string="his" />
            <token id="17" string="mother" />
          </tokens>
        </chunking>
        <chunking id="9" string="The judge" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="judge" />
          </tokens>
        </chunking>
        <chunking id="10" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Oct.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Oct.</governor>
          <dependent id="3">17</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Oct.</governor>
          <dependent id="5">1988</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">judge</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="8">judge</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">judge</governor>
          <dependent id="9">dismisses</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="12">counts</governor>
          <dependent id="10">eight</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">counts</governor>
          <dependent id="11">molestation</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">dismisses</governor>
          <dependent id="12">counts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Buckey</governor>
          <dependent id="13">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">dismisses</governor>
          <dependent id="14">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">Buckey</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">mother</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">Buckey</governor>
          <dependent id="17">mother</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Oct. 17 , 1988" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Oct." />
            <token id="3" string="17" />
            <token id="4" string="," />
            <token id="5" string="1988" />
          </tokens>
        </entity>
        <entity id="2" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Buckey" />
          </tokens>
        </entity>
        <entity id="3" string="eight" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="eight" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>They now face a combined 65 counts of molestation and conspiracy involving 11 former McMartin pupils.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="face" lemma="face" stem="face" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="combined" lemma="combine" stem="combin" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="65" lemma="65" stem="65" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="conspiracy" lemma="conspiracy" stem="conspiraci" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="involving" lemma="involve" stem="involv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="11" lemma="11" stem="11" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="pupils" lemma="pupil" stem="pupil" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (ADVP (RB now)) (VP (VBP face) (NP (NP (DT a) (VBN combined) (CD 65) (NNS counts)) (PP (IN of) (NP (NN molestation) (CC and) (NN conspiracy))) (VP (VBG involving) (NP (CD 11) (JJ former) (NNP McMartin) (NNS pupils))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="a combined 65 counts" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="combined" />
            <token id="6" string="65" />
            <token id="7" string="counts" />
          </tokens>
        </chunking>
        <chunking id="3" string="face a combined 65 counts of molestation and conspiracy involving 11 former McMartin pupils" type="VP">
          <tokens>
            <token id="3" string="face" />
            <token id="4" string="a" />
            <token id="5" string="combined" />
            <token id="6" string="65" />
            <token id="7" string="counts" />
            <token id="8" string="of" />
            <token id="9" string="molestation" />
            <token id="10" string="and" />
            <token id="11" string="conspiracy" />
            <token id="12" string="involving" />
            <token id="13" string="11" />
            <token id="14" string="former" />
            <token id="15" string="McMartin" />
            <token id="16" string="pupils" />
          </tokens>
        </chunking>
        <chunking id="4" string="11 former McMartin pupils" type="NP">
          <tokens>
            <token id="13" string="11" />
            <token id="14" string="former" />
            <token id="15" string="McMartin" />
            <token id="16" string="pupils" />
          </tokens>
        </chunking>
        <chunking id="5" string="a combined 65 counts of molestation and conspiracy involving 11 former McMartin pupils" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="combined" />
            <token id="6" string="65" />
            <token id="7" string="counts" />
            <token id="8" string="of" />
            <token id="9" string="molestation" />
            <token id="10" string="and" />
            <token id="11" string="conspiracy" />
            <token id="12" string="involving" />
            <token id="13" string="11" />
            <token id="14" string="former" />
            <token id="15" string="McMartin" />
            <token id="16" string="pupils" />
          </tokens>
        </chunking>
        <chunking id="6" string="molestation and conspiracy" type="NP">
          <tokens>
            <token id="9" string="molestation" />
            <token id="10" string="and" />
            <token id="11" string="conspiracy" />
          </tokens>
        </chunking>
        <chunking id="7" string="involving 11 former McMartin pupils" type="VP">
          <tokens>
            <token id="12" string="involving" />
            <token id="13" string="11" />
            <token id="14" string="former" />
            <token id="15" string="McMartin" />
            <token id="16" string="pupils" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">face</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">face</governor>
          <dependent id="2">now</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">face</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">counts</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">counts</governor>
          <dependent id="5">combined</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">counts</governor>
          <dependent id="6">65</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">face</governor>
          <dependent id="7">counts</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">molestation</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">counts</governor>
          <dependent id="9">molestation</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">molestation</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">molestation</governor>
          <dependent id="11">conspiracy</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">counts</governor>
          <dependent id="12">involving</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">pupils</governor>
          <dependent id="13">11</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">pupils</governor>
          <dependent id="14">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">pupils</governor>
          <dependent id="15">McMartin</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">involving</governor>
          <dependent id="16">pupils</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="65" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="65" />
          </tokens>
        </entity>
        <entity id="3" string="11" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="11" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>_Feb. 15, 1989: Buckey is released on $1.5 million bail after being jailed nearly five years.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Feb." lemma="Feb." stem="feb." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="released" lemma="release" stem="releas" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="12" string="1.5" lemma="1.5" stem="1.5" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="13" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="14" string="bail" lemma="bail" stem="bail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="jailed" lemma="jail" stem="jail" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="19" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="20" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP Feb.) (CD 15) (, ,) (CD 1989))) (: :) (S (NP (NNP Buckey)) (VP (VBZ is) (VP (VBN released) (PP (IN on) (NP (QP ($ $) (CD 1.5) (CD million)) (NN bail))) (PP (IN after) (S (VP (VBG being) (VP (VBN jailed) (NP (QP (RB nearly) (CD five)) (NNS years))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="being jailed nearly five years" type="VP">
          <tokens>
            <token id="16" string="being" />
            <token id="17" string="jailed" />
            <token id="18" string="nearly" />
            <token id="19" string="five" />
            <token id="20" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="Buckey" type="NP">
          <tokens>
            <token id="7" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="3" string="_ Feb. 15 , 1989 : Buckey is released on $ 1.5 million bail after being jailed nearly five years ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Feb." />
            <token id="3" string="15" />
            <token id="4" string="," />
            <token id="5" string="1989" />
            <token id="6" string=":" />
            <token id="7" string="Buckey" />
            <token id="8" string="is" />
            <token id="9" string="released" />
            <token id="10" string="on" />
            <token id="11" string="$" />
            <token id="12" string="1.5" />
            <token id="13" string="million" />
            <token id="14" string="bail" />
            <token id="15" string="after" />
            <token id="16" string="being" />
            <token id="17" string="jailed" />
            <token id="18" string="nearly" />
            <token id="19" string="five" />
            <token id="20" string="years" />
            <token id="21" string="." />
          </tokens>
        </chunking>
        <chunking id="4" string="jailed nearly five years" type="VP">
          <tokens>
            <token id="17" string="jailed" />
            <token id="18" string="nearly" />
            <token id="19" string="five" />
            <token id="20" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="released on $ 1.5 million bail after being jailed nearly five years" type="VP">
          <tokens>
            <token id="9" string="released" />
            <token id="10" string="on" />
            <token id="11" string="$" />
            <token id="12" string="1.5" />
            <token id="13" string="million" />
            <token id="14" string="bail" />
            <token id="15" string="after" />
            <token id="16" string="being" />
            <token id="17" string="jailed" />
            <token id="18" string="nearly" />
            <token id="19" string="five" />
            <token id="20" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="$ 1.5 million bail" type="NP">
          <tokens>
            <token id="11" string="$" />
            <token id="12" string="1.5" />
            <token id="13" string="million" />
            <token id="14" string="bail" />
          </tokens>
        </chunking>
        <chunking id="7" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="8" string="_ Feb. 15 , 1989" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Feb." />
            <token id="3" string="15" />
            <token id="4" string="," />
            <token id="5" string="1989" />
          </tokens>
        </chunking>
        <chunking id="9" string="is released on $ 1.5 million bail after being jailed nearly five years" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="released" />
            <token id="10" string="on" />
            <token id="11" string="$" />
            <token id="12" string="1.5" />
            <token id="13" string="million" />
            <token id="14" string="bail" />
            <token id="15" string="after" />
            <token id="16" string="being" />
            <token id="17" string="jailed" />
            <token id="18" string="nearly" />
            <token id="19" string="five" />
            <token id="20" string="years" />
          </tokens>
        </chunking>
        <chunking id="10" string="nearly five years" type="NP">
          <tokens>
            <token id="18" string="nearly" />
            <token id="19" string="five" />
            <token id="20" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Feb.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Feb.</governor>
          <dependent id="3">15</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Feb.</governor>
          <dependent id="5">1989</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">released</governor>
          <dependent id="7">Buckey</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">released</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">_</governor>
          <dependent id="9">released</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">bail</governor>
          <dependent id="10">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">bail</governor>
          <dependent id="11">$</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">million</governor>
          <dependent id="12">1.5</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">$</governor>
          <dependent id="13">million</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">released</governor>
          <dependent id="14">bail</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">jailed</governor>
          <dependent id="15">after</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="17">jailed</governor>
          <dependent id="16">being</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">released</governor>
          <dependent id="17">jailed</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">five</governor>
          <dependent id="18">nearly</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">years</governor>
          <dependent id="19">five</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="17">jailed</governor>
          <dependent id="20">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="$ 1.5 million" type="MONEY" score="0.0">
          <tokens>
            <token id="11" string="$" />
            <token id="12" string="1.5" />
            <token id="13" string="million" />
          </tokens>
        </entity>
        <entity id="3" string="Feb. 15 , 1989" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Feb." />
            <token id="3" string="15" />
            <token id="4" string="," />
            <token id="5" string="1989" />
          </tokens>
        </entity>
        <entity id="4" string="nearly five years" type="DURATION" score="0.0">
          <tokens>
            <token id="18" string="nearly" />
            <token id="19" string="five" />
            <token id="20" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>_April 27, 1989: The trial, hitting the 2-year, 4-day mark, becomes the longest criminal hearing in U.S. history when it surpasses by one day the Hillside Strangler trial of Angelo Buono in 1982-83.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="April" lemma="April" stem="april" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="27" lemma="27" stem="27" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="hitting" lemma="hit" stem="hit" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="2-year" lemma="2-year" stem="2-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="4-day" lemma="4-day" stem="4-dai" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="15" string="mark" lemma="mark" stem="mark" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="becomes" lemma="become" stem="becom" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="longest" lemma="longest" stem="longest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="criminal" lemma="criminal" stem="crimin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="hearing" lemma="hearing" stem="hear" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="U.S." lemma="U.S." stem="u.s." pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="24" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="surpasses" lemma="surpass" stem="surpass" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="30" string="day" lemma="day" stem="dai" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="Hillside" lemma="Hillside" stem="hillsid" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="Strangler" lemma="Strangler" stem="strangler" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="Angelo" lemma="Angelo" stem="angelo" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="37" string="Buono" lemma="Buono" stem="buono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="38" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="39" string="1982-83" lemma="1982-83" stem="1982-83" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP April) (CD 27) (, ,) (CD 1989))) (: :) (S (NP (NP (DT The) (NN trial)) (, ,) (VP (VBG hitting) (NP (DT the) (JJ 2-year) (, ,) (JJ 4-day) (NN mark))) (, ,)) (VP (VBZ becomes) (NP (NP (DT the) (JJS longest) (JJ criminal) (NN hearing)) (PP (IN in) (NP (NNP U.S.) (NN history))) (SBAR (WHADVP (WRB when)) (S (NP (PRP it)) (VP (VBZ surpasses) (PP (IN by) (NP (CD one) (NN day))) (NP (NP (DT the) (NNP Hillside) (NNP Strangler) (NN trial)) (PP (IN of) (NP (NP (NNP Angelo) (NNP Buono)) (PP (IN in) (NP (CD 1982-83)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the longest criminal hearing" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="longest" />
            <token id="20" string="criminal" />
            <token id="21" string="hearing" />
          </tokens>
        </chunking>
        <chunking id="2" string="becomes the longest criminal hearing in U.S. history when it surpasses by one day the Hillside Strangler trial of Angelo Buono in 1982-83" type="VP">
          <tokens>
            <token id="17" string="becomes" />
            <token id="18" string="the" />
            <token id="19" string="longest" />
            <token id="20" string="criminal" />
            <token id="21" string="hearing" />
            <token id="22" string="in" />
            <token id="23" string="U.S." />
            <token id="24" string="history" />
            <token id="25" string="when" />
            <token id="26" string="it" />
            <token id="27" string="surpasses" />
            <token id="28" string="by" />
            <token id="29" string="one" />
            <token id="30" string="day" />
            <token id="31" string="the" />
            <token id="32" string="Hillside" />
            <token id="33" string="Strangler" />
            <token id="34" string="trial" />
            <token id="35" string="of" />
            <token id="36" string="Angelo" />
            <token id="37" string="Buono" />
            <token id="38" string="in" />
            <token id="39" string="1982-83" />
          </tokens>
        </chunking>
        <chunking id="3" string="when it surpasses by one day the Hillside Strangler trial of Angelo Buono in 1982-83" type="SBAR">
          <tokens>
            <token id="25" string="when" />
            <token id="26" string="it" />
            <token id="27" string="surpasses" />
            <token id="28" string="by" />
            <token id="29" string="one" />
            <token id="30" string="day" />
            <token id="31" string="the" />
            <token id="32" string="Hillside" />
            <token id="33" string="Strangler" />
            <token id="34" string="trial" />
            <token id="35" string="of" />
            <token id="36" string="Angelo" />
            <token id="37" string="Buono" />
            <token id="38" string="in" />
            <token id="39" string="1982-83" />
          </tokens>
        </chunking>
        <chunking id="4" string="1982-83" type="NP">
          <tokens>
            <token id="39" string="1982-83" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 2-year , 4-day mark" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="2-year" />
            <token id="13" string="," />
            <token id="14" string="4-day" />
            <token id="15" string="mark" />
          </tokens>
        </chunking>
        <chunking id="6" string="one day" type="NP">
          <tokens>
            <token id="29" string="one" />
            <token id="30" string="day" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Hillside Strangler trial" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="Hillside" />
            <token id="33" string="Strangler" />
            <token id="34" string="trial" />
          </tokens>
        </chunking>
        <chunking id="8" string="Angelo Buono in 1982-83" type="NP">
          <tokens>
            <token id="36" string="Angelo" />
            <token id="37" string="Buono" />
            <token id="38" string="in" />
            <token id="39" string="1982-83" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="_ April 27 , 1989" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="April" />
            <token id="3" string="27" />
            <token id="4" string="," />
            <token id="5" string="1989" />
          </tokens>
        </chunking>
        <chunking id="11" string="when" type="WHADVP">
          <tokens>
            <token id="25" string="when" />
          </tokens>
        </chunking>
        <chunking id="12" string="the longest criminal hearing in U.S. history when it surpasses by one day the Hillside Strangler trial of Angelo Buono in 1982-83" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="longest" />
            <token id="20" string="criminal" />
            <token id="21" string="hearing" />
            <token id="22" string="in" />
            <token id="23" string="U.S." />
            <token id="24" string="history" />
            <token id="25" string="when" />
            <token id="26" string="it" />
            <token id="27" string="surpasses" />
            <token id="28" string="by" />
            <token id="29" string="one" />
            <token id="30" string="day" />
            <token id="31" string="the" />
            <token id="32" string="Hillside" />
            <token id="33" string="Strangler" />
            <token id="34" string="trial" />
            <token id="35" string="of" />
            <token id="36" string="Angelo" />
            <token id="37" string="Buono" />
            <token id="38" string="in" />
            <token id="39" string="1982-83" />
          </tokens>
        </chunking>
        <chunking id="13" string="surpasses by one day the Hillside Strangler trial of Angelo Buono in 1982-83" type="VP">
          <tokens>
            <token id="27" string="surpasses" />
            <token id="28" string="by" />
            <token id="29" string="one" />
            <token id="30" string="day" />
            <token id="31" string="the" />
            <token id="32" string="Hillside" />
            <token id="33" string="Strangler" />
            <token id="34" string="trial" />
            <token id="35" string="of" />
            <token id="36" string="Angelo" />
            <token id="37" string="Buono" />
            <token id="38" string="in" />
            <token id="39" string="1982-83" />
          </tokens>
        </chunking>
        <chunking id="14" string="The trial" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="trial" />
          </tokens>
        </chunking>
        <chunking id="15" string="U.S. history" type="NP">
          <tokens>
            <token id="23" string="U.S." />
            <token id="24" string="history" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Hillside Strangler trial of Angelo Buono in 1982-83" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="Hillside" />
            <token id="33" string="Strangler" />
            <token id="34" string="trial" />
            <token id="35" string="of" />
            <token id="36" string="Angelo" />
            <token id="37" string="Buono" />
            <token id="38" string="in" />
            <token id="39" string="1982-83" />
          </tokens>
        </chunking>
        <chunking id="17" string="_ April 27 , 1989 : The trial , hitting the 2-year , 4-day mark , becomes the longest criminal hearing in U.S. history when it surpasses by one day the Hillside Strangler trial of Angelo Buono in 1982-83 ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="April" />
            <token id="3" string="27" />
            <token id="4" string="," />
            <token id="5" string="1989" />
            <token id="6" string=":" />
            <token id="7" string="The" />
            <token id="8" string="trial" />
            <token id="9" string="," />
            <token id="10" string="hitting" />
            <token id="11" string="the" />
            <token id="12" string="2-year" />
            <token id="13" string="," />
            <token id="14" string="4-day" />
            <token id="15" string="mark" />
            <token id="16" string="," />
            <token id="17" string="becomes" />
            <token id="18" string="the" />
            <token id="19" string="longest" />
            <token id="20" string="criminal" />
            <token id="21" string="hearing" />
            <token id="22" string="in" />
            <token id="23" string="U.S." />
            <token id="24" string="history" />
            <token id="25" string="when" />
            <token id="26" string="it" />
            <token id="27" string="surpasses" />
            <token id="28" string="by" />
            <token id="29" string="one" />
            <token id="30" string="day" />
            <token id="31" string="the" />
            <token id="32" string="Hillside" />
            <token id="33" string="Strangler" />
            <token id="34" string="trial" />
            <token id="35" string="of" />
            <token id="36" string="Angelo" />
            <token id="37" string="Buono" />
            <token id="38" string="in" />
            <token id="39" string="1982-83" />
            <token id="40" string="." />
          </tokens>
        </chunking>
        <chunking id="18" string="hitting the 2-year , 4-day mark" type="VP">
          <tokens>
            <token id="10" string="hitting" />
            <token id="11" string="the" />
            <token id="12" string="2-year" />
            <token id="13" string="," />
            <token id="14" string="4-day" />
            <token id="15" string="mark" />
          </tokens>
        </chunking>
        <chunking id="19" string="Angelo Buono" type="NP">
          <tokens>
            <token id="36" string="Angelo" />
            <token id="37" string="Buono" />
          </tokens>
        </chunking>
        <chunking id="20" string="The trial , hitting the 2-year , 4-day mark ," type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="trial" />
            <token id="9" string="," />
            <token id="10" string="hitting" />
            <token id="11" string="the" />
            <token id="12" string="2-year" />
            <token id="13" string="," />
            <token id="14" string="4-day" />
            <token id="15" string="mark" />
            <token id="16" string="," />
          </tokens>
        </chunking>
        <chunking id="21" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">April</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">April</governor>
          <dependent id="3">27</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">April</governor>
          <dependent id="5">1989</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">trial</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">becomes</governor>
          <dependent id="8">trial</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">trial</governor>
          <dependent id="10">hitting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">mark</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">mark</governor>
          <dependent id="12">2-year</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">mark</governor>
          <dependent id="14">4-day</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">hitting</governor>
          <dependent id="15">mark</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">_</governor>
          <dependent id="17">becomes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">hearing</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">hearing</governor>
          <dependent id="19">longest</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">hearing</governor>
          <dependent id="20">criminal</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">becomes</governor>
          <dependent id="21">hearing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">history</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">history</governor>
          <dependent id="23">U.S.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">hearing</governor>
          <dependent id="24">history</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="27">surpasses</governor>
          <dependent id="25">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">surpasses</governor>
          <dependent id="26">it</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">hearing</governor>
          <dependent id="27">surpasses</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">day</governor>
          <dependent id="28">by</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="30">day</governor>
          <dependent id="29">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="27">surpasses</governor>
          <dependent id="30">day</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">trial</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">trial</governor>
          <dependent id="32">Hillside</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">trial</governor>
          <dependent id="33">Strangler</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">surpasses</governor>
          <dependent id="34">trial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">Buono</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">Buono</governor>
          <dependent id="36">Angelo</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">trial</governor>
          <dependent id="37">Buono</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">1982-83</governor>
          <dependent id="38">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">Buono</governor>
          <dependent id="39">1982-83</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="4-day" type="DURATION" score="0.0">
          <tokens>
            <token id="14" string="4-day" />
          </tokens>
        </entity>
        <entity id="2" string="2-year" type="DURATION" score="0.0">
          <tokens>
            <token id="12" string="2-year" />
          </tokens>
        </entity>
        <entity id="3" string="U.S." type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="U.S." />
          </tokens>
        </entity>
        <entity id="4" string="1982-83" type="DATE" score="0.0">
          <tokens>
            <token id="39" string="1982-83" />
          </tokens>
        </entity>
        <entity id="5" string="Angelo Buono" type="PERSON" score="0.0">
          <tokens>
            <token id="36" string="Angelo" />
            <token id="37" string="Buono" />
          </tokens>
        </entity>
        <entity id="6" string="one day" type="DURATION" score="0.0">
          <tokens>
            <token id="29" string="one" />
            <token id="30" string="day" />
          </tokens>
        </entity>
        <entity id="7" string="April 27 , 1989" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="April" />
            <token id="3" string="27" />
            <token id="4" string="," />
            <token id="5" string="1989" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>_May 16, 1989: Peggy McMartin Buckey takes the stand for the first time and strongly denies she ever sexually assaulted her students.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NNP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="May" lemma="May" stem="mai" pos="NNP" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="16" lemma="16" stem="16" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="stand" lemma="stand" stem="stand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="16" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="strongly" lemma="strongly" stem="strongli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="denies" lemma="deny" stem="deni" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="sexually" lemma="sexually" stem="sexual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="assaulted" lemma="assault" stem="assault" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NNP _) (NNP May) (CD 16) (, ,) (CD 1989)) (: :) (S (NP (NNP Peggy) (NNP McMartin) (NNP Buckey)) (VP (VP (VBZ takes) (NP (NP (DT the) (NN stand)) (PP (IN for) (NP (DT the) (JJ first) (NN time))))) (CC and) (VP (ADVP (RB strongly)) (VBZ denies) (NP (PRP she))) (ADVP (RB ever)) (VP (ADVP (RB sexually)) (VBD assaulted) (NP (PRP$ her) (NNS students))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="7" string="Peggy" />
            <token id="8" string="McMartin" />
            <token id="9" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="the stand" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="stand" />
          </tokens>
        </chunking>
        <chunking id="3" string="the first time" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="_ May 16 , 1989 : Peggy McMartin Buckey takes the stand for the first time and strongly denies she ever sexually assaulted her students ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="May" />
            <token id="3" string="16" />
            <token id="4" string="," />
            <token id="5" string="1989" />
            <token id="6" string=":" />
            <token id="7" string="Peggy" />
            <token id="8" string="McMartin" />
            <token id="9" string="Buckey" />
            <token id="10" string="takes" />
            <token id="11" string="the" />
            <token id="12" string="stand" />
            <token id="13" string="for" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="time" />
            <token id="17" string="and" />
            <token id="18" string="strongly" />
            <token id="19" string="denies" />
            <token id="20" string="she" />
            <token id="21" string="ever" />
            <token id="22" string="sexually" />
            <token id="23" string="assaulted" />
            <token id="24" string="her" />
            <token id="25" string="students" />
            <token id="26" string="." />
          </tokens>
        </chunking>
        <chunking id="5" string="takes the stand for the first time and strongly denies she ever sexually assaulted her students" type="VP">
          <tokens>
            <token id="10" string="takes" />
            <token id="11" string="the" />
            <token id="12" string="stand" />
            <token id="13" string="for" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="time" />
            <token id="17" string="and" />
            <token id="18" string="strongly" />
            <token id="19" string="denies" />
            <token id="20" string="she" />
            <token id="21" string="ever" />
            <token id="22" string="sexually" />
            <token id="23" string="assaulted" />
            <token id="24" string="her" />
            <token id="25" string="students" />
          </tokens>
        </chunking>
        <chunking id="6" string="takes the stand for the first time" type="VP">
          <tokens>
            <token id="10" string="takes" />
            <token id="11" string="the" />
            <token id="12" string="stand" />
            <token id="13" string="for" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="strongly denies she" type="VP">
          <tokens>
            <token id="18" string="strongly" />
            <token id="19" string="denies" />
            <token id="20" string="she" />
          </tokens>
        </chunking>
        <chunking id="8" string="sexually assaulted her students" type="VP">
          <tokens>
            <token id="22" string="sexually" />
            <token id="23" string="assaulted" />
            <token id="24" string="her" />
            <token id="25" string="students" />
          </tokens>
        </chunking>
        <chunking id="9" string="her students" type="NP">
          <tokens>
            <token id="24" string="her" />
            <token id="25" string="students" />
          </tokens>
        </chunking>
        <chunking id="10" string="the stand for the first time" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="stand" />
            <token id="13" string="for" />
            <token id="14" string="the" />
            <token id="15" string="first" />
            <token id="16" string="time" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="20" string="she" />
          </tokens>
        </chunking>
        <chunking id="12" string="_ May 16 , 1989" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="May" />
            <token id="3" string="16" />
            <token id="4" string="," />
            <token id="5" string="1989" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">May</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">May</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">May</governor>
          <dependent id="3">16</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">May</governor>
          <dependent id="5">1989</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Buckey</governor>
          <dependent id="7">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Buckey</governor>
          <dependent id="8">McMartin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">takes</governor>
          <dependent id="9">Buckey</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">May</governor>
          <dependent id="10">takes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">stand</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">takes</governor>
          <dependent id="12">stand</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">time</governor>
          <dependent id="13">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">time</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">time</governor>
          <dependent id="15">first</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">stand</governor>
          <dependent id="16">time</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">takes</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">denies</governor>
          <dependent id="18">strongly</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">takes</governor>
          <dependent id="19">denies</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">denies</governor>
          <dependent id="20">she</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">takes</governor>
          <dependent id="21">ever</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">assaulted</governor>
          <dependent id="22">sexually</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">takes</governor>
          <dependent id="23">assaulted</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">students</governor>
          <dependent id="24">her</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">assaulted</governor>
          <dependent id="25">students</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Peggy" />
            <token id="8" string="McMartin" />
            <token id="9" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="15" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="May 16 , 1989" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="May" />
            <token id="3" string="16" />
            <token id="4" string="," />
            <token id="5" string="1989" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>_July 26, 1989: Buckey takes the stand and denies he has ever molested children.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="July" lemma="July" stem="juli" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="26" lemma="26" stem="26" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="stand" lemma="stand" stem="stand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="denies" lemma="deny" stem="deni" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP July) (CD 26) (, ,) (CD 1989))) (: :) (S (NP (NNP Buckey)) (VP (VP (VBZ takes) (NP (DT the) (NN stand))) (CC and) (VP (VBZ denies) (SBAR (S (NP (PRP he)) (VP (VBZ has) (ADVP (RB ever)) (VP (VBN molested) (NP (NNS children))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="molested children" type="VP">
          <tokens>
            <token id="16" string="molested" />
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="2" string="takes the stand" type="VP">
          <tokens>
            <token id="8" string="takes" />
            <token id="9" string="the" />
            <token id="10" string="stand" />
          </tokens>
        </chunking>
        <chunking id="3" string="_ July 26 , 1989 : Buckey takes the stand and denies he has ever molested children ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="July" />
            <token id="3" string="26" />
            <token id="4" string="," />
            <token id="5" string="1989" />
            <token id="6" string=":" />
            <token id="7" string="Buckey" />
            <token id="8" string="takes" />
            <token id="9" string="the" />
            <token id="10" string="stand" />
            <token id="11" string="and" />
            <token id="12" string="denies" />
            <token id="13" string="he" />
            <token id="14" string="has" />
            <token id="15" string="ever" />
            <token id="16" string="molested" />
            <token id="17" string="children" />
            <token id="18" string="." />
          </tokens>
        </chunking>
        <chunking id="4" string="_ July 26 , 1989" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="July" />
            <token id="3" string="26" />
            <token id="4" string="," />
            <token id="5" string="1989" />
          </tokens>
        </chunking>
        <chunking id="5" string="takes the stand and denies he has ever molested children" type="VP">
          <tokens>
            <token id="8" string="takes" />
            <token id="9" string="the" />
            <token id="10" string="stand" />
            <token id="11" string="and" />
            <token id="12" string="denies" />
            <token id="13" string="he" />
            <token id="14" string="has" />
            <token id="15" string="ever" />
            <token id="16" string="molested" />
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="6" string="he has ever molested children" type="SBAR">
          <tokens>
            <token id="13" string="he" />
            <token id="14" string="has" />
            <token id="15" string="ever" />
            <token id="16" string="molested" />
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="7" string="Buckey" type="NP">
          <tokens>
            <token id="7" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="8" string="the stand" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="stand" />
          </tokens>
        </chunking>
        <chunking id="9" string="children" type="NP">
          <tokens>
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="10" string="denies he has ever molested children" type="VP">
          <tokens>
            <token id="12" string="denies" />
            <token id="13" string="he" />
            <token id="14" string="has" />
            <token id="15" string="ever" />
            <token id="16" string="molested" />
            <token id="17" string="children" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="13" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="13" string="has ever molested children" type="VP">
          <tokens>
            <token id="14" string="has" />
            <token id="15" string="ever" />
            <token id="16" string="molested" />
            <token id="17" string="children" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">July</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">July</governor>
          <dependent id="3">26</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">July</governor>
          <dependent id="5">1989</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">takes</governor>
          <dependent id="7">Buckey</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">_</governor>
          <dependent id="8">takes</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">stand</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">takes</governor>
          <dependent id="10">stand</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">takes</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">takes</governor>
          <dependent id="12">denies</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">molested</governor>
          <dependent id="13">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">molested</governor>
          <dependent id="14">has</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">molested</governor>
          <dependent id="15">ever</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">denies</governor>
          <dependent id="16">molested</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">molested</governor>
          <dependent id="17">children</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="July 26 , 1989" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="July" />
            <token id="3" string="26" />
            <token id="4" string="," />
            <token id="5" string="1989" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>_Nov. 2, 1989: Jurors adjourn to select a foreman and begin deliberations.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Nov." lemma="Nov." stem="nov." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1989" lemma="1989" stem="1989" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Jurors" lemma="Jurors" stem="juror" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="adjourn" lemma="adjourn" stem="adjourn" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="select" lemma="select" stem="select" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="foreman" lemma="foreman" stem="foreman" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="begin" lemma="begin" stem="begin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="deliberations" lemma="deliberation" stem="deliber" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP Nov.) (CD 2) (, ,) (CD 1989))) (: :) (S (NP (NNP Jurors)) (VP (VP (VB adjourn) (S (VP (TO to) (VP (VB select) (NP (DT a) (NN foreman)))))) (CC and) (VP (VB begin) (NP (NNS deliberations))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="_ Nov. 2 , 1989 : Jurors adjourn to select a foreman and begin deliberations ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Nov." />
            <token id="3" string="2" />
            <token id="4" string="," />
            <token id="5" string="1989" />
            <token id="6" string=":" />
            <token id="7" string="Jurors" />
            <token id="8" string="adjourn" />
            <token id="9" string="to" />
            <token id="10" string="select" />
            <token id="11" string="a" />
            <token id="12" string="foreman" />
            <token id="13" string="and" />
            <token id="14" string="begin" />
            <token id="15" string="deliberations" />
            <token id="16" string="." />
          </tokens>
        </chunking>
        <chunking id="2" string="select a foreman" type="VP">
          <tokens>
            <token id="10" string="select" />
            <token id="11" string="a" />
            <token id="12" string="foreman" />
          </tokens>
        </chunking>
        <chunking id="3" string="a foreman" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="foreman" />
          </tokens>
        </chunking>
        <chunking id="4" string="to select a foreman" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="select" />
            <token id="11" string="a" />
            <token id="12" string="foreman" />
          </tokens>
        </chunking>
        <chunking id="5" string="_ Nov. 2 , 1989" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Nov." />
            <token id="3" string="2" />
            <token id="4" string="," />
            <token id="5" string="1989" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jurors" type="NP">
          <tokens>
            <token id="7" string="Jurors" />
          </tokens>
        </chunking>
        <chunking id="7" string="adjourn to select a foreman and begin deliberations" type="VP">
          <tokens>
            <token id="8" string="adjourn" />
            <token id="9" string="to" />
            <token id="10" string="select" />
            <token id="11" string="a" />
            <token id="12" string="foreman" />
            <token id="13" string="and" />
            <token id="14" string="begin" />
            <token id="15" string="deliberations" />
          </tokens>
        </chunking>
        <chunking id="8" string="deliberations" type="NP">
          <tokens>
            <token id="15" string="deliberations" />
          </tokens>
        </chunking>
        <chunking id="9" string="adjourn to select a foreman" type="VP">
          <tokens>
            <token id="8" string="adjourn" />
            <token id="9" string="to" />
            <token id="10" string="select" />
            <token id="11" string="a" />
            <token id="12" string="foreman" />
          </tokens>
        </chunking>
        <chunking id="10" string="begin deliberations" type="VP">
          <tokens>
            <token id="14" string="begin" />
            <token id="15" string="deliberations" />
          </tokens>
        </chunking>
        <chunking id="11" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Nov.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Nov.</governor>
          <dependent id="3">2</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Nov.</governor>
          <dependent id="5">1989</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">adjourn</governor>
          <dependent id="7">Jurors</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="1">_</governor>
          <dependent id="8">adjourn</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">select</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">adjourn</governor>
          <dependent id="10">select</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">foreman</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">select</governor>
          <dependent id="12">foreman</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">adjourn</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">adjourn</governor>
          <dependent id="14">begin</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">begin</governor>
          <dependent id="15">deliberations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Nov. 2 , 1989" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Nov." />
            <token id="3" string="2" />
            <token id="4" string="," />
            <token id="5" string="1989" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="false">
      <content>The eight-men, four-women panel must sift through volumes of testimony from 124 witnesses.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="eight-men" lemma="eight-men" stem="eight-men" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="four-women" lemma="four-women" stem="four-women" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="panel" lemma="panel" stem="panel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="sift" lemma="sift" stem="sift" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="through" lemma="through" stem="through" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="volumes" lemma="volume" stem="volum" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="testimony" lemma="testimony" stem="testimoni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="124" lemma="124" stem="124" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="14" string="witnesses" lemma="witness" stem="wit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN eight-men) (, ,) (JJ four-women) (NN panel)) (VP (MD must) (VP (VB sift) (PP (IN through) (NP (NP (NNS volumes)) (PP (IN of) (NP (NN testimony))))) (PP (IN from) (NP (CD 124) (NNS witnesses))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="testimony" type="NP">
          <tokens>
            <token id="11" string="testimony" />
          </tokens>
        </chunking>
        <chunking id="2" string="must sift through volumes of testimony from 124 witnesses" type="VP">
          <tokens>
            <token id="6" string="must" />
            <token id="7" string="sift" />
            <token id="8" string="through" />
            <token id="9" string="volumes" />
            <token id="10" string="of" />
            <token id="11" string="testimony" />
            <token id="12" string="from" />
            <token id="13" string="124" />
            <token id="14" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="3" string="sift through volumes of testimony from 124 witnesses" type="VP">
          <tokens>
            <token id="7" string="sift" />
            <token id="8" string="through" />
            <token id="9" string="volumes" />
            <token id="10" string="of" />
            <token id="11" string="testimony" />
            <token id="12" string="from" />
            <token id="13" string="124" />
            <token id="14" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="4" string="124 witnesses" type="NP">
          <tokens>
            <token id="13" string="124" />
            <token id="14" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="5" string="volumes" type="NP">
          <tokens>
            <token id="9" string="volumes" />
          </tokens>
        </chunking>
        <chunking id="6" string="The eight-men , four-women panel" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="eight-men" />
            <token id="3" string="," />
            <token id="4" string="four-women" />
            <token id="5" string="panel" />
          </tokens>
        </chunking>
        <chunking id="7" string="volumes of testimony" type="NP">
          <tokens>
            <token id="9" string="volumes" />
            <token id="10" string="of" />
            <token id="11" string="testimony" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="5">panel</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">panel</governor>
          <dependent id="2">eight-men</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">panel</governor>
          <dependent id="4">four-women</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">sift</governor>
          <dependent id="5">panel</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">sift</governor>
          <dependent id="6">must</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">sift</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">volumes</governor>
          <dependent id="8">through</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">sift</governor>
          <dependent id="9">volumes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">testimony</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">volumes</governor>
          <dependent id="11">testimony</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">witnesses</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="14">witnesses</governor>
          <dependent id="13">124</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">sift</governor>
          <dependent id="14">witnesses</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="124" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="124" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>_Jan. 18, 1990: The jury acquits Buckey and his mother of 52 counts.</content>
      <tokens>
        <token id="1" string="_" lemma="_" stem="_" pos="NN" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Jan." lemma="Jan." stem="jan." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="18" lemma="18" stem="18" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="1990" lemma="1990" stem="1990" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="acquits" lemma="acquit" stem="acquit" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="52" lemma="52" stem="52" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN _)) (NP-TMP (NNP Jan.) (CD 18) (, ,) (CD 1990))) (: :) (NP (NP (DT The) (NN jury)) (SBAR (S (VP (VBZ acquits) (NP (NP (NNP Buckey)) (CC and) (NP (NP (PRP$ his) (NN mother)) (PP (IN of) (NP (CD 52) (NNS counts))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Buckey" type="NP">
          <tokens>
            <token id="10" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="his mother" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="mother" />
          </tokens>
        </chunking>
        <chunking id="3" string="_ Jan. 18 , 1990 : The jury acquits Buckey and his mother of 52 counts ." type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Jan." />
            <token id="3" string="18" />
            <token id="4" string="," />
            <token id="5" string="1990" />
            <token id="6" string=":" />
            <token id="7" string="The" />
            <token id="8" string="jury" />
            <token id="9" string="acquits" />
            <token id="10" string="Buckey" />
            <token id="11" string="and" />
            <token id="12" string="his" />
            <token id="13" string="mother" />
            <token id="14" string="of" />
            <token id="15" string="52" />
            <token id="16" string="counts" />
            <token id="17" string="." />
          </tokens>
        </chunking>
        <chunking id="4" string="The jury" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="jury" />
          </tokens>
        </chunking>
        <chunking id="5" string="52 counts" type="NP">
          <tokens>
            <token id="15" string="52" />
            <token id="16" string="counts" />
          </tokens>
        </chunking>
        <chunking id="6" string="acquits Buckey and his mother of 52 counts" type="SBAR">
          <tokens>
            <token id="9" string="acquits" />
            <token id="10" string="Buckey" />
            <token id="11" string="and" />
            <token id="12" string="his" />
            <token id="13" string="mother" />
            <token id="14" string="of" />
            <token id="15" string="52" />
            <token id="16" string="counts" />
          </tokens>
        </chunking>
        <chunking id="7" string="The jury acquits Buckey and his mother of 52 counts" type="NP">
          <tokens>
            <token id="7" string="The" />
            <token id="8" string="jury" />
            <token id="9" string="acquits" />
            <token id="10" string="Buckey" />
            <token id="11" string="and" />
            <token id="12" string="his" />
            <token id="13" string="mother" />
            <token id="14" string="of" />
            <token id="15" string="52" />
            <token id="16" string="counts" />
          </tokens>
        </chunking>
        <chunking id="8" string="his mother of 52 counts" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="mother" />
            <token id="14" string="of" />
            <token id="15" string="52" />
            <token id="16" string="counts" />
          </tokens>
        </chunking>
        <chunking id="9" string="_ Jan. 18 , 1990" type="NP">
          <tokens>
            <token id="1" string="_" />
            <token id="2" string="Jan." />
            <token id="3" string="18" />
            <token id="4" string="," />
            <token id="5" string="1990" />
          </tokens>
        </chunking>
        <chunking id="10" string="_" type="NP">
          <tokens>
            <token id="1" string="_" />
          </tokens>
        </chunking>
        <chunking id="11" string="Buckey and his mother of 52 counts" type="NP">
          <tokens>
            <token id="10" string="Buckey" />
            <token id="11" string="and" />
            <token id="12" string="his" />
            <token id="13" string="mother" />
            <token id="14" string="of" />
            <token id="15" string="52" />
            <token id="16" string="counts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">_</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="1">_</governor>
          <dependent id="2">Jan.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Jan.</governor>
          <dependent id="3">18</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="2">Jan.</governor>
          <dependent id="5">1990</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">jury</governor>
          <dependent id="7">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">_</governor>
          <dependent id="8">jury</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="8">jury</governor>
          <dependent id="9">acquits</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">acquits</governor>
          <dependent id="10">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">Buckey</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">mother</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Buckey</governor>
          <dependent id="13">mother</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">counts</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">counts</governor>
          <dependent id="15">52</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">mother</governor>
          <dependent id="16">counts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Jan. 18 , 1990" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="Jan." />
            <token id="3" string="18" />
            <token id="4" string="," />
            <token id="5" string="1990" />
          </tokens>
        </entity>
        <entity id="3" string="52" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="52" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>The judge declares a mistrial on 13 other counts _ 12 against Buckey and one against both Buckey and his mother.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="judge" lemma="judge" stem="judg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="declares" lemma="declare" stem="declar" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="mistrial" lemma="mistrial" stem="mistrial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="_" lemma="_" stem="_" pos="VBP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="12" lemma="12" stem="12" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN judge)) (VP (VBZ declares) (SBAR (S (NP (NP (DT a) (NN mistrial)) (PP (IN on) (NP (CD 13) (JJ other) (NNS counts)))) (VP (VBP _) (NP (NP (NP (CD 12)) (PP (IN against) (NP (NNP Buckey)))) (CC and) (NP (NP (CD one)) (PP (IN against) (NP (CC both) (NP (NNP Buckey)) (CC and) (NP (PRP$ his) (NN mother)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="12" type="NP">
          <tokens>
            <token id="11" string="12" />
          </tokens>
        </chunking>
        <chunking id="2" string="_ 12 against Buckey and one against both Buckey and his mother" type="VP">
          <tokens>
            <token id="10" string="_" />
            <token id="11" string="12" />
            <token id="12" string="against" />
            <token id="13" string="Buckey" />
            <token id="14" string="and" />
            <token id="15" string="one" />
            <token id="16" string="against" />
            <token id="17" string="both" />
            <token id="18" string="Buckey" />
            <token id="19" string="and" />
            <token id="20" string="his" />
            <token id="21" string="mother" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="15" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="12 against Buckey and one against both Buckey and his mother" type="NP">
          <tokens>
            <token id="11" string="12" />
            <token id="12" string="against" />
            <token id="13" string="Buckey" />
            <token id="14" string="and" />
            <token id="15" string="one" />
            <token id="16" string="against" />
            <token id="17" string="both" />
            <token id="18" string="Buckey" />
            <token id="19" string="and" />
            <token id="20" string="his" />
            <token id="21" string="mother" />
          </tokens>
        </chunking>
        <chunking id="5" string="12 against Buckey" type="NP">
          <tokens>
            <token id="11" string="12" />
            <token id="12" string="against" />
            <token id="13" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="6" string="The judge" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="judge" />
          </tokens>
        </chunking>
        <chunking id="7" string="a mistrial on 13 other counts _ 12 against Buckey and one against both Buckey and his mother" type="SBAR">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="mistrial" />
            <token id="6" string="on" />
            <token id="7" string="13" />
            <token id="8" string="other" />
            <token id="9" string="counts" />
            <token id="10" string="_" />
            <token id="11" string="12" />
            <token id="12" string="against" />
            <token id="13" string="Buckey" />
            <token id="14" string="and" />
            <token id="15" string="one" />
            <token id="16" string="against" />
            <token id="17" string="both" />
            <token id="18" string="Buckey" />
            <token id="19" string="and" />
            <token id="20" string="his" />
            <token id="21" string="mother" />
          </tokens>
        </chunking>
        <chunking id="8" string="13 other counts" type="NP">
          <tokens>
            <token id="7" string="13" />
            <token id="8" string="other" />
            <token id="9" string="counts" />
          </tokens>
        </chunking>
        <chunking id="9" string="a mistrial on 13 other counts" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="mistrial" />
            <token id="6" string="on" />
            <token id="7" string="13" />
            <token id="8" string="other" />
            <token id="9" string="counts" />
          </tokens>
        </chunking>
        <chunking id="10" string="Buckey" type="NP">
          <tokens>
            <token id="13" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="11" string="one against both Buckey and his mother" type="NP">
          <tokens>
            <token id="15" string="one" />
            <token id="16" string="against" />
            <token id="17" string="both" />
            <token id="18" string="Buckey" />
            <token id="19" string="and" />
            <token id="20" string="his" />
            <token id="21" string="mother" />
          </tokens>
        </chunking>
        <chunking id="12" string="a mistrial" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="mistrial" />
          </tokens>
        </chunking>
        <chunking id="13" string="his mother" type="NP">
          <tokens>
            <token id="20" string="his" />
            <token id="21" string="mother" />
          </tokens>
        </chunking>
        <chunking id="14" string="both Buckey and his mother" type="NP">
          <tokens>
            <token id="17" string="both" />
            <token id="18" string="Buckey" />
            <token id="19" string="and" />
            <token id="20" string="his" />
            <token id="21" string="mother" />
          </tokens>
        </chunking>
        <chunking id="15" string="declares a mistrial on 13 other counts _ 12 against Buckey and one against both Buckey and his mother" type="VP">
          <tokens>
            <token id="3" string="declares" />
            <token id="4" string="a" />
            <token id="5" string="mistrial" />
            <token id="6" string="on" />
            <token id="7" string="13" />
            <token id="8" string="other" />
            <token id="9" string="counts" />
            <token id="10" string="_" />
            <token id="11" string="12" />
            <token id="12" string="against" />
            <token id="13" string="Buckey" />
            <token id="14" string="and" />
            <token id="15" string="one" />
            <token id="16" string="against" />
            <token id="17" string="both" />
            <token id="18" string="Buckey" />
            <token id="19" string="and" />
            <token id="20" string="his" />
            <token id="21" string="mother" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">judge</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">declares</governor>
          <dependent id="2">judge</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">declares</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">mistrial</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">_</governor>
          <dependent id="5">mistrial</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">counts</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">counts</governor>
          <dependent id="7">13</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">counts</governor>
          <dependent id="8">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">mistrial</governor>
          <dependent id="9">counts</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">declares</governor>
          <dependent id="10">_</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">_</governor>
          <dependent id="11">12</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Buckey</governor>
          <dependent id="12">against</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">12</governor>
          <dependent id="13">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">12</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">12</governor>
          <dependent id="15">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Buckey</governor>
          <dependent id="16">against</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="18">Buckey</governor>
          <dependent id="17">both</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">one</governor>
          <dependent id="18">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">Buckey</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">mother</governor>
          <dependent id="20">his</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">Buckey</governor>
          <dependent id="21">mother</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="12" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="12" />
          </tokens>
        </entity>
        <entity id="2" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="13" />
          </tokens>
        </entity>
        <entity id="3" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Buckey" />
          </tokens>
        </entity>
        <entity id="4" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="46-47-48" string="the McMartin Pre-School" id_sentence="2" />
      <mentions>
        <mention ids_tokens="2-3" string="McMartin Pre-school" id_sentence="1" />
      </mentions>
    </coreference>
    <coreference id="2" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5" string="The McMartin Pre-school molestation case" id_sentence="1" />
      <mentions>
        <mention ids_tokens="6-7" string="the case" id_sentence="2" />
        <mention ids_tokens="14-15" string="the case" id_sentence="26" />
        <mention ids_tokens="24-25" string="the case" id_sentence="28" />
        <mention ids_tokens="7-8" string="The trial" id_sentence="32" />
        <mention ids_tokens="26" string="it" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="15-16" string="Judy Johnson" id_sentence="2" />
      <mentions>
        <mention ids_tokens="7-30" string="Judy Johnson , the mother who made the first allegations against Buckey , is found dead , naked and face down in her home" id_sentence="22" />
        <mention ids_tokens="10-30" string="the mother who made the first allegations against Buckey , is found dead , naked and face down in her home" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="28-29-30-31-32-33-34-35-36" string="Detective Jane Hoag that she believes her 2 {" id_sentence="2" />
      <mentions>
        <mention ids_tokens="8" string="Hoag" id_sentence="3" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="31-32-33" string="Peggy McMartin Buckey" id_sentence="7" />
      <mentions>
        <mention ids_tokens="43-48" string="Raymond Buckey at the McMartin Pre-School" id_sentence="2" />
        <mention ids_tokens="10" string="Buckey" id_sentence="3" />
        <mention ids_tokens="1" string="Buckey" id_sentence="9" />
        <mention ids_tokens="3" string="his" id_sentence="9" />
        <mention ids_tokens="3" string="he" id_sentence="10" />
        <mention ids_tokens="35-37" string="Peggy Ann Buckey" id_sentence="19" />
        <mention ids_tokens="5" string="Buckey" id_sentence="20" />
        <mention ids_tokens="7" string="his" id_sentence="20" />
        <mention ids_tokens="7-8" string="Mrs. Buckey" id_sentence="21" />
        <mention ids_tokens="18" string="Buckey" id_sentence="22" />
        <mention ids_tokens="14" string="Buckey" id_sentence="29" />
        <mention ids_tokens="7" string="Buckey" id_sentence="31" />
        <mention ids_tokens="7" string="Buckey" id_sentence="34" />
        <mention ids_tokens="13" string="he" id_sentence="34" />
        <mention ids_tokens="10" string="Buckey" id_sentence="37" />
        <mention ids_tokens="12" string="his" id_sentence="37" />
        <mention ids_tokens="13" string="Buckey" id_sentence="38" />
        <mention ids_tokens="18" string="Buckey" id_sentence="38" />
        <mention ids_tokens="20" string="his" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="33-34" string="his genitals" id_sentence="16" />
      <mentions>
        <mention ids_tokens="34-36" string="genitals and sodomy" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="16-17-18-19" string="Children 's Institute International" id_sentence="5" />
      <mentions>
        <mention ids_tokens="9" string="CII" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="Nearly 400 children" id_sentence="5" />
      <mentions>
        <mention ids_tokens="27" string="children" id_sentence="6" />
        <mention ids_tokens="17" string="children" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="28-29-30-31-32-33" string="his mother , Peggy McMartin Buckey" id_sentence="7" />
      <mentions>
        <mention ids_tokens="3-4" string="his mother" id_sentence="9" />
        <mention ids_tokens="7-8" string="his mother" id_sentence="20" />
        <mention ids_tokens="16-17" string="his mother" id_sentence="29" />
        <mention ids_tokens="20-21" string="his mother" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="21" type="LIST">
      <referenced ids_tokens="1-2-3-4" string="Buckey and his mother" id_sentence="9" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="4-5" string="Christine Johnston" id_sentence="11" />
      <mentions>
        <mention ids_tokens="12-13" string="Ms. Johnston" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="23" type="PROPER">
      <referenced ids_tokens="7-8" string="Glenn Stevens" id_sentence="11" />
      <mentions>
        <mention ids_tokens="1" string="Stevens" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36" string="_ April 20 , 1984 : The seven defendants plead innocent at an arraignment , during which they are charged with sexually abusing 18 children over 10 years and using death threats to silence them ." id_sentence="13" />
      <mentions>
        <mention ids_tokens="1-13" string="_ April 20 , 1987 : The trial begins with jury selection ." id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="2-3-4-5" string="April 20 , 1984" id_sentence="13" />
      <mentions>
        <mention ids_tokens="2-5" string="April 20 , 1987" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="The seven defendants" id_sentence="13" />
      <mentions>
        <mention ids_tokens="38-39" string="the defendants" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17" string="A preliminary hearing starts with Municipal Judge Aviva K. Bobb presiding" id_sentence="14" />
      <mentions>
        <mention ids_tokens="12-14" string="the preliminary hearing" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="30" type="PROPER">
      <referenced ids_tokens="12-13-14-15-16-17" string="Municipal Judge Aviva K. Bobb presiding" id_sentence="14" />
      <mentions>
        <mention ids_tokens="8" string="Bobb" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="34" type="PROPER">
      <referenced ids_tokens="17-18-19-20-21-22-23-24-25" string="Superior Court on 135 counts of molestation and conspiracy" id_sentence="17" />
      <mentions>
        <mention ids_tokens="20-21" string="Superior Court" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="28-29-30-31" string="the longest preliminary hearing" id_sentence="17" />
      <mentions>
        <mention ids_tokens="4-5" string="the hearing" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="37" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20" string="_ Jan. 23 , 1986 : Mrs. Buckey is released on $ 295,000 bail , reduced from $ 495,000 ." id_sentence="21" />
      <mentions>
        <mention ids_tokens="29" string="her" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="38" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35" string="_ Dec. 19 , 1986 : Judy Johnson , the mother who made the first allegations against Buckey , is found dead , naked and face down in her home , at age 44 ." id_sentence="22" />
      <mentions>
        <mention ids_tokens="4" string="she" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="40" type="PROPER">
      <referenced ids_tokens="7" string="Jurors" id_sentence="35" />
      <mentions>
        <mention ids_tokens="5-6" string="12 jurors" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="44" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25" string="_ Dec. 10 , 1987 : Paul Bynum , 39 , a former police officer who once served as a defense investigator in the case" id_sentence="28" />
      <mentions>
        <mention ids_tokens="16" string="his" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17" string="The judge dismisses eight molestation counts against Buckey and his mother" id_sentence="29" />
      <mentions>
        <mention ids_tokens="1-2" string="The judge" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="46" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37-38-39-40" string="_ April 27 , 1989 : The trial , hitting the 2-year , 4-day mark , becomes the longest criminal hearing in U.S. history when it surpasses by one day the Hillside Strangler trial of Angelo Buono in 1982-83 ." id_sentence="32" />
      <mentions>
        <mention ids_tokens="20" string="she" id_sentence="33" />
        <mention ids_tokens="24" string="her" id_sentence="33" />
      </mentions>
    </coreference>
  </coreferences>
</document>
