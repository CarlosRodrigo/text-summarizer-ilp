<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP880921-0201">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>When celebrity biographer Albert Goldman began digging into ``The Lives of John Lennon,&amp;apost;&amp;apost; his first move was to mail a long, reverential request for help to Yoko Ono.</content>
      <tokens>
        <token id="1" string="When" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="celebrity" lemma="celebrity" stem="celebr" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="biographer" lemma="biographer" stem="biograph" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Albert" lemma="Albert" stem="albert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="digging" lemma="digging" stem="dig" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="19" string="move" lemma="move" stem="move" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="mail" lemma="mail" stem="mail" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="reverential" lemma="reverential" stem="reverenti" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="request" lemma="request" stem="request" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="help" lemma="help" stem="help" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (WHADVP (WRB When)) (S (NP (NN celebrity) (NN biographer) (NNP Albert) (NNP Goldman)) (VP (VBD began) (NP (NN digging)) (PP (IN into) (`` ``) (NP (NP (DT The) (NNS Lives)) (PP (IN of) (NP (NNP John) (NNP Lennon)))))))) (, ,) ('' '') (NP (PRP$ his) (JJ first) (NN move)) (VP (VBD was) (S (VP (TO to) (VP (VB mail) (NP (DT a) (ADJP (RB long)) (, ,) (ADJP (JJ reverential)) (NN request)) (PP (IN for) (NP (NN help))) (PP (TO to) (NP (NNP Yoko) (NNP Ono))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a long , reverential request" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="long" />
            <token id="25" string="," />
            <token id="26" string="reverential" />
            <token id="27" string="request" />
          </tokens>
        </chunking>
        <chunking id="2" string="When celebrity biographer Albert Goldman began digging into `` The Lives of John Lennon" type="SBAR">
          <tokens>
            <token id="1" string="When" />
            <token id="2" string="celebrity" />
            <token id="3" string="biographer" />
            <token id="4" string="Albert" />
            <token id="5" string="Goldman" />
            <token id="6" string="began" />
            <token id="7" string="digging" />
            <token id="8" string="into" />
            <token id="9" string="``" />
            <token id="10" string="The" />
            <token id="11" string="Lives" />
            <token id="12" string="of" />
            <token id="13" string="John" />
            <token id="14" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="3" string="to mail a long , reverential request for help to Yoko Ono" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="mail" />
            <token id="23" string="a" />
            <token id="24" string="long" />
            <token id="25" string="," />
            <token id="26" string="reverential" />
            <token id="27" string="request" />
            <token id="28" string="for" />
            <token id="29" string="help" />
            <token id="30" string="to" />
            <token id="31" string="Yoko" />
            <token id="32" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="4" string="his first move" type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="first" />
            <token id="19" string="move" />
          </tokens>
        </chunking>
        <chunking id="5" string="was to mail a long , reverential request for help to Yoko Ono" type="VP">
          <tokens>
            <token id="20" string="was" />
            <token id="21" string="to" />
            <token id="22" string="mail" />
            <token id="23" string="a" />
            <token id="24" string="long" />
            <token id="25" string="," />
            <token id="26" string="reverential" />
            <token id="27" string="request" />
            <token id="28" string="for" />
            <token id="29" string="help" />
            <token id="30" string="to" />
            <token id="31" string="Yoko" />
            <token id="32" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="6" string="The Lives" type="NP">
          <tokens>
            <token id="10" string="The" />
            <token id="11" string="Lives" />
          </tokens>
        </chunking>
        <chunking id="7" string="long" type="ADJP">
          <tokens>
            <token id="24" string="long" />
          </tokens>
        </chunking>
        <chunking id="8" string="digging" type="NP">
          <tokens>
            <token id="7" string="digging" />
          </tokens>
        </chunking>
        <chunking id="9" string="mail a long , reverential request for help to Yoko Ono" type="VP">
          <tokens>
            <token id="22" string="mail" />
            <token id="23" string="a" />
            <token id="24" string="long" />
            <token id="25" string="," />
            <token id="26" string="reverential" />
            <token id="27" string="request" />
            <token id="28" string="for" />
            <token id="29" string="help" />
            <token id="30" string="to" />
            <token id="31" string="Yoko" />
            <token id="32" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="10" string="reverential" type="ADJP">
          <tokens>
            <token id="26" string="reverential" />
          </tokens>
        </chunking>
        <chunking id="11" string="When" type="WHADVP">
          <tokens>
            <token id="1" string="When" />
          </tokens>
        </chunking>
        <chunking id="12" string="celebrity biographer Albert Goldman" type="NP">
          <tokens>
            <token id="2" string="celebrity" />
            <token id="3" string="biographer" />
            <token id="4" string="Albert" />
            <token id="5" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="13" string="John Lennon" type="NP">
          <tokens>
            <token id="13" string="John" />
            <token id="14" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="14" string="help" type="NP">
          <tokens>
            <token id="29" string="help" />
          </tokens>
        </chunking>
        <chunking id="15" string="The Lives of John Lennon" type="NP">
          <tokens>
            <token id="10" string="The" />
            <token id="11" string="Lives" />
            <token id="12" string="of" />
            <token id="13" string="John" />
            <token id="14" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="16" string="began digging into `` The Lives of John Lennon" type="VP">
          <tokens>
            <token id="6" string="began" />
            <token id="7" string="digging" />
            <token id="8" string="into" />
            <token id="9" string="``" />
            <token id="10" string="The" />
            <token id="11" string="Lives" />
            <token id="12" string="of" />
            <token id="13" string="John" />
            <token id="14" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="17" string="Yoko Ono" type="NP">
          <tokens>
            <token id="31" string="Yoko" />
            <token id="32" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">began</governor>
          <dependent id="1">When</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Goldman</governor>
          <dependent id="2">celebrity</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Goldman</governor>
          <dependent id="3">biographer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Goldman</governor>
          <dependent id="4">Albert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">began</governor>
          <dependent id="5">Goldman</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">was</governor>
          <dependent id="6">began</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">began</governor>
          <dependent id="7">digging</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Lives</governor>
          <dependent id="8">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">Lives</governor>
          <dependent id="10">The</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">began</governor>
          <dependent id="11">Lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Lennon</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Lennon</governor>
          <dependent id="13">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">Lives</governor>
          <dependent id="14">Lennon</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">move</governor>
          <dependent id="17">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">move</governor>
          <dependent id="18">first</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">was</governor>
          <dependent id="19">move</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">mail</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="20">was</governor>
          <dependent id="22">mail</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">request</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">request</governor>
          <dependent id="24">long</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">request</governor>
          <dependent id="26">reverential</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">mail</governor>
          <dependent id="27">request</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">help</governor>
          <dependent id="28">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">mail</governor>
          <dependent id="29">help</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">Ono</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">Ono</governor>
          <dependent id="31">Yoko</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">mail</governor>
          <dependent id="32">Ono</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="John" />
            <token id="14" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="18" string="first" />
          </tokens>
        </entity>
        <entity id="3" string="Yoko Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Yoko" />
            <token id="32" string="Ono" />
          </tokens>
        </entity>
        <entity id="4" string="Albert Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Albert" />
            <token id="5" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>``She was Numero Uno, you&amp;apost;ve got to start with her.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Numero" lemma="Numero" stem="numero" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="5" string="Uno" lemma="Uno" stem="uno" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="'ve" lemma="have" stem="'ve" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="got" lemma="get" stem="got" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="start" lemma="start" stem="start" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP She)) (VP (VBD was) (NP (NNP Numero) (NNP Uno)))) (, ,) (NP (PRP you)) (VP (VBP 've) (VP (VBN got) (S (VP (TO to) (VP (VB start) (PP (IN with) (NP (PRP her)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Numero Uno" type="NP">
          <tokens>
            <token id="4" string="Numero" />
            <token id="5" string="Uno" />
          </tokens>
        </chunking>
        <chunking id="2" string="'ve got to start with her" type="VP">
          <tokens>
            <token id="8" string="'ve" />
            <token id="9" string="got" />
            <token id="10" string="to" />
            <token id="11" string="start" />
            <token id="12" string="with" />
            <token id="13" string="her" />
          </tokens>
        </chunking>
        <chunking id="3" string="her" type="NP">
          <tokens>
            <token id="13" string="her" />
          </tokens>
        </chunking>
        <chunking id="4" string="got to start with her" type="VP">
          <tokens>
            <token id="9" string="got" />
            <token id="10" string="to" />
            <token id="11" string="start" />
            <token id="12" string="with" />
            <token id="13" string="her" />
          </tokens>
        </chunking>
        <chunking id="5" string="to start with her" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="start" />
            <token id="12" string="with" />
            <token id="13" string="her" />
          </tokens>
        </chunking>
        <chunking id="6" string="start with her" type="VP">
          <tokens>
            <token id="11" string="start" />
            <token id="12" string="with" />
            <token id="13" string="her" />
          </tokens>
        </chunking>
        <chunking id="7" string="was Numero Uno" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="Numero" />
            <token id="5" string="Uno" />
          </tokens>
        </chunking>
        <chunking id="8" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
        <chunking id="9" string="you" type="NP">
          <tokens>
            <token id="7" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">Uno</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">Uno</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Uno</governor>
          <dependent id="4">Numero</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">got</governor>
          <dependent id="5">Uno</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">got</governor>
          <dependent id="7">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">got</governor>
          <dependent id="8">'ve</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">got</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">start</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">got</governor>
          <dependent id="11">start</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">her</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">start</governor>
          <dependent id="13">her</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Numero Uno" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Numero" />
            <token id="5" string="Uno" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>I sent her a sincere letter, because at that time I was a true believer in rock&amp;apost;s greatest love story.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="sent" lemma="send" stem="sent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sincere" lemma="sincere" stem="sincer" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="letter" lemma="letter" stem="letter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="believer" lemma="believer" stem="believ" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="rock" lemma="rock" stem="rock" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="greatest" lemma="greatest" stem="greatest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="love" lemma="love" stem="love" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBD sent) (NP (PRP her)) (NP (NP (DT a) (ADJP (JJ sincere)) (NN letter)) (, ,) (SBAR (IN because) (S (PP (IN at) (NP (DT that) (NN time))) (NP (PRP I)) (VP (VBD was) (NP (NP (DT a) (JJ true) (NN believer)) (PP (IN in) (NP (NP (NN rock) (POS 's)) (JJS greatest) (NN love) (NN story))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that time" type="NP">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="time" />
          </tokens>
        </chunking>
        <chunking id="2" string="was a true believer in rock 's greatest love story" type="VP">
          <tokens>
            <token id="13" string="was" />
            <token id="14" string="a" />
            <token id="15" string="true" />
            <token id="16" string="believer" />
            <token id="17" string="in" />
            <token id="18" string="rock" />
            <token id="19" string="'s" />
            <token id="20" string="greatest" />
            <token id="21" string="love" />
            <token id="22" string="story" />
          </tokens>
        </chunking>
        <chunking id="3" string="a sincere letter , because at that time I was a true believer in rock 's greatest love story" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="sincere" />
            <token id="6" string="letter" />
            <token id="7" string="," />
            <token id="8" string="because" />
            <token id="9" string="at" />
            <token id="10" string="that" />
            <token id="11" string="time" />
            <token id="12" string="I" />
            <token id="13" string="was" />
            <token id="14" string="a" />
            <token id="15" string="true" />
            <token id="16" string="believer" />
            <token id="17" string="in" />
            <token id="18" string="rock" />
            <token id="19" string="'s" />
            <token id="20" string="greatest" />
            <token id="21" string="love" />
            <token id="22" string="story" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="a sincere letter" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="sincere" />
            <token id="6" string="letter" />
          </tokens>
        </chunking>
        <chunking id="6" string="sent her a sincere letter , because at that time I was a true believer in rock 's greatest love story" type="VP">
          <tokens>
            <token id="2" string="sent" />
            <token id="3" string="her" />
            <token id="4" string="a" />
            <token id="5" string="sincere" />
            <token id="6" string="letter" />
            <token id="7" string="," />
            <token id="8" string="because" />
            <token id="9" string="at" />
            <token id="10" string="that" />
            <token id="11" string="time" />
            <token id="12" string="I" />
            <token id="13" string="was" />
            <token id="14" string="a" />
            <token id="15" string="true" />
            <token id="16" string="believer" />
            <token id="17" string="in" />
            <token id="18" string="rock" />
            <token id="19" string="'s" />
            <token id="20" string="greatest" />
            <token id="21" string="love" />
            <token id="22" string="story" />
          </tokens>
        </chunking>
        <chunking id="7" string="rock 's greatest love story" type="NP">
          <tokens>
            <token id="18" string="rock" />
            <token id="19" string="'s" />
            <token id="20" string="greatest" />
            <token id="21" string="love" />
            <token id="22" string="story" />
          </tokens>
        </chunking>
        <chunking id="8" string="rock 's" type="NP">
          <tokens>
            <token id="18" string="rock" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="her" type="NP">
          <tokens>
            <token id="3" string="her" />
          </tokens>
        </chunking>
        <chunking id="10" string="because at that time I was a true believer in rock 's greatest love story" type="SBAR">
          <tokens>
            <token id="8" string="because" />
            <token id="9" string="at" />
            <token id="10" string="that" />
            <token id="11" string="time" />
            <token id="12" string="I" />
            <token id="13" string="was" />
            <token id="14" string="a" />
            <token id="15" string="true" />
            <token id="16" string="believer" />
            <token id="17" string="in" />
            <token id="18" string="rock" />
            <token id="19" string="'s" />
            <token id="20" string="greatest" />
            <token id="21" string="love" />
            <token id="22" string="story" />
          </tokens>
        </chunking>
        <chunking id="11" string="sincere" type="ADJP">
          <tokens>
            <token id="5" string="sincere" />
          </tokens>
        </chunking>
        <chunking id="12" string="a true believer in rock 's greatest love story" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="true" />
            <token id="16" string="believer" />
            <token id="17" string="in" />
            <token id="18" string="rock" />
            <token id="19" string="'s" />
            <token id="20" string="greatest" />
            <token id="21" string="love" />
            <token id="22" string="story" />
          </tokens>
        </chunking>
        <chunking id="13" string="a true believer" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="true" />
            <token id="16" string="believer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">sent</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">sent</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="2">sent</governor>
          <dependent id="3">her</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">letter</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">letter</governor>
          <dependent id="5">sincere</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">sent</governor>
          <dependent id="6">letter</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">believer</governor>
          <dependent id="8">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">time</governor>
          <dependent id="9">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">time</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">believer</governor>
          <dependent id="11">time</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">believer</governor>
          <dependent id="12">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">believer</governor>
          <dependent id="13">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">believer</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">believer</governor>
          <dependent id="15">true</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">letter</governor>
          <dependent id="16">believer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">story</governor>
          <dependent id="17">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="22">story</governor>
          <dependent id="18">rock</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">rock</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">story</governor>
          <dependent id="20">greatest</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">story</governor>
          <dependent id="21">love</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">believer</governor>
          <dependent id="22">story</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>... I told her, `I&amp;apost;m in your corner,&amp;apost;&amp;apost;&amp;apost; Goldman recalled.</content>
      <tokens>
        <token id="1" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="her" lemma="she" stem="her" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="corner" lemma="corner" stem="corner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="recalled" lemma="recall" stem="recal" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ...) (NP (PRP I)) (VP (VBD told) (SBAR (S (NP (PRP her)) (PRN (, ,) (S (`` `) (NP (PRP I)) (VP (VBP 'm) (PP (IN in) (NP (PRP$ your) (NN corner)) (, ,) ('' ''))) ('' '))) (NP (NNP Goldman)) (VP (VBD recalled))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'m in your corner , ''" type="VP">
          <tokens>
            <token id="8" string="'m" />
            <token id="9" string="in" />
            <token id="10" string="your" />
            <token id="11" string="corner" />
            <token id="12" string="," />
            <token id="13" string="''" />
          </tokens>
        </chunking>
        <chunking id="2" string="told her , ` I 'm in your corner , '' ' Goldman recalled" type="VP">
          <tokens>
            <token id="3" string="told" />
            <token id="4" string="her" />
            <token id="5" string="," />
            <token id="6" string="`" />
            <token id="7" string="I" />
            <token id="8" string="'m" />
            <token id="9" string="in" />
            <token id="10" string="your" />
            <token id="11" string="corner" />
            <token id="12" string="," />
            <token id="13" string="''" />
            <token id="14" string="'" />
            <token id="15" string="Goldman" />
            <token id="16" string="recalled" />
          </tokens>
        </chunking>
        <chunking id="3" string="her" type="NP">
          <tokens>
            <token id="4" string="her" />
          </tokens>
        </chunking>
        <chunking id="4" string="her , ` I 'm in your corner , '' ' Goldman recalled" type="SBAR">
          <tokens>
            <token id="4" string="her" />
            <token id="5" string="," />
            <token id="6" string="`" />
            <token id="7" string="I" />
            <token id="8" string="'m" />
            <token id="9" string="in" />
            <token id="10" string="your" />
            <token id="11" string="corner" />
            <token id="12" string="," />
            <token id="13" string="''" />
            <token id="14" string="'" />
            <token id="15" string="Goldman" />
            <token id="16" string="recalled" />
          </tokens>
        </chunking>
        <chunking id="5" string="your corner" type="NP">
          <tokens>
            <token id="10" string="your" />
            <token id="11" string="corner" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="recalled" type="VP">
          <tokens>
            <token id="16" string="recalled" />
          </tokens>
        </chunking>
        <chunking id="8" string="Goldman" type="NP">
          <tokens>
            <token id="15" string="Goldman" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">told</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">told</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">recalled</governor>
          <dependent id="4">her</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">corner</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">corner</governor>
          <dependent id="8">'m</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">corner</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">corner</governor>
          <dependent id="10">your</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="16">recalled</governor>
          <dependent id="11">corner</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">recalled</governor>
          <dependent id="15">Goldman</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">told</governor>
          <dependent id="16">recalled</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Ono never responded.</content>
      <tokens>
        <token id="1" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="responded" lemma="respond" stem="respond" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Ono)) (ADVP (RB never)) (VP (VBD responded)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="responded" type="VP">
          <tokens>
            <token id="3" string="responded" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ono" type="NP">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">responded</governor>
          <dependent id="1">Ono</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">responded</governor>
          <dependent id="2">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">responded</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>And after 1,200 interviews and 6{ years, the dream was over for Goldman, his mythic view of Lennon the Great altered.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="1,200" lemma="1,200" stem="1,200" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="4" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="6" lemma="6" stem="6" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="7" string="{" lemma="-lcb-" stem="{" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="dream" lemma="dream" stem="dream" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="mythic" lemma="mythic" stem="mythic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="view" lemma="view" stem="view" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Great" lemma="Great" stem="great" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="altered" lemma="alter" stem="alter" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (PP (IN after) (NP (NP (NP (NP (CD 1,200) (NNS interviews)) (CC and) (NP (CD 6))) (-LRB- -LCB-) (NP (NNS years)) (, ,)) (SBAR (S (NP (DT the) (NN dream)) (VP (VBD was) (ADJP (IN over) (PP (IN for) (NP (NNP Goldman))))))))) (, ,) (NP (NP (PRP$ his) (JJ mythic) (NN view)) (PP (IN of) (NP (NNP Lennon) (DT the) (NNP Great)))) (VP (VBD altered)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lennon the Great" type="NP">
          <tokens>
            <token id="21" string="Lennon" />
            <token id="22" string="the" />
            <token id="23" string="Great" />
          </tokens>
        </chunking>
        <chunking id="2" string="his mythic view" type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="mythic" />
            <token id="19" string="view" />
          </tokens>
        </chunking>
        <chunking id="3" string="years" type="NP">
          <tokens>
            <token id="8" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="altered" type="VP">
          <tokens>
            <token id="24" string="altered" />
          </tokens>
        </chunking>
        <chunking id="5" string="his mythic view of Lennon the Great" type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="mythic" />
            <token id="19" string="view" />
            <token id="20" string="of" />
            <token id="21" string="Lennon" />
            <token id="22" string="the" />
            <token id="23" string="Great" />
          </tokens>
        </chunking>
        <chunking id="6" string="1,200 interviews and 6" type="NP">
          <tokens>
            <token id="3" string="1,200" />
            <token id="4" string="interviews" />
            <token id="5" string="and" />
            <token id="6" string="6" />
          </tokens>
        </chunking>
        <chunking id="7" string="the dream" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="dream" />
          </tokens>
        </chunking>
        <chunking id="8" string="was over for Goldman" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="over" />
            <token id="14" string="for" />
            <token id="15" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="9" string="6" type="NP">
          <tokens>
            <token id="6" string="6" />
          </tokens>
        </chunking>
        <chunking id="10" string="1,200 interviews and 6 -LCB- years , the dream was over for Goldman" type="NP">
          <tokens>
            <token id="3" string="1,200" />
            <token id="4" string="interviews" />
            <token id="5" string="and" />
            <token id="6" string="6" />
            <token id="7" string="{" />
            <token id="8" string="years" />
            <token id="9" string="," />
            <token id="10" string="the" />
            <token id="11" string="dream" />
            <token id="12" string="was" />
            <token id="13" string="over" />
            <token id="14" string="for" />
            <token id="15" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="11" string="Goldman" type="NP">
          <tokens>
            <token id="15" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="12" string="1,200 interviews and 6 -LCB- years ," type="NP">
          <tokens>
            <token id="3" string="1,200" />
            <token id="4" string="interviews" />
            <token id="5" string="and" />
            <token id="6" string="6" />
            <token id="7" string="{" />
            <token id="8" string="years" />
            <token id="9" string="," />
          </tokens>
        </chunking>
        <chunking id="13" string="1,200 interviews" type="NP">
          <tokens>
            <token id="3" string="1,200" />
            <token id="4" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="14" string="the dream was over for Goldman" type="SBAR">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="dream" />
            <token id="12" string="was" />
            <token id="13" string="over" />
            <token id="14" string="for" />
            <token id="15" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="15" string="over for Goldman" type="ADJP">
          <tokens>
            <token id="13" string="over" />
            <token id="14" string="for" />
            <token id="15" string="Goldman" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="24">altered</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">interviews</governor>
          <dependent id="2">after</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">interviews</governor>
          <dependent id="3">1,200</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">altered</governor>
          <dependent id="4">interviews</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">interviews</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">interviews</governor>
          <dependent id="6">6</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">interviews</governor>
          <dependent id="8">years</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">dream</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">over</governor>
          <dependent id="11">dream</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">over</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">interviews</governor>
          <dependent id="13">over</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Goldman</governor>
          <dependent id="14">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">over</governor>
          <dependent id="15">Goldman</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">view</governor>
          <dependent id="17">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">view</governor>
          <dependent id="18">mythic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">altered</governor>
          <dependent id="19">view</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Great</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Great</governor>
          <dependent id="21">Lennon</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Great</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">view</governor>
          <dependent id="23">Great</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="24">altered</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1,200" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="1,200" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="6" type="NUMBER" score="0.0">
          <tokens>
            <token id="6" string="6" />
          </tokens>
        </entity>
        <entity id="4" string="Goldman" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="15" string="Goldman" />
          </tokens>
        </entity>
        <entity id="5" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="8" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>Expecting the best, Goldman claims to have uncovered the worst: a volatile, debauched Lennon who evolved into the Howard Hughes of rock &amp;apost;n&amp;apost; roll, tucked in his Dakota bed for days at a time.</content>
      <tokens>
        <token id="1" string="Expecting" lemma="expect" stem="expect" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="claims" lemma="claim" stem="claim" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="uncovered" lemma="uncover" stem="uncov" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="worst" lemma="worst" stem="worst" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="volatile" lemma="volatile" stem="volatil" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="debauched" lemma="debauched" stem="debauch" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="evolved" lemma="evolve" stem="evolv" pos="VBD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="Howard" lemma="Howard" stem="howard" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="23" string="Hughes" lemma="Hughes" stem="hugh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="rock" lemma="rock" stem="rock" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="'n'" lemma="'n'" stem="'n'" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="roll" lemma="roll" stem="roll" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="tucked" lemma="tuck" stem="tuck" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="Dakota" lemma="Dakota" stem="dakota" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="33" string="bed" lemma="bed" stem="bed" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="36" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBG Expecting) (NP (DT the) (JJS best)))) (, ,) (NP (NNP Goldman)) (VP (VBZ claims) (S (VP (TO to) (VP (VB have) (VP (VBN uncovered) (NP (NP (DT the) (JJS worst)) (: :) (NP (NP (NP (DT a) (JJ volatile) (, ,) (JJ debauched) (NNP Lennon)) (SBAR (WHNP (WP who)) (S (VP (VBD evolved) (PP (IN into) (NP (NP (DT the) (NNP Howard) (NNP Hughes)) (PP (IN of) (NP (NN rock))))))))) (CC 'n') (NP (NP (NN roll)) (, ,) (VP (VBN tucked) (PP (IN in) (NP (PRP$ his) (NNP Dakota) (NN bed))) (PP (IN for) (NP (NP (NNS days)) (PP (IN at) (NP (DT a) (NN time)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="evolved into the Howard Hughes of rock" type="VP">
          <tokens>
            <token id="19" string="evolved" />
            <token id="20" string="into" />
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
            <token id="24" string="of" />
            <token id="25" string="rock" />
          </tokens>
        </chunking>
        <chunking id="2" string="to have uncovered the worst : a volatile , debauched Lennon who evolved into the Howard Hughes of rock 'n' roll , tucked in his Dakota bed for days at a time" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="have" />
            <token id="9" string="uncovered" />
            <token id="10" string="the" />
            <token id="11" string="worst" />
            <token id="12" string=":" />
            <token id="13" string="a" />
            <token id="14" string="volatile" />
            <token id="15" string="," />
            <token id="16" string="debauched" />
            <token id="17" string="Lennon" />
            <token id="18" string="who" />
            <token id="19" string="evolved" />
            <token id="20" string="into" />
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
            <token id="24" string="of" />
            <token id="25" string="rock" />
            <token id="26" string="'n'" />
            <token id="27" string="roll" />
            <token id="28" string="," />
            <token id="29" string="tucked" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="Dakota" />
            <token id="33" string="bed" />
            <token id="34" string="for" />
            <token id="35" string="days" />
            <token id="36" string="at" />
            <token id="37" string="a" />
            <token id="38" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="roll , tucked in his Dakota bed for days at a time" type="NP">
          <tokens>
            <token id="27" string="roll" />
            <token id="28" string="," />
            <token id="29" string="tucked" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="Dakota" />
            <token id="33" string="bed" />
            <token id="34" string="for" />
            <token id="35" string="days" />
            <token id="36" string="at" />
            <token id="37" string="a" />
            <token id="38" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="the worst" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="worst" />
          </tokens>
        </chunking>
        <chunking id="5" string="a volatile , debauched Lennon who evolved into the Howard Hughes of rock" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="volatile" />
            <token id="15" string="," />
            <token id="16" string="debauched" />
            <token id="17" string="Lennon" />
            <token id="18" string="who" />
            <token id="19" string="evolved" />
            <token id="20" string="into" />
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
            <token id="24" string="of" />
            <token id="25" string="rock" />
          </tokens>
        </chunking>
        <chunking id="6" string="Expecting the best" type="VP">
          <tokens>
            <token id="1" string="Expecting" />
            <token id="2" string="the" />
            <token id="3" string="best" />
          </tokens>
        </chunking>
        <chunking id="7" string="the worst : a volatile , debauched Lennon who evolved into the Howard Hughes of rock 'n' roll , tucked in his Dakota bed for days at a time" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="worst" />
            <token id="12" string=":" />
            <token id="13" string="a" />
            <token id="14" string="volatile" />
            <token id="15" string="," />
            <token id="16" string="debauched" />
            <token id="17" string="Lennon" />
            <token id="18" string="who" />
            <token id="19" string="evolved" />
            <token id="20" string="into" />
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
            <token id="24" string="of" />
            <token id="25" string="rock" />
            <token id="26" string="'n'" />
            <token id="27" string="roll" />
            <token id="28" string="," />
            <token id="29" string="tucked" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="Dakota" />
            <token id="33" string="bed" />
            <token id="34" string="for" />
            <token id="35" string="days" />
            <token id="36" string="at" />
            <token id="37" string="a" />
            <token id="38" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="the best" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="best" />
          </tokens>
        </chunking>
        <chunking id="9" string="a volatile , debauched Lennon who evolved into the Howard Hughes of rock 'n' roll , tucked in his Dakota bed for days at a time" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="volatile" />
            <token id="15" string="," />
            <token id="16" string="debauched" />
            <token id="17" string="Lennon" />
            <token id="18" string="who" />
            <token id="19" string="evolved" />
            <token id="20" string="into" />
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
            <token id="24" string="of" />
            <token id="25" string="rock" />
            <token id="26" string="'n'" />
            <token id="27" string="roll" />
            <token id="28" string="," />
            <token id="29" string="tucked" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="Dakota" />
            <token id="33" string="bed" />
            <token id="34" string="for" />
            <token id="35" string="days" />
            <token id="36" string="at" />
            <token id="37" string="a" />
            <token id="38" string="time" />
          </tokens>
        </chunking>
        <chunking id="10" string="roll" type="NP">
          <tokens>
            <token id="27" string="roll" />
          </tokens>
        </chunking>
        <chunking id="11" string="his Dakota bed" type="NP">
          <tokens>
            <token id="31" string="his" />
            <token id="32" string="Dakota" />
            <token id="33" string="bed" />
          </tokens>
        </chunking>
        <chunking id="12" string="days at a time" type="NP">
          <tokens>
            <token id="35" string="days" />
            <token id="36" string="at" />
            <token id="37" string="a" />
            <token id="38" string="time" />
          </tokens>
        </chunking>
        <chunking id="13" string="claims to have uncovered the worst : a volatile , debauched Lennon who evolved into the Howard Hughes of rock 'n' roll , tucked in his Dakota bed for days at a time" type="VP">
          <tokens>
            <token id="6" string="claims" />
            <token id="7" string="to" />
            <token id="8" string="have" />
            <token id="9" string="uncovered" />
            <token id="10" string="the" />
            <token id="11" string="worst" />
            <token id="12" string=":" />
            <token id="13" string="a" />
            <token id="14" string="volatile" />
            <token id="15" string="," />
            <token id="16" string="debauched" />
            <token id="17" string="Lennon" />
            <token id="18" string="who" />
            <token id="19" string="evolved" />
            <token id="20" string="into" />
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
            <token id="24" string="of" />
            <token id="25" string="rock" />
            <token id="26" string="'n'" />
            <token id="27" string="roll" />
            <token id="28" string="," />
            <token id="29" string="tucked" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="Dakota" />
            <token id="33" string="bed" />
            <token id="34" string="for" />
            <token id="35" string="days" />
            <token id="36" string="at" />
            <token id="37" string="a" />
            <token id="38" string="time" />
          </tokens>
        </chunking>
        <chunking id="14" string="rock" type="NP">
          <tokens>
            <token id="25" string="rock" />
          </tokens>
        </chunking>
        <chunking id="15" string="uncovered the worst : a volatile , debauched Lennon who evolved into the Howard Hughes of rock 'n' roll , tucked in his Dakota bed for days at a time" type="VP">
          <tokens>
            <token id="9" string="uncovered" />
            <token id="10" string="the" />
            <token id="11" string="worst" />
            <token id="12" string=":" />
            <token id="13" string="a" />
            <token id="14" string="volatile" />
            <token id="15" string="," />
            <token id="16" string="debauched" />
            <token id="17" string="Lennon" />
            <token id="18" string="who" />
            <token id="19" string="evolved" />
            <token id="20" string="into" />
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
            <token id="24" string="of" />
            <token id="25" string="rock" />
            <token id="26" string="'n'" />
            <token id="27" string="roll" />
            <token id="28" string="," />
            <token id="29" string="tucked" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="Dakota" />
            <token id="33" string="bed" />
            <token id="34" string="for" />
            <token id="35" string="days" />
            <token id="36" string="at" />
            <token id="37" string="a" />
            <token id="38" string="time" />
          </tokens>
        </chunking>
        <chunking id="16" string="a volatile , debauched Lennon" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="volatile" />
            <token id="15" string="," />
            <token id="16" string="debauched" />
            <token id="17" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="17" string="a time" type="NP">
          <tokens>
            <token id="37" string="a" />
            <token id="38" string="time" />
          </tokens>
        </chunking>
        <chunking id="18" string="the Howard Hughes of rock" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
            <token id="24" string="of" />
            <token id="25" string="rock" />
          </tokens>
        </chunking>
        <chunking id="19" string="the Howard Hughes" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
          </tokens>
        </chunking>
        <chunking id="20" string="tucked in his Dakota bed for days at a time" type="VP">
          <tokens>
            <token id="29" string="tucked" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="Dakota" />
            <token id="33" string="bed" />
            <token id="34" string="for" />
            <token id="35" string="days" />
            <token id="36" string="at" />
            <token id="37" string="a" />
            <token id="38" string="time" />
          </tokens>
        </chunking>
        <chunking id="21" string="days" type="NP">
          <tokens>
            <token id="35" string="days" />
          </tokens>
        </chunking>
        <chunking id="22" string="who evolved into the Howard Hughes of rock" type="SBAR">
          <tokens>
            <token id="18" string="who" />
            <token id="19" string="evolved" />
            <token id="20" string="into" />
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
            <token id="24" string="of" />
            <token id="25" string="rock" />
          </tokens>
        </chunking>
        <chunking id="23" string="Goldman" type="NP">
          <tokens>
            <token id="5" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="24" string="have uncovered the worst : a volatile , debauched Lennon who evolved into the Howard Hughes of rock 'n' roll , tucked in his Dakota bed for days at a time" type="VP">
          <tokens>
            <token id="8" string="have" />
            <token id="9" string="uncovered" />
            <token id="10" string="the" />
            <token id="11" string="worst" />
            <token id="12" string=":" />
            <token id="13" string="a" />
            <token id="14" string="volatile" />
            <token id="15" string="," />
            <token id="16" string="debauched" />
            <token id="17" string="Lennon" />
            <token id="18" string="who" />
            <token id="19" string="evolved" />
            <token id="20" string="into" />
            <token id="21" string="the" />
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
            <token id="24" string="of" />
            <token id="25" string="rock" />
            <token id="26" string="'n'" />
            <token id="27" string="roll" />
            <token id="28" string="," />
            <token id="29" string="tucked" />
            <token id="30" string="in" />
            <token id="31" string="his" />
            <token id="32" string="Dakota" />
            <token id="33" string="bed" />
            <token id="34" string="for" />
            <token id="35" string="days" />
            <token id="36" string="at" />
            <token id="37" string="a" />
            <token id="38" string="time" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="6">claims</governor>
          <dependent id="1">Expecting</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">best</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="1">Expecting</governor>
          <dependent id="3">best</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">claims</governor>
          <dependent id="5">Goldman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">claims</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">uncovered</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">uncovered</governor>
          <dependent id="8">have</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">claims</governor>
          <dependent id="9">uncovered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">worst</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">uncovered</governor>
          <dependent id="11">worst</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">Lennon</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">Lennon</governor>
          <dependent id="14">volatile</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">Lennon</governor>
          <dependent id="16">debauched</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">worst</governor>
          <dependent id="17">Lennon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">evolved</governor>
          <dependent id="18">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">Lennon</governor>
          <dependent id="19">evolved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Hughes</governor>
          <dependent id="20">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Hughes</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Hughes</governor>
          <dependent id="22">Howard</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">evolved</governor>
          <dependent id="23">Hughes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">rock</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">Hughes</governor>
          <dependent id="25">rock</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">Lennon</governor>
          <dependent id="26">'n'</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">Lennon</governor>
          <dependent id="27">roll</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="27">roll</governor>
          <dependent id="29">tucked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">bed</governor>
          <dependent id="30">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">bed</governor>
          <dependent id="31">his</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">bed</governor>
          <dependent id="32">Dakota</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">tucked</governor>
          <dependent id="33">bed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">days</governor>
          <dependent id="34">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">tucked</governor>
          <dependent id="35">days</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">time</governor>
          <dependent id="36">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">time</governor>
          <dependent id="37">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">days</governor>
          <dependent id="38">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="days" type="DURATION" score="0.0">
          <tokens>
            <token id="35" string="days" />
          </tokens>
        </entity>
        <entity id="3" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Goldman" />
          </tokens>
        </entity>
        <entity id="4" string="Howard Hughes" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Howard" />
            <token id="23" string="Hughes" />
          </tokens>
        </entity>
        <entity id="5" string="Dakota" type="LOCATION" score="0.0">
          <tokens>
            <token id="32" string="Dakota" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>That vision of the ex-Beatle has infuriated Lennon supporters, family and friends and prompted charges of fiction writing; it also taught Goldman _ who says he is a John Lennon fan _ a hard lesson.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="vision" lemma="vision" stem="vision" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="ex-Beatle" lemma="ex-Beatle" stem="ex-beatl" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="infuriated" lemma="infuriate" stem="infuri" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="9" string="supporters" lemma="supporter" stem="support" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="prompted" lemma="prompt" stem="prompt" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="writing" lemma="writing" stem="write" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="taught" lemma="teach" stem="taught" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="_" lemma="_" stem="_" pos="NNP" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="33" string="fan" lemma="fan" stem="fan" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="34" string="_" lemma="_" stem="_" pos="VBD" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="36" string="hard" lemma="hard" stem="hard" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="37" string="lesson" lemma="lesson" stem="lesson" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT That) (NN vision)) (PP (IN of) (NP (DT the) (NNP ex-Beatle)))) (VP (VP (VBZ has) (VP (VBN infuriated) (NP (NP (NNP Lennon) (NNS supporters)) (, ,) (NP (NN family)) (CC and) (NP (NNS friends))))) (CC and) (VP (VBD prompted) (NP (NP (NNS charges)) (PP (IN of) (NP (NN fiction) (NN writing))))))) (: ;) (S (NP (PRP it)) (ADVP (RB also)) (VP (VBD taught) (NP (NP (NNP Goldman) (NNP _)) (SBAR (WHNP (WP who)) (S (VP (VBZ says) (SBAR (S (NP (PRP he)) (VP (VBZ is) (NP (NP (DT a) (NNP John) (NNP Lennon) (NN fan)) (SBAR (S (VP (VBD _) (NP (DT a) (JJ hard) (NN lesson))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="has infuriated Lennon supporters , family and friends" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="infuriated" />
            <token id="8" string="Lennon" />
            <token id="9" string="supporters" />
            <token id="10" string="," />
            <token id="11" string="family" />
            <token id="12" string="and" />
            <token id="13" string="friends" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="21" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="the ex-Beatle" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="ex-Beatle" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lennon supporters" type="NP">
          <tokens>
            <token id="8" string="Lennon" />
            <token id="9" string="supporters" />
          </tokens>
        </chunking>
        <chunking id="5" string="prompted charges of fiction writing" type="VP">
          <tokens>
            <token id="15" string="prompted" />
            <token id="16" string="charges" />
            <token id="17" string="of" />
            <token id="18" string="fiction" />
            <token id="19" string="writing" />
          </tokens>
        </chunking>
        <chunking id="6" string="friends" type="NP">
          <tokens>
            <token id="13" string="friends" />
          </tokens>
        </chunking>
        <chunking id="7" string="charges of fiction writing" type="NP">
          <tokens>
            <token id="16" string="charges" />
            <token id="17" string="of" />
            <token id="18" string="fiction" />
            <token id="19" string="writing" />
          </tokens>
        </chunking>
        <chunking id="8" string="charges" type="NP">
          <tokens>
            <token id="16" string="charges" />
          </tokens>
        </chunking>
        <chunking id="9" string="Lennon supporters , family and friends" type="NP">
          <tokens>
            <token id="8" string="Lennon" />
            <token id="9" string="supporters" />
            <token id="10" string="," />
            <token id="11" string="family" />
            <token id="12" string="and" />
            <token id="13" string="friends" />
          </tokens>
        </chunking>
        <chunking id="10" string="family" type="NP">
          <tokens>
            <token id="11" string="family" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="28" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="says he is a John Lennon fan _ a hard lesson" type="VP">
          <tokens>
            <token id="27" string="says" />
            <token id="28" string="he" />
            <token id="29" string="is" />
            <token id="30" string="a" />
            <token id="31" string="John" />
            <token id="32" string="Lennon" />
            <token id="33" string="fan" />
            <token id="34" string="_" />
            <token id="35" string="a" />
            <token id="36" string="hard" />
            <token id="37" string="lesson" />
          </tokens>
        </chunking>
        <chunking id="13" string="infuriated Lennon supporters , family and friends" type="VP">
          <tokens>
            <token id="7" string="infuriated" />
            <token id="8" string="Lennon" />
            <token id="9" string="supporters" />
            <token id="10" string="," />
            <token id="11" string="family" />
            <token id="12" string="and" />
            <token id="13" string="friends" />
          </tokens>
        </chunking>
        <chunking id="14" string="fiction writing" type="NP">
          <tokens>
            <token id="18" string="fiction" />
            <token id="19" string="writing" />
          </tokens>
        </chunking>
        <chunking id="15" string="Goldman _" type="NP">
          <tokens>
            <token id="24" string="Goldman" />
            <token id="25" string="_" />
          </tokens>
        </chunking>
        <chunking id="16" string="is a John Lennon fan _ a hard lesson" type="VP">
          <tokens>
            <token id="29" string="is" />
            <token id="30" string="a" />
            <token id="31" string="John" />
            <token id="32" string="Lennon" />
            <token id="33" string="fan" />
            <token id="34" string="_" />
            <token id="35" string="a" />
            <token id="36" string="hard" />
            <token id="37" string="lesson" />
          </tokens>
        </chunking>
        <chunking id="17" string="has infuriated Lennon supporters , family and friends and prompted charges of fiction writing" type="VP">
          <tokens>
            <token id="6" string="has" />
            <token id="7" string="infuriated" />
            <token id="8" string="Lennon" />
            <token id="9" string="supporters" />
            <token id="10" string="," />
            <token id="11" string="family" />
            <token id="12" string="and" />
            <token id="13" string="friends" />
            <token id="14" string="and" />
            <token id="15" string="prompted" />
            <token id="16" string="charges" />
            <token id="17" string="of" />
            <token id="18" string="fiction" />
            <token id="19" string="writing" />
          </tokens>
        </chunking>
        <chunking id="18" string="That vision of the ex-Beatle" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="vision" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="ex-Beatle" />
          </tokens>
        </chunking>
        <chunking id="19" string="he is a John Lennon fan _ a hard lesson" type="SBAR">
          <tokens>
            <token id="28" string="he" />
            <token id="29" string="is" />
            <token id="30" string="a" />
            <token id="31" string="John" />
            <token id="32" string="Lennon" />
            <token id="33" string="fan" />
            <token id="34" string="_" />
            <token id="35" string="a" />
            <token id="36" string="hard" />
            <token id="37" string="lesson" />
          </tokens>
        </chunking>
        <chunking id="20" string="taught Goldman _ who says he is a John Lennon fan _ a hard lesson" type="VP">
          <tokens>
            <token id="23" string="taught" />
            <token id="24" string="Goldman" />
            <token id="25" string="_" />
            <token id="26" string="who" />
            <token id="27" string="says" />
            <token id="28" string="he" />
            <token id="29" string="is" />
            <token id="30" string="a" />
            <token id="31" string="John" />
            <token id="32" string="Lennon" />
            <token id="33" string="fan" />
            <token id="34" string="_" />
            <token id="35" string="a" />
            <token id="36" string="hard" />
            <token id="37" string="lesson" />
          </tokens>
        </chunking>
        <chunking id="21" string="_ a hard lesson" type="SBAR">
          <tokens>
            <token id="34" string="_" />
            <token id="35" string="a" />
            <token id="36" string="hard" />
            <token id="37" string="lesson" />
          </tokens>
        </chunking>
        <chunking id="22" string="a hard lesson" type="NP">
          <tokens>
            <token id="35" string="a" />
            <token id="36" string="hard" />
            <token id="37" string="lesson" />
          </tokens>
        </chunking>
        <chunking id="23" string="Goldman _ who says he is a John Lennon fan _ a hard lesson" type="NP">
          <tokens>
            <token id="24" string="Goldman" />
            <token id="25" string="_" />
            <token id="26" string="who" />
            <token id="27" string="says" />
            <token id="28" string="he" />
            <token id="29" string="is" />
            <token id="30" string="a" />
            <token id="31" string="John" />
            <token id="32" string="Lennon" />
            <token id="33" string="fan" />
            <token id="34" string="_" />
            <token id="35" string="a" />
            <token id="36" string="hard" />
            <token id="37" string="lesson" />
          </tokens>
        </chunking>
        <chunking id="24" string="a John Lennon fan _ a hard lesson" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="John" />
            <token id="32" string="Lennon" />
            <token id="33" string="fan" />
            <token id="34" string="_" />
            <token id="35" string="a" />
            <token id="36" string="hard" />
            <token id="37" string="lesson" />
          </tokens>
        </chunking>
        <chunking id="25" string="That vision" type="NP">
          <tokens>
            <token id="1" string="That" />
            <token id="2" string="vision" />
          </tokens>
        </chunking>
        <chunking id="26" string="a John Lennon fan" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="John" />
            <token id="32" string="Lennon" />
            <token id="33" string="fan" />
          </tokens>
        </chunking>
        <chunking id="27" string="who says he is a John Lennon fan _ a hard lesson" type="SBAR">
          <tokens>
            <token id="26" string="who" />
            <token id="27" string="says" />
            <token id="28" string="he" />
            <token id="29" string="is" />
            <token id="30" string="a" />
            <token id="31" string="John" />
            <token id="32" string="Lennon" />
            <token id="33" string="fan" />
            <token id="34" string="_" />
            <token id="35" string="a" />
            <token id="36" string="hard" />
            <token id="37" string="lesson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">vision</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">infuriated</governor>
          <dependent id="2">vision</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">ex-Beatle</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">ex-Beatle</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">vision</governor>
          <dependent id="5">ex-Beatle</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">infuriated</governor>
          <dependent id="6">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">infuriated</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">supporters</governor>
          <dependent id="8">Lennon</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">infuriated</governor>
          <dependent id="9">supporters</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">supporters</governor>
          <dependent id="11">family</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">supporters</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">supporters</governor>
          <dependent id="13">friends</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">infuriated</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">infuriated</governor>
          <dependent id="15">prompted</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">prompted</governor>
          <dependent id="16">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">writing</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">writing</governor>
          <dependent id="18">fiction</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">charges</governor>
          <dependent id="19">writing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">taught</governor>
          <dependent id="21">it</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">taught</governor>
          <dependent id="22">also</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">infuriated</governor>
          <dependent id="23">taught</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">_</governor>
          <dependent id="24">Goldman</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">taught</governor>
          <dependent id="25">_</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">says</governor>
          <dependent id="26">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="25">_</governor>
          <dependent id="27">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">fan</governor>
          <dependent id="28">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="33">fan</governor>
          <dependent id="29">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">fan</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">fan</governor>
          <dependent id="31">John</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="33">fan</governor>
          <dependent id="32">Lennon</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">says</governor>
          <dependent id="33">fan</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="33">fan</governor>
          <dependent id="34">_</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">lesson</governor>
          <dependent id="35">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">lesson</governor>
          <dependent id="36">hard</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">_</governor>
          <dependent id="37">lesson</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="John" />
            <token id="32" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>``It doesn&amp;apost;t pay to meet your idols.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="pay" lemma="pay" stem="pai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="meet" lemma="meet" stem="meet" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="your" lemma="you" stem="your" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="idols" lemma="idol" stem="idol" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBZ does) (RB n't) (VP (VB pay) (S (VP (TO to) (VP (VB meet) (NP (PRP$ your) (NNS idols))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="meet your idols" type="VP">
          <tokens>
            <token id="7" string="meet" />
            <token id="8" string="your" />
            <token id="9" string="idols" />
          </tokens>
        </chunking>
        <chunking id="2" string="does n't pay to meet your idols" type="VP">
          <tokens>
            <token id="3" string="does" />
            <token id="4" string="n't" />
            <token id="5" string="pay" />
            <token id="6" string="to" />
            <token id="7" string="meet" />
            <token id="8" string="your" />
            <token id="9" string="idols" />
          </tokens>
        </chunking>
        <chunking id="3" string="to meet your idols" type="VP">
          <tokens>
            <token id="6" string="to" />
            <token id="7" string="meet" />
            <token id="8" string="your" />
            <token id="9" string="idols" />
          </tokens>
        </chunking>
        <chunking id="4" string="your idols" type="NP">
          <tokens>
            <token id="8" string="your" />
            <token id="9" string="idols" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="6" string="pay to meet your idols" type="VP">
          <tokens>
            <token id="5" string="pay" />
            <token id="6" string="to" />
            <token id="7" string="meet" />
            <token id="8" string="your" />
            <token id="9" string="idols" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">pay</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">pay</governor>
          <dependent id="3">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">pay</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">pay</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">meet</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">pay</governor>
          <dependent id="7">meet</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">idols</governor>
          <dependent id="8">your</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">meet</governor>
          <dependent id="9">idols</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Just enjoy them; don&amp;apost;t try to see the reality,&amp;apost;&amp;apost; Goldman said.</content>
      <tokens>
        <token id="1" string="Just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="enjoy" lemma="enjoy" stem="enjoi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="try" lemma="try" stem="try" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="reality" lemma="reality" stem="realiti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Just)) (VP (VB enjoy) (NP (PRP them) (: ;) (SBAR (S (VP (VBP do) (RB n't) (VP (VB try) (S (VP (TO to) (VP (VB see) (NP (DT the) (NN reality)))))))))))) (, ,) ('' '') (NP (NNP Goldman)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="them ; do n't try to see the reality" type="NP">
          <tokens>
            <token id="3" string="them" />
            <token id="4" string=";" />
            <token id="5" string="do" />
            <token id="6" string="n't" />
            <token id="7" string="try" />
            <token id="8" string="to" />
            <token id="9" string="see" />
            <token id="10" string="the" />
            <token id="11" string="reality" />
          </tokens>
        </chunking>
        <chunking id="2" string="to see the reality" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="see" />
            <token id="10" string="the" />
            <token id="11" string="reality" />
          </tokens>
        </chunking>
        <chunking id="3" string="enjoy them ; do n't try to see the reality" type="VP">
          <tokens>
            <token id="2" string="enjoy" />
            <token id="3" string="them" />
            <token id="4" string=";" />
            <token id="5" string="do" />
            <token id="6" string="n't" />
            <token id="7" string="try" />
            <token id="8" string="to" />
            <token id="9" string="see" />
            <token id="10" string="the" />
            <token id="11" string="reality" />
          </tokens>
        </chunking>
        <chunking id="4" string="the reality" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="reality" />
          </tokens>
        </chunking>
        <chunking id="5" string="do n't try to see the reality" type="SBAR">
          <tokens>
            <token id="5" string="do" />
            <token id="6" string="n't" />
            <token id="7" string="try" />
            <token id="8" string="to" />
            <token id="9" string="see" />
            <token id="10" string="the" />
            <token id="11" string="reality" />
          </tokens>
        </chunking>
        <chunking id="6" string="try to see the reality" type="VP">
          <tokens>
            <token id="7" string="try" />
            <token id="8" string="to" />
            <token id="9" string="see" />
            <token id="10" string="the" />
            <token id="11" string="reality" />
          </tokens>
        </chunking>
        <chunking id="7" string="Goldman" type="NP">
          <tokens>
            <token id="14" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="8" string="said" type="VP">
          <tokens>
            <token id="15" string="said" />
          </tokens>
        </chunking>
        <chunking id="9" string="see the reality" type="VP">
          <tokens>
            <token id="9" string="see" />
            <token id="10" string="the" />
            <token id="11" string="reality" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">enjoy</governor>
          <dependent id="1">Just</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="2">enjoy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">enjoy</governor>
          <dependent id="3">them</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">try</governor>
          <dependent id="5">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">try</governor>
          <dependent id="6">n't</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">them</governor>
          <dependent id="7">try</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">see</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">try</governor>
          <dependent id="9">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">reality</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">see</governor>
          <dependent id="11">reality</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="14">Goldman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>``My books are a cold dose of reality.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="cold" lemma="cold" stem="cold" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="dose" lemma="dose" stem="dose" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="reality" lemma="reality" stem="realiti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP$ My) (NNS books)) (VP (VBP are) (NP (NP (DT a) (JJ cold) (NN dose)) (PP (IN of) (NP (NN reality))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="My books" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="books" />
          </tokens>
        </chunking>
        <chunking id="2" string="reality" type="NP">
          <tokens>
            <token id="9" string="reality" />
          </tokens>
        </chunking>
        <chunking id="3" string="are a cold dose of reality" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="a" />
            <token id="6" string="cold" />
            <token id="7" string="dose" />
            <token id="8" string="of" />
            <token id="9" string="reality" />
          </tokens>
        </chunking>
        <chunking id="4" string="a cold dose of reality" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="cold" />
            <token id="7" string="dose" />
            <token id="8" string="of" />
            <token id="9" string="reality" />
          </tokens>
        </chunking>
        <chunking id="5" string="a cold dose" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="cold" />
            <token id="7" string="dose" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">books</governor>
          <dependent id="2">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">dose</governor>
          <dependent id="3">books</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">dose</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">dose</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">dose</governor>
          <dependent id="6">cold</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">dose</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">reality</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">dose</governor>
          <dependent id="9">reality</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="12" has_coreference="false">
      <content>You get in the Beatle shower, and suddenly the water goes cold.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="get" lemma="get" stem="get" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Beatle" lemma="Beatle" stem="beatl" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="6" string="shower" lemma="shower" stem="shower" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="suddenly" lemma="suddenly" stem="suddenli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="water" lemma="water" stem="water" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="goes" lemma="go" stem="goe" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="cold" lemma="cold" stem="cold" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP You)) (VP (VBP get) (PP (IN in) (NP (DT the) (NNP Beatle) (NN shower))))) (, ,) (CC and) (S (ADVP (RB suddenly)) (NP (DT the) (NN water)) (VP (VBZ goes) (ADJP (JJ cold)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="the water" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="water" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Beatle shower" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="Beatle" />
            <token id="6" string="shower" />
          </tokens>
        </chunking>
        <chunking id="3" string="goes cold" type="VP">
          <tokens>
            <token id="12" string="goes" />
            <token id="13" string="cold" />
          </tokens>
        </chunking>
        <chunking id="4" string="get in the Beatle shower" type="VP">
          <tokens>
            <token id="2" string="get" />
            <token id="3" string="in" />
            <token id="4" string="the" />
            <token id="5" string="Beatle" />
            <token id="6" string="shower" />
          </tokens>
        </chunking>
        <chunking id="5" string="cold" type="ADJP">
          <tokens>
            <token id="13" string="cold" />
          </tokens>
        </chunking>
        <chunking id="6" string="You" type="NP">
          <tokens>
            <token id="1" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">get</governor>
          <dependent id="1">You</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">get</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">shower</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">shower</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">shower</governor>
          <dependent id="5">Beatle</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">get</governor>
          <dependent id="6">shower</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">get</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">goes</governor>
          <dependent id="9">suddenly</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">water</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">goes</governor>
          <dependent id="11">water</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">get</governor>
          <dependent id="12">goes</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">goes</governor>
          <dependent id="13">cold</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Beatle" type="MISC" score="0.0">
          <tokens>
            <token id="5" string="Beatle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>Goldman, whose past tell-all biographies dealt with Elvis Presley and Lenny Bruce, remains unmoved by the hue and cry from the music industry, from Ono and from Lennon&amp;apost;s Beatle buddy, Paul McCartney.</content>
      <tokens>
        <token id="1" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="5" string="tell-all" lemma="tell-all" stem="tell-al" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="biographies" lemma="biography" stem="biographi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="dealt" lemma="deal" stem="dealt" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="Elvis" lemma="Elvis" stem="elvi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="10" string="Presley" lemma="Presley" stem="preslei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="12" string="Lenny" lemma="Lenny" stem="lenni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="13" string="Bruce" lemma="Bruce" stem="bruce" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="remains" lemma="remain" stem="remain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="unmoved" lemma="unmoved" stem="unmov" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="hue" lemma="hue" stem="hue" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="cry" lemma="cry" stem="cry" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="music" lemma="music" stem="music" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="33" string="Beatle" lemma="Beatle" stem="beatl" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="34" string="buddy" lemma="buddy" stem="buddi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="Paul" lemma="Paul" stem="paul" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="37" string="McCartney" lemma="McCartney" stem="mccartnei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="38" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Goldman)) (, ,) (SBAR (WP$ whose) (S (NP (JJ past) (JJ tell-all) (NNS biographies)) (VP (VBN dealt) (PP (IN with) (NP (NP (NNP Elvis) (NNP Presley)) (CC and) (NP (NNP Lenny) (NNP Bruce))))))) (, ,)) (VP (VBZ remains) (ADJP (JJ unmoved) (PP (PP (IN by) (NP (NP (DT the) (NN hue) (CC and) (NN cry)) (PP (IN from) (NP (DT the) (NN music) (NN industry))))) (, ,) (PP (IN from) (NP (NNP Ono))) (CC and) (PP (IN from) (NP (NP (NP (NNP Lennon) (POS 's)) (NNP Beatle) (NN buddy)) (, ,) (NP (NNP Paul) (NNP McCartney))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="past tell-all biographies" type="NP">
          <tokens>
            <token id="4" string="past" />
            <token id="5" string="tell-all" />
            <token id="6" string="biographies" />
          </tokens>
        </chunking>
        <chunking id="2" string="the hue and cry" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="hue" />
            <token id="20" string="and" />
            <token id="21" string="cry" />
          </tokens>
        </chunking>
        <chunking id="3" string="Lennon 's Beatle buddy , Paul McCartney" type="NP">
          <tokens>
            <token id="31" string="Lennon" />
            <token id="32" string="'s" />
            <token id="33" string="Beatle" />
            <token id="34" string="buddy" />
            <token id="35" string="," />
            <token id="36" string="Paul" />
            <token id="37" string="McCartney" />
          </tokens>
        </chunking>
        <chunking id="4" string="Elvis Presley" type="NP">
          <tokens>
            <token id="9" string="Elvis" />
            <token id="10" string="Presley" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lenny Bruce" type="NP">
          <tokens>
            <token id="12" string="Lenny" />
            <token id="13" string="Bruce" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lennon 's" type="NP">
          <tokens>
            <token id="31" string="Lennon" />
            <token id="32" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="Elvis Presley and Lenny Bruce" type="NP">
          <tokens>
            <token id="9" string="Elvis" />
            <token id="10" string="Presley" />
            <token id="11" string="and" />
            <token id="12" string="Lenny" />
            <token id="13" string="Bruce" />
          </tokens>
        </chunking>
        <chunking id="8" string="the music industry" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="music" />
            <token id="25" string="industry" />
          </tokens>
        </chunking>
        <chunking id="9" string="Ono" type="NP">
          <tokens>
            <token id="28" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="10" string="Paul McCartney" type="NP">
          <tokens>
            <token id="36" string="Paul" />
            <token id="37" string="McCartney" />
          </tokens>
        </chunking>
        <chunking id="11" string="Goldman , whose past tell-all biographies dealt with Elvis Presley and Lenny Bruce ," type="NP">
          <tokens>
            <token id="1" string="Goldman" />
            <token id="2" string="," />
            <token id="3" string="whose" />
            <token id="4" string="past" />
            <token id="5" string="tell-all" />
            <token id="6" string="biographies" />
            <token id="7" string="dealt" />
            <token id="8" string="with" />
            <token id="9" string="Elvis" />
            <token id="10" string="Presley" />
            <token id="11" string="and" />
            <token id="12" string="Lenny" />
            <token id="13" string="Bruce" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="unmoved by the hue and cry from the music industry , from Ono and from Lennon 's Beatle buddy , Paul McCartney" type="ADJP">
          <tokens>
            <token id="16" string="unmoved" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="hue" />
            <token id="20" string="and" />
            <token id="21" string="cry" />
            <token id="22" string="from" />
            <token id="23" string="the" />
            <token id="24" string="music" />
            <token id="25" string="industry" />
            <token id="26" string="," />
            <token id="27" string="from" />
            <token id="28" string="Ono" />
            <token id="29" string="and" />
            <token id="30" string="from" />
            <token id="31" string="Lennon" />
            <token id="32" string="'s" />
            <token id="33" string="Beatle" />
            <token id="34" string="buddy" />
            <token id="35" string="," />
            <token id="36" string="Paul" />
            <token id="37" string="McCartney" />
          </tokens>
        </chunking>
        <chunking id="13" string="whose past tell-all biographies dealt with Elvis Presley and Lenny Bruce" type="SBAR">
          <tokens>
            <token id="3" string="whose" />
            <token id="4" string="past" />
            <token id="5" string="tell-all" />
            <token id="6" string="biographies" />
            <token id="7" string="dealt" />
            <token id="8" string="with" />
            <token id="9" string="Elvis" />
            <token id="10" string="Presley" />
            <token id="11" string="and" />
            <token id="12" string="Lenny" />
            <token id="13" string="Bruce" />
          </tokens>
        </chunking>
        <chunking id="14" string="remains unmoved by the hue and cry from the music industry , from Ono and from Lennon 's Beatle buddy , Paul McCartney" type="VP">
          <tokens>
            <token id="15" string="remains" />
            <token id="16" string="unmoved" />
            <token id="17" string="by" />
            <token id="18" string="the" />
            <token id="19" string="hue" />
            <token id="20" string="and" />
            <token id="21" string="cry" />
            <token id="22" string="from" />
            <token id="23" string="the" />
            <token id="24" string="music" />
            <token id="25" string="industry" />
            <token id="26" string="," />
            <token id="27" string="from" />
            <token id="28" string="Ono" />
            <token id="29" string="and" />
            <token id="30" string="from" />
            <token id="31" string="Lennon" />
            <token id="32" string="'s" />
            <token id="33" string="Beatle" />
            <token id="34" string="buddy" />
            <token id="35" string="," />
            <token id="36" string="Paul" />
            <token id="37" string="McCartney" />
          </tokens>
        </chunking>
        <chunking id="15" string="Goldman" type="NP">
          <tokens>
            <token id="1" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="16" string="dealt with Elvis Presley and Lenny Bruce" type="VP">
          <tokens>
            <token id="7" string="dealt" />
            <token id="8" string="with" />
            <token id="9" string="Elvis" />
            <token id="10" string="Presley" />
            <token id="11" string="and" />
            <token id="12" string="Lenny" />
            <token id="13" string="Bruce" />
          </tokens>
        </chunking>
        <chunking id="17" string="the hue and cry from the music industry" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="hue" />
            <token id="20" string="and" />
            <token id="21" string="cry" />
            <token id="22" string="from" />
            <token id="23" string="the" />
            <token id="24" string="music" />
            <token id="25" string="industry" />
          </tokens>
        </chunking>
        <chunking id="18" string="Lennon 's Beatle buddy" type="NP">
          <tokens>
            <token id="31" string="Lennon" />
            <token id="32" string="'s" />
            <token id="33" string="Beatle" />
            <token id="34" string="buddy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="15">remains</governor>
          <dependent id="1">Goldman</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">dealt</governor>
          <dependent id="3">whose</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">biographies</governor>
          <dependent id="4">past</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">biographies</governor>
          <dependent id="5">tell-all</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">dealt</governor>
          <dependent id="6">biographies</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Goldman</governor>
          <dependent id="7">dealt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Presley</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Presley</governor>
          <dependent id="9">Elvis</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">dealt</governor>
          <dependent id="10">Presley</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">Presley</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Bruce</governor>
          <dependent id="12">Lenny</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Presley</governor>
          <dependent id="13">Bruce</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">remains</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="15">remains</governor>
          <dependent id="16">unmoved</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">unmoved</governor>
          <dependent id="16">unmoved</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">unmoved</governor>
          <dependent id="16">unmoved</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">unmoved</governor>
          <dependent id="16">unmoved</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="16">unmoved</governor>
          <dependent id="16">unmoved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">hue</governor>
          <dependent id="17">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">hue</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">unmoved</governor>
          <dependent id="19">hue</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">unmoved</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">hue</governor>
          <dependent id="21">cry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">industry</governor>
          <dependent id="22">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">industry</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">industry</governor>
          <dependent id="24">music</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">hue</governor>
          <dependent id="25">industry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Ono</governor>
          <dependent id="27">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">unmoved</governor>
          <dependent id="28">Ono</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="16">unmoved</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">buddy</governor>
          <dependent id="30">from</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">buddy</governor>
          <dependent id="31">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Lennon</governor>
          <dependent id="32">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">buddy</governor>
          <dependent id="33">Beatle</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">unmoved</governor>
          <dependent id="34">buddy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">McCartney</governor>
          <dependent id="36">Paul</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="34">buddy</governor>
          <dependent id="37">McCartney</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Beatle" type="MISC" score="0.0">
          <tokens>
            <token id="33" string="Beatle" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="past" />
          </tokens>
        </entity>
        <entity id="4" string="Elvis Presley" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Elvis" />
            <token id="10" string="Presley" />
          </tokens>
        </entity>
        <entity id="5" string="Lenny Bruce" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Lenny" />
            <token id="13" string="Bruce" />
          </tokens>
        </entity>
        <entity id="6" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Goldman" />
          </tokens>
        </entity>
        <entity id="7" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Ono" />
          </tokens>
        </entity>
        <entity id="8" string="Paul McCartney" type="PERSON" score="0.0">
          <tokens>
            <token id="36" string="Paul" />
            <token id="37" string="McCartney" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>``My books are bad for business,&amp;apost;&amp;apost; Goldman said in a phone interview from Munich, West Germany.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="phone" lemma="phone" stem="phone" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Munich" lemma="Munich" stem="munich" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="West" lemma="West" stem="west" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Germany" lemma="Germany" stem="germani" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP$ My) (NNS books)) (VP (VBP are) (ADJP (JJ bad) (PP (IN for) (NP (NN business)))))) (, ,) ('' '') (NP (NNP Goldman)) (VP (VBD said) (PP (IN in) (NP (DT a) (NN phone) (NN interview))) (PP (IN from) (NP (NP (NNP Munich)) (, ,) (NP (NNP West) (NNP Germany))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a phone interview" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="phone" />
            <token id="15" string="interview" />
          </tokens>
        </chunking>
        <chunking id="2" string="My books" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="books" />
          </tokens>
        </chunking>
        <chunking id="3" string="bad for business" type="ADJP">
          <tokens>
            <token id="5" string="bad" />
            <token id="6" string="for" />
            <token id="7" string="business" />
          </tokens>
        </chunking>
        <chunking id="4" string="said in a phone interview from Munich , West Germany" type="VP">
          <tokens>
            <token id="11" string="said" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="phone" />
            <token id="15" string="interview" />
            <token id="16" string="from" />
            <token id="17" string="Munich" />
            <token id="18" string="," />
            <token id="19" string="West" />
            <token id="20" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="5" string="business" type="NP">
          <tokens>
            <token id="7" string="business" />
          </tokens>
        </chunking>
        <chunking id="6" string="are bad for business" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="bad" />
            <token id="6" string="for" />
            <token id="7" string="business" />
          </tokens>
        </chunking>
        <chunking id="7" string="Goldman" type="NP">
          <tokens>
            <token id="10" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="8" string="Munich , West Germany" type="NP">
          <tokens>
            <token id="17" string="Munich" />
            <token id="18" string="," />
            <token id="19" string="West" />
            <token id="20" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="9" string="West Germany" type="NP">
          <tokens>
            <token id="19" string="West" />
            <token id="20" string="Germany" />
          </tokens>
        </chunking>
        <chunking id="10" string="Munich" type="NP">
          <tokens>
            <token id="17" string="Munich" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">books</governor>
          <dependent id="2">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">bad</governor>
          <dependent id="3">books</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">bad</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="5">bad</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">business</governor>
          <dependent id="6">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">bad</governor>
          <dependent id="7">business</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Goldman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">interview</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">interview</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">interview</governor>
          <dependent id="14">phone</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">said</governor>
          <dependent id="15">interview</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">Munich</governor>
          <dependent id="16">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">said</governor>
          <dependent id="17">Munich</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Germany</governor>
          <dependent id="19">West</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">Munich</governor>
          <dependent id="20">Germany</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Goldman" />
          </tokens>
        </entity>
        <entity id="2" string="West Germany" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="West" />
            <token id="20" string="Germany" />
          </tokens>
        </entity>
        <entity id="3" string="Munich" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Munich" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>``They&amp;apost;re bad for Paul&amp;apost;s business, bad for Yoko&amp;apost;s business, back for the jive myth of rock business.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Paul" lemma="Paul" stem="paul" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="jive" lemma="jive" stem="jive" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="myth" lemma="myth" stem="myth" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="rock" lemma="rock" stem="rock" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP They)) (VP (VBP 're) (ADJP (JJ bad) (PP (IN for) (NP (NP (NNP Paul) (POS 's)) (NN business)))) (, ,) (ADJP (JJ bad) (PP (IN for) (NP (NP (NP (NNP Yoko) (POS 's)) (NN business)) (, ,) (ADVP (RB back) (PP (IN for) (NP (NP (DT the) (JJ jive) (NN myth)) (PP (IN of) (NP (NN rock) (NN business)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="2" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="the jive myth" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="jive" />
            <token id="20" string="myth" />
          </tokens>
        </chunking>
        <chunking id="3" string="'re bad for Paul 's business , bad for Yoko 's business , back for the jive myth of rock business" type="VP">
          <tokens>
            <token id="3" string="'re" />
            <token id="4" string="bad" />
            <token id="5" string="for" />
            <token id="6" string="Paul" />
            <token id="7" string="'s" />
            <token id="8" string="business" />
            <token id="9" string="," />
            <token id="10" string="bad" />
            <token id="11" string="for" />
            <token id="12" string="Yoko" />
            <token id="13" string="'s" />
            <token id="14" string="business" />
            <token id="15" string="," />
            <token id="16" string="back" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="jive" />
            <token id="20" string="myth" />
            <token id="21" string="of" />
            <token id="22" string="rock" />
            <token id="23" string="business" />
          </tokens>
        </chunking>
        <chunking id="4" string="Paul 's business" type="NP">
          <tokens>
            <token id="6" string="Paul" />
            <token id="7" string="'s" />
            <token id="8" string="business" />
          </tokens>
        </chunking>
        <chunking id="5" string="bad for Yoko 's business , back for the jive myth of rock business" type="ADJP">
          <tokens>
            <token id="10" string="bad" />
            <token id="11" string="for" />
            <token id="12" string="Yoko" />
            <token id="13" string="'s" />
            <token id="14" string="business" />
            <token id="15" string="," />
            <token id="16" string="back" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="jive" />
            <token id="20" string="myth" />
            <token id="21" string="of" />
            <token id="22" string="rock" />
            <token id="23" string="business" />
          </tokens>
        </chunking>
        <chunking id="6" string="Yoko 's business" type="NP">
          <tokens>
            <token id="12" string="Yoko" />
            <token id="13" string="'s" />
            <token id="14" string="business" />
          </tokens>
        </chunking>
        <chunking id="7" string="Yoko 's business , back for the jive myth of rock business" type="NP">
          <tokens>
            <token id="12" string="Yoko" />
            <token id="13" string="'s" />
            <token id="14" string="business" />
            <token id="15" string="," />
            <token id="16" string="back" />
            <token id="17" string="for" />
            <token id="18" string="the" />
            <token id="19" string="jive" />
            <token id="20" string="myth" />
            <token id="21" string="of" />
            <token id="22" string="rock" />
            <token id="23" string="business" />
          </tokens>
        </chunking>
        <chunking id="8" string="the jive myth of rock business" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="jive" />
            <token id="20" string="myth" />
            <token id="21" string="of" />
            <token id="22" string="rock" />
            <token id="23" string="business" />
          </tokens>
        </chunking>
        <chunking id="9" string="Paul 's" type="NP">
          <tokens>
            <token id="6" string="Paul" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="10" string="Yoko 's" type="NP">
          <tokens>
            <token id="12" string="Yoko" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="bad for Paul 's business" type="ADJP">
          <tokens>
            <token id="4" string="bad" />
            <token id="5" string="for" />
            <token id="6" string="Paul" />
            <token id="7" string="'s" />
            <token id="8" string="business" />
          </tokens>
        </chunking>
        <chunking id="12" string="rock business" type="NP">
          <tokens>
            <token id="22" string="rock" />
            <token id="23" string="business" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">bad</governor>
          <dependent id="2">They</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">bad</governor>
          <dependent id="3">'re</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">bad</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">business</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">business</governor>
          <dependent id="6">Paul</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Paul</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">bad</governor>
          <dependent id="8">business</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">bad</governor>
          <dependent id="10">bad</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">business</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">business</governor>
          <dependent id="12">Yoko</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Yoko</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">bad</governor>
          <dependent id="14">business</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">business</governor>
          <dependent id="16">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">myth</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">myth</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">myth</governor>
          <dependent id="19">jive</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">back</governor>
          <dependent id="20">myth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">business</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">business</governor>
          <dependent id="22">rock</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">myth</governor>
          <dependent id="23">business</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Paul" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Paul" />
          </tokens>
        </entity>
        <entity id="2" string="Yoko" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Yoko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Those people have to hate me.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="hate" lemma="hate" stem="hate" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Those) (NNS people)) (VP (VBP have) (S (VP (TO to) (VP (VB hate) (NP (PRP me)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="to hate me" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="hate" />
            <token id="6" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="hate me" type="VP">
          <tokens>
            <token id="5" string="hate" />
            <token id="6" string="me" />
          </tokens>
        </chunking>
        <chunking id="3" string="have to hate me" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="to" />
            <token id="5" string="hate" />
            <token id="6" string="me" />
          </tokens>
        </chunking>
        <chunking id="4" string="me" type="NP">
          <tokens>
            <token id="6" string="me" />
          </tokens>
        </chunking>
        <chunking id="5" string="Those people" type="NP">
          <tokens>
            <token id="1" string="Those" />
            <token id="2" string="people" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">people</governor>
          <dependent id="1">Those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">have</governor>
          <dependent id="2">people</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">hate</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">have</governor>
          <dependent id="5">hate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">hate</governor>
          <dependent id="6">me</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Myth-shattering is a not a bad thing, Goldman said.</content>
      <tokens>
        <token id="1" string="Myth-shattering" lemma="myth-shattering" stem="myth-shatt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="bad" lemma="bad" stem="bad" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NN Myth-shattering)) (VP (VBZ is) (NP (DT a) (ADJP (RB not) (DT a)) (JJ bad) (NN thing)))) (, ,) (NP (NNP Goldman)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a not a bad thing" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="not" />
            <token id="5" string="a" />
            <token id="6" string="bad" />
            <token id="7" string="thing" />
          </tokens>
        </chunking>
        <chunking id="2" string="not a" type="ADJP">
          <tokens>
            <token id="4" string="not" />
            <token id="5" string="a" />
          </tokens>
        </chunking>
        <chunking id="3" string="Myth-shattering" type="NP">
          <tokens>
            <token id="1" string="Myth-shattering" />
          </tokens>
        </chunking>
        <chunking id="4" string="is a not a bad thing" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="not" />
            <token id="5" string="a" />
            <token id="6" string="bad" />
            <token id="7" string="thing" />
          </tokens>
        </chunking>
        <chunking id="5" string="Goldman" type="NP">
          <tokens>
            <token id="9" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="10" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">thing</governor>
          <dependent id="1">Myth-shattering</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">thing</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">thing</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">a</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">thing</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">thing</governor>
          <dependent id="6">bad</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="7">thing</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="9">Goldman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>For example, he cites Lennon&amp;apost;s disillusioning meeting with Presley at Graceland in 1965.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="cites" lemma="cite" stem="cite" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="disillusioning" lemma="disillusioning" stem="disillus" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="meeting" lemma="meeting" stem="meet" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Presley" lemma="Presley" stem="preslei" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Graceland" lemma="Graceland" stem="graceland" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="1965" lemma="1965" stem="1965" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (NN example))) (, ,) (NP (PRP he)) (VP (VBZ cites) (NP (NP (NP (NNP Lennon) (POS 's)) (JJ disillusioning) (NN meeting)) (PP (IN with) (NP (NNP Presley)))) (PP (IN at) (NP (NP (NNP Graceland)) (PP (IN in) (NP (CD 1965)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="1965" type="NP">
          <tokens>
            <token id="15" string="1965" />
          </tokens>
        </chunking>
        <chunking id="2" string="Lennon 's disillusioning meeting with Presley" type="NP">
          <tokens>
            <token id="6" string="Lennon" />
            <token id="7" string="'s" />
            <token id="8" string="disillusioning" />
            <token id="9" string="meeting" />
            <token id="10" string="with" />
            <token id="11" string="Presley" />
          </tokens>
        </chunking>
        <chunking id="3" string="Graceland in 1965" type="NP">
          <tokens>
            <token id="13" string="Graceland" />
            <token id="14" string="in" />
            <token id="15" string="1965" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lennon 's disillusioning meeting" type="NP">
          <tokens>
            <token id="6" string="Lennon" />
            <token id="7" string="'s" />
            <token id="8" string="disillusioning" />
            <token id="9" string="meeting" />
          </tokens>
        </chunking>
        <chunking id="5" string="cites Lennon 's disillusioning meeting with Presley at Graceland in 1965" type="VP">
          <tokens>
            <token id="5" string="cites" />
            <token id="6" string="Lennon" />
            <token id="7" string="'s" />
            <token id="8" string="disillusioning" />
            <token id="9" string="meeting" />
            <token id="10" string="with" />
            <token id="11" string="Presley" />
            <token id="12" string="at" />
            <token id="13" string="Graceland" />
            <token id="14" string="in" />
            <token id="15" string="1965" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lennon 's" type="NP">
          <tokens>
            <token id="6" string="Lennon" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="example" type="NP">
          <tokens>
            <token id="2" string="example" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="Graceland" type="NP">
          <tokens>
            <token id="13" string="Graceland" />
          </tokens>
        </chunking>
        <chunking id="10" string="Presley" type="NP">
          <tokens>
            <token id="11" string="Presley" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">example</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">cites</governor>
          <dependent id="2">example</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">cites</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">cites</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">meeting</governor>
          <dependent id="6">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Lennon</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">meeting</governor>
          <dependent id="8">disillusioning</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">cites</governor>
          <dependent id="9">meeting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Presley</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">meeting</governor>
          <dependent id="11">Presley</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Graceland</governor>
          <dependent id="12">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">cites</governor>
          <dependent id="13">Graceland</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">1965</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">Graceland</governor>
          <dependent id="15">1965</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1965" type="DATE" score="0.0">
          <tokens>
            <token id="15" string="1965" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="Graceland" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Graceland" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>``John was very hooked into Elvis.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="hooked" lemma="hooked" stem="hook" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Elvis" lemma="Elvis" stem="elvi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP John)) (VP (VBD was) (ADJP (RB very) (JJ hooked)) (PP (IN into) (NP (NNP Elvis)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="very hooked" type="ADJP">
          <tokens>
            <token id="4" string="very" />
            <token id="5" string="hooked" />
          </tokens>
        </chunking>
        <chunking id="2" string="Elvis" type="NP">
          <tokens>
            <token id="7" string="Elvis" />
          </tokens>
        </chunking>
        <chunking id="3" string="John" type="NP">
          <tokens>
            <token id="2" string="John" />
          </tokens>
        </chunking>
        <chunking id="4" string="was very hooked into Elvis" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="very" />
            <token id="5" string="hooked" />
            <token id="6" string="into" />
            <token id="7" string="Elvis" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">hooked</governor>
          <dependent id="2">John</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">hooked</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">hooked</governor>
          <dependent id="4">very</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">hooked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Elvis</governor>
          <dependent id="6">into</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">hooked</governor>
          <dependent id="7">Elvis</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Elvis" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Elvis" />
          </tokens>
        </entity>
        <entity id="2" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="John" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>Elvis was his measure of success,&amp;apost;&amp;apost; said Goldman.</content>
      <tokens>
        <token id="1" string="Elvis" lemma="Elvis" stem="elvi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="measure" lemma="measure" stem="measur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="success" lemma="success" stem="success" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (NNP Elvis)) (VP (VBD was) (NP (NP (PRP$ his) (NN measure)) (PP (IN of) (NP (NN success)))))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Goldman)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his measure" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="measure" />
          </tokens>
        </chunking>
        <chunking id="2" string="Elvis" type="NP">
          <tokens>
            <token id="1" string="Elvis" />
          </tokens>
        </chunking>
        <chunking id="3" string="success" type="NP">
          <tokens>
            <token id="6" string="success" />
          </tokens>
        </chunking>
        <chunking id="4" string="his measure of success" type="NP">
          <tokens>
            <token id="3" string="his" />
            <token id="4" string="measure" />
            <token id="5" string="of" />
            <token id="6" string="success" />
          </tokens>
        </chunking>
        <chunking id="5" string="was his measure of success" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="his" />
            <token id="4" string="measure" />
            <token id="5" string="of" />
            <token id="6" string="success" />
          </tokens>
        </chunking>
        <chunking id="6" string="Goldman" type="NP">
          <tokens>
            <token id="10" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">measure</governor>
          <dependent id="1">Elvis</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">measure</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">measure</governor>
          <dependent id="3">his</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="4">measure</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">success</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">measure</governor>
          <dependent id="6">success</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="10">Goldman</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Elvis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Elvis" />
          </tokens>
        </entity>
        <entity id="2" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>``And the myth of Elvis: awesome.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="myth" lemma="myth" stem="myth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Elvis" lemma="Elvis" stem="elvi" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="awesome" lemma="awesome" stem="awesom" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (CC And) (ADVP (NP (DT the) (NN myth)) (IN of)) (NP (NNP Elvis)) (VP (: :) (ADJP (JJ awesome))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="awesome" type="ADJP">
          <tokens>
            <token id="8" string="awesome" />
          </tokens>
        </chunking>
        <chunking id="2" string=": awesome" type="VP">
          <tokens>
            <token id="7" string=":" />
            <token id="8" string="awesome" />
          </tokens>
        </chunking>
        <chunking id="3" string="Elvis" type="NP">
          <tokens>
            <token id="6" string="Elvis" />
          </tokens>
        </chunking>
        <chunking id="4" string="the myth" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="myth" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="8">awesome</governor>
          <dependent id="2">And</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">myth</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">awesome</governor>
          <dependent id="4">myth</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">myth</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">awesome</governor>
          <dependent id="6">Elvis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">awesome</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="22" has_coreference="false">
      <content>But the reality of Elvis: a mess.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="reality" lemma="reality" stem="realiti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Elvis" lemma="Elvis" stem="elvi" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="mess" lemma="mess" stem="mess" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (ADVP (CC But)) (DT the) (NN reality)) (PP (IN of) (NP (NP (NNP Elvis)) (: :) (NP (DT a) (NN mess)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Elvis : a mess" type="NP">
          <tokens>
            <token id="5" string="Elvis" />
            <token id="6" string=":" />
            <token id="7" string="a" />
            <token id="8" string="mess" />
          </tokens>
        </chunking>
        <chunking id="2" string="But the reality" type="NP">
          <tokens>
            <token id="1" string="But" />
            <token id="2" string="the" />
            <token id="3" string="reality" />
          </tokens>
        </chunking>
        <chunking id="3" string="Elvis" type="NP">
          <tokens>
            <token id="5" string="Elvis" />
          </tokens>
        </chunking>
        <chunking id="4" string="a mess" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="mess" />
          </tokens>
        </chunking>
        <chunking id="5" string="But the reality of Elvis : a mess . ''" type="NP">
          <tokens>
            <token id="1" string="But" />
            <token id="2" string="the" />
            <token id="3" string="reality" />
            <token id="4" string="of" />
            <token id="5" string="Elvis" />
            <token id="6" string=":" />
            <token id="7" string="a" />
            <token id="8" string="mess" />
            <token id="9" string="." />
            <token id="10" string="''" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="3">reality</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">reality</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">reality</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Elvis</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">reality</governor>
          <dependent id="5">Elvis</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">mess</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">Elvis</governor>
          <dependent id="8">mess</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>Goldman also rejected the complaint raised by Ono, McCartney, Julian Lennon and others that Lennon is an easy target to defame because he&amp;apost;s no longer around to answer the allegations.</content>
      <tokens>
        <token id="1" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="2" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="rejected" lemma="reject" stem="reject" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="complaint" lemma="complaint" stem="complaint" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="raised" lemma="raise" stem="rais" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="McCartney" lemma="McCartney" stem="mccartnei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Julian" lemma="Julian" stem="julian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="easy" lemma="easy" stem="easi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="target" lemma="target" stem="target" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="defame" lemma="defame" stem="defam" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="longer" lemma="longer" stem="longer" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="around" lemma="around" stem="around" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="answer" lemma="answer" stem="answer" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Goldman)) (ADVP (RB also)) (VP (VBD rejected) (NP (NP (DT the) (NN complaint)) (VP (VBN raised) (PP (IN by) (NP (NP (NNP Ono)) (, ,) (NP (NNP McCartney)) (, ,) (NP (NNP Julian) (NNP Lennon)) (CC and) (NP (NNS others))))) (SBAR (WHNP (WDT that)) (S (NP (NNP Lennon)) (VP (VBZ is) (NP (DT an) (JJ easy) (NN target) (S (VP (TO to) (VP (VB defame) (SBAR (IN because) (S (NP (PRP he)) (VP (VBZ 's) (ADVP (RB no) (RB longer)) (VP (IN around) (S (VP (TO to) (VP (VB answer) (NP (DT the) (NNS allegations)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the complaint raised by Ono , McCartney , Julian Lennon and others that Lennon is an easy target to defame because he 's no longer around to answer the allegations" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="complaint" />
            <token id="6" string="raised" />
            <token id="7" string="by" />
            <token id="8" string="Ono" />
            <token id="9" string="," />
            <token id="10" string="McCartney" />
            <token id="11" string="," />
            <token id="12" string="Julian" />
            <token id="13" string="Lennon" />
            <token id="14" string="and" />
            <token id="15" string="others" />
            <token id="16" string="that" />
            <token id="17" string="Lennon" />
            <token id="18" string="is" />
            <token id="19" string="an" />
            <token id="20" string="easy" />
            <token id="21" string="target" />
            <token id="22" string="to" />
            <token id="23" string="defame" />
            <token id="24" string="because" />
            <token id="25" string="he" />
            <token id="26" string="'s" />
            <token id="27" string="no" />
            <token id="28" string="longer" />
            <token id="29" string="around" />
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="2" string="Lennon" type="NP">
          <tokens>
            <token id="17" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="3" string="McCartney" type="NP">
          <tokens>
            <token id="10" string="McCartney" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s no longer around to answer the allegations" type="VP">
          <tokens>
            <token id="26" string="'s" />
            <token id="27" string="no" />
            <token id="28" string="longer" />
            <token id="29" string="around" />
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="5" string="the complaint" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="complaint" />
          </tokens>
        </chunking>
        <chunking id="6" string="because he 's no longer around to answer the allegations" type="SBAR">
          <tokens>
            <token id="24" string="because" />
            <token id="25" string="he" />
            <token id="26" string="'s" />
            <token id="27" string="no" />
            <token id="28" string="longer" />
            <token id="29" string="around" />
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="7" string="to answer the allegations" type="VP">
          <tokens>
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ono" type="NP">
          <tokens>
            <token id="8" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="9" string="rejected the complaint raised by Ono , McCartney , Julian Lennon and others that Lennon is an easy target to defame because he 's no longer around to answer the allegations" type="VP">
          <tokens>
            <token id="3" string="rejected" />
            <token id="4" string="the" />
            <token id="5" string="complaint" />
            <token id="6" string="raised" />
            <token id="7" string="by" />
            <token id="8" string="Ono" />
            <token id="9" string="," />
            <token id="10" string="McCartney" />
            <token id="11" string="," />
            <token id="12" string="Julian" />
            <token id="13" string="Lennon" />
            <token id="14" string="and" />
            <token id="15" string="others" />
            <token id="16" string="that" />
            <token id="17" string="Lennon" />
            <token id="18" string="is" />
            <token id="19" string="an" />
            <token id="20" string="easy" />
            <token id="21" string="target" />
            <token id="22" string="to" />
            <token id="23" string="defame" />
            <token id="24" string="because" />
            <token id="25" string="he" />
            <token id="26" string="'s" />
            <token id="27" string="no" />
            <token id="28" string="longer" />
            <token id="29" string="around" />
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="10" string="raised by Ono , McCartney , Julian Lennon and others" type="VP">
          <tokens>
            <token id="6" string="raised" />
            <token id="7" string="by" />
            <token id="8" string="Ono" />
            <token id="9" string="," />
            <token id="10" string="McCartney" />
            <token id="11" string="," />
            <token id="12" string="Julian" />
            <token id="13" string="Lennon" />
            <token id="14" string="and" />
            <token id="15" string="others" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ono , McCartney , Julian Lennon and others" type="NP">
          <tokens>
            <token id="8" string="Ono" />
            <token id="9" string="," />
            <token id="10" string="McCartney" />
            <token id="11" string="," />
            <token id="12" string="Julian" />
            <token id="13" string="Lennon" />
            <token id="14" string="and" />
            <token id="15" string="others" />
          </tokens>
        </chunking>
        <chunking id="12" string="an easy target to defame because he 's no longer around to answer the allegations" type="NP">
          <tokens>
            <token id="19" string="an" />
            <token id="20" string="easy" />
            <token id="21" string="target" />
            <token id="22" string="to" />
            <token id="23" string="defame" />
            <token id="24" string="because" />
            <token id="25" string="he" />
            <token id="26" string="'s" />
            <token id="27" string="no" />
            <token id="28" string="longer" />
            <token id="29" string="around" />
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="13" string="the allegations" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="14" string="defame because he 's no longer around to answer the allegations" type="VP">
          <tokens>
            <token id="23" string="defame" />
            <token id="24" string="because" />
            <token id="25" string="he" />
            <token id="26" string="'s" />
            <token id="27" string="no" />
            <token id="28" string="longer" />
            <token id="29" string="around" />
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="15" string="that Lennon is an easy target to defame because he 's no longer around to answer the allegations" type="SBAR">
          <tokens>
            <token id="16" string="that" />
            <token id="17" string="Lennon" />
            <token id="18" string="is" />
            <token id="19" string="an" />
            <token id="20" string="easy" />
            <token id="21" string="target" />
            <token id="22" string="to" />
            <token id="23" string="defame" />
            <token id="24" string="because" />
            <token id="25" string="he" />
            <token id="26" string="'s" />
            <token id="27" string="no" />
            <token id="28" string="longer" />
            <token id="29" string="around" />
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="16" string="answer the allegations" type="VP">
          <tokens>
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="17" string="is an easy target to defame because he 's no longer around to answer the allegations" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="an" />
            <token id="20" string="easy" />
            <token id="21" string="target" />
            <token id="22" string="to" />
            <token id="23" string="defame" />
            <token id="24" string="because" />
            <token id="25" string="he" />
            <token id="26" string="'s" />
            <token id="27" string="no" />
            <token id="28" string="longer" />
            <token id="29" string="around" />
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="18" string="Julian Lennon" type="NP">
          <tokens>
            <token id="12" string="Julian" />
            <token id="13" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="19" string="to defame because he 's no longer around to answer the allegations" type="VP">
          <tokens>
            <token id="22" string="to" />
            <token id="23" string="defame" />
            <token id="24" string="because" />
            <token id="25" string="he" />
            <token id="26" string="'s" />
            <token id="27" string="no" />
            <token id="28" string="longer" />
            <token id="29" string="around" />
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="20" string="around to answer the allegations" type="VP">
          <tokens>
            <token id="29" string="around" />
            <token id="30" string="to" />
            <token id="31" string="answer" />
            <token id="32" string="the" />
            <token id="33" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="21" string="Goldman" type="NP">
          <tokens>
            <token id="1" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="22" string="he" type="NP">
          <tokens>
            <token id="25" string="he" />
          </tokens>
        </chunking>
        <chunking id="23" string="others" type="NP">
          <tokens>
            <token id="15" string="others" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">rejected</governor>
          <dependent id="1">Goldman</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">rejected</governor>
          <dependent id="2">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">rejected</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">complaint</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">rejected</governor>
          <dependent id="5">complaint</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="5">complaint</governor>
          <dependent id="6">raised</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Ono</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">raised</governor>
          <dependent id="8">Ono</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Ono</governor>
          <dependent id="10">McCartney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Lennon</governor>
          <dependent id="12">Julian</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Ono</governor>
          <dependent id="13">Lennon</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Ono</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Ono</governor>
          <dependent id="15">others</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">target</governor>
          <dependent id="16">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">target</governor>
          <dependent id="17">Lennon</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">target</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">target</governor>
          <dependent id="19">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">target</governor>
          <dependent id="20">easy</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">complaint</governor>
          <dependent id="21">target</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">defame</governor>
          <dependent id="22">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">target</governor>
          <dependent id="23">defame</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">around</governor>
          <dependent id="24">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">around</governor>
          <dependent id="25">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">around</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="28">longer</governor>
          <dependent id="27">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">around</governor>
          <dependent id="28">longer</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">defame</governor>
          <dependent id="29">around</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">answer</governor>
          <dependent id="30">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">around</governor>
          <dependent id="31">answer</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">allegations</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">answer</governor>
          <dependent id="33">allegations</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="McCartney" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="McCartney" />
          </tokens>
        </entity>
        <entity id="3" string="Julian Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Julian" />
            <token id="13" string="Lennon" />
          </tokens>
        </entity>
        <entity id="4" string="Goldman" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Goldman" />
          </tokens>
        </entity>
        <entity id="5" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>``You can&amp;apost;t say John lacks for defenders.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="lacks" lemma="lack" stem="lack" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="defenders" lemma="defender" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP You)) (VP (MD ca) (RB n't) (VP (VB say) (SBAR (S (NP (NNP John)) (VP (VBZ lacks) (PP (IN for) (NP (NNS defenders)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="lacks for defenders" type="VP">
          <tokens>
            <token id="7" string="lacks" />
            <token id="8" string="for" />
            <token id="9" string="defenders" />
          </tokens>
        </chunking>
        <chunking id="2" string="say John lacks for defenders" type="VP">
          <tokens>
            <token id="5" string="say" />
            <token id="6" string="John" />
            <token id="7" string="lacks" />
            <token id="8" string="for" />
            <token id="9" string="defenders" />
          </tokens>
        </chunking>
        <chunking id="3" string="John lacks for defenders" type="SBAR">
          <tokens>
            <token id="6" string="John" />
            <token id="7" string="lacks" />
            <token id="8" string="for" />
            <token id="9" string="defenders" />
          </tokens>
        </chunking>
        <chunking id="4" string="John" type="NP">
          <tokens>
            <token id="6" string="John" />
          </tokens>
        </chunking>
        <chunking id="5" string="defenders" type="NP">
          <tokens>
            <token id="9" string="defenders" />
          </tokens>
        </chunking>
        <chunking id="6" string="ca n't say John lacks for defenders" type="VP">
          <tokens>
            <token id="3" string="ca" />
            <token id="4" string="n't" />
            <token id="5" string="say" />
            <token id="6" string="John" />
            <token id="7" string="lacks" />
            <token id="8" string="for" />
            <token id="9" string="defenders" />
          </tokens>
        </chunking>
        <chunking id="7" string="You" type="NP">
          <tokens>
            <token id="2" string="You" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">say</governor>
          <dependent id="2">You</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">say</governor>
          <dependent id="3">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">say</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">say</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">lacks</governor>
          <dependent id="6">John</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">say</governor>
          <dependent id="7">lacks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">defenders</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">lacks</governor>
          <dependent id="9">defenders</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="John" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>And Yoko isn&amp;apost;t dead.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (NNP Yoko)) (VP (VBZ is) (RB n't) (ADJP (JJ dead))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Yoko" type="NP">
          <tokens>
            <token id="2" string="Yoko" />
          </tokens>
        </chunking>
        <chunking id="2" string="dead" type="ADJP">
          <tokens>
            <token id="5" string="dead" />
          </tokens>
        </chunking>
        <chunking id="3" string="is n't dead" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="n't" />
            <token id="5" string="dead" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="5">dead</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">dead</governor>
          <dependent id="2">Yoko</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">dead</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">dead</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">dead</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Yoko" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Yoko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Colonel Parker (Presley&amp;apost;s manager) isn&amp;apost;t dead.</content>
      <tokens>
        <token id="1" string="Colonel" lemma="Colonel" stem="colonel" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Parker" lemma="Parker" stem="parker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Presley" lemma="Presley" stem="preslei" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="manager" lemma="manager" stem="manag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Colonel) (NNP Parker)) (PRN (-LRB- -LRB-) (NP (NP (NNP Presley) (POS 's)) (NN manager)) (-RRB- -RRB-))) (VP (VBZ is) (RB n't) (ADJP (JJ dead))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Presley 's" type="NP">
          <tokens>
            <token id="4" string="Presley" />
            <token id="5" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="Colonel Parker" type="NP">
          <tokens>
            <token id="1" string="Colonel" />
            <token id="2" string="Parker" />
          </tokens>
        </chunking>
        <chunking id="3" string="Presley 's manager" type="NP">
          <tokens>
            <token id="4" string="Presley" />
            <token id="5" string="'s" />
            <token id="6" string="manager" />
          </tokens>
        </chunking>
        <chunking id="4" string="dead" type="ADJP">
          <tokens>
            <token id="10" string="dead" />
          </tokens>
        </chunking>
        <chunking id="5" string="Colonel Parker -LRB- Presley 's manager -RRB-" type="NP">
          <tokens>
            <token id="1" string="Colonel" />
            <token id="2" string="Parker" />
            <token id="3" string="(" />
            <token id="4" string="Presley" />
            <token id="5" string="'s" />
            <token id="6" string="manager" />
            <token id="7" string=")" />
          </tokens>
        </chunking>
        <chunking id="6" string="is n't dead" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="n't" />
            <token id="10" string="dead" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Parker</governor>
          <dependent id="1">Colonel</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">dead</governor>
          <dependent id="2">Parker</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">manager</governor>
          <dependent id="4">Presley</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Presley</governor>
          <dependent id="5">'s</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Parker</governor>
          <dependent id="6">manager</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">dead</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">dead</governor>
          <dependent id="9">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">dead</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Parker" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Parker" />
          </tokens>
        </entity>
        <entity id="2" string="Presley" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Presley" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Ninety-five percent of the people in my books aren&amp;apost;t dead.</content>
      <tokens>
        <token id="1" string="Ninety-five" lemma="ninety-five" stem="ninety-f" pos="JJ" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="2" string="percent" lemma="percent" stem="percent" pos="NN" type="Word" isStopWord="false" ner="PERCENT" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="dead" lemma="dead" stem="dead" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (JJ Ninety-five) (NN percent)) (PP (IN of) (NP (NP (DT the) (NNS people)) (PP (IN in) (NP (PRP$ my) (NNS books)))))) (VP (VBP are) (RB n't) (ADJP (JJ dead))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the people in my books" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="people" />
            <token id="6" string="in" />
            <token id="7" string="my" />
            <token id="8" string="books" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ninety-five percent" type="NP">
          <tokens>
            <token id="1" string="Ninety-five" />
            <token id="2" string="percent" />
          </tokens>
        </chunking>
        <chunking id="3" string="my books" type="NP">
          <tokens>
            <token id="7" string="my" />
            <token id="8" string="books" />
          </tokens>
        </chunking>
        <chunking id="4" string="are n't dead" type="VP">
          <tokens>
            <token id="9" string="are" />
            <token id="10" string="n't" />
            <token id="11" string="dead" />
          </tokens>
        </chunking>
        <chunking id="5" string="Ninety-five percent of the people in my books" type="NP">
          <tokens>
            <token id="1" string="Ninety-five" />
            <token id="2" string="percent" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="people" />
            <token id="6" string="in" />
            <token id="7" string="my" />
            <token id="8" string="books" />
          </tokens>
        </chunking>
        <chunking id="6" string="the people" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="dead" type="ADJP">
          <tokens>
            <token id="11" string="dead" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">percent</governor>
          <dependent id="1">Ninety-five</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">dead</governor>
          <dependent id="2">percent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">people</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">people</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">percent</governor>
          <dependent id="5">people</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">books</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">books</governor>
          <dependent id="7">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">people</governor>
          <dependent id="8">books</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">dead</governor>
          <dependent id="9">are</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">dead</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">dead</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ninety-five percent" type="PERCENT" score="0.0">
          <tokens>
            <token id="1" string="Ninety-five" />
            <token id="2" string="percent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>They can do something about it,&amp;apost;&amp;apost; said Goldman, his voice quickening.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="something" lemma="something" stem="someth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="voice" lemma="voice" stem="voic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="14" string="quickening" lemma="quicken" stem="quicken" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (PRP They)) (VP (MD can) (VP (VB do) (NP (NN something)) (PP (IN about) (NP (PRP it)))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Goldman)) (, ,) (NP (NP (PRP$ his) (NN voice)) (VP (VBG quickening)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="his voice" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="voice" />
          </tokens>
        </chunking>
        <chunking id="3" string="can do something about it" type="VP">
          <tokens>
            <token id="2" string="can" />
            <token id="3" string="do" />
            <token id="4" string="something" />
            <token id="5" string="about" />
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="his voice quickening" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="voice" />
            <token id="14" string="quickening" />
          </tokens>
        </chunking>
        <chunking id="5" string="quickening" type="VP">
          <tokens>
            <token id="14" string="quickening" />
          </tokens>
        </chunking>
        <chunking id="6" string="Goldman , his voice quickening" type="NP">
          <tokens>
            <token id="10" string="Goldman" />
            <token id="11" string="," />
            <token id="12" string="his" />
            <token id="13" string="voice" />
            <token id="14" string="quickening" />
          </tokens>
        </chunking>
        <chunking id="7" string="do something about it" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="something" />
            <token id="5" string="about" />
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="Goldman" type="NP">
          <tokens>
            <token id="10" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="10" string="something" type="NP">
          <tokens>
            <token id="4" string="something" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">do</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">do</governor>
          <dependent id="2">can</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">do</governor>
          <dependent id="4">something</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">it</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">do</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="10">Goldman</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">voice</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">Goldman</governor>
          <dependent id="13">voice</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">voice</governor>
          <dependent id="14">quickening</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>``This business of making it easy for defending myself is insane.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="business" lemma="business" stem="busi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="easy" lemma="easy" stem="easi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="defending" lemma="defend" stem="defend" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="myself" lemma="myself" stem="myself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="insane" lemma="insane" stem="insan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (DT This) (NN business)) (PP (IN of) (S (VP (VBG making) (S (NP (PRP it)) (ADJP (JJ easy) (PP (IN for) (S (VP (VBG defending) (NP (PRP myself))))))))))) (VP (VBZ is) (ADJP (JJ insane))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="making it easy for defending myself" type="VP">
          <tokens>
            <token id="5" string="making" />
            <token id="6" string="it" />
            <token id="7" string="easy" />
            <token id="8" string="for" />
            <token id="9" string="defending" />
            <token id="10" string="myself" />
          </tokens>
        </chunking>
        <chunking id="2" string="This business of making it easy for defending myself" type="NP">
          <tokens>
            <token id="2" string="This" />
            <token id="3" string="business" />
            <token id="4" string="of" />
            <token id="5" string="making" />
            <token id="6" string="it" />
            <token id="7" string="easy" />
            <token id="8" string="for" />
            <token id="9" string="defending" />
            <token id="10" string="myself" />
          </tokens>
        </chunking>
        <chunking id="3" string="This business" type="NP">
          <tokens>
            <token id="2" string="This" />
            <token id="3" string="business" />
          </tokens>
        </chunking>
        <chunking id="4" string="defending myself" type="VP">
          <tokens>
            <token id="9" string="defending" />
            <token id="10" string="myself" />
          </tokens>
        </chunking>
        <chunking id="5" string="myself" type="NP">
          <tokens>
            <token id="10" string="myself" />
          </tokens>
        </chunking>
        <chunking id="6" string="insane" type="ADJP">
          <tokens>
            <token id="12" string="insane" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="easy for defending myself" type="ADJP">
          <tokens>
            <token id="7" string="easy" />
            <token id="8" string="for" />
            <token id="9" string="defending" />
            <token id="10" string="myself" />
          </tokens>
        </chunking>
        <chunking id="9" string="is insane" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="insane" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">business</governor>
          <dependent id="2">This</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">insane</governor>
          <dependent id="3">business</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">making</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">business</governor>
          <dependent id="5">making</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">easy</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="5">making</governor>
          <dependent id="7">easy</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">defending</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">easy</governor>
          <dependent id="9">defending</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">defending</governor>
          <dependent id="10">myself</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">insane</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">insane</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>I&amp;apost;m the target of scores of attacks.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="target" lemma="target" stem="target" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="scores" lemma="score" stem="score" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="attacks" lemma="attack" stem="attack" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="true" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP 'm) (NP (NP (DT the) (NN target)) (PP (IN of) (NP (NP (NNS scores)) (PP (IN of) (NP (NNS attacks))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="'m the target of scores of attacks" type="VP">
          <tokens>
            <token id="2" string="'m" />
            <token id="3" string="the" />
            <token id="4" string="target" />
            <token id="5" string="of" />
            <token id="6" string="scores" />
            <token id="7" string="of" />
            <token id="8" string="attacks" />
          </tokens>
        </chunking>
        <chunking id="2" string="the target of scores of attacks" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="target" />
            <token id="5" string="of" />
            <token id="6" string="scores" />
            <token id="7" string="of" />
            <token id="8" string="attacks" />
          </tokens>
        </chunking>
        <chunking id="3" string="scores of attacks" type="NP">
          <tokens>
            <token id="6" string="scores" />
            <token id="7" string="of" />
            <token id="8" string="attacks" />
          </tokens>
        </chunking>
        <chunking id="4" string="scores" type="NP">
          <tokens>
            <token id="6" string="scores" />
          </tokens>
        </chunking>
        <chunking id="5" string="attacks" type="NP">
          <tokens>
            <token id="8" string="attacks" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="the target" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="target" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">target</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">target</governor>
          <dependent id="2">'m</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">target</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">target</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">scores</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">target</governor>
          <dependent id="6">scores</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">attacks</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">scores</governor>
          <dependent id="8">attacks</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="attacks" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="8" string="attacks" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>I can&amp;apost;t imagine a harder thing for an author.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="ca" lemma="can" stem="ca" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="imagine" lemma="imagine" stem="imagin" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="harder" lemma="harder" stem="harder" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (MD ca) (RB n't) (VP (VB imagine) (NP (DT a) (JJR harder) (NN thing)) (PP (IN for) (NP (DT an) (NN author))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="2" string="a harder thing" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="harder" />
            <token id="7" string="thing" />
          </tokens>
        </chunking>
        <chunking id="3" string="an author" type="NP">
          <tokens>
            <token id="9" string="an" />
            <token id="10" string="author" />
          </tokens>
        </chunking>
        <chunking id="4" string="ca n't imagine a harder thing for an author" type="VP">
          <tokens>
            <token id="2" string="ca" />
            <token id="3" string="n't" />
            <token id="4" string="imagine" />
            <token id="5" string="a" />
            <token id="6" string="harder" />
            <token id="7" string="thing" />
            <token id="8" string="for" />
            <token id="9" string="an" />
            <token id="10" string="author" />
          </tokens>
        </chunking>
        <chunking id="5" string="imagine a harder thing for an author" type="VP">
          <tokens>
            <token id="4" string="imagine" />
            <token id="5" string="a" />
            <token id="6" string="harder" />
            <token id="7" string="thing" />
            <token id="8" string="for" />
            <token id="9" string="an" />
            <token id="10" string="author" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">imagine</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">imagine</governor>
          <dependent id="2">ca</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">imagine</governor>
          <dependent id="3">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">imagine</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">thing</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">thing</governor>
          <dependent id="6">harder</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">imagine</governor>
          <dependent id="7">thing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">author</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">author</governor>
          <dependent id="9">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">imagine</governor>
          <dependent id="10">author</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>Those attacks don&amp;apost;t really bother him, unless they come from someone who hasn&amp;apost;t read ``The Lives of John Lennon,&amp;apost;&amp;apost; Goldman said.</content>
      <tokens>
        <token id="1" string="Those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="attacks" lemma="attack" stem="attack" pos="NNS" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="true" is_refers="false" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="bother" lemma="bother" stem="bother" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="unless" lemma="unless" stem="unless" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="come" lemma="come" stem="come" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="someone" lemma="someone" stem="someon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="read" lemma="read" stem="read" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="27" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT Those) (NNS attacks)) (VP (VBP do) (RB n't) (ADVP (RB really)) (VP (VB bother) (NP (PRP him)) (, ,) (SBAR (IN unless) (S (NP (PRP they)) (VP (VBP come) (PP (IN from) (NP (NP (NN someone)) (SBAR (WHNP (WP who)) (S (VP (VBZ has) (RB n't) (VP (VB read) (`` ``) (NP (NP (DT The) (NNS Lives)) (PP (IN of) (NP (NNP John) (NNP Lennon)))))))))))))))) (, ,) ('' '') (NP (NNP Goldman)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Those attacks" type="NP">
          <tokens>
            <token id="1" string="Those" />
            <token id="2" string="attacks" />
          </tokens>
        </chunking>
        <chunking id="2" string="has n't read `` The Lives of John Lennon" type="VP">
          <tokens>
            <token id="15" string="has" />
            <token id="16" string="n't" />
            <token id="17" string="read" />
            <token id="18" string="``" />
            <token id="19" string="The" />
            <token id="20" string="Lives" />
            <token id="21" string="of" />
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="3" string="read `` The Lives of John Lennon" type="VP">
          <tokens>
            <token id="17" string="read" />
            <token id="18" string="``" />
            <token id="19" string="The" />
            <token id="20" string="Lives" />
            <token id="21" string="of" />
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="4" string="The Lives" type="NP">
          <tokens>
            <token id="19" string="The" />
            <token id="20" string="Lives" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="7" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="someone who has n't read `` The Lives of John Lennon" type="NP">
          <tokens>
            <token id="13" string="someone" />
            <token id="14" string="who" />
            <token id="15" string="has" />
            <token id="16" string="n't" />
            <token id="17" string="read" />
            <token id="18" string="``" />
            <token id="19" string="The" />
            <token id="20" string="Lives" />
            <token id="21" string="of" />
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="7" string="come from someone who has n't read `` The Lives of John Lennon" type="VP">
          <tokens>
            <token id="11" string="come" />
            <token id="12" string="from" />
            <token id="13" string="someone" />
            <token id="14" string="who" />
            <token id="15" string="has" />
            <token id="16" string="n't" />
            <token id="17" string="read" />
            <token id="18" string="``" />
            <token id="19" string="The" />
            <token id="20" string="Lives" />
            <token id="21" string="of" />
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="8" string="bother him , unless they come from someone who has n't read `` The Lives of John Lennon" type="VP">
          <tokens>
            <token id="6" string="bother" />
            <token id="7" string="him" />
            <token id="8" string="," />
            <token id="9" string="unless" />
            <token id="10" string="they" />
            <token id="11" string="come" />
            <token id="12" string="from" />
            <token id="13" string="someone" />
            <token id="14" string="who" />
            <token id="15" string="has" />
            <token id="16" string="n't" />
            <token id="17" string="read" />
            <token id="18" string="``" />
            <token id="19" string="The" />
            <token id="20" string="Lives" />
            <token id="21" string="of" />
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="9" string="John Lennon" type="NP">
          <tokens>
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="10" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="The Lives of John Lennon" type="NP">
          <tokens>
            <token id="19" string="The" />
            <token id="20" string="Lives" />
            <token id="21" string="of" />
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="12" string="someone" type="NP">
          <tokens>
            <token id="13" string="someone" />
          </tokens>
        </chunking>
        <chunking id="13" string="unless they come from someone who has n't read `` The Lives of John Lennon" type="SBAR">
          <tokens>
            <token id="9" string="unless" />
            <token id="10" string="they" />
            <token id="11" string="come" />
            <token id="12" string="from" />
            <token id="13" string="someone" />
            <token id="14" string="who" />
            <token id="15" string="has" />
            <token id="16" string="n't" />
            <token id="17" string="read" />
            <token id="18" string="``" />
            <token id="19" string="The" />
            <token id="20" string="Lives" />
            <token id="21" string="of" />
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="14" string="Goldman" type="NP">
          <tokens>
            <token id="26" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="15" string="said" type="VP">
          <tokens>
            <token id="27" string="said" />
          </tokens>
        </chunking>
        <chunking id="16" string="who has n't read `` The Lives of John Lennon" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="has" />
            <token id="16" string="n't" />
            <token id="17" string="read" />
            <token id="18" string="``" />
            <token id="19" string="The" />
            <token id="20" string="Lives" />
            <token id="21" string="of" />
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="17" string="do n't really bother him , unless they come from someone who has n't read `` The Lives of John Lennon" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="really" />
            <token id="6" string="bother" />
            <token id="7" string="him" />
            <token id="8" string="," />
            <token id="9" string="unless" />
            <token id="10" string="they" />
            <token id="11" string="come" />
            <token id="12" string="from" />
            <token id="13" string="someone" />
            <token id="14" string="who" />
            <token id="15" string="has" />
            <token id="16" string="n't" />
            <token id="17" string="read" />
            <token id="18" string="``" />
            <token id="19" string="The" />
            <token id="20" string="Lives" />
            <token id="21" string="of" />
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">attacks</governor>
          <dependent id="1">Those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">bother</governor>
          <dependent id="2">attacks</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">bother</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">bother</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">bother</governor>
          <dependent id="5">really</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="27">said</governor>
          <dependent id="6">bother</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">bother</governor>
          <dependent id="7">him</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">come</governor>
          <dependent id="9">unless</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">come</governor>
          <dependent id="10">they</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">bother</governor>
          <dependent id="11">come</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">someone</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">come</governor>
          <dependent id="13">someone</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">read</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">read</governor>
          <dependent id="15">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">read</governor>
          <dependent id="16">n't</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">someone</governor>
          <dependent id="17">read</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Lives</governor>
          <dependent id="19">The</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">read</governor>
          <dependent id="20">Lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Lennon</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Lennon</governor>
          <dependent id="22">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">Lives</governor>
          <dependent id="23">Lennon</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">said</governor>
          <dependent id="26">Goldman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="27">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="John" />
            <token id="23" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="attacks" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="2" string="attacks" />
          </tokens>
        </entity>
        <entity id="3" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="26" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>``A lot of people already made up their minds.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="lot" lemma="lot" stem="lot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="already" lemma="already" stem="alreadi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="up" lemma="up" stem="up" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="minds" lemma="mind" stem="mind" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NP (DT A) (NN lot)) (PP (IN of) (NP (NNS people)))) (ADVP (RB already)) (VP (VBD made) (PRT (RP up)) (NP (PRP$ their) (NNS minds))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A lot of people" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="lot" />
            <token id="4" string="of" />
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="made up their minds" type="VP">
          <tokens>
            <token id="7" string="made" />
            <token id="8" string="up" />
            <token id="9" string="their" />
            <token id="10" string="minds" />
          </tokens>
        </chunking>
        <chunking id="3" string="A lot" type="NP">
          <tokens>
            <token id="2" string="A" />
            <token id="3" string="lot" />
          </tokens>
        </chunking>
        <chunking id="4" string="people" type="NP">
          <tokens>
            <token id="5" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="their minds" type="NP">
          <tokens>
            <token id="9" string="their" />
            <token id="10" string="minds" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">lot</governor>
          <dependent id="2">A</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">made</governor>
          <dependent id="3">lot</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">people</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">lot</governor>
          <dependent id="5">people</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">made</governor>
          <dependent id="6">already</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">made</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="7">made</governor>
          <dependent id="8">up</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">minds</governor>
          <dependent id="9">their</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">made</governor>
          <dependent id="10">minds</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>They hear Albert Goldman, John Lennon, homosexuality _ bang, let him have it!</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="hear" lemma="hear" stem="hear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Albert" lemma="Albert" stem="albert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="homosexuality" lemma="homosexuality" stem="homosexu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="10" string="_" lemma="_" stem="_" pos="CD" type="Symbol" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="true" />
        <token id="11" string="bang" lemma="bang" stem="bang" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="!" lemma="!" stem="!" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP hear) (S (NP (NP (NNP Albert) (NNP Goldman)) (, ,) (NP (NP (NNP John) (NNP Lennon)) (, ,) (NP (NN homosexuality) (CD _) (NN bang))) (, ,)) (VP (VB let) (S (NP (PRP him)) (VP (VB have) (NP (PRP it))))))) (. !)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="John Lennon" type="NP">
          <tokens>
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="3" string="hear Albert Goldman , John Lennon , homosexuality _ bang , let him have it" type="VP">
          <tokens>
            <token id="2" string="hear" />
            <token id="3" string="Albert" />
            <token id="4" string="Goldman" />
            <token id="5" string="," />
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
            <token id="8" string="," />
            <token id="9" string="homosexuality" />
            <token id="10" string="_" />
            <token id="11" string="bang" />
            <token id="12" string="," />
            <token id="13" string="let" />
            <token id="14" string="him" />
            <token id="15" string="have" />
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="4" string="Albert Goldman , John Lennon , homosexuality _ bang ," type="NP">
          <tokens>
            <token id="3" string="Albert" />
            <token id="4" string="Goldman" />
            <token id="5" string="," />
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
            <token id="8" string="," />
            <token id="9" string="homosexuality" />
            <token id="10" string="_" />
            <token id="11" string="bang" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="John Lennon , homosexuality _ bang" type="NP">
          <tokens>
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
            <token id="8" string="," />
            <token id="9" string="homosexuality" />
            <token id="10" string="_" />
            <token id="11" string="bang" />
          </tokens>
        </chunking>
        <chunking id="6" string="let him have it" type="VP">
          <tokens>
            <token id="13" string="let" />
            <token id="14" string="him" />
            <token id="15" string="have" />
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="have it" type="VP">
          <tokens>
            <token id="15" string="have" />
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="him" type="NP">
          <tokens>
            <token id="14" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="it" type="NP">
          <tokens>
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="10" string="Albert Goldman" type="NP">
          <tokens>
            <token id="3" string="Albert" />
            <token id="4" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="11" string="homosexuality _ bang" type="NP">
          <tokens>
            <token id="9" string="homosexuality" />
            <token id="10" string="_" />
            <token id="11" string="bang" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">hear</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">hear</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">Goldman</governor>
          <dependent id="3">Albert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">let</governor>
          <dependent id="4">Goldman</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Lennon</governor>
          <dependent id="6">John</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="4">Goldman</governor>
          <dependent id="7">Lennon</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">bang</governor>
          <dependent id="9">homosexuality</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">bang</governor>
          <dependent id="10">_</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">Lennon</governor>
          <dependent id="11">bang</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">hear</governor>
          <dependent id="13">let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">have</governor>
          <dependent id="14">him</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">let</governor>
          <dependent id="15">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">have</governor>
          <dependent id="16">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="John" />
            <token id="7" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Albert Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Albert" />
            <token id="4" string="Goldman" />
          </tokens>
        </entity>
        <entity id="3" string="_" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="_" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>I resent people commenting on a book they haven&amp;apost;t read, including Yoko,&amp;apost;&amp;apost; the author said.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="resent" lemma="resent" stem="resent" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="commenting" lemma="comment" stem="comment" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="read" lemma="read" stem="read" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP I)) (VP (VBP resent) (NP (NP (NNS people)) (VP (VBG commenting) (PP (IN on) (NP (NP (DT a) (NN book)) (SBAR (S (NP (PRP they)) (VP (VBP have) (RB n't) (VP (VB read))))) (, ,) (PP (VBG including) (NP (NNP Yoko))))))))) (, ,) ('' '') (NP (DT the) (NN author)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="read" type="VP">
          <tokens>
            <token id="11" string="read" />
          </tokens>
        </chunking>
        <chunking id="2" string="a book they have n't read , including Yoko" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="book" />
            <token id="8" string="they" />
            <token id="9" string="have" />
            <token id="10" string="n't" />
            <token id="11" string="read" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="Yoko" />
          </tokens>
        </chunking>
        <chunking id="3" string="the author" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="author" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="they have n't read" type="SBAR">
          <tokens>
            <token id="8" string="they" />
            <token id="9" string="have" />
            <token id="10" string="n't" />
            <token id="11" string="read" />
          </tokens>
        </chunking>
        <chunking id="6" string="have n't read" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="n't" />
            <token id="11" string="read" />
          </tokens>
        </chunking>
        <chunking id="7" string="people" type="NP">
          <tokens>
            <token id="3" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="resent people commenting on a book they have n't read , including Yoko" type="VP">
          <tokens>
            <token id="2" string="resent" />
            <token id="3" string="people" />
            <token id="4" string="commenting" />
            <token id="5" string="on" />
            <token id="6" string="a" />
            <token id="7" string="book" />
            <token id="8" string="they" />
            <token id="9" string="have" />
            <token id="10" string="n't" />
            <token id="11" string="read" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="Yoko" />
          </tokens>
        </chunking>
        <chunking id="9" string="a book" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="book" />
          </tokens>
        </chunking>
        <chunking id="10" string="they" type="NP">
          <tokens>
            <token id="8" string="they" />
          </tokens>
        </chunking>
        <chunking id="11" string="Yoko" type="NP">
          <tokens>
            <token id="14" string="Yoko" />
          </tokens>
        </chunking>
        <chunking id="12" string="people commenting on a book they have n't read , including Yoko" type="NP">
          <tokens>
            <token id="3" string="people" />
            <token id="4" string="commenting" />
            <token id="5" string="on" />
            <token id="6" string="a" />
            <token id="7" string="book" />
            <token id="8" string="they" />
            <token id="9" string="have" />
            <token id="10" string="n't" />
            <token id="11" string="read" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="Yoko" />
          </tokens>
        </chunking>
        <chunking id="13" string="commenting on a book they have n't read , including Yoko" type="VP">
          <tokens>
            <token id="4" string="commenting" />
            <token id="5" string="on" />
            <token id="6" string="a" />
            <token id="7" string="book" />
            <token id="8" string="they" />
            <token id="9" string="have" />
            <token id="10" string="n't" />
            <token id="11" string="read" />
            <token id="12" string="," />
            <token id="13" string="including" />
            <token id="14" string="Yoko" />
          </tokens>
        </chunking>
        <chunking id="14" string="said" type="VP">
          <tokens>
            <token id="19" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">resent</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">said</governor>
          <dependent id="2">resent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">resent</governor>
          <dependent id="3">people</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">people</governor>
          <dependent id="4">commenting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">book</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">book</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">commenting</governor>
          <dependent id="7">book</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">read</governor>
          <dependent id="8">they</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">read</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">read</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">book</governor>
          <dependent id="11">read</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Yoko</governor>
          <dependent id="13">including</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">book</governor>
          <dependent id="14">Yoko</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">author</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">said</governor>
          <dependent id="18">author</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Yoko" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Yoko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Ono&amp;apost;s reaction came on a nationally broadcast response to the book.</content>
      <tokens>
        <token id="1" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="reaction" lemma="reaction" stem="reaction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="came" lemma="come" stem="came" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="nationally" lemma="nationally" stem="nation" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="broadcast" lemma="broadcast" stem="broadcast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="response" lemma="response" stem="respons" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Ono) (POS 's)) (NN reaction)) (VP (VBD came) (PP (IN on) (NP (DT a) (ADJP (RB nationally) (NN broadcast)) (NN response))) (PP (TO to) (NP (DT the) (NN book)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Ono 's" type="NP">
          <tokens>
            <token id="1" string="Ono" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="Ono 's reaction" type="NP">
          <tokens>
            <token id="1" string="Ono" />
            <token id="2" string="'s" />
            <token id="3" string="reaction" />
          </tokens>
        </chunking>
        <chunking id="3" string="a nationally broadcast response" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="nationally" />
            <token id="8" string="broadcast" />
            <token id="9" string="response" />
          </tokens>
        </chunking>
        <chunking id="4" string="came on a nationally broadcast response to the book" type="VP">
          <tokens>
            <token id="4" string="came" />
            <token id="5" string="on" />
            <token id="6" string="a" />
            <token id="7" string="nationally" />
            <token id="8" string="broadcast" />
            <token id="9" string="response" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="book" />
          </tokens>
        </chunking>
        <chunking id="5" string="the book" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="book" />
          </tokens>
        </chunking>
        <chunking id="6" string="nationally broadcast" type="ADJP">
          <tokens>
            <token id="7" string="nationally" />
            <token id="8" string="broadcast" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">reaction</governor>
          <dependent id="1">Ono</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Ono</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">came</governor>
          <dependent id="3">reaction</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">came</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">response</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">response</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">broadcast</governor>
          <dependent id="7">nationally</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">response</governor>
          <dependent id="8">broadcast</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">came</governor>
          <dependent id="9">response</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">book</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">book</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">came</governor>
          <dependent id="12">book</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>She labeled Goldman&amp;apost;s version of life with the Lennons ``totally fiction&amp;apost;&amp;apost; and brought out Lennon&amp;apost;s sons, Julian and 12-year-old Sean, to refute the biography.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="labeled" lemma="label" stem="label" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="version" lemma="version" stem="version" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Lennons" lemma="Lennons" stem="lennon" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="11" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="totally" lemma="totally" stem="total" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="brought" lemma="bring" stem="brought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="19" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="sons" lemma="son" stem="son" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Julian" lemma="Julian" stem="julian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="12-year-old" lemma="12-year-old" stem="12-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="25" string="Sean" lemma="Sean" stem="sean" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="refute" lemma="refute" stem="refut" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="biography" lemma="biography" stem="biographi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (VP (VP (VBD labeled) (NP (NP (NP (NNP Goldman) (POS 's)) (NN version)) (PP (IN of) (NP (NN life)))) (PP (IN with) (NP (NP (DT the) (NNPS Lennons)) (`` ``) (NP (RB totally) (NN fiction)) ('' '')))) (CC and) (VP (VBD brought) (PRT (RP out)) (NP (NP (NP (NNP Lennon) (POS 's)) (NNS sons)) (, ,) (NP (NNP Julian)) (CC and) (NP (JJ 12-year-old) (NNP Sean)))) (, ,) (S (VP (TO to) (VP (VB refute) (NP (DT the) (NN biography)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lennon 's sons , Julian and 12-year-old Sean" type="NP">
          <tokens>
            <token id="18" string="Lennon" />
            <token id="19" string="'s" />
            <token id="20" string="sons" />
            <token id="21" string="," />
            <token id="22" string="Julian" />
            <token id="23" string="and" />
            <token id="24" string="12-year-old" />
            <token id="25" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="2" string="12-year-old Sean" type="NP">
          <tokens>
            <token id="24" string="12-year-old" />
            <token id="25" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="3" string="labeled Goldman 's version of life with the Lennons `` totally fiction ''" type="VP">
          <tokens>
            <token id="2" string="labeled" />
            <token id="3" string="Goldman" />
            <token id="4" string="'s" />
            <token id="5" string="version" />
            <token id="6" string="of" />
            <token id="7" string="life" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="Lennons" />
            <token id="11" string="``" />
            <token id="12" string="totally" />
            <token id="13" string="fiction" />
            <token id="14" string="''" />
          </tokens>
        </chunking>
        <chunking id="4" string="totally fiction" type="NP">
          <tokens>
            <token id="12" string="totally" />
            <token id="13" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="the biography" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="biography" />
          </tokens>
        </chunking>
        <chunking id="6" string="life" type="NP">
          <tokens>
            <token id="7" string="life" />
          </tokens>
        </chunking>
        <chunking id="7" string="labeled Goldman 's version of life with the Lennons `` totally fiction '' and brought out Lennon 's sons , Julian and 12-year-old Sean , to refute the biography" type="VP">
          <tokens>
            <token id="2" string="labeled" />
            <token id="3" string="Goldman" />
            <token id="4" string="'s" />
            <token id="5" string="version" />
            <token id="6" string="of" />
            <token id="7" string="life" />
            <token id="8" string="with" />
            <token id="9" string="the" />
            <token id="10" string="Lennons" />
            <token id="11" string="``" />
            <token id="12" string="totally" />
            <token id="13" string="fiction" />
            <token id="14" string="''" />
            <token id="15" string="and" />
            <token id="16" string="brought" />
            <token id="17" string="out" />
            <token id="18" string="Lennon" />
            <token id="19" string="'s" />
            <token id="20" string="sons" />
            <token id="21" string="," />
            <token id="22" string="Julian" />
            <token id="23" string="and" />
            <token id="24" string="12-year-old" />
            <token id="25" string="Sean" />
            <token id="26" string="," />
            <token id="27" string="to" />
            <token id="28" string="refute" />
            <token id="29" string="the" />
            <token id="30" string="biography" />
          </tokens>
        </chunking>
        <chunking id="8" string="Lennon 's" type="NP">
          <tokens>
            <token id="18" string="Lennon" />
            <token id="19" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="Goldman 's version" type="NP">
          <tokens>
            <token id="3" string="Goldman" />
            <token id="4" string="'s" />
            <token id="5" string="version" />
          </tokens>
        </chunking>
        <chunking id="10" string="refute the biography" type="VP">
          <tokens>
            <token id="28" string="refute" />
            <token id="29" string="the" />
            <token id="30" string="biography" />
          </tokens>
        </chunking>
        <chunking id="11" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
        <chunking id="12" string="brought out Lennon 's sons , Julian and 12-year-old Sean" type="VP">
          <tokens>
            <token id="16" string="brought" />
            <token id="17" string="out" />
            <token id="18" string="Lennon" />
            <token id="19" string="'s" />
            <token id="20" string="sons" />
            <token id="21" string="," />
            <token id="22" string="Julian" />
            <token id="23" string="and" />
            <token id="24" string="12-year-old" />
            <token id="25" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="13" string="Goldman 's" type="NP">
          <tokens>
            <token id="3" string="Goldman" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="to refute the biography" type="VP">
          <tokens>
            <token id="27" string="to" />
            <token id="28" string="refute" />
            <token id="29" string="the" />
            <token id="30" string="biography" />
          </tokens>
        </chunking>
        <chunking id="15" string="the Lennons" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Lennons" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Lennons `` totally fiction ''" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="Lennons" />
            <token id="11" string="``" />
            <token id="12" string="totally" />
            <token id="13" string="fiction" />
            <token id="14" string="''" />
          </tokens>
        </chunking>
        <chunking id="17" string="Goldman 's version of life" type="NP">
          <tokens>
            <token id="3" string="Goldman" />
            <token id="4" string="'s" />
            <token id="5" string="version" />
            <token id="6" string="of" />
            <token id="7" string="life" />
          </tokens>
        </chunking>
        <chunking id="18" string="Lennon 's sons" type="NP">
          <tokens>
            <token id="18" string="Lennon" />
            <token id="19" string="'s" />
            <token id="20" string="sons" />
          </tokens>
        </chunking>
        <chunking id="19" string="Julian" type="NP">
          <tokens>
            <token id="22" string="Julian" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">labeled</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">labeled</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">version</governor>
          <dependent id="3">Goldman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Goldman</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">labeled</governor>
          <dependent id="5">version</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">life</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">version</governor>
          <dependent id="7">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Lennons</governor>
          <dependent id="8">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">Lennons</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">labeled</governor>
          <dependent id="10">Lennons</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">fiction</governor>
          <dependent id="12">totally</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="10">Lennons</governor>
          <dependent id="13">fiction</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">labeled</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">labeled</governor>
          <dependent id="16">brought</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="16">brought</governor>
          <dependent id="17">out</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">sons</governor>
          <dependent id="18">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">Lennon</governor>
          <dependent id="19">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">brought</governor>
          <dependent id="20">sons</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">sons</governor>
          <dependent id="22">Julian</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">sons</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">Sean</governor>
          <dependent id="24">12-year-old</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">sons</governor>
          <dependent id="25">Sean</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">refute</governor>
          <dependent id="27">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">labeled</governor>
          <dependent id="28">refute</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">biography</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">refute</governor>
          <dependent id="30">biography</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Sean" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Sean" />
          </tokens>
        </entity>
        <entity id="3" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Goldman" />
          </tokens>
        </entity>
        <entity id="4" string="Lennons" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="10" string="Lennons" />
          </tokens>
        </entity>
        <entity id="5" string="Julian" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Julian" />
          </tokens>
        </entity>
        <entity id="6" string="12-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="24" string="12-year-old" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>``These giant promotions of Yoko are presented as honest documentaries, when they&amp;apost;re in-house documentaries,&amp;apost;&amp;apost; said Goldman, who complimented Ono on a well-prepared show.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="These" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="giant" lemma="giant" stem="giant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="promotions" lemma="promotion" stem="promot" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="presented" lemma="present" stem="present" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="honest" lemma="honest" stem="honest" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="documentaries" lemma="documentary" stem="documentari" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="'re" lemma="be" stem="'re" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in-house" lemma="in-house" stem="in-hous" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="documentaries" lemma="documentary" stem="documentari" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="complimented" lemma="compliment" stem="compliment" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="28" string="well-prepared" lemma="well-prepared" stem="well-prepar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="show" lemma="show" stem="show" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (NP (DT These) (JJ giant) (NNS promotions)) (PP (IN of) (NP (NNP Yoko)))) (VP (VBP are) (VP (VBN presented) (PP (IN as) (NP (NP (JJ honest) (NNS documentaries)) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (PRP they)) (VP (VBP 're) (NP (JJ in-house) (NNS documentaries)))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Goldman)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD complimented) (NP (NP (NNP Ono)) (PP (IN on) (NP (DT a) (JJ well-prepared) (NN show)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="are presented as honest documentaries , when they 're in-house documentaries" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="presented" />
            <token id="9" string="as" />
            <token id="10" string="honest" />
            <token id="11" string="documentaries" />
            <token id="12" string="," />
            <token id="13" string="when" />
            <token id="14" string="they" />
            <token id="15" string="'re" />
            <token id="16" string="in-house" />
            <token id="17" string="documentaries" />
          </tokens>
        </chunking>
        <chunking id="2" string="a well-prepared show" type="NP">
          <tokens>
            <token id="27" string="a" />
            <token id="28" string="well-prepared" />
            <token id="29" string="show" />
          </tokens>
        </chunking>
        <chunking id="3" string="These giant promotions" type="NP">
          <tokens>
            <token id="2" string="These" />
            <token id="3" string="giant" />
            <token id="4" string="promotions" />
          </tokens>
        </chunking>
        <chunking id="4" string="honest documentaries , when they 're in-house documentaries" type="NP">
          <tokens>
            <token id="10" string="honest" />
            <token id="11" string="documentaries" />
            <token id="12" string="," />
            <token id="13" string="when" />
            <token id="14" string="they" />
            <token id="15" string="'re" />
            <token id="16" string="in-house" />
            <token id="17" string="documentaries" />
          </tokens>
        </chunking>
        <chunking id="5" string="Goldman , who complimented Ono on a well-prepared show" type="NP">
          <tokens>
            <token id="21" string="Goldman" />
            <token id="22" string="," />
            <token id="23" string="who" />
            <token id="24" string="complimented" />
            <token id="25" string="Ono" />
            <token id="26" string="on" />
            <token id="27" string="a" />
            <token id="28" string="well-prepared" />
            <token id="29" string="show" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ono on a well-prepared show" type="NP">
          <tokens>
            <token id="25" string="Ono" />
            <token id="26" string="on" />
            <token id="27" string="a" />
            <token id="28" string="well-prepared" />
            <token id="29" string="show" />
          </tokens>
        </chunking>
        <chunking id="7" string="in-house documentaries" type="NP">
          <tokens>
            <token id="16" string="in-house" />
            <token id="17" string="documentaries" />
          </tokens>
        </chunking>
        <chunking id="8" string="complimented Ono on a well-prepared show" type="VP">
          <tokens>
            <token id="24" string="complimented" />
            <token id="25" string="Ono" />
            <token id="26" string="on" />
            <token id="27" string="a" />
            <token id="28" string="well-prepared" />
            <token id="29" string="show" />
          </tokens>
        </chunking>
        <chunking id="9" string="who complimented Ono on a well-prepared show" type="SBAR">
          <tokens>
            <token id="23" string="who" />
            <token id="24" string="complimented" />
            <token id="25" string="Ono" />
            <token id="26" string="on" />
            <token id="27" string="a" />
            <token id="28" string="well-prepared" />
            <token id="29" string="show" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="13" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="Ono" type="NP">
          <tokens>
            <token id="25" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="12" string="they" type="NP">
          <tokens>
            <token id="14" string="they" />
          </tokens>
        </chunking>
        <chunking id="13" string="These giant promotions of Yoko" type="NP">
          <tokens>
            <token id="2" string="These" />
            <token id="3" string="giant" />
            <token id="4" string="promotions" />
            <token id="5" string="of" />
            <token id="6" string="Yoko" />
          </tokens>
        </chunking>
        <chunking id="14" string="Yoko" type="NP">
          <tokens>
            <token id="6" string="Yoko" />
          </tokens>
        </chunking>
        <chunking id="15" string="honest documentaries" type="NP">
          <tokens>
            <token id="10" string="honest" />
            <token id="11" string="documentaries" />
          </tokens>
        </chunking>
        <chunking id="16" string="'re in-house documentaries" type="VP">
          <tokens>
            <token id="15" string="'re" />
            <token id="16" string="in-house" />
            <token id="17" string="documentaries" />
          </tokens>
        </chunking>
        <chunking id="17" string="presented as honest documentaries , when they 're in-house documentaries" type="VP">
          <tokens>
            <token id="8" string="presented" />
            <token id="9" string="as" />
            <token id="10" string="honest" />
            <token id="11" string="documentaries" />
            <token id="12" string="," />
            <token id="13" string="when" />
            <token id="14" string="they" />
            <token id="15" string="'re" />
            <token id="16" string="in-house" />
            <token id="17" string="documentaries" />
          </tokens>
        </chunking>
        <chunking id="18" string="Goldman" type="NP">
          <tokens>
            <token id="21" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="19" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
        <chunking id="20" string="when they 're in-house documentaries" type="SBAR">
          <tokens>
            <token id="13" string="when" />
            <token id="14" string="they" />
            <token id="15" string="'re" />
            <token id="16" string="in-house" />
            <token id="17" string="documentaries" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="4">promotions</governor>
          <dependent id="2">These</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">promotions</governor>
          <dependent id="3">giant</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="8">presented</governor>
          <dependent id="4">promotions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Yoko</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">promotions</governor>
          <dependent id="6">Yoko</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">presented</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="8">presented</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">documentaries</governor>
          <dependent id="9">as</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">documentaries</governor>
          <dependent id="10">honest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">presented</governor>
          <dependent id="11">documentaries</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">documentaries</governor>
          <dependent id="13">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">documentaries</governor>
          <dependent id="14">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">documentaries</governor>
          <dependent id="15">'re</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">documentaries</governor>
          <dependent id="16">in-house</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">documentaries</governor>
          <dependent id="17">documentaries</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="21">Goldman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">complimented</governor>
          <dependent id="23">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">Goldman</governor>
          <dependent id="24">complimented</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">complimented</governor>
          <dependent id="25">Ono</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">show</governor>
          <dependent id="26">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">show</governor>
          <dependent id="27">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">show</governor>
          <dependent id="28">well-prepared</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">Ono</governor>
          <dependent id="29">show</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Yoko" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Yoko" />
          </tokens>
        </entity>
        <entity id="2" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Goldman" />
          </tokens>
        </entity>
        <entity id="3" string="Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Ono" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>``She takes no chances.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="takes" lemma="take" stem="take" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="chances" lemma="chance" stem="chanc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP She)) (VP (VBZ takes) (NP (DT no) (NNS chances))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="no chances" type="NP">
          <tokens>
            <token id="4" string="no" />
            <token id="5" string="chances" />
          </tokens>
        </chunking>
        <chunking id="2" string="takes no chances" type="VP">
          <tokens>
            <token id="3" string="takes" />
            <token id="4" string="no" />
            <token id="5" string="chances" />
          </tokens>
        </chunking>
        <chunking id="3" string="She" type="NP">
          <tokens>
            <token id="2" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">takes</governor>
          <dependent id="2">She</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">takes</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">chances</governor>
          <dependent id="4">no</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">takes</governor>
          <dependent id="5">chances</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="false">
      <content>This was another no-chance Yoko.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="no-chance" lemma="no-chance" stem="no-chanc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT This)) (VP (VBD was) (NP (DT another) (JJ no-chance) (NNP Yoko))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="was another no-chance Yoko" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="another" />
            <token id="4" string="no-chance" />
            <token id="5" string="Yoko" />
          </tokens>
        </chunking>
        <chunking id="2" string="This" type="NP">
          <tokens>
            <token id="1" string="This" />
          </tokens>
        </chunking>
        <chunking id="3" string="another no-chance Yoko" type="NP">
          <tokens>
            <token id="3" string="another" />
            <token id="4" string="no-chance" />
            <token id="5" string="Yoko" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">Yoko</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">Yoko</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Yoko</governor>
          <dependent id="3">another</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">Yoko</governor>
          <dependent id="4">no-chance</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">Yoko</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Yoko" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Yoko" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>As for the sensational charges of bisexuality, drug abuse by Yoko and John, wild drinking binges, anorexia and reclusiveness, Goldman says it all fits together with the image of Lennon presented by those who knew him.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="sensational" lemma="sensational" stem="sensat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="bisexuality" lemma="bisexuality" stem="bisexu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="abuse" lemma="abuse" stem="abus" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="wild" lemma="wild" stem="wild" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="drinking" lemma="drinking" stem="drink" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="binges" lemma="binge" stem="bing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="anorexia" lemma="anorexia" stem="anorexia" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="reclusiveness" lemma="reclusiveness" stem="reclus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="fits" lemma="fit" stem="fit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="together" lemma="together" stem="togeth" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="image" lemma="image" stem="imag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="35" string="presented" lemma="present" stem="present" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="knew" lemma="know" stem="knew" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN As) (PP (IN for) (NP (NP (DT the) (JJ sensational) (NNS charges)) (PP (IN of) (NP (NP (NN bisexuality)) (, ,) (NP (NP (NN drug) (NN abuse)) (PP (IN by) (NP (NNP Yoko) (CC and) (NNP John)))) (, ,) (NP (JJ wild) (NN drinking) (NNS binges)) (, ,) (NP (NN anorexia)) (CC and) (NP (NN reclusiveness))))))) (, ,) (NP (NNP Goldman)) (VP (VBZ says) (S (NP (PRP it)) (NP (NP (DT all) (NNS fits)) (VP (ADVP (RB together) (PP (IN with) (NP (NP (DT the) (NN image)) (PP (IN of) (NP (NNP Lennon)))))) (VBN presented) (PP (IN by) (NP (NP (DT those)) (SBAR (WHNP (WP who)) (S (VP (VBD knew) (NP (PRP him))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the image of Lennon" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="image" />
            <token id="33" string="of" />
            <token id="34" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="2" string="knew him" type="VP">
          <tokens>
            <token id="39" string="knew" />
            <token id="40" string="him" />
          </tokens>
        </chunking>
        <chunking id="3" string="reclusiveness" type="NP">
          <tokens>
            <token id="22" string="reclusiveness" />
          </tokens>
        </chunking>
        <chunking id="4" string="Yoko and John" type="NP">
          <tokens>
            <token id="12" string="Yoko" />
            <token id="13" string="and" />
            <token id="14" string="John" />
          </tokens>
        </chunking>
        <chunking id="5" string="all fits together with the image of Lennon presented by those who knew him" type="NP">
          <tokens>
            <token id="27" string="all" />
            <token id="28" string="fits" />
            <token id="29" string="together" />
            <token id="30" string="with" />
            <token id="31" string="the" />
            <token id="32" string="image" />
            <token id="33" string="of" />
            <token id="34" string="Lennon" />
            <token id="35" string="presented" />
            <token id="36" string="by" />
            <token id="37" string="those" />
            <token id="38" string="who" />
            <token id="39" string="knew" />
            <token id="40" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lennon" type="NP">
          <tokens>
            <token id="34" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="7" string="anorexia" type="NP">
          <tokens>
            <token id="20" string="anorexia" />
          </tokens>
        </chunking>
        <chunking id="8" string="who knew him" type="SBAR">
          <tokens>
            <token id="38" string="who" />
            <token id="39" string="knew" />
            <token id="40" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="says it all fits together with the image of Lennon presented by those who knew him" type="VP">
          <tokens>
            <token id="25" string="says" />
            <token id="26" string="it" />
            <token id="27" string="all" />
            <token id="28" string="fits" />
            <token id="29" string="together" />
            <token id="30" string="with" />
            <token id="31" string="the" />
            <token id="32" string="image" />
            <token id="33" string="of" />
            <token id="34" string="Lennon" />
            <token id="35" string="presented" />
            <token id="36" string="by" />
            <token id="37" string="those" />
            <token id="38" string="who" />
            <token id="39" string="knew" />
            <token id="40" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="together with the image of Lennon presented by those who knew him" type="VP">
          <tokens>
            <token id="29" string="together" />
            <token id="30" string="with" />
            <token id="31" string="the" />
            <token id="32" string="image" />
            <token id="33" string="of" />
            <token id="34" string="Lennon" />
            <token id="35" string="presented" />
            <token id="36" string="by" />
            <token id="37" string="those" />
            <token id="38" string="who" />
            <token id="39" string="knew" />
            <token id="40" string="him" />
          </tokens>
        </chunking>
        <chunking id="11" string="those who knew him" type="NP">
          <tokens>
            <token id="37" string="those" />
            <token id="38" string="who" />
            <token id="39" string="knew" />
            <token id="40" string="him" />
          </tokens>
        </chunking>
        <chunking id="12" string="it" type="NP">
          <tokens>
            <token id="26" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="him" type="NP">
          <tokens>
            <token id="40" string="him" />
          </tokens>
        </chunking>
        <chunking id="14" string="the image" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="image" />
          </tokens>
        </chunking>
        <chunking id="15" string="bisexuality" type="NP">
          <tokens>
            <token id="7" string="bisexuality" />
          </tokens>
        </chunking>
        <chunking id="16" string="drug abuse" type="NP">
          <tokens>
            <token id="9" string="drug" />
            <token id="10" string="abuse" />
          </tokens>
        </chunking>
        <chunking id="17" string="all fits" type="NP">
          <tokens>
            <token id="27" string="all" />
            <token id="28" string="fits" />
          </tokens>
        </chunking>
        <chunking id="18" string="wild drinking binges" type="NP">
          <tokens>
            <token id="16" string="wild" />
            <token id="17" string="drinking" />
            <token id="18" string="binges" />
          </tokens>
        </chunking>
        <chunking id="19" string="bisexuality , drug abuse by Yoko and John , wild drinking binges , anorexia and reclusiveness" type="NP">
          <tokens>
            <token id="7" string="bisexuality" />
            <token id="8" string="," />
            <token id="9" string="drug" />
            <token id="10" string="abuse" />
            <token id="11" string="by" />
            <token id="12" string="Yoko" />
            <token id="13" string="and" />
            <token id="14" string="John" />
            <token id="15" string="," />
            <token id="16" string="wild" />
            <token id="17" string="drinking" />
            <token id="18" string="binges" />
            <token id="19" string="," />
            <token id="20" string="anorexia" />
            <token id="21" string="and" />
            <token id="22" string="reclusiveness" />
          </tokens>
        </chunking>
        <chunking id="20" string="the sensational charges" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="sensational" />
            <token id="5" string="charges" />
          </tokens>
        </chunking>
        <chunking id="21" string="drug abuse by Yoko and John" type="NP">
          <tokens>
            <token id="9" string="drug" />
            <token id="10" string="abuse" />
            <token id="11" string="by" />
            <token id="12" string="Yoko" />
            <token id="13" string="and" />
            <token id="14" string="John" />
          </tokens>
        </chunking>
        <chunking id="22" string="the sensational charges of bisexuality , drug abuse by Yoko and John , wild drinking binges , anorexia and reclusiveness" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="sensational" />
            <token id="5" string="charges" />
            <token id="6" string="of" />
            <token id="7" string="bisexuality" />
            <token id="8" string="," />
            <token id="9" string="drug" />
            <token id="10" string="abuse" />
            <token id="11" string="by" />
            <token id="12" string="Yoko" />
            <token id="13" string="and" />
            <token id="14" string="John" />
            <token id="15" string="," />
            <token id="16" string="wild" />
            <token id="17" string="drinking" />
            <token id="18" string="binges" />
            <token id="19" string="," />
            <token id="20" string="anorexia" />
            <token id="21" string="and" />
            <token id="22" string="reclusiveness" />
          </tokens>
        </chunking>
        <chunking id="23" string="Goldman" type="NP">
          <tokens>
            <token id="24" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="24" string="those" type="NP">
          <tokens>
            <token id="37" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">charges</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">As</governor>
          <dependent id="2">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">charges</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">charges</governor>
          <dependent id="4">sensational</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">says</governor>
          <dependent id="5">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">bisexuality</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">charges</governor>
          <dependent id="7">bisexuality</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">abuse</governor>
          <dependent id="9">drug</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">bisexuality</governor>
          <dependent id="10">abuse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Yoko</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">abuse</governor>
          <dependent id="12">Yoko</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">Yoko</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">Yoko</governor>
          <dependent id="14">John</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">binges</governor>
          <dependent id="16">wild</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">binges</governor>
          <dependent id="17">drinking</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">bisexuality</governor>
          <dependent id="18">binges</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">bisexuality</governor>
          <dependent id="20">anorexia</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">bisexuality</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">bisexuality</governor>
          <dependent id="22">reclusiveness</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">says</governor>
          <dependent id="24">Goldman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">says</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">fits</governor>
          <dependent id="26">it</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">fits</governor>
          <dependent id="27">all</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">says</governor>
          <dependent id="28">fits</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">image</governor>
          <dependent id="29">together</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="29">together</governor>
          <dependent id="30">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">image</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">presented</governor>
          <dependent id="32">image</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Lennon</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">image</governor>
          <dependent id="34">Lennon</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="28">fits</governor>
          <dependent id="35">presented</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">those</governor>
          <dependent id="36">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">presented</governor>
          <dependent id="37">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">knew</governor>
          <dependent id="38">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="37">those</governor>
          <dependent id="39">knew</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="39">knew</governor>
          <dependent id="40">him</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Yoko" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Yoko" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="34" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="anorexia" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="20" string="anorexia" />
          </tokens>
        </entity>
        <entity id="4" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="John" />
          </tokens>
        </entity>
        <entity id="5" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>``My thesis is John Lennon was a divided mind.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="thesis" lemma="thesis" stem="thesi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="divided" lemma="divide" stem="divid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="mind" lemma="mind" stem="mind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP$ My) (NN thesis)) (VP (VBZ is) (NP (NP (NNP John) (NNP Lennon)) (SBAR (S (VP (VBD was) (NP (DT a) (VBN divided) (NN mind))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="John Lennon" type="NP">
          <tokens>
            <token id="5" string="John" />
            <token id="6" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="2" string="was a divided mind" type="SBAR">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="divided" />
            <token id="10" string="mind" />
          </tokens>
        </chunking>
        <chunking id="3" string="John Lennon was a divided mind" type="NP">
          <tokens>
            <token id="5" string="John" />
            <token id="6" string="Lennon" />
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="divided" />
            <token id="10" string="mind" />
          </tokens>
        </chunking>
        <chunking id="4" string="a divided mind" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="divided" />
            <token id="10" string="mind" />
          </tokens>
        </chunking>
        <chunking id="5" string="My thesis" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="thesis" />
          </tokens>
        </chunking>
        <chunking id="6" string="is John Lennon was a divided mind" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="John" />
            <token id="6" string="Lennon" />
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="divided" />
            <token id="10" string="mind" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">thesis</governor>
          <dependent id="2">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">Lennon</governor>
          <dependent id="3">thesis</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">Lennon</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Lennon</governor>
          <dependent id="5">John</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">Lennon</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">mind</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">mind</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">mind</governor>
          <dependent id="9">divided</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="6">Lennon</governor>
          <dependent id="10">mind</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="John" />
            <token id="6" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>Every yin had a yang,&amp;apost;&amp;apost; said Goldman.</content>
      <tokens>
        <token id="1" string="Every" lemma="every" stem="everi" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="yin" lemma="yin" stem="yin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="yang" lemma="yang" stem="yang" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (NP (DT Every) (NN yin)) (VP (VBD had) (NP (DT a) (NN yang)))) (, ,) ('' '') (VP (VBD said)) (NP (NNP Goldman)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="had a yang" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="a" />
            <token id="5" string="yang" />
          </tokens>
        </chunking>
        <chunking id="2" string="Every yin" type="NP">
          <tokens>
            <token id="1" string="Every" />
            <token id="2" string="yin" />
          </tokens>
        </chunking>
        <chunking id="3" string="Goldman" type="NP">
          <tokens>
            <token id="9" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="8" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="a yang" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="yang" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">yin</governor>
          <dependent id="1">Every</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">had</governor>
          <dependent id="2">yin</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">said</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">yang</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">had</governor>
          <dependent id="5">yang</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">said</governor>
          <dependent id="9">Goldman</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>``There is nothing more natural than for John to try the other side (sexually).</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="nothing" lemma="nothing" stem="noth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="try" lemma="try" stem="try" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="sexually" lemma="sexually" stem="sexual" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (EX There)) (VP (VBZ is) (ADVP (NN nothing)) (ADJP (ADJP (JJR more) (JJ natural)) (PP (IN than) (PP (IN for) (NP (NNP John))))) (S (VP (TO to) (VP (VB try) (NP (DT the) (JJ other) (NN side)) (PRN (-LRB- -LRB-) (ADVP (RB sexually)) (-RRB- -RRB-)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="There" type="NP">
          <tokens>
            <token id="2" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="more natural than for John" type="ADJP">
          <tokens>
            <token id="5" string="more" />
            <token id="6" string="natural" />
            <token id="7" string="than" />
            <token id="8" string="for" />
            <token id="9" string="John" />
          </tokens>
        </chunking>
        <chunking id="3" string="the other side" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="other" />
            <token id="14" string="side" />
          </tokens>
        </chunking>
        <chunking id="4" string="to try the other side -LRB- sexually -RRB-" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="try" />
            <token id="12" string="the" />
            <token id="13" string="other" />
            <token id="14" string="side" />
            <token id="15" string="(" />
            <token id="16" string="sexually" />
            <token id="17" string=")" />
          </tokens>
        </chunking>
        <chunking id="5" string="John" type="NP">
          <tokens>
            <token id="9" string="John" />
          </tokens>
        </chunking>
        <chunking id="6" string="try the other side -LRB- sexually -RRB-" type="VP">
          <tokens>
            <token id="11" string="try" />
            <token id="12" string="the" />
            <token id="13" string="other" />
            <token id="14" string="side" />
            <token id="15" string="(" />
            <token id="16" string="sexually" />
            <token id="17" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="more natural" type="ADJP">
          <tokens>
            <token id="5" string="more" />
            <token id="6" string="natural" />
          </tokens>
        </chunking>
        <chunking id="8" string="is nothing more natural than for John to try the other side -LRB- sexually -RRB-" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="nothing" />
            <token id="5" string="more" />
            <token id="6" string="natural" />
            <token id="7" string="than" />
            <token id="8" string="for" />
            <token id="9" string="John" />
            <token id="10" string="to" />
            <token id="11" string="try" />
            <token id="12" string="the" />
            <token id="13" string="other" />
            <token id="14" string="side" />
            <token id="15" string="(" />
            <token id="16" string="sexually" />
            <token id="17" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="3">is</governor>
          <dependent id="2">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">is</governor>
          <dependent id="4">nothing</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">natural</governor>
          <dependent id="5">more</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">is</governor>
          <dependent id="6">natural</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">John</governor>
          <dependent id="7">than</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">John</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">natural</governor>
          <dependent id="9">John</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">try</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">is</governor>
          <dependent id="11">try</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">side</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">side</governor>
          <dependent id="13">other</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">try</governor>
          <dependent id="14">side</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">try</governor>
          <dependent id="16">sexually</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="John" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>That&amp;apost;s just the kind of guy he was.</content>
      <tokens>
        <token id="1" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="kind" lemma="kind" stem="kind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="guy" lemma="guy" stem="gui" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT That)) (VP (VBZ 's) (ADVP (RB just)) (NP (NP (DT the) (NN kind)) (PP (IN of) (NP (NN guy))) (SBAR (S (NP (PRP he)) (VP (VBD was)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="That" type="NP">
          <tokens>
            <token id="1" string="That" />
          </tokens>
        </chunking>
        <chunking id="2" string="he was" type="SBAR">
          <tokens>
            <token id="8" string="he" />
            <token id="9" string="was" />
          </tokens>
        </chunking>
        <chunking id="3" string="the kind of guy he was" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="kind" />
            <token id="6" string="of" />
            <token id="7" string="guy" />
            <token id="8" string="he" />
            <token id="9" string="was" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s just the kind of guy he was" type="VP">
          <tokens>
            <token id="2" string="'s" />
            <token id="3" string="just" />
            <token id="4" string="the" />
            <token id="5" string="kind" />
            <token id="6" string="of" />
            <token id="7" string="guy" />
            <token id="8" string="he" />
            <token id="9" string="was" />
          </tokens>
        </chunking>
        <chunking id="5" string="was" type="VP">
          <tokens>
            <token id="9" string="was" />
          </tokens>
        </chunking>
        <chunking id="6" string="guy" type="NP">
          <tokens>
            <token id="7" string="guy" />
          </tokens>
        </chunking>
        <chunking id="7" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
        <chunking id="8" string="the kind" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="kind" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">kind</governor>
          <dependent id="1">That</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">kind</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">kind</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">kind</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">kind</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">guy</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">kind</governor>
          <dependent id="7">guy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">was</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="5">kind</governor>
          <dependent id="9">was</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>He wanted to try everything once.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="try" lemma="try" stem="try" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD wanted) (S (VP (TO to) (VP (VB try) (NP (NN everything)) (ADVP (RB once)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="try everything once" type="VP">
          <tokens>
            <token id="4" string="try" />
            <token id="5" string="everything" />
            <token id="6" string="once" />
          </tokens>
        </chunking>
        <chunking id="2" string="wanted to try everything once" type="VP">
          <tokens>
            <token id="2" string="wanted" />
            <token id="3" string="to" />
            <token id="4" string="try" />
            <token id="5" string="everything" />
            <token id="6" string="once" />
          </tokens>
        </chunking>
        <chunking id="3" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="4" string="to try everything once" type="VP">
          <tokens>
            <token id="3" string="to" />
            <token id="4" string="try" />
            <token id="5" string="everything" />
            <token id="6" string="once" />
          </tokens>
        </chunking>
        <chunking id="5" string="everything" type="NP">
          <tokens>
            <token id="5" string="everything" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">wanted</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="4">try</governor>
          <dependent id="3">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">wanted</governor>
          <dependent id="4">try</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">try</governor>
          <dependent id="5">everything</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">try</governor>
          <dependent id="6">once</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="once" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="13-14" string="John Lennon" id_sentence="1" />
      <mentions>
        <mention ids_tokens="21" string="Lennon" id_sentence="6" />
        <mention ids_tokens="8" string="Lennon" id_sentence="8" />
        <mention ids_tokens="31-32" string="Lennon's" id_sentence="13" />
        <mention ids_tokens="6-7" string="Lennon's" id_sentence="18" />
        <mention ids_tokens="2" string="John" id_sentence="19" />
        <mention ids_tokens="3" string="his" id_sentence="20" />
        <mention ids_tokens="12-13" string="Julian Lennon" id_sentence="23" />
        <mention ids_tokens="17" string="Lennon" id_sentence="23" />
        <mention ids_tokens="25" string="he" id_sentence="23" />
        <mention ids_tokens="6" string="John" id_sentence="24" />
        <mention ids_tokens="6-11" string="John Lennon , homosexuality _ bang" id_sentence="34" />
        <mention ids_tokens="18-19" string="Lennon's" id_sentence="37" />
        <mention ids_tokens="22" string="Julian" id_sentence="37" />
        <mention ids_tokens="14" string="John" id_sentence="41" />
        <mention ids_tokens="34" string="Lennon" id_sentence="41" />
        <mention ids_tokens="40" string="him" id_sentence="41" />
        <mention ids_tokens="9" string="John" id_sentence="44" />
        <mention ids_tokens="8" string="he" id_sentence="45" />
        <mention ids_tokens="1" string="He" id_sentence="46" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="31-32" string="Yoko Ono" id_sentence="1" />
      <mentions>
        <mention ids_tokens="2" string="She" id_sentence="2" />
        <mention ids_tokens="13" string="her" id_sentence="2" />
        <mention ids_tokens="3" string="her" id_sentence="3" />
        <mention ids_tokens="4" string="her" id_sentence="4" />
        <mention ids_tokens="1" string="Ono" id_sentence="5" />
        <mention ids_tokens="28" string="Ono" id_sentence="13" />
        <mention ids_tokens="12-13" string="Yoko's" id_sentence="15" />
        <mention ids_tokens="8" string="Ono" id_sentence="23" />
        <mention ids_tokens="2" string="Yoko" id_sentence="25" />
        <mention ids_tokens="14" string="Yoko" id_sentence="35" />
        <mention ids_tokens="1-2" string="Ono's" id_sentence="36" />
        <mention ids_tokens="1" string="She" id_sentence="37" />
        <mention ids_tokens="6" string="Yoko" id_sentence="38" />
        <mention ids_tokens="2" string="She" id_sentence="39" />
        <mention ids_tokens="12" string="Yoko" id_sentence="41" />
        <mention ids_tokens="2" string="My" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="2-3-4-5" string="celebrity biographer Albert Goldman" id_sentence="1" />
      <mentions>
        <mention ids_tokens="15" string="Goldman" id_sentence="4" />
        <mention ids_tokens="15" string="Goldman" id_sentence="6" />
        <mention ids_tokens="17" string="his" id_sentence="6" />
        <mention ids_tokens="5" string="Goldman" id_sentence="7" />
        <mention ids_tokens="24-37" string="Goldman _ who says he is a John Lennon fan _ a hard lesson" id_sentence="8" />
        <mention ids_tokens="24" string="Goldman" id_sentence="8" />
        <mention ids_tokens="14" string="Goldman" id_sentence="10" />
        <mention ids_tokens="1-13" string="Goldman , whose past tell-all biographies dealt with Elvis Presley and Lenny Bruce" id_sentence="13" />
        <mention ids_tokens="1" string="Goldman" id_sentence="13" />
        <mention ids_tokens="10" string="Goldman" id_sentence="14" />
        <mention ids_tokens="9" string="Goldman" id_sentence="17" />
        <mention ids_tokens="4" string="he" id_sentence="18" />
        <mention ids_tokens="7" string="Elvis" id_sentence="19" />
        <mention ids_tokens="10" string="Goldman" id_sentence="20" />
        <mention ids_tokens="6" string="Elvis" id_sentence="21" />
        <mention ids_tokens="1" string="Goldman" id_sentence="23" />
        <mention ids_tokens="10-14" string="Goldman , his voice quickening" id_sentence="28" />
        <mention ids_tokens="10" string="Goldman" id_sentence="28" />
        <mention ids_tokens="12" string="his" id_sentence="28" />
        <mention ids_tokens="26" string="Goldman" id_sentence="32" />
        <mention ids_tokens="3-11" string="Albert Goldman , John Lennon , homosexuality _ bang" id_sentence="34" />
        <mention ids_tokens="3-4" string="Albert Goldman" id_sentence="34" />
        <mention ids_tokens="10" string="_" id_sentence="34" />
        <mention ids_tokens="14" string="him" id_sentence="34" />
        <mention ids_tokens="3-4" string="Goldman's" id_sentence="37" />
        <mention ids_tokens="21-29" string="Goldman , who complimented Ono on a well-prepared show" id_sentence="38" />
        <mention ids_tokens="21" string="Goldman" id_sentence="38" />
        <mention ids_tokens="24" string="Goldman" id_sentence="41" />
        <mention ids_tokens="9" string="Goldman" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="5" type="PRONOMINAL">
      <referenced ids_tokens="7" string="you" id_sentence="2" />
      <mentions>
        <mention ids_tokens="10" string="your" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="14-15-16-17-18-19-20-21-22" string="a true believer in rock 's greatest love story" id_sentence="3" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="4" />
        <mention ids_tokens="7" string="I" id_sentence="4" />
        <mention ids_tokens="8" string="your" id_sentence="9" />
        <mention ids_tokens="2" string="My" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5" string="That vision of the ex-Beatle" id_sentence="8" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="8-9" string="Lennon supporters" id_sentence="8" />
      <mentions>
        <mention ids_tokens="3-11" string="them ; do n't try to see the reality" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="9-10" string="Elvis Presley" id_sentence="13" />
      <mentions>
        <mention ids_tokens="11" string="Presley" id_sentence="18" />
        <mention ids_tokens="1" string="Elvis" id_sentence="20" />
        <mention ids_tokens="4-5" string="Presley's" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="14" type="LIST">
      <referenced ids_tokens="9-10-11-12-13" string="Elvis Presley and Lenny Bruce" id_sentence="13" />
      <mentions>
        <mention ids_tokens="2" string="They" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="36-37" string="Paul McCartney" id_sentence="13" />
      <mentions>
        <mention ids_tokens="2" string="My" id_sentence="14" />
        <mention ids_tokens="6" string="me" id_sentence="16" />
        <mention ids_tokens="10" string="McCartney" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="18-19-20-21-22-23" string="the jive myth of rock business" id_sentence="15" />
      <mentions>
        <mention ids_tokens="3-4" string="the myth" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="4-5-6-7-8" string="the people in my books" id_sentence="27" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="28" />
        <mention ids_tokens="5" string="people" id_sentence="33" />
        <mention ids_tokens="9" string="their" id_sentence="33" />
        <mention ids_tokens="1" string="They" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8" string="the target of scores of attacks" id_sentence="30" />
      <mentions>
        <mention ids_tokens="7" string="my" id_sentence="27" />
        <mention ids_tokens="6" string="it" id_sentence="28" />
        <mention ids_tokens="10" string="myself" id_sentence="29" />
        <mention ids_tokens="1" string="I" id_sentence="31" />
      </mentions>
    </coreference>
    <coreference id="19" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="his voice quickening" id_sentence="28" />
      <mentions>
        <mention ids_tokens="6" string="it" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="20" type="PROPER">
      <referenced ids_tokens="1-2" string="Those attacks" id_sentence="32" />
      <mentions>
        <mention ids_tokens="8" string="attacks" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="9-10" string="an author" id_sentence="31" />
      <mentions>
        <mention ids_tokens="7" string="him" id_sentence="32" />
        <mention ids_tokens="1" string="I" id_sentence="35" />
        <mention ids_tokens="8" string="they" id_sentence="35" />
        <mention ids_tokens="17-18" string="the author" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9-10-11-12-13-14" string="a book they have n't read , including Yoko" id_sentence="35" />
      <mentions>
        <mention ids_tokens="11-12" string="the book" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="18-19-20" string="Lennon 's sons" id_sentence="37" />
      <mentions>
        <mention ids_tokens="14" string="they" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="26" type="NOMINAL">
      <referenced ids_tokens="12-13-14" string="the other side" id_sentence="44" />
      <mentions>
        <mention ids_tokens="1" string="That" id_sentence="45" />
        <mention ids_tokens="4-9" string="the kind of guy he was" id_sentence="45" />
      </mentions>
    </coreference>
  </coreferences>
</document>
