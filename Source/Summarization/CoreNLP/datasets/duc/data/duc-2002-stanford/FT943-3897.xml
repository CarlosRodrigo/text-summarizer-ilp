<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="FT943-3897">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>It is a sensational shortlist: a bestseller about love and hypnotism, a blockbuster about battles and brides in Ruritania, and a pornographic shocker about teenage sex and baby murder so explicit that only an obscure Newcastle publisher would risk printing it.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="sensational" lemma="sensational" stem="sensat" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="shortlist" lemma="shortlist" stem="shortlist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="bestseller" lemma="bestseller" stem="bestsel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="love" lemma="love" stem="love" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="hypnotism" lemma="hypnotism" stem="hypnot" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="blockbuster" lemma="blockbuster" stem="blockbust" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="battles" lemma="battle" stem="battl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="brides" lemma="bride" stem="bride" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Ruritania" lemma="Ruritania" stem="ruritania" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="pornographic" lemma="pornographic" stem="pornograph" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="shocker" lemma="shocker" stem="shocker" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="teenage" lemma="teenage" stem="teenag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="sex" lemma="sex" stem="sex" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="baby" lemma="baby" stem="babi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="murder" lemma="murder" stem="murder" pos="NN" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="33" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="explicit" lemma="explicit" stem="explicit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="obscure" lemma="obscure" stem="obscur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="Newcastle" lemma="Newcastle" stem="newcastl" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="40" string="publisher" lemma="publisher" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="risk" lemma="risk" stem="risk" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="printing" lemma="print" stem="print" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (NP (NP (NP (DT a) (JJ sensational) (NN shortlist)) (: :) (NP (NP (DT a) (NN bestseller)) (PP (IN about) (NP (NN love) (CC and) (NN hypnotism))))) (, ,) (NP (NP (DT a) (NN blockbuster)) (PP (IN about) (NP (NP (NNS battles) (CC and) (NNS brides)) (PP (IN in) (NP (NNP Ruritania)))))) (, ,) (CC and) (NP (NP (DT a) (JJ pornographic) (NN shocker)) (PP (IN about) (NP (NP (JJ teenage) (NN sex) (CC and) (NN baby) (NN murder)) (ADJP (RB so) (JJ explicit)))))) (SBAR (IN that) (RB only) (S (NP (DT an) (JJ obscure) (NNP Newcastle) (NN publisher)) (VP (MD would) (VP (VB risk) (S (VP (VBG printing) (NP (PRP it))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="love and hypnotism" type="NP">
          <tokens>
            <token id="10" string="love" />
            <token id="11" string="and" />
            <token id="12" string="hypnotism" />
          </tokens>
        </chunking>
        <chunking id="2" string="would risk printing it" type="VP">
          <tokens>
            <token id="41" string="would" />
            <token id="42" string="risk" />
            <token id="43" string="printing" />
            <token id="44" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="battles and brides in Ruritania" type="NP">
          <tokens>
            <token id="17" string="battles" />
            <token id="18" string="and" />
            <token id="19" string="brides" />
            <token id="20" string="in" />
            <token id="21" string="Ruritania" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ruritania" type="NP">
          <tokens>
            <token id="21" string="Ruritania" />
          </tokens>
        </chunking>
        <chunking id="5" string="teenage sex and baby murder" type="NP">
          <tokens>
            <token id="28" string="teenage" />
            <token id="29" string="sex" />
            <token id="30" string="and" />
            <token id="31" string="baby" />
            <token id="32" string="murder" />
          </tokens>
        </chunking>
        <chunking id="6" string="printing it" type="VP">
          <tokens>
            <token id="43" string="printing" />
            <token id="44" string="it" />
          </tokens>
        </chunking>
        <chunking id="7" string="a pornographic shocker" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="pornographic" />
            <token id="26" string="shocker" />
          </tokens>
        </chunking>
        <chunking id="8" string="an obscure Newcastle publisher" type="NP">
          <tokens>
            <token id="37" string="an" />
            <token id="38" string="obscure" />
            <token id="39" string="Newcastle" />
            <token id="40" string="publisher" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="44" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="battles and brides" type="NP">
          <tokens>
            <token id="17" string="battles" />
            <token id="18" string="and" />
            <token id="19" string="brides" />
          </tokens>
        </chunking>
        <chunking id="12" string="teenage sex and baby murder so explicit" type="NP">
          <tokens>
            <token id="28" string="teenage" />
            <token id="29" string="sex" />
            <token id="30" string="and" />
            <token id="31" string="baby" />
            <token id="32" string="murder" />
            <token id="33" string="so" />
            <token id="34" string="explicit" />
          </tokens>
        </chunking>
        <chunking id="13" string="that only an obscure Newcastle publisher would risk printing it" type="SBAR">
          <tokens>
            <token id="35" string="that" />
            <token id="36" string="only" />
            <token id="37" string="an" />
            <token id="38" string="obscure" />
            <token id="39" string="Newcastle" />
            <token id="40" string="publisher" />
            <token id="41" string="would" />
            <token id="42" string="risk" />
            <token id="43" string="printing" />
            <token id="44" string="it" />
          </tokens>
        </chunking>
        <chunking id="14" string="a sensational shortlist : a bestseller about love and hypnotism" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="sensational" />
            <token id="5" string="shortlist" />
            <token id="6" string=":" />
            <token id="7" string="a" />
            <token id="8" string="bestseller" />
            <token id="9" string="about" />
            <token id="10" string="love" />
            <token id="11" string="and" />
            <token id="12" string="hypnotism" />
          </tokens>
        </chunking>
        <chunking id="15" string="a blockbuster about battles and brides in Ruritania" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="blockbuster" />
            <token id="16" string="about" />
            <token id="17" string="battles" />
            <token id="18" string="and" />
            <token id="19" string="brides" />
            <token id="20" string="in" />
            <token id="21" string="Ruritania" />
          </tokens>
        </chunking>
        <chunking id="16" string="a blockbuster" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="blockbuster" />
          </tokens>
        </chunking>
        <chunking id="17" string="so explicit" type="ADJP">
          <tokens>
            <token id="33" string="so" />
            <token id="34" string="explicit" />
          </tokens>
        </chunking>
        <chunking id="18" string="a pornographic shocker about teenage sex and baby murder so explicit" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="pornographic" />
            <token id="26" string="shocker" />
            <token id="27" string="about" />
            <token id="28" string="teenage" />
            <token id="29" string="sex" />
            <token id="30" string="and" />
            <token id="31" string="baby" />
            <token id="32" string="murder" />
            <token id="33" string="so" />
            <token id="34" string="explicit" />
          </tokens>
        </chunking>
        <chunking id="19" string="is a sensational shortlist : a bestseller about love and hypnotism , a blockbuster about battles and brides in Ruritania , and a pornographic shocker about teenage sex and baby murder so explicit that only an obscure Newcastle publisher would risk printing it" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="sensational" />
            <token id="5" string="shortlist" />
            <token id="6" string=":" />
            <token id="7" string="a" />
            <token id="8" string="bestseller" />
            <token id="9" string="about" />
            <token id="10" string="love" />
            <token id="11" string="and" />
            <token id="12" string="hypnotism" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="blockbuster" />
            <token id="16" string="about" />
            <token id="17" string="battles" />
            <token id="18" string="and" />
            <token id="19" string="brides" />
            <token id="20" string="in" />
            <token id="21" string="Ruritania" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="a" />
            <token id="25" string="pornographic" />
            <token id="26" string="shocker" />
            <token id="27" string="about" />
            <token id="28" string="teenage" />
            <token id="29" string="sex" />
            <token id="30" string="and" />
            <token id="31" string="baby" />
            <token id="32" string="murder" />
            <token id="33" string="so" />
            <token id="34" string="explicit" />
            <token id="35" string="that" />
            <token id="36" string="only" />
            <token id="37" string="an" />
            <token id="38" string="obscure" />
            <token id="39" string="Newcastle" />
            <token id="40" string="publisher" />
            <token id="41" string="would" />
            <token id="42" string="risk" />
            <token id="43" string="printing" />
            <token id="44" string="it" />
          </tokens>
        </chunking>
        <chunking id="20" string="risk printing it" type="VP">
          <tokens>
            <token id="42" string="risk" />
            <token id="43" string="printing" />
            <token id="44" string="it" />
          </tokens>
        </chunking>
        <chunking id="21" string="a sensational shortlist" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="sensational" />
            <token id="5" string="shortlist" />
          </tokens>
        </chunking>
        <chunking id="22" string="a bestseller about love and hypnotism" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="bestseller" />
            <token id="9" string="about" />
            <token id="10" string="love" />
            <token id="11" string="and" />
            <token id="12" string="hypnotism" />
          </tokens>
        </chunking>
        <chunking id="23" string="a bestseller" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="bestseller" />
          </tokens>
        </chunking>
        <chunking id="24" string="a sensational shortlist : a bestseller about love and hypnotism , a blockbuster about battles and brides in Ruritania , and a pornographic shocker about teenage sex and baby murder so explicit" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="sensational" />
            <token id="5" string="shortlist" />
            <token id="6" string=":" />
            <token id="7" string="a" />
            <token id="8" string="bestseller" />
            <token id="9" string="about" />
            <token id="10" string="love" />
            <token id="11" string="and" />
            <token id="12" string="hypnotism" />
            <token id="13" string="," />
            <token id="14" string="a" />
            <token id="15" string="blockbuster" />
            <token id="16" string="about" />
            <token id="17" string="battles" />
            <token id="18" string="and" />
            <token id="19" string="brides" />
            <token id="20" string="in" />
            <token id="21" string="Ruritania" />
            <token id="22" string="," />
            <token id="23" string="and" />
            <token id="24" string="a" />
            <token id="25" string="pornographic" />
            <token id="26" string="shocker" />
            <token id="27" string="about" />
            <token id="28" string="teenage" />
            <token id="29" string="sex" />
            <token id="30" string="and" />
            <token id="31" string="baby" />
            <token id="32" string="murder" />
            <token id="33" string="so" />
            <token id="34" string="explicit" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">shortlist</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">shortlist</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">shortlist</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">shortlist</governor>
          <dependent id="4">sensational</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">shortlist</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">bestseller</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">shortlist</governor>
          <dependent id="8">bestseller</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">love</governor>
          <dependent id="9">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">bestseller</governor>
          <dependent id="10">love</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">love</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">love</governor>
          <dependent id="12">hypnotism</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">blockbuster</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">shortlist</governor>
          <dependent id="15">blockbuster</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">battles</governor>
          <dependent id="16">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">blockbuster</governor>
          <dependent id="17">battles</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">battles</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">battles</governor>
          <dependent id="19">brides</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Ruritania</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">battles</governor>
          <dependent id="21">Ruritania</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">shortlist</governor>
          <dependent id="23">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">shocker</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">shocker</governor>
          <dependent id="25">pornographic</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">shortlist</governor>
          <dependent id="26">shocker</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">sex</governor>
          <dependent id="27">about</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">sex</governor>
          <dependent id="28">teenage</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">shocker</governor>
          <dependent id="29">sex</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="29">sex</governor>
          <dependent id="30">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="32">murder</governor>
          <dependent id="31">baby</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="29">sex</governor>
          <dependent id="32">murder</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">explicit</governor>
          <dependent id="33">so</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">sex</governor>
          <dependent id="34">explicit</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="42">risk</governor>
          <dependent id="35">that</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="42">risk</governor>
          <dependent id="36">only</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">publisher</governor>
          <dependent id="37">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="40">publisher</governor>
          <dependent id="38">obscure</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="40">publisher</governor>
          <dependent id="39">Newcastle</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="42">risk</governor>
          <dependent id="40">publisher</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="42">risk</governor>
          <dependent id="41">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">shortlist</governor>
          <dependent id="42">risk</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="42">risk</governor>
          <dependent id="43">printing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">printing</governor>
          <dependent id="44">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="murder" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="32" string="murder" />
          </tokens>
        </entity>
        <entity id="2" string="Newcastle" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="39" string="Newcastle" />
          </tokens>
        </entity>
        <entity id="3" string="Ruritania" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Ruritania" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="false">
      <content>Out are the eminences gris of Victorian letters - novels by Thomas Hardy and Mrs Humphry Ward, who advised Gladstone and Roosevelt, didn&amp;apost;t make the grade.</content>
      <tokens>
        <token id="1" string="Out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="eminences" lemma="eminence" stem="emin" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="gris" lemma="gris" stem="gri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Victorian" lemma="victorian" stem="victorian" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="8" string="letters" lemma="letter" stem="letter" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="novels" lemma="novel" stem="novel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Thomas" lemma="Thomas" stem="thoma" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="Hardy" lemma="Hardy" stem="hardi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Mrs" lemma="Mrs" stem="mr" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Humphry" lemma="Humphry" stem="humphri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Ward" lemma="Ward" stem="ward" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="advised" lemma="advise" stem="advis" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Gladstone" lemma="Gladstone" stem="gladston" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Roosevelt" lemma="Roosevelt" stem="roosevelt" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="make" lemma="make" stem="make" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="grade" lemma="grade" stem="grade" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (PP (IN Out)) (VP (VBP are)) (NP (NP (NP (DT the) (NNS eminences) (NN gris)) (PP (IN of) (NP (JJ Victorian) (NNS letters)))) (: -) (NP (NP (NNS novels)) (PP (IN by) (NP (NP (NNP Thomas) (NNP Hardy)) (CC and) (S (NP (NP (NNP Mrs) (NNP Humphry) (NNP Ward)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD advised) (NP (NNP Gladstone) (CC and) (NNP Roosevelt))))) (, ,)) (VP (VBD did) (RB n't) (VP (VB make) (NP (DT the) (NN grade))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who advised Gladstone and Roosevelt" type="SBAR">
          <tokens>
            <token id="19" string="who" />
            <token id="20" string="advised" />
            <token id="21" string="Gladstone" />
            <token id="22" string="and" />
            <token id="23" string="Roosevelt" />
          </tokens>
        </chunking>
        <chunking id="2" string="Thomas Hardy and Mrs Humphry Ward , who advised Gladstone and Roosevelt , did n't make the grade" type="NP">
          <tokens>
            <token id="12" string="Thomas" />
            <token id="13" string="Hardy" />
            <token id="14" string="and" />
            <token id="15" string="Mrs" />
            <token id="16" string="Humphry" />
            <token id="17" string="Ward" />
            <token id="18" string="," />
            <token id="19" string="who" />
            <token id="20" string="advised" />
            <token id="21" string="Gladstone" />
            <token id="22" string="and" />
            <token id="23" string="Roosevelt" />
            <token id="24" string="," />
            <token id="25" string="did" />
            <token id="26" string="n't" />
            <token id="27" string="make" />
            <token id="28" string="the" />
            <token id="29" string="grade" />
          </tokens>
        </chunking>
        <chunking id="3" string="advised Gladstone and Roosevelt" type="VP">
          <tokens>
            <token id="20" string="advised" />
            <token id="21" string="Gladstone" />
            <token id="22" string="and" />
            <token id="23" string="Roosevelt" />
          </tokens>
        </chunking>
        <chunking id="4" string="the eminences gris of Victorian letters - novels by Thomas Hardy and Mrs Humphry Ward , who advised Gladstone and Roosevelt , did n't make the grade" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="eminences" />
            <token id="5" string="gris" />
            <token id="6" string="of" />
            <token id="7" string="Victorian" />
            <token id="8" string="letters" />
            <token id="9" string="-" />
            <token id="10" string="novels" />
            <token id="11" string="by" />
            <token id="12" string="Thomas" />
            <token id="13" string="Hardy" />
            <token id="14" string="and" />
            <token id="15" string="Mrs" />
            <token id="16" string="Humphry" />
            <token id="17" string="Ward" />
            <token id="18" string="," />
            <token id="19" string="who" />
            <token id="20" string="advised" />
            <token id="21" string="Gladstone" />
            <token id="22" string="and" />
            <token id="23" string="Roosevelt" />
            <token id="24" string="," />
            <token id="25" string="did" />
            <token id="26" string="n't" />
            <token id="27" string="make" />
            <token id="28" string="the" />
            <token id="29" string="grade" />
          </tokens>
        </chunking>
        <chunking id="5" string="did n't make the grade" type="VP">
          <tokens>
            <token id="25" string="did" />
            <token id="26" string="n't" />
            <token id="27" string="make" />
            <token id="28" string="the" />
            <token id="29" string="grade" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mrs Humphry Ward , who advised Gladstone and Roosevelt ," type="NP">
          <tokens>
            <token id="15" string="Mrs" />
            <token id="16" string="Humphry" />
            <token id="17" string="Ward" />
            <token id="18" string="," />
            <token id="19" string="who" />
            <token id="20" string="advised" />
            <token id="21" string="Gladstone" />
            <token id="22" string="and" />
            <token id="23" string="Roosevelt" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="the grade" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="grade" />
          </tokens>
        </chunking>
        <chunking id="8" string="Gladstone and Roosevelt" type="NP">
          <tokens>
            <token id="21" string="Gladstone" />
            <token id="22" string="and" />
            <token id="23" string="Roosevelt" />
          </tokens>
        </chunking>
        <chunking id="9" string="Victorian letters" type="NP">
          <tokens>
            <token id="7" string="Victorian" />
            <token id="8" string="letters" />
          </tokens>
        </chunking>
        <chunking id="10" string="are" type="VP">
          <tokens>
            <token id="2" string="are" />
          </tokens>
        </chunking>
        <chunking id="11" string="the eminences gris of Victorian letters" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="eminences" />
            <token id="5" string="gris" />
            <token id="6" string="of" />
            <token id="7" string="Victorian" />
            <token id="8" string="letters" />
          </tokens>
        </chunking>
        <chunking id="12" string="the eminences gris" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="eminences" />
            <token id="5" string="gris" />
          </tokens>
        </chunking>
        <chunking id="13" string="novels by Thomas Hardy and Mrs Humphry Ward , who advised Gladstone and Roosevelt , did n't make the grade" type="NP">
          <tokens>
            <token id="10" string="novels" />
            <token id="11" string="by" />
            <token id="12" string="Thomas" />
            <token id="13" string="Hardy" />
            <token id="14" string="and" />
            <token id="15" string="Mrs" />
            <token id="16" string="Humphry" />
            <token id="17" string="Ward" />
            <token id="18" string="," />
            <token id="19" string="who" />
            <token id="20" string="advised" />
            <token id="21" string="Gladstone" />
            <token id="22" string="and" />
            <token id="23" string="Roosevelt" />
            <token id="24" string="," />
            <token id="25" string="did" />
            <token id="26" string="n't" />
            <token id="27" string="make" />
            <token id="28" string="the" />
            <token id="29" string="grade" />
          </tokens>
        </chunking>
        <chunking id="14" string="Thomas Hardy" type="NP">
          <tokens>
            <token id="12" string="Thomas" />
            <token id="13" string="Hardy" />
          </tokens>
        </chunking>
        <chunking id="15" string="novels" type="NP">
          <tokens>
            <token id="10" string="novels" />
          </tokens>
        </chunking>
        <chunking id="16" string="Mrs Humphry Ward" type="NP">
          <tokens>
            <token id="15" string="Mrs" />
            <token id="16" string="Humphry" />
            <token id="17" string="Ward" />
          </tokens>
        </chunking>
        <chunking id="17" string="make the grade" type="VP">
          <tokens>
            <token id="27" string="make" />
            <token id="28" string="the" />
            <token id="29" string="grade" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod">
          <governor id="2">are</governor>
          <dependent id="1">Out</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">gris</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">gris</governor>
          <dependent id="4">eminences</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">are</governor>
          <dependent id="5">gris</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">letters</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">letters</governor>
          <dependent id="7">Victorian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">gris</governor>
          <dependent id="8">letters</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">gris</governor>
          <dependent id="10">novels</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Hardy</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Hardy</governor>
          <dependent id="12">Thomas</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">novels</governor>
          <dependent id="13">Hardy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Hardy</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Ward</governor>
          <dependent id="15">Mrs</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Ward</governor>
          <dependent id="16">Humphry</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="27">make</governor>
          <dependent id="17">Ward</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">advised</governor>
          <dependent id="19">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">Ward</governor>
          <dependent id="20">advised</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">advised</governor>
          <dependent id="21">Gladstone</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">Gladstone</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">Gladstone</governor>
          <dependent id="23">Roosevelt</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="27">make</governor>
          <dependent id="25">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="27">make</governor>
          <dependent id="26">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Hardy</governor>
          <dependent id="27">make</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">grade</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">make</governor>
          <dependent id="29">grade</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Gladstone" type="PERSON" score="0.0">
          <tokens>
            <token id="21" string="Gladstone" />
          </tokens>
        </entity>
        <entity id="2" string="Victorian" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="Victorian" />
          </tokens>
        </entity>
        <entity id="3" string="Thomas Hardy" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Thomas" />
            <token id="13" string="Hardy" />
          </tokens>
        </entity>
        <entity id="4" string="Mrs Humphry Ward" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Mrs" />
            <token id="16" string="Humphry" />
            <token id="17" string="Ward" />
          </tokens>
        </entity>
        <entity id="5" string="Roosevelt" type="PERSON" score="0.0">
          <tokens>
            <token id="23" string="Roosevelt" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>This week the shortlist for the hypothetical 1894 Booker Prize will be announced by six judges, including biographer Victoria Glendinning and broadcaster Melvyn Bragg.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="shortlist" lemma="shortlist" stem="shortlist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="hypothetical" lemma="hypothetical" stem="hypothet" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="9" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="10" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="11" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="announced" lemma="announce" stem="announc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="16" string="judges" lemma="judge" stem="judg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="biographer" lemma="biographer" stem="biograph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="Victoria" lemma="Victoria" stem="victoria" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="Glendinning" lemma="Glendinning" stem="glendin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="broadcaster" lemma="broadcaster" stem="broadcast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Melvyn" lemma="Melvyn" stem="melvyn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="Bragg" lemma="Bragg" stem="bragg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (DT This) (NN week)) (NP (NP (DT the) (NN shortlist)) (PP (IN for) (NP (DT the) (JJ hypothetical) (CD 1894)))) (NP (NNP Booker) (NNP Prize)) (VP (MD will) (VP (VB be) (VP (VBN announced) (PP (IN by) (NP (NP (CD six) (NNS judges)) (, ,) (PP (VBG including) (NP (NP (NN biographer) (NNP Victoria) (NNP Glendinning)) (CC and) (NP (NN broadcaster) (NNP Melvyn) (NNP Bragg))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="broadcaster Melvyn Bragg" type="NP">
          <tokens>
            <token id="23" string="broadcaster" />
            <token id="24" string="Melvyn" />
            <token id="25" string="Bragg" />
          </tokens>
        </chunking>
        <chunking id="2" string="the shortlist for the hypothetical 1894" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="shortlist" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="hypothetical" />
            <token id="8" string="1894" />
          </tokens>
        </chunking>
        <chunking id="3" string="the shortlist" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="shortlist" />
          </tokens>
        </chunking>
        <chunking id="4" string="six judges , including biographer Victoria Glendinning and broadcaster Melvyn Bragg" type="NP">
          <tokens>
            <token id="15" string="six" />
            <token id="16" string="judges" />
            <token id="17" string="," />
            <token id="18" string="including" />
            <token id="19" string="biographer" />
            <token id="20" string="Victoria" />
            <token id="21" string="Glendinning" />
            <token id="22" string="and" />
            <token id="23" string="broadcaster" />
            <token id="24" string="Melvyn" />
            <token id="25" string="Bragg" />
          </tokens>
        </chunking>
        <chunking id="5" string="the hypothetical 1894" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="hypothetical" />
            <token id="8" string="1894" />
          </tokens>
        </chunking>
        <chunking id="6" string="will be announced by six judges , including biographer Victoria Glendinning and broadcaster Melvyn Bragg" type="VP">
          <tokens>
            <token id="11" string="will" />
            <token id="12" string="be" />
            <token id="13" string="announced" />
            <token id="14" string="by" />
            <token id="15" string="six" />
            <token id="16" string="judges" />
            <token id="17" string="," />
            <token id="18" string="including" />
            <token id="19" string="biographer" />
            <token id="20" string="Victoria" />
            <token id="21" string="Glendinning" />
            <token id="22" string="and" />
            <token id="23" string="broadcaster" />
            <token id="24" string="Melvyn" />
            <token id="25" string="Bragg" />
          </tokens>
        </chunking>
        <chunking id="7" string="Booker Prize" type="NP">
          <tokens>
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="8" string="be announced by six judges , including biographer Victoria Glendinning and broadcaster Melvyn Bragg" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="announced" />
            <token id="14" string="by" />
            <token id="15" string="six" />
            <token id="16" string="judges" />
            <token id="17" string="," />
            <token id="18" string="including" />
            <token id="19" string="biographer" />
            <token id="20" string="Victoria" />
            <token id="21" string="Glendinning" />
            <token id="22" string="and" />
            <token id="23" string="broadcaster" />
            <token id="24" string="Melvyn" />
            <token id="25" string="Bragg" />
          </tokens>
        </chunking>
        <chunking id="9" string="biographer Victoria Glendinning" type="NP">
          <tokens>
            <token id="19" string="biographer" />
            <token id="20" string="Victoria" />
            <token id="21" string="Glendinning" />
          </tokens>
        </chunking>
        <chunking id="10" string="six judges" type="NP">
          <tokens>
            <token id="15" string="six" />
            <token id="16" string="judges" />
          </tokens>
        </chunking>
        <chunking id="11" string="announced by six judges , including biographer Victoria Glendinning and broadcaster Melvyn Bragg" type="VP">
          <tokens>
            <token id="13" string="announced" />
            <token id="14" string="by" />
            <token id="15" string="six" />
            <token id="16" string="judges" />
            <token id="17" string="," />
            <token id="18" string="including" />
            <token id="19" string="biographer" />
            <token id="20" string="Victoria" />
            <token id="21" string="Glendinning" />
            <token id="22" string="and" />
            <token id="23" string="broadcaster" />
            <token id="24" string="Melvyn" />
            <token id="25" string="Bragg" />
          </tokens>
        </chunking>
        <chunking id="12" string="biographer Victoria Glendinning and broadcaster Melvyn Bragg" type="NP">
          <tokens>
            <token id="19" string="biographer" />
            <token id="20" string="Victoria" />
            <token id="21" string="Glendinning" />
            <token id="22" string="and" />
            <token id="23" string="broadcaster" />
            <token id="24" string="Melvyn" />
            <token id="25" string="Bragg" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">week</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="13">announced</governor>
          <dependent id="2">week</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">shortlist</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">announced</governor>
          <dependent id="4">shortlist</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">1894</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">1894</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">1894</governor>
          <dependent id="7">hypothetical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">shortlist</governor>
          <dependent id="8">1894</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Prize</governor>
          <dependent id="9">Booker</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">announced</governor>
          <dependent id="10">Prize</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">announced</governor>
          <dependent id="11">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">announced</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">announced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">judges</governor>
          <dependent id="14">by</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="16">judges</governor>
          <dependent id="15">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">announced</governor>
          <dependent id="16">judges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Glendinning</governor>
          <dependent id="18">including</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Glendinning</governor>
          <dependent id="19">biographer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Glendinning</governor>
          <dependent id="20">Victoria</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">judges</governor>
          <dependent id="21">Glendinning</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">Glendinning</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Bragg</governor>
          <dependent id="23">broadcaster</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Bragg</governor>
          <dependent id="24">Melvyn</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">Glendinning</governor>
          <dependent id="25">Bragg</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="This week" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="week" />
          </tokens>
        </entity>
        <entity id="3" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="1894" />
          </tokens>
        </entity>
        <entity id="4" string="Melvyn Bragg" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Melvyn" />
            <token id="25" string="Bragg" />
          </tokens>
        </entity>
        <entity id="5" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="9" string="Booker" />
            <token id="10" string="Prize" />
          </tokens>
        </entity>
        <entity id="6" string="Victoria Glendinning" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Victoria" />
            <token id="21" string="Glendinning" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>They have avoided dull and worthy classics and chosen six books which stirred the fin de siecle world and remain compelling today: George du Maurier&amp;apost;s Trilby, Anthony Hope&amp;apost;s The Prisoner of Zenda, George Moore&amp;apost;s Esther Waters, Kipling&amp;apost;s Jungle Book, George Gissing&amp;apost;s In the Year of Jubilee and RL Stevenson&amp;apost;s The Ebb Tide.</content>
      <tokens>
        <token id="1" string="They" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="avoided" lemma="avoid" stem="avoid" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="dull" lemma="dull" stem="dull" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="worthy" lemma="worthy" stem="worthi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="classics" lemma="classic" stem="classic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="chosen" lemma="choose" stem="chosen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="stirred" lemma="stir" stem="stir" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="fin" lemma="fin" stem="fin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="de" lemma="de" stem="de" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="siecle" lemma="siecle" stem="siecl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="remain" lemma="remain" stem="remain" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="compelling" lemma="compelling" stem="compel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="25" string="du" lemma="du" stem="du" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="Maurier" lemma="Maurier" stem="maurier" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="Trilby" lemma="Trilby" stem="trilbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Anthony" lemma="Anthony" stem="anthoni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="31" string="Hope" lemma="Hope" stem="hope" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="34" string="Prisoner" lemma="prisoner" stem="prison" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="36" string="Zenda" lemma="Zenda" stem="zenda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="37" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="39" string="Moore" lemma="Moore" stem="moor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="40" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="41" string="Esther" lemma="Esther" stem="esther" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="42" string="Waters" lemma="Waters" stem="water" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="43" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="Kipling" lemma="Kipling" stem="kipl" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="45" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="46" string="Jungle" lemma="jungle" stem="jungl" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="47" string="Book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="48" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="50" string="Gissing" lemma="Gissing" stem="giss" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="51" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="53" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="54" string="Year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="55" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="56" string="Jubilee" lemma="Jubilee" stem="jubile" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="57" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="58" string="RL" lemma="RL" stem="rl" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="59" string="Stevenson" lemma="Stevenson" stem="stevenson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="60" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="61" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="62" string="Ebb" lemma="ebb" stem="ebb" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="63" string="Tide" lemma="Tide" stem="tide" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="64" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP They)) (VP (VBP have) (VP (VP (VBN avoided) (NP (ADJP (JJ dull) (CC and) (JJ worthy)) (NNS classics))) (CC and) (VP (VBN chosen) (NP (NP (NP (CD six) (NNS books)) (SBAR (WHNP (WDT which)) (S (VP (VP (VBD stirred) (NP (NP (DT the) (NN fin)) (IN de) (NP (JJ siecle) (NN world)))) (CC and) (VP (VBP remain) (NP-TMP (JJ compelling) (NN today))))))) (: :) (NP (NP (NP (NNP George) (NNP du) (NNP Maurier) (POS 's)) (NNP Trilby)) (, ,) (NP (NP (NNP Anthony) (NNP Hope) (POS 's)) (NX (NP (DT The) (NN Prisoner)) (PP (IN of) (NP (NNP Zenda))))) (, ,) (NP (NP (NNP George) (NNP Moore) (POS 's)) (NNP Esther) (NNP Waters)) (, ,) (NP (NP (NNP Kipling) (POS 's)) (NN Jungle) (NN Book))) (, ,) (NP (NP (NNP George) (NNP Gissing) (POS 's)) (PP (IN In) (NP (NP (DT the) (NN Year)) (PP (IN of) (NP (NNP Jubilee)))))) (CC and) (NP (NP (NNP RL) (NNP Stevenson) (POS 's)) (NP (NP (DT The) (NN Ebb)) (NP (NNP Tide)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="They" type="NP">
          <tokens>
            <token id="1" string="They" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Year of Jubilee" type="NP">
          <tokens>
            <token id="53" string="the" />
            <token id="54" string="Year" />
            <token id="55" string="of" />
            <token id="56" string="Jubilee" />
          </tokens>
        </chunking>
        <chunking id="3" string="dull and worthy classics" type="NP">
          <tokens>
            <token id="4" string="dull" />
            <token id="5" string="and" />
            <token id="6" string="worthy" />
            <token id="7" string="classics" />
          </tokens>
        </chunking>
        <chunking id="4" string="have avoided dull and worthy classics and chosen six books which stirred the fin de siecle world and remain compelling today : George du Maurier 's Trilby , Anthony Hope 's The Prisoner of Zenda , George Moore 's Esther Waters , Kipling 's Jungle Book , George Gissing 's In the Year of Jubilee and RL Stevenson 's The Ebb Tide" type="VP">
          <tokens>
            <token id="2" string="have" />
            <token id="3" string="avoided" />
            <token id="4" string="dull" />
            <token id="5" string="and" />
            <token id="6" string="worthy" />
            <token id="7" string="classics" />
            <token id="8" string="and" />
            <token id="9" string="chosen" />
            <token id="10" string="six" />
            <token id="11" string="books" />
            <token id="12" string="which" />
            <token id="13" string="stirred" />
            <token id="14" string="the" />
            <token id="15" string="fin" />
            <token id="16" string="de" />
            <token id="17" string="siecle" />
            <token id="18" string="world" />
            <token id="19" string="and" />
            <token id="20" string="remain" />
            <token id="21" string="compelling" />
            <token id="22" string="today" />
            <token id="23" string=":" />
            <token id="24" string="George" />
            <token id="25" string="du" />
            <token id="26" string="Maurier" />
            <token id="27" string="'s" />
            <token id="28" string="Trilby" />
            <token id="29" string="," />
            <token id="30" string="Anthony" />
            <token id="31" string="Hope" />
            <token id="32" string="'s" />
            <token id="33" string="The" />
            <token id="34" string="Prisoner" />
            <token id="35" string="of" />
            <token id="36" string="Zenda" />
            <token id="37" string="," />
            <token id="38" string="George" />
            <token id="39" string="Moore" />
            <token id="40" string="'s" />
            <token id="41" string="Esther" />
            <token id="42" string="Waters" />
            <token id="43" string="," />
            <token id="44" string="Kipling" />
            <token id="45" string="'s" />
            <token id="46" string="Jungle" />
            <token id="47" string="Book" />
            <token id="48" string="," />
            <token id="49" string="George" />
            <token id="50" string="Gissing" />
            <token id="51" string="'s" />
            <token id="52" string="In" />
            <token id="53" string="the" />
            <token id="54" string="Year" />
            <token id="55" string="of" />
            <token id="56" string="Jubilee" />
            <token id="57" string="and" />
            <token id="58" string="RL" />
            <token id="59" string="Stevenson" />
            <token id="60" string="'s" />
            <token id="61" string="The" />
            <token id="62" string="Ebb" />
            <token id="63" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="5" string="six books which stirred the fin de siecle world and remain compelling today : George du Maurier 's Trilby , Anthony Hope 's The Prisoner of Zenda , George Moore 's Esther Waters , Kipling 's Jungle Book , George Gissing 's In the Year of Jubilee and RL Stevenson 's The Ebb Tide" type="NP">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="books" />
            <token id="12" string="which" />
            <token id="13" string="stirred" />
            <token id="14" string="the" />
            <token id="15" string="fin" />
            <token id="16" string="de" />
            <token id="17" string="siecle" />
            <token id="18" string="world" />
            <token id="19" string="and" />
            <token id="20" string="remain" />
            <token id="21" string="compelling" />
            <token id="22" string="today" />
            <token id="23" string=":" />
            <token id="24" string="George" />
            <token id="25" string="du" />
            <token id="26" string="Maurier" />
            <token id="27" string="'s" />
            <token id="28" string="Trilby" />
            <token id="29" string="," />
            <token id="30" string="Anthony" />
            <token id="31" string="Hope" />
            <token id="32" string="'s" />
            <token id="33" string="The" />
            <token id="34" string="Prisoner" />
            <token id="35" string="of" />
            <token id="36" string="Zenda" />
            <token id="37" string="," />
            <token id="38" string="George" />
            <token id="39" string="Moore" />
            <token id="40" string="'s" />
            <token id="41" string="Esther" />
            <token id="42" string="Waters" />
            <token id="43" string="," />
            <token id="44" string="Kipling" />
            <token id="45" string="'s" />
            <token id="46" string="Jungle" />
            <token id="47" string="Book" />
            <token id="48" string="," />
            <token id="49" string="George" />
            <token id="50" string="Gissing" />
            <token id="51" string="'s" />
            <token id="52" string="In" />
            <token id="53" string="the" />
            <token id="54" string="Year" />
            <token id="55" string="of" />
            <token id="56" string="Jubilee" />
            <token id="57" string="and" />
            <token id="58" string="RL" />
            <token id="59" string="Stevenson" />
            <token id="60" string="'s" />
            <token id="61" string="The" />
            <token id="62" string="Ebb" />
            <token id="63" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="6" string="six books which stirred the fin de siecle world and remain compelling today" type="NP">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="books" />
            <token id="12" string="which" />
            <token id="13" string="stirred" />
            <token id="14" string="the" />
            <token id="15" string="fin" />
            <token id="16" string="de" />
            <token id="17" string="siecle" />
            <token id="18" string="world" />
            <token id="19" string="and" />
            <token id="20" string="remain" />
            <token id="21" string="compelling" />
            <token id="22" string="today" />
          </tokens>
        </chunking>
        <chunking id="7" string="siecle world" type="NP">
          <tokens>
            <token id="17" string="siecle" />
            <token id="18" string="world" />
          </tokens>
        </chunking>
        <chunking id="8" string="George du Maurier 's Trilby , Anthony Hope 's The Prisoner of Zenda , George Moore 's Esther Waters , Kipling 's Jungle Book" type="NP">
          <tokens>
            <token id="24" string="George" />
            <token id="25" string="du" />
            <token id="26" string="Maurier" />
            <token id="27" string="'s" />
            <token id="28" string="Trilby" />
            <token id="29" string="," />
            <token id="30" string="Anthony" />
            <token id="31" string="Hope" />
            <token id="32" string="'s" />
            <token id="33" string="The" />
            <token id="34" string="Prisoner" />
            <token id="35" string="of" />
            <token id="36" string="Zenda" />
            <token id="37" string="," />
            <token id="38" string="George" />
            <token id="39" string="Moore" />
            <token id="40" string="'s" />
            <token id="41" string="Esther" />
            <token id="42" string="Waters" />
            <token id="43" string="," />
            <token id="44" string="Kipling" />
            <token id="45" string="'s" />
            <token id="46" string="Jungle" />
            <token id="47" string="Book" />
          </tokens>
        </chunking>
        <chunking id="9" string="George Moore 's Esther Waters" type="NP">
          <tokens>
            <token id="38" string="George" />
            <token id="39" string="Moore" />
            <token id="40" string="'s" />
            <token id="41" string="Esther" />
            <token id="42" string="Waters" />
          </tokens>
        </chunking>
        <chunking id="10" string="avoided dull and worthy classics" type="VP">
          <tokens>
            <token id="3" string="avoided" />
            <token id="4" string="dull" />
            <token id="5" string="and" />
            <token id="6" string="worthy" />
            <token id="7" string="classics" />
          </tokens>
        </chunking>
        <chunking id="11" string="Anthony Hope 's" type="NP">
          <tokens>
            <token id="30" string="Anthony" />
            <token id="31" string="Hope" />
            <token id="32" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="George Gissing 's" type="NP">
          <tokens>
            <token id="49" string="George" />
            <token id="50" string="Gissing" />
            <token id="51" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="the fin" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="fin" />
          </tokens>
        </chunking>
        <chunking id="14" string="Tide" type="NP">
          <tokens>
            <token id="63" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="15" string="George du Maurier 's Trilby" type="NP">
          <tokens>
            <token id="24" string="George" />
            <token id="25" string="du" />
            <token id="26" string="Maurier" />
            <token id="27" string="'s" />
            <token id="28" string="Trilby" />
          </tokens>
        </chunking>
        <chunking id="16" string="RL Stevenson 's" type="NP">
          <tokens>
            <token id="58" string="RL" />
            <token id="59" string="Stevenson" />
            <token id="60" string="'s" />
          </tokens>
        </chunking>
        <chunking id="17" string="stirred the fin de siecle world" type="VP">
          <tokens>
            <token id="13" string="stirred" />
            <token id="14" string="the" />
            <token id="15" string="fin" />
            <token id="16" string="de" />
            <token id="17" string="siecle" />
            <token id="18" string="world" />
          </tokens>
        </chunking>
        <chunking id="18" string="stirred the fin de siecle world and remain compelling today" type="VP">
          <tokens>
            <token id="13" string="stirred" />
            <token id="14" string="the" />
            <token id="15" string="fin" />
            <token id="16" string="de" />
            <token id="17" string="siecle" />
            <token id="18" string="world" />
            <token id="19" string="and" />
            <token id="20" string="remain" />
            <token id="21" string="compelling" />
            <token id="22" string="today" />
          </tokens>
        </chunking>
        <chunking id="19" string="the fin de siecle world" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="fin" />
            <token id="16" string="de" />
            <token id="17" string="siecle" />
            <token id="18" string="world" />
          </tokens>
        </chunking>
        <chunking id="20" string="the Year" type="NP">
          <tokens>
            <token id="53" string="the" />
            <token id="54" string="Year" />
          </tokens>
        </chunking>
        <chunking id="21" string="dull and worthy" type="ADJP">
          <tokens>
            <token id="4" string="dull" />
            <token id="5" string="and" />
            <token id="6" string="worthy" />
          </tokens>
        </chunking>
        <chunking id="22" string="Kipling 's Jungle Book" type="NP">
          <tokens>
            <token id="44" string="Kipling" />
            <token id="45" string="'s" />
            <token id="46" string="Jungle" />
            <token id="47" string="Book" />
          </tokens>
        </chunking>
        <chunking id="23" string="George du Maurier 's" type="NP">
          <tokens>
            <token id="24" string="George" />
            <token id="25" string="du" />
            <token id="26" string="Maurier" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="24" string="which stirred the fin de siecle world and remain compelling today" type="SBAR">
          <tokens>
            <token id="12" string="which" />
            <token id="13" string="stirred" />
            <token id="14" string="the" />
            <token id="15" string="fin" />
            <token id="16" string="de" />
            <token id="17" string="siecle" />
            <token id="18" string="world" />
            <token id="19" string="and" />
            <token id="20" string="remain" />
            <token id="21" string="compelling" />
            <token id="22" string="today" />
          </tokens>
        </chunking>
        <chunking id="25" string="Kipling 's" type="NP">
          <tokens>
            <token id="44" string="Kipling" />
            <token id="45" string="'s" />
          </tokens>
        </chunking>
        <chunking id="26" string="RL Stevenson 's The Ebb Tide" type="NP">
          <tokens>
            <token id="58" string="RL" />
            <token id="59" string="Stevenson" />
            <token id="60" string="'s" />
            <token id="61" string="The" />
            <token id="62" string="Ebb" />
            <token id="63" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="27" string="chosen six books which stirred the fin de siecle world and remain compelling today : George du Maurier 's Trilby , Anthony Hope 's The Prisoner of Zenda , George Moore 's Esther Waters , Kipling 's Jungle Book , George Gissing 's In the Year of Jubilee and RL Stevenson 's The Ebb Tide" type="VP">
          <tokens>
            <token id="9" string="chosen" />
            <token id="10" string="six" />
            <token id="11" string="books" />
            <token id="12" string="which" />
            <token id="13" string="stirred" />
            <token id="14" string="the" />
            <token id="15" string="fin" />
            <token id="16" string="de" />
            <token id="17" string="siecle" />
            <token id="18" string="world" />
            <token id="19" string="and" />
            <token id="20" string="remain" />
            <token id="21" string="compelling" />
            <token id="22" string="today" />
            <token id="23" string=":" />
            <token id="24" string="George" />
            <token id="25" string="du" />
            <token id="26" string="Maurier" />
            <token id="27" string="'s" />
            <token id="28" string="Trilby" />
            <token id="29" string="," />
            <token id="30" string="Anthony" />
            <token id="31" string="Hope" />
            <token id="32" string="'s" />
            <token id="33" string="The" />
            <token id="34" string="Prisoner" />
            <token id="35" string="of" />
            <token id="36" string="Zenda" />
            <token id="37" string="," />
            <token id="38" string="George" />
            <token id="39" string="Moore" />
            <token id="40" string="'s" />
            <token id="41" string="Esther" />
            <token id="42" string="Waters" />
            <token id="43" string="," />
            <token id="44" string="Kipling" />
            <token id="45" string="'s" />
            <token id="46" string="Jungle" />
            <token id="47" string="Book" />
            <token id="48" string="," />
            <token id="49" string="George" />
            <token id="50" string="Gissing" />
            <token id="51" string="'s" />
            <token id="52" string="In" />
            <token id="53" string="the" />
            <token id="54" string="Year" />
            <token id="55" string="of" />
            <token id="56" string="Jubilee" />
            <token id="57" string="and" />
            <token id="58" string="RL" />
            <token id="59" string="Stevenson" />
            <token id="60" string="'s" />
            <token id="61" string="The" />
            <token id="62" string="Ebb" />
            <token id="63" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="28" string="The Ebb Tide" type="NP">
          <tokens>
            <token id="61" string="The" />
            <token id="62" string="Ebb" />
            <token id="63" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="29" string="avoided dull and worthy classics and chosen six books which stirred the fin de siecle world and remain compelling today : George du Maurier 's Trilby , Anthony Hope 's The Prisoner of Zenda , George Moore 's Esther Waters , Kipling 's Jungle Book , George Gissing 's In the Year of Jubilee and RL Stevenson 's The Ebb Tide" type="VP">
          <tokens>
            <token id="3" string="avoided" />
            <token id="4" string="dull" />
            <token id="5" string="and" />
            <token id="6" string="worthy" />
            <token id="7" string="classics" />
            <token id="8" string="and" />
            <token id="9" string="chosen" />
            <token id="10" string="six" />
            <token id="11" string="books" />
            <token id="12" string="which" />
            <token id="13" string="stirred" />
            <token id="14" string="the" />
            <token id="15" string="fin" />
            <token id="16" string="de" />
            <token id="17" string="siecle" />
            <token id="18" string="world" />
            <token id="19" string="and" />
            <token id="20" string="remain" />
            <token id="21" string="compelling" />
            <token id="22" string="today" />
            <token id="23" string=":" />
            <token id="24" string="George" />
            <token id="25" string="du" />
            <token id="26" string="Maurier" />
            <token id="27" string="'s" />
            <token id="28" string="Trilby" />
            <token id="29" string="," />
            <token id="30" string="Anthony" />
            <token id="31" string="Hope" />
            <token id="32" string="'s" />
            <token id="33" string="The" />
            <token id="34" string="Prisoner" />
            <token id="35" string="of" />
            <token id="36" string="Zenda" />
            <token id="37" string="," />
            <token id="38" string="George" />
            <token id="39" string="Moore" />
            <token id="40" string="'s" />
            <token id="41" string="Esther" />
            <token id="42" string="Waters" />
            <token id="43" string="," />
            <token id="44" string="Kipling" />
            <token id="45" string="'s" />
            <token id="46" string="Jungle" />
            <token id="47" string="Book" />
            <token id="48" string="," />
            <token id="49" string="George" />
            <token id="50" string="Gissing" />
            <token id="51" string="'s" />
            <token id="52" string="In" />
            <token id="53" string="the" />
            <token id="54" string="Year" />
            <token id="55" string="of" />
            <token id="56" string="Jubilee" />
            <token id="57" string="and" />
            <token id="58" string="RL" />
            <token id="59" string="Stevenson" />
            <token id="60" string="'s" />
            <token id="61" string="The" />
            <token id="62" string="Ebb" />
            <token id="63" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="30" string="six books" type="NP">
          <tokens>
            <token id="10" string="six" />
            <token id="11" string="books" />
          </tokens>
        </chunking>
        <chunking id="31" string="Anthony Hope 's The Prisoner of Zenda" type="NP">
          <tokens>
            <token id="30" string="Anthony" />
            <token id="31" string="Hope" />
            <token id="32" string="'s" />
            <token id="33" string="The" />
            <token id="34" string="Prisoner" />
            <token id="35" string="of" />
            <token id="36" string="Zenda" />
          </tokens>
        </chunking>
        <chunking id="32" string="The Prisoner" type="NP">
          <tokens>
            <token id="33" string="The" />
            <token id="34" string="Prisoner" />
          </tokens>
        </chunking>
        <chunking id="33" string="George Moore 's" type="NP">
          <tokens>
            <token id="38" string="George" />
            <token id="39" string="Moore" />
            <token id="40" string="'s" />
          </tokens>
        </chunking>
        <chunking id="34" string="Jubilee" type="NP">
          <tokens>
            <token id="56" string="Jubilee" />
          </tokens>
        </chunking>
        <chunking id="35" string="The Ebb" type="NP">
          <tokens>
            <token id="61" string="The" />
            <token id="62" string="Ebb" />
          </tokens>
        </chunking>
        <chunking id="36" string="remain compelling today" type="VP">
          <tokens>
            <token id="20" string="remain" />
            <token id="21" string="compelling" />
            <token id="22" string="today" />
          </tokens>
        </chunking>
        <chunking id="37" string="George Gissing 's In the Year of Jubilee" type="NP">
          <tokens>
            <token id="49" string="George" />
            <token id="50" string="Gissing" />
            <token id="51" string="'s" />
            <token id="52" string="In" />
            <token id="53" string="the" />
            <token id="54" string="Year" />
            <token id="55" string="of" />
            <token id="56" string="Jubilee" />
          </tokens>
        </chunking>
        <chunking id="38" string="Zenda" type="NP">
          <tokens>
            <token id="36" string="Zenda" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">avoided</governor>
          <dependent id="1">They</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">avoided</governor>
          <dependent id="2">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">avoided</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">classics</governor>
          <dependent id="4">dull</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">dull</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">dull</governor>
          <dependent id="6">worthy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">avoided</governor>
          <dependent id="7">classics</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">avoided</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">avoided</governor>
          <dependent id="9">chosen</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">books</governor>
          <dependent id="10">six</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">chosen</governor>
          <dependent id="11">books</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">stirred</governor>
          <dependent id="12">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">books</governor>
          <dependent id="13">stirred</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">fin</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">stirred</governor>
          <dependent id="15">fin</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">fin</governor>
          <dependent id="16">de</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">world</governor>
          <dependent id="17">siecle</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">fin</governor>
          <dependent id="18">world</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">stirred</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">stirred</governor>
          <dependent id="20">remain</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">today</governor>
          <dependent id="21">compelling</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="20">remain</governor>
          <dependent id="22">today</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Maurier</governor>
          <dependent id="24">George</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Maurier</governor>
          <dependent id="25">du</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">Trilby</governor>
          <dependent id="26">Maurier</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Maurier</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">books</governor>
          <dependent id="28">Trilby</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Hope</governor>
          <dependent id="30">Anthony</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="34">Prisoner</governor>
          <dependent id="31">Hope</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Hope</governor>
          <dependent id="32">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="34">Prisoner</governor>
          <dependent id="33">The</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="28">Trilby</governor>
          <dependent id="34">Prisoner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Zenda</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">Prisoner</governor>
          <dependent id="36">Zenda</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="39">Moore</governor>
          <dependent id="38">George</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="42">Waters</governor>
          <dependent id="39">Moore</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">Moore</governor>
          <dependent id="40">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="42">Waters</governor>
          <dependent id="41">Esther</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="28">Trilby</governor>
          <dependent id="42">Waters</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="47">Book</governor>
          <dependent id="44">Kipling</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">Kipling</governor>
          <dependent id="45">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="47">Book</governor>
          <dependent id="46">Jungle</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="28">Trilby</governor>
          <dependent id="47">Book</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="50">Gissing</governor>
          <dependent id="49">George</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">books</governor>
          <dependent id="50">Gissing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="50">Gissing</governor>
          <dependent id="51">'s</dependent>
        </dependency>
        <dependency type="case">
          <governor id="54">Year</governor>
          <dependent id="52">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="54">Year</governor>
          <dependent id="53">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="50">Gissing</governor>
          <dependent id="54">Year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="56">Jubilee</governor>
          <dependent id="55">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="54">Year</governor>
          <dependent id="56">Jubilee</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">books</governor>
          <dependent id="57">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="59">Stevenson</governor>
          <dependent id="58">RL</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">books</governor>
          <dependent id="59">Stevenson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="59">Stevenson</governor>
          <dependent id="60">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="62">Ebb</governor>
          <dependent id="61">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="59">Stevenson</governor>
          <dependent id="62">Ebb</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="62">Ebb</governor>
          <dependent id="63">Tide</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="six" />
          </tokens>
        </entity>
        <entity id="2" string="Anthony Hope" type="PERSON" score="0.0">
          <tokens>
            <token id="30" string="Anthony" />
            <token id="31" string="Hope" />
          </tokens>
        </entity>
        <entity id="3" string="George Moore" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="George" />
            <token id="39" string="Moore" />
          </tokens>
        </entity>
        <entity id="4" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="today" />
          </tokens>
        </entity>
        <entity id="5" string="Esther Waters" type="PERSON" score="0.0">
          <tokens>
            <token id="41" string="Esther" />
            <token id="42" string="Waters" />
          </tokens>
        </entity>
        <entity id="6" string="George Gissing" type="PERSON" score="0.0">
          <tokens>
            <token id="49" string="George" />
            <token id="50" string="Gissing" />
          </tokens>
        </entity>
        <entity id="7" string="Trilby" type="PERSON" score="0.0">
          <tokens>
            <token id="28" string="Trilby" />
          </tokens>
        </entity>
        <entity id="8" string="Ebb Tide" type="MISC" score="0.0">
          <tokens>
            <token id="62" string="Ebb" />
            <token id="63" string="Tide" />
          </tokens>
        </entity>
        <entity id="9" string="George du Maurier" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="George" />
            <token id="25" string="du" />
            <token id="26" string="Maurier" />
          </tokens>
        </entity>
        <entity id="10" string="Stevenson" type="PERSON" score="0.0">
          <tokens>
            <token id="59" string="Stevenson" />
          </tokens>
        </entity>
        <entity id="11" string="Zenda" type="PERSON" score="0.0">
          <tokens>
            <token id="36" string="Zenda" />
          </tokens>
        </entity>
        <entity id="12" string="the Year" type="DATE" score="0.0">
          <tokens>
            <token id="53" string="the" />
            <token id="54" string="Year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>The winner will be revealed on October 15 (four days after the 1994 Booker Prize ceremony) at the Cheltenham Festival of Literature.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="revealed" lemma="reveal" stem="reveal" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="October" lemma="October" stem="october" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="8" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="9" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="four" lemma="four" stem="four" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="11" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="12" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="1994" lemma="1994" stem="1994" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="15" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="16" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="17" string="ceremony" lemma="ceremony" stem="ceremoni" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Cheltenham" lemma="Cheltenham" stem="cheltenham" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Festival" lemma="Festival" stem="festiv" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Literature" lemma="Literature" stem="literatur" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN winner)) (VP (MD will) (VP (VB be) (VP (VBN revealed) (PP (IN on) (NP (NP (NNP October) (CD 15)) (PRN (-LRB- -LRB-) (NP (NP (CD four) (NNS days)) (PP (IN after) (NP (DT the) (CD 1994) (NNP Booker) (NNP Prize) (NN ceremony)))) (-RRB- -RRB-)))) (PP (IN at) (NP (NP (DT the) (NNP Cheltenham) (NNP Festival)) (PP (IN of) (NP (NNP Literature)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Cheltenham Festival of Literature" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Cheltenham" />
            <token id="22" string="Festival" />
            <token id="23" string="of" />
            <token id="24" string="Literature" />
          </tokens>
        </chunking>
        <chunking id="2" string="Literature" type="NP">
          <tokens>
            <token id="24" string="Literature" />
          </tokens>
        </chunking>
        <chunking id="3" string="four days after the 1994 Booker Prize ceremony" type="NP">
          <tokens>
            <token id="10" string="four" />
            <token id="11" string="days" />
            <token id="12" string="after" />
            <token id="13" string="the" />
            <token id="14" string="1994" />
            <token id="15" string="Booker" />
            <token id="16" string="Prize" />
            <token id="17" string="ceremony" />
          </tokens>
        </chunking>
        <chunking id="4" string="be revealed on October 15 -LRB- four days after the 1994 Booker Prize ceremony -RRB- at the Cheltenham Festival of Literature" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="revealed" />
            <token id="6" string="on" />
            <token id="7" string="October" />
            <token id="8" string="15" />
            <token id="9" string="(" />
            <token id="10" string="four" />
            <token id="11" string="days" />
            <token id="12" string="after" />
            <token id="13" string="the" />
            <token id="14" string="1994" />
            <token id="15" string="Booker" />
            <token id="16" string="Prize" />
            <token id="17" string="ceremony" />
            <token id="18" string=")" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="Cheltenham" />
            <token id="22" string="Festival" />
            <token id="23" string="of" />
            <token id="24" string="Literature" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Cheltenham Festival" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Cheltenham" />
            <token id="22" string="Festival" />
          </tokens>
        </chunking>
        <chunking id="6" string="will be revealed on October 15 -LRB- four days after the 1994 Booker Prize ceremony -RRB- at the Cheltenham Festival of Literature" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="be" />
            <token id="5" string="revealed" />
            <token id="6" string="on" />
            <token id="7" string="October" />
            <token id="8" string="15" />
            <token id="9" string="(" />
            <token id="10" string="four" />
            <token id="11" string="days" />
            <token id="12" string="after" />
            <token id="13" string="the" />
            <token id="14" string="1994" />
            <token id="15" string="Booker" />
            <token id="16" string="Prize" />
            <token id="17" string="ceremony" />
            <token id="18" string=")" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="Cheltenham" />
            <token id="22" string="Festival" />
            <token id="23" string="of" />
            <token id="24" string="Literature" />
          </tokens>
        </chunking>
        <chunking id="7" string="revealed on October 15 -LRB- four days after the 1994 Booker Prize ceremony -RRB- at the Cheltenham Festival of Literature" type="VP">
          <tokens>
            <token id="5" string="revealed" />
            <token id="6" string="on" />
            <token id="7" string="October" />
            <token id="8" string="15" />
            <token id="9" string="(" />
            <token id="10" string="four" />
            <token id="11" string="days" />
            <token id="12" string="after" />
            <token id="13" string="the" />
            <token id="14" string="1994" />
            <token id="15" string="Booker" />
            <token id="16" string="Prize" />
            <token id="17" string="ceremony" />
            <token id="18" string=")" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="Cheltenham" />
            <token id="22" string="Festival" />
            <token id="23" string="of" />
            <token id="24" string="Literature" />
          </tokens>
        </chunking>
        <chunking id="8" string="October 15" type="NP">
          <tokens>
            <token id="7" string="October" />
            <token id="8" string="15" />
          </tokens>
        </chunking>
        <chunking id="9" string="the 1994 Booker Prize ceremony" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="1994" />
            <token id="15" string="Booker" />
            <token id="16" string="Prize" />
            <token id="17" string="ceremony" />
          </tokens>
        </chunking>
        <chunking id="10" string="four days" type="NP">
          <tokens>
            <token id="10" string="four" />
            <token id="11" string="days" />
          </tokens>
        </chunking>
        <chunking id="11" string="The winner" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="winner" />
          </tokens>
        </chunking>
        <chunking id="12" string="October 15 -LRB- four days after the 1994 Booker Prize ceremony -RRB-" type="NP">
          <tokens>
            <token id="7" string="October" />
            <token id="8" string="15" />
            <token id="9" string="(" />
            <token id="10" string="four" />
            <token id="11" string="days" />
            <token id="12" string="after" />
            <token id="13" string="the" />
            <token id="14" string="1994" />
            <token id="15" string="Booker" />
            <token id="16" string="Prize" />
            <token id="17" string="ceremony" />
            <token id="18" string=")" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">winner</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">revealed</governor>
          <dependent id="2">winner</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">revealed</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">revealed</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">revealed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">October</governor>
          <dependent id="6">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">revealed</governor>
          <dependent id="7">October</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="7">October</governor>
          <dependent id="8">15</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="11">days</governor>
          <dependent id="10">four</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">October</governor>
          <dependent id="11">days</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">ceremony</governor>
          <dependent id="12">after</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">ceremony</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="17">ceremony</governor>
          <dependent id="14">1994</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">ceremony</governor>
          <dependent id="15">Booker</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">ceremony</governor>
          <dependent id="16">Prize</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">days</governor>
          <dependent id="17">ceremony</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Festival</governor>
          <dependent id="19">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">Festival</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Festival</governor>
          <dependent id="21">Cheltenham</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">revealed</governor>
          <dependent id="22">Festival</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Literature</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">Festival</governor>
          <dependent id="24">Literature</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1994" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="1994" />
          </tokens>
        </entity>
        <entity id="2" string="October 15" type="DATE" score="0.0">
          <tokens>
            <token id="7" string="October" />
            <token id="8" string="15" />
          </tokens>
        </entity>
        <entity id="3" string="four days" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="four" />
            <token id="11" string="days" />
          </tokens>
        </entity>
        <entity id="4" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="15" string="Booker" />
            <token id="16" string="Prize" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Like today&amp;apost;s Booker Prize, it is a publishing gimmick; Everyman, which is backing the spoof award, is a significant publisher of classic Victorian novels.</content>
      <tokens>
        <token id="1" string="Like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="publishing" lemma="publishing" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="gimmick" lemma="gimmick" stem="gimmick" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Everyman" lemma="Everyman" stem="everyman" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="backing" lemma="back" stem="back" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="spoof" lemma="spoof" stem="spoof" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="award" lemma="award" stem="award" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="significant" lemma="significant" stem="signific" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="publisher" lemma="publisher" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="classic" lemma="classic" stem="classic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="Victorian" lemma="victorian" stem="victorian" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="29" string="novels" lemma="novel" stem="novel" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN Like) (NP (NP (NN today) (POS 's)) (NNP Booker) (NNP Prize))) (, ,) (NP (PRP it)) (VP (VBZ is) (NP (DT a) (NN publishing) (NN gimmick)))) (: ;) (S (NP (NP (NNP Everyman)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBG backing) (NP (DT the) (JJ spoof) (NN award)))))) (, ,)) (VP (VBZ is) (NP (NP (DT a) (JJ significant) (NN publisher)) (PP (IN of) (NP (JJ classic) (JJ Victorian) (NNS novels)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="today 's" type="NP">
          <tokens>
            <token id="2" string="today" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="is backing the spoof award" type="VP">
          <tokens>
            <token id="16" string="is" />
            <token id="17" string="backing" />
            <token id="18" string="the" />
            <token id="19" string="spoof" />
            <token id="20" string="award" />
          </tokens>
        </chunking>
        <chunking id="3" string="a publishing gimmick" type="NP">
          <tokens>
            <token id="9" string="a" />
            <token id="10" string="publishing" />
            <token id="11" string="gimmick" />
          </tokens>
        </chunking>
        <chunking id="4" string="backing the spoof award" type="VP">
          <tokens>
            <token id="17" string="backing" />
            <token id="18" string="the" />
            <token id="19" string="spoof" />
            <token id="20" string="award" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="the spoof award" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="spoof" />
            <token id="20" string="award" />
          </tokens>
        </chunking>
        <chunking id="7" string="Everyman , which is backing the spoof award ," type="NP">
          <tokens>
            <token id="13" string="Everyman" />
            <token id="14" string="," />
            <token id="15" string="which" />
            <token id="16" string="is" />
            <token id="17" string="backing" />
            <token id="18" string="the" />
            <token id="19" string="spoof" />
            <token id="20" string="award" />
            <token id="21" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="classic Victorian novels" type="NP">
          <tokens>
            <token id="27" string="classic" />
            <token id="28" string="Victorian" />
            <token id="29" string="novels" />
          </tokens>
        </chunking>
        <chunking id="9" string="is a significant publisher of classic Victorian novels" type="VP">
          <tokens>
            <token id="22" string="is" />
            <token id="23" string="a" />
            <token id="24" string="significant" />
            <token id="25" string="publisher" />
            <token id="26" string="of" />
            <token id="27" string="classic" />
            <token id="28" string="Victorian" />
            <token id="29" string="novels" />
          </tokens>
        </chunking>
        <chunking id="10" string="Everyman" type="NP">
          <tokens>
            <token id="13" string="Everyman" />
          </tokens>
        </chunking>
        <chunking id="11" string="is a publishing gimmick" type="VP">
          <tokens>
            <token id="8" string="is" />
            <token id="9" string="a" />
            <token id="10" string="publishing" />
            <token id="11" string="gimmick" />
          </tokens>
        </chunking>
        <chunking id="12" string="a significant publisher of classic Victorian novels" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="significant" />
            <token id="25" string="publisher" />
            <token id="26" string="of" />
            <token id="27" string="classic" />
            <token id="28" string="Victorian" />
            <token id="29" string="novels" />
          </tokens>
        </chunking>
        <chunking id="13" string="which is backing the spoof award" type="SBAR">
          <tokens>
            <token id="15" string="which" />
            <token id="16" string="is" />
            <token id="17" string="backing" />
            <token id="18" string="the" />
            <token id="19" string="spoof" />
            <token id="20" string="award" />
          </tokens>
        </chunking>
        <chunking id="14" string="a significant publisher" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="significant" />
            <token id="25" string="publisher" />
          </tokens>
        </chunking>
        <chunking id="15" string="today 's Booker Prize" type="NP">
          <tokens>
            <token id="2" string="today" />
            <token id="3" string="'s" />
            <token id="4" string="Booker" />
            <token id="5" string="Prize" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">Prize</governor>
          <dependent id="1">Like</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">Prize</governor>
          <dependent id="2">today</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">today</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Prize</governor>
          <dependent id="4">Booker</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">gimmick</governor>
          <dependent id="5">Prize</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">gimmick</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">gimmick</governor>
          <dependent id="8">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">gimmick</governor>
          <dependent id="9">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">gimmick</governor>
          <dependent id="10">publishing</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">gimmick</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">publisher</governor>
          <dependent id="13">Everyman</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">backing</governor>
          <dependent id="15">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">backing</governor>
          <dependent id="16">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">Everyman</governor>
          <dependent id="17">backing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">award</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">award</governor>
          <dependent id="19">spoof</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">backing</governor>
          <dependent id="20">award</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="25">publisher</governor>
          <dependent id="22">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">publisher</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">publisher</governor>
          <dependent id="24">significant</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="11">gimmick</governor>
          <dependent id="25">publisher</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">novels</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">novels</governor>
          <dependent id="27">classic</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="29">novels</governor>
          <dependent id="28">Victorian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">publisher</governor>
          <dependent id="29">novels</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="today" />
          </tokens>
        </entity>
        <entity id="2" string="Victorian" type="MISC" score="0.0">
          <tokens>
            <token id="28" string="Victorian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>But the retrospective Booker is also a fascinating exercise in historical reconstruction.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="retrospective" lemma="retrospective" stem="retrospect" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="fascinating" lemma="fascinating" stem="fascin" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="exercise" lemma="exercise" stem="exercis" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="historical" lemma="historical" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="reconstruction" lemma="reconstruction" stem="reconstruct" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT the) (JJ retrospective) (NNP Booker)) (VP (VBZ is) (ADVP (RB also)) (NP (NP (DT a) (JJ fascinating) (NN exercise)) (PP (IN in) (NP (JJ historical) (NN reconstruction))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a fascinating exercise" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="fascinating" />
            <token id="9" string="exercise" />
          </tokens>
        </chunking>
        <chunking id="2" string="the retrospective Booker" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="retrospective" />
            <token id="4" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="3" string="is also a fascinating exercise in historical reconstruction" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="also" />
            <token id="7" string="a" />
            <token id="8" string="fascinating" />
            <token id="9" string="exercise" />
            <token id="10" string="in" />
            <token id="11" string="historical" />
            <token id="12" string="reconstruction" />
          </tokens>
        </chunking>
        <chunking id="4" string="historical reconstruction" type="NP">
          <tokens>
            <token id="11" string="historical" />
            <token id="12" string="reconstruction" />
          </tokens>
        </chunking>
        <chunking id="5" string="a fascinating exercise in historical reconstruction" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="fascinating" />
            <token id="9" string="exercise" />
            <token id="10" string="in" />
            <token id="11" string="historical" />
            <token id="12" string="reconstruction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="9">exercise</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Booker</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">Booker</governor>
          <dependent id="3">retrospective</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">exercise</governor>
          <dependent id="4">Booker</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">exercise</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">exercise</governor>
          <dependent id="6">also</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">exercise</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">exercise</governor>
          <dependent id="8">fascinating</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">exercise</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">reconstruction</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">reconstruction</governor>
          <dependent id="11">historical</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">exercise</governor>
          <dependent id="12">reconstruction</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Booker" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>It raises questions about how the relationship between literature and society has changed in the past 100 years.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="raises" lemma="raise" stem="rais" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="relationship" lemma="relationship" stem="relationship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="literature" lemma="literature" stem="literatur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="society" lemma="society" stem="societi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="changed" lemma="change" stem="chang" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="16" string="past" lemma="past" stem="past" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="17" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="18" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ raises) (NP (NP (NNS questions)) (PP (IN about) (SBAR (WHADVP (WRB how)) (S (NP (NP (DT the) (NN relationship)) (PP (IN between) (NP (NN literature) (CC and) (NN society)))) (VP (VBZ has) (VP (VBN changed) (PP (IN in) (NP (DT the) (JJ past) (CD 100) (NNS years)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="questions about how the relationship between literature and society has changed in the past 100 years" type="NP">
          <tokens>
            <token id="3" string="questions" />
            <token id="4" string="about" />
            <token id="5" string="how" />
            <token id="6" string="the" />
            <token id="7" string="relationship" />
            <token id="8" string="between" />
            <token id="9" string="literature" />
            <token id="10" string="and" />
            <token id="11" string="society" />
            <token id="12" string="has" />
            <token id="13" string="changed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="past" />
            <token id="17" string="100" />
            <token id="18" string="years" />
          </tokens>
        </chunking>
        <chunking id="2" string="has changed in the past 100 years" type="VP">
          <tokens>
            <token id="12" string="has" />
            <token id="13" string="changed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="past" />
            <token id="17" string="100" />
            <token id="18" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="changed in the past 100 years" type="VP">
          <tokens>
            <token id="13" string="changed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="past" />
            <token id="17" string="100" />
            <token id="18" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="the relationship" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="relationship" />
          </tokens>
        </chunking>
        <chunking id="5" string="the past 100 years" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="past" />
            <token id="17" string="100" />
            <token id="18" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="questions" type="NP">
          <tokens>
            <token id="3" string="questions" />
          </tokens>
        </chunking>
        <chunking id="7" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="8" string="literature and society" type="NP">
          <tokens>
            <token id="9" string="literature" />
            <token id="10" string="and" />
            <token id="11" string="society" />
          </tokens>
        </chunking>
        <chunking id="9" string="the relationship between literature and society" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="relationship" />
            <token id="8" string="between" />
            <token id="9" string="literature" />
            <token id="10" string="and" />
            <token id="11" string="society" />
          </tokens>
        </chunking>
        <chunking id="10" string="how the relationship between literature and society has changed in the past 100 years" type="SBAR">
          <tokens>
            <token id="5" string="how" />
            <token id="6" string="the" />
            <token id="7" string="relationship" />
            <token id="8" string="between" />
            <token id="9" string="literature" />
            <token id="10" string="and" />
            <token id="11" string="society" />
            <token id="12" string="has" />
            <token id="13" string="changed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="past" />
            <token id="17" string="100" />
            <token id="18" string="years" />
          </tokens>
        </chunking>
        <chunking id="11" string="how" type="WHADVP">
          <tokens>
            <token id="5" string="how" />
          </tokens>
        </chunking>
        <chunking id="12" string="raises questions about how the relationship between literature and society has changed in the past 100 years" type="VP">
          <tokens>
            <token id="2" string="raises" />
            <token id="3" string="questions" />
            <token id="4" string="about" />
            <token id="5" string="how" />
            <token id="6" string="the" />
            <token id="7" string="relationship" />
            <token id="8" string="between" />
            <token id="9" string="literature" />
            <token id="10" string="and" />
            <token id="11" string="society" />
            <token id="12" string="has" />
            <token id="13" string="changed" />
            <token id="14" string="in" />
            <token id="15" string="the" />
            <token id="16" string="past" />
            <token id="17" string="100" />
            <token id="18" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">raises</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">raises</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">raises</governor>
          <dependent id="3">questions</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">changed</governor>
          <dependent id="4">about</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">changed</governor>
          <dependent id="5">how</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">relationship</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">changed</governor>
          <dependent id="7">relationship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">literature</governor>
          <dependent id="8">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">relationship</governor>
          <dependent id="9">literature</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">literature</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">literature</governor>
          <dependent id="11">society</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">changed</governor>
          <dependent id="12">has</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="3">questions</governor>
          <dependent id="13">changed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">years</governor>
          <dependent id="14">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">years</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">years</governor>
          <dependent id="16">past</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">years</governor>
          <dependent id="17">100</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">changed</governor>
          <dependent id="18">years</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the past 100 years" type="DURATION" score="0.0">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="past" />
            <token id="17" string="100" />
            <token id="18" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="false">
      <content>First, the similarities.</content>
      <tokens>
        <token id="1" string="First" lemma="first" stem="first" pos="RB" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="true" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="similarities" lemma="similarity" stem="similar" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (ADVP (RB First)) (, ,) (NP (DT the) (NNS similarities)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the similarities" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="similarities" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="4">similarities</governor>
          <dependent id="1">First</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">similarities</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">similarities</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="First" type="ORDINAL" score="0.0">
          <tokens>
            <token id="1" string="First" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="false">
      <content>A good yarn is a good yarn.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="yarn" lemma="yarn" stem="yarn" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="good" lemma="good" stem="good" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="yarn" lemma="yarn" stem="yarn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (JJ good) (NN yarn)) (VP (VBZ is) (NP (DT a) (JJ good) (NN yarn))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a good yarn" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="good" />
            <token id="7" string="yarn" />
          </tokens>
        </chunking>
        <chunking id="2" string="A good yarn" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="good" />
            <token id="3" string="yarn" />
          </tokens>
        </chunking>
        <chunking id="3" string="is a good yarn" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="a" />
            <token id="6" string="good" />
            <token id="7" string="yarn" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">yarn</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">yarn</governor>
          <dependent id="2">good</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">yarn</governor>
          <dependent id="3">yarn</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">yarn</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">yarn</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">yarn</governor>
          <dependent id="6">good</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">yarn</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="11" has_coreference="false">
      <content>Of the 1894 books, Trilby is the tale of a tone-deaf model who sings like an angel when mesmerised by the sinister hypnotist Svengali, then croaks like a crow when he dies during one of her concerts.</content>
      <tokens>
        <token id="1" string="Of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Trilby" lemma="Trilby" stem="trilbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="tale" lemma="tale" stem="tale" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="tone-deaf" lemma="tone-deaf" stem="tone-deaf" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="model" lemma="model" stem="model" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="sings" lemma="sing" stem="sing" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="angel" lemma="angel" stem="angel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="mesmerised" lemma="mesmerise" stem="mesmeris" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="sinister" lemma="sinister" stem="sinist" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="hypnotist" lemma="hypnotist" stem="hypnotist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="Svengali" lemma="Svengali" stem="svengali" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="croaks" lemma="croak" stem="croak" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="crow" lemma="crow" stem="crow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="dies" lemma="die" stem="di" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="37" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="concerts" lemma="concert" stem="concert" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Of) (NP (DT the) (CD 1894) (NNS books))) (, ,) (NP (NNP Trilby)) (VP (VBZ is) (NP (NP (DT the) (NN tale)) (PP (IN of) (NP (NP (DT a) (JJ tone-deaf) (NN model)) (SBAR (WHNP (WP who)) (S (VP (VBZ sings) (PP (IN like) (NP (NP (DT an) (NN angel)) (SBAR (WHADVP (WRB when)) (S (S (VP (VBN mesmerised) (PP (IN by) (NP (DT the) (JJ sinister) (NN hypnotist) (NNP Svengali))) (, ,) (ADVP (RB then)))) (VP (VBZ croaks) (PP (IN like) (NP (NP (DT a) (NN crow)) (SBAR (WHADVP (WRB when)) (S (NP (PRP he)) (VP (VBZ dies) (PP (IN during) (NP (NP (CD one)) (PP (IN of) (NP (PRP$ her) (NNS concerts)))))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is the tale of a tone-deaf model who sings like an angel when mesmerised by the sinister hypnotist Svengali , then croaks like a crow when he dies during one of her concerts" type="VP">
          <tokens>
            <token id="7" string="is" />
            <token id="8" string="the" />
            <token id="9" string="tale" />
            <token id="10" string="of" />
            <token id="11" string="a" />
            <token id="12" string="tone-deaf" />
            <token id="13" string="model" />
            <token id="14" string="who" />
            <token id="15" string="sings" />
            <token id="16" string="like" />
            <token id="17" string="an" />
            <token id="18" string="angel" />
            <token id="19" string="when" />
            <token id="20" string="mesmerised" />
            <token id="21" string="by" />
            <token id="22" string="the" />
            <token id="23" string="sinister" />
            <token id="24" string="hypnotist" />
            <token id="25" string="Svengali" />
            <token id="26" string="," />
            <token id="27" string="then" />
            <token id="28" string="croaks" />
            <token id="29" string="like" />
            <token id="30" string="a" />
            <token id="31" string="crow" />
            <token id="32" string="when" />
            <token id="33" string="he" />
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="2" string="a crow" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="crow" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="36" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="mesmerised by the sinister hypnotist Svengali , then" type="VP">
          <tokens>
            <token id="20" string="mesmerised" />
            <token id="21" string="by" />
            <token id="22" string="the" />
            <token id="23" string="sinister" />
            <token id="24" string="hypnotist" />
            <token id="25" string="Svengali" />
            <token id="26" string="," />
            <token id="27" string="then" />
          </tokens>
        </chunking>
        <chunking id="5" string="the tale of a tone-deaf model who sings like an angel when mesmerised by the sinister hypnotist Svengali , then croaks like a crow when he dies during one of her concerts" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="tale" />
            <token id="10" string="of" />
            <token id="11" string="a" />
            <token id="12" string="tone-deaf" />
            <token id="13" string="model" />
            <token id="14" string="who" />
            <token id="15" string="sings" />
            <token id="16" string="like" />
            <token id="17" string="an" />
            <token id="18" string="angel" />
            <token id="19" string="when" />
            <token id="20" string="mesmerised" />
            <token id="21" string="by" />
            <token id="22" string="the" />
            <token id="23" string="sinister" />
            <token id="24" string="hypnotist" />
            <token id="25" string="Svengali" />
            <token id="26" string="," />
            <token id="27" string="then" />
            <token id="28" string="croaks" />
            <token id="29" string="like" />
            <token id="30" string="a" />
            <token id="31" string="crow" />
            <token id="32" string="when" />
            <token id="33" string="he" />
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="6" string="an angel" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="angel" />
          </tokens>
        </chunking>
        <chunking id="7" string="when" type="WHADVP">
          <tokens>
            <token id="19" string="when" />
          </tokens>
        </chunking>
        <chunking id="8" string="a tone-deaf model who sings like an angel when mesmerised by the sinister hypnotist Svengali , then croaks like a crow when he dies during one of her concerts" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="tone-deaf" />
            <token id="13" string="model" />
            <token id="14" string="who" />
            <token id="15" string="sings" />
            <token id="16" string="like" />
            <token id="17" string="an" />
            <token id="18" string="angel" />
            <token id="19" string="when" />
            <token id="20" string="mesmerised" />
            <token id="21" string="by" />
            <token id="22" string="the" />
            <token id="23" string="sinister" />
            <token id="24" string="hypnotist" />
            <token id="25" string="Svengali" />
            <token id="26" string="," />
            <token id="27" string="then" />
            <token id="28" string="croaks" />
            <token id="29" string="like" />
            <token id="30" string="a" />
            <token id="31" string="crow" />
            <token id="32" string="when" />
            <token id="33" string="he" />
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="9" string="who sings like an angel when mesmerised by the sinister hypnotist Svengali , then croaks like a crow when he dies during one of her concerts" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="sings" />
            <token id="16" string="like" />
            <token id="17" string="an" />
            <token id="18" string="angel" />
            <token id="19" string="when" />
            <token id="20" string="mesmerised" />
            <token id="21" string="by" />
            <token id="22" string="the" />
            <token id="23" string="sinister" />
            <token id="24" string="hypnotist" />
            <token id="25" string="Svengali" />
            <token id="26" string="," />
            <token id="27" string="then" />
            <token id="28" string="croaks" />
            <token id="29" string="like" />
            <token id="30" string="a" />
            <token id="31" string="crow" />
            <token id="32" string="when" />
            <token id="33" string="he" />
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="10" string="dies during one of her concerts" type="VP">
          <tokens>
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="11" string="her concerts" type="NP">
          <tokens>
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="12" string="the 1894 books" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="1894" />
            <token id="4" string="books" />
          </tokens>
        </chunking>
        <chunking id="13" string="sings like an angel when mesmerised by the sinister hypnotist Svengali , then croaks like a crow when he dies during one of her concerts" type="VP">
          <tokens>
            <token id="15" string="sings" />
            <token id="16" string="like" />
            <token id="17" string="an" />
            <token id="18" string="angel" />
            <token id="19" string="when" />
            <token id="20" string="mesmerised" />
            <token id="21" string="by" />
            <token id="22" string="the" />
            <token id="23" string="sinister" />
            <token id="24" string="hypnotist" />
            <token id="25" string="Svengali" />
            <token id="26" string="," />
            <token id="27" string="then" />
            <token id="28" string="croaks" />
            <token id="29" string="like" />
            <token id="30" string="a" />
            <token id="31" string="crow" />
            <token id="32" string="when" />
            <token id="33" string="he" />
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="14" string="when mesmerised by the sinister hypnotist Svengali , then croaks like a crow when he dies during one of her concerts" type="SBAR">
          <tokens>
            <token id="19" string="when" />
            <token id="20" string="mesmerised" />
            <token id="21" string="by" />
            <token id="22" string="the" />
            <token id="23" string="sinister" />
            <token id="24" string="hypnotist" />
            <token id="25" string="Svengali" />
            <token id="26" string="," />
            <token id="27" string="then" />
            <token id="28" string="croaks" />
            <token id="29" string="like" />
            <token id="30" string="a" />
            <token id="31" string="crow" />
            <token id="32" string="when" />
            <token id="33" string="he" />
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="15" string="the tale" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="tale" />
          </tokens>
        </chunking>
        <chunking id="16" string="a tone-deaf model" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="tone-deaf" />
            <token id="13" string="model" />
          </tokens>
        </chunking>
        <chunking id="17" string="the sinister hypnotist Svengali" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="sinister" />
            <token id="24" string="hypnotist" />
            <token id="25" string="Svengali" />
          </tokens>
        </chunking>
        <chunking id="18" string="Trilby" type="NP">
          <tokens>
            <token id="6" string="Trilby" />
          </tokens>
        </chunking>
        <chunking id="19" string="when he dies during one of her concerts" type="SBAR">
          <tokens>
            <token id="32" string="when" />
            <token id="33" string="he" />
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="20" string="an angel when mesmerised by the sinister hypnotist Svengali , then croaks like a crow when he dies during one of her concerts" type="NP">
          <tokens>
            <token id="17" string="an" />
            <token id="18" string="angel" />
            <token id="19" string="when" />
            <token id="20" string="mesmerised" />
            <token id="21" string="by" />
            <token id="22" string="the" />
            <token id="23" string="sinister" />
            <token id="24" string="hypnotist" />
            <token id="25" string="Svengali" />
            <token id="26" string="," />
            <token id="27" string="then" />
            <token id="28" string="croaks" />
            <token id="29" string="like" />
            <token id="30" string="a" />
            <token id="31" string="crow" />
            <token id="32" string="when" />
            <token id="33" string="he" />
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="21" string="a crow when he dies during one of her concerts" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="crow" />
            <token id="32" string="when" />
            <token id="33" string="he" />
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="22" string="croaks like a crow when he dies during one of her concerts" type="VP">
          <tokens>
            <token id="28" string="croaks" />
            <token id="29" string="like" />
            <token id="30" string="a" />
            <token id="31" string="crow" />
            <token id="32" string="when" />
            <token id="33" string="he" />
            <token id="34" string="dies" />
            <token id="35" string="during" />
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
        <chunking id="23" string="he" type="NP">
          <tokens>
            <token id="33" string="he" />
          </tokens>
        </chunking>
        <chunking id="24" string="one of her concerts" type="NP">
          <tokens>
            <token id="36" string="one" />
            <token id="37" string="of" />
            <token id="38" string="her" />
            <token id="39" string="concerts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">books</governor>
          <dependent id="1">Of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">books</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">books</governor>
          <dependent id="3">1894</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">tale</governor>
          <dependent id="4">books</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">tale</governor>
          <dependent id="6">Trilby</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">tale</governor>
          <dependent id="7">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">tale</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">tale</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">model</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">model</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">model</governor>
          <dependent id="12">tone-deaf</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">tale</governor>
          <dependent id="13">model</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">sings</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">model</governor>
          <dependent id="15">sings</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">angel</governor>
          <dependent id="16">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">angel</governor>
          <dependent id="17">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">sings</governor>
          <dependent id="18">angel</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">croaks</governor>
          <dependent id="19">when</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="28">croaks</governor>
          <dependent id="20">mesmerised</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Svengali</governor>
          <dependent id="21">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Svengali</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">Svengali</governor>
          <dependent id="23">sinister</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">Svengali</governor>
          <dependent id="24">hypnotist</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">mesmerised</governor>
          <dependent id="25">Svengali</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">mesmerised</governor>
          <dependent id="27">then</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">angel</governor>
          <dependent id="28">croaks</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">crow</governor>
          <dependent id="29">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">crow</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">croaks</governor>
          <dependent id="31">crow</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="34">dies</governor>
          <dependent id="32">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">dies</governor>
          <dependent id="33">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="31">crow</governor>
          <dependent id="34">dies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">one</governor>
          <dependent id="35">during</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">dies</governor>
          <dependent id="36">one</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">concerts</governor>
          <dependent id="37">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="39">concerts</governor>
          <dependent id="38">her</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">one</governor>
          <dependent id="39">concerts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="36" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="1894" />
          </tokens>
        </entity>
        <entity id="3" string="Trilby" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Trilby" />
          </tokens>
        </entity>
        <entity id="4" string="Svengali" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Svengali" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>The Prisoner of Zenda tells of an Englishman impersonating the King of Ruritania and rescuing him from demons.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="Prisoner" lemma="prisoner" stem="prison" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Zenda" lemma="Zenda" stem="zenda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="tells" lemma="tell" stem="tell" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Englishman" lemma="Englishman" stem="englishman" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="9" string="impersonating" lemma="impersonate" stem="imperson" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="King" lemma="King" stem="king" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="12" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Ruritania" lemma="Ruritania" stem="ruritania" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="rescuing" lemma="rescue" stem="rescu" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="demons" lemma="demon" stem="demon" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN Prisoner)) (PP (IN of) (NP (NNP Zenda)))) (VP (VBZ tells) (PP (IN of) (S (NP (DT an) (NNP Englishman)) (VP (VP (VBG impersonating) (NP (NP (DT the) (NNP King)) (PP (IN of) (NP (NNP Ruritania))))) (CC and) (VP (VBG rescuing) (NP (PRP him)) (PP (IN from) (NP (NNS demons)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="demons" type="NP">
          <tokens>
            <token id="18" string="demons" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Prisoner of Zenda" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Prisoner" />
            <token id="3" string="of" />
            <token id="4" string="Zenda" />
          </tokens>
        </chunking>
        <chunking id="3" string="the King of Ruritania" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="King" />
            <token id="12" string="of" />
            <token id="13" string="Ruritania" />
          </tokens>
        </chunking>
        <chunking id="4" string="Ruritania" type="NP">
          <tokens>
            <token id="13" string="Ruritania" />
          </tokens>
        </chunking>
        <chunking id="5" string="impersonating the King of Ruritania" type="VP">
          <tokens>
            <token id="9" string="impersonating" />
            <token id="10" string="the" />
            <token id="11" string="King" />
            <token id="12" string="of" />
            <token id="13" string="Ruritania" />
          </tokens>
        </chunking>
        <chunking id="6" string="him" type="NP">
          <tokens>
            <token id="16" string="him" />
          </tokens>
        </chunking>
        <chunking id="7" string="tells of an Englishman impersonating the King of Ruritania and rescuing him from demons" type="VP">
          <tokens>
            <token id="5" string="tells" />
            <token id="6" string="of" />
            <token id="7" string="an" />
            <token id="8" string="Englishman" />
            <token id="9" string="impersonating" />
            <token id="10" string="the" />
            <token id="11" string="King" />
            <token id="12" string="of" />
            <token id="13" string="Ruritania" />
            <token id="14" string="and" />
            <token id="15" string="rescuing" />
            <token id="16" string="him" />
            <token id="17" string="from" />
            <token id="18" string="demons" />
          </tokens>
        </chunking>
        <chunking id="8" string="an Englishman" type="NP">
          <tokens>
            <token id="7" string="an" />
            <token id="8" string="Englishman" />
          </tokens>
        </chunking>
        <chunking id="9" string="impersonating the King of Ruritania and rescuing him from demons" type="VP">
          <tokens>
            <token id="9" string="impersonating" />
            <token id="10" string="the" />
            <token id="11" string="King" />
            <token id="12" string="of" />
            <token id="13" string="Ruritania" />
            <token id="14" string="and" />
            <token id="15" string="rescuing" />
            <token id="16" string="him" />
            <token id="17" string="from" />
            <token id="18" string="demons" />
          </tokens>
        </chunking>
        <chunking id="10" string="The Prisoner" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Prisoner" />
          </tokens>
        </chunking>
        <chunking id="11" string="the King" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="King" />
          </tokens>
        </chunking>
        <chunking id="12" string="rescuing him from demons" type="VP">
          <tokens>
            <token id="15" string="rescuing" />
            <token id="16" string="him" />
            <token id="17" string="from" />
            <token id="18" string="demons" />
          </tokens>
        </chunking>
        <chunking id="13" string="Zenda" type="NP">
          <tokens>
            <token id="4" string="Zenda" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Prisoner</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">tells</governor>
          <dependent id="2">Prisoner</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Zenda</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Prisoner</governor>
          <dependent id="4">Zenda</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">tells</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">impersonating</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Englishman</governor>
          <dependent id="7">an</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">impersonating</governor>
          <dependent id="8">Englishman</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">tells</governor>
          <dependent id="9">impersonating</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">King</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">impersonating</governor>
          <dependent id="11">King</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Ruritania</governor>
          <dependent id="12">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">King</governor>
          <dependent id="13">Ruritania</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">impersonating</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">impersonating</governor>
          <dependent id="15">rescuing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">rescuing</governor>
          <dependent id="16">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">demons</governor>
          <dependent id="17">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">rescuing</governor>
          <dependent id="18">demons</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="King" type="TITLE" score="0.0">
          <tokens>
            <token id="11" string="King" />
          </tokens>
        </entity>
        <entity id="2" string="Englishman" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="8" string="Englishman" />
          </tokens>
        </entity>
        <entity id="3" string="Ruritania" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Ruritania" />
          </tokens>
        </entity>
        <entity id="4" string="Zenda" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Zenda" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="false">
      <content>On the 1994 list Romesh Guneskera&amp;apost;s Reef is about a Sri Lankan servant boy and his mysterious master, while Jill Paton Walsh&amp;apost;s Knowledge of Angels re-enacts the wolf-child legend.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="1994" lemma="1994" stem="1994" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Romesh" lemma="Romesh" stem="romesh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="Guneskera" lemma="Guneskera" stem="guneskera" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="Reef" lemma="reef" stem="reef" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Sri" lemma="Sri" stem="sri" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="13" string="Lankan" lemma="Lankan" stem="lankan" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="14" string="servant" lemma="servant" stem="servant" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="boy" lemma="boy" stem="boi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="mysterious" lemma="mysterious" stem="mysteri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="master" lemma="master" stem="master" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Jill" lemma="Jill" stem="jill" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="Paton" lemma="Paton" stem="paton" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="Walsh" lemma="Walsh" stem="walsh" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="25" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Knowledge" lemma="knowledge" stem="knowledg" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="28" string="Angels" lemma="Angels" stem="angel" pos="NNPS" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="re-enacts" lemma="re-enact" stem="re-enact" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="wolf-child" lemma="wolf-child" stem="wolf-child" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="legend" lemma="legend" stem="legend" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (DT the) (CD 1994) (NN list))) (NP (NP (NNP Romesh) (NNP Guneskera) (POS 's)) (NN Reef)) (VP (VBZ is) (PP (IN about) (NP (NP (DT a) (NNP Sri) (NNP Lankan) (JJ servant) (NN boy)) (CC and) (NP (PRP$ his) (JJ mysterious) (NN master)))) (, ,) (SBAR (IN while) (S (NP (NP (NP (NNP Jill) (NNP Paton) (NNP Walsh) (POS 's)) (NN Knowledge)) (PP (IN of) (NP (NNPS Angels)))) (VP (VBZ re-enacts) (NP (DT the) (JJ wolf-child) (NN legend)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="his mysterious master" type="NP">
          <tokens>
            <token id="17" string="his" />
            <token id="18" string="mysterious" />
            <token id="19" string="master" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jill Paton Walsh 's Knowledge of Angels" type="NP">
          <tokens>
            <token id="22" string="Jill" />
            <token id="23" string="Paton" />
            <token id="24" string="Walsh" />
            <token id="25" string="'s" />
            <token id="26" string="Knowledge" />
            <token id="27" string="of" />
            <token id="28" string="Angels" />
          </tokens>
        </chunking>
        <chunking id="3" string="is about a Sri Lankan servant boy and his mysterious master , while Jill Paton Walsh 's Knowledge of Angels re-enacts the wolf-child legend" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="about" />
            <token id="11" string="a" />
            <token id="12" string="Sri" />
            <token id="13" string="Lankan" />
            <token id="14" string="servant" />
            <token id="15" string="boy" />
            <token id="16" string="and" />
            <token id="17" string="his" />
            <token id="18" string="mysterious" />
            <token id="19" string="master" />
            <token id="20" string="," />
            <token id="21" string="while" />
            <token id="22" string="Jill" />
            <token id="23" string="Paton" />
            <token id="24" string="Walsh" />
            <token id="25" string="'s" />
            <token id="26" string="Knowledge" />
            <token id="27" string="of" />
            <token id="28" string="Angels" />
            <token id="29" string="re-enacts" />
            <token id="30" string="the" />
            <token id="31" string="wolf-child" />
            <token id="32" string="legend" />
          </tokens>
        </chunking>
        <chunking id="4" string="the 1994 list" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="1994" />
            <token id="4" string="list" />
          </tokens>
        </chunking>
        <chunking id="5" string="a Sri Lankan servant boy and his mysterious master" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="Sri" />
            <token id="13" string="Lankan" />
            <token id="14" string="servant" />
            <token id="15" string="boy" />
            <token id="16" string="and" />
            <token id="17" string="his" />
            <token id="18" string="mysterious" />
            <token id="19" string="master" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jill Paton Walsh 's Knowledge" type="NP">
          <tokens>
            <token id="22" string="Jill" />
            <token id="23" string="Paton" />
            <token id="24" string="Walsh" />
            <token id="25" string="'s" />
            <token id="26" string="Knowledge" />
          </tokens>
        </chunking>
        <chunking id="7" string="re-enacts the wolf-child legend" type="VP">
          <tokens>
            <token id="29" string="re-enacts" />
            <token id="30" string="the" />
            <token id="31" string="wolf-child" />
            <token id="32" string="legend" />
          </tokens>
        </chunking>
        <chunking id="8" string="Romesh Guneskera 's" type="NP">
          <tokens>
            <token id="5" string="Romesh" />
            <token id="6" string="Guneskera" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="the wolf-child legend" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="wolf-child" />
            <token id="32" string="legend" />
          </tokens>
        </chunking>
        <chunking id="10" string="Romesh Guneskera 's Reef" type="NP">
          <tokens>
            <token id="5" string="Romesh" />
            <token id="6" string="Guneskera" />
            <token id="7" string="'s" />
            <token id="8" string="Reef" />
          </tokens>
        </chunking>
        <chunking id="11" string="Jill Paton Walsh 's" type="NP">
          <tokens>
            <token id="22" string="Jill" />
            <token id="23" string="Paton" />
            <token id="24" string="Walsh" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="a Sri Lankan servant boy" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="Sri" />
            <token id="13" string="Lankan" />
            <token id="14" string="servant" />
            <token id="15" string="boy" />
          </tokens>
        </chunking>
        <chunking id="13" string="Angels" type="NP">
          <tokens>
            <token id="28" string="Angels" />
          </tokens>
        </chunking>
        <chunking id="14" string="while Jill Paton Walsh 's Knowledge of Angels re-enacts the wolf-child legend" type="SBAR">
          <tokens>
            <token id="21" string="while" />
            <token id="22" string="Jill" />
            <token id="23" string="Paton" />
            <token id="24" string="Walsh" />
            <token id="25" string="'s" />
            <token id="26" string="Knowledge" />
            <token id="27" string="of" />
            <token id="28" string="Angels" />
            <token id="29" string="re-enacts" />
            <token id="30" string="the" />
            <token id="31" string="wolf-child" />
            <token id="32" string="legend" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">list</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">list</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">list</governor>
          <dependent id="3">1994</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">boy</governor>
          <dependent id="4">list</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Guneskera</governor>
          <dependent id="5">Romesh</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">Reef</governor>
          <dependent id="6">Guneskera</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Guneskera</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">boy</governor>
          <dependent id="8">Reef</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">boy</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">boy</governor>
          <dependent id="10">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">boy</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">boy</governor>
          <dependent id="12">Sri</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">boy</governor>
          <dependent id="13">Lankan</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">boy</governor>
          <dependent id="14">servant</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">boy</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">boy</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">master</governor>
          <dependent id="17">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">master</governor>
          <dependent id="18">mysterious</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">boy</governor>
          <dependent id="19">master</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">re-enacts</governor>
          <dependent id="21">while</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Walsh</governor>
          <dependent id="22">Jill</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">Walsh</governor>
          <dependent id="23">Paton</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="26">Knowledge</governor>
          <dependent id="24">Walsh</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Walsh</governor>
          <dependent id="25">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">re-enacts</governor>
          <dependent id="26">Knowledge</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Angels</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">Knowledge</governor>
          <dependent id="28">Angels</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">boy</governor>
          <dependent id="29">re-enacts</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">legend</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">legend</governor>
          <dependent id="31">wolf-child</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">re-enacts</governor>
          <dependent id="32">legend</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Romesh Guneskera" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Romesh" />
            <token id="6" string="Guneskera" />
          </tokens>
        </entity>
        <entity id="2" string="Sri Lankan" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="Sri" />
            <token id="13" string="Lankan" />
          </tokens>
        </entity>
        <entity id="3" string="Jill Paton Walsh" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Jill" />
            <token id="23" string="Paton" />
            <token id="24" string="Walsh" />
          </tokens>
        </entity>
        <entity id="4" string="1994" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="1994" />
          </tokens>
        </entity>
        <entity id="5" string="Knowledge of Angels" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="26" string="Knowledge" />
            <token id="27" string="of" />
            <token id="28" string="Angels" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>All the books on both lists are gripping stories.</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="lists" lemma="list" stem="list" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="gripping" lemma="grip" stem="grip" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="stories" lemma="story" stem="stori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PDT All) (DT the) (NNS books)) (PP (IN on) (NP (DT both) (NNS lists)))) (VP (VBP are) (NP (VBG gripping) (NNS stories))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="gripping stories" type="NP">
          <tokens>
            <token id="8" string="gripping" />
            <token id="9" string="stories" />
          </tokens>
        </chunking>
        <chunking id="2" string="All the books on both lists" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="the" />
            <token id="3" string="books" />
            <token id="4" string="on" />
            <token id="5" string="both" />
            <token id="6" string="lists" />
          </tokens>
        </chunking>
        <chunking id="3" string="are gripping stories" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="gripping" />
            <token id="9" string="stories" />
          </tokens>
        </chunking>
        <chunking id="4" string="All the books" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="the" />
            <token id="3" string="books" />
          </tokens>
        </chunking>
        <chunking id="5" string="both lists" type="NP">
          <tokens>
            <token id="5" string="both" />
            <token id="6" string="lists" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det:predet">
          <governor id="3">books</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">books</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">stories</governor>
          <dependent id="3">books</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">lists</governor>
          <dependent id="4">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">lists</governor>
          <dependent id="5">both</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">books</governor>
          <dependent id="6">lists</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">stories</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">stories</governor>
          <dependent id="8">gripping</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">stories</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>The lists share key themes.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="lists" lemma="list" stem="list" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="share" lemma="share" stem="share" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="key" lemma="key" stem="kei" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="themes" lemma="theme" stem="theme" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNS lists)) (VP (VBP share) (NP (JJ key) (NNS themes))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="share key themes" type="VP">
          <tokens>
            <token id="3" string="share" />
            <token id="4" string="key" />
            <token id="5" string="themes" />
          </tokens>
        </chunking>
        <chunking id="2" string="The lists" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="lists" />
          </tokens>
        </chunking>
        <chunking id="3" string="key themes" type="NP">
          <tokens>
            <token id="4" string="key" />
            <token id="5" string="themes" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">lists</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">share</governor>
          <dependent id="2">lists</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">share</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">themes</governor>
          <dependent id="4">key</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">share</governor>
          <dependent id="5">themes</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Both, for instance, have books about colonial exploitation - Stevenson&amp;apost;s The Ebb Tide and Abdulrazak Gurnah&amp;apost;s Paradise, which is set in the First World War in German East Africa.</content>
      <tokens>
        <token id="1" string="Both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="instance" lemma="instance" stem="instanc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="colonial" lemma="colonial" stem="coloni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="exploitation" lemma="exploitation" stem="exploit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Stevenson" lemma="Stevenson" stem="stevenson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="Ebb" lemma="ebb" stem="ebb" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="16" string="Tide" lemma="Tide" stem="tide" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="Abdulrazak" lemma="Abdulrazak" stem="abdulrazak" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="Gurnah" lemma="Gurnah" stem="gurnah" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="Paradise" lemma="Paradise" stem="paradis" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="set" lemma="set" stem="set" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="First" lemma="First" stem="first" pos="NNP" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="29" string="World" lemma="World" stem="world" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="30" string="War" lemma="War" stem="war" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="German" lemma="German" stem="german" pos="NNP" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="33" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="Africa" lemma="Africa" stem="africa" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT Both)) (, ,) (PP (IN for) (NP (NN instance))) (, ,)) (VP (VBP have) (NP (NP (NP (NP (NNS books)) (PP (IN about) (NP (NN colonial) (NN exploitation)))) (: -) (NP (NP (NNP Stevenson) (POS 's)) (NP (NP (DT The) (NN Ebb)) (NP (NNP Tide))))) (CC and) (NP (NP (NP (NNP Abdulrazak) (NNP Gurnah) (POS 's)) (NNP Paradise)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBZ is) (VP (VBN set) (PP (IN in) (NP (NP (DT the) (NNP First) (NNP World) (NNP War)) (PP (IN in) (NP (NNP German) (NNP East) (NNP Africa)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Abdulrazak Gurnah 's Paradise , which is set in the First World War in German East Africa" type="NP">
          <tokens>
            <token id="18" string="Abdulrazak" />
            <token id="19" string="Gurnah" />
            <token id="20" string="'s" />
            <token id="21" string="Paradise" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="is" />
            <token id="25" string="set" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="First" />
            <token id="29" string="World" />
            <token id="30" string="War" />
            <token id="31" string="in" />
            <token id="32" string="German" />
            <token id="33" string="East" />
            <token id="34" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="2" string="instance" type="NP">
          <tokens>
            <token id="4" string="instance" />
          </tokens>
        </chunking>
        <chunking id="3" string="colonial exploitation" type="NP">
          <tokens>
            <token id="9" string="colonial" />
            <token id="10" string="exploitation" />
          </tokens>
        </chunking>
        <chunking id="4" string="Abdulrazak Gurnah 's Paradise" type="NP">
          <tokens>
            <token id="18" string="Abdulrazak" />
            <token id="19" string="Gurnah" />
            <token id="20" string="'s" />
            <token id="21" string="Paradise" />
          </tokens>
        </chunking>
        <chunking id="5" string="have books about colonial exploitation - Stevenson 's The Ebb Tide and Abdulrazak Gurnah 's Paradise , which is set in the First World War in German East Africa" type="VP">
          <tokens>
            <token id="6" string="have" />
            <token id="7" string="books" />
            <token id="8" string="about" />
            <token id="9" string="colonial" />
            <token id="10" string="exploitation" />
            <token id="11" string="-" />
            <token id="12" string="Stevenson" />
            <token id="13" string="'s" />
            <token id="14" string="The" />
            <token id="15" string="Ebb" />
            <token id="16" string="Tide" />
            <token id="17" string="and" />
            <token id="18" string="Abdulrazak" />
            <token id="19" string="Gurnah" />
            <token id="20" string="'s" />
            <token id="21" string="Paradise" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="is" />
            <token id="25" string="set" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="First" />
            <token id="29" string="World" />
            <token id="30" string="War" />
            <token id="31" string="in" />
            <token id="32" string="German" />
            <token id="33" string="East" />
            <token id="34" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="6" string="which is set in the First World War in German East Africa" type="SBAR">
          <tokens>
            <token id="23" string="which" />
            <token id="24" string="is" />
            <token id="25" string="set" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="First" />
            <token id="29" string="World" />
            <token id="30" string="War" />
            <token id="31" string="in" />
            <token id="32" string="German" />
            <token id="33" string="East" />
            <token id="34" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="7" string="books about colonial exploitation - Stevenson 's The Ebb Tide" type="NP">
          <tokens>
            <token id="7" string="books" />
            <token id="8" string="about" />
            <token id="9" string="colonial" />
            <token id="10" string="exploitation" />
            <token id="11" string="-" />
            <token id="12" string="Stevenson" />
            <token id="13" string="'s" />
            <token id="14" string="The" />
            <token id="15" string="Ebb" />
            <token id="16" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="8" string="German East Africa" type="NP">
          <tokens>
            <token id="32" string="German" />
            <token id="33" string="East" />
            <token id="34" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="9" string="The Ebb Tide" type="NP">
          <tokens>
            <token id="14" string="The" />
            <token id="15" string="Ebb" />
            <token id="16" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="10" string="the First World War in German East Africa" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="First" />
            <token id="29" string="World" />
            <token id="30" string="War" />
            <token id="31" string="in" />
            <token id="32" string="German" />
            <token id="33" string="East" />
            <token id="34" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="11" string="books" type="NP">
          <tokens>
            <token id="7" string="books" />
          </tokens>
        </chunking>
        <chunking id="12" string="Abdulrazak Gurnah 's" type="NP">
          <tokens>
            <token id="18" string="Abdulrazak" />
            <token id="19" string="Gurnah" />
            <token id="20" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="the First World War" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="First" />
            <token id="29" string="World" />
            <token id="30" string="War" />
          </tokens>
        </chunking>
        <chunking id="14" string="Tide" type="NP">
          <tokens>
            <token id="16" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="15" string="books about colonial exploitation" type="NP">
          <tokens>
            <token id="7" string="books" />
            <token id="8" string="about" />
            <token id="9" string="colonial" />
            <token id="10" string="exploitation" />
          </tokens>
        </chunking>
        <chunking id="16" string="is set in the First World War in German East Africa" type="VP">
          <tokens>
            <token id="24" string="is" />
            <token id="25" string="set" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="First" />
            <token id="29" string="World" />
            <token id="30" string="War" />
            <token id="31" string="in" />
            <token id="32" string="German" />
            <token id="33" string="East" />
            <token id="34" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="17" string="set in the First World War in German East Africa" type="VP">
          <tokens>
            <token id="25" string="set" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="First" />
            <token id="29" string="World" />
            <token id="30" string="War" />
            <token id="31" string="in" />
            <token id="32" string="German" />
            <token id="33" string="East" />
            <token id="34" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="18" string="Stevenson 's The Ebb Tide" type="NP">
          <tokens>
            <token id="12" string="Stevenson" />
            <token id="13" string="'s" />
            <token id="14" string="The" />
            <token id="15" string="Ebb" />
            <token id="16" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="19" string="The Ebb" type="NP">
          <tokens>
            <token id="14" string="The" />
            <token id="15" string="Ebb" />
          </tokens>
        </chunking>
        <chunking id="20" string="Both , for instance ," type="NP">
          <tokens>
            <token id="1" string="Both" />
            <token id="2" string="," />
            <token id="3" string="for" />
            <token id="4" string="instance" />
            <token id="5" string="," />
          </tokens>
        </chunking>
        <chunking id="21" string="books about colonial exploitation - Stevenson 's The Ebb Tide and Abdulrazak Gurnah 's Paradise , which is set in the First World War in German East Africa" type="NP">
          <tokens>
            <token id="7" string="books" />
            <token id="8" string="about" />
            <token id="9" string="colonial" />
            <token id="10" string="exploitation" />
            <token id="11" string="-" />
            <token id="12" string="Stevenson" />
            <token id="13" string="'s" />
            <token id="14" string="The" />
            <token id="15" string="Ebb" />
            <token id="16" string="Tide" />
            <token id="17" string="and" />
            <token id="18" string="Abdulrazak" />
            <token id="19" string="Gurnah" />
            <token id="20" string="'s" />
            <token id="21" string="Paradise" />
            <token id="22" string="," />
            <token id="23" string="which" />
            <token id="24" string="is" />
            <token id="25" string="set" />
            <token id="26" string="in" />
            <token id="27" string="the" />
            <token id="28" string="First" />
            <token id="29" string="World" />
            <token id="30" string="War" />
            <token id="31" string="in" />
            <token id="32" string="German" />
            <token id="33" string="East" />
            <token id="34" string="Africa" />
          </tokens>
        </chunking>
        <chunking id="22" string="Stevenson 's" type="NP">
          <tokens>
            <token id="12" string="Stevenson" />
            <token id="13" string="'s" />
          </tokens>
        </chunking>
        <chunking id="23" string="Both" type="NP">
          <tokens>
            <token id="1" string="Both" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">have</governor>
          <dependent id="1">Both</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">instance</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Both</governor>
          <dependent id="4">instance</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">have</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">have</governor>
          <dependent id="7">books</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">exploitation</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">exploitation</governor>
          <dependent id="9">colonial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">books</governor>
          <dependent id="10">exploitation</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">books</governor>
          <dependent id="12">Stevenson</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Stevenson</governor>
          <dependent id="13">'s</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Ebb</governor>
          <dependent id="14">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="12">Stevenson</governor>
          <dependent id="15">Ebb</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="15">Ebb</governor>
          <dependent id="16">Tide</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">books</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Gurnah</governor>
          <dependent id="18">Abdulrazak</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">Paradise</governor>
          <dependent id="19">Gurnah</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Gurnah</governor>
          <dependent id="20">'s</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">books</governor>
          <dependent id="21">Paradise</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="25">set</governor>
          <dependent id="23">which</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="25">set</governor>
          <dependent id="24">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">Paradise</governor>
          <dependent id="25">set</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">War</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">War</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">War</governor>
          <dependent id="28">First</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">War</governor>
          <dependent id="29">World</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">set</governor>
          <dependent id="30">War</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">Africa</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Africa</governor>
          <dependent id="32">German</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">Africa</governor>
          <dependent id="33">East</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">War</governor>
          <dependent id="34">Africa</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Abdulrazak Gurnah" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Abdulrazak" />
            <token id="19" string="Gurnah" />
          </tokens>
        </entity>
        <entity id="2" string="First" type="ORDINAL" score="0.0">
          <tokens>
            <token id="28" string="First" />
          </tokens>
        </entity>
        <entity id="3" string="Ebb Tide" type="MISC" score="0.0">
          <tokens>
            <token id="15" string="Ebb" />
            <token id="16" string="Tide" />
          </tokens>
        </entity>
        <entity id="4" string="German" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="32" string="German" />
          </tokens>
        </entity>
        <entity id="5" string="Stevenson" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Stevenson" />
          </tokens>
        </entity>
        <entity id="6" string="World War" type="MISC" score="0.0">
          <tokens>
            <token id="29" string="World" />
            <token id="30" string="War" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="false">
      <content>Both provoke in similar ways.</content>
      <tokens>
        <token id="1" string="Both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="provoke" lemma="provoke" stem="provok" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="ways" lemma="way" stem="wai" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Both)) (VP (VBP provoke) (PP (IN in) (NP (JJ similar) (NNS ways)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="provoke in similar ways" type="VP">
          <tokens>
            <token id="2" string="provoke" />
            <token id="3" string="in" />
            <token id="4" string="similar" />
            <token id="5" string="ways" />
          </tokens>
        </chunking>
        <chunking id="2" string="similar ways" type="NP">
          <tokens>
            <token id="4" string="similar" />
            <token id="5" string="ways" />
          </tokens>
        </chunking>
        <chunking id="3" string="Both" type="NP">
          <tokens>
            <token id="1" string="Both" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">provoke</governor>
          <dependent id="1">Both</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">provoke</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">ways</governor>
          <dependent id="3">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">ways</governor>
          <dependent id="4">similar</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">provoke</governor>
          <dependent id="5">ways</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>The controversial books of 1894 were Trilby, with its louche vie boheme milieu, and Esther Waters, in which a 17-year-old girl is seduced, impregnated and offered the services of a professional baby killer for a fiver.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="controversial" lemma="controversial" stem="controversi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="6" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Trilby" lemma="Trilby" stem="trilbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="louche" lemma="louche" stem="louch" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="vie" lemma="vie" stem="vie" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="boheme" lemma="boheme" stem="bohem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="milieu" lemma="milieu" stem="milieu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Esther" lemma="Esther" stem="esther" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="18" string="Waters" lemma="Waters" stem="water" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="17-year-old" lemma="17-year-old" stem="17-year-old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="24" string="girl" lemma="girl" stem="girl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="seduced" lemma="seduce" stem="seduc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="impregnated" lemma="impregnate" stem="impregn" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="offered" lemma="offer" stem="offer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="services" lemma="service" stem="servic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="professional" lemma="professional" stem="profession" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="baby" lemma="baby" stem="babi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="killer" lemma="killer" stem="killer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="fiver" lemma="fiver" stem="fiver" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (JJ controversial) (NNS books)) (PP (IN of) (NP (CD 1894)))) (VP (VBD were) (NP (NNP Trilby)) (, ,) (PP (IN with) (NP (PRP$ its) (JJ louche) (NN vie) (NN boheme) (NN milieu))))) (, ,) (CC and) (S (NP (NP (NNP Esther) (NNP Waters)) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (DT a) (JJ 17-year-old) (NN girl)) (VP (VBZ is) (VP (VBN seduced))))) (, ,)) (VP (VP (VBN impregnated)) (CC and) (VP (VBN offered) (NP (NP (DT the) (NNS services)) (PP (IN of) (NP (NP (DT a) (JJ professional) (NN baby) (NN killer)) (PP (IN for) (NP (DT a) (NN fiver))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="its louche vie boheme milieu" type="NP">
          <tokens>
            <token id="10" string="its" />
            <token id="11" string="louche" />
            <token id="12" string="vie" />
            <token id="13" string="boheme" />
            <token id="14" string="milieu" />
          </tokens>
        </chunking>
        <chunking id="2" string="seduced" type="VP">
          <tokens>
            <token id="26" string="seduced" />
          </tokens>
        </chunking>
        <chunking id="3" string="a fiver" type="NP">
          <tokens>
            <token id="39" string="a" />
            <token id="40" string="fiver" />
          </tokens>
        </chunking>
        <chunking id="4" string="The controversial books of 1894" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="controversial" />
            <token id="3" string="books" />
            <token id="4" string="of" />
            <token id="5" string="1894" />
          </tokens>
        </chunking>
        <chunking id="5" string="Esther Waters" type="NP">
          <tokens>
            <token id="17" string="Esther" />
            <token id="18" string="Waters" />
          </tokens>
        </chunking>
        <chunking id="6" string="is seduced" type="VP">
          <tokens>
            <token id="25" string="is" />
            <token id="26" string="seduced" />
          </tokens>
        </chunking>
        <chunking id="7" string="the services" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="services" />
          </tokens>
        </chunking>
        <chunking id="8" string="impregnated" type="VP">
          <tokens>
            <token id="28" string="impregnated" />
          </tokens>
        </chunking>
        <chunking id="9" string="impregnated and offered the services of a professional baby killer for a fiver" type="VP">
          <tokens>
            <token id="28" string="impregnated" />
            <token id="29" string="and" />
            <token id="30" string="offered" />
            <token id="31" string="the" />
            <token id="32" string="services" />
            <token id="33" string="of" />
            <token id="34" string="a" />
            <token id="35" string="professional" />
            <token id="36" string="baby" />
            <token id="37" string="killer" />
            <token id="38" string="for" />
            <token id="39" string="a" />
            <token id="40" string="fiver" />
          </tokens>
        </chunking>
        <chunking id="10" string="a professional baby killer for a fiver" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="professional" />
            <token id="36" string="baby" />
            <token id="37" string="killer" />
            <token id="38" string="for" />
            <token id="39" string="a" />
            <token id="40" string="fiver" />
          </tokens>
        </chunking>
        <chunking id="11" string="a professional baby killer" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="professional" />
            <token id="36" string="baby" />
            <token id="37" string="killer" />
          </tokens>
        </chunking>
        <chunking id="12" string="in which a 17-year-old girl is seduced" type="SBAR">
          <tokens>
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="a" />
            <token id="23" string="17-year-old" />
            <token id="24" string="girl" />
            <token id="25" string="is" />
            <token id="26" string="seduced" />
          </tokens>
        </chunking>
        <chunking id="13" string="a 17-year-old girl" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="17-year-old" />
            <token id="24" string="girl" />
          </tokens>
        </chunking>
        <chunking id="14" string="were Trilby , with its louche vie boheme milieu" type="VP">
          <tokens>
            <token id="6" string="were" />
            <token id="7" string="Trilby" />
            <token id="8" string="," />
            <token id="9" string="with" />
            <token id="10" string="its" />
            <token id="11" string="louche" />
            <token id="12" string="vie" />
            <token id="13" string="boheme" />
            <token id="14" string="milieu" />
          </tokens>
        </chunking>
        <chunking id="15" string="offered the services of a professional baby killer for a fiver" type="VP">
          <tokens>
            <token id="30" string="offered" />
            <token id="31" string="the" />
            <token id="32" string="services" />
            <token id="33" string="of" />
            <token id="34" string="a" />
            <token id="35" string="professional" />
            <token id="36" string="baby" />
            <token id="37" string="killer" />
            <token id="38" string="for" />
            <token id="39" string="a" />
            <token id="40" string="fiver" />
          </tokens>
        </chunking>
        <chunking id="16" string="Esther Waters , in which a 17-year-old girl is seduced ," type="NP">
          <tokens>
            <token id="17" string="Esther" />
            <token id="18" string="Waters" />
            <token id="19" string="," />
            <token id="20" string="in" />
            <token id="21" string="which" />
            <token id="22" string="a" />
            <token id="23" string="17-year-old" />
            <token id="24" string="girl" />
            <token id="25" string="is" />
            <token id="26" string="seduced" />
            <token id="27" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="1894" type="NP">
          <tokens>
            <token id="5" string="1894" />
          </tokens>
        </chunking>
        <chunking id="18" string="Trilby" type="NP">
          <tokens>
            <token id="7" string="Trilby" />
          </tokens>
        </chunking>
        <chunking id="19" string="the services of a professional baby killer for a fiver" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="services" />
            <token id="33" string="of" />
            <token id="34" string="a" />
            <token id="35" string="professional" />
            <token id="36" string="baby" />
            <token id="37" string="killer" />
            <token id="38" string="for" />
            <token id="39" string="a" />
            <token id="40" string="fiver" />
          </tokens>
        </chunking>
        <chunking id="20" string="The controversial books" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="controversial" />
            <token id="3" string="books" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">books</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">books</governor>
          <dependent id="2">controversial</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">Trilby</governor>
          <dependent id="3">books</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">1894</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">books</governor>
          <dependent id="5">1894</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">Trilby</governor>
          <dependent id="6">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">Trilby</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">milieu</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">milieu</governor>
          <dependent id="10">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">milieu</governor>
          <dependent id="11">louche</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">milieu</governor>
          <dependent id="12">vie</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">milieu</governor>
          <dependent id="13">boheme</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">Trilby</governor>
          <dependent id="14">milieu</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">Trilby</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Waters</governor>
          <dependent id="17">Esther</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">impregnated</governor>
          <dependent id="18">Waters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">which</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">seduced</governor>
          <dependent id="21">which</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">girl</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">girl</governor>
          <dependent id="23">17-year-old</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="26">seduced</governor>
          <dependent id="24">girl</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="26">seduced</governor>
          <dependent id="25">is</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">Waters</governor>
          <dependent id="26">seduced</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">Trilby</governor>
          <dependent id="28">impregnated</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="28">impregnated</governor>
          <dependent id="29">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="28">impregnated</governor>
          <dependent id="30">offered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">services</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">offered</governor>
          <dependent id="32">services</dependent>
        </dependency>
        <dependency type="case">
          <governor id="37">killer</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="37">killer</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="37">killer</governor>
          <dependent id="35">professional</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="37">killer</governor>
          <dependent id="36">baby</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">services</governor>
          <dependent id="37">killer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="40">fiver</governor>
          <dependent id="38">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="40">fiver</governor>
          <dependent id="39">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">killer</governor>
          <dependent id="40">fiver</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="1894" />
          </tokens>
        </entity>
        <entity id="2" string="17-year-old" type="DURATION" score="0.0">
          <tokens>
            <token id="23" string="17-year-old" />
          </tokens>
        </entity>
        <entity id="3" string="Esther Waters" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Esther" />
            <token id="18" string="Waters" />
          </tokens>
        </entity>
        <entity id="4" string="Trilby" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Trilby" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>It is now seen as Moore&amp;apost;s best work, but in 1894 it had problems finding a publisher and the powerful circulating libraries refused to take it.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Moore" lemma="Moore" stem="moor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="best" lemma="best" stem="best" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="work" lemma="work" stem="work" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="14" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="problems" lemma="problem" stem="problem" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="finding" lemma="find" stem="find" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="publisher" lemma="publisher" stem="publish" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="powerful" lemma="powerful" stem="power" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="circulating" lemma="circulate" stem="circul" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="libraries" lemma="library" stem="librari" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="refused" lemma="refuse" stem="refus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (VBZ is) (ADVP (RB now)) (VP (VBN seen) (PP (IN as) (NP (NP (NNP Moore) (POS 's)) (JJS best) (NN work)))))) (, ,) (CC but) (S (PP (IN in) (NP (CD 1894))) (S (NP (PRP it)) (VP (VBD had) (NP (NP (NNS problems)) (VP (VBG finding) (NP (DT a) (NN publisher)))))) (CC and) (S (NP (NP (DT the) (JJ powerful)) (VP (VBG circulating) (NP (NNS libraries)))) (VP (VBD refused) (S (VP (TO to) (VP (VB take) (NP (PRP it)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="seen as Moore 's best work" type="VP">
          <tokens>
            <token id="4" string="seen" />
            <token id="5" string="as" />
            <token id="6" string="Moore" />
            <token id="7" string="'s" />
            <token id="8" string="best" />
            <token id="9" string="work" />
          </tokens>
        </chunking>
        <chunking id="2" string="Moore 's best work" type="NP">
          <tokens>
            <token id="6" string="Moore" />
            <token id="7" string="'s" />
            <token id="8" string="best" />
            <token id="9" string="work" />
          </tokens>
        </chunking>
        <chunking id="3" string="is now seen as Moore 's best work" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="now" />
            <token id="4" string="seen" />
            <token id="5" string="as" />
            <token id="6" string="Moore" />
            <token id="7" string="'s" />
            <token id="8" string="best" />
            <token id="9" string="work" />
          </tokens>
        </chunking>
        <chunking id="4" string="finding a publisher" type="VP">
          <tokens>
            <token id="17" string="finding" />
            <token id="18" string="a" />
            <token id="19" string="publisher" />
          </tokens>
        </chunking>
        <chunking id="5" string="Moore 's" type="NP">
          <tokens>
            <token id="6" string="Moore" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="a publisher" type="NP">
          <tokens>
            <token id="18" string="a" />
            <token id="19" string="publisher" />
          </tokens>
        </chunking>
        <chunking id="7" string="take it" type="VP">
          <tokens>
            <token id="27" string="take" />
            <token id="28" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="libraries" type="NP">
          <tokens>
            <token id="24" string="libraries" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="14" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="circulating libraries" type="VP">
          <tokens>
            <token id="23" string="circulating" />
            <token id="24" string="libraries" />
          </tokens>
        </chunking>
        <chunking id="12" string="had problems finding a publisher" type="VP">
          <tokens>
            <token id="15" string="had" />
            <token id="16" string="problems" />
            <token id="17" string="finding" />
            <token id="18" string="a" />
            <token id="19" string="publisher" />
          </tokens>
        </chunking>
        <chunking id="13" string="1894" type="NP">
          <tokens>
            <token id="13" string="1894" />
          </tokens>
        </chunking>
        <chunking id="14" string="the powerful circulating libraries" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="powerful" />
            <token id="23" string="circulating" />
            <token id="24" string="libraries" />
          </tokens>
        </chunking>
        <chunking id="15" string="problems" type="NP">
          <tokens>
            <token id="16" string="problems" />
          </tokens>
        </chunking>
        <chunking id="16" string="to take it" type="VP">
          <tokens>
            <token id="26" string="to" />
            <token id="27" string="take" />
            <token id="28" string="it" />
          </tokens>
        </chunking>
        <chunking id="17" string="problems finding a publisher" type="NP">
          <tokens>
            <token id="16" string="problems" />
            <token id="17" string="finding" />
            <token id="18" string="a" />
            <token id="19" string="publisher" />
          </tokens>
        </chunking>
        <chunking id="18" string="the powerful" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="powerful" />
          </tokens>
        </chunking>
        <chunking id="19" string="refused to take it" type="VP">
          <tokens>
            <token id="25" string="refused" />
            <token id="26" string="to" />
            <token id="27" string="take" />
            <token id="28" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="4">seen</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">seen</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">seen</governor>
          <dependent id="3">now</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">seen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">work</governor>
          <dependent id="5">as</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">work</governor>
          <dependent id="6">Moore</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Moore</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">work</governor>
          <dependent id="8">best</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">seen</governor>
          <dependent id="9">work</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">seen</governor>
          <dependent id="11">but</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">1894</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">had</governor>
          <dependent id="13">1894</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">had</governor>
          <dependent id="14">it</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">seen</governor>
          <dependent id="15">had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">had</governor>
          <dependent id="16">problems</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="16">problems</governor>
          <dependent id="17">finding</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">publisher</governor>
          <dependent id="18">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">finding</governor>
          <dependent id="19">publisher</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">had</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">powerful</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">refused</governor>
          <dependent id="22">powerful</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="22">powerful</governor>
          <dependent id="23">circulating</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">circulating</governor>
          <dependent id="24">libraries</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">had</governor>
          <dependent id="25">refused</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="27">take</governor>
          <dependent id="26">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">refused</governor>
          <dependent id="27">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="27">take</governor>
          <dependent id="28">it</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="13" string="1894" />
          </tokens>
        </entity>
        <entity id="3" string="Moore" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Moore" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="20" has_coreference="false">
      <content>A century on, the relationship between fiction and sexual morality remains vexed.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="2" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="relationship" lemma="relationship" stem="relationship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="sexual" lemma="sexual" stem="sexual" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="morality" lemma="morality" stem="moral" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="remains" lemma="remain" stem="remain" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="vexed" lemma="vexed" stem="vex" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (NP (DT A) (NN century)) (IN on)) (, ,) (NP (NP (DT the) (NN relationship)) (PP (IN between) (NP (NN fiction) (CC and) (JJ sexual) (NN morality)))) (VP (VBZ remains) (ADJP (JJ vexed))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fiction and sexual morality" type="NP">
          <tokens>
            <token id="8" string="fiction" />
            <token id="9" string="and" />
            <token id="10" string="sexual" />
            <token id="11" string="morality" />
          </tokens>
        </chunking>
        <chunking id="2" string="remains vexed" type="VP">
          <tokens>
            <token id="12" string="remains" />
            <token id="13" string="vexed" />
          </tokens>
        </chunking>
        <chunking id="3" string="the relationship" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="relationship" />
          </tokens>
        </chunking>
        <chunking id="4" string="A century" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="century" />
          </tokens>
        </chunking>
        <chunking id="5" string="the relationship between fiction and sexual morality" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="relationship" />
            <token id="7" string="between" />
            <token id="8" string="fiction" />
            <token id="9" string="and" />
            <token id="10" string="sexual" />
            <token id="11" string="morality" />
          </tokens>
        </chunking>
        <chunking id="6" string="vexed" type="ADJP">
          <tokens>
            <token id="13" string="vexed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">century</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">remains</governor>
          <dependent id="2">century</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">century</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">relationship</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">remains</governor>
          <dependent id="6">relationship</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">morality</governor>
          <dependent id="7">between</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">morality</governor>
          <dependent id="8">fiction</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">fiction</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">fiction</governor>
          <dependent id="10">sexual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">relationship</governor>
          <dependent id="11">morality</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">remains</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">remains</governor>
          <dependent id="13">vexed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="A century" type="DURATION" score="0.0">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="century" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Last week, a Times critic complained about the inclusion of Alan Hollinghurst&amp;apost;s candid novel of homosexual love, The Folding Star, on the Booker list, because it offended Judaeo-Christian ethics.</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="2" string="week" lemma="week" stem="week" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Times" lemma="Times" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="6" string="critic" lemma="critic" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="complained" lemma="complain" stem="complain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="inclusion" lemma="inclusion" stem="inclus" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Alan" lemma="Alan" stem="alan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="Hollinghurst" lemma="Hollinghurst" stem="hollinghurst" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="candid" lemma="candid" stem="candid" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="homosexual" lemma="homosexual" stem="homosexu" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="love" lemma="love" stem="love" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="Folding" lemma="Folding" stem="fold" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="Star" lemma="Star" stem="star" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="offended" lemma="offend" stem="offend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="Judaeo-Christian" lemma="judaeo-christian" stem="judaeo-christian" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="34" string="ethics" lemma="ethic" stem="ethic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (JJ Last) (NN week)) (, ,) (NP (DT a) (NNP Times) (NN critic)) (VP (VBD complained) (PP (IN about) (NP (NP (DT the) (NN inclusion)) (PP (IN of) (NP (NP (NP (NNP Alan) (NNP Hollinghurst) (POS 's)) (ADJP (JJ candid)) (NN novel)) (PP (IN of) (NP (NP (JJ homosexual) (NN love)) (, ,) (NP (DT The) (NNP Folding) (NNP Star)) (, ,))))))) (PP (IN on) (NP (DT the) (NNP Booker) (NN list))) (, ,) (SBAR (IN because) (S (NP (PRP it)) (VP (VBD offended) (NP (JJ Judaeo-Christian) (NNS ethics)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="homosexual love" type="NP">
          <tokens>
            <token id="18" string="homosexual" />
            <token id="19" string="love" />
          </tokens>
        </chunking>
        <chunking id="2" string="Alan Hollinghurst 's" type="NP">
          <tokens>
            <token id="12" string="Alan" />
            <token id="13" string="Hollinghurst" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="the inclusion of Alan Hollinghurst 's candid novel of homosexual love , The Folding Star ," type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="inclusion" />
            <token id="11" string="of" />
            <token id="12" string="Alan" />
            <token id="13" string="Hollinghurst" />
            <token id="14" string="'s" />
            <token id="15" string="candid" />
            <token id="16" string="novel" />
            <token id="17" string="of" />
            <token id="18" string="homosexual" />
            <token id="19" string="love" />
            <token id="20" string="," />
            <token id="21" string="The" />
            <token id="22" string="Folding" />
            <token id="23" string="Star" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="Alan Hollinghurst 's candid novel" type="NP">
          <tokens>
            <token id="12" string="Alan" />
            <token id="13" string="Hollinghurst" />
            <token id="14" string="'s" />
            <token id="15" string="candid" />
            <token id="16" string="novel" />
          </tokens>
        </chunking>
        <chunking id="5" string="offended Judaeo-Christian ethics" type="VP">
          <tokens>
            <token id="32" string="offended" />
            <token id="33" string="Judaeo-Christian" />
            <token id="34" string="ethics" />
          </tokens>
        </chunking>
        <chunking id="6" string="Alan Hollinghurst 's candid novel of homosexual love , The Folding Star ," type="NP">
          <tokens>
            <token id="12" string="Alan" />
            <token id="13" string="Hollinghurst" />
            <token id="14" string="'s" />
            <token id="15" string="candid" />
            <token id="16" string="novel" />
            <token id="17" string="of" />
            <token id="18" string="homosexual" />
            <token id="19" string="love" />
            <token id="20" string="," />
            <token id="21" string="The" />
            <token id="22" string="Folding" />
            <token id="23" string="Star" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="31" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="the inclusion" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="inclusion" />
          </tokens>
        </chunking>
        <chunking id="9" string="homosexual love , The Folding Star ," type="NP">
          <tokens>
            <token id="18" string="homosexual" />
            <token id="19" string="love" />
            <token id="20" string="," />
            <token id="21" string="The" />
            <token id="22" string="Folding" />
            <token id="23" string="Star" />
            <token id="24" string="," />
          </tokens>
        </chunking>
        <chunking id="10" string="the Booker list" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="Booker" />
            <token id="28" string="list" />
          </tokens>
        </chunking>
        <chunking id="11" string="because it offended Judaeo-Christian ethics" type="SBAR">
          <tokens>
            <token id="30" string="because" />
            <token id="31" string="it" />
            <token id="32" string="offended" />
            <token id="33" string="Judaeo-Christian" />
            <token id="34" string="ethics" />
          </tokens>
        </chunking>
        <chunking id="12" string="a Times critic" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="Times" />
            <token id="6" string="critic" />
          </tokens>
        </chunking>
        <chunking id="13" string="candid" type="ADJP">
          <tokens>
            <token id="15" string="candid" />
          </tokens>
        </chunking>
        <chunking id="14" string="The Folding Star" type="NP">
          <tokens>
            <token id="21" string="The" />
            <token id="22" string="Folding" />
            <token id="23" string="Star" />
          </tokens>
        </chunking>
        <chunking id="15" string="complained about the inclusion of Alan Hollinghurst 's candid novel of homosexual love , The Folding Star , on the Booker list , because it offended Judaeo-Christian ethics" type="VP">
          <tokens>
            <token id="7" string="complained" />
            <token id="8" string="about" />
            <token id="9" string="the" />
            <token id="10" string="inclusion" />
            <token id="11" string="of" />
            <token id="12" string="Alan" />
            <token id="13" string="Hollinghurst" />
            <token id="14" string="'s" />
            <token id="15" string="candid" />
            <token id="16" string="novel" />
            <token id="17" string="of" />
            <token id="18" string="homosexual" />
            <token id="19" string="love" />
            <token id="20" string="," />
            <token id="21" string="The" />
            <token id="22" string="Folding" />
            <token id="23" string="Star" />
            <token id="24" string="," />
            <token id="25" string="on" />
            <token id="26" string="the" />
            <token id="27" string="Booker" />
            <token id="28" string="list" />
            <token id="29" string="," />
            <token id="30" string="because" />
            <token id="31" string="it" />
            <token id="32" string="offended" />
            <token id="33" string="Judaeo-Christian" />
            <token id="34" string="ethics" />
          </tokens>
        </chunking>
        <chunking id="16" string="Judaeo-Christian ethics" type="NP">
          <tokens>
            <token id="33" string="Judaeo-Christian" />
            <token id="34" string="ethics" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">week</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">complained</governor>
          <dependent id="2">week</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">critic</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">critic</governor>
          <dependent id="5">Times</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">complained</governor>
          <dependent id="6">critic</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">complained</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">inclusion</governor>
          <dependent id="8">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">inclusion</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">complained</governor>
          <dependent id="10">inclusion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">novel</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Hollinghurst</governor>
          <dependent id="12">Alan</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">novel</governor>
          <dependent id="13">Hollinghurst</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Hollinghurst</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">novel</governor>
          <dependent id="15">candid</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">inclusion</governor>
          <dependent id="16">novel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">love</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">love</governor>
          <dependent id="18">homosexual</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">novel</governor>
          <dependent id="19">love</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Star</governor>
          <dependent id="21">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Star</governor>
          <dependent id="22">Folding</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="19">love</governor>
          <dependent id="23">Star</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">list</governor>
          <dependent id="25">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">list</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">list</governor>
          <dependent id="27">Booker</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">complained</governor>
          <dependent id="28">list</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="32">offended</governor>
          <dependent id="30">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="32">offended</governor>
          <dependent id="31">it</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">complained</governor>
          <dependent id="32">offended</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">ethics</governor>
          <dependent id="33">Judaeo-Christian</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="32">offended</governor>
          <dependent id="34">ethics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Alan Hollinghurst" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Alan" />
            <token id="13" string="Hollinghurst" />
          </tokens>
        </entity>
        <entity id="2" string="Last week" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="week" />
          </tokens>
        </entity>
        <entity id="3" string="Times" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Times" />
          </tokens>
        </entity>
        <entity id="4" string="Judaeo-Christian" type="MISC" score="0.0">
          <tokens>
            <token id="33" string="Judaeo-Christian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>But even if Hollinghurst wins the Booker, his novel will not become the succes de scandale of Esther Waters and Trilby, which became the bestselling novel of the 19th century.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Hollinghurst" lemma="Hollinghurst" stem="hollinghurst" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="wins" lemma="win" stem="win" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="succes" lemma="succe" stem="succ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="de" lemma="de" stem="de" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="scandale" lemma="scandale" stem="scandal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Esther" lemma="Esther" stem="esther" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Waters" lemma="Waters" stem="water" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Trilby" lemma="Trilby" stem="trilbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="became" lemma="become" stem="becam" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="bestselling" lemma="bestselling" stem="bestsel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="31" string="19th" lemma="19th" stem="19th" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="32" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (SBAR (RB even) (IN if) (S (NP (NNP Hollinghurst)) (VP (VBZ wins) (NP (DT the) (NNP Booker))))) (, ,) (NP (PRP$ his) (NN novel)) (VP (MD will) (RB not) (VP (VB become) (NP (NP (DT the) (NNS succes)) (PP (IN de) (NP (NP (NN scandale)) (PP (IN of) (NP (NNP Esther) (NNP Waters) (CC and) (NNP Trilby))) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD became) (NP (NP (DT the) (JJ bestselling) (NN novel)) (PP (IN of) (NP (DT the) (JJ 19th) (NN century)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="scandale of Esther Waters and Trilby , which became the bestselling novel of the 19th century" type="NP">
          <tokens>
            <token id="17" string="scandale" />
            <token id="18" string="of" />
            <token id="19" string="Esther" />
            <token id="20" string="Waters" />
            <token id="21" string="and" />
            <token id="22" string="Trilby" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="became" />
            <token id="26" string="the" />
            <token id="27" string="bestselling" />
            <token id="28" string="novel" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="19th" />
            <token id="32" string="century" />
          </tokens>
        </chunking>
        <chunking id="2" string="scandale" type="NP">
          <tokens>
            <token id="17" string="scandale" />
          </tokens>
        </chunking>
        <chunking id="3" string="wins the Booker" type="VP">
          <tokens>
            <token id="5" string="wins" />
            <token id="6" string="the" />
            <token id="7" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Booker" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="5" string="Esther Waters and Trilby" type="NP">
          <tokens>
            <token id="19" string="Esther" />
            <token id="20" string="Waters" />
            <token id="21" string="and" />
            <token id="22" string="Trilby" />
          </tokens>
        </chunking>
        <chunking id="6" string="become the succes de scandale of Esther Waters and Trilby , which became the bestselling novel of the 19th century" type="VP">
          <tokens>
            <token id="13" string="become" />
            <token id="14" string="the" />
            <token id="15" string="succes" />
            <token id="16" string="de" />
            <token id="17" string="scandale" />
            <token id="18" string="of" />
            <token id="19" string="Esther" />
            <token id="20" string="Waters" />
            <token id="21" string="and" />
            <token id="22" string="Trilby" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="became" />
            <token id="26" string="the" />
            <token id="27" string="bestselling" />
            <token id="28" string="novel" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="19th" />
            <token id="32" string="century" />
          </tokens>
        </chunking>
        <chunking id="7" string="the succes" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="succes" />
          </tokens>
        </chunking>
        <chunking id="8" string="even if Hollinghurst wins the Booker" type="SBAR">
          <tokens>
            <token id="2" string="even" />
            <token id="3" string="if" />
            <token id="4" string="Hollinghurst" />
            <token id="5" string="wins" />
            <token id="6" string="the" />
            <token id="7" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="9" string="the 19th century" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="19th" />
            <token id="32" string="century" />
          </tokens>
        </chunking>
        <chunking id="10" string="the succes de scandale of Esther Waters and Trilby , which became the bestselling novel of the 19th century" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="succes" />
            <token id="16" string="de" />
            <token id="17" string="scandale" />
            <token id="18" string="of" />
            <token id="19" string="Esther" />
            <token id="20" string="Waters" />
            <token id="21" string="and" />
            <token id="22" string="Trilby" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="became" />
            <token id="26" string="the" />
            <token id="27" string="bestselling" />
            <token id="28" string="novel" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="19th" />
            <token id="32" string="century" />
          </tokens>
        </chunking>
        <chunking id="11" string="which became the bestselling novel of the 19th century" type="SBAR">
          <tokens>
            <token id="24" string="which" />
            <token id="25" string="became" />
            <token id="26" string="the" />
            <token id="27" string="bestselling" />
            <token id="28" string="novel" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="19th" />
            <token id="32" string="century" />
          </tokens>
        </chunking>
        <chunking id="12" string="will not become the succes de scandale of Esther Waters and Trilby , which became the bestselling novel of the 19th century" type="VP">
          <tokens>
            <token id="11" string="will" />
            <token id="12" string="not" />
            <token id="13" string="become" />
            <token id="14" string="the" />
            <token id="15" string="succes" />
            <token id="16" string="de" />
            <token id="17" string="scandale" />
            <token id="18" string="of" />
            <token id="19" string="Esther" />
            <token id="20" string="Waters" />
            <token id="21" string="and" />
            <token id="22" string="Trilby" />
            <token id="23" string="," />
            <token id="24" string="which" />
            <token id="25" string="became" />
            <token id="26" string="the" />
            <token id="27" string="bestselling" />
            <token id="28" string="novel" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="19th" />
            <token id="32" string="century" />
          </tokens>
        </chunking>
        <chunking id="13" string="the bestselling novel of the 19th century" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="bestselling" />
            <token id="28" string="novel" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="19th" />
            <token id="32" string="century" />
          </tokens>
        </chunking>
        <chunking id="14" string="the bestselling novel" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="bestselling" />
            <token id="28" string="novel" />
          </tokens>
        </chunking>
        <chunking id="15" string="became the bestselling novel of the 19th century" type="VP">
          <tokens>
            <token id="25" string="became" />
            <token id="26" string="the" />
            <token id="27" string="bestselling" />
            <token id="28" string="novel" />
            <token id="29" string="of" />
            <token id="30" string="the" />
            <token id="31" string="19th" />
            <token id="32" string="century" />
          </tokens>
        </chunking>
        <chunking id="16" string="Hollinghurst" type="NP">
          <tokens>
            <token id="4" string="Hollinghurst" />
          </tokens>
        </chunking>
        <chunking id="17" string="his novel" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="novel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="13">become</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">wins</governor>
          <dependent id="2">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">wins</governor>
          <dependent id="3">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">wins</governor>
          <dependent id="4">Hollinghurst</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">become</governor>
          <dependent id="5">wins</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Booker</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">wins</governor>
          <dependent id="7">Booker</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">novel</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">become</governor>
          <dependent id="10">novel</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">become</governor>
          <dependent id="11">will</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">become</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">become</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">succes</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">become</governor>
          <dependent id="15">succes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">scandale</governor>
          <dependent id="16">de</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">succes</governor>
          <dependent id="17">scandale</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Waters</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Waters</governor>
          <dependent id="19">Esther</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">scandale</governor>
          <dependent id="20">Waters</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">Waters</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">Waters</governor>
          <dependent id="22">Trilby</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">became</governor>
          <dependent id="24">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">scandale</governor>
          <dependent id="25">became</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">novel</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">novel</governor>
          <dependent id="27">bestselling</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="25">became</governor>
          <dependent id="28">novel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">century</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">century</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">century</governor>
          <dependent id="31">19th</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">novel</governor>
          <dependent id="32">century</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the 19th century" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="19th" />
            <token id="32" string="century" />
          </tokens>
        </entity>
        <entity id="2" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Booker" />
          </tokens>
        </entity>
        <entity id="3" string="Esther Waters" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Esther" />
            <token id="20" string="Waters" />
          </tokens>
        </entity>
        <entity id="4" string="Trilby" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Trilby" />
          </tokens>
        </entity>
        <entity id="5" string="Hollinghurst" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Hollinghurst" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>For the great difference between then and now is that in 1894 a Booker Prize was not needed to sell fiction.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="difference" lemma="difference" stem="differ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="then" lemma="then" stem="then" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="15" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="needed" lemma="need" stem="need" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="sell" lemma="sell" stem="sell" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (IN For) (NP (NP (DT the) (JJ great) (NN difference)) (PP (IN between) (NP (RB then) (CC and) (RB now)))) (VP (VBZ is) (SBAR (IN that) (S (PP (IN in) (NP (CD 1894))) (NP (DT a) (NNP Booker) (NNP Prize)) (VP (VBD was) (RB not) (VP (VBN needed) (S (VP (TO to) (VP (VB sell) (NP (NN fiction)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a Booker Prize" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="2" string="the great difference" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="great" />
            <token id="4" string="difference" />
          </tokens>
        </chunking>
        <chunking id="3" string="fiction" type="NP">
          <tokens>
            <token id="21" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="4" string="needed to sell fiction" type="VP">
          <tokens>
            <token id="18" string="needed" />
            <token id="19" string="to" />
            <token id="20" string="sell" />
            <token id="21" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="is that in 1894 a Booker Prize was not needed to sell fiction" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="that" />
            <token id="11" string="in" />
            <token id="12" string="1894" />
            <token id="13" string="a" />
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
            <token id="16" string="was" />
            <token id="17" string="not" />
            <token id="18" string="needed" />
            <token id="19" string="to" />
            <token id="20" string="sell" />
            <token id="21" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="6" string="that in 1894 a Booker Prize was not needed to sell fiction" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="in" />
            <token id="12" string="1894" />
            <token id="13" string="a" />
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
            <token id="16" string="was" />
            <token id="17" string="not" />
            <token id="18" string="needed" />
            <token id="19" string="to" />
            <token id="20" string="sell" />
            <token id="21" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="7" string="1894" type="NP">
          <tokens>
            <token id="12" string="1894" />
          </tokens>
        </chunking>
        <chunking id="8" string="then and now" type="NP">
          <tokens>
            <token id="6" string="then" />
            <token id="7" string="and" />
            <token id="8" string="now" />
          </tokens>
        </chunking>
        <chunking id="9" string="was not needed to sell fiction" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="not" />
            <token id="18" string="needed" />
            <token id="19" string="to" />
            <token id="20" string="sell" />
            <token id="21" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="10" string="the great difference between then and now" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="great" />
            <token id="4" string="difference" />
            <token id="5" string="between" />
            <token id="6" string="then" />
            <token id="7" string="and" />
            <token id="8" string="now" />
          </tokens>
        </chunking>
        <chunking id="11" string="to sell fiction" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="sell" />
            <token id="21" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="12" string="sell fiction" type="VP">
          <tokens>
            <token id="20" string="sell" />
            <token id="21" string="fiction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="dep">
          <governor id="9">is</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">difference</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">difference</governor>
          <dependent id="3">great</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">is</governor>
          <dependent id="4">difference</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">then</governor>
          <dependent id="5">between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">difference</governor>
          <dependent id="6">then</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">then</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">then</governor>
          <dependent id="8">now</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">needed</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">1894</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">needed</governor>
          <dependent id="12">1894</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Prize</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Prize</governor>
          <dependent id="14">Booker</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">needed</governor>
          <dependent id="15">Prize</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">needed</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">needed</governor>
          <dependent id="17">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">is</governor>
          <dependent id="18">needed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">sell</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">needed</governor>
          <dependent id="20">sell</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">sell</governor>
          <dependent id="21">fiction</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1894" />
          </tokens>
        </entity>
        <entity id="3" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="14" string="Booker" />
            <token id="15" string="Prize" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Today, we accept the gap between literary writing, such as Hollinghurst&amp;apost;s, and popular bestsellers by writers like Jeffrey Archer and Barbara Cartland.</content>
      <tokens>
        <token id="1" string="Today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="accept" lemma="accept" stem="accept" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="gap" lemma="gap" stem="gap" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="literary" lemma="literary" stem="literari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="writing" lemma="writing" stem="write" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Hollinghurst" lemma="Hollinghurst" stem="hollinghurst" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="popular" lemma="popular" stem="popular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="bestsellers" lemma="bestseller" stem="bestsel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="writers" lemma="writer" stem="writer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="Jeffrey" lemma="Jeffrey" stem="jeffrei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="23" string="Archer" lemma="Archer" stem="archer" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Barbara" lemma="Barbara" stem="barbara" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="Cartland" lemma="Cartland" stem="cartland" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (NN Today)) (, ,) (NP (PRP we)) (VP (VBP accept) (NP (NP (NP (DT the) (NN gap)) (PP (IN between) (NP (JJ literary) (NN writing))) (, ,) (PP (JJ such) (IN as) (NP (NNP Hollinghurst) (POS 's)))) (, ,) (CC and) (NP (NP (JJ popular) (NNS bestsellers)) (PP (IN by) (NP (NP (NNS writers)) (PP (IN like) (NP (NP (NNP Jeffrey) (NNP Archer)) (CC and) (NP (NNP Barbara) (NNP Cartland))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Hollinghurst 's" type="NP">
          <tokens>
            <token id="13" string="Hollinghurst" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="the gap between literary writing , such as Hollinghurst 's , and popular bestsellers by writers like Jeffrey Archer and Barbara Cartland" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="gap" />
            <token id="7" string="between" />
            <token id="8" string="literary" />
            <token id="9" string="writing" />
            <token id="10" string="," />
            <token id="11" string="such" />
            <token id="12" string="as" />
            <token id="13" string="Hollinghurst" />
            <token id="14" string="'s" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="popular" />
            <token id="18" string="bestsellers" />
            <token id="19" string="by" />
            <token id="20" string="writers" />
            <token id="21" string="like" />
            <token id="22" string="Jeffrey" />
            <token id="23" string="Archer" />
            <token id="24" string="and" />
            <token id="25" string="Barbara" />
            <token id="26" string="Cartland" />
          </tokens>
        </chunking>
        <chunking id="3" string="literary writing" type="NP">
          <tokens>
            <token id="8" string="literary" />
            <token id="9" string="writing" />
          </tokens>
        </chunking>
        <chunking id="4" string="popular bestsellers by writers like Jeffrey Archer and Barbara Cartland" type="NP">
          <tokens>
            <token id="17" string="popular" />
            <token id="18" string="bestsellers" />
            <token id="19" string="by" />
            <token id="20" string="writers" />
            <token id="21" string="like" />
            <token id="22" string="Jeffrey" />
            <token id="23" string="Archer" />
            <token id="24" string="and" />
            <token id="25" string="Barbara" />
            <token id="26" string="Cartland" />
          </tokens>
        </chunking>
        <chunking id="5" string="writers like Jeffrey Archer and Barbara Cartland" type="NP">
          <tokens>
            <token id="20" string="writers" />
            <token id="21" string="like" />
            <token id="22" string="Jeffrey" />
            <token id="23" string="Archer" />
            <token id="24" string="and" />
            <token id="25" string="Barbara" />
            <token id="26" string="Cartland" />
          </tokens>
        </chunking>
        <chunking id="6" string="Jeffrey Archer" type="NP">
          <tokens>
            <token id="22" string="Jeffrey" />
            <token id="23" string="Archer" />
          </tokens>
        </chunking>
        <chunking id="7" string="Jeffrey Archer and Barbara Cartland" type="NP">
          <tokens>
            <token id="22" string="Jeffrey" />
            <token id="23" string="Archer" />
            <token id="24" string="and" />
            <token id="25" string="Barbara" />
            <token id="26" string="Cartland" />
          </tokens>
        </chunking>
        <chunking id="8" string="the gap" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="gap" />
          </tokens>
        </chunking>
        <chunking id="9" string="we" type="NP">
          <tokens>
            <token id="3" string="we" />
          </tokens>
        </chunking>
        <chunking id="10" string="popular bestsellers" type="NP">
          <tokens>
            <token id="17" string="popular" />
            <token id="18" string="bestsellers" />
          </tokens>
        </chunking>
        <chunking id="11" string="writers" type="NP">
          <tokens>
            <token id="20" string="writers" />
          </tokens>
        </chunking>
        <chunking id="12" string="Barbara Cartland" type="NP">
          <tokens>
            <token id="25" string="Barbara" />
            <token id="26" string="Cartland" />
          </tokens>
        </chunking>
        <chunking id="13" string="the gap between literary writing , such as Hollinghurst 's" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="gap" />
            <token id="7" string="between" />
            <token id="8" string="literary" />
            <token id="9" string="writing" />
            <token id="10" string="," />
            <token id="11" string="such" />
            <token id="12" string="as" />
            <token id="13" string="Hollinghurst" />
            <token id="14" string="'s" />
          </tokens>
        </chunking>
        <chunking id="14" string="accept the gap between literary writing , such as Hollinghurst 's , and popular bestsellers by writers like Jeffrey Archer and Barbara Cartland" type="VP">
          <tokens>
            <token id="4" string="accept" />
            <token id="5" string="the" />
            <token id="6" string="gap" />
            <token id="7" string="between" />
            <token id="8" string="literary" />
            <token id="9" string="writing" />
            <token id="10" string="," />
            <token id="11" string="such" />
            <token id="12" string="as" />
            <token id="13" string="Hollinghurst" />
            <token id="14" string="'s" />
            <token id="15" string="," />
            <token id="16" string="and" />
            <token id="17" string="popular" />
            <token id="18" string="bestsellers" />
            <token id="19" string="by" />
            <token id="20" string="writers" />
            <token id="21" string="like" />
            <token id="22" string="Jeffrey" />
            <token id="23" string="Archer" />
            <token id="24" string="and" />
            <token id="25" string="Barbara" />
            <token id="26" string="Cartland" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:tmod">
          <governor id="4">accept</governor>
          <dependent id="1">Today</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">accept</governor>
          <dependent id="3">we</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">accept</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">gap</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">accept</governor>
          <dependent id="6">gap</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">writing</governor>
          <dependent id="7">between</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">writing</governor>
          <dependent id="8">literary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">gap</governor>
          <dependent id="9">writing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Hollinghurst</governor>
          <dependent id="11">such</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="11">such</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">gap</governor>
          <dependent id="13">Hollinghurst</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Hollinghurst</governor>
          <dependent id="14">'s</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">gap</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">bestsellers</governor>
          <dependent id="17">popular</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">gap</governor>
          <dependent id="18">bestsellers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">writers</governor>
          <dependent id="19">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">bestsellers</governor>
          <dependent id="20">writers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Archer</governor>
          <dependent id="21">like</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Archer</governor>
          <dependent id="22">Jeffrey</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">writers</governor>
          <dependent id="23">Archer</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="23">Archer</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Cartland</governor>
          <dependent id="25">Barbara</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="23">Archer</governor>
          <dependent id="26">Cartland</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Today" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Today" />
          </tokens>
        </entity>
        <entity id="2" string="Barbara Cartland" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Barbara" />
            <token id="26" string="Cartland" />
          </tokens>
        </entity>
        <entity id="3" string="Jeffrey Archer" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Jeffrey" />
            <token id="23" string="Archer" />
          </tokens>
        </entity>
        <entity id="4" string="Hollinghurst" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Hollinghurst" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>This is the gap the Booker tries to bridge by giving high-level publicity to works which would not normally reach a mass audience.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="gap" lemma="gap" stem="gap" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="6" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="7" string="tries" lemma="try" stem="tri" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="bridge" lemma="bridge" stem="bridg" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="giving" lemma="give" stem="give" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="high-level" lemma="high-level" stem="high-level" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="publicity" lemma="publicity" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="works" lemma="work" stem="work" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="normally" lemma="normally" stem="normal" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="reach" lemma="reach" stem="reach" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="mass" lemma="mass" stem="mass" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="audience" lemma="audience" stem="audienc" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT This)) (VP (VBZ is) (NP (NP (DT the) (NN gap)) (SBAR (S (NP (DT the) (NNP Booker)) (VP (VBZ tries) (PP (TO to) (NP (NN bridge))) (PP (IN by) (S (VP (VBG giving) (NP (JJ high-level) (NN publicity)) (PP (TO to) (NP (NP (NNS works)) (SBAR (WHNP (WDT which)) (S (VP (MD would) (RB not) (ADVP (RB normally)) (VP (VB reach) (NP (DT a) (NN mass) (NN audience)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="works" type="NP">
          <tokens>
            <token id="15" string="works" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Booker tries to bridge by giving high-level publicity to works which would not normally reach a mass audience" type="SBAR">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Booker" />
            <token id="7" string="tries" />
            <token id="8" string="to" />
            <token id="9" string="bridge" />
            <token id="10" string="by" />
            <token id="11" string="giving" />
            <token id="12" string="high-level" />
            <token id="13" string="publicity" />
            <token id="14" string="to" />
            <token id="15" string="works" />
            <token id="16" string="which" />
            <token id="17" string="would" />
            <token id="18" string="not" />
            <token id="19" string="normally" />
            <token id="20" string="reach" />
            <token id="21" string="a" />
            <token id="22" string="mass" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Booker" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Booker" />
          </tokens>
        </chunking>
        <chunking id="4" string="is the gap the Booker tries to bridge by giving high-level publicity to works which would not normally reach a mass audience" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="the" />
            <token id="4" string="gap" />
            <token id="5" string="the" />
            <token id="6" string="Booker" />
            <token id="7" string="tries" />
            <token id="8" string="to" />
            <token id="9" string="bridge" />
            <token id="10" string="by" />
            <token id="11" string="giving" />
            <token id="12" string="high-level" />
            <token id="13" string="publicity" />
            <token id="14" string="to" />
            <token id="15" string="works" />
            <token id="16" string="which" />
            <token id="17" string="would" />
            <token id="18" string="not" />
            <token id="19" string="normally" />
            <token id="20" string="reach" />
            <token id="21" string="a" />
            <token id="22" string="mass" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="5" string="the gap" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="gap" />
          </tokens>
        </chunking>
        <chunking id="6" string="the gap the Booker tries to bridge by giving high-level publicity to works which would not normally reach a mass audience" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="gap" />
            <token id="5" string="the" />
            <token id="6" string="Booker" />
            <token id="7" string="tries" />
            <token id="8" string="to" />
            <token id="9" string="bridge" />
            <token id="10" string="by" />
            <token id="11" string="giving" />
            <token id="12" string="high-level" />
            <token id="13" string="publicity" />
            <token id="14" string="to" />
            <token id="15" string="works" />
            <token id="16" string="which" />
            <token id="17" string="would" />
            <token id="18" string="not" />
            <token id="19" string="normally" />
            <token id="20" string="reach" />
            <token id="21" string="a" />
            <token id="22" string="mass" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="7" string="would not normally reach a mass audience" type="VP">
          <tokens>
            <token id="17" string="would" />
            <token id="18" string="not" />
            <token id="19" string="normally" />
            <token id="20" string="reach" />
            <token id="21" string="a" />
            <token id="22" string="mass" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="8" string="giving high-level publicity to works which would not normally reach a mass audience" type="VP">
          <tokens>
            <token id="11" string="giving" />
            <token id="12" string="high-level" />
            <token id="13" string="publicity" />
            <token id="14" string="to" />
            <token id="15" string="works" />
            <token id="16" string="which" />
            <token id="17" string="would" />
            <token id="18" string="not" />
            <token id="19" string="normally" />
            <token id="20" string="reach" />
            <token id="21" string="a" />
            <token id="22" string="mass" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="9" string="high-level publicity" type="NP">
          <tokens>
            <token id="12" string="high-level" />
            <token id="13" string="publicity" />
          </tokens>
        </chunking>
        <chunking id="10" string="reach a mass audience" type="VP">
          <tokens>
            <token id="20" string="reach" />
            <token id="21" string="a" />
            <token id="22" string="mass" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="11" string="tries to bridge by giving high-level publicity to works which would not normally reach a mass audience" type="VP">
          <tokens>
            <token id="7" string="tries" />
            <token id="8" string="to" />
            <token id="9" string="bridge" />
            <token id="10" string="by" />
            <token id="11" string="giving" />
            <token id="12" string="high-level" />
            <token id="13" string="publicity" />
            <token id="14" string="to" />
            <token id="15" string="works" />
            <token id="16" string="which" />
            <token id="17" string="would" />
            <token id="18" string="not" />
            <token id="19" string="normally" />
            <token id="20" string="reach" />
            <token id="21" string="a" />
            <token id="22" string="mass" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="12" string="a mass audience" type="NP">
          <tokens>
            <token id="21" string="a" />
            <token id="22" string="mass" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="13" string="works which would not normally reach a mass audience" type="NP">
          <tokens>
            <token id="15" string="works" />
            <token id="16" string="which" />
            <token id="17" string="would" />
            <token id="18" string="not" />
            <token id="19" string="normally" />
            <token id="20" string="reach" />
            <token id="21" string="a" />
            <token id="22" string="mass" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="14" string="which would not normally reach a mass audience" type="SBAR">
          <tokens>
            <token id="16" string="which" />
            <token id="17" string="would" />
            <token id="18" string="not" />
            <token id="19" string="normally" />
            <token id="20" string="reach" />
            <token id="21" string="a" />
            <token id="22" string="mass" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="15" string="This" type="NP">
          <tokens>
            <token id="1" string="This" />
          </tokens>
        </chunking>
        <chunking id="16" string="bridge" type="NP">
          <tokens>
            <token id="9" string="bridge" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">gap</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">gap</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">gap</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">gap</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Booker</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">tries</governor>
          <dependent id="6">Booker</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="4">gap</governor>
          <dependent id="7">tries</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">bridge</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">tries</governor>
          <dependent id="9">bridge</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">giving</governor>
          <dependent id="10">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">tries</governor>
          <dependent id="11">giving</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">publicity</governor>
          <dependent id="12">high-level</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">giving</governor>
          <dependent id="13">publicity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">works</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">giving</governor>
          <dependent id="15">works</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">reach</governor>
          <dependent id="16">which</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">reach</governor>
          <dependent id="17">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="20">reach</governor>
          <dependent id="18">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">reach</governor>
          <dependent id="19">normally</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="15">works</governor>
          <dependent id="20">reach</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">audience</governor>
          <dependent id="21">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">audience</governor>
          <dependent id="22">mass</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">reach</governor>
          <dependent id="23">audience</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Booker" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="false">
      <content>The trick works - last year&amp;apost;s winner, Roddy Doyle&amp;apost;s Paddy Clarke Ha Ha Ha sold 360,000 hardback copies.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="trick" lemma="trick" stem="trick" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="works" lemma="work" stem="work" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Roddy" lemma="Roddy" stem="roddi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="Doyle" lemma="Doyle" stem="doyl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Paddy" lemma="Paddy" stem="paddi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="14" string="Clarke" lemma="Clarke" stem="clark" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Ha" lemma="Ha" stem="ha" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="Ha" lemma="Ha" stem="ha" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="17" string="Ha" lemma="Ha" stem="ha" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="sold" lemma="sell" stem="sold" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="360,000" lemma="360,000" stem="360,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="20" string="hardback" lemma="hardback" stem="hardback" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="copies" lemma="copy" stem="copi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (NN trick)) (VP (VBZ works))) (: -) (S (NP (NP (NP (JJ last) (NN year) (POS 's)) (NN winner)) (, ,) (NP (NP (NNP Roddy) (NNP Doyle) (POS 's)) (NNP Paddy) (NNP Clarke) (NNP Ha) (NNP Ha) (NNP Ha))) (VP (VBD sold) (NP (CD 360,000) (NN hardback) (NNS copies)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="works" type="VP">
          <tokens>
            <token id="3" string="works" />
          </tokens>
        </chunking>
        <chunking id="2" string="last year 's" type="NP">
          <tokens>
            <token id="5" string="last" />
            <token id="6" string="year" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="The trick" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="trick" />
          </tokens>
        </chunking>
        <chunking id="4" string="Roddy Doyle 's Paddy Clarke Ha Ha Ha" type="NP">
          <tokens>
            <token id="10" string="Roddy" />
            <token id="11" string="Doyle" />
            <token id="12" string="'s" />
            <token id="13" string="Paddy" />
            <token id="14" string="Clarke" />
            <token id="15" string="Ha" />
            <token id="16" string="Ha" />
            <token id="17" string="Ha" />
          </tokens>
        </chunking>
        <chunking id="5" string="last year 's winner" type="NP">
          <tokens>
            <token id="5" string="last" />
            <token id="6" string="year" />
            <token id="7" string="'s" />
            <token id="8" string="winner" />
          </tokens>
        </chunking>
        <chunking id="6" string="last year 's winner , Roddy Doyle 's Paddy Clarke Ha Ha Ha" type="NP">
          <tokens>
            <token id="5" string="last" />
            <token id="6" string="year" />
            <token id="7" string="'s" />
            <token id="8" string="winner" />
            <token id="9" string="," />
            <token id="10" string="Roddy" />
            <token id="11" string="Doyle" />
            <token id="12" string="'s" />
            <token id="13" string="Paddy" />
            <token id="14" string="Clarke" />
            <token id="15" string="Ha" />
            <token id="16" string="Ha" />
            <token id="17" string="Ha" />
          </tokens>
        </chunking>
        <chunking id="7" string="Roddy Doyle 's" type="NP">
          <tokens>
            <token id="10" string="Roddy" />
            <token id="11" string="Doyle" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="sold 360,000 hardback copies" type="VP">
          <tokens>
            <token id="18" string="sold" />
            <token id="19" string="360,000" />
            <token id="20" string="hardback" />
            <token id="21" string="copies" />
          </tokens>
        </chunking>
        <chunking id="9" string="360,000 hardback copies" type="NP">
          <tokens>
            <token id="19" string="360,000" />
            <token id="20" string="hardback" />
            <token id="21" string="copies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">trick</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">works</governor>
          <dependent id="2">trick</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">works</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">year</governor>
          <dependent id="5">last</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">winner</governor>
          <dependent id="6">year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">year</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">sold</governor>
          <dependent id="8">winner</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Doyle</governor>
          <dependent id="10">Roddy</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">Ha</governor>
          <dependent id="11">Doyle</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Doyle</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Ha</governor>
          <dependent id="13">Paddy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Ha</governor>
          <dependent id="14">Clarke</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Ha</governor>
          <dependent id="15">Ha</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">Ha</governor>
          <dependent id="16">Ha</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="8">winner</governor>
          <dependent id="17">Ha</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="3">works</governor>
          <dependent id="18">sold</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">copies</governor>
          <dependent id="19">360,000</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">copies</governor>
          <dependent id="20">hardback</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">sold</governor>
          <dependent id="21">copies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Paddy Clarke Ha Ha Ha" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Paddy" />
            <token id="14" string="Clarke" />
            <token id="15" string="Ha" />
            <token id="16" string="Ha" />
            <token id="17" string="Ha" />
          </tokens>
        </entity>
        <entity id="2" string="Roddy Doyle" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Roddy" />
            <token id="11" string="Doyle" />
          </tokens>
        </entity>
        <entity id="3" string="360,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="19" string="360,000" />
          </tokens>
        </entity>
        <entity id="4" string="last year" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="last" />
            <token id="6" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="false">
      <content>Before the short-list was announced it sold 10,600.</content>
      <tokens>
        <token id="1" string="Before" lemma="before" stem="befor" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="short-list" lemma="short-list" stem="short-list" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="announced" lemma="announce" stem="announc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="sold" lemma="sell" stem="sold" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="10,600" lemma="10,600" stem="10,600" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Before) (S (NP (DT the) (NN short-list)) (VP (VBD was) (VP (VBN announced))))) (NP (PRP it)) (VP (VBD sold) (NP (CD 10,600))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="announced" type="VP">
          <tokens>
            <token id="5" string="announced" />
          </tokens>
        </chunking>
        <chunking id="2" string="sold 10,600" type="VP">
          <tokens>
            <token id="7" string="sold" />
            <token id="8" string="10,600" />
          </tokens>
        </chunking>
        <chunking id="3" string="the short-list" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="short-list" />
          </tokens>
        </chunking>
        <chunking id="4" string="Before the short-list was announced" type="SBAR">
          <tokens>
            <token id="1" string="Before" />
            <token id="2" string="the" />
            <token id="3" string="short-list" />
            <token id="4" string="was" />
            <token id="5" string="announced" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="was announced" type="VP">
          <tokens>
            <token id="4" string="was" />
            <token id="5" string="announced" />
          </tokens>
        </chunking>
        <chunking id="7" string="10,600" type="NP">
          <tokens>
            <token id="8" string="10,600" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">announced</governor>
          <dependent id="1">Before</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">short-list</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">announced</governor>
          <dependent id="3">short-list</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">announced</governor>
          <dependent id="4">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">sold</governor>
          <dependent id="5">announced</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">sold</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">sold</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">sold</governor>
          <dependent id="8">10,600</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="10,600" type="NUMBER" score="0.0">
          <tokens>
            <token id="8" string="10,600" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="false">
      <content>The Victorians, in contrast, were lovers of contemporary fiction.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Victorians" lemma="Victorians" stem="victorian" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="contrast" lemma="contrast" stem="contrast" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="lovers" lemma="lover" stem="lover" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="contemporary" lemma="contemporary" stem="contemporari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NNPS Victorians)) (, ,) (PP (IN in) (NP (NN contrast))) (, ,) (VP (VBD were) (NP (NP (NNS lovers)) (PP (IN of) (NP (JJ contemporary) (NN fiction))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The Victorians" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="Victorians" />
          </tokens>
        </chunking>
        <chunking id="2" string="contrast" type="NP">
          <tokens>
            <token id="5" string="contrast" />
          </tokens>
        </chunking>
        <chunking id="3" string="were lovers of contemporary fiction" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="lovers" />
            <token id="9" string="of" />
            <token id="10" string="contemporary" />
            <token id="11" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="4" string="contemporary fiction" type="NP">
          <tokens>
            <token id="10" string="contemporary" />
            <token id="11" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="lovers of contemporary fiction" type="NP">
          <tokens>
            <token id="8" string="lovers" />
            <token id="9" string="of" />
            <token id="10" string="contemporary" />
            <token id="11" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="6" string="lovers" type="NP">
          <tokens>
            <token id="8" string="lovers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">Victorians</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">lovers</governor>
          <dependent id="2">Victorians</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">contrast</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">lovers</governor>
          <dependent id="5">contrast</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">lovers</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">lovers</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">fiction</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">fiction</governor>
          <dependent id="10">contemporary</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">lovers</governor>
          <dependent id="11">fiction</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Victorians" type="MISC" score="0.0">
          <tokens>
            <token id="2" string="Victorians" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>Novels accounted for 20 per cent of published books, and no distinction was made between high and low art.</content>
      <tokens>
        <token id="1" string="Novels" lemma="novel" stem="novel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="accounted" lemma="account" stem="account" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="20" lemma="20" stem="20" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="5" string="per" lemma="per" stem="per" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="cent" lemma="cent" stem="cent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="distinction" lemma="distinction" stem="distinct" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="high" lemma="high" stem="high" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="low" lemma="low" stem="low" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="art" lemma="art" stem="art" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNS Novels)) (VP (VBD accounted) (PP (IN for) (NP (NP (CD 20)) (PP (IN per) (NP (NP (NN cent)) (PP (IN of) (NP (VBN published) (NNS books))))))))) (, ,) (CC and) (S (NP (DT no) (NN distinction)) (VP (VBD was) (VP (VBN made) (PP (IN between) (NP (ADJP (JJ high) (CC and) (JJ low)) (NN art)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="high and low art" type="NP">
          <tokens>
            <token id="17" string="high" />
            <token id="18" string="and" />
            <token id="19" string="low" />
            <token id="20" string="art" />
          </tokens>
        </chunking>
        <chunking id="2" string="no distinction" type="NP">
          <tokens>
            <token id="12" string="no" />
            <token id="13" string="distinction" />
          </tokens>
        </chunking>
        <chunking id="3" string="high and low" type="ADJP">
          <tokens>
            <token id="17" string="high" />
            <token id="18" string="and" />
            <token id="19" string="low" />
          </tokens>
        </chunking>
        <chunking id="4" string="cent of published books" type="NP">
          <tokens>
            <token id="6" string="cent" />
            <token id="7" string="of" />
            <token id="8" string="published" />
            <token id="9" string="books" />
          </tokens>
        </chunking>
        <chunking id="5" string="cent" type="NP">
          <tokens>
            <token id="6" string="cent" />
          </tokens>
        </chunking>
        <chunking id="6" string="accounted for 20 per cent of published books" type="VP">
          <tokens>
            <token id="2" string="accounted" />
            <token id="3" string="for" />
            <token id="4" string="20" />
            <token id="5" string="per" />
            <token id="6" string="cent" />
            <token id="7" string="of" />
            <token id="8" string="published" />
            <token id="9" string="books" />
          </tokens>
        </chunking>
        <chunking id="7" string="Novels" type="NP">
          <tokens>
            <token id="1" string="Novels" />
          </tokens>
        </chunking>
        <chunking id="8" string="20 per cent of published books" type="NP">
          <tokens>
            <token id="4" string="20" />
            <token id="5" string="per" />
            <token id="6" string="cent" />
            <token id="7" string="of" />
            <token id="8" string="published" />
            <token id="9" string="books" />
          </tokens>
        </chunking>
        <chunking id="9" string="was made between high and low art" type="VP">
          <tokens>
            <token id="14" string="was" />
            <token id="15" string="made" />
            <token id="16" string="between" />
            <token id="17" string="high" />
            <token id="18" string="and" />
            <token id="19" string="low" />
            <token id="20" string="art" />
          </tokens>
        </chunking>
        <chunking id="10" string="20" type="NP">
          <tokens>
            <token id="4" string="20" />
          </tokens>
        </chunking>
        <chunking id="11" string="made between high and low art" type="VP">
          <tokens>
            <token id="15" string="made" />
            <token id="16" string="between" />
            <token id="17" string="high" />
            <token id="18" string="and" />
            <token id="19" string="low" />
            <token id="20" string="art" />
          </tokens>
        </chunking>
        <chunking id="12" string="published books" type="NP">
          <tokens>
            <token id="8" string="published" />
            <token id="9" string="books" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">accounted</governor>
          <dependent id="1">Novels</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">accounted</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">20</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">accounted</governor>
          <dependent id="4">20</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">cent</governor>
          <dependent id="5">per</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">20</governor>
          <dependent id="6">cent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">books</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">books</governor>
          <dependent id="8">published</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">cent</governor>
          <dependent id="9">books</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">accounted</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">distinction</governor>
          <dependent id="12">no</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="15">made</governor>
          <dependent id="13">distinction</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">made</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">accounted</governor>
          <dependent id="15">made</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">art</governor>
          <dependent id="16">between</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">art</governor>
          <dependent id="17">high</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">high</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">high</governor>
          <dependent id="19">low</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">made</governor>
          <dependent id="20">art</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="20" type="NUMBER" score="0.0">
          <tokens>
            <token id="4" string="20" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>In the mid 19th century, Dickens made Pounds 12,000 for Little Dorrit, the equivalent of nearly Pounds 400,000 today.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="mid" lemma="mid" stem="mid" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="19th" lemma="19th" stem="19th" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Dickens" lemma="Dickens" stem="dicken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Pounds" lemma="Pounds" stem="pound" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="12,000" lemma="12,000" stem="12,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Dorrit" lemma="dorrit" stem="dorrit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="equivalent" lemma="equivalent" stem="equival" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Pounds" lemma="Pounds" stem="pound" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="400,000" lemma="400,000" stem="400,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="21" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (DT the) (JJ mid) (JJ 19th) (NN century))) (, ,) (NP (NNP Dickens)) (VP (VBD made) (NP (NNPS Pounds)) (NP (CD 12,000)) (PP (IN for) (NP (JJ Little) (NN Dorrit))) (, ,) (NP (NP (DT the) (NN equivalent)) (PP (IN of) (NP (NP (RB nearly) (NNPS Pounds)) (NP-TMP (CD 400,000) (NN today)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Pounds" type="NP">
          <tokens>
            <token id="9" string="Pounds" />
          </tokens>
        </chunking>
        <chunking id="2" string="nearly Pounds 400,000 today" type="NP">
          <tokens>
            <token id="18" string="nearly" />
            <token id="19" string="Pounds" />
            <token id="20" string="400,000" />
            <token id="21" string="today" />
          </tokens>
        </chunking>
        <chunking id="3" string="Dickens" type="NP">
          <tokens>
            <token id="7" string="Dickens" />
          </tokens>
        </chunking>
        <chunking id="4" string="12,000" type="NP">
          <tokens>
            <token id="10" string="12,000" />
          </tokens>
        </chunking>
        <chunking id="5" string="the mid 19th century" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="mid" />
            <token id="4" string="19th" />
            <token id="5" string="century" />
          </tokens>
        </chunking>
        <chunking id="6" string="made Pounds 12,000 for Little Dorrit , the equivalent of nearly Pounds 400,000 today" type="VP">
          <tokens>
            <token id="8" string="made" />
            <token id="9" string="Pounds" />
            <token id="10" string="12,000" />
            <token id="11" string="for" />
            <token id="12" string="Little" />
            <token id="13" string="Dorrit" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="equivalent" />
            <token id="17" string="of" />
            <token id="18" string="nearly" />
            <token id="19" string="Pounds" />
            <token id="20" string="400,000" />
            <token id="21" string="today" />
          </tokens>
        </chunking>
        <chunking id="7" string="the equivalent" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="equivalent" />
          </tokens>
        </chunking>
        <chunking id="8" string="nearly Pounds" type="NP">
          <tokens>
            <token id="18" string="nearly" />
            <token id="19" string="Pounds" />
          </tokens>
        </chunking>
        <chunking id="9" string="Little Dorrit" type="NP">
          <tokens>
            <token id="12" string="Little" />
            <token id="13" string="Dorrit" />
          </tokens>
        </chunking>
        <chunking id="10" string="the equivalent of nearly Pounds 400,000 today" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="equivalent" />
            <token id="17" string="of" />
            <token id="18" string="nearly" />
            <token id="19" string="Pounds" />
            <token id="20" string="400,000" />
            <token id="21" string="today" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">century</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">century</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">century</governor>
          <dependent id="3">mid</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">century</governor>
          <dependent id="4">19th</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">made</governor>
          <dependent id="5">century</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">made</governor>
          <dependent id="7">Dickens</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">made</dependent>
        </dependency>
        <dependency type="iobj">
          <governor id="8">made</governor>
          <dependent id="9">Pounds</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">made</governor>
          <dependent id="10">12,000</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Dorrit</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">Dorrit</governor>
          <dependent id="12">Little</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">made</governor>
          <dependent id="13">Dorrit</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">equivalent</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">made</governor>
          <dependent id="16">equivalent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Pounds</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">Pounds</governor>
          <dependent id="18">nearly</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">equivalent</governor>
          <dependent id="19">Pounds</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">today</governor>
          <dependent id="20">400,000</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="19">Pounds</governor>
          <dependent id="21">today</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="400,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="400,000" />
          </tokens>
        </entity>
        <entity id="2" string="Dickens" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Dickens" />
          </tokens>
        </entity>
        <entity id="3" string="12,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="10" string="12,000" />
          </tokens>
        </entity>
        <entity id="4" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="today" />
          </tokens>
        </entity>
        <entity id="5" string="the mid 19th century" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="mid" />
            <token id="4" string="19th" />
            <token id="5" string="century" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="false">
      <content>Between 1861 and 1894, when the population of the UK was half that of today and the literate population smaller still, Mrs Henry Wood&amp;apost;s East Lynne sold 400,000 copies.</content>
      <tokens>
        <token id="1" string="Between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1861" lemma="1861" stem="1861" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="UK" lemma="UK" stem="uk" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="half" lemma="half" stem="half" pos="PDT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="literate" lemma="literate" stem="liter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="smaller" lemma="smaller" stem="smaller" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Mrs" lemma="Mrs" stem="mr" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="25" string="Henry" lemma="Henry" stem="henri" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="26" string="Wood" lemma="Wood" stem="wood" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="27" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="28" string="East" lemma="East" stem="east" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="29" string="Lynne" lemma="Lynne" stem="lynn" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="30" string="sold" lemma="sell" stem="sold" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="400,000" lemma="400,000" stem="400,000" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="32" string="copies" lemma="copy" stem="copi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Between) (NP (CD 1861) (CC and) (CD 1894))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (NP (DT the) (NN population)) (PP (IN of) (NP (DT the) (NNP UK)))) (VP (VBD was) (NP (PDT half) (NP (NP (DT that)) (PP (IN of) (NP (NN today)))) (CC and) (NP (NP (DT the) (JJ literate) (NN population)) (RRC (ADJP (JJR smaller)) (ADVP (RB still)))))))) (, ,) (NP (NP (NNP Mrs) (NNP Henry) (NNP Wood) (POS 's)) (NNP East) (NNP Lynne)) (VP (VBD sold) (NP (CD 400,000) (NNS copies))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="1861 and 1894" type="NP">
          <tokens>
            <token id="2" string="1861" />
            <token id="3" string="and" />
            <token id="4" string="1894" />
          </tokens>
        </chunking>
        <chunking id="2" string="the population of the UK" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="population" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="UK" />
          </tokens>
        </chunking>
        <chunking id="3" string="was half that of today and the literate population smaller still" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="half" />
            <token id="14" string="that" />
            <token id="15" string="of" />
            <token id="16" string="today" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="literate" />
            <token id="20" string="population" />
            <token id="21" string="smaller" />
            <token id="22" string="still" />
          </tokens>
        </chunking>
        <chunking id="4" string="half that of today and the literate population smaller still" type="NP">
          <tokens>
            <token id="13" string="half" />
            <token id="14" string="that" />
            <token id="15" string="of" />
            <token id="16" string="today" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="literate" />
            <token id="20" string="population" />
            <token id="21" string="smaller" />
            <token id="22" string="still" />
          </tokens>
        </chunking>
        <chunking id="5" string="the literate population" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="literate" />
            <token id="20" string="population" />
          </tokens>
        </chunking>
        <chunking id="6" string="smaller" type="ADJP">
          <tokens>
            <token id="21" string="smaller" />
          </tokens>
        </chunking>
        <chunking id="7" string="that of today" type="NP">
          <tokens>
            <token id="14" string="that" />
            <token id="15" string="of" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="8" string="the literate population smaller still" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="literate" />
            <token id="20" string="population" />
            <token id="21" string="smaller" />
            <token id="22" string="still" />
          </tokens>
        </chunking>
        <chunking id="9" string="400,000 copies" type="NP">
          <tokens>
            <token id="31" string="400,000" />
            <token id="32" string="copies" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="6" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="that" type="NP">
          <tokens>
            <token id="14" string="that" />
          </tokens>
        </chunking>
        <chunking id="12" string="when the population of the UK was half that of today and the literate population smaller still" type="SBAR">
          <tokens>
            <token id="6" string="when" />
            <token id="7" string="the" />
            <token id="8" string="population" />
            <token id="9" string="of" />
            <token id="10" string="the" />
            <token id="11" string="UK" />
            <token id="12" string="was" />
            <token id="13" string="half" />
            <token id="14" string="that" />
            <token id="15" string="of" />
            <token id="16" string="today" />
            <token id="17" string="and" />
            <token id="18" string="the" />
            <token id="19" string="literate" />
            <token id="20" string="population" />
            <token id="21" string="smaller" />
            <token id="22" string="still" />
          </tokens>
        </chunking>
        <chunking id="13" string="the population" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="population" />
          </tokens>
        </chunking>
        <chunking id="14" string="Mrs Henry Wood 's East Lynne" type="NP">
          <tokens>
            <token id="24" string="Mrs" />
            <token id="25" string="Henry" />
            <token id="26" string="Wood" />
            <token id="27" string="'s" />
            <token id="28" string="East" />
            <token id="29" string="Lynne" />
          </tokens>
        </chunking>
        <chunking id="15" string="Mrs Henry Wood 's" type="NP">
          <tokens>
            <token id="24" string="Mrs" />
            <token id="25" string="Henry" />
            <token id="26" string="Wood" />
            <token id="27" string="'s" />
          </tokens>
        </chunking>
        <chunking id="16" string="sold 400,000 copies" type="VP">
          <tokens>
            <token id="30" string="sold" />
            <token id="31" string="400,000" />
            <token id="32" string="copies" />
          </tokens>
        </chunking>
        <chunking id="17" string="today" type="NP">
          <tokens>
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="18" string="the UK" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="UK" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1861</governor>
          <dependent id="1">Between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">sold</governor>
          <dependent id="2">1861</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">1861</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">1861</governor>
          <dependent id="4">1894</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">that</governor>
          <dependent id="6">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">population</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">that</governor>
          <dependent id="8">population</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">UK</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">UK</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">population</governor>
          <dependent id="11">UK</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">that</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="14">that</governor>
          <dependent id="13">half</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="30">sold</governor>
          <dependent id="14">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">today</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">that</governor>
          <dependent id="16">today</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">that</governor>
          <dependent id="17">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">population</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">population</governor>
          <dependent id="19">literate</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">that</governor>
          <dependent id="20">population</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">population</governor>
          <dependent id="21">smaller</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">smaller</governor>
          <dependent id="22">still</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Wood</governor>
          <dependent id="24">Mrs</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">Wood</governor>
          <dependent id="25">Henry</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="29">Lynne</governor>
          <dependent id="26">Wood</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Wood</governor>
          <dependent id="27">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">Lynne</governor>
          <dependent id="28">East</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">sold</governor>
          <dependent id="29">Lynne</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="30">sold</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="32">copies</governor>
          <dependent id="31">400,000</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">sold</governor>
          <dependent id="32">copies</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="400,000" type="NUMBER" score="0.0">
          <tokens>
            <token id="31" string="400,000" />
          </tokens>
        </entity>
        <entity id="2" string="Mrs Henry Wood 's East Lynne" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="24" string="Mrs" />
            <token id="25" string="Henry" />
            <token id="26" string="Wood" />
            <token id="27" string="'s" />
            <token id="28" string="East" />
            <token id="29" string="Lynne" />
          </tokens>
        </entity>
        <entity id="3" string="UK" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="UK" />
          </tokens>
        </entity>
        <entity id="4" string="1861" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1861" />
          </tokens>
        </entity>
        <entity id="5" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1894" />
          </tokens>
        </entity>
        <entity id="6" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="today" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>All the 1894 Booker writers were popular names; they were also serious, skilful writers whose books can be reread with pleasure 100 years later.</content>
      <tokens>
        <token id="1" string="All" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="5" string="writers" lemma="writer" stem="writer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="popular" lemma="popular" stem="popular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="names" lemma="name" stem="name" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="serious" lemma="serious" stem="seriou" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="skilful" lemma="skilful" stem="skil" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="writers" lemma="writer" stem="writer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="19" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="reread" lemma="reread" stem="reread" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="pleasure" lemma="pleasure" stem="pleasur" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="100" lemma="100" stem="100" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="25" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="26" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (PDT All) (DT the)) (NP (CD 1894) (NNP Booker) (NNS writers))) (VP (VBD were) (NP (JJ popular) (NNS names)))) (: ;) (S (NP (PRP they)) (VP (VBD were) (ADVP (RB also)) (NP (NP (JJ serious) (, ,) (JJ skilful) (NNS writers)) (SBAR (WP$ whose) (S (NP (NNS books)) (VP (MD can) (VP (VB be) (VP (VBN reread) (PP (IN with) (NP (NN pleasure))))))))) (ADVP (NP (CD 100) (NNS years)) (RB later)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="serious , skilful writers" type="NP">
          <tokens>
            <token id="13" string="serious" />
            <token id="14" string="," />
            <token id="15" string="skilful" />
            <token id="16" string="writers" />
          </tokens>
        </chunking>
        <chunking id="2" string="reread with pleasure" type="VP">
          <tokens>
            <token id="21" string="reread" />
            <token id="22" string="with" />
            <token id="23" string="pleasure" />
          </tokens>
        </chunking>
        <chunking id="3" string="were also serious , skilful writers whose books can be reread with pleasure 100 years later" type="VP">
          <tokens>
            <token id="11" string="were" />
            <token id="12" string="also" />
            <token id="13" string="serious" />
            <token id="14" string="," />
            <token id="15" string="skilful" />
            <token id="16" string="writers" />
            <token id="17" string="whose" />
            <token id="18" string="books" />
            <token id="19" string="can" />
            <token id="20" string="be" />
            <token id="21" string="reread" />
            <token id="22" string="with" />
            <token id="23" string="pleasure" />
            <token id="24" string="100" />
            <token id="25" string="years" />
            <token id="26" string="later" />
          </tokens>
        </chunking>
        <chunking id="4" string="popular names" type="NP">
          <tokens>
            <token id="7" string="popular" />
            <token id="8" string="names" />
          </tokens>
        </chunking>
        <chunking id="5" string="be reread with pleasure" type="VP">
          <tokens>
            <token id="20" string="be" />
            <token id="21" string="reread" />
            <token id="22" string="with" />
            <token id="23" string="pleasure" />
          </tokens>
        </chunking>
        <chunking id="6" string="pleasure" type="NP">
          <tokens>
            <token id="23" string="pleasure" />
          </tokens>
        </chunking>
        <chunking id="7" string="serious , skilful writers whose books can be reread with pleasure" type="NP">
          <tokens>
            <token id="13" string="serious" />
            <token id="14" string="," />
            <token id="15" string="skilful" />
            <token id="16" string="writers" />
            <token id="17" string="whose" />
            <token id="18" string="books" />
            <token id="19" string="can" />
            <token id="20" string="be" />
            <token id="21" string="reread" />
            <token id="22" string="with" />
            <token id="23" string="pleasure" />
          </tokens>
        </chunking>
        <chunking id="8" string="can be reread with pleasure" type="VP">
          <tokens>
            <token id="19" string="can" />
            <token id="20" string="be" />
            <token id="21" string="reread" />
            <token id="22" string="with" />
            <token id="23" string="pleasure" />
          </tokens>
        </chunking>
        <chunking id="9" string="whose books can be reread with pleasure" type="SBAR">
          <tokens>
            <token id="17" string="whose" />
            <token id="18" string="books" />
            <token id="19" string="can" />
            <token id="20" string="be" />
            <token id="21" string="reread" />
            <token id="22" string="with" />
            <token id="23" string="pleasure" />
          </tokens>
        </chunking>
        <chunking id="10" string="books" type="NP">
          <tokens>
            <token id="18" string="books" />
          </tokens>
        </chunking>
        <chunking id="11" string="they" type="NP">
          <tokens>
            <token id="10" string="they" />
          </tokens>
        </chunking>
        <chunking id="12" string="All the" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="the" />
          </tokens>
        </chunking>
        <chunking id="13" string="1894 Booker writers" type="NP">
          <tokens>
            <token id="3" string="1894" />
            <token id="4" string="Booker" />
            <token id="5" string="writers" />
          </tokens>
        </chunking>
        <chunking id="14" string="100 years" type="NP">
          <tokens>
            <token id="24" string="100" />
            <token id="25" string="years" />
          </tokens>
        </chunking>
        <chunking id="15" string="All the 1894 Booker writers" type="NP">
          <tokens>
            <token id="1" string="All" />
            <token id="2" string="the" />
            <token id="3" string="1894" />
            <token id="4" string="Booker" />
            <token id="5" string="writers" />
          </tokens>
        </chunking>
        <chunking id="16" string="were popular names" type="VP">
          <tokens>
            <token id="6" string="were" />
            <token id="7" string="popular" />
            <token id="8" string="names" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det:predet">
          <governor id="2">the</governor>
          <dependent id="1">All</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">names</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="5">writers</governor>
          <dependent id="3">1894</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">writers</governor>
          <dependent id="4">Booker</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">the</governor>
          <dependent id="5">writers</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">names</governor>
          <dependent id="6">were</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">names</governor>
          <dependent id="7">popular</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">names</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">writers</governor>
          <dependent id="10">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">writers</governor>
          <dependent id="11">were</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">writers</governor>
          <dependent id="12">also</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">writers</governor>
          <dependent id="13">serious</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">writers</governor>
          <dependent id="15">skilful</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="8">names</governor>
          <dependent id="16">writers</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">reread</governor>
          <dependent id="17">whose</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="21">reread</governor>
          <dependent id="18">books</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="21">reread</governor>
          <dependent id="19">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="21">reread</governor>
          <dependent id="20">be</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">writers</governor>
          <dependent id="21">reread</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">pleasure</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">reread</governor>
          <dependent id="23">pleasure</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="25">years</governor>
          <dependent id="24">100</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="26">later</governor>
          <dependent id="25">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">writers</governor>
          <dependent id="26">later</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Booker" />
          </tokens>
        </entity>
        <entity id="2" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="1894" />
          </tokens>
        </entity>
        <entity id="3" string="100 years later" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="100" />
            <token id="25" string="years" />
            <token id="26" string="later" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>Why was fiction so much closer to the public heart in 1894?</content>
      <tokens>
        <token id="1" string="Why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="closer" lemma="closer" stem="closer" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="13" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHADVP (WRB Why)) (SQ (VBD was) (NP (NN fiction)) (ADJP (ADJP (RB so) (RB much) (JJR closer)) (PP (TO to) (NP (NP (DT the) (JJ public) (NN heart)) (PP (IN in) (NP (CD 1894))))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="fiction" type="NP">
          <tokens>
            <token id="3" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="2" string="the public heart" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="public" />
            <token id="10" string="heart" />
          </tokens>
        </chunking>
        <chunking id="3" string="Why" type="WHADVP">
          <tokens>
            <token id="1" string="Why" />
          </tokens>
        </chunking>
        <chunking id="4" string="1894" type="NP">
          <tokens>
            <token id="12" string="1894" />
          </tokens>
        </chunking>
        <chunking id="5" string="so much closer to the public heart in 1894" type="ADJP">
          <tokens>
            <token id="4" string="so" />
            <token id="5" string="much" />
            <token id="6" string="closer" />
            <token id="7" string="to" />
            <token id="8" string="the" />
            <token id="9" string="public" />
            <token id="10" string="heart" />
            <token id="11" string="in" />
            <token id="12" string="1894" />
          </tokens>
        </chunking>
        <chunking id="6" string="so much closer" type="ADJP">
          <tokens>
            <token id="4" string="so" />
            <token id="5" string="much" />
            <token id="6" string="closer" />
          </tokens>
        </chunking>
        <chunking id="7" string="the public heart in 1894" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="public" />
            <token id="10" string="heart" />
            <token id="11" string="in" />
            <token id="12" string="1894" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">closer</governor>
          <dependent id="1">Why</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">closer</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">closer</governor>
          <dependent id="3">fiction</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">closer</governor>
          <dependent id="4">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">closer</governor>
          <dependent id="5">much</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">closer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">heart</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">heart</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">heart</governor>
          <dependent id="9">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">closer</governor>
          <dependent id="10">heart</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">1894</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">heart</governor>
          <dependent id="12">1894</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1894" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="false">
      <content>Social, cultural and psychological reasons play a part.</content>
      <tokens>
        <token id="1" string="Social" lemma="Social" stem="social" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="cultural" lemma="cultural" stem="cultur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="psychological" lemma="psychological" stem="psycholog" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="reasons" lemma="reason" stem="reason" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="play" lemma="play" stem="plai" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Social)) (, ,) (NP (ADJP (JJ cultural) (CC and) (JJ psychological)) (NNS reasons))) (VP (VBP play) (NP (DT a) (NN part))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Social" type="NP">
          <tokens>
            <token id="1" string="Social" />
          </tokens>
        </chunking>
        <chunking id="2" string="cultural and psychological reasons" type="NP">
          <tokens>
            <token id="3" string="cultural" />
            <token id="4" string="and" />
            <token id="5" string="psychological" />
            <token id="6" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="3" string="cultural and psychological" type="ADJP">
          <tokens>
            <token id="3" string="cultural" />
            <token id="4" string="and" />
            <token id="5" string="psychological" />
          </tokens>
        </chunking>
        <chunking id="4" string="play a part" type="VP">
          <tokens>
            <token id="7" string="play" />
            <token id="8" string="a" />
            <token id="9" string="part" />
          </tokens>
        </chunking>
        <chunking id="5" string="Social , cultural and psychological reasons" type="NP">
          <tokens>
            <token id="1" string="Social" />
            <token id="2" string="," />
            <token id="3" string="cultural" />
            <token id="4" string="and" />
            <token id="5" string="psychological" />
            <token id="6" string="reasons" />
          </tokens>
        </chunking>
        <chunking id="6" string="a part" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="part" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">play</governor>
          <dependent id="1">Social</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">reasons</governor>
          <dependent id="3">cultural</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">cultural</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">cultural</governor>
          <dependent id="5">psychological</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Social</governor>
          <dependent id="6">reasons</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">play</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">part</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">play</governor>
          <dependent id="9">part</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="35" has_coreference="false">
      <content>Socially, the 1890s reading public was a vastly more homogenous group than today: a small number of middle class authors wrote for a middle class audience at a time when to be literate was to belong to an elite.</content>
      <tokens>
        <token id="1" string="Socially" lemma="socially" stem="social" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="4" string="1890s" lemma="1890s" stem="1890" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="5" string="reading" lemma="read" stem="read" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="public" lemma="public" stem="public" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="vastly" lemma="vastly" stem="vastli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="homogenous" lemma="homogenous" stem="homogen" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="middle" lemma="middle" stem="middl" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="21" string="class" lemma="class" stem="class" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="22" string="authors" lemma="author" stem="author" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="middle" lemma="middle" stem="middl" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="27" string="class" lemma="class" stem="class" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="28" string="audience" lemma="audience" stem="audienc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="literate" lemma="literate" stem="liter" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="belong" lemma="belong" stem="belong" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="elite" lemma="elite" stem="elit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADVP (RB Socially)) (, ,) (NP (NP (DT the) (CD 1890s)) (VP (VBG reading) (NP (NN public)))) (VP (VBD was) (NP (DT a) (ADJP (RB vastly) (RBR more)) (JJ homogenous) (NN group)) (ADVP (IN than) (NN today)))) (: :) (S (NP (NP (DT a) (JJ small) (NN number)) (PP (IN of) (NP (JJ middle) (NN class) (NNS authors)))) (VP (VBD wrote) (PP (IN for) (NP (NP (DT a) (JJ middle) (NN class) (NN audience)) (PP (IN at) (NP (DT a) (NN time))))) (SBAR (WHADVP (WRB when)) (S (S (VP (TO to) (VP (VB be) (ADJP (JJ literate))))) (VP (VBD was) (S (VP (TO to) (VP (VB belong) (PP (TO to) (NP (DT an) (NN elite))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an elite" type="NP">
          <tokens>
            <token id="40" string="an" />
            <token id="41" string="elite" />
          </tokens>
        </chunking>
        <chunking id="2" string="to belong to an elite" type="VP">
          <tokens>
            <token id="37" string="to" />
            <token id="38" string="belong" />
            <token id="39" string="to" />
            <token id="40" string="an" />
            <token id="41" string="elite" />
          </tokens>
        </chunking>
        <chunking id="3" string="belong to an elite" type="VP">
          <tokens>
            <token id="38" string="belong" />
            <token id="39" string="to" />
            <token id="40" string="an" />
            <token id="41" string="elite" />
          </tokens>
        </chunking>
        <chunking id="4" string="middle class authors" type="NP">
          <tokens>
            <token id="20" string="middle" />
            <token id="21" string="class" />
            <token id="22" string="authors" />
          </tokens>
        </chunking>
        <chunking id="5" string="was to belong to an elite" type="VP">
          <tokens>
            <token id="36" string="was" />
            <token id="37" string="to" />
            <token id="38" string="belong" />
            <token id="39" string="to" />
            <token id="40" string="an" />
            <token id="41" string="elite" />
          </tokens>
        </chunking>
        <chunking id="6" string="a small number" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="small" />
            <token id="18" string="number" />
          </tokens>
        </chunking>
        <chunking id="7" string="a middle class audience" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="middle" />
            <token id="27" string="class" />
            <token id="28" string="audience" />
          </tokens>
        </chunking>
        <chunking id="8" string="wrote for a middle class audience at a time when to be literate was to belong to an elite" type="VP">
          <tokens>
            <token id="23" string="wrote" />
            <token id="24" string="for" />
            <token id="25" string="a" />
            <token id="26" string="middle" />
            <token id="27" string="class" />
            <token id="28" string="audience" />
            <token id="29" string="at" />
            <token id="30" string="a" />
            <token id="31" string="time" />
            <token id="32" string="when" />
            <token id="33" string="to" />
            <token id="34" string="be" />
            <token id="35" string="literate" />
            <token id="36" string="was" />
            <token id="37" string="to" />
            <token id="38" string="belong" />
            <token id="39" string="to" />
            <token id="40" string="an" />
            <token id="41" string="elite" />
          </tokens>
        </chunking>
        <chunking id="9" string="was a vastly more homogenous group than today" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="a" />
            <token id="9" string="vastly" />
            <token id="10" string="more" />
            <token id="11" string="homogenous" />
            <token id="12" string="group" />
            <token id="13" string="than" />
            <token id="14" string="today" />
          </tokens>
        </chunking>
        <chunking id="10" string="vastly more" type="ADJP">
          <tokens>
            <token id="9" string="vastly" />
            <token id="10" string="more" />
          </tokens>
        </chunking>
        <chunking id="11" string="a middle class audience at a time" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="middle" />
            <token id="27" string="class" />
            <token id="28" string="audience" />
            <token id="29" string="at" />
            <token id="30" string="a" />
            <token id="31" string="time" />
          </tokens>
        </chunking>
        <chunking id="12" string="a vastly more homogenous group" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="vastly" />
            <token id="10" string="more" />
            <token id="11" string="homogenous" />
            <token id="12" string="group" />
          </tokens>
        </chunking>
        <chunking id="13" string="when" type="WHADVP">
          <tokens>
            <token id="32" string="when" />
          </tokens>
        </chunking>
        <chunking id="14" string="literate" type="ADJP">
          <tokens>
            <token id="35" string="literate" />
          </tokens>
        </chunking>
        <chunking id="15" string="the 1890s reading public" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="1890s" />
            <token id="5" string="reading" />
            <token id="6" string="public" />
          </tokens>
        </chunking>
        <chunking id="16" string="a time" type="NP">
          <tokens>
            <token id="30" string="a" />
            <token id="31" string="time" />
          </tokens>
        </chunking>
        <chunking id="17" string="public" type="NP">
          <tokens>
            <token id="6" string="public" />
          </tokens>
        </chunking>
        <chunking id="18" string="when to be literate was to belong to an elite" type="SBAR">
          <tokens>
            <token id="32" string="when" />
            <token id="33" string="to" />
            <token id="34" string="be" />
            <token id="35" string="literate" />
            <token id="36" string="was" />
            <token id="37" string="to" />
            <token id="38" string="belong" />
            <token id="39" string="to" />
            <token id="40" string="an" />
            <token id="41" string="elite" />
          </tokens>
        </chunking>
        <chunking id="19" string="the 1890s" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="1890s" />
          </tokens>
        </chunking>
        <chunking id="20" string="reading public" type="VP">
          <tokens>
            <token id="5" string="reading" />
            <token id="6" string="public" />
          </tokens>
        </chunking>
        <chunking id="21" string="a small number of middle class authors" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="small" />
            <token id="18" string="number" />
            <token id="19" string="of" />
            <token id="20" string="middle" />
            <token id="21" string="class" />
            <token id="22" string="authors" />
          </tokens>
        </chunking>
        <chunking id="22" string="be literate" type="VP">
          <tokens>
            <token id="34" string="be" />
            <token id="35" string="literate" />
          </tokens>
        </chunking>
        <chunking id="23" string="to be literate" type="VP">
          <tokens>
            <token id="33" string="to" />
            <token id="34" string="be" />
            <token id="35" string="literate" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="12">group</governor>
          <dependent id="1">Socially</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">1890s</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">group</governor>
          <dependent id="4">1890s</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">1890s</governor>
          <dependent id="5">reading</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">reading</governor>
          <dependent id="6">public</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">group</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">group</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">more</governor>
          <dependent id="9">vastly</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">group</governor>
          <dependent id="10">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">group</governor>
          <dependent id="11">homogenous</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">group</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">today</governor>
          <dependent id="13">than</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">group</governor>
          <dependent id="14">today</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">number</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">number</governor>
          <dependent id="17">small</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">wrote</governor>
          <dependent id="18">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">authors</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">authors</governor>
          <dependent id="20">middle</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">authors</governor>
          <dependent id="21">class</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">number</governor>
          <dependent id="22">authors</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="12">group</governor>
          <dependent id="23">wrote</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">audience</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">audience</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">audience</governor>
          <dependent id="26">middle</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">audience</governor>
          <dependent id="27">class</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">wrote</governor>
          <dependent id="28">audience</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">time</governor>
          <dependent id="29">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">time</governor>
          <dependent id="30">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">audience</governor>
          <dependent id="31">time</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">was</governor>
          <dependent id="32">when</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="35">literate</governor>
          <dependent id="33">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="35">literate</governor>
          <dependent id="34">be</dependent>
        </dependency>
        <dependency type="csubj">
          <governor id="36">was</governor>
          <dependent id="35">literate</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="23">wrote</governor>
          <dependent id="36">was</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="38">belong</governor>
          <dependent id="37">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="36">was</governor>
          <dependent id="38">belong</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">elite</governor>
          <dependent id="39">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">elite</governor>
          <dependent id="40">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="38">belong</governor>
          <dependent id="41">elite</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="today" />
          </tokens>
        </entity>
        <entity id="2" string="the 1890s" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="1890s" />
          </tokens>
        </entity>
        <entity id="3" string="middle class" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="20" string="middle" />
            <token id="21" string="class" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="false">
      <content>The idea of a two-tier, up and down-market, fiction was irrelevant.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="idea" lemma="idea" stem="idea" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="two-tier" lemma="two-tier" stem="two-tier" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="down-market" lemma="down-market" stem="down-market" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="irrelevant" lemma="irrelevant" stem="irrelev" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN idea)) (PP (IN of) (NP (NP (NP (DT a) (JJ two-tier)) (, ,) (ADVP (RB up))) (CC and) (NP (NP (JJ down-market)) (, ,) (NP (NN fiction)))))) (VP (VBD was) (ADJP (JJ irrelevant))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="irrelevant" type="ADJP">
          <tokens>
            <token id="13" string="irrelevant" />
          </tokens>
        </chunking>
        <chunking id="2" string="fiction" type="NP">
          <tokens>
            <token id="11" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="3" string="down-market" type="NP">
          <tokens>
            <token id="9" string="down-market" />
          </tokens>
        </chunking>
        <chunking id="4" string="a two-tier , up and down-market , fiction" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="two-tier" />
            <token id="6" string="," />
            <token id="7" string="up" />
            <token id="8" string="and" />
            <token id="9" string="down-market" />
            <token id="10" string="," />
            <token id="11" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="5" string="down-market , fiction" type="NP">
          <tokens>
            <token id="9" string="down-market" />
            <token id="10" string="," />
            <token id="11" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="6" string="The idea of a two-tier , up and down-market , fiction" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="idea" />
            <token id="3" string="of" />
            <token id="4" string="a" />
            <token id="5" string="two-tier" />
            <token id="6" string="," />
            <token id="7" string="up" />
            <token id="8" string="and" />
            <token id="9" string="down-market" />
            <token id="10" string="," />
            <token id="11" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="7" string="a two-tier , up" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="two-tier" />
            <token id="6" string="," />
            <token id="7" string="up" />
          </tokens>
        </chunking>
        <chunking id="8" string="a two-tier" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="two-tier" />
          </tokens>
        </chunking>
        <chunking id="9" string="was irrelevant" type="VP">
          <tokens>
            <token id="12" string="was" />
            <token id="13" string="irrelevant" />
          </tokens>
        </chunking>
        <chunking id="10" string="The idea" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="idea" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">idea</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">irrelevant</governor>
          <dependent id="2">idea</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">two-tier</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">two-tier</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">idea</governor>
          <dependent id="5">two-tier</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">two-tier</governor>
          <dependent id="7">up</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">two-tier</governor>
          <dependent id="8">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">two-tier</governor>
          <dependent id="9">down-market</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="9">down-market</governor>
          <dependent id="11">fiction</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">irrelevant</governor>
          <dependent id="12">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">irrelevant</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Culturally, these writers and readers were certain of their place in the mainstream, and the novel was their political and intellectual forum.</content>
      <tokens>
        <token id="1" string="Culturally" lemma="culturally" stem="cultur" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="writers" lemma="writer" stem="writer" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="readers" lemma="reader" stem="reader" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="mainstream" lemma="mainstream" stem="mainstream" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="intellectual" lemma="intellectual" stem="intellectu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="forum" lemma="forum" stem="forum" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Culturally)) (, ,) (S (NP (DT these) (NNS writers) (CC and) (NNS readers)) (VP (VBD were) (ADJP (JJ certain) (PP (IN of) (NP (PRP$ their) (NN place)))) (PP (IN in) (NP (DT the) (NN mainstream))))) (, ,) (CC and) (S (NP (DT the) (NN novel)) (VP (VBD was) (NP (PRP$ their) (ADJP (JJ political) (CC and) (JJ intellectual)) (NN forum)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="their place" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="place" />
          </tokens>
        </chunking>
        <chunking id="2" string="the mainstream" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="mainstream" />
          </tokens>
        </chunking>
        <chunking id="3" string="certain of their place" type="ADJP">
          <tokens>
            <token id="8" string="certain" />
            <token id="9" string="of" />
            <token id="10" string="their" />
            <token id="11" string="place" />
          </tokens>
        </chunking>
        <chunking id="4" string="the novel" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="novel" />
          </tokens>
        </chunking>
        <chunking id="5" string="these writers and readers" type="NP">
          <tokens>
            <token id="3" string="these" />
            <token id="4" string="writers" />
            <token id="5" string="and" />
            <token id="6" string="readers" />
          </tokens>
        </chunking>
        <chunking id="6" string="their political and intellectual forum" type="NP">
          <tokens>
            <token id="20" string="their" />
            <token id="21" string="political" />
            <token id="22" string="and" />
            <token id="23" string="intellectual" />
            <token id="24" string="forum" />
          </tokens>
        </chunking>
        <chunking id="7" string="political and intellectual" type="ADJP">
          <tokens>
            <token id="21" string="political" />
            <token id="22" string="and" />
            <token id="23" string="intellectual" />
          </tokens>
        </chunking>
        <chunking id="8" string="was their political and intellectual forum" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="their" />
            <token id="21" string="political" />
            <token id="22" string="and" />
            <token id="23" string="intellectual" />
            <token id="24" string="forum" />
          </tokens>
        </chunking>
        <chunking id="9" string="were certain of their place in the mainstream" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="certain" />
            <token id="9" string="of" />
            <token id="10" string="their" />
            <token id="11" string="place" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="mainstream" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="8">certain</governor>
          <dependent id="1">Culturally</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">writers</governor>
          <dependent id="3">these</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">certain</governor>
          <dependent id="4">writers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">writers</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">writers</governor>
          <dependent id="6">readers</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">certain</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">certain</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">place</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">place</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">certain</governor>
          <dependent id="11">place</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">mainstream</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">mainstream</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">certain</governor>
          <dependent id="14">mainstream</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">certain</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">novel</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">forum</governor>
          <dependent id="18">novel</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">forum</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">forum</governor>
          <dependent id="20">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">forum</governor>
          <dependent id="21">political</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">political</governor>
          <dependent id="22">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">political</governor>
          <dependent id="23">intellectual</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">certain</governor>
          <dependent id="24">forum</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>Today we no longer share the Victorian confidence in the novel as a key genre of our age.</content>
      <tokens>
        <token id="1" string="Today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="2" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="3" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="longer" lemma="longer" stem="longer" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="share" lemma="share" stem="share" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Victorian" lemma="victorian" stem="victorian" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="8" string="confidence" lemma="confidence" stem="confid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="novel" lemma="novel" stem="novel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="key" lemma="key" stem="kei" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="genre" lemma="genre" stem="genr" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="age" lemma="age" stem="ag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NN Today)) (NP (PRP we))) (ADVP (RB no) (RBR longer)) (VP (VB share) (NP (DT the) (JJ Victorian) (NN confidence)) (PP (IN in) (NP (NP (DT the) (JJ novel)) (PP (IN as) (NP (NP (DT a) (JJ key) (NN genre)) (PP (IN of) (NP (PRP$ our) (NN age)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Victorian confidence" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="Victorian" />
            <token id="8" string="confidence" />
          </tokens>
        </chunking>
        <chunking id="2" string="Today" type="NP">
          <tokens>
            <token id="1" string="Today" />
          </tokens>
        </chunking>
        <chunking id="3" string="the novel" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="novel" />
          </tokens>
        </chunking>
        <chunking id="4" string="a key genre of our age" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="key" />
            <token id="15" string="genre" />
            <token id="16" string="of" />
            <token id="17" string="our" />
            <token id="18" string="age" />
          </tokens>
        </chunking>
        <chunking id="5" string="Today we" type="NP">
          <tokens>
            <token id="1" string="Today" />
            <token id="2" string="we" />
          </tokens>
        </chunking>
        <chunking id="6" string="the novel as a key genre of our age" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="novel" />
            <token id="12" string="as" />
            <token id="13" string="a" />
            <token id="14" string="key" />
            <token id="15" string="genre" />
            <token id="16" string="of" />
            <token id="17" string="our" />
            <token id="18" string="age" />
          </tokens>
        </chunking>
        <chunking id="7" string="our age" type="NP">
          <tokens>
            <token id="17" string="our" />
            <token id="18" string="age" />
          </tokens>
        </chunking>
        <chunking id="8" string="we" type="NP">
          <tokens>
            <token id="2" string="we" />
          </tokens>
        </chunking>
        <chunking id="9" string="a key genre" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="key" />
            <token id="15" string="genre" />
          </tokens>
        </chunking>
        <chunking id="10" string="share the Victorian confidence in the novel as a key genre of our age" type="VP">
          <tokens>
            <token id="5" string="share" />
            <token id="6" string="the" />
            <token id="7" string="Victorian" />
            <token id="8" string="confidence" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="novel" />
            <token id="12" string="as" />
            <token id="13" string="a" />
            <token id="14" string="key" />
            <token id="15" string="genre" />
            <token id="16" string="of" />
            <token id="17" string="our" />
            <token id="18" string="age" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">share</governor>
          <dependent id="1">Today</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="1">Today</governor>
          <dependent id="2">we</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">longer</governor>
          <dependent id="3">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">share</governor>
          <dependent id="4">longer</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">share</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">confidence</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">confidence</governor>
          <dependent id="7">Victorian</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">share</governor>
          <dependent id="8">confidence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">novel</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">novel</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">share</governor>
          <dependent id="11">novel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">genre</governor>
          <dependent id="12">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">genre</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">genre</governor>
          <dependent id="14">key</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">novel</governor>
          <dependent id="15">genre</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">age</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">age</governor>
          <dependent id="17">our</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">genre</governor>
          <dependent id="18">age</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Today" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Today" />
          </tokens>
        </entity>
        <entity id="2" string="Victorian" type="MISC" score="0.0">
          <tokens>
            <token id="7" string="Victorian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>Modernism and the overturning of the traditional form by Joyce and Woolf weakened 20th-century belief in the novel and encouraged the divergence between highbrow and lowbrow.</content>
      <tokens>
        <token id="1" string="Modernism" lemma="Modernism" stem="modern" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="2" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="overturning" lemma="overturn" stem="overturn" pos="VBG" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="traditional" lemma="traditional" stem="tradit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Joyce" lemma="Joyce" stem="joyc" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Woolf" lemma="Woolf" stem="woolf" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="weakened" lemma="weaken" stem="weaken" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="20th-century" lemma="20th-century" stem="20th-centuri" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="belief" lemma="belief" stem="belief" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="novel" lemma="novel" stem="novel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="encouraged" lemma="encourage" stem="encourag" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="divergence" lemma="divergence" stem="diverg" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="highbrow" lemma="highbrow" stem="highbrow" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="lowbrow" lemma="lowbrow" stem="lowbrow" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Modernism)) (CC and) (NP (DT the) (VBG overturning)) (PP (IN of) (NP (NP (DT the) (JJ traditional) (NN form)) (PP (IN by) (NP (NNP Joyce) (CC and) (NNP Woolf)))))) (VP (VP (VBD weakened) (NP (ADJP (JJ 20th-century)) (NN belief)) (PP (IN in) (NP (DT the) (JJ novel)))) (CC and) (VP (VBD encouraged) (NP (DT the) (NN divergence)) (PP (IN between) (ADJP (JJ highbrow) (CC and) (JJ lowbrow))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="encouraged the divergence between highbrow and lowbrow" type="VP">
          <tokens>
            <token id="20" string="encouraged" />
            <token id="21" string="the" />
            <token id="22" string="divergence" />
            <token id="23" string="between" />
            <token id="24" string="highbrow" />
            <token id="25" string="and" />
            <token id="26" string="lowbrow" />
          </tokens>
        </chunking>
        <chunking id="2" string="weakened 20th-century belief in the novel and encouraged the divergence between highbrow and lowbrow" type="VP">
          <tokens>
            <token id="13" string="weakened" />
            <token id="14" string="20th-century" />
            <token id="15" string="belief" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="novel" />
            <token id="19" string="and" />
            <token id="20" string="encouraged" />
            <token id="21" string="the" />
            <token id="22" string="divergence" />
            <token id="23" string="between" />
            <token id="24" string="highbrow" />
            <token id="25" string="and" />
            <token id="26" string="lowbrow" />
          </tokens>
        </chunking>
        <chunking id="3" string="the novel" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="novel" />
          </tokens>
        </chunking>
        <chunking id="4" string="Joyce and Woolf" type="NP">
          <tokens>
            <token id="10" string="Joyce" />
            <token id="11" string="and" />
            <token id="12" string="Woolf" />
          </tokens>
        </chunking>
        <chunking id="5" string="the overturning" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="overturning" />
          </tokens>
        </chunking>
        <chunking id="6" string="the traditional form" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="traditional" />
            <token id="8" string="form" />
          </tokens>
        </chunking>
        <chunking id="7" string="the divergence" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="divergence" />
          </tokens>
        </chunking>
        <chunking id="8" string="20th-century belief" type="NP">
          <tokens>
            <token id="14" string="20th-century" />
            <token id="15" string="belief" />
          </tokens>
        </chunking>
        <chunking id="9" string="weakened 20th-century belief in the novel" type="VP">
          <tokens>
            <token id="13" string="weakened" />
            <token id="14" string="20th-century" />
            <token id="15" string="belief" />
            <token id="16" string="in" />
            <token id="17" string="the" />
            <token id="18" string="novel" />
          </tokens>
        </chunking>
        <chunking id="10" string="Modernism" type="NP">
          <tokens>
            <token id="1" string="Modernism" />
          </tokens>
        </chunking>
        <chunking id="11" string="highbrow and lowbrow" type="ADJP">
          <tokens>
            <token id="24" string="highbrow" />
            <token id="25" string="and" />
            <token id="26" string="lowbrow" />
          </tokens>
        </chunking>
        <chunking id="12" string="Modernism and the overturning of the traditional form by Joyce and Woolf" type="NP">
          <tokens>
            <token id="1" string="Modernism" />
            <token id="2" string="and" />
            <token id="3" string="the" />
            <token id="4" string="overturning" />
            <token id="5" string="of" />
            <token id="6" string="the" />
            <token id="7" string="traditional" />
            <token id="8" string="form" />
            <token id="9" string="by" />
            <token id="10" string="Joyce" />
            <token id="11" string="and" />
            <token id="12" string="Woolf" />
          </tokens>
        </chunking>
        <chunking id="13" string="20th-century" type="ADJP">
          <tokens>
            <token id="14" string="20th-century" />
          </tokens>
        </chunking>
        <chunking id="14" string="the traditional form by Joyce and Woolf" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="traditional" />
            <token id="8" string="form" />
            <token id="9" string="by" />
            <token id="10" string="Joyce" />
            <token id="11" string="and" />
            <token id="12" string="Woolf" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="13">weakened</governor>
          <dependent id="1">Modernism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Modernism</governor>
          <dependent id="2">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Modernism</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">the</governor>
          <dependent id="4">overturning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">form</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">form</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">form</governor>
          <dependent id="7">traditional</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Modernism</governor>
          <dependent id="8">form</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Joyce</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">form</governor>
          <dependent id="10">Joyce</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="10">Joyce</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="10">Joyce</governor>
          <dependent id="12">Woolf</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">weakened</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">belief</governor>
          <dependent id="14">20th-century</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">weakened</governor>
          <dependent id="15">belief</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">novel</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">novel</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">weakened</governor>
          <dependent id="18">novel</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">weakened</governor>
          <dependent id="19">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">weakened</governor>
          <dependent id="20">encouraged</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">divergence</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">encouraged</governor>
          <dependent id="22">divergence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">highbrow</governor>
          <dependent id="23">between</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">encouraged</governor>
          <dependent id="24">highbrow</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">highbrow</governor>
          <dependent id="25">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">highbrow</governor>
          <dependent id="26">lowbrow</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Joyce" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Joyce" />
          </tokens>
        </entity>
        <entity id="2" string="Modernism" type="MISC" score="0.0">
          <tokens>
            <token id="1" string="Modernism" />
          </tokens>
        </entity>
        <entity id="3" string="20th-century" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="20th-century" />
          </tokens>
        </entity>
        <entity id="4" string="Woolf" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="Woolf" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="40" has_coreference="true">
      <content>The dominance of film and television has made novels a more marginal form and perhaps they no longer attract the most creative talents.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="dominance" lemma="dominance" stem="domin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="television" lemma="television" stem="televis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="made" lemma="make" stem="made" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="novels" lemma="novel" stem="novel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="marginal" lemma="marginal" stem="margin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="form" lemma="form" stem="form" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="perhaps" lemma="perhaps" stem="perhap" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="no" lemma="no" stem="no" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="longer" lemma="longer" stem="longer" pos="RBR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="attract" lemma="attract" stem="attract" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="creative" lemma="creative" stem="creativ" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="talents" lemma="talent" stem="talent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN dominance)) (PP (IN of) (NP (NN film) (CC and) (NN television)))) (VP (VBZ has) (VP (VBN made) (S (NP (NNS novels)) (NP (DT a) (ADJP (RBR more) (JJ marginal)) (NN form)))))) (CC and) (ADVP (RB perhaps)) (S (NP (PRP they)) (ADVP (RB no) (RBR longer)) (VP (VB attract) (NP (DT the) (ADJP (RBS most) (JJ creative)) (NNS talents)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="16" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="has made novels a more marginal form" type="VP">
          <tokens>
            <token id="7" string="has" />
            <token id="8" string="made" />
            <token id="9" string="novels" />
            <token id="10" string="a" />
            <token id="11" string="more" />
            <token id="12" string="marginal" />
            <token id="13" string="form" />
          </tokens>
        </chunking>
        <chunking id="3" string="more marginal" type="ADJP">
          <tokens>
            <token id="11" string="more" />
            <token id="12" string="marginal" />
          </tokens>
        </chunking>
        <chunking id="4" string="a more marginal form" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="more" />
            <token id="12" string="marginal" />
            <token id="13" string="form" />
          </tokens>
        </chunking>
        <chunking id="5" string="attract the most creative talents" type="VP">
          <tokens>
            <token id="19" string="attract" />
            <token id="20" string="the" />
            <token id="21" string="most" />
            <token id="22" string="creative" />
            <token id="23" string="talents" />
          </tokens>
        </chunking>
        <chunking id="6" string="film and television" type="NP">
          <tokens>
            <token id="4" string="film" />
            <token id="5" string="and" />
            <token id="6" string="television" />
          </tokens>
        </chunking>
        <chunking id="7" string="the most creative talents" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="most" />
            <token id="22" string="creative" />
            <token id="23" string="talents" />
          </tokens>
        </chunking>
        <chunking id="8" string="made novels a more marginal form" type="VP">
          <tokens>
            <token id="8" string="made" />
            <token id="9" string="novels" />
            <token id="10" string="a" />
            <token id="11" string="more" />
            <token id="12" string="marginal" />
            <token id="13" string="form" />
          </tokens>
        </chunking>
        <chunking id="9" string="most creative" type="ADJP">
          <tokens>
            <token id="21" string="most" />
            <token id="22" string="creative" />
          </tokens>
        </chunking>
        <chunking id="10" string="The dominance of film and television" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="dominance" />
            <token id="3" string="of" />
            <token id="4" string="film" />
            <token id="5" string="and" />
            <token id="6" string="television" />
          </tokens>
        </chunking>
        <chunking id="11" string="The dominance" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="dominance" />
          </tokens>
        </chunking>
        <chunking id="12" string="novels" type="NP">
          <tokens>
            <token id="9" string="novels" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">dominance</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">made</governor>
          <dependent id="2">dominance</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">film</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">dominance</governor>
          <dependent id="4">film</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">film</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">film</governor>
          <dependent id="6">television</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">made</governor>
          <dependent id="7">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">made</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">form</governor>
          <dependent id="9">novels</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">form</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">marginal</governor>
          <dependent id="11">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">form</governor>
          <dependent id="12">marginal</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">made</governor>
          <dependent id="13">form</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">made</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">attract</governor>
          <dependent id="15">perhaps</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">attract</governor>
          <dependent id="16">they</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">longer</governor>
          <dependent id="17">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">attract</governor>
          <dependent id="18">longer</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">made</governor>
          <dependent id="19">attract</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">talents</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">creative</governor>
          <dependent id="21">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">talents</governor>
          <dependent id="22">creative</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">attract</governor>
          <dependent id="23">talents</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>George du Maurier originally offered the outline of Trilby to Henry James, who he thought would write a better novel.</content>
      <tokens>
        <token id="1" string="George" lemma="George" stem="georg" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="du" lemma="du" stem="du" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="Maurier" lemma="Maurier" stem="maurier" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="originally" lemma="originally" stem="origin" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="offered" lemma="offer" stem="offer" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="outline" lemma="outline" stem="outlin" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="Trilby" lemma="Trilby" stem="trilbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Henry" lemma="Henry" stem="henri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="James" lemma="James" stem="jame" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="thought" lemma="think" stem="thought" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="write" lemma="write" stem="write" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="better" lemma="better" stem="better" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP George) (NNP du) (NNP Maurier)) (ADVP (RB originally)) (VP (VBD offered) (NP (NP (DT the) (NN outline)) (PP (IN of) (NP (NNP Trilby)))) (PP (TO to) (NP (NP (NNP Henry) (NNP James)) (, ,) (SBAR (WHNP (WP who)) (S (NP (PRP he)) (VP (VBD thought) (SBAR (S (VP (MD would) (VP (VB write) (NP (DT a) (JJR better) (NN novel)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a better novel" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="better" />
            <token id="21" string="novel" />
          </tokens>
        </chunking>
        <chunking id="2" string="offered the outline of Trilby to Henry James , who he thought would write a better novel" type="VP">
          <tokens>
            <token id="5" string="offered" />
            <token id="6" string="the" />
            <token id="7" string="outline" />
            <token id="8" string="of" />
            <token id="9" string="Trilby" />
            <token id="10" string="to" />
            <token id="11" string="Henry" />
            <token id="12" string="James" />
            <token id="13" string="," />
            <token id="14" string="who" />
            <token id="15" string="he" />
            <token id="16" string="thought" />
            <token id="17" string="would" />
            <token id="18" string="write" />
            <token id="19" string="a" />
            <token id="20" string="better" />
            <token id="21" string="novel" />
          </tokens>
        </chunking>
        <chunking id="3" string="write a better novel" type="VP">
          <tokens>
            <token id="18" string="write" />
            <token id="19" string="a" />
            <token id="20" string="better" />
            <token id="21" string="novel" />
          </tokens>
        </chunking>
        <chunking id="4" string="Henry James , who he thought would write a better novel" type="NP">
          <tokens>
            <token id="11" string="Henry" />
            <token id="12" string="James" />
            <token id="13" string="," />
            <token id="14" string="who" />
            <token id="15" string="he" />
            <token id="16" string="thought" />
            <token id="17" string="would" />
            <token id="18" string="write" />
            <token id="19" string="a" />
            <token id="20" string="better" />
            <token id="21" string="novel" />
          </tokens>
        </chunking>
        <chunking id="5" string="George du Maurier" type="NP">
          <tokens>
            <token id="1" string="George" />
            <token id="2" string="du" />
            <token id="3" string="Maurier" />
          </tokens>
        </chunking>
        <chunking id="6" string="who he thought would write a better novel" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="he" />
            <token id="16" string="thought" />
            <token id="17" string="would" />
            <token id="18" string="write" />
            <token id="19" string="a" />
            <token id="20" string="better" />
            <token id="21" string="novel" />
          </tokens>
        </chunking>
        <chunking id="7" string="the outline of Trilby" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="outline" />
            <token id="8" string="of" />
            <token id="9" string="Trilby" />
          </tokens>
        </chunking>
        <chunking id="8" string="would write a better novel" type="SBAR">
          <tokens>
            <token id="17" string="would" />
            <token id="18" string="write" />
            <token id="19" string="a" />
            <token id="20" string="better" />
            <token id="21" string="novel" />
          </tokens>
        </chunking>
        <chunking id="9" string="Trilby" type="NP">
          <tokens>
            <token id="9" string="Trilby" />
          </tokens>
        </chunking>
        <chunking id="10" string="Henry James" type="NP">
          <tokens>
            <token id="11" string="Henry" />
            <token id="12" string="James" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="thought would write a better novel" type="VP">
          <tokens>
            <token id="16" string="thought" />
            <token id="17" string="would" />
            <token id="18" string="write" />
            <token id="19" string="a" />
            <token id="20" string="better" />
            <token id="21" string="novel" />
          </tokens>
        </chunking>
        <chunking id="13" string="the outline" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="outline" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Maurier</governor>
          <dependent id="1">George</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Maurier</governor>
          <dependent id="2">du</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">offered</governor>
          <dependent id="3">Maurier</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">offered</governor>
          <dependent id="4">originally</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">offered</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">outline</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">offered</governor>
          <dependent id="7">outline</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Trilby</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">outline</governor>
          <dependent id="9">Trilby</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">James</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">James</governor>
          <dependent id="11">Henry</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">offered</governor>
          <dependent id="12">James</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">thought</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">thought</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">James</governor>
          <dependent id="16">thought</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">write</governor>
          <dependent id="17">would</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">thought</governor>
          <dependent id="18">write</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">novel</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">novel</governor>
          <dependent id="20">better</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">write</governor>
          <dependent id="21">novel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Trilby" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Trilby" />
          </tokens>
        </entity>
        <entity id="2" string="George du Maurier" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="George" />
            <token id="2" string="du" />
            <token id="3" string="Maurier" />
          </tokens>
        </entity>
        <entity id="3" string="Henry James" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Henry" />
            <token id="12" string="James" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>Today du Maurier would have sold it to Hollywood or the BBC.</content>
      <tokens>
        <token id="1" string="Today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="du" lemma="du" stem="du" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="Maurier" lemma="Maurier" stem="maurier" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="sold" lemma="sell" stem="sold" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Hollywood" lemma="Hollywood" stem="hollywood" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="BBC" lemma="BBC" stem="bbc" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (NN Today)) (NP (NNP du) (NNP Maurier)) (VP (MD would) (VP (VB have) (VP (VBN sold) (NP (PRP it)) (PP (TO to) (NP (NP (NNP Hollywood)) (CC or) (NP (DT the) (NNP BBC))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Hollywood" type="NP">
          <tokens>
            <token id="9" string="Hollywood" />
          </tokens>
        </chunking>
        <chunking id="2" string="Hollywood or the BBC" type="NP">
          <tokens>
            <token id="9" string="Hollywood" />
            <token id="10" string="or" />
            <token id="11" string="the" />
            <token id="12" string="BBC" />
          </tokens>
        </chunking>
        <chunking id="3" string="have sold it to Hollywood or the BBC" type="VP">
          <tokens>
            <token id="5" string="have" />
            <token id="6" string="sold" />
            <token id="7" string="it" />
            <token id="8" string="to" />
            <token id="9" string="Hollywood" />
            <token id="10" string="or" />
            <token id="11" string="the" />
            <token id="12" string="BBC" />
          </tokens>
        </chunking>
        <chunking id="4" string="sold it to Hollywood or the BBC" type="VP">
          <tokens>
            <token id="6" string="sold" />
            <token id="7" string="it" />
            <token id="8" string="to" />
            <token id="9" string="Hollywood" />
            <token id="10" string="or" />
            <token id="11" string="the" />
            <token id="12" string="BBC" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="7" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="the BBC" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="BBC" />
          </tokens>
        </chunking>
        <chunking id="7" string="du Maurier" type="NP">
          <tokens>
            <token id="2" string="du" />
            <token id="3" string="Maurier" />
          </tokens>
        </chunking>
        <chunking id="8" string="would have sold it to Hollywood or the BBC" type="VP">
          <tokens>
            <token id="4" string="would" />
            <token id="5" string="have" />
            <token id="6" string="sold" />
            <token id="7" string="it" />
            <token id="8" string="to" />
            <token id="9" string="Hollywood" />
            <token id="10" string="or" />
            <token id="11" string="the" />
            <token id="12" string="BBC" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:tmod">
          <governor id="6">sold</governor>
          <dependent id="1">Today</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Maurier</governor>
          <dependent id="2">du</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">sold</governor>
          <dependent id="3">Maurier</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">sold</governor>
          <dependent id="4">would</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">sold</governor>
          <dependent id="5">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">sold</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">sold</governor>
          <dependent id="7">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Hollywood</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">sold</governor>
          <dependent id="9">Hollywood</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">Hollywood</governor>
          <dependent id="10">or</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">BBC</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">Hollywood</governor>
          <dependent id="12">BBC</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Hollywood" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Hollywood" />
          </tokens>
        </entity>
        <entity id="2" string="Today" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Today" />
          </tokens>
        </entity>
        <entity id="3" string="BBC" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="BBC" />
          </tokens>
        </entity>
        <entity id="4" string="Maurier" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Maurier" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>The fantasy element of fiction, in which we identify with characters as if we know them, was answered in the 19th century by the novel; in the 20th century we have TV soaps.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="fantasy" lemma="fantasy" stem="fantasi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="element" lemma="element" stem="element" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="fiction" lemma="fiction" stem="fiction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="identify" lemma="identify" stem="identifi" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="characters" lemma="character" stem="charact" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="know" lemma="know" stem="know" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="answered" lemma="answer" stem="answer" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="19th" lemma="19th" stem="19th" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="24" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="31" string="20th" lemma="20th" stem="20th" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="32" string="century" lemma="century" stem="centuri" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="TV" lemma="tv" stem="tv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="soaps" lemma="soap" stem="soap" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN fantasy) (NN element)) (PP (IN of) (NP (NN fiction))) (, ,) (SBAR (WHPP (IN in) (WHNP (WDT which))) (S (NP (PRP we)) (VP (VBP identify) (PP (IN with) (NP (NNS characters))) (SBAR (IN as) (IN if) (S (NP (PRP we)) (VP (VBP know) (NP (PRP them)))))))) (, ,)) (VP (VBD was) (VP (VBN answered) (PP (IN in) (NP (DT the) (JJ 19th) (NN century))) (PP (IN by) (NP (DT the) (NN novel)))))) (: ;) (S (PP (IN in) (NP (DT the) (JJ 20th) (NN century))) (NP (PRP we)) (VP (VBP have) (NP (NN TV) (NNS soaps)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The fantasy element of fiction , in which we identify with characters as if we know them ," type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="fantasy" />
            <token id="3" string="element" />
            <token id="4" string="of" />
            <token id="5" string="fiction" />
            <token id="6" string="," />
            <token id="7" string="in" />
            <token id="8" string="which" />
            <token id="9" string="we" />
            <token id="10" string="identify" />
            <token id="11" string="with" />
            <token id="12" string="characters" />
            <token id="13" string="as" />
            <token id="14" string="if" />
            <token id="15" string="we" />
            <token id="16" string="know" />
            <token id="17" string="them" />
            <token id="18" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="in which we identify with characters as if we know them" type="SBAR">
          <tokens>
            <token id="7" string="in" />
            <token id="8" string="which" />
            <token id="9" string="we" />
            <token id="10" string="identify" />
            <token id="11" string="with" />
            <token id="12" string="characters" />
            <token id="13" string="as" />
            <token id="14" string="if" />
            <token id="15" string="we" />
            <token id="16" string="know" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="fiction" type="NP">
          <tokens>
            <token id="5" string="fiction" />
          </tokens>
        </chunking>
        <chunking id="4" string="the novel" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="novel" />
          </tokens>
        </chunking>
        <chunking id="5" string="the 20th century" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="20th" />
            <token id="32" string="century" />
          </tokens>
        </chunking>
        <chunking id="6" string="The fantasy element" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="fantasy" />
            <token id="3" string="element" />
          </tokens>
        </chunking>
        <chunking id="7" string="know them" type="VP">
          <tokens>
            <token id="16" string="know" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="8" string="identify with characters as if we know them" type="VP">
          <tokens>
            <token id="10" string="identify" />
            <token id="11" string="with" />
            <token id="12" string="characters" />
            <token id="13" string="as" />
            <token id="14" string="if" />
            <token id="15" string="we" />
            <token id="16" string="know" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="we" type="NP">
          <tokens>
            <token id="9" string="we" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="characters" type="NP">
          <tokens>
            <token id="12" string="characters" />
          </tokens>
        </chunking>
        <chunking id="12" string="the 19th century" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="19th" />
            <token id="24" string="century" />
          </tokens>
        </chunking>
        <chunking id="13" string="as if we know them" type="SBAR">
          <tokens>
            <token id="13" string="as" />
            <token id="14" string="if" />
            <token id="15" string="we" />
            <token id="16" string="know" />
            <token id="17" string="them" />
          </tokens>
        </chunking>
        <chunking id="14" string="TV soaps" type="NP">
          <tokens>
            <token id="35" string="TV" />
            <token id="36" string="soaps" />
          </tokens>
        </chunking>
        <chunking id="15" string="answered in the 19th century by the novel" type="VP">
          <tokens>
            <token id="20" string="answered" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="19th" />
            <token id="24" string="century" />
            <token id="25" string="by" />
            <token id="26" string="the" />
            <token id="27" string="novel" />
          </tokens>
        </chunking>
        <chunking id="16" string="was answered in the 19th century by the novel" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="answered" />
            <token id="21" string="in" />
            <token id="22" string="the" />
            <token id="23" string="19th" />
            <token id="24" string="century" />
            <token id="25" string="by" />
            <token id="26" string="the" />
            <token id="27" string="novel" />
          </tokens>
        </chunking>
        <chunking id="17" string="have TV soaps" type="VP">
          <tokens>
            <token id="34" string="have" />
            <token id="35" string="TV" />
            <token id="36" string="soaps" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">element</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">element</governor>
          <dependent id="2">fantasy</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">answered</governor>
          <dependent id="3">element</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">fiction</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">element</governor>
          <dependent id="5">fiction</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">which</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">identify</governor>
          <dependent id="8">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">identify</governor>
          <dependent id="9">we</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">element</governor>
          <dependent id="10">identify</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">characters</governor>
          <dependent id="11">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">identify</governor>
          <dependent id="12">characters</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">know</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="13">as</governor>
          <dependent id="14">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">know</governor>
          <dependent id="15">we</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="10">identify</governor>
          <dependent id="16">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">know</governor>
          <dependent id="17">them</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">answered</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">answered</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">century</governor>
          <dependent id="21">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">century</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="24">century</governor>
          <dependent id="23">19th</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">answered</governor>
          <dependent id="24">century</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">novel</governor>
          <dependent id="25">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">novel</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">answered</governor>
          <dependent id="27">novel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">century</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">century</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">century</governor>
          <dependent id="31">20th</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">have</governor>
          <dependent id="32">century</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">have</governor>
          <dependent id="33">we</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="20">answered</governor>
          <dependent id="34">have</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">soaps</governor>
          <dependent id="35">TV</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="34">have</governor>
          <dependent id="36">soaps</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the 19th century" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="19th" />
            <token id="24" string="century" />
          </tokens>
        </entity>
        <entity id="2" string="the 20th century" type="DATE" score="0.0">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="20th" />
            <token id="32" string="century" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="true">
      <content>Just as the tabloid newspapers feature characters from EastEnders, so when Dickens&amp;apost; The Old Curiosity Shop was running as a serial there was widespread press speculation on whether Little Nell would die, and readers wrote in begging for her to be saved.</content>
      <tokens>
        <token id="1" string="Just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="tabloid" lemma="tabloid" stem="tabloid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="newspapers" lemma="newspaper" stem="newspap" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="feature" lemma="feature" stem="featur" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="characters" lemma="character" stem="charact" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="EastEnders" lemma="EastEnders" stem="eastender" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Dickens" lemma="Dickens" stem="dicken" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="The" lemma="The" stem="the" pos="NNP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Old" lemma="Old" stem="old" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Curiosity" lemma="Curiosity" stem="curios" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Shop" lemma="Shop" stem="shop" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="running" lemma="run" stem="run" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="serial" lemma="serial" stem="serial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="widespread" lemma="widespread" stem="widespread" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="press" lemma="press" stem="press" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="speculation" lemma="speculation" stem="specul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="Little" lemma="little" stem="littl" pos="JJ" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="Nell" lemma="Nell" stem="nell" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="33" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="die" lemma="die" stem="die" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="readers" lemma="reader" stem="reader" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="wrote" lemma="write" stem="wrote" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="begging" lemma="beg" stem="beg" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="saved" lemma="save" stem="save" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (RB Just) (IN as) (S (NP (DT the) (JJ tabloid) (NNS newspapers)) (VP (VBP feature) (NP (NNS characters)) (PP (IN from) (NP (NNP EastEnders)))))) (, ,) (S (SBAR (RB so) (WHADVP (WRB when)) (S (NP (NP (NNP Dickens) (POS ')) (NNP The) (NNP Old) (NNP Curiosity) (NNP Shop)) (VP (VBD was) (VP (VBG running) (PP (IN as) (NP (DT a) (NN serial))))))) (NP (EX there)) (VP (VBD was) (NP (NP (JJ widespread) (NN press) (NN speculation)) (PP (IN on) (SBAR (IN whether) (S (NP (JJ Little) (NNP Nell)) (VP (MD would) (VP (VB die))))))))) (, ,) (CC and) (S (NP (NNS readers)) (VP (VBD wrote) (PP (IN in) (S (VP (VBG begging) (PP (IN for) (NP (PRP$ her))) (S (VP (TO to) (VP (VB be) (VP (VBN saved)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the tabloid newspapers" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="tabloid" />
            <token id="5" string="newspapers" />
          </tokens>
        </chunking>
        <chunking id="2" string="running as a serial" type="VP">
          <tokens>
            <token id="20" string="running" />
            <token id="21" string="as" />
            <token id="22" string="a" />
            <token id="23" string="serial" />
          </tokens>
        </chunking>
        <chunking id="3" string="Dickens ' The Old Curiosity Shop" type="NP">
          <tokens>
            <token id="13" string="Dickens" />
            <token id="14" string="'" />
            <token id="15" string="The" />
            <token id="16" string="Old" />
            <token id="17" string="Curiosity" />
            <token id="18" string="Shop" />
          </tokens>
        </chunking>
        <chunking id="4" string="Dickens '" type="NP">
          <tokens>
            <token id="13" string="Dickens" />
            <token id="14" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="readers" type="NP">
          <tokens>
            <token id="37" string="readers" />
          </tokens>
        </chunking>
        <chunking id="6" string="widespread press speculation on whether Little Nell would die" type="NP">
          <tokens>
            <token id="26" string="widespread" />
            <token id="27" string="press" />
            <token id="28" string="speculation" />
            <token id="29" string="on" />
            <token id="30" string="whether" />
            <token id="31" string="Little" />
            <token id="32" string="Nell" />
            <token id="33" string="would" />
            <token id="34" string="die" />
          </tokens>
        </chunking>
        <chunking id="7" string="there" type="NP">
          <tokens>
            <token id="24" string="there" />
          </tokens>
        </chunking>
        <chunking id="8" string="would die" type="VP">
          <tokens>
            <token id="33" string="would" />
            <token id="34" string="die" />
          </tokens>
        </chunking>
        <chunking id="9" string="so when Dickens ' The Old Curiosity Shop was running as a serial" type="SBAR">
          <tokens>
            <token id="11" string="so" />
            <token id="12" string="when" />
            <token id="13" string="Dickens" />
            <token id="14" string="'" />
            <token id="15" string="The" />
            <token id="16" string="Old" />
            <token id="17" string="Curiosity" />
            <token id="18" string="Shop" />
            <token id="19" string="was" />
            <token id="20" string="running" />
            <token id="21" string="as" />
            <token id="22" string="a" />
            <token id="23" string="serial" />
          </tokens>
        </chunking>
        <chunking id="10" string="widespread press speculation" type="NP">
          <tokens>
            <token id="26" string="widespread" />
            <token id="27" string="press" />
            <token id="28" string="speculation" />
          </tokens>
        </chunking>
        <chunking id="11" string="die" type="VP">
          <tokens>
            <token id="34" string="die" />
          </tokens>
        </chunking>
        <chunking id="12" string="to be saved" type="VP">
          <tokens>
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="saved" />
          </tokens>
        </chunking>
        <chunking id="13" string="saved" type="VP">
          <tokens>
            <token id="45" string="saved" />
          </tokens>
        </chunking>
        <chunking id="14" string="begging for her to be saved" type="VP">
          <tokens>
            <token id="40" string="begging" />
            <token id="41" string="for" />
            <token id="42" string="her" />
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="saved" />
          </tokens>
        </chunking>
        <chunking id="15" string="EastEnders" type="NP">
          <tokens>
            <token id="9" string="EastEnders" />
          </tokens>
        </chunking>
        <chunking id="16" string="a serial" type="NP">
          <tokens>
            <token id="22" string="a" />
            <token id="23" string="serial" />
          </tokens>
        </chunking>
        <chunking id="17" string="when" type="WHADVP">
          <tokens>
            <token id="12" string="when" />
          </tokens>
        </chunking>
        <chunking id="18" string="wrote in begging for her to be saved" type="VP">
          <tokens>
            <token id="38" string="wrote" />
            <token id="39" string="in" />
            <token id="40" string="begging" />
            <token id="41" string="for" />
            <token id="42" string="her" />
            <token id="43" string="to" />
            <token id="44" string="be" />
            <token id="45" string="saved" />
          </tokens>
        </chunking>
        <chunking id="19" string="was running as a serial" type="VP">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="running" />
            <token id="21" string="as" />
            <token id="22" string="a" />
            <token id="23" string="serial" />
          </tokens>
        </chunking>
        <chunking id="20" string="be saved" type="VP">
          <tokens>
            <token id="44" string="be" />
            <token id="45" string="saved" />
          </tokens>
        </chunking>
        <chunking id="21" string="Little Nell" type="NP">
          <tokens>
            <token id="31" string="Little" />
            <token id="32" string="Nell" />
          </tokens>
        </chunking>
        <chunking id="22" string="Just as the tabloid newspapers feature characters from EastEnders" type="SBAR">
          <tokens>
            <token id="1" string="Just" />
            <token id="2" string="as" />
            <token id="3" string="the" />
            <token id="4" string="tabloid" />
            <token id="5" string="newspapers" />
            <token id="6" string="feature" />
            <token id="7" string="characters" />
            <token id="8" string="from" />
            <token id="9" string="EastEnders" />
          </tokens>
        </chunking>
        <chunking id="23" string="characters" type="NP">
          <tokens>
            <token id="7" string="characters" />
          </tokens>
        </chunking>
        <chunking id="24" string="feature characters from EastEnders" type="VP">
          <tokens>
            <token id="6" string="feature" />
            <token id="7" string="characters" />
            <token id="8" string="from" />
            <token id="9" string="EastEnders" />
          </tokens>
        </chunking>
        <chunking id="25" string="her" type="NP">
          <tokens>
            <token id="42" string="her" />
          </tokens>
        </chunking>
        <chunking id="26" string="was widespread press speculation on whether Little Nell would die" type="VP">
          <tokens>
            <token id="25" string="was" />
            <token id="26" string="widespread" />
            <token id="27" string="press" />
            <token id="28" string="speculation" />
            <token id="29" string="on" />
            <token id="30" string="whether" />
            <token id="31" string="Little" />
            <token id="32" string="Nell" />
            <token id="33" string="would" />
            <token id="34" string="die" />
          </tokens>
        </chunking>
        <chunking id="27" string="whether Little Nell would die" type="SBAR">
          <tokens>
            <token id="30" string="whether" />
            <token id="31" string="Little" />
            <token id="32" string="Nell" />
            <token id="33" string="would" />
            <token id="34" string="die" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">feature</governor>
          <dependent id="1">Just</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">feature</governor>
          <dependent id="2">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">newspapers</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">newspapers</governor>
          <dependent id="4">tabloid</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">feature</governor>
          <dependent id="5">newspapers</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="25">was</governor>
          <dependent id="6">feature</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">feature</governor>
          <dependent id="7">characters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">EastEnders</governor>
          <dependent id="8">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">feature</governor>
          <dependent id="9">EastEnders</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">running</governor>
          <dependent id="11">so</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">running</governor>
          <dependent id="12">when</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">Shop</governor>
          <dependent id="13">Dickens</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Dickens</governor>
          <dependent id="14">'</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Shop</governor>
          <dependent id="15">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Shop</governor>
          <dependent id="16">Old</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Shop</governor>
          <dependent id="17">Curiosity</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">running</governor>
          <dependent id="18">Shop</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="20">running</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="25">was</governor>
          <dependent id="20">running</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">serial</governor>
          <dependent id="21">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">serial</governor>
          <dependent id="22">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">running</governor>
          <dependent id="23">serial</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="25">was</governor>
          <dependent id="24">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="25">was</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">speculation</governor>
          <dependent id="26">widespread</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">speculation</governor>
          <dependent id="27">press</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">was</governor>
          <dependent id="28">speculation</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">die</governor>
          <dependent id="29">on</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="34">die</governor>
          <dependent id="30">whether</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">Nell</governor>
          <dependent id="31">Little</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="34">die</governor>
          <dependent id="32">Nell</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="34">die</governor>
          <dependent id="33">would</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="28">speculation</governor>
          <dependent id="34">die</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">was</governor>
          <dependent id="36">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">wrote</governor>
          <dependent id="37">readers</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">was</governor>
          <dependent id="38">wrote</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">begging</governor>
          <dependent id="39">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="38">wrote</governor>
          <dependent id="40">begging</dependent>
        </dependency>
        <dependency type="case">
          <governor id="42">her</governor>
          <dependent id="41">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="40">begging</governor>
          <dependent id="42">her</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="45">saved</governor>
          <dependent id="43">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="45">saved</governor>
          <dependent id="44">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="40">begging</governor>
          <dependent id="45">saved</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Little Nell" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Little" />
            <token id="32" string="Nell" />
          </tokens>
        </entity>
        <entity id="2" string="Dickens" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Dickens" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>Sentimentality, accessibility, topicality - what characterises today&amp;apost;s soaps were clear features of the novel in 1894.</content>
      <tokens>
        <token id="1" string="Sentimentality" lemma="sentimentality" stem="sentiment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="accessibility" lemma="accessibility" stem="access" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="topicality" lemma="topicality" stem="topic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="characterises" lemma="characterise" stem="characteris" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="soaps" lemma="soap" stem="soap" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="clear" lemma="clear" stem="clear" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="features" lemma="feature" stem="featur" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (NN Sentimentality)) (, ,) (NP (NN accessibility)) (, ,) (NP (NN topicality))) (: -) (SBAR (WHNP (WP what)) (S (VP (VBZ characterises) (SBAR (S (NP (NP (NN today) (POS 's)) (NNS soaps)) (VP (VBD were) (NP (NP (JJ clear) (NNS features)) (PP (IN of) (NP (NP (DT the) (NN novel)) (PP (IN in) (NP (CD 1894)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Sentimentality" type="NP">
          <tokens>
            <token id="1" string="Sentimentality" />
          </tokens>
        </chunking>
        <chunking id="2" string="the novel" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="novel" />
          </tokens>
        </chunking>
        <chunking id="3" string="today 's" type="NP">
          <tokens>
            <token id="9" string="today" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="accessibility" type="NP">
          <tokens>
            <token id="3" string="accessibility" />
          </tokens>
        </chunking>
        <chunking id="5" string="Sentimentality , accessibility , topicality" type="NP">
          <tokens>
            <token id="1" string="Sentimentality" />
            <token id="2" string="," />
            <token id="3" string="accessibility" />
            <token id="4" string="," />
            <token id="5" string="topicality" />
          </tokens>
        </chunking>
        <chunking id="6" string="topicality" type="NP">
          <tokens>
            <token id="5" string="topicality" />
          </tokens>
        </chunking>
        <chunking id="7" string="today 's soaps were clear features of the novel in 1894" type="SBAR">
          <tokens>
            <token id="9" string="today" />
            <token id="10" string="'s" />
            <token id="11" string="soaps" />
            <token id="12" string="were" />
            <token id="13" string="clear" />
            <token id="14" string="features" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="novel" />
            <token id="18" string="in" />
            <token id="19" string="1894" />
          </tokens>
        </chunking>
        <chunking id="8" string="characterises today 's soaps were clear features of the novel in 1894" type="VP">
          <tokens>
            <token id="8" string="characterises" />
            <token id="9" string="today" />
            <token id="10" string="'s" />
            <token id="11" string="soaps" />
            <token id="12" string="were" />
            <token id="13" string="clear" />
            <token id="14" string="features" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="novel" />
            <token id="18" string="in" />
            <token id="19" string="1894" />
          </tokens>
        </chunking>
        <chunking id="9" string="were clear features of the novel in 1894" type="VP">
          <tokens>
            <token id="12" string="were" />
            <token id="13" string="clear" />
            <token id="14" string="features" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="novel" />
            <token id="18" string="in" />
            <token id="19" string="1894" />
          </tokens>
        </chunking>
        <chunking id="10" string="Sentimentality , accessibility , topicality - what characterises today 's soaps were clear features of the novel in 1894 ." type="NP">
          <tokens>
            <token id="1" string="Sentimentality" />
            <token id="2" string="," />
            <token id="3" string="accessibility" />
            <token id="4" string="," />
            <token id="5" string="topicality" />
            <token id="6" string="-" />
            <token id="7" string="what" />
            <token id="8" string="characterises" />
            <token id="9" string="today" />
            <token id="10" string="'s" />
            <token id="11" string="soaps" />
            <token id="12" string="were" />
            <token id="13" string="clear" />
            <token id="14" string="features" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="novel" />
            <token id="18" string="in" />
            <token id="19" string="1894" />
            <token id="20" string="." />
          </tokens>
        </chunking>
        <chunking id="11" string="today 's soaps" type="NP">
          <tokens>
            <token id="9" string="today" />
            <token id="10" string="'s" />
            <token id="11" string="soaps" />
          </tokens>
        </chunking>
        <chunking id="12" string="what characterises today 's soaps were clear features of the novel in 1894" type="SBAR">
          <tokens>
            <token id="7" string="what" />
            <token id="8" string="characterises" />
            <token id="9" string="today" />
            <token id="10" string="'s" />
            <token id="11" string="soaps" />
            <token id="12" string="were" />
            <token id="13" string="clear" />
            <token id="14" string="features" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="novel" />
            <token id="18" string="in" />
            <token id="19" string="1894" />
          </tokens>
        </chunking>
        <chunking id="13" string="1894" type="NP">
          <tokens>
            <token id="19" string="1894" />
          </tokens>
        </chunking>
        <chunking id="14" string="clear features" type="NP">
          <tokens>
            <token id="13" string="clear" />
            <token id="14" string="features" />
          </tokens>
        </chunking>
        <chunking id="15" string="the novel in 1894" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="novel" />
            <token id="18" string="in" />
            <token id="19" string="1894" />
          </tokens>
        </chunking>
        <chunking id="16" string="clear features of the novel in 1894" type="NP">
          <tokens>
            <token id="13" string="clear" />
            <token id="14" string="features" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="novel" />
            <token id="18" string="in" />
            <token id="19" string="1894" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Sentimentality</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Sentimentality</governor>
          <dependent id="3">accessibility</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">Sentimentality</governor>
          <dependent id="5">topicality</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">characterises</governor>
          <dependent id="7">what</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="1">Sentimentality</governor>
          <dependent id="8">characterises</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">soaps</governor>
          <dependent id="9">today</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">today</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">features</governor>
          <dependent id="11">soaps</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">features</governor>
          <dependent id="12">were</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">features</governor>
          <dependent id="13">clear</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">characterises</governor>
          <dependent id="14">features</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">novel</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">novel</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">features</governor>
          <dependent id="17">novel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">1894</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">novel</governor>
          <dependent id="19">1894</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="9" string="today" />
          </tokens>
        </entity>
        <entity id="2" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="1894" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="true">
      <content>Both In the Year of Jubilee and Esther Waters, for example, centre on the burning 1890s debate about marriage, feminism and the &amp;apost;New Woman&amp;apost;, yet both are also tearjerkers which everyone enjoyed.</content>
      <tokens>
        <token id="1" string="Both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="Year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Jubilee" lemma="jubilee" stem="jubile" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Esther" lemma="Esther" stem="esther" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="9" string="Waters" lemma="Waters" stem="water" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="example" lemma="example" stem="exampl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="centre" lemma="centre" stem="centr" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="burning" lemma="burning" stem="burn" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="1890s" lemma="1890s" stem="1890" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="debate" lemma="debate" stem="debat" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="marriage" lemma="marriage" stem="marriag" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="feminism" lemma="feminism" stem="femin" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="27" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="28" string="Woman" lemma="Woman" stem="woman" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="29" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="yet" lemma="yet" stem="yet" pos="CC" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="both" lemma="both" stem="both" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="tearjerkers" lemma="tearjerker" stem="tearjerk" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="enjoyed" lemma="enjoy" stem="enjoi" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Both)) (PP (IN In) (NP (NP (NP (DT the) (NN Year)) (PP (IN of) (NP (NN Jubilee)))) (CC and) (NP (NNP Esther) (NNP Waters)) (, ,) (PP (IN for) (NP (NN example))) (, ,) (NP (NP (NN centre)) (PP (IN on) (NP (DT the) (NN burning)))))) (NP (NP (CD 1890s) (NN debate)) (PP (IN about) (NP (NP (NN marriage)) (, ,) (NP (NN feminism)) (CC and) (NP (NP (DT the) (`` `) (NNP New)) (NP (NNP Woman) (POS '))) (, ,) (ADVP (CC yet))))) (DT both) (VP (VBP are) (ADVP (RB also)) (NP (NP (NNS tearjerkers)) (SBAR (WHNP (WDT which)) (S (NP (NN everyone)) (VP (VBD enjoyed)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the Year of Jubilee" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Year" />
            <token id="5" string="of" />
            <token id="6" string="Jubilee" />
          </tokens>
        </chunking>
        <chunking id="2" string="the burning" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="burning" />
          </tokens>
        </chunking>
        <chunking id="3" string="everyone" type="NP">
          <tokens>
            <token id="37" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="4" string="feminism" type="NP">
          <tokens>
            <token id="23" string="feminism" />
          </tokens>
        </chunking>
        <chunking id="5" string="Esther Waters" type="NP">
          <tokens>
            <token id="8" string="Esther" />
            <token id="9" string="Waters" />
          </tokens>
        </chunking>
        <chunking id="6" string="centre" type="NP">
          <tokens>
            <token id="14" string="centre" />
          </tokens>
        </chunking>
        <chunking id="7" string="marriage , feminism and the ` New Woman ' , yet" type="NP">
          <tokens>
            <token id="21" string="marriage" />
            <token id="22" string="," />
            <token id="23" string="feminism" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="New" />
            <token id="28" string="Woman" />
            <token id="29" string="'" />
            <token id="30" string="," />
            <token id="31" string="yet" />
          </tokens>
        </chunking>
        <chunking id="8" string="example" type="NP">
          <tokens>
            <token id="12" string="example" />
          </tokens>
        </chunking>
        <chunking id="9" string="1890s debate about marriage , feminism and the ` New Woman ' , yet" type="NP">
          <tokens>
            <token id="18" string="1890s" />
            <token id="19" string="debate" />
            <token id="20" string="about" />
            <token id="21" string="marriage" />
            <token id="22" string="," />
            <token id="23" string="feminism" />
            <token id="24" string="and" />
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="New" />
            <token id="28" string="Woman" />
            <token id="29" string="'" />
            <token id="30" string="," />
            <token id="31" string="yet" />
          </tokens>
        </chunking>
        <chunking id="10" string="Jubilee" type="NP">
          <tokens>
            <token id="6" string="Jubilee" />
          </tokens>
        </chunking>
        <chunking id="11" string="which everyone enjoyed" type="SBAR">
          <tokens>
            <token id="36" string="which" />
            <token id="37" string="everyone" />
            <token id="38" string="enjoyed" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Year of Jubilee and Esther Waters , for example , centre on the burning" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Year" />
            <token id="5" string="of" />
            <token id="6" string="Jubilee" />
            <token id="7" string="and" />
            <token id="8" string="Esther" />
            <token id="9" string="Waters" />
            <token id="10" string="," />
            <token id="11" string="for" />
            <token id="12" string="example" />
            <token id="13" string="," />
            <token id="14" string="centre" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="burning" />
          </tokens>
        </chunking>
        <chunking id="13" string="marriage" type="NP">
          <tokens>
            <token id="21" string="marriage" />
          </tokens>
        </chunking>
        <chunking id="14" string="the ` New" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="New" />
          </tokens>
        </chunking>
        <chunking id="15" string="the ` New Woman '" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="'" />
            <token id="27" string="New" />
            <token id="28" string="Woman" />
            <token id="29" string="'" />
          </tokens>
        </chunking>
        <chunking id="16" string="are also tearjerkers which everyone enjoyed" type="VP">
          <tokens>
            <token id="33" string="are" />
            <token id="34" string="also" />
            <token id="35" string="tearjerkers" />
            <token id="36" string="which" />
            <token id="37" string="everyone" />
            <token id="38" string="enjoyed" />
          </tokens>
        </chunking>
        <chunking id="17" string="tearjerkers" type="NP">
          <tokens>
            <token id="35" string="tearjerkers" />
          </tokens>
        </chunking>
        <chunking id="18" string="centre on the burning" type="NP">
          <tokens>
            <token id="14" string="centre" />
            <token id="15" string="on" />
            <token id="16" string="the" />
            <token id="17" string="burning" />
          </tokens>
        </chunking>
        <chunking id="19" string="1890s debate" type="NP">
          <tokens>
            <token id="18" string="1890s" />
            <token id="19" string="debate" />
          </tokens>
        </chunking>
        <chunking id="20" string="the Year" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Year" />
          </tokens>
        </chunking>
        <chunking id="21" string="Woman '" type="NP">
          <tokens>
            <token id="28" string="Woman" />
            <token id="29" string="'" />
          </tokens>
        </chunking>
        <chunking id="22" string="enjoyed" type="VP">
          <tokens>
            <token id="38" string="enjoyed" />
          </tokens>
        </chunking>
        <chunking id="23" string="tearjerkers which everyone enjoyed" type="NP">
          <tokens>
            <token id="35" string="tearjerkers" />
            <token id="36" string="which" />
            <token id="37" string="everyone" />
            <token id="38" string="enjoyed" />
          </tokens>
        </chunking>
        <chunking id="24" string="Both" type="NP">
          <tokens>
            <token id="1" string="Both" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="35">tearjerkers</governor>
          <dependent id="1">Both</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">Year</governor>
          <dependent id="2">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Year</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">tearjerkers</governor>
          <dependent id="4">Year</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Jubilee</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">Year</governor>
          <dependent id="6">Jubilee</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="35">tearjerkers</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Waters</governor>
          <dependent id="8">Esther</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Year</governor>
          <dependent id="9">Waters</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">example</governor>
          <dependent id="11">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">tearjerkers</governor>
          <dependent id="12">example</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">Year</governor>
          <dependent id="14">centre</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">burning</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">burning</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">centre</governor>
          <dependent id="17">burning</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">debate</governor>
          <dependent id="18">1890s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="35">tearjerkers</governor>
          <dependent id="19">debate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">marriage</governor>
          <dependent id="20">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">debate</governor>
          <dependent id="21">marriage</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">marriage</governor>
          <dependent id="23">feminism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="21">marriage</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">New</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="21">marriage</governor>
          <dependent id="27">New</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">New</governor>
          <dependent id="28">Woman</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Woman</governor>
          <dependent id="29">'</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="21">marriage</governor>
          <dependent id="31">yet</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="35">tearjerkers</governor>
          <dependent id="32">both</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="35">tearjerkers</governor>
          <dependent id="33">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">tearjerkers</governor>
          <dependent id="34">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="35">tearjerkers</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="35">tearjerkers</governor>
          <dependent id="35">tearjerkers</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="38">enjoyed</governor>
          <dependent id="36">which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="38">enjoyed</governor>
          <dependent id="37">everyone</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="35">tearjerkers</governor>
          <dependent id="38">enjoyed</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="feminism" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="23" string="feminism" />
          </tokens>
        </entity>
        <entity id="2" string="Esther Waters" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Esther" />
            <token id="9" string="Waters" />
          </tokens>
        </entity>
        <entity id="3" string="centre" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="14" string="centre" />
          </tokens>
        </entity>
        <entity id="4" string="1890s" type="DATE" score="0.0">
          <tokens>
            <token id="18" string="1890s" />
          </tokens>
        </entity>
        <entity id="5" string="' New Woman" type="MISC" score="0.0">
          <tokens>
            <token id="26" string="'" />
            <token id="27" string="New" />
            <token id="28" string="Woman" />
          </tokens>
        </entity>
        <entity id="6" string="the Year" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="47" has_coreference="true">
      <content>The 1894 books are compelling because they prefigure our own times and yet are set back from them.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="compelling" lemma="compelling" stem="compel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="prefigure" lemma="prefigure" stem="prefigur" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="our" lemma="we" stem="our" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="times" lemma="time" stem="time" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="set" lemma="set" stem="set" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="back" lemma="back" stem="back" pos="RP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="them" lemma="they" stem="them" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (CD 1894) (NNS books)) (VP (VBP are) (ADJP (JJ compelling) (SBAR (IN because) (S (NP (PRP they)) (VP (VP (VBP prefigure) (NP (PRP$ our) (JJ own) (NNS times))) (CC and) (ADVP (RB yet)) (VP (VBP are) (VP (VBN set) (PRT (RP back)) (PP (IN from) (NP (PRP them)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="7" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="compelling because they prefigure our own times and yet are set back from them" type="ADJP">
          <tokens>
            <token id="5" string="compelling" />
            <token id="6" string="because" />
            <token id="7" string="they" />
            <token id="8" string="prefigure" />
            <token id="9" string="our" />
            <token id="10" string="own" />
            <token id="11" string="times" />
            <token id="12" string="and" />
            <token id="13" string="yet" />
            <token id="14" string="are" />
            <token id="15" string="set" />
            <token id="16" string="back" />
            <token id="17" string="from" />
            <token id="18" string="them" />
          </tokens>
        </chunking>
        <chunking id="3" string="prefigure our own times and yet are set back from them" type="VP">
          <tokens>
            <token id="8" string="prefigure" />
            <token id="9" string="our" />
            <token id="10" string="own" />
            <token id="11" string="times" />
            <token id="12" string="and" />
            <token id="13" string="yet" />
            <token id="14" string="are" />
            <token id="15" string="set" />
            <token id="16" string="back" />
            <token id="17" string="from" />
            <token id="18" string="them" />
          </tokens>
        </chunking>
        <chunking id="4" string="The 1894 books" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="1894" />
            <token id="3" string="books" />
          </tokens>
        </chunking>
        <chunking id="5" string="are compelling because they prefigure our own times and yet are set back from them" type="VP">
          <tokens>
            <token id="4" string="are" />
            <token id="5" string="compelling" />
            <token id="6" string="because" />
            <token id="7" string="they" />
            <token id="8" string="prefigure" />
            <token id="9" string="our" />
            <token id="10" string="own" />
            <token id="11" string="times" />
            <token id="12" string="and" />
            <token id="13" string="yet" />
            <token id="14" string="are" />
            <token id="15" string="set" />
            <token id="16" string="back" />
            <token id="17" string="from" />
            <token id="18" string="them" />
          </tokens>
        </chunking>
        <chunking id="6" string="set back from them" type="VP">
          <tokens>
            <token id="15" string="set" />
            <token id="16" string="back" />
            <token id="17" string="from" />
            <token id="18" string="them" />
          </tokens>
        </chunking>
        <chunking id="7" string="prefigure our own times" type="VP">
          <tokens>
            <token id="8" string="prefigure" />
            <token id="9" string="our" />
            <token id="10" string="own" />
            <token id="11" string="times" />
          </tokens>
        </chunking>
        <chunking id="8" string="because they prefigure our own times and yet are set back from them" type="SBAR">
          <tokens>
            <token id="6" string="because" />
            <token id="7" string="they" />
            <token id="8" string="prefigure" />
            <token id="9" string="our" />
            <token id="10" string="own" />
            <token id="11" string="times" />
            <token id="12" string="and" />
            <token id="13" string="yet" />
            <token id="14" string="are" />
            <token id="15" string="set" />
            <token id="16" string="back" />
            <token id="17" string="from" />
            <token id="18" string="them" />
          </tokens>
        </chunking>
        <chunking id="9" string="our own times" type="NP">
          <tokens>
            <token id="9" string="our" />
            <token id="10" string="own" />
            <token id="11" string="times" />
          </tokens>
        </chunking>
        <chunking id="10" string="them" type="NP">
          <tokens>
            <token id="18" string="them" />
          </tokens>
        </chunking>
        <chunking id="11" string="are set back from them" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="set" />
            <token id="16" string="back" />
            <token id="17" string="from" />
            <token id="18" string="them" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">books</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="3">books</governor>
          <dependent id="2">1894</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">compelling</governor>
          <dependent id="3">books</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">compelling</governor>
          <dependent id="4">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">compelling</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">prefigure</governor>
          <dependent id="6">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">prefigure</governor>
          <dependent id="7">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">compelling</governor>
          <dependent id="8">prefigure</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">times</governor>
          <dependent id="9">our</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">times</governor>
          <dependent id="10">own</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">prefigure</governor>
          <dependent id="11">times</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">prefigure</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">set</governor>
          <dependent id="13">yet</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="15">set</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">prefigure</governor>
          <dependent id="15">set</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="15">set</governor>
          <dependent id="16">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">them</governor>
          <dependent id="17">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">set</governor>
          <dependent id="18">them</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1894" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="48" has_coreference="false">
      <content>Trilby is a tale of hypnotism and the unconscious a decade away from Freud; The Ebb Tide paved the way for Conrad&amp;apost;s Heart of Darkness and the first questioning of colonial oppression.</content>
      <tokens>
        <token id="1" string="Trilby" lemma="Trilby" stem="trilbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="tale" lemma="tale" stem="tale" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="hypnotism" lemma="hypnotism" stem="hypnot" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="unconscious" lemma="unconscious" stem="unconsci" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="11" string="decade" lemma="decade" stem="decad" pos="NN" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="12" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Freud" lemma="Freud" stem="freud" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="Ebb" lemma="ebb" stem="ebb" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="18" string="Tide" lemma="Tide" stem="tide" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="19" string="paved" lemma="pave" stem="pave" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="way" lemma="way" stem="wai" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Conrad" lemma="Conrad" stem="conrad" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="24" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Heart" lemma="Heart" stem="heart" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="Darkness" lemma="darkness" stem="dark" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="first" lemma="first" stem="first" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="31" string="questioning" lemma="question" stem="question" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="colonial" lemma="colonial" stem="coloni" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="oppression" lemma="oppression" stem="oppress" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NNP Trilby)) (VP (VBZ is) (NP (NP (NP (DT a) (NN tale)) (PP (IN of) (NP (NN hypnotism)))) (CC and) (NP (DT the) (ADJP (JJ unconscious) (PP (ADVP (NP (DT a) (NN decade)) (RB away)) (IN from) (NP (NNP Freud)))))))) (: ;) (S (NP (DT The) (NN Ebb) (NNP Tide)) (VP (VBD paved) (NP (NP (DT the) (NN way)) (PP (IN for) (NP (NP (NP (NP (NNP Conrad) (POS 's)) (NNP Heart)) (PP (IN of) (NP (NN Darkness)))) (CC and) (NP (NP (DT the) (JJ first) (VBG questioning)) (PP (IN of) (NP (NN colonial) (NN oppression))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Darkness" type="NP">
          <tokens>
            <token id="27" string="Darkness" />
          </tokens>
        </chunking>
        <chunking id="2" string="the unconscious a decade away from Freud" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="unconscious" />
            <token id="10" string="a" />
            <token id="11" string="decade" />
            <token id="12" string="away" />
            <token id="13" string="from" />
            <token id="14" string="Freud" />
          </tokens>
        </chunking>
        <chunking id="3" string="the first questioning of colonial oppression" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="first" />
            <token id="31" string="questioning" />
            <token id="32" string="of" />
            <token id="33" string="colonial" />
            <token id="34" string="oppression" />
          </tokens>
        </chunking>
        <chunking id="4" string="colonial oppression" type="NP">
          <tokens>
            <token id="33" string="colonial" />
            <token id="34" string="oppression" />
          </tokens>
        </chunking>
        <chunking id="5" string="is a tale of hypnotism and the unconscious a decade away from Freud" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="a" />
            <token id="4" string="tale" />
            <token id="5" string="of" />
            <token id="6" string="hypnotism" />
            <token id="7" string="and" />
            <token id="8" string="the" />
            <token id="9" string="unconscious" />
            <token id="10" string="a" />
            <token id="11" string="decade" />
            <token id="12" string="away" />
            <token id="13" string="from" />
            <token id="14" string="Freud" />
          </tokens>
        </chunking>
        <chunking id="6" string="a decade" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="decade" />
          </tokens>
        </chunking>
        <chunking id="7" string="unconscious a decade away from Freud" type="ADJP">
          <tokens>
            <token id="9" string="unconscious" />
            <token id="10" string="a" />
            <token id="11" string="decade" />
            <token id="12" string="away" />
            <token id="13" string="from" />
            <token id="14" string="Freud" />
          </tokens>
        </chunking>
        <chunking id="8" string="Freud" type="NP">
          <tokens>
            <token id="14" string="Freud" />
          </tokens>
        </chunking>
        <chunking id="9" string="a tale of hypnotism" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="tale" />
            <token id="5" string="of" />
            <token id="6" string="hypnotism" />
          </tokens>
        </chunking>
        <chunking id="10" string="The Ebb Tide" type="NP">
          <tokens>
            <token id="16" string="The" />
            <token id="17" string="Ebb" />
            <token id="18" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="11" string="a tale of hypnotism and the unconscious a decade away from Freud" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="tale" />
            <token id="5" string="of" />
            <token id="6" string="hypnotism" />
            <token id="7" string="and" />
            <token id="8" string="the" />
            <token id="9" string="unconscious" />
            <token id="10" string="a" />
            <token id="11" string="decade" />
            <token id="12" string="away" />
            <token id="13" string="from" />
            <token id="14" string="Freud" />
          </tokens>
        </chunking>
        <chunking id="12" string="hypnotism" type="NP">
          <tokens>
            <token id="6" string="hypnotism" />
          </tokens>
        </chunking>
        <chunking id="13" string="Conrad 's Heart of Darkness and the first questioning of colonial oppression" type="NP">
          <tokens>
            <token id="23" string="Conrad" />
            <token id="24" string="'s" />
            <token id="25" string="Heart" />
            <token id="26" string="of" />
            <token id="27" string="Darkness" />
            <token id="28" string="and" />
            <token id="29" string="the" />
            <token id="30" string="first" />
            <token id="31" string="questioning" />
            <token id="32" string="of" />
            <token id="33" string="colonial" />
            <token id="34" string="oppression" />
          </tokens>
        </chunking>
        <chunking id="14" string="paved the way for Conrad 's Heart of Darkness and the first questioning of colonial oppression" type="VP">
          <tokens>
            <token id="19" string="paved" />
            <token id="20" string="the" />
            <token id="21" string="way" />
            <token id="22" string="for" />
            <token id="23" string="Conrad" />
            <token id="24" string="'s" />
            <token id="25" string="Heart" />
            <token id="26" string="of" />
            <token id="27" string="Darkness" />
            <token id="28" string="and" />
            <token id="29" string="the" />
            <token id="30" string="first" />
            <token id="31" string="questioning" />
            <token id="32" string="of" />
            <token id="33" string="colonial" />
            <token id="34" string="oppression" />
          </tokens>
        </chunking>
        <chunking id="15" string="the way for Conrad 's Heart of Darkness and the first questioning of colonial oppression" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="way" />
            <token id="22" string="for" />
            <token id="23" string="Conrad" />
            <token id="24" string="'s" />
            <token id="25" string="Heart" />
            <token id="26" string="of" />
            <token id="27" string="Darkness" />
            <token id="28" string="and" />
            <token id="29" string="the" />
            <token id="30" string="first" />
            <token id="31" string="questioning" />
            <token id="32" string="of" />
            <token id="33" string="colonial" />
            <token id="34" string="oppression" />
          </tokens>
        </chunking>
        <chunking id="16" string="the way" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="way" />
          </tokens>
        </chunking>
        <chunking id="17" string="the first questioning" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="first" />
            <token id="31" string="questioning" />
          </tokens>
        </chunking>
        <chunking id="18" string="Trilby" type="NP">
          <tokens>
            <token id="1" string="Trilby" />
          </tokens>
        </chunking>
        <chunking id="19" string="Conrad 's Heart of Darkness" type="NP">
          <tokens>
            <token id="23" string="Conrad" />
            <token id="24" string="'s" />
            <token id="25" string="Heart" />
            <token id="26" string="of" />
            <token id="27" string="Darkness" />
          </tokens>
        </chunking>
        <chunking id="20" string="a tale" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="tale" />
          </tokens>
        </chunking>
        <chunking id="21" string="Conrad 's Heart" type="NP">
          <tokens>
            <token id="23" string="Conrad" />
            <token id="24" string="'s" />
            <token id="25" string="Heart" />
          </tokens>
        </chunking>
        <chunking id="22" string="Conrad 's" type="NP">
          <tokens>
            <token id="23" string="Conrad" />
            <token id="24" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">tale</governor>
          <dependent id="1">Trilby</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">tale</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">tale</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">tale</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">hypnotism</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">tale</governor>
          <dependent id="6">hypnotism</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">tale</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">unconscious</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">tale</governor>
          <dependent id="9">unconscious</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">decade</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="12">away</governor>
          <dependent id="11">decade</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">Freud</governor>
          <dependent id="12">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Freud</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">unconscious</governor>
          <dependent id="14">Freud</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">Tide</governor>
          <dependent id="16">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Tide</governor>
          <dependent id="17">Ebb</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">paved</governor>
          <dependent id="18">Tide</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">tale</governor>
          <dependent id="19">paved</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">way</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">paved</governor>
          <dependent id="21">way</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Heart</governor>
          <dependent id="22">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="25">Heart</governor>
          <dependent id="23">Conrad</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Conrad</governor>
          <dependent id="24">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">way</governor>
          <dependent id="25">Heart</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">Darkness</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">Heart</governor>
          <dependent id="27">Darkness</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">Heart</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">first</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">Heart</governor>
          <dependent id="30">first</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">first</governor>
          <dependent id="31">questioning</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">oppression</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="34">oppression</governor>
          <dependent id="33">colonial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">first</governor>
          <dependent id="34">oppression</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="first" type="ORDINAL" score="0.0">
          <tokens>
            <token id="30" string="first" />
          </tokens>
        </entity>
        <entity id="2" string="a decade" type="DURATION" score="0.0">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="decade" />
          </tokens>
        </entity>
        <entity id="3" string="Conrad" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="23" string="Conrad" />
          </tokens>
        </entity>
        <entity id="4" string="Freud" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="14" string="Freud" />
          </tokens>
        </entity>
        <entity id="5" string="Trilby" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Trilby" />
          </tokens>
        </entity>
        <entity id="6" string="Ebb Tide" type="MISC" score="0.0">
          <tokens>
            <token id="17" string="Ebb" />
            <token id="18" string="Tide" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>It is unlikely that the 1994 Booker choices will speak as eloquently of new trends today.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="unlikely" lemma="unlikely" stem="unlik" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="1994" lemma="1994" stem="1994" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="7" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="choices" lemma="choice" stem="choic" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="speak" lemma="speak" stem="speak" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="eloquently" lemma="eloquently" stem="eloqu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="trends" lemma="trend" stem="trend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBZ is) (ADJP (JJ unlikely)) (SBAR (IN that) (S (NP (DT the) (CD 1994) (NNP Booker) (NNS choices)) (VP (MD will) (VP (VB speak) (ADVP (IN as) (RB eloquently)) (PP (IN of) (NP (JJ new) (NNS trends))) (NP-TMP (NN today))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="unlikely" type="ADJP">
          <tokens>
            <token id="3" string="unlikely" />
          </tokens>
        </chunking>
        <chunking id="2" string="speak as eloquently of new trends today" type="VP">
          <tokens>
            <token id="10" string="speak" />
            <token id="11" string="as" />
            <token id="12" string="eloquently" />
            <token id="13" string="of" />
            <token id="14" string="new" />
            <token id="15" string="trends" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="3" string="that the 1994 Booker choices will speak as eloquently of new trends today" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="1994" />
            <token id="7" string="Booker" />
            <token id="8" string="choices" />
            <token id="9" string="will" />
            <token id="10" string="speak" />
            <token id="11" string="as" />
            <token id="12" string="eloquently" />
            <token id="13" string="of" />
            <token id="14" string="new" />
            <token id="15" string="trends" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="will speak as eloquently of new trends today" type="VP">
          <tokens>
            <token id="9" string="will" />
            <token id="10" string="speak" />
            <token id="11" string="as" />
            <token id="12" string="eloquently" />
            <token id="13" string="of" />
            <token id="14" string="new" />
            <token id="15" string="trends" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="6" string="new trends" type="NP">
          <tokens>
            <token id="14" string="new" />
            <token id="15" string="trends" />
          </tokens>
        </chunking>
        <chunking id="7" string="is unlikely that the 1994 Booker choices will speak as eloquently of new trends today" type="VP">
          <tokens>
            <token id="2" string="is" />
            <token id="3" string="unlikely" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="1994" />
            <token id="7" string="Booker" />
            <token id="8" string="choices" />
            <token id="9" string="will" />
            <token id="10" string="speak" />
            <token id="11" string="as" />
            <token id="12" string="eloquently" />
            <token id="13" string="of" />
            <token id="14" string="new" />
            <token id="15" string="trends" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="8" string="the 1994 Booker choices" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="1994" />
            <token id="7" string="Booker" />
            <token id="8" string="choices" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">unlikely</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">unlikely</governor>
          <dependent id="2">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">unlikely</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">speak</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">choices</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">choices</governor>
          <dependent id="6">1994</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">choices</governor>
          <dependent id="7">Booker</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">speak</governor>
          <dependent id="8">choices</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">speak</governor>
          <dependent id="9">will</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">unlikely</governor>
          <dependent id="10">speak</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">eloquently</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">speak</governor>
          <dependent id="12">eloquently</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">trends</governor>
          <dependent id="13">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">trends</governor>
          <dependent id="14">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">speak</governor>
          <dependent id="15">trends</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="10">speak</governor>
          <dependent id="16">today</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1994" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="1994" />
          </tokens>
        </entity>
        <entity id="2" string="Booker" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="Booker" />
          </tokens>
        </entity>
        <entity id="3" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="today" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>Whereas the 1894 titles had contemporary settings, many of the 1994 books are historical (such as Paradise) or are driven by nostalgia (such as Beside the Ocean of Time).</content>
      <tokens>
        <token id="1" string="Whereas" lemma="whereas" stem="wherea" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="titles" lemma="title" stem="titl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="contemporary" lemma="contemporary" stem="contemporari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="settings" lemma="setting" stem="set" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="1994" lemma="1994" stem="1994" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="13" string="books" lemma="book" stem="book" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="historical" lemma="historical" stem="histor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Paradise" lemma="Paradise" stem="paradis" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="driven" lemma="drive" stem="driven" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="nostalgia" lemma="nostalgia" stem="nostalgia" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Beside" lemma="beside" stem="besid" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="Ocean" lemma="ocean" stem="ocean" pos="NN" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="32" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="33" string="Time" lemma="Time" stem="time" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="34" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN Whereas) (S (NP (DT the) (CD 1894) (NNS titles)) (VP (VBD had) (NP (JJ contemporary) (NNS settings))))) (, ,) (NP (NP (JJ many)) (PP (IN of) (NP (DT the) (CD 1994) (NNS books)))) (VP (VP (VBP are) (ADJP (ADJP (JJ historical)) (PRN (-LRB- -LRB-) (PP (JJ such) (IN as) (NP (NNP Paradise))) (-RRB- -RRB-)))) (CC or) (VP (VBP are) (VP (VBN driven) (PP (IN by) (NP (NN nostalgia))) (PRN (-LRB- -LRB-) (PP (JJ such) (PP (IN as) (PP (IN Beside) (NP (NP (DT the) (NN Ocean)) (PP (IN of) (NP (NNP Time))))))) (-RRB- -RRB-))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="contemporary settings" type="NP">
          <tokens>
            <token id="6" string="contemporary" />
            <token id="7" string="settings" />
          </tokens>
        </chunking>
        <chunking id="2" string="nostalgia" type="NP">
          <tokens>
            <token id="25" string="nostalgia" />
          </tokens>
        </chunking>
        <chunking id="3" string="historical -LRB- such as Paradise -RRB-" type="ADJP">
          <tokens>
            <token id="15" string="historical" />
            <token id="16" string="(" />
            <token id="17" string="such" />
            <token id="18" string="as" />
            <token id="19" string="Paradise" />
            <token id="20" string=")" />
          </tokens>
        </chunking>
        <chunking id="4" string="are historical -LRB- such as Paradise -RRB-" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="historical" />
            <token id="16" string="(" />
            <token id="17" string="such" />
            <token id="18" string="as" />
            <token id="19" string="Paradise" />
            <token id="20" string=")" />
          </tokens>
        </chunking>
        <chunking id="5" string="historical" type="ADJP">
          <tokens>
            <token id="15" string="historical" />
          </tokens>
        </chunking>
        <chunking id="6" string="driven by nostalgia -LRB- such as Beside the Ocean of Time -RRB-" type="VP">
          <tokens>
            <token id="23" string="driven" />
            <token id="24" string="by" />
            <token id="25" string="nostalgia" />
            <token id="26" string="(" />
            <token id="27" string="such" />
            <token id="28" string="as" />
            <token id="29" string="Beside" />
            <token id="30" string="the" />
            <token id="31" string="Ocean" />
            <token id="32" string="of" />
            <token id="33" string="Time" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Ocean of Time" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Ocean" />
            <token id="32" string="of" />
            <token id="33" string="Time" />
          </tokens>
        </chunking>
        <chunking id="8" string="Time" type="NP">
          <tokens>
            <token id="33" string="Time" />
          </tokens>
        </chunking>
        <chunking id="9" string="many" type="NP">
          <tokens>
            <token id="9" string="many" />
          </tokens>
        </chunking>
        <chunking id="10" string="the 1994 books" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="1994" />
            <token id="13" string="books" />
          </tokens>
        </chunking>
        <chunking id="11" string="are historical -LRB- such as Paradise -RRB- or are driven by nostalgia -LRB- such as Beside the Ocean of Time -RRB-" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="historical" />
            <token id="16" string="(" />
            <token id="17" string="such" />
            <token id="18" string="as" />
            <token id="19" string="Paradise" />
            <token id="20" string=")" />
            <token id="21" string="or" />
            <token id="22" string="are" />
            <token id="23" string="driven" />
            <token id="24" string="by" />
            <token id="25" string="nostalgia" />
            <token id="26" string="(" />
            <token id="27" string="such" />
            <token id="28" string="as" />
            <token id="29" string="Beside" />
            <token id="30" string="the" />
            <token id="31" string="Ocean" />
            <token id="32" string="of" />
            <token id="33" string="Time" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="12" string="many of the 1994 books" type="NP">
          <tokens>
            <token id="9" string="many" />
            <token id="10" string="of" />
            <token id="11" string="the" />
            <token id="12" string="1994" />
            <token id="13" string="books" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Ocean" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="Ocean" />
          </tokens>
        </chunking>
        <chunking id="14" string="Whereas the 1894 titles had contemporary settings" type="SBAR">
          <tokens>
            <token id="1" string="Whereas" />
            <token id="2" string="the" />
            <token id="3" string="1894" />
            <token id="4" string="titles" />
            <token id="5" string="had" />
            <token id="6" string="contemporary" />
            <token id="7" string="settings" />
          </tokens>
        </chunking>
        <chunking id="15" string="the 1894 titles" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="1894" />
            <token id="4" string="titles" />
          </tokens>
        </chunking>
        <chunking id="16" string="are driven by nostalgia -LRB- such as Beside the Ocean of Time -RRB-" type="VP">
          <tokens>
            <token id="22" string="are" />
            <token id="23" string="driven" />
            <token id="24" string="by" />
            <token id="25" string="nostalgia" />
            <token id="26" string="(" />
            <token id="27" string="such" />
            <token id="28" string="as" />
            <token id="29" string="Beside" />
            <token id="30" string="the" />
            <token id="31" string="Ocean" />
            <token id="32" string="of" />
            <token id="33" string="Time" />
            <token id="34" string=")" />
          </tokens>
        </chunking>
        <chunking id="17" string="Paradise" type="NP">
          <tokens>
            <token id="19" string="Paradise" />
          </tokens>
        </chunking>
        <chunking id="18" string="had contemporary settings" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="contemporary" />
            <token id="7" string="settings" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">had</governor>
          <dependent id="1">Whereas</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">titles</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">titles</governor>
          <dependent id="3">1894</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">had</governor>
          <dependent id="4">titles</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">historical</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">settings</governor>
          <dependent id="6">contemporary</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">had</governor>
          <dependent id="7">settings</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">historical</governor>
          <dependent id="9">many</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">books</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">books</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">books</governor>
          <dependent id="12">1994</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">many</governor>
          <dependent id="13">books</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">historical</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">historical</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Paradise</governor>
          <dependent id="17">such</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="17">such</governor>
          <dependent id="18">as</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">historical</governor>
          <dependent id="19">Paradise</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">historical</governor>
          <dependent id="21">or</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">driven</governor>
          <dependent id="22">are</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">historical</governor>
          <dependent id="23">driven</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">nostalgia</governor>
          <dependent id="24">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">driven</governor>
          <dependent id="25">nostalgia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Ocean</governor>
          <dependent id="27">such</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Ocean</governor>
          <dependent id="28">as</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Ocean</governor>
          <dependent id="29">Beside</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">Ocean</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">driven</governor>
          <dependent id="31">Ocean</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">Time</governor>
          <dependent id="32">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">Ocean</governor>
          <dependent id="33">Time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1994" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="1994" />
          </tokens>
        </entity>
        <entity id="2" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="1894" />
          </tokens>
        </entity>
        <entity id="3" string="Ocean of Time" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="31" string="Ocean" />
            <token id="32" string="of" />
            <token id="33" string="Time" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="51" has_coreference="true">
      <content>Which book will win on October 15?</content>
      <tokens>
        <token id="1" string="Which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="win" lemma="win" stem="win" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="October" lemma="October" stem="october" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="7" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="8" string="?" lemma="?" stem="?" pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SBARQ (WHNP (WDT Which) (NN book)) (SQ (VP (MD will) (VP (VB win) (PP (IN on) (NP (NNP October) (CD 15)))))) (. ?)))</syntactictree>
      <chunkings>
        <chunking id="1" string="win on October 15" type="VP">
          <tokens>
            <token id="4" string="win" />
            <token id="5" string="on" />
            <token id="6" string="October" />
            <token id="7" string="15" />
          </tokens>
        </chunking>
        <chunking id="2" string="October 15" type="NP">
          <tokens>
            <token id="6" string="October" />
            <token id="7" string="15" />
          </tokens>
        </chunking>
        <chunking id="3" string="will win on October 15" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="win" />
            <token id="5" string="on" />
            <token id="6" string="October" />
            <token id="7" string="15" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">book</governor>
          <dependent id="1">Which</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">win</governor>
          <dependent id="2">book</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">win</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">win</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">October</governor>
          <dependent id="5">on</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">win</governor>
          <dependent id="6">October</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">October</governor>
          <dependent id="7">15</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="October 15" type="DATE" score="0.0">
          <tokens>
            <token id="6" string="October" />
            <token id="7" string="15" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="52" has_coreference="true">
      <content>Stevenson will get the sympathy vote because he died in 1894 in Samoa, the setting of The Ebb Tide.</content>
      <tokens>
        <token id="1" string="Stevenson" lemma="Stevenson" stem="stevenson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sympathy" lemma="sympathy" stem="sympathi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="died" lemma="die" stem="di" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="1894" lemma="1894" stem="1894" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Samoa" lemma="Samoa" stem="samoa" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="setting" lemma="setting" stem="set" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Ebb" lemma="ebb" stem="ebb" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="20" string="Tide" lemma="Tide" stem="tide" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Stevenson)) (VP (MD will) (VP (VB get) (NP (DT the) (NN sympathy) (NN vote)) (SBAR (IN because) (S (NP (PRP he)) (VP (VBD died) (PP (IN in) (NP (CD 1894))) (PP (IN in) (NP (NP (NNP Samoa)) (, ,) (NP (NP (DT the) (NN setting)) (PP (IN of) (NP (DT The) (NN Ebb) (NNP Tide))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the sympathy vote" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="sympathy" />
            <token id="6" string="vote" />
          </tokens>
        </chunking>
        <chunking id="2" string="the setting of The Ebb Tide" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="setting" />
            <token id="17" string="of" />
            <token id="18" string="The" />
            <token id="19" string="Ebb" />
            <token id="20" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="3" string="because he died in 1894 in Samoa , the setting of The Ebb Tide" type="SBAR">
          <tokens>
            <token id="7" string="because" />
            <token id="8" string="he" />
            <token id="9" string="died" />
            <token id="10" string="in" />
            <token id="11" string="1894" />
            <token id="12" string="in" />
            <token id="13" string="Samoa" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="setting" />
            <token id="17" string="of" />
            <token id="18" string="The" />
            <token id="19" string="Ebb" />
            <token id="20" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="4" string="The Ebb Tide" type="NP">
          <tokens>
            <token id="18" string="The" />
            <token id="19" string="Ebb" />
            <token id="20" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="5" string="Samoa , the setting of The Ebb Tide" type="NP">
          <tokens>
            <token id="13" string="Samoa" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="setting" />
            <token id="17" string="of" />
            <token id="18" string="The" />
            <token id="19" string="Ebb" />
            <token id="20" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="6" string="died in 1894 in Samoa , the setting of The Ebb Tide" type="VP">
          <tokens>
            <token id="9" string="died" />
            <token id="10" string="in" />
            <token id="11" string="1894" />
            <token id="12" string="in" />
            <token id="13" string="Samoa" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="setting" />
            <token id="17" string="of" />
            <token id="18" string="The" />
            <token id="19" string="Ebb" />
            <token id="20" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="7" string="Samoa" type="NP">
          <tokens>
            <token id="13" string="Samoa" />
          </tokens>
        </chunking>
        <chunking id="8" string="will get the sympathy vote because he died in 1894 in Samoa , the setting of The Ebb Tide" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="get" />
            <token id="4" string="the" />
            <token id="5" string="sympathy" />
            <token id="6" string="vote" />
            <token id="7" string="because" />
            <token id="8" string="he" />
            <token id="9" string="died" />
            <token id="10" string="in" />
            <token id="11" string="1894" />
            <token id="12" string="in" />
            <token id="13" string="Samoa" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="setting" />
            <token id="17" string="of" />
            <token id="18" string="The" />
            <token id="19" string="Ebb" />
            <token id="20" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="9" string="get the sympathy vote because he died in 1894 in Samoa , the setting of The Ebb Tide" type="VP">
          <tokens>
            <token id="3" string="get" />
            <token id="4" string="the" />
            <token id="5" string="sympathy" />
            <token id="6" string="vote" />
            <token id="7" string="because" />
            <token id="8" string="he" />
            <token id="9" string="died" />
            <token id="10" string="in" />
            <token id="11" string="1894" />
            <token id="12" string="in" />
            <token id="13" string="Samoa" />
            <token id="14" string="," />
            <token id="15" string="the" />
            <token id="16" string="setting" />
            <token id="17" string="of" />
            <token id="18" string="The" />
            <token id="19" string="Ebb" />
            <token id="20" string="Tide" />
          </tokens>
        </chunking>
        <chunking id="10" string="1894" type="NP">
          <tokens>
            <token id="11" string="1894" />
          </tokens>
        </chunking>
        <chunking id="11" string="Stevenson" type="NP">
          <tokens>
            <token id="1" string="Stevenson" />
          </tokens>
        </chunking>
        <chunking id="12" string="the setting" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="setting" />
          </tokens>
        </chunking>
        <chunking id="13" string="he" type="NP">
          <tokens>
            <token id="8" string="he" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">get</governor>
          <dependent id="1">Stevenson</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">get</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">get</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">vote</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">vote</governor>
          <dependent id="5">sympathy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">get</governor>
          <dependent id="6">vote</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">died</governor>
          <dependent id="7">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">died</governor>
          <dependent id="8">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="3">get</governor>
          <dependent id="9">died</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">1894</governor>
          <dependent id="10">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">died</governor>
          <dependent id="11">1894</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Samoa</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">died</governor>
          <dependent id="13">Samoa</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">setting</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">Samoa</governor>
          <dependent id="16">setting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">Tide</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">Tide</governor>
          <dependent id="18">The</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Tide</governor>
          <dependent id="19">Ebb</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">setting</governor>
          <dependent id="20">Tide</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1894" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1894" />
          </tokens>
        </entity>
        <entity id="2" string="Ebb Tide" type="MISC" score="0.0">
          <tokens>
            <token id="19" string="Ebb" />
            <token id="20" string="Tide" />
          </tokens>
        </entity>
        <entity id="3" string="Stevenson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Stevenson" />
          </tokens>
        </entity>
        <entity id="4" string="Samoa" type="LOCATION" score="0.0">
          <tokens>
            <token id="13" string="Samoa" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="53" has_coreference="true">
      <content>Jungle Book will get the retrospective vote, because it is the best-known today and has fashionable mythic overtones in the lost paradise of Mowgli&amp;apost;s jungle; its position on the list may also rescue it from schmaltzy Disney associations and confirm it as a serious novel about a young man&amp;apost;s self-discovery.</content>
      <tokens>
        <token id="1" string="Jungle" lemma="jungle" stem="jungl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="Book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="retrospective" lemma="retrospective" stem="retrospect" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="best-known" lemma="best-known" stem="best-known" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="fashionable" lemma="fashionable" stem="fashion" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="mythic" lemma="mythic" stem="mythic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="overtones" lemma="overtone" stem="overton" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="lost" lemma="lose" stem="lost" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="paradise" lemma="paradise" stem="paradis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Mowgli" lemma="Mowgli" stem="mowgli" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="26" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="jungle" lemma="jungle" stem="jungl" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string=";" lemma=";" stem=";" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="30" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="32" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="33" string="list" lemma="list" stem="list" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="34" string="may" lemma="may" stem="mai" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="rescue" lemma="rescue" stem="rescu" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="schmaltzy" lemma="schmaltzy" stem="schmaltzi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="Disney" lemma="Disney" stem="disnei" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="41" string="associations" lemma="association" stem="associ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="confirm" lemma="confirm" stem="confirm" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="44" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="serious" lemma="serious" stem="seriou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="novel" lemma="novel" stem="novel" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="52" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="54" string="self-discovery" lemma="self-discovery" stem="self-discoveri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="55" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NN Jungle) (NN Book)) (VP (MD will) (VP (VB get) (NP (DT the) (ADJP (JJ retrospective)) (NN vote)) (, ,) (SBAR (IN because) (S (NP (PRP it)) (VP (VP (VBZ is) (NP (DT the) (JJS best-known) (NN today))) (CC and) (VP (VBZ has) (NP (NP (JJ fashionable) (JJ mythic) (NNS overtones)) (PP (IN in) (NP (NP (DT the) (VBN lost) (NN paradise)) (PP (IN of) (NP (NP (NNP Mowgli) (POS 's)) (NN jungle))))))))))))) (: ;) (S (NP (NP (PRP$ its) (NN position)) (PP (IN on) (NP (DT the) (NN list)))) (VP (VP (MD may) (ADVP (RB also)) (VP (VB rescue) (NP (PRP it)) (PP (IN from) (NP (JJ schmaltzy) (NNP Disney) (NNS associations))))) (CC and) (VP (VBP confirm) (NP (PRP it)) (PP (IN as) (NP (NP (DT a) (JJ serious) (JJ novel)) (PP (IN about) (NP (NP (DT a) (JJ young) (NN man) (POS 's)) (NN self-discovery)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the retrospective vote" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="retrospective" />
            <token id="7" string="vote" />
          </tokens>
        </chunking>
        <chunking id="2" string="is the best-known today" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="the" />
            <token id="13" string="best-known" />
            <token id="14" string="today" />
          </tokens>
        </chunking>
        <chunking id="3" string="Jungle Book" type="NP">
          <tokens>
            <token id="1" string="Jungle" />
            <token id="2" string="Book" />
          </tokens>
        </chunking>
        <chunking id="4" string="has fashionable mythic overtones in the lost paradise of Mowgli 's jungle" type="VP">
          <tokens>
            <token id="16" string="has" />
            <token id="17" string="fashionable" />
            <token id="18" string="mythic" />
            <token id="19" string="overtones" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="lost" />
            <token id="23" string="paradise" />
            <token id="24" string="of" />
            <token id="25" string="Mowgli" />
            <token id="26" string="'s" />
            <token id="27" string="jungle" />
          </tokens>
        </chunking>
        <chunking id="5" string="a serious novel" type="NP">
          <tokens>
            <token id="46" string="a" />
            <token id="47" string="serious" />
            <token id="48" string="novel" />
          </tokens>
        </chunking>
        <chunking id="6" string="retrospective" type="ADJP">
          <tokens>
            <token id="6" string="retrospective" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="10" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="a serious novel about a young man 's self-discovery" type="NP">
          <tokens>
            <token id="46" string="a" />
            <token id="47" string="serious" />
            <token id="48" string="novel" />
            <token id="49" string="about" />
            <token id="50" string="a" />
            <token id="51" string="young" />
            <token id="52" string="man" />
            <token id="53" string="'s" />
            <token id="54" string="self-discovery" />
          </tokens>
        </chunking>
        <chunking id="9" string="is the best-known today and has fashionable mythic overtones in the lost paradise of Mowgli 's jungle" type="VP">
          <tokens>
            <token id="11" string="is" />
            <token id="12" string="the" />
            <token id="13" string="best-known" />
            <token id="14" string="today" />
            <token id="15" string="and" />
            <token id="16" string="has" />
            <token id="17" string="fashionable" />
            <token id="18" string="mythic" />
            <token id="19" string="overtones" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="lost" />
            <token id="23" string="paradise" />
            <token id="24" string="of" />
            <token id="25" string="Mowgli" />
            <token id="26" string="'s" />
            <token id="27" string="jungle" />
          </tokens>
        </chunking>
        <chunking id="10" string="may also rescue it from schmaltzy Disney associations" type="VP">
          <tokens>
            <token id="34" string="may" />
            <token id="35" string="also" />
            <token id="36" string="rescue" />
            <token id="37" string="it" />
            <token id="38" string="from" />
            <token id="39" string="schmaltzy" />
            <token id="40" string="Disney" />
            <token id="41" string="associations" />
          </tokens>
        </chunking>
        <chunking id="11" string="the lost paradise" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="lost" />
            <token id="23" string="paradise" />
          </tokens>
        </chunking>
        <chunking id="12" string="the list" type="NP">
          <tokens>
            <token id="32" string="the" />
            <token id="33" string="list" />
          </tokens>
        </chunking>
        <chunking id="13" string="fashionable mythic overtones" type="NP">
          <tokens>
            <token id="17" string="fashionable" />
            <token id="18" string="mythic" />
            <token id="19" string="overtones" />
          </tokens>
        </chunking>
        <chunking id="14" string="a young man 's" type="NP">
          <tokens>
            <token id="50" string="a" />
            <token id="51" string="young" />
            <token id="52" string="man" />
            <token id="53" string="'s" />
          </tokens>
        </chunking>
        <chunking id="15" string="fashionable mythic overtones in the lost paradise of Mowgli 's jungle" type="NP">
          <tokens>
            <token id="17" string="fashionable" />
            <token id="18" string="mythic" />
            <token id="19" string="overtones" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="lost" />
            <token id="23" string="paradise" />
            <token id="24" string="of" />
            <token id="25" string="Mowgli" />
            <token id="26" string="'s" />
            <token id="27" string="jungle" />
          </tokens>
        </chunking>
        <chunking id="16" string="its position" type="NP">
          <tokens>
            <token id="29" string="its" />
            <token id="30" string="position" />
          </tokens>
        </chunking>
        <chunking id="17" string="Mowgli 's jungle" type="NP">
          <tokens>
            <token id="25" string="Mowgli" />
            <token id="26" string="'s" />
            <token id="27" string="jungle" />
          </tokens>
        </chunking>
        <chunking id="18" string="Mowgli 's" type="NP">
          <tokens>
            <token id="25" string="Mowgli" />
            <token id="26" string="'s" />
          </tokens>
        </chunking>
        <chunking id="19" string="may also rescue it from schmaltzy Disney associations and confirm it as a serious novel about a young man 's self-discovery" type="VP">
          <tokens>
            <token id="34" string="may" />
            <token id="35" string="also" />
            <token id="36" string="rescue" />
            <token id="37" string="it" />
            <token id="38" string="from" />
            <token id="39" string="schmaltzy" />
            <token id="40" string="Disney" />
            <token id="41" string="associations" />
            <token id="42" string="and" />
            <token id="43" string="confirm" />
            <token id="44" string="it" />
            <token id="45" string="as" />
            <token id="46" string="a" />
            <token id="47" string="serious" />
            <token id="48" string="novel" />
            <token id="49" string="about" />
            <token id="50" string="a" />
            <token id="51" string="young" />
            <token id="52" string="man" />
            <token id="53" string="'s" />
            <token id="54" string="self-discovery" />
          </tokens>
        </chunking>
        <chunking id="20" string="rescue it from schmaltzy Disney associations" type="VP">
          <tokens>
            <token id="36" string="rescue" />
            <token id="37" string="it" />
            <token id="38" string="from" />
            <token id="39" string="schmaltzy" />
            <token id="40" string="Disney" />
            <token id="41" string="associations" />
          </tokens>
        </chunking>
        <chunking id="21" string="a young man 's self-discovery" type="NP">
          <tokens>
            <token id="50" string="a" />
            <token id="51" string="young" />
            <token id="52" string="man" />
            <token id="53" string="'s" />
            <token id="54" string="self-discovery" />
          </tokens>
        </chunking>
        <chunking id="22" string="the lost paradise of Mowgli 's jungle" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="lost" />
            <token id="23" string="paradise" />
            <token id="24" string="of" />
            <token id="25" string="Mowgli" />
            <token id="26" string="'s" />
            <token id="27" string="jungle" />
          </tokens>
        </chunking>
        <chunking id="23" string="confirm it as a serious novel about a young man 's self-discovery" type="VP">
          <tokens>
            <token id="43" string="confirm" />
            <token id="44" string="it" />
            <token id="45" string="as" />
            <token id="46" string="a" />
            <token id="47" string="serious" />
            <token id="48" string="novel" />
            <token id="49" string="about" />
            <token id="50" string="a" />
            <token id="51" string="young" />
            <token id="52" string="man" />
            <token id="53" string="'s" />
            <token id="54" string="self-discovery" />
          </tokens>
        </chunking>
        <chunking id="24" string="because it is the best-known today and has fashionable mythic overtones in the lost paradise of Mowgli 's jungle" type="SBAR">
          <tokens>
            <token id="9" string="because" />
            <token id="10" string="it" />
            <token id="11" string="is" />
            <token id="12" string="the" />
            <token id="13" string="best-known" />
            <token id="14" string="today" />
            <token id="15" string="and" />
            <token id="16" string="has" />
            <token id="17" string="fashionable" />
            <token id="18" string="mythic" />
            <token id="19" string="overtones" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="lost" />
            <token id="23" string="paradise" />
            <token id="24" string="of" />
            <token id="25" string="Mowgli" />
            <token id="26" string="'s" />
            <token id="27" string="jungle" />
          </tokens>
        </chunking>
        <chunking id="25" string="will get the retrospective vote , because it is the best-known today and has fashionable mythic overtones in the lost paradise of Mowgli 's jungle" type="VP">
          <tokens>
            <token id="3" string="will" />
            <token id="4" string="get" />
            <token id="5" string="the" />
            <token id="6" string="retrospective" />
            <token id="7" string="vote" />
            <token id="8" string="," />
            <token id="9" string="because" />
            <token id="10" string="it" />
            <token id="11" string="is" />
            <token id="12" string="the" />
            <token id="13" string="best-known" />
            <token id="14" string="today" />
            <token id="15" string="and" />
            <token id="16" string="has" />
            <token id="17" string="fashionable" />
            <token id="18" string="mythic" />
            <token id="19" string="overtones" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="lost" />
            <token id="23" string="paradise" />
            <token id="24" string="of" />
            <token id="25" string="Mowgli" />
            <token id="26" string="'s" />
            <token id="27" string="jungle" />
          </tokens>
        </chunking>
        <chunking id="26" string="its position on the list" type="NP">
          <tokens>
            <token id="29" string="its" />
            <token id="30" string="position" />
            <token id="31" string="on" />
            <token id="32" string="the" />
            <token id="33" string="list" />
          </tokens>
        </chunking>
        <chunking id="27" string="the best-known today" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="best-known" />
            <token id="14" string="today" />
          </tokens>
        </chunking>
        <chunking id="28" string="schmaltzy Disney associations" type="NP">
          <tokens>
            <token id="39" string="schmaltzy" />
            <token id="40" string="Disney" />
            <token id="41" string="associations" />
          </tokens>
        </chunking>
        <chunking id="29" string="get the retrospective vote , because it is the best-known today and has fashionable mythic overtones in the lost paradise of Mowgli 's jungle" type="VP">
          <tokens>
            <token id="4" string="get" />
            <token id="5" string="the" />
            <token id="6" string="retrospective" />
            <token id="7" string="vote" />
            <token id="8" string="," />
            <token id="9" string="because" />
            <token id="10" string="it" />
            <token id="11" string="is" />
            <token id="12" string="the" />
            <token id="13" string="best-known" />
            <token id="14" string="today" />
            <token id="15" string="and" />
            <token id="16" string="has" />
            <token id="17" string="fashionable" />
            <token id="18" string="mythic" />
            <token id="19" string="overtones" />
            <token id="20" string="in" />
            <token id="21" string="the" />
            <token id="22" string="lost" />
            <token id="23" string="paradise" />
            <token id="24" string="of" />
            <token id="25" string="Mowgli" />
            <token id="26" string="'s" />
            <token id="27" string="jungle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Book</governor>
          <dependent id="1">Jungle</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">get</governor>
          <dependent id="2">Book</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">get</governor>
          <dependent id="3">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">get</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">vote</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">vote</governor>
          <dependent id="6">retrospective</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">get</governor>
          <dependent id="7">vote</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">today</governor>
          <dependent id="9">because</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">today</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="14">today</governor>
          <dependent id="11">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">today</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">today</governor>
          <dependent id="13">best-known</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="4">get</governor>
          <dependent id="14">today</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="14">today</governor>
          <dependent id="15">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="14">today</governor>
          <dependent id="16">has</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">overtones</governor>
          <dependent id="17">fashionable</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="19">overtones</governor>
          <dependent id="18">mythic</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="16">has</governor>
          <dependent id="19">overtones</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">paradise</governor>
          <dependent id="20">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">paradise</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">paradise</governor>
          <dependent id="22">lost</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">overtones</governor>
          <dependent id="23">paradise</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">jungle</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">jungle</governor>
          <dependent id="25">Mowgli</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Mowgli</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">paradise</governor>
          <dependent id="27">jungle</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">position</governor>
          <dependent id="29">its</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="36">rescue</governor>
          <dependent id="30">position</dependent>
        </dependency>
        <dependency type="case">
          <governor id="33">list</governor>
          <dependent id="31">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="33">list</governor>
          <dependent id="32">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="30">position</governor>
          <dependent id="33">list</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="36">rescue</governor>
          <dependent id="34">may</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="36">rescue</governor>
          <dependent id="35">also</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="4">get</governor>
          <dependent id="36">rescue</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="36">rescue</governor>
          <dependent id="37">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">associations</governor>
          <dependent id="38">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="41">associations</governor>
          <dependent id="39">schmaltzy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="41">associations</governor>
          <dependent id="40">Disney</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="36">rescue</governor>
          <dependent id="41">associations</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="36">rescue</governor>
          <dependent id="42">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="36">rescue</governor>
          <dependent id="43">confirm</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="43">confirm</governor>
          <dependent id="44">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="48">novel</governor>
          <dependent id="45">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">novel</governor>
          <dependent id="46">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">novel</governor>
          <dependent id="47">serious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">confirm</governor>
          <dependent id="48">novel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="54">self-discovery</governor>
          <dependent id="49">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="52">man</governor>
          <dependent id="50">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="52">man</governor>
          <dependent id="51">young</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="54">self-discovery</governor>
          <dependent id="52">man</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">man</governor>
          <dependent id="53">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="48">novel</governor>
          <dependent id="54">self-discovery</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Disney" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="40" string="Disney" />
          </tokens>
        </entity>
        <entity id="2" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="today" />
          </tokens>
        </entity>
        <entity id="3" string="Mowgli" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="Mowgli" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="54" has_coreference="true">
      <content>My vote goes to Trilby.</content>
      <tokens>
        <token id="1" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="vote" lemma="vote" stem="vote" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="goes" lemma="go" stem="goe" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Trilby" lemma="Trilby" stem="trilbi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ My) (NN vote)) (VP (VBZ goes) (PP (TO to) (NP (NNP Trilby)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="goes to Trilby" type="VP">
          <tokens>
            <token id="3" string="goes" />
            <token id="4" string="to" />
            <token id="5" string="Trilby" />
          </tokens>
        </chunking>
        <chunking id="2" string="My vote" type="NP">
          <tokens>
            <token id="1" string="My" />
            <token id="2" string="vote" />
          </tokens>
        </chunking>
        <chunking id="3" string="Trilby" type="NP">
          <tokens>
            <token id="5" string="Trilby" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">vote</governor>
          <dependent id="1">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">goes</governor>
          <dependent id="2">vote</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">goes</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Trilby</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">goes</governor>
          <dependent id="5">Trilby</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Trilby" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Trilby" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="55" has_coreference="true">
      <content>Soft-focus, ideologically shaky - in its anti-Semitic portrait of Svengali - and sometimes sloppy, it is a story of demonic possession and haunts the imagination like a fairy tale long after better-written works have faded from memory.</content>
      <tokens>
        <token id="1" string="Soft-focus" lemma="soft-focus" stem="soft-focu" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="ideologically" lemma="ideologically" stem="ideolog" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="shaky" lemma="shaky" stem="shaki" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="8" string="anti-Semitic" lemma="anti-semitic" stem="anti-semit" pos="JJ" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="9" string="portrait" lemma="portrait" stem="portrait" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="Svengali" lemma="Svengali" stem="svengali" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="sometimes" lemma="sometimes" stem="sometim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="sloppy" lemma="sloppy" stem="sloppi" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="story" lemma="story" stem="stori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="demonic" lemma="demonic" stem="demon" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="possession" lemma="possession" stem="possess" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="haunts" lemma="haunt" stem="haunt" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="imagination" lemma="imagination" stem="imagin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="fairy" lemma="fairy" stem="fairi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="tale" lemma="tale" stem="tale" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="better-written" lemma="better-written" stem="better-written" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="works" lemma="work" stem="work" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="faded" lemma="fade" stem="fade" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="38" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="memory" lemma="memory" stem="memori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (ADJP (ADJP (JJ Soft-focus)) (, ,) (ADJP (ADJP (RB ideologically) (JJ shaky)) (PRN (: -) (PP (IN in) (NP (NP (PRP$ its) (ADJP (JJ anti-Semitic)) (NN portrait)) (PP (IN of) (NP (NNP Svengali))))) (: -))) (CC and) (ADJP (RB sometimes) (JJ sloppy)))) (, ,) (NP (PRP it)) (VP (VP (VBZ is) (NP (NP (DT a) (NN story)) (PP (IN of) (NP (JJ demonic) (NN possession))))) (CC and) (VP (VBZ haunts) (NP (DT the) (NN imagination)) (PP (IN like) (NP (DT a) (NN fairy) (NN tale)))) (SBAR (RB long) (IN after) (S (NP (JJ better-written) (NNS works)) (VP (VBP have) (VP (VBN faded) (PP (IN from) (NP (NN memory)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is a story of demonic possession and haunts the imagination like a fairy tale long after better-written works have faded from memory" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="a" />
            <token id="20" string="story" />
            <token id="21" string="of" />
            <token id="22" string="demonic" />
            <token id="23" string="possession" />
            <token id="24" string="and" />
            <token id="25" string="haunts" />
            <token id="26" string="the" />
            <token id="27" string="imagination" />
            <token id="28" string="like" />
            <token id="29" string="a" />
            <token id="30" string="fairy" />
            <token id="31" string="tale" />
            <token id="32" string="long" />
            <token id="33" string="after" />
            <token id="34" string="better-written" />
            <token id="35" string="works" />
            <token id="36" string="have" />
            <token id="37" string="faded" />
            <token id="38" string="from" />
            <token id="39" string="memory" />
          </tokens>
        </chunking>
        <chunking id="2" string="the imagination" type="NP">
          <tokens>
            <token id="26" string="the" />
            <token id="27" string="imagination" />
          </tokens>
        </chunking>
        <chunking id="3" string="memory" type="NP">
          <tokens>
            <token id="39" string="memory" />
          </tokens>
        </chunking>
        <chunking id="4" string="a fairy tale" type="NP">
          <tokens>
            <token id="29" string="a" />
            <token id="30" string="fairy" />
            <token id="31" string="tale" />
          </tokens>
        </chunking>
        <chunking id="5" string="better-written works" type="NP">
          <tokens>
            <token id="34" string="better-written" />
            <token id="35" string="works" />
          </tokens>
        </chunking>
        <chunking id="6" string="its anti-Semitic portrait" type="NP">
          <tokens>
            <token id="7" string="its" />
            <token id="8" string="anti-Semitic" />
            <token id="9" string="portrait" />
          </tokens>
        </chunking>
        <chunking id="7" string="demonic possession" type="NP">
          <tokens>
            <token id="22" string="demonic" />
            <token id="23" string="possession" />
          </tokens>
        </chunking>
        <chunking id="8" string="anti-Semitic" type="ADJP">
          <tokens>
            <token id="8" string="anti-Semitic" />
          </tokens>
        </chunking>
        <chunking id="9" string="Soft-focus , ideologically shaky - in its anti-Semitic portrait of Svengali - and sometimes sloppy" type="ADJP">
          <tokens>
            <token id="1" string="Soft-focus" />
            <token id="2" string="," />
            <token id="3" string="ideologically" />
            <token id="4" string="shaky" />
            <token id="5" string="-" />
            <token id="6" string="in" />
            <token id="7" string="its" />
            <token id="8" string="anti-Semitic" />
            <token id="9" string="portrait" />
            <token id="10" string="of" />
            <token id="11" string="Svengali" />
            <token id="12" string="-" />
            <token id="13" string="and" />
            <token id="14" string="sometimes" />
            <token id="15" string="sloppy" />
          </tokens>
        </chunking>
        <chunking id="10" string="faded from memory" type="VP">
          <tokens>
            <token id="37" string="faded" />
            <token id="38" string="from" />
            <token id="39" string="memory" />
          </tokens>
        </chunking>
        <chunking id="11" string="its anti-Semitic portrait of Svengali" type="NP">
          <tokens>
            <token id="7" string="its" />
            <token id="8" string="anti-Semitic" />
            <token id="9" string="portrait" />
            <token id="10" string="of" />
            <token id="11" string="Svengali" />
          </tokens>
        </chunking>
        <chunking id="12" string="it" type="NP">
          <tokens>
            <token id="17" string="it" />
          </tokens>
        </chunking>
        <chunking id="13" string="have faded from memory" type="VP">
          <tokens>
            <token id="36" string="have" />
            <token id="37" string="faded" />
            <token id="38" string="from" />
            <token id="39" string="memory" />
          </tokens>
        </chunking>
        <chunking id="14" string="ideologically shaky" type="ADJP">
          <tokens>
            <token id="3" string="ideologically" />
            <token id="4" string="shaky" />
          </tokens>
        </chunking>
        <chunking id="15" string="long after better-written works have faded from memory" type="SBAR">
          <tokens>
            <token id="32" string="long" />
            <token id="33" string="after" />
            <token id="34" string="better-written" />
            <token id="35" string="works" />
            <token id="36" string="have" />
            <token id="37" string="faded" />
            <token id="38" string="from" />
            <token id="39" string="memory" />
          </tokens>
        </chunking>
        <chunking id="16" string="haunts the imagination like a fairy tale" type="VP">
          <tokens>
            <token id="25" string="haunts" />
            <token id="26" string="the" />
            <token id="27" string="imagination" />
            <token id="28" string="like" />
            <token id="29" string="a" />
            <token id="30" string="fairy" />
            <token id="31" string="tale" />
          </tokens>
        </chunking>
        <chunking id="17" string="a story of demonic possession" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="story" />
            <token id="21" string="of" />
            <token id="22" string="demonic" />
            <token id="23" string="possession" />
          </tokens>
        </chunking>
        <chunking id="18" string="Soft-focus" type="ADJP">
          <tokens>
            <token id="1" string="Soft-focus" />
          </tokens>
        </chunking>
        <chunking id="19" string="a story" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="story" />
          </tokens>
        </chunking>
        <chunking id="20" string="Svengali" type="NP">
          <tokens>
            <token id="11" string="Svengali" />
          </tokens>
        </chunking>
        <chunking id="21" string="ideologically shaky - in its anti-Semitic portrait of Svengali -" type="ADJP">
          <tokens>
            <token id="3" string="ideologically" />
            <token id="4" string="shaky" />
            <token id="5" string="-" />
            <token id="6" string="in" />
            <token id="7" string="its" />
            <token id="8" string="anti-Semitic" />
            <token id="9" string="portrait" />
            <token id="10" string="of" />
            <token id="11" string="Svengali" />
            <token id="12" string="-" />
          </tokens>
        </chunking>
        <chunking id="22" string="sometimes sloppy" type="ADJP">
          <tokens>
            <token id="14" string="sometimes" />
            <token id="15" string="sloppy" />
          </tokens>
        </chunking>
        <chunking id="23" string="is a story of demonic possession" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="a" />
            <token id="20" string="story" />
            <token id="21" string="of" />
            <token id="22" string="demonic" />
            <token id="23" string="possession" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="ccomp">
          <governor id="20">story</governor>
          <dependent id="1">Soft-focus</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">shaky</governor>
          <dependent id="3">ideologically</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Soft-focus</governor>
          <dependent id="4">shaky</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">portrait</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">portrait</governor>
          <dependent id="7">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">portrait</governor>
          <dependent id="8">anti-Semitic</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">shaky</governor>
          <dependent id="9">portrait</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Svengali</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">portrait</governor>
          <dependent id="11">Svengali</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="1">Soft-focus</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">sloppy</governor>
          <dependent id="14">sometimes</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="1">Soft-focus</governor>
          <dependent id="15">sloppy</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">story</governor>
          <dependent id="17">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="20">story</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">story</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">story</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">possession</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">possession</governor>
          <dependent id="22">demonic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">story</governor>
          <dependent id="23">possession</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="20">story</governor>
          <dependent id="24">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="20">story</governor>
          <dependent id="25">haunts</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">imagination</governor>
          <dependent id="26">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="25">haunts</governor>
          <dependent id="27">imagination</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">tale</governor>
          <dependent id="28">like</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">tale</governor>
          <dependent id="29">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">tale</governor>
          <dependent id="30">fairy</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">haunts</governor>
          <dependent id="31">tale</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="37">faded</governor>
          <dependent id="32">long</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">faded</governor>
          <dependent id="33">after</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">works</governor>
          <dependent id="34">better-written</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="37">faded</governor>
          <dependent id="35">works</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="37">faded</governor>
          <dependent id="36">have</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="20">story</governor>
          <dependent id="37">faded</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">memory</governor>
          <dependent id="38">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="37">faded</governor>
          <dependent id="39">memory</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="anti-Semitic" type="MISC" score="0.0">
          <tokens>
            <token id="8" string="anti-Semitic" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="56" has_coreference="true">
      <content>Like Rebecca, the popular novel by du Maurier&amp;apost;s granddaughter, it is a natural equivalent of what the current Booker Prize seeks to create: a combination of the classic and the bestseller.</content>
      <tokens>
        <token id="1" string="Like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="Rebecca" lemma="Rebecca" stem="rebecca" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="popular" lemma="popular" stem="popular" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="novel" lemma="novel" stem="novel" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="du" lemma="du" stem="du" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="9" string="Maurier" lemma="Maurier" stem="maurier" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="true" />
        <token id="10" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="granddaughter" lemma="granddaughter" stem="granddaught" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="natural" lemma="natural" stem="natur" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="equivalent" lemma="equivalent" stem="equival" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="current" lemma="current" stem="current" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="22" string="Booker" lemma="Booker" stem="booker" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="23" string="Prize" lemma="Prize" stem="prize" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="24" string="seeks" lemma="seek" stem="seek" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="create" lemma="create" stem="creat" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="combination" lemma="combination" stem="combin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="classic" lemma="classic" stem="classic" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="35" string="bestseller" lemma="bestseller" stem="bestsel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Like) (NP (NP (NNP Rebecca)) (, ,) (NP (NP (DT the) (JJ popular) (NN novel)) (PP (IN by) (NP (NP (NNP du) (NNP Maurier) (POS 's)) (NN granddaughter)))))) (, ,) (NP (PRP it)) (VP (VBZ is) (NP (NP (NP (DT a) (JJ natural) (NN equivalent)) (PP (IN of) (SBAR (WHNP (WP what)) (S (NP (DT the) (JJ current) (NNP Booker) (NNP Prize)) (VP (VBZ seeks) (S (VP (TO to) (VP (VB create))))))))) (: :) (NP (NP (DT a) (NN combination)) (PP (IN of) (NP (DT the) (JJ classic)))) (CC and) (NP (DT the) (NN bestseller)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a natural equivalent of what the current Booker Prize seeks to create : a combination of the classic and the bestseller" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="natural" />
            <token id="17" string="equivalent" />
            <token id="18" string="of" />
            <token id="19" string="what" />
            <token id="20" string="the" />
            <token id="21" string="current" />
            <token id="22" string="Booker" />
            <token id="23" string="Prize" />
            <token id="24" string="seeks" />
            <token id="25" string="to" />
            <token id="26" string="create" />
            <token id="27" string=":" />
            <token id="28" string="a" />
            <token id="29" string="combination" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="classic" />
            <token id="33" string="and" />
            <token id="34" string="the" />
            <token id="35" string="bestseller" />
          </tokens>
        </chunking>
        <chunking id="2" string="is a natural equivalent of what the current Booker Prize seeks to create : a combination of the classic and the bestseller" type="VP">
          <tokens>
            <token id="14" string="is" />
            <token id="15" string="a" />
            <token id="16" string="natural" />
            <token id="17" string="equivalent" />
            <token id="18" string="of" />
            <token id="19" string="what" />
            <token id="20" string="the" />
            <token id="21" string="current" />
            <token id="22" string="Booker" />
            <token id="23" string="Prize" />
            <token id="24" string="seeks" />
            <token id="25" string="to" />
            <token id="26" string="create" />
            <token id="27" string=":" />
            <token id="28" string="a" />
            <token id="29" string="combination" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="classic" />
            <token id="33" string="and" />
            <token id="34" string="the" />
            <token id="35" string="bestseller" />
          </tokens>
        </chunking>
        <chunking id="3" string="the current Booker Prize" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="current" />
            <token id="22" string="Booker" />
            <token id="23" string="Prize" />
          </tokens>
        </chunking>
        <chunking id="4" string="seeks to create" type="VP">
          <tokens>
            <token id="24" string="seeks" />
            <token id="25" string="to" />
            <token id="26" string="create" />
          </tokens>
        </chunking>
        <chunking id="5" string="a combination" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="combination" />
          </tokens>
        </chunking>
        <chunking id="6" string="Rebecca" type="NP">
          <tokens>
            <token id="2" string="Rebecca" />
          </tokens>
        </chunking>
        <chunking id="7" string="du Maurier 's granddaughter" type="NP">
          <tokens>
            <token id="8" string="du" />
            <token id="9" string="Maurier" />
            <token id="10" string="'s" />
            <token id="11" string="granddaughter" />
          </tokens>
        </chunking>
        <chunking id="8" string="it" type="NP">
          <tokens>
            <token id="13" string="it" />
          </tokens>
        </chunking>
        <chunking id="9" string="the bestseller" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="bestseller" />
          </tokens>
        </chunking>
        <chunking id="10" string="du Maurier 's" type="NP">
          <tokens>
            <token id="8" string="du" />
            <token id="9" string="Maurier" />
            <token id="10" string="'s" />
          </tokens>
        </chunking>
        <chunking id="11" string="to create" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="create" />
          </tokens>
        </chunking>
        <chunking id="12" string="a combination of the classic" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="combination" />
            <token id="30" string="of" />
            <token id="31" string="the" />
            <token id="32" string="classic" />
          </tokens>
        </chunking>
        <chunking id="13" string="Rebecca , the popular novel by du Maurier 's granddaughter" type="NP">
          <tokens>
            <token id="2" string="Rebecca" />
            <token id="3" string="," />
            <token id="4" string="the" />
            <token id="5" string="popular" />
            <token id="6" string="novel" />
            <token id="7" string="by" />
            <token id="8" string="du" />
            <token id="9" string="Maurier" />
            <token id="10" string="'s" />
            <token id="11" string="granddaughter" />
          </tokens>
        </chunking>
        <chunking id="14" string="the popular novel" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="popular" />
            <token id="6" string="novel" />
          </tokens>
        </chunking>
        <chunking id="15" string="a natural equivalent of what the current Booker Prize seeks to create" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="natural" />
            <token id="17" string="equivalent" />
            <token id="18" string="of" />
            <token id="19" string="what" />
            <token id="20" string="the" />
            <token id="21" string="current" />
            <token id="22" string="Booker" />
            <token id="23" string="Prize" />
            <token id="24" string="seeks" />
            <token id="25" string="to" />
            <token id="26" string="create" />
          </tokens>
        </chunking>
        <chunking id="16" string="a natural equivalent" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="natural" />
            <token id="17" string="equivalent" />
          </tokens>
        </chunking>
        <chunking id="17" string="what the current Booker Prize seeks to create" type="SBAR">
          <tokens>
            <token id="19" string="what" />
            <token id="20" string="the" />
            <token id="21" string="current" />
            <token id="22" string="Booker" />
            <token id="23" string="Prize" />
            <token id="24" string="seeks" />
            <token id="25" string="to" />
            <token id="26" string="create" />
          </tokens>
        </chunking>
        <chunking id="18" string="the popular novel by du Maurier 's granddaughter" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="popular" />
            <token id="6" string="novel" />
            <token id="7" string="by" />
            <token id="8" string="du" />
            <token id="9" string="Maurier" />
            <token id="10" string="'s" />
            <token id="11" string="granddaughter" />
          </tokens>
        </chunking>
        <chunking id="19" string="create" type="VP">
          <tokens>
            <token id="26" string="create" />
          </tokens>
        </chunking>
        <chunking id="20" string="the classic" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="classic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">Rebecca</governor>
          <dependent id="1">Like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">equivalent</governor>
          <dependent id="2">Rebecca</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">novel</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">novel</governor>
          <dependent id="5">popular</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Rebecca</governor>
          <dependent id="6">novel</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">granddaughter</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Maurier</governor>
          <dependent id="8">du</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">granddaughter</governor>
          <dependent id="9">Maurier</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Maurier</governor>
          <dependent id="10">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">novel</governor>
          <dependent id="11">granddaughter</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">equivalent</governor>
          <dependent id="13">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">equivalent</governor>
          <dependent id="14">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">equivalent</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">equivalent</governor>
          <dependent id="16">natural</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">equivalent</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">seeks</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">seeks</governor>
          <dependent id="19">what</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Prize</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="23">Prize</governor>
          <dependent id="21">current</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Prize</governor>
          <dependent id="22">Booker</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">seeks</governor>
          <dependent id="23">Prize</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">equivalent</governor>
          <dependent id="24">seeks</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">create</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">seeks</governor>
          <dependent id="26">create</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">combination</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">equivalent</governor>
          <dependent id="29">combination</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">classic</governor>
          <dependent id="30">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">classic</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">combination</governor>
          <dependent id="32">classic</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">equivalent</governor>
          <dependent id="33">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">bestseller</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">equivalent</governor>
          <dependent id="35">bestseller</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="current" type="DATE" score="0.0">
          <tokens>
            <token id="21" string="current" />
          </tokens>
        </entity>
        <entity id="2" string="Rebecca" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Rebecca" />
          </tokens>
        </entity>
        <entity id="3" string="Maurier" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Maurier" />
          </tokens>
        </entity>
        <entity id="4" string="Booker Prize" type="MISC" score="0.0">
          <tokens>
            <token id="22" string="Booker" />
            <token id="23" string="Prize" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12" string="a bestseller about love and hypnotism" id_sentence="1" />
      <mentions>
        <mention ids_tokens="34-35" string="the bestseller" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="9-10" string="Booker Prize" id_sentence="3" />
      <mentions>
        <mention ids_tokens="2-5" string="today's Booker Prize" id_sentence="6" />
        <mention ids_tokens="7" string="it" id_sentence="6" />
        <mention ids_tokens="9-11" string="a publishing gimmick" id_sentence="6" />
      </mentions>
    </coreference>
    <coreference id="8" type="PROPER">
      <referenced ids_tokens="6-7-8" string="the hypothetical 1894" id_sentence="3" />
      <mentions>
        <mention ids_tokens="5" string="1894" id_sentence="18" />
        <mention ids_tokens="10" string="its" id_sentence="18" />
        <mention ids_tokens="1" string="It" id_sentence="19" />
        <mention ids_tokens="13" string="1894" id_sentence="19" />
        <mention ids_tokens="14" string="it" id_sentence="19" />
        <mention ids_tokens="12" string="1894" id_sentence="23" />
        <mention ids_tokens="12" string="1894" id_sentence="33" />
        <mention ids_tokens="19" string="1894" id_sentence="45" />
        <mention ids_tokens="11" string="1894" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="15-16" string="six judges" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1" string="They" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="24-25-26-27" string="George du Maurier 's" id_sentence="4" />
      <mentions>
        <mention ids_tokens="1-3" string="George du Maurier" id_sentence="41" />
        <mention ids_tokens="15" string="he" id_sentence="41" />
        <mention ids_tokens="2-3" string="du Maurier" id_sentence="42" />
        <mention ids_tokens="8-10" string="du Maurier's" id_sentence="56" />
      </mentions>
    </coreference>
    <coreference id="13" type="PROPER">
      <referenced ids_tokens="38-39-40" string="George Moore 's" id_sentence="4" />
      <mentions>
        <mention ids_tokens="6-7" string="Moore's" id_sentence="19" />
      </mentions>
    </coreference>
    <coreference id="14" type="PROPER">
      <referenced ids_tokens="41-42" string="Esther Waters" id_sentence="4" />
      <mentions>
        <mention ids_tokens="17-26" string="Esther Waters , in which a 17-year-old girl is seduced" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="30-31-32-33-34-35-36" string="Anthony Hope 's The Prisoner of Zenda" id_sentence="4" />
      <mentions>
        <mention ids_tokens="1-4" string="The Prisoner of Zenda" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="44-45-46-47" string="Kipling 's Jungle Book" id_sentence="4" />
      <mentions>
        <mention ids_tokens="1-2" string="Jungle Book" id_sentence="53" />
        <mention ids_tokens="10" string="it" id_sentence="53" />
        <mention ids_tokens="29" string="its" id_sentence="53" />
      </mentions>
    </coreference>
    <coreference id="19" type="PROPER">
      <referenced ids_tokens="58-59-60-61-62-63" string="RL Stevenson 's The Ebb Tide" id_sentence="4" />
      <mentions>
        <mention ids_tokens="12-16" string="Stevenson's The Ebb Tide" id_sentence="16" />
        <mention ids_tokens="1" string="Stevenson" id_sentence="52" />
        <mention ids_tokens="8" string="he" id_sentence="52" />
      </mentions>
    </coreference>
    <coreference id="21" type="PROPER">
      <referenced ids_tokens="7-8-9-10-11-12-13-14-15-16-17-18" string="October 15 ( four days after the 1994 Booker Prize ceremony )" id_sentence="5" />
      <mentions>
        <mention ids_tokens="6-7" string="October 15" id_sentence="51" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="27-28-29" string="classic Victorian novels" id_sentence="6" />
      <mentions>
        <mention ids_tokens="1" string="Novels" id_sentence="29" />
        <mention ids_tokens="9" string="novels" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="24" type="PROPER">
      <referenced ids_tokens="2-3-4" string="the retrospective Booker" id_sentence="7" />
      <mentions>
        <mention ids_tokens="6-7" string="the Booker" id_sentence="22" />
        <mention ids_tokens="7" string="Booker" id_sentence="22" />
        <mention ids_tokens="5-6" string="the Booker" id_sentence="25" />
        <mention ids_tokens="4" string="Booker" id_sentence="32" />
        <mention ids_tokens="7" string="Booker" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="25" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11-12" string="a fascinating exercise in historical reconstruction" id_sentence="7" />
      <mentions>
        <mention ids_tokens="1" string="It" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="26" type="PROPER">
      <referenced ids_tokens="15-16-17-18" string="the past 100 years" id_sentence="8" />
      <mentions>
        <mention ids_tokens="24-25" string="100 years" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="33" type="NOMINAL">
      <referenced ids_tokens="5-6" string="both lists" id_sentence="14" />
      <mentions>
        <mention ids_tokens="1-2" string="The lists" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="34" type="PROPER">
      <referenced ids_tokens="18-19-20-21" string="Abdulrazak Gurnah 's Paradise" id_sentence="16" />
      <mentions>
        <mention ids_tokens="19" string="Paradise" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="36" type="PROPER">
      <referenced ids_tokens="12-13-14" string="Alan Hollinghurst 's" id_sentence="21" />
      <mentions>
        <mention ids_tokens="4" string="Hollinghurst" id_sentence="22" />
        <mention ids_tokens="9" string="his" id_sentence="22" />
        <mention ids_tokens="13-14" string="Hollinghurst's" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="38" type="NOMINAL">
      <referenced ids_tokens="12-13-14-15-16-17-18-19-20-21-22-23" string="Alan Hollinghurst 's candid novel of homosexual love , The Folding Star" id_sentence="21" />
      <mentions>
        <mention ids_tokens="9-10" string="his novel" id_sentence="22" />
        <mention ids_tokens="17-18" string="the novel" id_sentence="37" />
        <mention ids_tokens="17-18" string="the novel" id_sentence="39" />
        <mention ids_tokens="26-27" string="the novel" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="39" type="NOMINAL">
      <referenced ids_tokens="26-27-28" string="the Booker list" id_sentence="21" />
      <mentions>
        <mention ids_tokens="32-33" string="the list" id_sentence="53" />
      </mentions>
    </coreference>
    <coreference id="41" type="PROPER">
      <referenced ids_tokens="20-21-22-23" string="the current Booker Prize" id_sentence="56" />
      <mentions>
        <mention ids_tokens="13-15" string="a Booker Prize" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="44" type="NOMINAL">
      <referenced ids_tokens="8-9" string="published books" id_sentence="29" />
      <mentions>
        <mention ids_tokens="18" string="books" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="45" type="PROPER">
      <referenced ids_tokens="7" string="Dickens" id_sentence="30" />
      <mentions>
        <mention ids_tokens="13-14" string="Dickens'" id_sentence="44" />
      </mentions>
    </coreference>
    <coreference id="47" type="PROPER">
      <referenced ids_tokens="20-21" string="400,000 today" id_sentence="30" />
      <mentions>
        <mention ids_tokens="1-2" string="Today we" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="53" type="NOMINAL">
      <referenced ids_tokens="3-4" string="the overturning" id_sentence="39" />
      <mentions>
        <mention ids_tokens="16" string="they" id_sentence="40" />
      </mentions>
    </coreference>
    <coreference id="54" type="NOMINAL">
      <referenced ids_tokens="6-7-8-9" string="the outline of Trilby" id_sentence="41" />
      <mentions>
        <mention ids_tokens="7" string="it" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="59" type="NOMINAL">
      <referenced ids_tokens="1" string="Both" id_sentence="46" />
      <mentions>
        <mention ids_tokens="7" string="they" id_sentence="47" />
        <mention ids_tokens="18" string="them" id_sentence="47" />
      </mentions>
    </coreference>
    <coreference id="61" type="NOMINAL">
      <referenced ids_tokens="5-6-7" string="the retrospective vote" id_sentence="53" />
      <mentions>
        <mention ids_tokens="1-2" string="My vote" id_sentence="54" />
        <mention ids_tokens="7" string="its" id_sentence="55" />
      </mentions>
    </coreference>
  </coreferences>
</document>
