<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="FBIS4-40244">
  <sentences>
    <sentence id="1" has_coreference="false">
      <content>BFN Viktor Alksnis, former USSR Supreme Soviet deputy, today reminded us of his existence.</content>
      <tokens>
        <token id="1" string="BFN" lemma="BFN" stem="bfn" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Viktor" lemma="Viktor" stem="viktor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Alksnis" lemma="Alksnis" stem="alksni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="USSR" lemma="USSR" stem="ussr" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="7" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="8" string="Soviet" lemma="Soviet" stem="soviet" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="deputy" lemma="deputy" stem="deputi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="reminded" lemma="remind" stem="remind" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="us" lemma="we" stem="u" pos="PRP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="existence" lemma="existence" stem="exist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP BFN) (NNP Viktor) (NNP Alksnis)) (, ,) (NP (JJ former) (NNP USSR) (NNP Supreme) (NNP Soviet) (NN deputy)) (, ,)) (NP-TMP (NN today)) (VP (VBD reminded) (NP (PRP us)) (PP (IN of) (NP (PRP$ his) (NN existence)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="BFN Viktor Alksnis , former USSR Supreme Soviet deputy ," type="NP">
          <tokens>
            <token id="1" string="BFN" />
            <token id="2" string="Viktor" />
            <token id="3" string="Alksnis" />
            <token id="4" string="," />
            <token id="5" string="former" />
            <token id="6" string="USSR" />
            <token id="7" string="Supreme" />
            <token id="8" string="Soviet" />
            <token id="9" string="deputy" />
            <token id="10" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="reminded us of his existence" type="VP">
          <tokens>
            <token id="12" string="reminded" />
            <token id="13" string="us" />
            <token id="14" string="of" />
            <token id="15" string="his" />
            <token id="16" string="existence" />
          </tokens>
        </chunking>
        <chunking id="3" string="BFN Viktor Alksnis" type="NP">
          <tokens>
            <token id="1" string="BFN" />
            <token id="2" string="Viktor" />
            <token id="3" string="Alksnis" />
          </tokens>
        </chunking>
        <chunking id="4" string="former USSR Supreme Soviet deputy" type="NP">
          <tokens>
            <token id="5" string="former" />
            <token id="6" string="USSR" />
            <token id="7" string="Supreme" />
            <token id="8" string="Soviet" />
            <token id="9" string="deputy" />
          </tokens>
        </chunking>
        <chunking id="5" string="us" type="NP">
          <tokens>
            <token id="13" string="us" />
          </tokens>
        </chunking>
        <chunking id="6" string="his existence" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="existence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Alksnis</governor>
          <dependent id="1">BFN</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Alksnis</governor>
          <dependent id="2">Viktor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">reminded</governor>
          <dependent id="3">Alksnis</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">deputy</governor>
          <dependent id="5">former</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">deputy</governor>
          <dependent id="6">USSR</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">deputy</governor>
          <dependent id="7">Supreme</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">deputy</governor>
          <dependent id="8">Soviet</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="3">Alksnis</governor>
          <dependent id="9">deputy</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="12">reminded</governor>
          <dependent id="11">today</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">reminded</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">reminded</governor>
          <dependent id="13">us</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">existence</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="16">existence</governor>
          <dependent id="15">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">reminded</governor>
          <dependent id="16">existence</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="USSR Supreme Soviet" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="USSR" />
            <token id="7" string="Supreme" />
            <token id="8" string="Soviet" />
          </tokens>
        </entity>
        <entity id="2" string="BFN Viktor Alksnis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="BFN" />
            <token id="2" string="Viktor" />
            <token id="3" string="Alksnis" />
          </tokens>
        </entity>
        <entity id="3" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="today" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Viktor Alksnis, born 1950, Latvian, former deputy of the Supreme Soviet of the former USSR, soldier, resigned from the Army in order to fight for the restoration of the USSR.</content>
      <tokens>
        <token id="1" string="Viktor" lemma="Viktor" stem="viktor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Alksnis" lemma="Alksnis" stem="alksni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="born" lemma="bear" stem="born" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="1950" lemma="1950" stem="1950" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="Latvian" lemma="latvian" stem="latvian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="deputy" lemma="deputy" stem="deputi" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="Supreme" lemma="Supreme" stem="suprem" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="14" string="Soviet" lemma="Soviet" stem="soviet" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="17" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="USSR" lemma="USSR" stem="ussr" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="soldier" lemma="soldier" stem="soldier" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="resigned" lemma="resign" stem="resign" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Army" lemma="Army" stem="army" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="order" lemma="order" stem="order" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="fight" lemma="fight" stem="fight" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="restoration" lemma="restoration" stem="restor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="USSR" lemma="USSR" stem="ussr" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="36" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Viktor) (NNP Alksnis)) (, ,) (VP (VBN born) (NP (NP (CD 1950)) (, ,) (NP (NP (JJ Latvian) (, ,) (JJ former) (NN deputy)) (PP (IN of) (NP (NP (DT the) (NNP Supreme) (NNP Soviet)) (PP (IN of) (NP (DT the) (JJ former) (NNP USSR)))))) (, ,) (NP (NN soldier)))) (, ,)) (VP (VBD resigned) (PP (IN from) (NP (DT the) (NNP Army))) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB fight) (PP (IN for) (NP (NP (DT the) (NN restoration)) (PP (IN of) (NP (DT the) (NNP USSR)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the restoration" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="restoration" />
          </tokens>
        </chunking>
        <chunking id="2" string="Viktor Alksnis , born 1950 , Latvian , former deputy of the Supreme Soviet of the former USSR , soldier ," type="NP">
          <tokens>
            <token id="1" string="Viktor" />
            <token id="2" string="Alksnis" />
            <token id="3" string="," />
            <token id="4" string="born" />
            <token id="5" string="1950" />
            <token id="6" string="," />
            <token id="7" string="Latvian" />
            <token id="8" string="," />
            <token id="9" string="former" />
            <token id="10" string="deputy" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Soviet" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="former" />
            <token id="18" string="USSR" />
            <token id="19" string="," />
            <token id="20" string="soldier" />
            <token id="21" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="the Army" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Army" />
          </tokens>
        </chunking>
        <chunking id="4" string="Latvian , former deputy" type="NP">
          <tokens>
            <token id="7" string="Latvian" />
            <token id="8" string="," />
            <token id="9" string="former" />
            <token id="10" string="deputy" />
          </tokens>
        </chunking>
        <chunking id="5" string="1950 , Latvian , former deputy of the Supreme Soviet of the former USSR , soldier" type="NP">
          <tokens>
            <token id="5" string="1950" />
            <token id="6" string="," />
            <token id="7" string="Latvian" />
            <token id="8" string="," />
            <token id="9" string="former" />
            <token id="10" string="deputy" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Soviet" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="former" />
            <token id="18" string="USSR" />
            <token id="19" string="," />
            <token id="20" string="soldier" />
          </tokens>
        </chunking>
        <chunking id="6" string="fight for the restoration of the USSR" type="VP">
          <tokens>
            <token id="29" string="fight" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="restoration" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="USSR" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Supreme Soviet of the former USSR" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Soviet" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="former" />
            <token id="18" string="USSR" />
          </tokens>
        </chunking>
        <chunking id="8" string="born 1950 , Latvian , former deputy of the Supreme Soviet of the former USSR , soldier" type="VP">
          <tokens>
            <token id="4" string="born" />
            <token id="5" string="1950" />
            <token id="6" string="," />
            <token id="7" string="Latvian" />
            <token id="8" string="," />
            <token id="9" string="former" />
            <token id="10" string="deputy" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Soviet" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="former" />
            <token id="18" string="USSR" />
            <token id="19" string="," />
            <token id="20" string="soldier" />
          </tokens>
        </chunking>
        <chunking id="9" string="resigned from the Army in order to fight for the restoration of the USSR" type="VP">
          <tokens>
            <token id="22" string="resigned" />
            <token id="23" string="from" />
            <token id="24" string="the" />
            <token id="25" string="Army" />
            <token id="26" string="in" />
            <token id="27" string="order" />
            <token id="28" string="to" />
            <token id="29" string="fight" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="restoration" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="USSR" />
          </tokens>
        </chunking>
        <chunking id="10" string="Viktor Alksnis" type="NP">
          <tokens>
            <token id="1" string="Viktor" />
            <token id="2" string="Alksnis" />
          </tokens>
        </chunking>
        <chunking id="11" string="the Supreme Soviet" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Soviet" />
          </tokens>
        </chunking>
        <chunking id="12" string="to fight for the restoration of the USSR" type="VP">
          <tokens>
            <token id="28" string="to" />
            <token id="29" string="fight" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="restoration" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="USSR" />
          </tokens>
        </chunking>
        <chunking id="13" string="the restoration of the USSR" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="restoration" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="USSR" />
          </tokens>
        </chunking>
        <chunking id="14" string="1950" type="NP">
          <tokens>
            <token id="5" string="1950" />
          </tokens>
        </chunking>
        <chunking id="15" string="soldier" type="NP">
          <tokens>
            <token id="20" string="soldier" />
          </tokens>
        </chunking>
        <chunking id="16" string="the former USSR" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="former" />
            <token id="18" string="USSR" />
          </tokens>
        </chunking>
        <chunking id="17" string="in order to fight for the restoration of the USSR" type="SBAR">
          <tokens>
            <token id="26" string="in" />
            <token id="27" string="order" />
            <token id="28" string="to" />
            <token id="29" string="fight" />
            <token id="30" string="for" />
            <token id="31" string="the" />
            <token id="32" string="restoration" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="USSR" />
          </tokens>
        </chunking>
        <chunking id="18" string="Latvian , former deputy of the Supreme Soviet of the former USSR" type="NP">
          <tokens>
            <token id="7" string="Latvian" />
            <token id="8" string="," />
            <token id="9" string="former" />
            <token id="10" string="deputy" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="Supreme" />
            <token id="14" string="Soviet" />
            <token id="15" string="of" />
            <token id="16" string="the" />
            <token id="17" string="former" />
            <token id="18" string="USSR" />
          </tokens>
        </chunking>
        <chunking id="19" string="the USSR" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="USSR" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Alksnis</governor>
          <dependent id="1">Viktor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">resigned</governor>
          <dependent id="2">Alksnis</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="2">Alksnis</governor>
          <dependent id="4">born</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">born</governor>
          <dependent id="5">1950</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">deputy</governor>
          <dependent id="7">Latvian</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">deputy</governor>
          <dependent id="9">former</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">1950</governor>
          <dependent id="10">deputy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Soviet</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Soviet</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Soviet</governor>
          <dependent id="13">Supreme</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">deputy</governor>
          <dependent id="14">Soviet</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">USSR</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">USSR</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">USSR</governor>
          <dependent id="17">former</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">Soviet</governor>
          <dependent id="18">USSR</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">1950</governor>
          <dependent id="20">soldier</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="22">resigned</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Army</governor>
          <dependent id="23">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Army</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">resigned</governor>
          <dependent id="25">Army</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">fight</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="26">in</governor>
          <dependent id="27">order</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="29">fight</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">resigned</governor>
          <dependent id="29">fight</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">restoration</governor>
          <dependent id="30">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">restoration</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">fight</governor>
          <dependent id="32">restoration</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">USSR</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">USSR</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">restoration</governor>
          <dependent id="35">USSR</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Viktor Alksnis" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Viktor" />
            <token id="2" string="Alksnis" />
          </tokens>
        </entity>
        <entity id="2" string="Army" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="25" string="Army" />
          </tokens>
        </entity>
        <entity id="3" string="1950" type="DATE" score="0.0">
          <tokens>
            <token id="5" string="1950" />
          </tokens>
        </entity>
        <entity id="4" string="Latvian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="7" string="Latvian" />
          </tokens>
        </entity>
        <entity id="5" string="USSR" type="LOCATION" score="0.0">
          <tokens>
            <token id="18" string="USSR" />
          </tokens>
        </entity>
        <entity id="6" string="Supreme Soviet" type="MISC" score="0.0">
          <tokens>
            <token id="13" string="Supreme" />
            <token id="14" string="Soviet" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>During the October events he left the White House with a head wound and was taken to hospital.</content>
      <tokens>
        <token id="1" string="During" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="October" lemma="October" stem="october" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="4" string="events" lemma="event" stem="event" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="left" lemma="leave" stem="left" pos="VBD" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="White" lemma="White" stem="white" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="9" string="House" lemma="House" stem="hous" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="10" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="wound" lemma="wound" stem="wound" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="hospital" lemma="hospital" stem="hospit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN During) (NP (DT the) (NNP October) (NNS events))) (NP (PRP he)) (VP (VP (VBD left) (NP (DT the) (NNP White) (NNP House)) (PP (IN with) (NP (DT a) (NN head) (NN wound)))) (CC and) (VP (VBD was) (VP (VBN taken) (PP (TO to) (NP (NN hospital)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="left the White House with a head wound" type="VP">
          <tokens>
            <token id="6" string="left" />
            <token id="7" string="the" />
            <token id="8" string="White" />
            <token id="9" string="House" />
            <token id="10" string="with" />
            <token id="11" string="a" />
            <token id="12" string="head" />
            <token id="13" string="wound" />
          </tokens>
        </chunking>
        <chunking id="2" string="taken to hospital" type="VP">
          <tokens>
            <token id="16" string="taken" />
            <token id="17" string="to" />
            <token id="18" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="3" string="left the White House with a head wound and was taken to hospital" type="VP">
          <tokens>
            <token id="6" string="left" />
            <token id="7" string="the" />
            <token id="8" string="White" />
            <token id="9" string="House" />
            <token id="10" string="with" />
            <token id="11" string="a" />
            <token id="12" string="head" />
            <token id="13" string="wound" />
            <token id="14" string="and" />
            <token id="15" string="was" />
            <token id="16" string="taken" />
            <token id="17" string="to" />
            <token id="18" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="4" string="a head wound" type="NP">
          <tokens>
            <token id="11" string="a" />
            <token id="12" string="head" />
            <token id="13" string="wound" />
          </tokens>
        </chunking>
        <chunking id="5" string="the October events" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="October" />
            <token id="4" string="events" />
          </tokens>
        </chunking>
        <chunking id="6" string="the White House" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="White" />
            <token id="9" string="House" />
          </tokens>
        </chunking>
        <chunking id="7" string="was taken to hospital" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="taken" />
            <token id="17" string="to" />
            <token id="18" string="hospital" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="hospital" type="NP">
          <tokens>
            <token id="18" string="hospital" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">events</governor>
          <dependent id="1">During</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">events</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">events</governor>
          <dependent id="3">October</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">left</governor>
          <dependent id="4">events</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">left</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">left</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">House</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">House</governor>
          <dependent id="8">White</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">left</governor>
          <dependent id="9">House</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">wound</governor>
          <dependent id="10">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">wound</governor>
          <dependent id="11">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">wound</governor>
          <dependent id="12">head</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">left</governor>
          <dependent id="13">wound</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">left</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="16">taken</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">left</governor>
          <dependent id="16">taken</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">hospital</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">taken</governor>
          <dependent id="18">hospital</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="left" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="6" string="left" />
          </tokens>
        </entity>
        <entity id="2" string="White House" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="White" />
            <token id="9" string="House" />
          </tokens>
        </entity>
        <entity id="3" string="October" type="DATE" score="0.0">
          <tokens>
            <token id="3" string="October" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>After a long interval Viktor Alksnis held a news conference today in the Slavjanskaya Hotel.</content>
      <tokens>
        <token id="1" string="After" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="interval" lemma="interval" stem="interv" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Viktor" lemma="Viktor" stem="viktor" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="Alksnis" lemma="Alksnis" stem="alksni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="held" lemma="hold" stem="held" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="news" lemma="news" stem="new" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="conference" lemma="conference" stem="confer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Slavjanskaya" lemma="Slavjanskaya" stem="slavjanskaya" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Hotel" lemma="Hotel" stem="hotel" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN After) (NP (DT a) (JJ long) (NN interval))) (NP (NNP Viktor) (NNP Alksnis)) (VP (VBD held) (NP (DT a) (NN news) (NN conference)) (NP-TMP (NN today)) (PP (IN in) (NP (DT the) (NNP Slavjanskaya) (NNP Hotel)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a long interval" type="NP">
          <tokens>
            <token id="2" string="a" />
            <token id="3" string="long" />
            <token id="4" string="interval" />
          </tokens>
        </chunking>
        <chunking id="2" string="Viktor Alksnis" type="NP">
          <tokens>
            <token id="5" string="Viktor" />
            <token id="6" string="Alksnis" />
          </tokens>
        </chunking>
        <chunking id="3" string="a news conference" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="news" />
            <token id="10" string="conference" />
          </tokens>
        </chunking>
        <chunking id="4" string="held a news conference today in the Slavjanskaya Hotel" type="VP">
          <tokens>
            <token id="7" string="held" />
            <token id="8" string="a" />
            <token id="9" string="news" />
            <token id="10" string="conference" />
            <token id="11" string="today" />
            <token id="12" string="in" />
            <token id="13" string="the" />
            <token id="14" string="Slavjanskaya" />
            <token id="15" string="Hotel" />
          </tokens>
        </chunking>
        <chunking id="5" string="the Slavjanskaya Hotel" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="Slavjanskaya" />
            <token id="15" string="Hotel" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">interval</governor>
          <dependent id="1">After</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">interval</governor>
          <dependent id="2">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">interval</governor>
          <dependent id="3">long</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">held</governor>
          <dependent id="4">interval</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Alksnis</governor>
          <dependent id="5">Viktor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">held</governor>
          <dependent id="6">Alksnis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">held</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">conference</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">conference</governor>
          <dependent id="9">news</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">held</governor>
          <dependent id="10">conference</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">held</governor>
          <dependent id="11">today</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Hotel</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">Hotel</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Hotel</governor>
          <dependent id="14">Slavjanskaya</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">held</governor>
          <dependent id="15">Hotel</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Slavjanskaya Hotel" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Slavjanskaya" />
            <token id="15" string="Hotel" />
          </tokens>
        </entity>
        <entity id="2" string="Viktor Alksnis" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Viktor" />
            <token id="6" string="Alksnis" />
          </tokens>
        </entity>
        <entity id="3" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="today" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>He began it with a short statement, the essence of which comes down to the fact that the adoption of the Latvian citizenship law violates not only human rights, but creates the conditions for a conflict similar, in his opinion, to the ones in Yugoslavia and the Caucasus.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="began" lemma="begin" stem="began" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="short" lemma="short" stem="short" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="statement" lemma="statement" stem="statement" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="essence" lemma="essence" stem="essenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="down" lemma="down" stem="down" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="adoption" lemma="adoption" stem="adopt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Latvian" lemma="latvian" stem="latvian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="24" string="citizenship" lemma="citizenship" stem="citizenship" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="violates" lemma="violate" stem="violat" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="human" lemma="human" stem="human" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="rights" lemma="rights" stem="right" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="creates" lemma="create" stem="creat" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="conditions" lemma="condition" stem="condit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="conflict" lemma="conflict" stem="conflict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="similar" lemma="similar" stem="similar" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="40" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="42" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="43" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="44" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="ones" lemma="one" stem="on" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="48" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="49" string="Yugoslavia" lemma="Yugoslavia" stem="yugoslavia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="50" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="52" string="Caucasus" lemma="Caucasus" stem="caucasu" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="53" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD began) (NP (PRP it)) (PP (IN with) (NP (NP (DT a) (JJ short) (NN statement)) (, ,) (SBAR (WHNP (NP (DT the) (NN essence)) (WHPP (IN of) (WHNP (WDT which)))) (S (VP (VBZ comes) (PRT (RP down)) (PP (TO to) (NP (DT the) (NN fact))) (SBAR (IN that) (S (NP (NP (DT the) (NN adoption)) (PP (IN of) (NP (DT the) (JJ Latvian) (NN citizenship) (NN law)))) (VP (VP (VBZ violates) (NP (RB not) (RB only) (JJ human) (NNS rights))) (, ,) (CC but) (VP (VBZ creates) (S (NP (NP (DT the) (NNS conditions)) (PP (IN for) (NP (DT a) (NN conflict)))) (ADJP (JJ similar)))))))))))) (, ,) (PP (IN in) (NP (PRP$ his) (NN opinion))) (, ,) (PP (TO to) (NP (NP (DT the) (NNS ones)) (PP (IN in) (NP (NP (NNP Yugoslavia)) (CC and) (NP (DT the) (NNP Caucasus))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="similar" type="ADJP">
          <tokens>
            <token id="39" string="similar" />
          </tokens>
        </chunking>
        <chunking id="2" string="the conditions for a conflict" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="conditions" />
            <token id="36" string="for" />
            <token id="37" string="a" />
            <token id="38" string="conflict" />
          </tokens>
        </chunking>
        <chunking id="3" string="the fact" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="fact" />
          </tokens>
        </chunking>
        <chunking id="4" string="the adoption of the Latvian citizenship law" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="adoption" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Latvian" />
            <token id="24" string="citizenship" />
            <token id="25" string="law" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="his opinion" type="NP">
          <tokens>
            <token id="42" string="his" />
            <token id="43" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="7" string="the conditions" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="conditions" />
          </tokens>
        </chunking>
        <chunking id="8" string="the ones in Yugoslavia and the Caucasus" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="ones" />
            <token id="48" string="in" />
            <token id="49" string="Yugoslavia" />
            <token id="50" string="and" />
            <token id="51" string="the" />
            <token id="52" string="Caucasus" />
          </tokens>
        </chunking>
        <chunking id="9" string="the essence of which comes down to the fact that the adoption of the Latvian citizenship law violates not only human rights , but creates the conditions for a conflict similar" type="SBAR">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="essence" />
            <token id="11" string="of" />
            <token id="12" string="which" />
            <token id="13" string="comes" />
            <token id="14" string="down" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="adoption" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Latvian" />
            <token id="24" string="citizenship" />
            <token id="25" string="law" />
            <token id="26" string="violates" />
            <token id="27" string="not" />
            <token id="28" string="only" />
            <token id="29" string="human" />
            <token id="30" string="rights" />
            <token id="31" string="," />
            <token id="32" string="but" />
            <token id="33" string="creates" />
            <token id="34" string="the" />
            <token id="35" string="conditions" />
            <token id="36" string="for" />
            <token id="37" string="a" />
            <token id="38" string="conflict" />
            <token id="39" string="similar" />
          </tokens>
        </chunking>
        <chunking id="10" string="comes down to the fact that the adoption of the Latvian citizenship law violates not only human rights , but creates the conditions for a conflict similar" type="VP">
          <tokens>
            <token id="13" string="comes" />
            <token id="14" string="down" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="adoption" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Latvian" />
            <token id="24" string="citizenship" />
            <token id="25" string="law" />
            <token id="26" string="violates" />
            <token id="27" string="not" />
            <token id="28" string="only" />
            <token id="29" string="human" />
            <token id="30" string="rights" />
            <token id="31" string="," />
            <token id="32" string="but" />
            <token id="33" string="creates" />
            <token id="34" string="the" />
            <token id="35" string="conditions" />
            <token id="36" string="for" />
            <token id="37" string="a" />
            <token id="38" string="conflict" />
            <token id="39" string="similar" />
          </tokens>
        </chunking>
        <chunking id="11" string="a short statement , the essence of which comes down to the fact that the adoption of the Latvian citizenship law violates not only human rights , but creates the conditions for a conflict similar" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="short" />
            <token id="7" string="statement" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="essence" />
            <token id="11" string="of" />
            <token id="12" string="which" />
            <token id="13" string="comes" />
            <token id="14" string="down" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="adoption" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Latvian" />
            <token id="24" string="citizenship" />
            <token id="25" string="law" />
            <token id="26" string="violates" />
            <token id="27" string="not" />
            <token id="28" string="only" />
            <token id="29" string="human" />
            <token id="30" string="rights" />
            <token id="31" string="," />
            <token id="32" string="but" />
            <token id="33" string="creates" />
            <token id="34" string="the" />
            <token id="35" string="conditions" />
            <token id="36" string="for" />
            <token id="37" string="a" />
            <token id="38" string="conflict" />
            <token id="39" string="similar" />
          </tokens>
        </chunking>
        <chunking id="12" string="began it with a short statement , the essence of which comes down to the fact that the adoption of the Latvian citizenship law violates not only human rights , but creates the conditions for a conflict similar , in his opinion , to the ones in Yugoslavia and the Caucasus" type="VP">
          <tokens>
            <token id="2" string="began" />
            <token id="3" string="it" />
            <token id="4" string="with" />
            <token id="5" string="a" />
            <token id="6" string="short" />
            <token id="7" string="statement" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="essence" />
            <token id="11" string="of" />
            <token id="12" string="which" />
            <token id="13" string="comes" />
            <token id="14" string="down" />
            <token id="15" string="to" />
            <token id="16" string="the" />
            <token id="17" string="fact" />
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="adoption" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Latvian" />
            <token id="24" string="citizenship" />
            <token id="25" string="law" />
            <token id="26" string="violates" />
            <token id="27" string="not" />
            <token id="28" string="only" />
            <token id="29" string="human" />
            <token id="30" string="rights" />
            <token id="31" string="," />
            <token id="32" string="but" />
            <token id="33" string="creates" />
            <token id="34" string="the" />
            <token id="35" string="conditions" />
            <token id="36" string="for" />
            <token id="37" string="a" />
            <token id="38" string="conflict" />
            <token id="39" string="similar" />
            <token id="40" string="," />
            <token id="41" string="in" />
            <token id="42" string="his" />
            <token id="43" string="opinion" />
            <token id="44" string="," />
            <token id="45" string="to" />
            <token id="46" string="the" />
            <token id="47" string="ones" />
            <token id="48" string="in" />
            <token id="49" string="Yugoslavia" />
            <token id="50" string="and" />
            <token id="51" string="the" />
            <token id="52" string="Caucasus" />
          </tokens>
        </chunking>
        <chunking id="13" string="the ones" type="NP">
          <tokens>
            <token id="46" string="the" />
            <token id="47" string="ones" />
          </tokens>
        </chunking>
        <chunking id="14" string="a short statement" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="short" />
            <token id="7" string="statement" />
          </tokens>
        </chunking>
        <chunking id="15" string="a conflict" type="NP">
          <tokens>
            <token id="37" string="a" />
            <token id="38" string="conflict" />
          </tokens>
        </chunking>
        <chunking id="16" string="the Latvian citizenship law" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="Latvian" />
            <token id="24" string="citizenship" />
            <token id="25" string="law" />
          </tokens>
        </chunking>
        <chunking id="17" string="violates not only human rights , but creates the conditions for a conflict similar" type="VP">
          <tokens>
            <token id="26" string="violates" />
            <token id="27" string="not" />
            <token id="28" string="only" />
            <token id="29" string="human" />
            <token id="30" string="rights" />
            <token id="31" string="," />
            <token id="32" string="but" />
            <token id="33" string="creates" />
            <token id="34" string="the" />
            <token id="35" string="conditions" />
            <token id="36" string="for" />
            <token id="37" string="a" />
            <token id="38" string="conflict" />
            <token id="39" string="similar" />
          </tokens>
        </chunking>
        <chunking id="18" string="violates not only human rights" type="VP">
          <tokens>
            <token id="26" string="violates" />
            <token id="27" string="not" />
            <token id="28" string="only" />
            <token id="29" string="human" />
            <token id="30" string="rights" />
          </tokens>
        </chunking>
        <chunking id="19" string="creates the conditions for a conflict similar" type="VP">
          <tokens>
            <token id="33" string="creates" />
            <token id="34" string="the" />
            <token id="35" string="conditions" />
            <token id="36" string="for" />
            <token id="37" string="a" />
            <token id="38" string="conflict" />
            <token id="39" string="similar" />
          </tokens>
        </chunking>
        <chunking id="20" string="the Caucasus" type="NP">
          <tokens>
            <token id="51" string="the" />
            <token id="52" string="Caucasus" />
          </tokens>
        </chunking>
        <chunking id="21" string="not only human rights" type="NP">
          <tokens>
            <token id="27" string="not" />
            <token id="28" string="only" />
            <token id="29" string="human" />
            <token id="30" string="rights" />
          </tokens>
        </chunking>
        <chunking id="22" string="Yugoslavia" type="NP">
          <tokens>
            <token id="49" string="Yugoslavia" />
          </tokens>
        </chunking>
        <chunking id="23" string="the essence" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="essence" />
          </tokens>
        </chunking>
        <chunking id="24" string="that the adoption of the Latvian citizenship law violates not only human rights , but creates the conditions for a conflict similar" type="SBAR">
          <tokens>
            <token id="18" string="that" />
            <token id="19" string="the" />
            <token id="20" string="adoption" />
            <token id="21" string="of" />
            <token id="22" string="the" />
            <token id="23" string="Latvian" />
            <token id="24" string="citizenship" />
            <token id="25" string="law" />
            <token id="26" string="violates" />
            <token id="27" string="not" />
            <token id="28" string="only" />
            <token id="29" string="human" />
            <token id="30" string="rights" />
            <token id="31" string="," />
            <token id="32" string="but" />
            <token id="33" string="creates" />
            <token id="34" string="the" />
            <token id="35" string="conditions" />
            <token id="36" string="for" />
            <token id="37" string="a" />
            <token id="38" string="conflict" />
            <token id="39" string="similar" />
          </tokens>
        </chunking>
        <chunking id="25" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="26" string="the adoption" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="adoption" />
          </tokens>
        </chunking>
        <chunking id="27" string="Yugoslavia and the Caucasus" type="NP">
          <tokens>
            <token id="49" string="Yugoslavia" />
            <token id="50" string="and" />
            <token id="51" string="the" />
            <token id="52" string="Caucasus" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">began</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">began</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">began</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">statement</governor>
          <dependent id="4">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">statement</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">statement</governor>
          <dependent id="6">short</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">began</governor>
          <dependent id="7">statement</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">essence</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">comes</governor>
          <dependent id="10">essence</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">which</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">essence</governor>
          <dependent id="12">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">statement</governor>
          <dependent id="13">comes</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="13">comes</governor>
          <dependent id="14">down</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">fact</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">fact</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">comes</governor>
          <dependent id="17">fact</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">violates</governor>
          <dependent id="18">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">adoption</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="26">violates</governor>
          <dependent id="20">adoption</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">law</governor>
          <dependent id="21">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">law</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">law</governor>
          <dependent id="23">Latvian</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="25">law</governor>
          <dependent id="24">citizenship</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">adoption</governor>
          <dependent id="25">law</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">comes</governor>
          <dependent id="26">violates</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="30">rights</governor>
          <dependent id="27">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="30">rights</governor>
          <dependent id="28">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">rights</governor>
          <dependent id="29">human</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="26">violates</governor>
          <dependent id="30">rights</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="26">violates</governor>
          <dependent id="32">but</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="26">violates</governor>
          <dependent id="33">creates</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">conditions</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="39">similar</governor>
          <dependent id="35">conditions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">conflict</governor>
          <dependent id="36">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">conflict</governor>
          <dependent id="37">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">conditions</governor>
          <dependent id="38">conflict</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="33">creates</governor>
          <dependent id="39">similar</dependent>
        </dependency>
        <dependency type="case">
          <governor id="43">opinion</governor>
          <dependent id="41">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="43">opinion</governor>
          <dependent id="42">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">began</governor>
          <dependent id="43">opinion</dependent>
        </dependency>
        <dependency type="case">
          <governor id="47">ones</governor>
          <dependent id="45">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="47">ones</governor>
          <dependent id="46">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">began</governor>
          <dependent id="47">ones</dependent>
        </dependency>
        <dependency type="case">
          <governor id="49">Yugoslavia</governor>
          <dependent id="48">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="47">ones</governor>
          <dependent id="49">Yugoslavia</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="49">Yugoslavia</governor>
          <dependent id="50">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="52">Caucasus</governor>
          <dependent id="51">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="49">Yugoslavia</governor>
          <dependent id="52">Caucasus</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Yugoslavia" type="LOCATION" score="0.0">
          <tokens>
            <token id="49" string="Yugoslavia" />
          </tokens>
        </entity>
        <entity id="2" string="Latvian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="23" string="Latvian" />
          </tokens>
        </entity>
        <entity id="3" string="Caucasus" type="LOCATION" score="0.0">
          <tokens>
            <token id="52" string="Caucasus" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>It was not only the Latvian Government Alksnis accused of this, but also the United States.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Latvian" lemma="latvian" stem="latvian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="7" string="Government" lemma="government" stem="govern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="Alksnis" lemma="Alksnis" stem="alksni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="accused" lemma="accuse" stem="accus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="17" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP It)) (VP (VBD was) (RB not) (ADVP (RB only)) (NP (NP (DT the) (JJ Latvian) (NN Government)) (SBAR (S (NP (NNP Alksnis)) (VP (VBD accused) (PP (IN of) (NP (NP (DT this)) (, ,) (CONJP (CC but) (RB also)) (NP (DT the) (NNP United) (NNPS States))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the United States" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="United" />
            <token id="17" string="States" />
          </tokens>
        </chunking>
        <chunking id="2" string="Alksnis accused of this , but also the United States" type="SBAR">
          <tokens>
            <token id="8" string="Alksnis" />
            <token id="9" string="accused" />
            <token id="10" string="of" />
            <token id="11" string="this" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="also" />
            <token id="15" string="the" />
            <token id="16" string="United" />
            <token id="17" string="States" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Latvian Government Alksnis accused of this , but also the United States" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Latvian" />
            <token id="7" string="Government" />
            <token id="8" string="Alksnis" />
            <token id="9" string="accused" />
            <token id="10" string="of" />
            <token id="11" string="this" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="also" />
            <token id="15" string="the" />
            <token id="16" string="United" />
            <token id="17" string="States" />
          </tokens>
        </chunking>
        <chunking id="4" string="the Latvian Government" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="Latvian" />
            <token id="7" string="Government" />
          </tokens>
        </chunking>
        <chunking id="5" string="accused of this , but also the United States" type="VP">
          <tokens>
            <token id="9" string="accused" />
            <token id="10" string="of" />
            <token id="11" string="this" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="also" />
            <token id="15" string="the" />
            <token id="16" string="United" />
            <token id="17" string="States" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="was not only the Latvian Government Alksnis accused of this , but also the United States" type="VP">
          <tokens>
            <token id="2" string="was" />
            <token id="3" string="not" />
            <token id="4" string="only" />
            <token id="5" string="the" />
            <token id="6" string="Latvian" />
            <token id="7" string="Government" />
            <token id="8" string="Alksnis" />
            <token id="9" string="accused" />
            <token id="10" string="of" />
            <token id="11" string="this" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="also" />
            <token id="15" string="the" />
            <token id="16" string="United" />
            <token id="17" string="States" />
          </tokens>
        </chunking>
        <chunking id="8" string="this , but also the United States" type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="," />
            <token id="13" string="but" />
            <token id="14" string="also" />
            <token id="15" string="the" />
            <token id="16" string="United" />
            <token id="17" string="States" />
          </tokens>
        </chunking>
        <chunking id="9" string="this" type="NP">
          <tokens>
            <token id="11" string="this" />
          </tokens>
        </chunking>
        <chunking id="10" string="Alksnis" type="NP">
          <tokens>
            <token id="8" string="Alksnis" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">Government</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">Government</governor>
          <dependent id="2">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">Government</governor>
          <dependent id="3">not</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">Government</governor>
          <dependent id="4">only</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Government</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Government</governor>
          <dependent id="6">Latvian</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">Government</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">accused</governor>
          <dependent id="8">Alksnis</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">Government</governor>
          <dependent id="9">accused</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">this</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">accused</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">this</governor>
          <dependent id="13">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">States</governor>
          <dependent id="14">also</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">States</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">States</governor>
          <dependent id="16">United</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="11">this</governor>
          <dependent id="17">States</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="16" string="United" />
            <token id="17" string="States" />
          </tokens>
        </entity>
        <entity id="2" string="Latvian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="6" string="Latvian" />
          </tokens>
        </entity>
        <entity id="3" string="Alksnis" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Alksnis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>According to him, during the latest visit to the United States by Guntis Ulmanis, sanction was obtained for the adoption of the aforementioned discriminatory law.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="latest" lemma="latest" stem="latest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="visit" lemma="visit" stem="visit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="United" lemma="United" stem="unite" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="12" string="States" lemma="States" stem="state" pos="NNPS" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="13" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Guntis" lemma="Guntis" stem="gunti" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="15" string="Ulmanis" lemma="Ulmanis" stem="ulmani" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="sanction" lemma="sanction" stem="sanction" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="obtained" lemma="obtain" stem="obtain" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="adoption" lemma="adoption" stem="adopt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="aforementioned" lemma="aforementioned" stem="aforement" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="discriminatory" lemma="discriminatory" stem="discriminatori" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (PRP him))) (, ,) (PP (IN during) (NP (NP (DT the) (JJS latest) (NN visit)) (PP (TO to) (NP (NP (DT the) (NNP United) (NNPS States)) (PP (IN by) (NP (NNP Guntis) (NNP Ulmanis)))))))) (, ,) (NP (NN sanction)) (VP (VBD was) (VP (VBN obtained) (PP (IN for) (NP (NP (DT the) (NN adoption)) (PP (IN of) (NP (DT the) (JJ aforementioned) (JJ discriminatory) (NN law))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the United States" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="United" />
            <token id="12" string="States" />
          </tokens>
        </chunking>
        <chunking id="2" string="the latest visit" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="latest" />
            <token id="8" string="visit" />
          </tokens>
        </chunking>
        <chunking id="3" string="Guntis Ulmanis" type="NP">
          <tokens>
            <token id="14" string="Guntis" />
            <token id="15" string="Ulmanis" />
          </tokens>
        </chunking>
        <chunking id="4" string="was obtained for the adoption of the aforementioned discriminatory law" type="VP">
          <tokens>
            <token id="18" string="was" />
            <token id="19" string="obtained" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="adoption" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="aforementioned" />
            <token id="26" string="discriminatory" />
            <token id="27" string="law" />
          </tokens>
        </chunking>
        <chunking id="5" string="sanction" type="NP">
          <tokens>
            <token id="17" string="sanction" />
          </tokens>
        </chunking>
        <chunking id="6" string="the adoption of the aforementioned discriminatory law" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="adoption" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="aforementioned" />
            <token id="26" string="discriminatory" />
            <token id="27" string="law" />
          </tokens>
        </chunking>
        <chunking id="7" string="the aforementioned discriminatory law" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="aforementioned" />
            <token id="26" string="discriminatory" />
            <token id="27" string="law" />
          </tokens>
        </chunking>
        <chunking id="8" string="obtained for the adoption of the aforementioned discriminatory law" type="VP">
          <tokens>
            <token id="19" string="obtained" />
            <token id="20" string="for" />
            <token id="21" string="the" />
            <token id="22" string="adoption" />
            <token id="23" string="of" />
            <token id="24" string="the" />
            <token id="25" string="aforementioned" />
            <token id="26" string="discriminatory" />
            <token id="27" string="law" />
          </tokens>
        </chunking>
        <chunking id="9" string="him" type="NP">
          <tokens>
            <token id="3" string="him" />
          </tokens>
        </chunking>
        <chunking id="10" string="the United States by Guntis Ulmanis" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="United" />
            <token id="12" string="States" />
            <token id="13" string="by" />
            <token id="14" string="Guntis" />
            <token id="15" string="Ulmanis" />
          </tokens>
        </chunking>
        <chunking id="11" string="the latest visit to the United States by Guntis Ulmanis" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="latest" />
            <token id="8" string="visit" />
            <token id="9" string="to" />
            <token id="10" string="the" />
            <token id="11" string="United" />
            <token id="12" string="States" />
            <token id="13" string="by" />
            <token id="14" string="Guntis" />
            <token id="15" string="Ulmanis" />
          </tokens>
        </chunking>
        <chunking id="12" string="the adoption" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="adoption" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">him</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">obtained</governor>
          <dependent id="3">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">visit</governor>
          <dependent id="5">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">visit</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">visit</governor>
          <dependent id="7">latest</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">him</governor>
          <dependent id="8">visit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">States</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">States</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">States</governor>
          <dependent id="11">United</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">visit</governor>
          <dependent id="12">States</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">Ulmanis</governor>
          <dependent id="13">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Ulmanis</governor>
          <dependent id="14">Guntis</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">States</governor>
          <dependent id="15">Ulmanis</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">obtained</governor>
          <dependent id="17">sanction</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">obtained</governor>
          <dependent id="18">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="19">obtained</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">adoption</governor>
          <dependent id="20">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">adoption</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">obtained</governor>
          <dependent id="22">adoption</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">law</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="27">law</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">law</governor>
          <dependent id="25">aforementioned</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="27">law</governor>
          <dependent id="26">discriminatory</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">adoption</governor>
          <dependent id="27">law</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Guntis Ulmanis" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Guntis" />
            <token id="15" string="Ulmanis" />
          </tokens>
        </entity>
        <entity id="2" string="United States" type="LOCATION" score="0.0">
          <tokens>
            <token id="11" string="United" />
            <token id="12" string="States" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>And thus carte blanche was given for mild ethnic cleansing of the Russian speaking population of the republic.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="thus" lemma="thus" stem="thu" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="carte" lemma="carte" stem="cart" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="blanche" lemma="blanche" stem="blanch" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="given" lemma="give" stem="given" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="mild" lemma="mild" stem="mild" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="ethnic" lemma="ethnic" stem="ethnic" pos="JJ" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="true" is_refers="false" />
        <token id="10" string="cleansing" lemma="cleanse" stem="cleans" pos="VBG" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="true" is_refers="false" />
        <token id="11" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Russian" lemma="russian" stem="russian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="14" string="speaking" lemma="speak" stem="speak" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="republic" lemma="republic" stem="republ" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (RB thus) (VP (VBP carte) (SBAR (S (NP (NN blanche)) (VP (VBD was) (VP (VBN given) (PP (IN for) (NP (JJ mild) (JJ ethnic))) (S (VP (VBG cleansing) (PP (IN of) (NP (NP (DT the) (JJ Russian) (VBG speaking) (NN population)) (PP (IN of) (NP (DT the) (NN republic)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="blanche" type="NP">
          <tokens>
            <token id="4" string="blanche" />
          </tokens>
        </chunking>
        <chunking id="2" string="the Russian speaking population" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Russian" />
            <token id="14" string="speaking" />
            <token id="15" string="population" />
          </tokens>
        </chunking>
        <chunking id="3" string="blanche was given for mild ethnic cleansing of the Russian speaking population of the republic" type="SBAR">
          <tokens>
            <token id="4" string="blanche" />
            <token id="5" string="was" />
            <token id="6" string="given" />
            <token id="7" string="for" />
            <token id="8" string="mild" />
            <token id="9" string="ethnic" />
            <token id="10" string="cleansing" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="Russian" />
            <token id="14" string="speaking" />
            <token id="15" string="population" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="republic" />
          </tokens>
        </chunking>
        <chunking id="4" string="mild ethnic" type="NP">
          <tokens>
            <token id="8" string="mild" />
            <token id="9" string="ethnic" />
          </tokens>
        </chunking>
        <chunking id="5" string="the republic" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="republic" />
          </tokens>
        </chunking>
        <chunking id="6" string="cleansing of the Russian speaking population of the republic" type="VP">
          <tokens>
            <token id="10" string="cleansing" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="Russian" />
            <token id="14" string="speaking" />
            <token id="15" string="population" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="republic" />
          </tokens>
        </chunking>
        <chunking id="7" string="carte blanche was given for mild ethnic cleansing of the Russian speaking population of the republic" type="VP">
          <tokens>
            <token id="3" string="carte" />
            <token id="4" string="blanche" />
            <token id="5" string="was" />
            <token id="6" string="given" />
            <token id="7" string="for" />
            <token id="8" string="mild" />
            <token id="9" string="ethnic" />
            <token id="10" string="cleansing" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="Russian" />
            <token id="14" string="speaking" />
            <token id="15" string="population" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="republic" />
          </tokens>
        </chunking>
        <chunking id="8" string="given for mild ethnic cleansing of the Russian speaking population of the republic" type="VP">
          <tokens>
            <token id="6" string="given" />
            <token id="7" string="for" />
            <token id="8" string="mild" />
            <token id="9" string="ethnic" />
            <token id="10" string="cleansing" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="Russian" />
            <token id="14" string="speaking" />
            <token id="15" string="population" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="republic" />
          </tokens>
        </chunking>
        <chunking id="9" string="was given for mild ethnic cleansing of the Russian speaking population of the republic" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="given" />
            <token id="7" string="for" />
            <token id="8" string="mild" />
            <token id="9" string="ethnic" />
            <token id="10" string="cleansing" />
            <token id="11" string="of" />
            <token id="12" string="the" />
            <token id="13" string="Russian" />
            <token id="14" string="speaking" />
            <token id="15" string="population" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="republic" />
          </tokens>
        </chunking>
        <chunking id="10" string="the Russian speaking population of the republic" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="Russian" />
            <token id="14" string="speaking" />
            <token id="15" string="population" />
            <token id="16" string="of" />
            <token id="17" string="the" />
            <token id="18" string="republic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">carte</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">carte</governor>
          <dependent id="2">thus</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">carte</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">given</governor>
          <dependent id="4">blanche</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">given</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">carte</governor>
          <dependent id="6">given</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">ethnic</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">ethnic</governor>
          <dependent id="8">mild</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">given</governor>
          <dependent id="9">ethnic</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">given</governor>
          <dependent id="10">cleansing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">population</governor>
          <dependent id="11">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">population</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">population</governor>
          <dependent id="13">Russian</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">population</governor>
          <dependent id="14">speaking</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">cleansing</governor>
          <dependent id="15">population</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">republic</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">republic</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">population</governor>
          <dependent id="18">republic</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Russian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="13" string="Russian" />
          </tokens>
        </entity>
        <entity id="2" string="ethnic cleansing" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="9" string="ethnic" />
            <token id="10" string="cleansing" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>Apart from that, Alksnis added, according to information received from reliable sources, certain circles in Moscow want conflict in Latvia.</content>
      <tokens>
        <token id="1" string="Apart" lemma="apart" stem="apart" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Alksnis" lemma="Alksnis" stem="alksni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="added" lemma="add" stem="ad" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="received" lemma="receive" stem="receiv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="reliable" lemma="reliable" stem="reliabl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="sources" lemma="source" stem="sourc" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="circles" lemma="circle" stem="circl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Moscow" lemma="Moscow" stem="moscow" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="conflict" lemma="conflict" stem="conflict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="Latvia" lemma="Latvia" stem="latvia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="24" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (ADVP (RB Apart)) (IN from) (NP (DT that))) (PRN (, ,) (NP (NNP Alksnis)) (VP (VBD added)) (, ,)) (PP (VBG according) (PP (TO to) (NP (NP (NN information)) (VP (VBD received) (PP (IN from) (NP (JJ reliable) (NNS sources))))))) (, ,) (NP (NP (JJ certain) (NNS circles)) (PP (IN in) (NP (NNP Moscow)))) (VP (VBP want) (NP (NP (NN conflict)) (PP (IN in) (NP (NNP Latvia))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="certain circles in Moscow" type="NP">
          <tokens>
            <token id="16" string="certain" />
            <token id="17" string="circles" />
            <token id="18" string="in" />
            <token id="19" string="Moscow" />
          </tokens>
        </chunking>
        <chunking id="2" string="want conflict in Latvia" type="VP">
          <tokens>
            <token id="20" string="want" />
            <token id="21" string="conflict" />
            <token id="22" string="in" />
            <token id="23" string="Latvia" />
          </tokens>
        </chunking>
        <chunking id="3" string="information received from reliable sources" type="NP">
          <tokens>
            <token id="10" string="information" />
            <token id="11" string="received" />
            <token id="12" string="from" />
            <token id="13" string="reliable" />
            <token id="14" string="sources" />
          </tokens>
        </chunking>
        <chunking id="4" string="Moscow" type="NP">
          <tokens>
            <token id="19" string="Moscow" />
          </tokens>
        </chunking>
        <chunking id="5" string="reliable sources" type="NP">
          <tokens>
            <token id="13" string="reliable" />
            <token id="14" string="sources" />
          </tokens>
        </chunking>
        <chunking id="6" string="conflict in Latvia" type="NP">
          <tokens>
            <token id="21" string="conflict" />
            <token id="22" string="in" />
            <token id="23" string="Latvia" />
          </tokens>
        </chunking>
        <chunking id="7" string="that" type="NP">
          <tokens>
            <token id="3" string="that" />
          </tokens>
        </chunking>
        <chunking id="8" string="Latvia" type="NP">
          <tokens>
            <token id="23" string="Latvia" />
          </tokens>
        </chunking>
        <chunking id="9" string="certain circles" type="NP">
          <tokens>
            <token id="16" string="certain" />
            <token id="17" string="circles" />
          </tokens>
        </chunking>
        <chunking id="10" string="received from reliable sources" type="VP">
          <tokens>
            <token id="11" string="received" />
            <token id="12" string="from" />
            <token id="13" string="reliable" />
            <token id="14" string="sources" />
          </tokens>
        </chunking>
        <chunking id="11" string="added" type="VP">
          <tokens>
            <token id="6" string="added" />
          </tokens>
        </chunking>
        <chunking id="12" string="conflict" type="NP">
          <tokens>
            <token id="21" string="conflict" />
          </tokens>
        </chunking>
        <chunking id="13" string="information" type="NP">
          <tokens>
            <token id="10" string="information" />
          </tokens>
        </chunking>
        <chunking id="14" string="Alksnis" type="NP">
          <tokens>
            <token id="5" string="Alksnis" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">that</governor>
          <dependent id="1">Apart</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">Apart</governor>
          <dependent id="2">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">want</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">added</governor>
          <dependent id="5">Alksnis</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="20">want</governor>
          <dependent id="6">added</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">information</governor>
          <dependent id="8">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="8">according</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">want</governor>
          <dependent id="10">information</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">information</governor>
          <dependent id="11">received</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">sources</governor>
          <dependent id="12">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">sources</governor>
          <dependent id="13">reliable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">received</governor>
          <dependent id="14">sources</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">circles</governor>
          <dependent id="16">certain</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">want</governor>
          <dependent id="17">circles</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Moscow</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">circles</governor>
          <dependent id="19">Moscow</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">want</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">want</governor>
          <dependent id="21">conflict</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Latvia</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">conflict</governor>
          <dependent id="23">Latvia</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Latvia" type="LOCATION" score="0.0">
          <tokens>
            <token id="23" string="Latvia" />
          </tokens>
        </entity>
        <entity id="2" string="Alksnis" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Alksnis" />
          </tokens>
        </entity>
        <entity id="3" string="Moscow" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Moscow" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="false">
      <content>A certain scenario exists to drive a so-called security corridor along the route Daugavpils-Yekabpils-Riga where stringent ethnic cleansing of the Latvian population will take place in reply to the mild ethnic cleansing of the Russian population in order to bring so-called independent Latvia to its knees.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="certain" lemma="certain" stem="certain" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="scenario" lemma="scenario" stem="scenario" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="exists" lemma="exist" stem="exist" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="drive" lemma="drive" stem="drive" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="so-called" lemma="so-called" stem="so-cal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="security" lemma="security" stem="secur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="corridor" lemma="corridor" stem="corridor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="along" lemma="along" stem="along" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="route" lemma="route" stem="rout" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Daugavpils-Yekabpils-Riga" lemma="Daugavpils-Yekabpils-Riga" stem="daugavpils-yekabpils-riga" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="15" string="where" lemma="where" stem="where" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="stringent" lemma="stringent" stem="stringent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="ethnic" lemma="ethnic" stem="ethnic" pos="JJ" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="18" string="cleansing" lemma="cleanse" stem="cleans" pos="VBG" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="19" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="Latvian" lemma="latvian" stem="latvian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="22" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="reply" lemma="reply" stem="repli" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="mild" lemma="mild" stem="mild" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="ethnic" lemma="ethnic" stem="ethnic" pos="JJ" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="32" string="cleansing" lemma="cleanse" stem="cleans" pos="VBG" type="Word" isStopWord="false" ner="CRIMINAL_CHARGE" is_referenced="false" is_refers="false" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Russian" lemma="russian" stem="russian" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="36" string="population" lemma="population" stem="popul" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="37" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="order" lemma="order" stem="order" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="bring" lemma="bring" stem="bring" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="41" string="so-called" lemma="so-called" stem="so-cal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="independent" lemma="independent" stem="independ" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="43" string="Latvia" lemma="Latvia" stem="latvia" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="44" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="45" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="knees" lemma="knee" stem="knee" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="47" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT A) (JJ certain) (NN scenario)) (VP (VBZ exists) (S (VP (TO to) (VP (VB drive) (NP (DT a) (JJ so-called) (NN security) (NN corridor)) (PP (IN along) (NP (DT the) (NN route) (NNP Daugavpils-Yekabpils-Riga))) (SBAR (WHADVP (WRB where)) (S (NP (NP (ADJP (JJ stringent)) (JJ ethnic)) (VP (VBG cleansing) (PP (IN of) (NP (DT the) (JJ Latvian) (NN population))))) (VP (MD will) (VP (VB take) (NP (NP (NN place)) (PP (IN in) (NP (NN reply)))) (PP (TO to) (NP (NP (DT the) (JJ mild) (JJ ethnic)) (VP (VBG cleansing) (PP (IN of) (NP (NP (DT the) (JJ Russian) (NN population)) (PP (IN in) (NP (NN order))))) (S (VP (TO to) (VP (VB bring) (NP (NP (JJ so-called) (JJ independent) (NNP Latvia)) (PP (TO to) (NP (PRP$ its) (NNS knees)))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="to bring so-called independent Latvia to its knees" type="VP">
          <tokens>
            <token id="39" string="to" />
            <token id="40" string="bring" />
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="2" string="cleansing of the Russian population in order to bring so-called independent Latvia to its knees" type="VP">
          <tokens>
            <token id="32" string="cleansing" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="Russian" />
            <token id="36" string="population" />
            <token id="37" string="in" />
            <token id="38" string="order" />
            <token id="39" string="to" />
            <token id="40" string="bring" />
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="3" string="a so-called security corridor" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="so-called" />
            <token id="9" string="security" />
            <token id="10" string="corridor" />
          </tokens>
        </chunking>
        <chunking id="4" string="will take place in reply to the mild ethnic cleansing of the Russian population in order to bring so-called independent Latvia to its knees" type="VP">
          <tokens>
            <token id="23" string="will" />
            <token id="24" string="take" />
            <token id="25" string="place" />
            <token id="26" string="in" />
            <token id="27" string="reply" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="mild" />
            <token id="31" string="ethnic" />
            <token id="32" string="cleansing" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="Russian" />
            <token id="36" string="population" />
            <token id="37" string="in" />
            <token id="38" string="order" />
            <token id="39" string="to" />
            <token id="40" string="bring" />
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="5" string="bring so-called independent Latvia to its knees" type="VP">
          <tokens>
            <token id="40" string="bring" />
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="6" string="take place in reply to the mild ethnic cleansing of the Russian population in order to bring so-called independent Latvia to its knees" type="VP">
          <tokens>
            <token id="24" string="take" />
            <token id="25" string="place" />
            <token id="26" string="in" />
            <token id="27" string="reply" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="mild" />
            <token id="31" string="ethnic" />
            <token id="32" string="cleansing" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="Russian" />
            <token id="36" string="population" />
            <token id="37" string="in" />
            <token id="38" string="order" />
            <token id="39" string="to" />
            <token id="40" string="bring" />
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="7" string="the Russian population" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="Russian" />
            <token id="36" string="population" />
          </tokens>
        </chunking>
        <chunking id="8" string="A certain scenario" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="certain" />
            <token id="3" string="scenario" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Russian population in order" type="NP">
          <tokens>
            <token id="34" string="the" />
            <token id="35" string="Russian" />
            <token id="36" string="population" />
            <token id="37" string="in" />
            <token id="38" string="order" />
          </tokens>
        </chunking>
        <chunking id="10" string="its knees" type="NP">
          <tokens>
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="11" string="the mild ethnic cleansing of the Russian population in order to bring so-called independent Latvia to its knees" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="mild" />
            <token id="31" string="ethnic" />
            <token id="32" string="cleansing" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="Russian" />
            <token id="36" string="population" />
            <token id="37" string="in" />
            <token id="38" string="order" />
            <token id="39" string="to" />
            <token id="40" string="bring" />
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="12" string="drive a so-called security corridor along the route Daugavpils-Yekabpils-Riga where stringent ethnic cleansing of the Latvian population will take place in reply to the mild ethnic cleansing of the Russian population in order to bring so-called independent Latvia to its knees" type="VP">
          <tokens>
            <token id="6" string="drive" />
            <token id="7" string="a" />
            <token id="8" string="so-called" />
            <token id="9" string="security" />
            <token id="10" string="corridor" />
            <token id="11" string="along" />
            <token id="12" string="the" />
            <token id="13" string="route" />
            <token id="14" string="Daugavpils-Yekabpils-Riga" />
            <token id="15" string="where" />
            <token id="16" string="stringent" />
            <token id="17" string="ethnic" />
            <token id="18" string="cleansing" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="Latvian" />
            <token id="22" string="population" />
            <token id="23" string="will" />
            <token id="24" string="take" />
            <token id="25" string="place" />
            <token id="26" string="in" />
            <token id="27" string="reply" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="mild" />
            <token id="31" string="ethnic" />
            <token id="32" string="cleansing" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="Russian" />
            <token id="36" string="population" />
            <token id="37" string="in" />
            <token id="38" string="order" />
            <token id="39" string="to" />
            <token id="40" string="bring" />
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Latvian population" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="Latvian" />
            <token id="22" string="population" />
          </tokens>
        </chunking>
        <chunking id="14" string="so-called independent Latvia" type="NP">
          <tokens>
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
          </tokens>
        </chunking>
        <chunking id="15" string="stringent" type="ADJP">
          <tokens>
            <token id="16" string="stringent" />
          </tokens>
        </chunking>
        <chunking id="16" string="where stringent ethnic cleansing of the Latvian population will take place in reply to the mild ethnic cleansing of the Russian population in order to bring so-called independent Latvia to its knees" type="SBAR">
          <tokens>
            <token id="15" string="where" />
            <token id="16" string="stringent" />
            <token id="17" string="ethnic" />
            <token id="18" string="cleansing" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="Latvian" />
            <token id="22" string="population" />
            <token id="23" string="will" />
            <token id="24" string="take" />
            <token id="25" string="place" />
            <token id="26" string="in" />
            <token id="27" string="reply" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="mild" />
            <token id="31" string="ethnic" />
            <token id="32" string="cleansing" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="Russian" />
            <token id="36" string="population" />
            <token id="37" string="in" />
            <token id="38" string="order" />
            <token id="39" string="to" />
            <token id="40" string="bring" />
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="17" string="cleansing of the Latvian population" type="VP">
          <tokens>
            <token id="18" string="cleansing" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="Latvian" />
            <token id="22" string="population" />
          </tokens>
        </chunking>
        <chunking id="18" string="exists to drive a so-called security corridor along the route Daugavpils-Yekabpils-Riga where stringent ethnic cleansing of the Latvian population will take place in reply to the mild ethnic cleansing of the Russian population in order to bring so-called independent Latvia to its knees" type="VP">
          <tokens>
            <token id="4" string="exists" />
            <token id="5" string="to" />
            <token id="6" string="drive" />
            <token id="7" string="a" />
            <token id="8" string="so-called" />
            <token id="9" string="security" />
            <token id="10" string="corridor" />
            <token id="11" string="along" />
            <token id="12" string="the" />
            <token id="13" string="route" />
            <token id="14" string="Daugavpils-Yekabpils-Riga" />
            <token id="15" string="where" />
            <token id="16" string="stringent" />
            <token id="17" string="ethnic" />
            <token id="18" string="cleansing" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="Latvian" />
            <token id="22" string="population" />
            <token id="23" string="will" />
            <token id="24" string="take" />
            <token id="25" string="place" />
            <token id="26" string="in" />
            <token id="27" string="reply" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="mild" />
            <token id="31" string="ethnic" />
            <token id="32" string="cleansing" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="Russian" />
            <token id="36" string="population" />
            <token id="37" string="in" />
            <token id="38" string="order" />
            <token id="39" string="to" />
            <token id="40" string="bring" />
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="19" string="stringent ethnic cleansing of the Latvian population" type="NP">
          <tokens>
            <token id="16" string="stringent" />
            <token id="17" string="ethnic" />
            <token id="18" string="cleansing" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="Latvian" />
            <token id="22" string="population" />
          </tokens>
        </chunking>
        <chunking id="20" string="place in reply" type="NP">
          <tokens>
            <token id="25" string="place" />
            <token id="26" string="in" />
            <token id="27" string="reply" />
          </tokens>
        </chunking>
        <chunking id="21" string="to drive a so-called security corridor along the route Daugavpils-Yekabpils-Riga where stringent ethnic cleansing of the Latvian population will take place in reply to the mild ethnic cleansing of the Russian population in order to bring so-called independent Latvia to its knees" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="drive" />
            <token id="7" string="a" />
            <token id="8" string="so-called" />
            <token id="9" string="security" />
            <token id="10" string="corridor" />
            <token id="11" string="along" />
            <token id="12" string="the" />
            <token id="13" string="route" />
            <token id="14" string="Daugavpils-Yekabpils-Riga" />
            <token id="15" string="where" />
            <token id="16" string="stringent" />
            <token id="17" string="ethnic" />
            <token id="18" string="cleansing" />
            <token id="19" string="of" />
            <token id="20" string="the" />
            <token id="21" string="Latvian" />
            <token id="22" string="population" />
            <token id="23" string="will" />
            <token id="24" string="take" />
            <token id="25" string="place" />
            <token id="26" string="in" />
            <token id="27" string="reply" />
            <token id="28" string="to" />
            <token id="29" string="the" />
            <token id="30" string="mild" />
            <token id="31" string="ethnic" />
            <token id="32" string="cleansing" />
            <token id="33" string="of" />
            <token id="34" string="the" />
            <token id="35" string="Russian" />
            <token id="36" string="population" />
            <token id="37" string="in" />
            <token id="38" string="order" />
            <token id="39" string="to" />
            <token id="40" string="bring" />
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="22" string="so-called independent Latvia to its knees" type="NP">
          <tokens>
            <token id="41" string="so-called" />
            <token id="42" string="independent" />
            <token id="43" string="Latvia" />
            <token id="44" string="to" />
            <token id="45" string="its" />
            <token id="46" string="knees" />
          </tokens>
        </chunking>
        <chunking id="23" string="place" type="NP">
          <tokens>
            <token id="25" string="place" />
          </tokens>
        </chunking>
        <chunking id="24" string="where" type="WHADVP">
          <tokens>
            <token id="15" string="where" />
          </tokens>
        </chunking>
        <chunking id="25" string="order" type="NP">
          <tokens>
            <token id="38" string="order" />
          </tokens>
        </chunking>
        <chunking id="26" string="the route Daugavpils-Yekabpils-Riga" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="route" />
            <token id="14" string="Daugavpils-Yekabpils-Riga" />
          </tokens>
        </chunking>
        <chunking id="27" string="stringent ethnic" type="NP">
          <tokens>
            <token id="16" string="stringent" />
            <token id="17" string="ethnic" />
          </tokens>
        </chunking>
        <chunking id="28" string="reply" type="NP">
          <tokens>
            <token id="27" string="reply" />
          </tokens>
        </chunking>
        <chunking id="29" string="the mild ethnic" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="mild" />
            <token id="31" string="ethnic" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">scenario</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">scenario</governor>
          <dependent id="2">certain</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">exists</governor>
          <dependent id="3">scenario</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">exists</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">drive</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">exists</governor>
          <dependent id="6">drive</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">corridor</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">corridor</governor>
          <dependent id="8">so-called</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">corridor</governor>
          <dependent id="9">security</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">drive</governor>
          <dependent id="10">corridor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">Daugavpils-Yekabpils-Riga</governor>
          <dependent id="11">along</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">Daugavpils-Yekabpils-Riga</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">Daugavpils-Yekabpils-Riga</governor>
          <dependent id="13">route</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">drive</governor>
          <dependent id="14">Daugavpils-Yekabpils-Riga</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">take</governor>
          <dependent id="15">where</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">ethnic</governor>
          <dependent id="16">stringent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">take</governor>
          <dependent id="17">ethnic</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="17">ethnic</governor>
          <dependent id="18">cleansing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">population</governor>
          <dependent id="19">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">population</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">population</governor>
          <dependent id="21">Latvian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">cleansing</governor>
          <dependent id="22">population</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">take</governor>
          <dependent id="23">will</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">drive</governor>
          <dependent id="24">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">take</governor>
          <dependent id="25">place</dependent>
        </dependency>
        <dependency type="case">
          <governor id="27">reply</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">place</governor>
          <dependent id="27">reply</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">ethnic</governor>
          <dependent id="28">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">ethnic</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="31">ethnic</governor>
          <dependent id="30">mild</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">take</governor>
          <dependent id="31">ethnic</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="31">ethnic</governor>
          <dependent id="32">cleansing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">population</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="36">population</governor>
          <dependent id="34">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="36">population</governor>
          <dependent id="35">Russian</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">cleansing</governor>
          <dependent id="36">population</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="36">population</governor>
          <dependent id="37">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="37">in</governor>
          <dependent id="38">order</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="40">bring</governor>
          <dependent id="39">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="32">cleansing</governor>
          <dependent id="40">bring</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">Latvia</governor>
          <dependent id="41">so-called</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="43">Latvia</governor>
          <dependent id="42">independent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="40">bring</governor>
          <dependent id="43">Latvia</dependent>
        </dependency>
        <dependency type="case">
          <governor id="46">knees</governor>
          <dependent id="44">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="46">knees</governor>
          <dependent id="45">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="43">Latvia</governor>
          <dependent id="46">knees</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Russian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="35" string="Russian" />
          </tokens>
        </entity>
        <entity id="2" string="Latvia" type="LOCATION" score="0.0">
          <tokens>
            <token id="43" string="Latvia" />
          </tokens>
        </entity>
        <entity id="3" string="Daugavpils-Yekabpils-Riga" type="LOCATION" score="0.0">
          <tokens>
            <token id="14" string="Daugavpils-Yekabpils-Riga" />
          </tokens>
        </entity>
        <entity id="4" string="ethnic cleansing" type="CRIMINAL_CHARGE" score="0.0">
          <tokens>
            <token id="17" string="ethnic" />
            <token id="18" string="cleansing" />
          </tokens>
        </entity>
        <entity id="5" string="Latvian" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="21" string="Latvian" />
          </tokens>
        </entity>
        <entity id="6" string="independent" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="42" string="independent" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>Journalists asked for more precise information about what Alksnis called reliable sources.</content>
      <tokens>
        <token id="1" string="Journalists" lemma="journalist" stem="journalist" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="asked" lemma="ask" stem="ask" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="precise" lemma="precise" stem="precis" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Alksnis" lemma="Alksnis" stem="alksni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="called" lemma="call" stem="call" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="reliable" lemma="reliable" stem="reliabl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="sources" lemma="source" stem="sourc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Journalists)) (VP (VBD asked) (PP (IN for) (NP (ADJP (RBR more) (JJ precise)) (NN information))) (PP (IN about) (SBAR (WHNP (WP what)) (S (NP (NNP Alksnis)) (VP (VBD called) (NP (JJ reliable) (NNS sources))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="called reliable sources" type="VP">
          <tokens>
            <token id="10" string="called" />
            <token id="11" string="reliable" />
            <token id="12" string="sources" />
          </tokens>
        </chunking>
        <chunking id="2" string="Journalists" type="NP">
          <tokens>
            <token id="1" string="Journalists" />
          </tokens>
        </chunking>
        <chunking id="3" string="what Alksnis called reliable sources" type="SBAR">
          <tokens>
            <token id="8" string="what" />
            <token id="9" string="Alksnis" />
            <token id="10" string="called" />
            <token id="11" string="reliable" />
            <token id="12" string="sources" />
          </tokens>
        </chunking>
        <chunking id="4" string="more precise" type="ADJP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="precise" />
          </tokens>
        </chunking>
        <chunking id="5" string="asked for more precise information about what Alksnis called reliable sources" type="VP">
          <tokens>
            <token id="2" string="asked" />
            <token id="3" string="for" />
            <token id="4" string="more" />
            <token id="5" string="precise" />
            <token id="6" string="information" />
            <token id="7" string="about" />
            <token id="8" string="what" />
            <token id="9" string="Alksnis" />
            <token id="10" string="called" />
            <token id="11" string="reliable" />
            <token id="12" string="sources" />
          </tokens>
        </chunking>
        <chunking id="6" string="more precise information" type="NP">
          <tokens>
            <token id="4" string="more" />
            <token id="5" string="precise" />
            <token id="6" string="information" />
          </tokens>
        </chunking>
        <chunking id="7" string="Alksnis" type="NP">
          <tokens>
            <token id="9" string="Alksnis" />
          </tokens>
        </chunking>
        <chunking id="8" string="reliable sources" type="NP">
          <tokens>
            <token id="11" string="reliable" />
            <token id="12" string="sources" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">asked</governor>
          <dependent id="1">Journalists</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">asked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">information</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">precise</governor>
          <dependent id="4">more</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">information</governor>
          <dependent id="5">precise</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">asked</governor>
          <dependent id="6">information</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">called</governor>
          <dependent id="7">about</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">called</governor>
          <dependent id="8">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">called</governor>
          <dependent id="9">Alksnis</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">asked</governor>
          <dependent id="10">called</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">sources</governor>
          <dependent id="11">reliable</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">called</governor>
          <dependent id="12">sources</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Alksnis" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Alksnis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>You understand that I cannot name these sources.</content>
      <tokens>
        <token id="1" string="You" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="understand" lemma="understand" stem="understand" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="name" lemma="name" stem="name" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="these" lemma="these" stem="these" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="sources" lemma="source" stem="sourc" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP You)) (VP (VBP understand) (SBAR (IN that) (S (NP (PRP I)) (VP (MD can) (RB not) (VP (VB name) (NP (DT these) (NNS sources))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="name these sources" type="VP">
          <tokens>
            <token id="7" string="name" />
            <token id="8" string="these" />
            <token id="9" string="sources" />
          </tokens>
        </chunking>
        <chunking id="2" string="can not name these sources" type="VP">
          <tokens>
            <token id="5" string="can" />
            <token id="6" string="not" />
            <token id="7" string="name" />
            <token id="8" string="these" />
            <token id="9" string="sources" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="4" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="understand that I can not name these sources" type="VP">
          <tokens>
            <token id="2" string="understand" />
            <token id="3" string="that" />
            <token id="4" string="I" />
            <token id="5" string="can" />
            <token id="6" string="not" />
            <token id="7" string="name" />
            <token id="8" string="these" />
            <token id="9" string="sources" />
          </tokens>
        </chunking>
        <chunking id="5" string="these sources" type="NP">
          <tokens>
            <token id="8" string="these" />
            <token id="9" string="sources" />
          </tokens>
        </chunking>
        <chunking id="6" string="You" type="NP">
          <tokens>
            <token id="1" string="You" />
          </tokens>
        </chunking>
        <chunking id="7" string="that I can not name these sources" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="I" />
            <token id="5" string="can" />
            <token id="6" string="not" />
            <token id="7" string="name" />
            <token id="8" string="these" />
            <token id="9" string="sources" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">understand</governor>
          <dependent id="1">You</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">understand</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">name</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">name</governor>
          <dependent id="4">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">name</governor>
          <dependent id="5">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="7">name</governor>
          <dependent id="6">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">understand</governor>
          <dependent id="7">name</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">sources</governor>
          <dependent id="8">these</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">name</governor>
          <dependent id="9">sources</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>But I can say that they are fairly authoritative.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="say" lemma="say" stem="sai" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="fairly" lemma="fairly" stem="fairli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="authoritative" lemma="authoritative" stem="authorit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP I)) (VP (MD can) (VP (VB say) (SBAR (IN that) (S (NP (PRP they)) (VP (VBP are) (ADJP (RB fairly) (JJ authoritative))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="6" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="are fairly authoritative" type="VP">
          <tokens>
            <token id="7" string="are" />
            <token id="8" string="fairly" />
            <token id="9" string="authoritative" />
          </tokens>
        </chunking>
        <chunking id="3" string="fairly authoritative" type="ADJP">
          <tokens>
            <token id="8" string="fairly" />
            <token id="9" string="authoritative" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="can say that they are fairly authoritative" type="VP">
          <tokens>
            <token id="3" string="can" />
            <token id="4" string="say" />
            <token id="5" string="that" />
            <token id="6" string="they" />
            <token id="7" string="are" />
            <token id="8" string="fairly" />
            <token id="9" string="authoritative" />
          </tokens>
        </chunking>
        <chunking id="6" string="say that they are fairly authoritative" type="VP">
          <tokens>
            <token id="4" string="say" />
            <token id="5" string="that" />
            <token id="6" string="they" />
            <token id="7" string="are" />
            <token id="8" string="fairly" />
            <token id="9" string="authoritative" />
          </tokens>
        </chunking>
        <chunking id="7" string="that they are fairly authoritative" type="SBAR">
          <tokens>
            <token id="5" string="that" />
            <token id="6" string="they" />
            <token id="7" string="are" />
            <token id="8" string="fairly" />
            <token id="9" string="authoritative" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">say</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">say</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">say</governor>
          <dependent id="3">can</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">say</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">authoritative</governor>
          <dependent id="5">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">authoritative</governor>
          <dependent id="6">they</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="9">authoritative</governor>
          <dependent id="7">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">authoritative</governor>
          <dependent id="8">fairly</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">say</governor>
          <dependent id="9">authoritative</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>Asked what he intends to do, Alksnis said his opportunities are unfortunately limited, and that is why he is appealing to journalists.</content>
      <tokens>
        <token id="1" string="Asked" lemma="ask" stem="asked" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="intends" lemma="intend" stem="intend" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Alksnis" lemma="Alksnis" stem="alksni" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="opportunities" lemma="opportunity" stem="opportun" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="unfortunately" lemma="unfortunately" stem="unfortun" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="limited" lemma="limit" stem="limit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="why" lemma="why" stem="why" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="appealing" lemma="appeal" stem="appeal" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="journalists" lemma="journalist" stem="journalist" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (S (VP (VBN Asked) (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (VBZ intends) (S (VP (TO to) (VP (VB do))))))))) (, ,) (NP (NNP Alksnis)) (VP (VBD said) (SBAR (S (NP (PRP$ his) (NNS opportunities)) (VP (VBP are) (ADVP (RB unfortunately)) (VP (VBN limited))))))) (, ,) (CC and) (S (NP (DT that)) (VP (VBZ is) (SBAR (WHADVP (WRB why)) (S (NP (PRP he)) (VP (VBZ is) (VP (VBG appealing) (PP (TO to) (NP (NNS journalists))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="limited" type="VP">
          <tokens>
            <token id="14" string="limited" />
          </tokens>
        </chunking>
        <chunking id="2" string="why" type="WHADVP">
          <tokens>
            <token id="19" string="why" />
          </tokens>
        </chunking>
        <chunking id="3" string="are unfortunately limited" type="VP">
          <tokens>
            <token id="12" string="are" />
            <token id="13" string="unfortunately" />
            <token id="14" string="limited" />
          </tokens>
        </chunking>
        <chunking id="4" string="do" type="VP">
          <tokens>
            <token id="6" string="do" />
          </tokens>
        </chunking>
        <chunking id="5" string="Asked what he intends to do" type="VP">
          <tokens>
            <token id="1" string="Asked" />
            <token id="2" string="what" />
            <token id="3" string="he" />
            <token id="4" string="intends" />
            <token id="5" string="to" />
            <token id="6" string="do" />
          </tokens>
        </chunking>
        <chunking id="6" string="his opportunities are unfortunately limited" type="SBAR">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="opportunities" />
            <token id="12" string="are" />
            <token id="13" string="unfortunately" />
            <token id="14" string="limited" />
          </tokens>
        </chunking>
        <chunking id="7" string="why he is appealing to journalists" type="SBAR">
          <tokens>
            <token id="19" string="why" />
            <token id="20" string="he" />
            <token id="21" string="is" />
            <token id="22" string="appealing" />
            <token id="23" string="to" />
            <token id="24" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="8" string="that" type="NP">
          <tokens>
            <token id="17" string="that" />
          </tokens>
        </chunking>
        <chunking id="9" string="intends to do" type="VP">
          <tokens>
            <token id="4" string="intends" />
            <token id="5" string="to" />
            <token id="6" string="do" />
          </tokens>
        </chunking>
        <chunking id="10" string="journalists" type="NP">
          <tokens>
            <token id="24" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="11" string="said his opportunities are unfortunately limited" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="his" />
            <token id="11" string="opportunities" />
            <token id="12" string="are" />
            <token id="13" string="unfortunately" />
            <token id="14" string="limited" />
          </tokens>
        </chunking>
        <chunking id="12" string="is appealing to journalists" type="VP">
          <tokens>
            <token id="21" string="is" />
            <token id="22" string="appealing" />
            <token id="23" string="to" />
            <token id="24" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="13" string="to do" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="do" />
          </tokens>
        </chunking>
        <chunking id="14" string="is why he is appealing to journalists" type="VP">
          <tokens>
            <token id="18" string="is" />
            <token id="19" string="why" />
            <token id="20" string="he" />
            <token id="21" string="is" />
            <token id="22" string="appealing" />
            <token id="23" string="to" />
            <token id="24" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="3" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="what he intends to do" type="SBAR">
          <tokens>
            <token id="2" string="what" />
            <token id="3" string="he" />
            <token id="4" string="intends" />
            <token id="5" string="to" />
            <token id="6" string="do" />
          </tokens>
        </chunking>
        <chunking id="17" string="appealing to journalists" type="VP">
          <tokens>
            <token id="22" string="appealing" />
            <token id="23" string="to" />
            <token id="24" string="journalists" />
          </tokens>
        </chunking>
        <chunking id="18" string="Alksnis" type="NP">
          <tokens>
            <token id="8" string="Alksnis" />
          </tokens>
        </chunking>
        <chunking id="19" string="his opportunities" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="opportunities" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="9">said</governor>
          <dependent id="1">Asked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">intends</governor>
          <dependent id="2">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">intends</governor>
          <dependent id="3">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">Asked</governor>
          <dependent id="4">intends</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">do</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">intends</governor>
          <dependent id="6">do</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="8">Alksnis</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">opportunities</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="14">limited</governor>
          <dependent id="11">opportunities</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="14">limited</governor>
          <dependent id="12">are</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">limited</governor>
          <dependent id="13">unfortunately</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="14">limited</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">said</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">is</governor>
          <dependent id="17">that</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">said</governor>
          <dependent id="18">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">appealing</governor>
          <dependent id="19">why</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">appealing</governor>
          <dependent id="20">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="22">appealing</governor>
          <dependent id="21">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="18">is</governor>
          <dependent id="22">appealing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">journalists</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">appealing</governor>
          <dependent id="24">journalists</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Alksnis" type="PERSON" score="0.0">
          <tokens>
            <token id="8" string="Alksnis" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>In his opinion, only joint efforts can bring this information to the attention of world public opinion, point out the seriousness of this issue, and avoid the coming tragedy.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="joint" lemma="joint" stem="joint" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="efforts" lemma="effort" stem="effort" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="bring" lemma="bring" stem="bring" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="information" lemma="information" stem="inform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="world" lemma="world" stem="world" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="opinion" lemma="opinion" stem="opinion" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="out" lemma="out" stem="out" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="seriousness" lemma="seriousness" stem="serious" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="avoid" lemma="avoid" stem="avoid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="coming" lemma="come" stem="come" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="tragedy" lemma="tragedy" stem="tragedi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (PRP$ his) (NN opinion))) (, ,) (NP (RB only) (JJ joint) (NNS efforts)) (VP (MD can) (VP (VP (VB bring) (NP (DT this) (NN information)) (PP (TO to) (NP (NP (DT the) (NN attention)) (PP (IN of) (NP (NP (NN world) (JJ public) (NN opinion)) (, ,) (NP (NP (NN point)) (PP (IN out) (NP (NP (DT the) (NN seriousness)) (PP (IN of) (NP (DT this) (NN issue)))))) (, ,)))))) (CC and) (VP (VB avoid) (NP (DT the) (VBG coming) (NN tragedy))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="world public opinion , point out the seriousness of this issue ," type="NP">
          <tokens>
            <token id="16" string="world" />
            <token id="17" string="public" />
            <token id="18" string="opinion" />
            <token id="19" string="," />
            <token id="20" string="point" />
            <token id="21" string="out" />
            <token id="22" string="the" />
            <token id="23" string="seriousness" />
            <token id="24" string="of" />
            <token id="25" string="this" />
            <token id="26" string="issue" />
            <token id="27" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="this issue" type="NP">
          <tokens>
            <token id="25" string="this" />
            <token id="26" string="issue" />
          </tokens>
        </chunking>
        <chunking id="3" string="bring this information to the attention of world public opinion , point out the seriousness of this issue ," type="VP">
          <tokens>
            <token id="9" string="bring" />
            <token id="10" string="this" />
            <token id="11" string="information" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="attention" />
            <token id="15" string="of" />
            <token id="16" string="world" />
            <token id="17" string="public" />
            <token id="18" string="opinion" />
            <token id="19" string="," />
            <token id="20" string="point" />
            <token id="21" string="out" />
            <token id="22" string="the" />
            <token id="23" string="seriousness" />
            <token id="24" string="of" />
            <token id="25" string="this" />
            <token id="26" string="issue" />
            <token id="27" string="," />
          </tokens>
        </chunking>
        <chunking id="4" string="the attention of world public opinion , point out the seriousness of this issue ," type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="attention" />
            <token id="15" string="of" />
            <token id="16" string="world" />
            <token id="17" string="public" />
            <token id="18" string="opinion" />
            <token id="19" string="," />
            <token id="20" string="point" />
            <token id="21" string="out" />
            <token id="22" string="the" />
            <token id="23" string="seriousness" />
            <token id="24" string="of" />
            <token id="25" string="this" />
            <token id="26" string="issue" />
            <token id="27" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="his opinion" type="NP">
          <tokens>
            <token id="2" string="his" />
            <token id="3" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="6" string="only joint efforts" type="NP">
          <tokens>
            <token id="5" string="only" />
            <token id="6" string="joint" />
            <token id="7" string="efforts" />
          </tokens>
        </chunking>
        <chunking id="7" string="world public opinion" type="NP">
          <tokens>
            <token id="16" string="world" />
            <token id="17" string="public" />
            <token id="18" string="opinion" />
          </tokens>
        </chunking>
        <chunking id="8" string="can bring this information to the attention of world public opinion , point out the seriousness of this issue , and avoid the coming tragedy" type="VP">
          <tokens>
            <token id="8" string="can" />
            <token id="9" string="bring" />
            <token id="10" string="this" />
            <token id="11" string="information" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="attention" />
            <token id="15" string="of" />
            <token id="16" string="world" />
            <token id="17" string="public" />
            <token id="18" string="opinion" />
            <token id="19" string="," />
            <token id="20" string="point" />
            <token id="21" string="out" />
            <token id="22" string="the" />
            <token id="23" string="seriousness" />
            <token id="24" string="of" />
            <token id="25" string="this" />
            <token id="26" string="issue" />
            <token id="27" string="," />
            <token id="28" string="and" />
            <token id="29" string="avoid" />
            <token id="30" string="the" />
            <token id="31" string="coming" />
            <token id="32" string="tragedy" />
          </tokens>
        </chunking>
        <chunking id="9" string="point" type="NP">
          <tokens>
            <token id="20" string="point" />
          </tokens>
        </chunking>
        <chunking id="10" string="the seriousness" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="seriousness" />
          </tokens>
        </chunking>
        <chunking id="11" string="this information" type="NP">
          <tokens>
            <token id="10" string="this" />
            <token id="11" string="information" />
          </tokens>
        </chunking>
        <chunking id="12" string="the seriousness of this issue" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="seriousness" />
            <token id="24" string="of" />
            <token id="25" string="this" />
            <token id="26" string="issue" />
          </tokens>
        </chunking>
        <chunking id="13" string="the attention" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="attention" />
          </tokens>
        </chunking>
        <chunking id="14" string="bring this information to the attention of world public opinion , point out the seriousness of this issue , and avoid the coming tragedy" type="VP">
          <tokens>
            <token id="9" string="bring" />
            <token id="10" string="this" />
            <token id="11" string="information" />
            <token id="12" string="to" />
            <token id="13" string="the" />
            <token id="14" string="attention" />
            <token id="15" string="of" />
            <token id="16" string="world" />
            <token id="17" string="public" />
            <token id="18" string="opinion" />
            <token id="19" string="," />
            <token id="20" string="point" />
            <token id="21" string="out" />
            <token id="22" string="the" />
            <token id="23" string="seriousness" />
            <token id="24" string="of" />
            <token id="25" string="this" />
            <token id="26" string="issue" />
            <token id="27" string="," />
            <token id="28" string="and" />
            <token id="29" string="avoid" />
            <token id="30" string="the" />
            <token id="31" string="coming" />
            <token id="32" string="tragedy" />
          </tokens>
        </chunking>
        <chunking id="15" string="avoid the coming tragedy" type="VP">
          <tokens>
            <token id="29" string="avoid" />
            <token id="30" string="the" />
            <token id="31" string="coming" />
            <token id="32" string="tragedy" />
          </tokens>
        </chunking>
        <chunking id="16" string="point out the seriousness of this issue" type="NP">
          <tokens>
            <token id="20" string="point" />
            <token id="21" string="out" />
            <token id="22" string="the" />
            <token id="23" string="seriousness" />
            <token id="24" string="of" />
            <token id="25" string="this" />
            <token id="26" string="issue" />
          </tokens>
        </chunking>
        <chunking id="17" string="the coming tragedy" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="coming" />
            <token id="32" string="tragedy" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">opinion</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="3">opinion</governor>
          <dependent id="2">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">bring</governor>
          <dependent id="3">opinion</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">efforts</governor>
          <dependent id="5">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">efforts</governor>
          <dependent id="6">joint</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">bring</governor>
          <dependent id="7">efforts</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">bring</governor>
          <dependent id="8">can</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">bring</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">information</governor>
          <dependent id="10">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">bring</governor>
          <dependent id="11">information</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">attention</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">attention</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">bring</governor>
          <dependent id="14">attention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">opinion</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">opinion</governor>
          <dependent id="16">world</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">opinion</governor>
          <dependent id="17">public</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">attention</governor>
          <dependent id="18">opinion</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">opinion</governor>
          <dependent id="20">point</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">seriousness</governor>
          <dependent id="21">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">seriousness</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">point</governor>
          <dependent id="23">seriousness</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">issue</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">issue</governor>
          <dependent id="25">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">seriousness</governor>
          <dependent id="26">issue</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="9">bring</governor>
          <dependent id="28">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="9">bring</governor>
          <dependent id="29">avoid</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">tragedy</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">tragedy</governor>
          <dependent id="31">coming</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="29">avoid</governor>
          <dependent id="32">tragedy</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20" string="Viktor Alksnis , born 1950 , Latvian , former deputy of the Supreme Soviet of the former USSR , soldier" id_sentence="2" />
      <mentions>
        <mention ids_tokens="5" string="he" id_sentence="3" />
        <mention ids_tokens="5-6" string="Viktor Alksnis" id_sentence="4" />
        <mention ids_tokens="1" string="He" id_sentence="5" />
        <mention ids_tokens="42" string="his" id_sentence="5" />
        <mention ids_tokens="8" string="Alksnis" id_sentence="6" />
        <mention ids_tokens="3" string="him" id_sentence="7" />
        <mention ids_tokens="5" string="Alksnis" id_sentence="9" />
        <mention ids_tokens="9" string="Alksnis" id_sentence="11" />
        <mention ids_tokens="3" string="he" id_sentence="14" />
        <mention ids_tokens="8" string="Alksnis" id_sentence="14" />
        <mention ids_tokens="10" string="his" id_sentence="14" />
        <mention ids_tokens="20" string="he" id_sentence="14" />
        <mention ids_tokens="2" string="his" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="4" type="NOMINAL">
      <referenced ids_tokens="8-9-10" string="a news conference" id_sentence="4" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="9-10" string="ethnic cleansing" id_sentence="8" />
      <mentions>
        <mention ids_tokens="3" string="that" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="13-14" string="reliable sources" id_sentence="9" />
      <mentions>
        <mention ids_tokens="8-9" string="these sources" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="1" string="Journalists" id_sentence="11" />
      <mentions>
        <mention ids_tokens="6" string="they" id_sentence="13" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="4-5-6" string="more precise information" id_sentence="11" />
      <mentions>
        <mention ids_tokens="10-11" string="this information" id_sentence="15" />
      </mentions>
    </coreference>
  </coreferences>
</document>
