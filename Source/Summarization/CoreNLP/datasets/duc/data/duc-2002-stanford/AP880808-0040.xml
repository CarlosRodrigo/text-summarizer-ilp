<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP880808-0040">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>John Lennon spent much of a three-year span tucked away in his room, sleeping or sitting in a lotus position with his head enveloped in tobacco or marijuana smoke, according to a biography of the slain Beatle.</content>
      <tokens>
        <token id="1" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="spent" lemma="spend" stem="spent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="three-year" lemma="three-year" stem="three-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="8" string="span" lemma="span" stem="span" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="tucked" lemma="tuck" stem="tuck" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="away" lemma="away" stem="awai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="sleeping" lemma="sleep" stem="sleep" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="sitting" lemma="sit" stem="sit" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="lotus" lemma="lotus" stem="lotu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="position" lemma="position" stem="posit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="head" lemma="head" stem="head" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="enveloped" lemma="envelop" stem="envelop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="tobacco" lemma="tobacco" stem="tobacco" pos="NN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="28" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="marijuana" lemma="marijuana" stem="marijuana" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="smoke" lemma="smoke" stem="smoke" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="biography" lemma="biography" stem="biographi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="38" string="slain" lemma="slay" stem="slain" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="39" string="Beatle" lemma="Beatle" stem="beatl" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="true" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP John) (NNP Lennon)) (VP (VBD spent) (SBAR (S (NP (NP (RB much)) (PP (IN of) (NP (DT a) (JJ three-year) (NN span)))) (VP (VBD tucked) (ADVP (RB away)) (PP (IN in) (NP (PRP$ his) (NN room))) (, ,) (S (VP (VP (VBG sleeping)) (CC or) (VP (VBG sitting) (PP (IN in) (NP (DT a) (NN lotus) (NN position))) (SBAR (IN with) (S (NP (PRP$ his) (NN head)) (VP (VBD enveloped) (PP (IN in) (NP (NN tobacco) (CC or) (NN marijuana) (NN smoke))) (, ,) (PP (VBG according) (PP (TO to) (NP (NP (DT a) (NN biography)) (PP (IN of) (NP (DT the) (VBN slain) (NNP Beatle)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a three-year span" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="three-year" />
            <token id="8" string="span" />
          </tokens>
        </chunking>
        <chunking id="2" string="the slain Beatle" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="slain" />
            <token id="39" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="3" string="enveloped in tobacco or marijuana smoke , according to a biography of the slain Beatle" type="VP">
          <tokens>
            <token id="25" string="enveloped" />
            <token id="26" string="in" />
            <token id="27" string="tobacco" />
            <token id="28" string="or" />
            <token id="29" string="marijuana" />
            <token id="30" string="smoke" />
            <token id="31" string="," />
            <token id="32" string="according" />
            <token id="33" string="to" />
            <token id="34" string="a" />
            <token id="35" string="biography" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="slain" />
            <token id="39" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="4" string="a biography of the slain Beatle" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="biography" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="slain" />
            <token id="39" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="5" string="tucked away in his room , sleeping or sitting in a lotus position with his head enveloped in tobacco or marijuana smoke , according to a biography of the slain Beatle" type="VP">
          <tokens>
            <token id="9" string="tucked" />
            <token id="10" string="away" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="room" />
            <token id="14" string="," />
            <token id="15" string="sleeping" />
            <token id="16" string="or" />
            <token id="17" string="sitting" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="lotus" />
            <token id="21" string="position" />
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="head" />
            <token id="25" string="enveloped" />
            <token id="26" string="in" />
            <token id="27" string="tobacco" />
            <token id="28" string="or" />
            <token id="29" string="marijuana" />
            <token id="30" string="smoke" />
            <token id="31" string="," />
            <token id="32" string="according" />
            <token id="33" string="to" />
            <token id="34" string="a" />
            <token id="35" string="biography" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="slain" />
            <token id="39" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="6" string="much of a three-year span tucked away in his room , sleeping or sitting in a lotus position with his head enveloped in tobacco or marijuana smoke , according to a biography of the slain Beatle" type="SBAR">
          <tokens>
            <token id="4" string="much" />
            <token id="5" string="of" />
            <token id="6" string="a" />
            <token id="7" string="three-year" />
            <token id="8" string="span" />
            <token id="9" string="tucked" />
            <token id="10" string="away" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="room" />
            <token id="14" string="," />
            <token id="15" string="sleeping" />
            <token id="16" string="or" />
            <token id="17" string="sitting" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="lotus" />
            <token id="21" string="position" />
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="head" />
            <token id="25" string="enveloped" />
            <token id="26" string="in" />
            <token id="27" string="tobacco" />
            <token id="28" string="or" />
            <token id="29" string="marijuana" />
            <token id="30" string="smoke" />
            <token id="31" string="," />
            <token id="32" string="according" />
            <token id="33" string="to" />
            <token id="34" string="a" />
            <token id="35" string="biography" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="slain" />
            <token id="39" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="7" string="a lotus position" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="lotus" />
            <token id="21" string="position" />
          </tokens>
        </chunking>
        <chunking id="8" string="sleeping" type="VP">
          <tokens>
            <token id="15" string="sleeping" />
          </tokens>
        </chunking>
        <chunking id="9" string="John Lennon" type="NP">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="10" string="his head" type="NP">
          <tokens>
            <token id="23" string="his" />
            <token id="24" string="head" />
          </tokens>
        </chunking>
        <chunking id="11" string="his room" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="room" />
          </tokens>
        </chunking>
        <chunking id="12" string="with his head enveloped in tobacco or marijuana smoke , according to a biography of the slain Beatle" type="SBAR">
          <tokens>
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="head" />
            <token id="25" string="enveloped" />
            <token id="26" string="in" />
            <token id="27" string="tobacco" />
            <token id="28" string="or" />
            <token id="29" string="marijuana" />
            <token id="30" string="smoke" />
            <token id="31" string="," />
            <token id="32" string="according" />
            <token id="33" string="to" />
            <token id="34" string="a" />
            <token id="35" string="biography" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="slain" />
            <token id="39" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="13" string="sleeping or sitting in a lotus position with his head enveloped in tobacco or marijuana smoke , according to a biography of the slain Beatle" type="VP">
          <tokens>
            <token id="15" string="sleeping" />
            <token id="16" string="or" />
            <token id="17" string="sitting" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="lotus" />
            <token id="21" string="position" />
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="head" />
            <token id="25" string="enveloped" />
            <token id="26" string="in" />
            <token id="27" string="tobacco" />
            <token id="28" string="or" />
            <token id="29" string="marijuana" />
            <token id="30" string="smoke" />
            <token id="31" string="," />
            <token id="32" string="according" />
            <token id="33" string="to" />
            <token id="34" string="a" />
            <token id="35" string="biography" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="slain" />
            <token id="39" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="14" string="much of a three-year span" type="NP">
          <tokens>
            <token id="4" string="much" />
            <token id="5" string="of" />
            <token id="6" string="a" />
            <token id="7" string="three-year" />
            <token id="8" string="span" />
          </tokens>
        </chunking>
        <chunking id="15" string="tobacco or marijuana smoke" type="NP">
          <tokens>
            <token id="27" string="tobacco" />
            <token id="28" string="or" />
            <token id="29" string="marijuana" />
            <token id="30" string="smoke" />
          </tokens>
        </chunking>
        <chunking id="16" string="spent much of a three-year span tucked away in his room , sleeping or sitting in a lotus position with his head enveloped in tobacco or marijuana smoke , according to a biography of the slain Beatle" type="VP">
          <tokens>
            <token id="3" string="spent" />
            <token id="4" string="much" />
            <token id="5" string="of" />
            <token id="6" string="a" />
            <token id="7" string="three-year" />
            <token id="8" string="span" />
            <token id="9" string="tucked" />
            <token id="10" string="away" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="room" />
            <token id="14" string="," />
            <token id="15" string="sleeping" />
            <token id="16" string="or" />
            <token id="17" string="sitting" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="lotus" />
            <token id="21" string="position" />
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="head" />
            <token id="25" string="enveloped" />
            <token id="26" string="in" />
            <token id="27" string="tobacco" />
            <token id="28" string="or" />
            <token id="29" string="marijuana" />
            <token id="30" string="smoke" />
            <token id="31" string="," />
            <token id="32" string="according" />
            <token id="33" string="to" />
            <token id="34" string="a" />
            <token id="35" string="biography" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="slain" />
            <token id="39" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="17" string="sitting in a lotus position with his head enveloped in tobacco or marijuana smoke , according to a biography of the slain Beatle" type="VP">
          <tokens>
            <token id="17" string="sitting" />
            <token id="18" string="in" />
            <token id="19" string="a" />
            <token id="20" string="lotus" />
            <token id="21" string="position" />
            <token id="22" string="with" />
            <token id="23" string="his" />
            <token id="24" string="head" />
            <token id="25" string="enveloped" />
            <token id="26" string="in" />
            <token id="27" string="tobacco" />
            <token id="28" string="or" />
            <token id="29" string="marijuana" />
            <token id="30" string="smoke" />
            <token id="31" string="," />
            <token id="32" string="according" />
            <token id="33" string="to" />
            <token id="34" string="a" />
            <token id="35" string="biography" />
            <token id="36" string="of" />
            <token id="37" string="the" />
            <token id="38" string="slain" />
            <token id="39" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="18" string="a biography" type="NP">
          <tokens>
            <token id="34" string="a" />
            <token id="35" string="biography" />
          </tokens>
        </chunking>
        <chunking id="19" string="much" type="NP">
          <tokens>
            <token id="4" string="much" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Lennon</governor>
          <dependent id="1">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">spent</governor>
          <dependent id="2">Lennon</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">spent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">tucked</governor>
          <dependent id="4">much</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">span</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">span</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">span</governor>
          <dependent id="7">three-year</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">much</governor>
          <dependent id="8">span</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">spent</governor>
          <dependent id="9">tucked</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">tucked</governor>
          <dependent id="10">away</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">room</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">room</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">tucked</governor>
          <dependent id="13">room</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">tucked</governor>
          <dependent id="15">sleeping</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">sleeping</governor>
          <dependent id="16">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">sleeping</governor>
          <dependent id="17">sitting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">position</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">position</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">position</governor>
          <dependent id="20">lotus</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">sitting</governor>
          <dependent id="21">position</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="25">enveloped</governor>
          <dependent id="22">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">head</governor>
          <dependent id="23">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="25">enveloped</governor>
          <dependent id="24">head</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">sitting</governor>
          <dependent id="25">enveloped</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">smoke</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">smoke</governor>
          <dependent id="27">tobacco</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="27">tobacco</governor>
          <dependent id="28">or</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="27">tobacco</governor>
          <dependent id="29">marijuana</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">enveloped</governor>
          <dependent id="30">smoke</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">biography</governor>
          <dependent id="32">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="32">according</governor>
          <dependent id="33">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">biography</governor>
          <dependent id="34">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">enveloped</governor>
          <dependent id="35">biography</dependent>
        </dependency>
        <dependency type="case">
          <governor id="39">Beatle</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="39">Beatle</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="39">Beatle</governor>
          <dependent id="38">slain</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">biography</governor>
          <dependent id="39">Beatle</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="three-year" type="DURATION" score="0.0">
          <tokens>
            <token id="7" string="three-year" />
          </tokens>
        </entity>
        <entity id="3" string="Beatle" type="MISC" score="0.0">
          <tokens>
            <token id="39" string="Beatle" />
          </tokens>
        </entity>
        <entity id="4" string="tobacco" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="27" string="tobacco" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>An excerpt from the book, ``The Lives of John Lennon&amp;apost;&amp;apost; by journalist and biographer Albert Goldman, appearing in the Aug. 15 issue of People magazine, discloses a sometimes unflattering portrait of both Lennon and his second wife, Yoko Ono.</content>
      <tokens>
        <token id="1" string="An" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="excerpt" lemma="excerpt" stem="excerpt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Lives" lemma="life" stem="live" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="12" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="13" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="journalist" lemma="journalist" stem="journalist" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="biographer" lemma="biographer" stem="biograph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="Albert" lemma="Albert" stem="albert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="appearing" lemma="appear" stem="appear" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Aug." lemma="Aug." stem="aug." pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="issue" lemma="issue" stem="issu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="People" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="magazine" lemma="magazine" stem="magazin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="discloses" lemma="disclose" stem="disclos" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="sometimes" lemma="sometimes" stem="sometim" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="unflattering" lemma="unflattering" stem="unflatt" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="portrait" lemma="portrait" stem="portrait" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="36" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="both" lemma="both" stem="both" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="39" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="41" string="second" lemma="second" stem="second" pos="JJ" type="Word" isStopWord="false" ner="ORDINAL" is_referenced="false" is_refers="false" />
        <token id="42" string="wife" lemma="wife" stem="wife" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="43" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="45" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="46" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT An) (NN excerpt)) (PP (IN from) (NP (NP (DT the) (NN book)) (, ,) (`` ``) (NP (NP (DT The) (NNS Lives)) (PP (IN of) (NP (NNP John) (NNP Lennon)))) ('' '')))) (PP (IN by) (NP (NN journalist) (CC and) (NN biographer))) (NP (NP (NNP Albert) (NNP Goldman)) (, ,) (VP (VBG appearing) (PP (IN in) (NP (NP (DT the) (NNP Aug.) (CD 15) (NN issue)) (PP (IN of) (NP (NNS People) (NN magazine)))))) (, ,)) (VP (VBZ discloses) (NP (NP (NP (DT a) (RB sometimes) (JJ unflattering) (NN portrait)) (PP (IN of) (NP (CC both) (NP (NNP Lennon)) (CC and) (NP (PRP$ his) (JJ second) (NN wife))))) (, ,) (NP (NNP Yoko) (NNP Ono)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="An excerpt from the book , `` The Lives of John Lennon ''" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="excerpt" />
            <token id="3" string="from" />
            <token id="4" string="the" />
            <token id="5" string="book" />
            <token id="6" string="," />
            <token id="7" string="``" />
            <token id="8" string="The" />
            <token id="9" string="Lives" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
            <token id="13" string="''" />
          </tokens>
        </chunking>
        <chunking id="2" string="a sometimes unflattering portrait of both Lennon and his second wife" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="sometimes" />
            <token id="34" string="unflattering" />
            <token id="35" string="portrait" />
            <token id="36" string="of" />
            <token id="37" string="both" />
            <token id="38" string="Lennon" />
            <token id="39" string="and" />
            <token id="40" string="his" />
            <token id="41" string="second" />
            <token id="42" string="wife" />
          </tokens>
        </chunking>
        <chunking id="3" string="appearing in the Aug. 15 issue of People magazine" type="VP">
          <tokens>
            <token id="21" string="appearing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="Aug." />
            <token id="25" string="15" />
            <token id="26" string="issue" />
            <token id="27" string="of" />
            <token id="28" string="People" />
            <token id="29" string="magazine" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lennon" type="NP">
          <tokens>
            <token id="38" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="5" string="The Lives" type="NP">
          <tokens>
            <token id="8" string="The" />
            <token id="9" string="Lives" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Aug. 15 issue" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="Aug." />
            <token id="25" string="15" />
            <token id="26" string="issue" />
          </tokens>
        </chunking>
        <chunking id="7" string="People magazine" type="NP">
          <tokens>
            <token id="28" string="People" />
            <token id="29" string="magazine" />
          </tokens>
        </chunking>
        <chunking id="8" string="his second wife" type="NP">
          <tokens>
            <token id="40" string="his" />
            <token id="41" string="second" />
            <token id="42" string="wife" />
          </tokens>
        </chunking>
        <chunking id="9" string="both Lennon and his second wife" type="NP">
          <tokens>
            <token id="37" string="both" />
            <token id="38" string="Lennon" />
            <token id="39" string="and" />
            <token id="40" string="his" />
            <token id="41" string="second" />
            <token id="42" string="wife" />
          </tokens>
        </chunking>
        <chunking id="10" string="the book" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="book" />
          </tokens>
        </chunking>
        <chunking id="11" string="John Lennon" type="NP">
          <tokens>
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="12" string="the book , `` The Lives of John Lennon ''" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="book" />
            <token id="6" string="," />
            <token id="7" string="``" />
            <token id="8" string="The" />
            <token id="9" string="Lives" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
            <token id="13" string="''" />
          </tokens>
        </chunking>
        <chunking id="13" string="The Lives of John Lennon" type="NP">
          <tokens>
            <token id="8" string="The" />
            <token id="9" string="Lives" />
            <token id="10" string="of" />
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="14" string="the Aug. 15 issue of People magazine" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="Aug." />
            <token id="25" string="15" />
            <token id="26" string="issue" />
            <token id="27" string="of" />
            <token id="28" string="People" />
            <token id="29" string="magazine" />
          </tokens>
        </chunking>
        <chunking id="15" string="a sometimes unflattering portrait" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="sometimes" />
            <token id="34" string="unflattering" />
            <token id="35" string="portrait" />
          </tokens>
        </chunking>
        <chunking id="16" string="Yoko Ono" type="NP">
          <tokens>
            <token id="44" string="Yoko" />
            <token id="45" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="17" string="a sometimes unflattering portrait of both Lennon and his second wife , Yoko Ono" type="NP">
          <tokens>
            <token id="32" string="a" />
            <token id="33" string="sometimes" />
            <token id="34" string="unflattering" />
            <token id="35" string="portrait" />
            <token id="36" string="of" />
            <token id="37" string="both" />
            <token id="38" string="Lennon" />
            <token id="39" string="and" />
            <token id="40" string="his" />
            <token id="41" string="second" />
            <token id="42" string="wife" />
            <token id="43" string="," />
            <token id="44" string="Yoko" />
            <token id="45" string="Ono" />
          </tokens>
        </chunking>
        <chunking id="18" string="journalist and biographer" type="NP">
          <tokens>
            <token id="15" string="journalist" />
            <token id="16" string="and" />
            <token id="17" string="biographer" />
          </tokens>
        </chunking>
        <chunking id="19" string="An excerpt" type="NP">
          <tokens>
            <token id="1" string="An" />
            <token id="2" string="excerpt" />
          </tokens>
        </chunking>
        <chunking id="20" string="Albert Goldman" type="NP">
          <tokens>
            <token id="18" string="Albert" />
            <token id="19" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="21" string="Albert Goldman , appearing in the Aug. 15 issue of People magazine ," type="NP">
          <tokens>
            <token id="18" string="Albert" />
            <token id="19" string="Goldman" />
            <token id="20" string="," />
            <token id="21" string="appearing" />
            <token id="22" string="in" />
            <token id="23" string="the" />
            <token id="24" string="Aug." />
            <token id="25" string="15" />
            <token id="26" string="issue" />
            <token id="27" string="of" />
            <token id="28" string="People" />
            <token id="29" string="magazine" />
            <token id="30" string="," />
          </tokens>
        </chunking>
        <chunking id="22" string="discloses a sometimes unflattering portrait of both Lennon and his second wife , Yoko Ono" type="VP">
          <tokens>
            <token id="31" string="discloses" />
            <token id="32" string="a" />
            <token id="33" string="sometimes" />
            <token id="34" string="unflattering" />
            <token id="35" string="portrait" />
            <token id="36" string="of" />
            <token id="37" string="both" />
            <token id="38" string="Lennon" />
            <token id="39" string="and" />
            <token id="40" string="his" />
            <token id="41" string="second" />
            <token id="42" string="wife" />
            <token id="43" string="," />
            <token id="44" string="Yoko" />
            <token id="45" string="Ono" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">excerpt</governor>
          <dependent id="1">An</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">discloses</governor>
          <dependent id="2">excerpt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">book</governor>
          <dependent id="3">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">book</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">excerpt</governor>
          <dependent id="5">book</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">Lives</governor>
          <dependent id="8">The</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">book</governor>
          <dependent id="9">Lives</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">Lennon</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Lennon</governor>
          <dependent id="11">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">Lives</governor>
          <dependent id="12">Lennon</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">journalist</governor>
          <dependent id="14">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">discloses</governor>
          <dependent id="15">journalist</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">journalist</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">journalist</governor>
          <dependent id="17">biographer</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">Goldman</governor>
          <dependent id="18">Albert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">discloses</governor>
          <dependent id="19">Goldman</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="19">Goldman</governor>
          <dependent id="21">appearing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">issue</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">issue</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="26">issue</governor>
          <dependent id="24">Aug.</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="26">issue</governor>
          <dependent id="25">15</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">appearing</governor>
          <dependent id="26">issue</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">magazine</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">magazine</governor>
          <dependent id="28">People</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">issue</governor>
          <dependent id="29">magazine</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="31">discloses</dependent>
        </dependency>
        <dependency type="det">
          <governor id="35">portrait</governor>
          <dependent id="32">a</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="35">portrait</governor>
          <dependent id="33">sometimes</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="35">portrait</governor>
          <dependent id="34">unflattering</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">discloses</governor>
          <dependent id="35">portrait</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">Lennon</governor>
          <dependent id="36">of</dependent>
        </dependency>
        <dependency type="cc:preconj">
          <governor id="38">Lennon</governor>
          <dependent id="37">both</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">portrait</governor>
          <dependent id="38">Lennon</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="38">Lennon</governor>
          <dependent id="39">and</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="42">wife</governor>
          <dependent id="40">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="42">wife</governor>
          <dependent id="41">second</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="38">Lennon</governor>
          <dependent id="42">wife</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="45">Ono</governor>
          <dependent id="44">Yoko</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="35">portrait</governor>
          <dependent id="45">Ono</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="John" />
            <token id="12" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="Aug. 15" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="Aug." />
            <token id="25" string="15" />
          </tokens>
        </entity>
        <entity id="3" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="38" string="Lennon" />
          </tokens>
        </entity>
        <entity id="4" string="Yoko Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="44" string="Yoko" />
            <token id="45" string="Ono" />
          </tokens>
        </entity>
        <entity id="5" string="second" type="ORDINAL" score="0.0">
          <tokens>
            <token id="41" string="second" />
          </tokens>
        </entity>
        <entity id="6" string="Albert Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Albert" />
            <token id="19" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="false">
      <content>The book is scheduled to be published later this month by William Morrow &amp;amp;amp; Co.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="scheduled" lemma="schedule" stem="schedul" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="published" lemma="publish" stem="publish" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="later" lemma="later" stem="later" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="9" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="10" string="month" lemma="month" stem="month" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="11" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="Morrow" lemma="Morrow" stem="morrow" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="&amp;amp;" lemma="&amp;" stem="&amp;amp;" pos="CC" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="15" string="Co" lemma="Co." stem="co" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN book)) (VP (VBZ is) (VP (VBN scheduled) (S (VP (TO to) (VP (VB be) (VP (VBN published) (NP-TMP (RB later) (DT this) (NN month)) (PP (IN by) (NP (NNP William) (NNP Morrow) (CC &amp;) (NNP Co.))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="William Morrow &amp; Co." type="NP">
          <tokens>
            <token id="12" string="William" />
            <token id="13" string="Morrow" />
            <token id="14" string="&amp;amp;" />
            <token id="15" string="Co" />
          </tokens>
        </chunking>
        <chunking id="2" string="to be published later this month by William Morrow &amp; Co." type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="published" />
            <token id="8" string="later" />
            <token id="9" string="this" />
            <token id="10" string="month" />
            <token id="11" string="by" />
            <token id="12" string="William" />
            <token id="13" string="Morrow" />
            <token id="14" string="&amp;amp;" />
            <token id="15" string="Co" />
          </tokens>
        </chunking>
        <chunking id="3" string="The book" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="book" />
          </tokens>
        </chunking>
        <chunking id="4" string="is scheduled to be published later this month by William Morrow &amp; Co." type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="scheduled" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="published" />
            <token id="8" string="later" />
            <token id="9" string="this" />
            <token id="10" string="month" />
            <token id="11" string="by" />
            <token id="12" string="William" />
            <token id="13" string="Morrow" />
            <token id="14" string="&amp;amp;" />
            <token id="15" string="Co" />
          </tokens>
        </chunking>
        <chunking id="5" string="be published later this month by William Morrow &amp; Co." type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="published" />
            <token id="8" string="later" />
            <token id="9" string="this" />
            <token id="10" string="month" />
            <token id="11" string="by" />
            <token id="12" string="William" />
            <token id="13" string="Morrow" />
            <token id="14" string="&amp;amp;" />
            <token id="15" string="Co" />
          </tokens>
        </chunking>
        <chunking id="6" string="scheduled to be published later this month by William Morrow &amp; Co." type="VP">
          <tokens>
            <token id="4" string="scheduled" />
            <token id="5" string="to" />
            <token id="6" string="be" />
            <token id="7" string="published" />
            <token id="8" string="later" />
            <token id="9" string="this" />
            <token id="10" string="month" />
            <token id="11" string="by" />
            <token id="12" string="William" />
            <token id="13" string="Morrow" />
            <token id="14" string="&amp;amp;" />
            <token id="15" string="Co" />
          </tokens>
        </chunking>
        <chunking id="7" string="published later this month by William Morrow &amp; Co." type="VP">
          <tokens>
            <token id="7" string="published" />
            <token id="8" string="later" />
            <token id="9" string="this" />
            <token id="10" string="month" />
            <token id="11" string="by" />
            <token id="12" string="William" />
            <token id="13" string="Morrow" />
            <token id="14" string="&amp;amp;" />
            <token id="15" string="Co" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">book</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="4">scheduled</governor>
          <dependent id="2">book</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="4">scheduled</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">scheduled</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="7">published</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">published</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">scheduled</governor>
          <dependent id="7">published</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">month</governor>
          <dependent id="8">later</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">month</governor>
          <dependent id="9">this</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="7">published</governor>
          <dependent id="10">month</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Morrow</governor>
          <dependent id="11">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="13">Morrow</governor>
          <dependent id="12">William</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">published</governor>
          <dependent id="13">Morrow</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">Morrow</governor>
          <dependent id="14">&amp;</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">Morrow</governor>
          <dependent id="15">Co.</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="William Morrow &amp;amp; Co" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="William" />
            <token id="13" string="Morrow" />
            <token id="14" string="&amp;amp;" />
            <token id="15" string="Co" />
          </tokens>
        </entity>
        <entity id="2" string="later this month" type="DATE" score="0.0">
          <tokens>
            <token id="8" string="later" />
            <token id="9" string="this" />
            <token id="10" string="month" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="false">
      <content>Inc.</content>
      <tokens>
        <token id="1" string="Inc" lemma="Inc." stem="inc" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (NP (NNP Inc.)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Inc." type="NP">
          <tokens>
            <token id="1" string="Inc" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="1">Inc.</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>Between 1976 and 1979, Goldman writes, Lennon ``could not be more remote.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="1976" lemma="1976" stem="1976" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="1979" lemma="1979" stem="1979" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="writes" lemma="write" stem="write" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="remote" lemma="remote" stem="remot" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN Between) (NP (CD 1976) (CC and) (CD 1979))) (PRN (, ,) (NP (NNP Goldman)) (VP (VBZ writes)) (, ,)) (NP (NNP Lennon)) (`` ``) (VP (MD could) (RB not) (VP (VB be) (ADJP (RBR more) (JJ remote)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Lennon" type="NP">
          <tokens>
            <token id="9" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="2" string="1976 and 1979" type="NP">
          <tokens>
            <token id="2" string="1976" />
            <token id="3" string="and" />
            <token id="4" string="1979" />
          </tokens>
        </chunking>
        <chunking id="3" string="could not be more remote" type="VP">
          <tokens>
            <token id="11" string="could" />
            <token id="12" string="not" />
            <token id="13" string="be" />
            <token id="14" string="more" />
            <token id="15" string="remote" />
          </tokens>
        </chunking>
        <chunking id="4" string="more remote" type="ADJP">
          <tokens>
            <token id="14" string="more" />
            <token id="15" string="remote" />
          </tokens>
        </chunking>
        <chunking id="5" string="writes" type="VP">
          <tokens>
            <token id="7" string="writes" />
          </tokens>
        </chunking>
        <chunking id="6" string="be more remote" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="more" />
            <token id="15" string="remote" />
          </tokens>
        </chunking>
        <chunking id="7" string="Goldman" type="NP">
          <tokens>
            <token id="6" string="Goldman" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">1976</governor>
          <dependent id="1">Between</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">remote</governor>
          <dependent id="2">1976</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">1976</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">1976</governor>
          <dependent id="4">1979</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">writes</governor>
          <dependent id="6">Goldman</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="15">remote</governor>
          <dependent id="7">writes</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">remote</governor>
          <dependent id="9">Lennon</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="15">remote</governor>
          <dependent id="11">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="15">remote</governor>
          <dependent id="12">not</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="15">remote</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">remote</governor>
          <dependent id="14">more</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">remote</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1976" type="DATE" score="0.0">
          <tokens>
            <token id="2" string="1976" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Goldman" />
          </tokens>
        </entity>
        <entity id="4" string="1979" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="1979" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Apart from a few hours in the morning and evening, including time spent with his son, Sean, ``Lennon is back here in his room, alone and silent.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="Apart" lemma="apart" stem="apart" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="hours" lemma="hour" stem="hour" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="morning" lemma="morning" stem="morn" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="evening" lemma="evening" stem="even" pos="NN" type="Word" isStopWord="false" ner="TIME" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="spent" lemma="spend" stem="spent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="17" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Sean" lemma="Sean" stem="sean" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="23" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="room" lemma="room" stem="room" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="alone" lemma="alone" stem="alon" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="silent" lemma="silent" stem="silent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (ADVP (RB Apart)) (IN from) (NP (NP (DT a) (JJ few) (NNS hours)) (PP (IN in) (NP (NP (DT the) (NN morning) (CC and) (NN evening)) (, ,) (PP (VBG including) (NP (NP (NN time)) (VP (VBD spent) (PP (IN with) (NP (NP (PRP$ his) (NN son)) (, ,) (NP (NNP Sean))))))))))) (, ,) (`` ``) (NP (NNP Lennon)) (VP (VBZ is) (ADVP (RB back) (RB here)) (PP (IN in) (NP (NP (PRP$ his) (NN room)) (, ,) (UCP (ADVP (RB alone)) (CC and) (ADJP (JJ silent)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="is back here in his room , alone and silent" type="VP">
          <tokens>
            <token id="23" string="is" />
            <token id="24" string="back" />
            <token id="25" string="here" />
            <token id="26" string="in" />
            <token id="27" string="his" />
            <token id="28" string="room" />
            <token id="29" string="," />
            <token id="30" string="alone" />
            <token id="31" string="and" />
            <token id="32" string="silent" />
          </tokens>
        </chunking>
        <chunking id="2" string="his son , Sean" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="son" />
            <token id="18" string="," />
            <token id="19" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="3" string="silent" type="ADJP">
          <tokens>
            <token id="32" string="silent" />
          </tokens>
        </chunking>
        <chunking id="4" string="a few hours in the morning and evening , including time spent with his son , Sean" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="few" />
            <token id="5" string="hours" />
            <token id="6" string="in" />
            <token id="7" string="the" />
            <token id="8" string="morning" />
            <token id="9" string="and" />
            <token id="10" string="evening" />
            <token id="11" string="," />
            <token id="12" string="including" />
            <token id="13" string="time" />
            <token id="14" string="spent" />
            <token id="15" string="with" />
            <token id="16" string="his" />
            <token id="17" string="son" />
            <token id="18" string="," />
            <token id="19" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lennon" type="NP">
          <tokens>
            <token id="22" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="6" string="spent with his son , Sean" type="VP">
          <tokens>
            <token id="14" string="spent" />
            <token id="15" string="with" />
            <token id="16" string="his" />
            <token id="17" string="son" />
            <token id="18" string="," />
            <token id="19" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="7" string="his room , alone and silent" type="NP">
          <tokens>
            <token id="27" string="his" />
            <token id="28" string="room" />
            <token id="29" string="," />
            <token id="30" string="alone" />
            <token id="31" string="and" />
            <token id="32" string="silent" />
          </tokens>
        </chunking>
        <chunking id="8" string="the morning and evening" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="morning" />
            <token id="9" string="and" />
            <token id="10" string="evening" />
          </tokens>
        </chunking>
        <chunking id="9" string="his room" type="NP">
          <tokens>
            <token id="27" string="his" />
            <token id="28" string="room" />
          </tokens>
        </chunking>
        <chunking id="10" string="a few hours" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="few" />
            <token id="5" string="hours" />
          </tokens>
        </chunking>
        <chunking id="11" string="the morning and evening , including time spent with his son , Sean" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="morning" />
            <token id="9" string="and" />
            <token id="10" string="evening" />
            <token id="11" string="," />
            <token id="12" string="including" />
            <token id="13" string="time" />
            <token id="14" string="spent" />
            <token id="15" string="with" />
            <token id="16" string="his" />
            <token id="17" string="son" />
            <token id="18" string="," />
            <token id="19" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="12" string="Sean" type="NP">
          <tokens>
            <token id="19" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="13" string="time spent with his son , Sean" type="NP">
          <tokens>
            <token id="13" string="time" />
            <token id="14" string="spent" />
            <token id="15" string="with" />
            <token id="16" string="his" />
            <token id="17" string="son" />
            <token id="18" string="," />
            <token id="19" string="Sean" />
          </tokens>
        </chunking>
        <chunking id="14" string="time" type="NP">
          <tokens>
            <token id="13" string="time" />
          </tokens>
        </chunking>
        <chunking id="15" string="his son" type="NP">
          <tokens>
            <token id="16" string="his" />
            <token id="17" string="son" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="5">hours</governor>
          <dependent id="1">Apart</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">Apart</governor>
          <dependent id="2">from</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">hours</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">hours</governor>
          <dependent id="4">few</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">room</governor>
          <dependent id="5">hours</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">morning</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">morning</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">hours</governor>
          <dependent id="8">morning</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">morning</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">morning</governor>
          <dependent id="10">evening</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">time</governor>
          <dependent id="12">including</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">morning</governor>
          <dependent id="13">time</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">time</governor>
          <dependent id="14">spent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">son</governor>
          <dependent id="15">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="17">son</governor>
          <dependent id="16">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">spent</governor>
          <dependent id="17">son</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="17">son</governor>
          <dependent id="19">Sean</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">room</governor>
          <dependent id="22">Lennon</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">room</governor>
          <dependent id="23">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">here</governor>
          <dependent id="24">back</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">room</governor>
          <dependent id="25">here</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">room</governor>
          <dependent id="26">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">room</governor>
          <dependent id="27">his</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">room</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">room</governor>
          <dependent id="30">alone</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">alone</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">alone</governor>
          <dependent id="32">silent</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="evening" type="TIME" score="0.0">
          <tokens>
            <token id="10" string="evening" />
          </tokens>
        </entity>
        <entity id="2" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="22" string="Lennon" />
          </tokens>
        </entity>
        <entity id="3" string="a few hours" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="few" />
            <token id="5" string="hours" />
          </tokens>
        </entity>
        <entity id="4" string="morning" type="TIME" score="0.0">
          <tokens>
            <token id="8" string="morning" />
          </tokens>
        </entity>
        <entity id="5" string="Sean" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Sean" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>The author says the idolized Beatle spent most of his adult life as an anorexic, starving himself to what he perceived as perfection.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="author" lemma="author" stem="author" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="says" lemma="say" stem="sai" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="idolized" lemma="idolize" stem="idol" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Beatle" lemma="Beatle" stem="beatl" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="7" string="spent" lemma="spend" stem="spent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="most" lemma="most" stem="most" pos="JJS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="adult" lemma="adult" stem="adult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="life" lemma="life" stem="life" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="anorexic" lemma="anorexic" stem="anorex" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="starving" lemma="starve" stem="starv" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="perceived" lemma="perceive" stem="perceiv" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="perfection" lemma="perfection" stem="perfect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN author)) (VP (VBZ says) (NP (NP (DT the)) (VP (VBN idolized) (SBAR (S (NP (NNP Beatle)) (VP (VBD spent) (NP (NP (JJS most)) (PP (IN of) (NP (PRP$ his) (JJ adult) (NN life)))) (PP (IN as) (NP (DT an) (JJ anorexic))) (, ,) (S (VP (VBG starving) (NP (PRP himself)) (PP (TO to) (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (VBD perceived) (PP (IN as) (NP (NN perfection))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The author" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="author" />
          </tokens>
        </chunking>
        <chunking id="2" string="an anorexic" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="anorexic" />
          </tokens>
        </chunking>
        <chunking id="3" string="most of his adult life" type="NP">
          <tokens>
            <token id="8" string="most" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="adult" />
            <token id="12" string="life" />
          </tokens>
        </chunking>
        <chunking id="4" string="the" type="NP">
          <tokens>
            <token id="4" string="the" />
          </tokens>
        </chunking>
        <chunking id="5" string="most" type="NP">
          <tokens>
            <token id="8" string="most" />
          </tokens>
        </chunking>
        <chunking id="6" string="Beatle spent most of his adult life as an anorexic , starving himself to what he perceived as perfection" type="SBAR">
          <tokens>
            <token id="6" string="Beatle" />
            <token id="7" string="spent" />
            <token id="8" string="most" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="adult" />
            <token id="12" string="life" />
            <token id="13" string="as" />
            <token id="14" string="an" />
            <token id="15" string="anorexic" />
            <token id="16" string="," />
            <token id="17" string="starving" />
            <token id="18" string="himself" />
            <token id="19" string="to" />
            <token id="20" string="what" />
            <token id="21" string="he" />
            <token id="22" string="perceived" />
            <token id="23" string="as" />
            <token id="24" string="perfection" />
          </tokens>
        </chunking>
        <chunking id="7" string="Beatle" type="NP">
          <tokens>
            <token id="6" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="8" string="his adult life" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="adult" />
            <token id="12" string="life" />
          </tokens>
        </chunking>
        <chunking id="9" string="starving himself to what he perceived as perfection" type="VP">
          <tokens>
            <token id="17" string="starving" />
            <token id="18" string="himself" />
            <token id="19" string="to" />
            <token id="20" string="what" />
            <token id="21" string="he" />
            <token id="22" string="perceived" />
            <token id="23" string="as" />
            <token id="24" string="perfection" />
          </tokens>
        </chunking>
        <chunking id="10" string="idolized Beatle spent most of his adult life as an anorexic , starving himself to what he perceived as perfection" type="VP">
          <tokens>
            <token id="5" string="idolized" />
            <token id="6" string="Beatle" />
            <token id="7" string="spent" />
            <token id="8" string="most" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="adult" />
            <token id="12" string="life" />
            <token id="13" string="as" />
            <token id="14" string="an" />
            <token id="15" string="anorexic" />
            <token id="16" string="," />
            <token id="17" string="starving" />
            <token id="18" string="himself" />
            <token id="19" string="to" />
            <token id="20" string="what" />
            <token id="21" string="he" />
            <token id="22" string="perceived" />
            <token id="23" string="as" />
            <token id="24" string="perfection" />
          </tokens>
        </chunking>
        <chunking id="11" string="says the idolized Beatle spent most of his adult life as an anorexic , starving himself to what he perceived as perfection" type="VP">
          <tokens>
            <token id="3" string="says" />
            <token id="4" string="the" />
            <token id="5" string="idolized" />
            <token id="6" string="Beatle" />
            <token id="7" string="spent" />
            <token id="8" string="most" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="adult" />
            <token id="12" string="life" />
            <token id="13" string="as" />
            <token id="14" string="an" />
            <token id="15" string="anorexic" />
            <token id="16" string="," />
            <token id="17" string="starving" />
            <token id="18" string="himself" />
            <token id="19" string="to" />
            <token id="20" string="what" />
            <token id="21" string="he" />
            <token id="22" string="perceived" />
            <token id="23" string="as" />
            <token id="24" string="perfection" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="21" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="himself" type="NP">
          <tokens>
            <token id="18" string="himself" />
          </tokens>
        </chunking>
        <chunking id="14" string="what he perceived as perfection" type="SBAR">
          <tokens>
            <token id="20" string="what" />
            <token id="21" string="he" />
            <token id="22" string="perceived" />
            <token id="23" string="as" />
            <token id="24" string="perfection" />
          </tokens>
        </chunking>
        <chunking id="15" string="the idolized Beatle spent most of his adult life as an anorexic , starving himself to what he perceived as perfection" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="idolized" />
            <token id="6" string="Beatle" />
            <token id="7" string="spent" />
            <token id="8" string="most" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="adult" />
            <token id="12" string="life" />
            <token id="13" string="as" />
            <token id="14" string="an" />
            <token id="15" string="anorexic" />
            <token id="16" string="," />
            <token id="17" string="starving" />
            <token id="18" string="himself" />
            <token id="19" string="to" />
            <token id="20" string="what" />
            <token id="21" string="he" />
            <token id="22" string="perceived" />
            <token id="23" string="as" />
            <token id="24" string="perfection" />
          </tokens>
        </chunking>
        <chunking id="16" string="perceived as perfection" type="VP">
          <tokens>
            <token id="22" string="perceived" />
            <token id="23" string="as" />
            <token id="24" string="perfection" />
          </tokens>
        </chunking>
        <chunking id="17" string="spent most of his adult life as an anorexic , starving himself to what he perceived as perfection" type="VP">
          <tokens>
            <token id="7" string="spent" />
            <token id="8" string="most" />
            <token id="9" string="of" />
            <token id="10" string="his" />
            <token id="11" string="adult" />
            <token id="12" string="life" />
            <token id="13" string="as" />
            <token id="14" string="an" />
            <token id="15" string="anorexic" />
            <token id="16" string="," />
            <token id="17" string="starving" />
            <token id="18" string="himself" />
            <token id="19" string="to" />
            <token id="20" string="what" />
            <token id="21" string="he" />
            <token id="22" string="perceived" />
            <token id="23" string="as" />
            <token id="24" string="perfection" />
          </tokens>
        </chunking>
        <chunking id="18" string="perfection" type="NP">
          <tokens>
            <token id="24" string="perfection" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">author</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">says</governor>
          <dependent id="2">author</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">says</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">says</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="4">the</governor>
          <dependent id="5">idolized</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">spent</governor>
          <dependent id="6">Beatle</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">idolized</governor>
          <dependent id="7">spent</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">spent</governor>
          <dependent id="8">most</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">life</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">life</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">life</governor>
          <dependent id="11">adult</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">most</governor>
          <dependent id="12">life</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">anorexic</governor>
          <dependent id="13">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">anorexic</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">spent</governor>
          <dependent id="15">anorexic</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">spent</governor>
          <dependent id="17">starving</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">starving</governor>
          <dependent id="18">himself</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">perceived</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="22">perceived</governor>
          <dependent id="20">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">perceived</governor>
          <dependent id="21">he</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">starving</governor>
          <dependent id="22">perceived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">perfection</governor>
          <dependent id="23">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">perceived</governor>
          <dependent id="24">perfection</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Beatle" type="MISC" score="0.0">
          <tokens>
            <token id="6" string="Beatle" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>The onset of the eating disorder can be traced to 1965, Goldman writes, ``when some fool described him in print as the `fat Beatle.&amp;apost; &amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="onset" lemma="onset" stem="onset" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="eating" lemma="eating" stem="eat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="disorder" lemma="disorder" stem="disord" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="traced" lemma="trace" stem="trace" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="1965" lemma="1965" stem="1965" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="14" string="writes" lemma="write" stem="write" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="fool" lemma="fool" stem="fool" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="described" lemma="describe" stem="describ" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="print" lemma="print" stem="print" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="fat" lemma="fat" stem="fat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="Beatle" lemma="beatle" stem="beatl" pos="NN" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (DT The) (NN onset)) (PP (IN of) (NP (DT the) (JJ eating) (NN disorder)))) (VP (MD can) (VP (VB be) (VP (VBN traced) (PP (TO to) (NP (CD 1965))))))) (, ,) (NP (NNP Goldman)) (VP (VBZ writes) (, ,) (`` ``) (SBARQ (WHADVP (WRB when)) (S (NP (DT some) (NN fool)) (VP (VBD described) (NP (PRP him)) (PP (IN in) (NP (NN print))) (PP (IN as) (NP (DT the) (`` `) (JJ fat) (NN Beatle))))))) (. .) ('' ') ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="traced to 1965" type="VP">
          <tokens>
            <token id="9" string="traced" />
            <token id="10" string="to" />
            <token id="11" string="1965" />
          </tokens>
        </chunking>
        <chunking id="2" string="can be traced to 1965" type="VP">
          <tokens>
            <token id="7" string="can" />
            <token id="8" string="be" />
            <token id="9" string="traced" />
            <token id="10" string="to" />
            <token id="11" string="1965" />
          </tokens>
        </chunking>
        <chunking id="3" string="some fool" type="NP">
          <tokens>
            <token id="18" string="some" />
            <token id="19" string="fool" />
          </tokens>
        </chunking>
        <chunking id="4" string="the eating disorder" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="eating" />
            <token id="6" string="disorder" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="21" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="the ` fat Beatle" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="`" />
            <token id="27" string="fat" />
            <token id="28" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="7" string="be traced to 1965" type="VP">
          <tokens>
            <token id="8" string="be" />
            <token id="9" string="traced" />
            <token id="10" string="to" />
            <token id="11" string="1965" />
          </tokens>
        </chunking>
        <chunking id="8" string="when" type="WHADVP">
          <tokens>
            <token id="17" string="when" />
          </tokens>
        </chunking>
        <chunking id="9" string="The onset of the eating disorder" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="onset" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="eating" />
            <token id="6" string="disorder" />
          </tokens>
        </chunking>
        <chunking id="10" string="1965" type="NP">
          <tokens>
            <token id="11" string="1965" />
          </tokens>
        </chunking>
        <chunking id="11" string="print" type="NP">
          <tokens>
            <token id="23" string="print" />
          </tokens>
        </chunking>
        <chunking id="12" string="The onset" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="onset" />
          </tokens>
        </chunking>
        <chunking id="13" string="Goldman" type="NP">
          <tokens>
            <token id="13" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="14" string="writes , `` when some fool described him in print as the ` fat Beatle" type="VP">
          <tokens>
            <token id="14" string="writes" />
            <token id="15" string="," />
            <token id="16" string="``" />
            <token id="17" string="when" />
            <token id="18" string="some" />
            <token id="19" string="fool" />
            <token id="20" string="described" />
            <token id="21" string="him" />
            <token id="22" string="in" />
            <token id="23" string="print" />
            <token id="24" string="as" />
            <token id="25" string="the" />
            <token id="26" string="`" />
            <token id="27" string="fat" />
            <token id="28" string="Beatle" />
          </tokens>
        </chunking>
        <chunking id="15" string="described him in print as the ` fat Beatle" type="VP">
          <tokens>
            <token id="20" string="described" />
            <token id="21" string="him" />
            <token id="22" string="in" />
            <token id="23" string="print" />
            <token id="24" string="as" />
            <token id="25" string="the" />
            <token id="26" string="`" />
            <token id="27" string="fat" />
            <token id="28" string="Beatle" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">onset</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="9">traced</governor>
          <dependent id="2">onset</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">disorder</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">disorder</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">disorder</governor>
          <dependent id="5">eating</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">onset</governor>
          <dependent id="6">disorder</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="9">traced</governor>
          <dependent id="7">can</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="9">traced</governor>
          <dependent id="8">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">writes</governor>
          <dependent id="9">traced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">1965</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">traced</governor>
          <dependent id="11">1965</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">writes</governor>
          <dependent id="13">Goldman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">writes</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">described</governor>
          <dependent id="17">when</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">fool</governor>
          <dependent id="18">some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">described</governor>
          <dependent id="19">fool</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">writes</governor>
          <dependent id="20">described</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="20">described</governor>
          <dependent id="21">him</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">print</governor>
          <dependent id="22">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">described</governor>
          <dependent id="23">print</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">Beatle</governor>
          <dependent id="24">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">Beatle</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">Beatle</governor>
          <dependent id="27">fat</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">described</governor>
          <dependent id="28">Beatle</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1965" type="DATE" score="0.0">
          <tokens>
            <token id="11" string="1965" />
          </tokens>
        </entity>
        <entity id="2" string="Beatle" type="MISC" score="0.0">
          <tokens>
            <token id="28" string="Beatle" />
          </tokens>
        </entity>
        <entity id="3" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Goldman" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>``That phrase struck such a blow to his fragile ego that the wound has never healed.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="That" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="phrase" lemma="phrase" stem="phrase" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="struck" lemma="strike" stem="struck" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="such" lemma="such" stem="such" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="blow" lemma="blow" stem="blow" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="fragile" lemma="fragile" stem="fragil" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="ego" lemma="ego" stem="ego" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="wound" lemma="wound" stem="wound" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="healed" lemma="heal" stem="heal" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (DT That) (NN phrase)) (VP (VBD struck) (NP (PDT such) (DT a) (NN blow)) (PP (TO to) (NP (PRP$ his) (JJ fragile) (NN ego))) (SBAR (IN that) (S (NP (DT the) (NN wound)) (VP (VBZ has) (ADVP (RB never)) (VP (VBN healed)))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="his fragile ego" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="fragile" />
            <token id="11" string="ego" />
          </tokens>
        </chunking>
        <chunking id="2" string="has never healed" type="VP">
          <tokens>
            <token id="15" string="has" />
            <token id="16" string="never" />
            <token id="17" string="healed" />
          </tokens>
        </chunking>
        <chunking id="3" string="healed" type="VP">
          <tokens>
            <token id="17" string="healed" />
          </tokens>
        </chunking>
        <chunking id="4" string="such a blow" type="NP">
          <tokens>
            <token id="5" string="such" />
            <token id="6" string="a" />
            <token id="7" string="blow" />
          </tokens>
        </chunking>
        <chunking id="5" string="that the wound has never healed" type="SBAR">
          <tokens>
            <token id="12" string="that" />
            <token id="13" string="the" />
            <token id="14" string="wound" />
            <token id="15" string="has" />
            <token id="16" string="never" />
            <token id="17" string="healed" />
          </tokens>
        </chunking>
        <chunking id="6" string="That phrase" type="NP">
          <tokens>
            <token id="2" string="That" />
            <token id="3" string="phrase" />
          </tokens>
        </chunking>
        <chunking id="7" string="the wound" type="NP">
          <tokens>
            <token id="13" string="the" />
            <token id="14" string="wound" />
          </tokens>
        </chunking>
        <chunking id="8" string="struck such a blow to his fragile ego that the wound has never healed" type="VP">
          <tokens>
            <token id="4" string="struck" />
            <token id="5" string="such" />
            <token id="6" string="a" />
            <token id="7" string="blow" />
            <token id="8" string="to" />
            <token id="9" string="his" />
            <token id="10" string="fragile" />
            <token id="11" string="ego" />
            <token id="12" string="that" />
            <token id="13" string="the" />
            <token id="14" string="wound" />
            <token id="15" string="has" />
            <token id="16" string="never" />
            <token id="17" string="healed" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">phrase</governor>
          <dependent id="2">That</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">struck</governor>
          <dependent id="3">phrase</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">struck</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="7">blow</governor>
          <dependent id="5">such</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">blow</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">struck</governor>
          <dependent id="7">blow</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">ego</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">ego</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">ego</governor>
          <dependent id="10">fragile</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">struck</governor>
          <dependent id="11">ego</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">healed</governor>
          <dependent id="12">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">wound</governor>
          <dependent id="13">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">healed</governor>
          <dependent id="14">wound</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">healed</governor>
          <dependent id="15">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="17">healed</governor>
          <dependent id="16">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">struck</governor>
          <dependent id="17">healed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Lennon rarely wore clothing, other than a pair of backless slippers, and avoided touching anyone, according to the book.</content>
      <tokens>
        <token id="1" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="rarely" lemma="rarely" stem="rare" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="wore" lemma="wear" stem="wore" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="clothing" lemma="clothing" stem="cloth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="pair" lemma="pair" stem="pair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="backless" lemma="backless" stem="backless" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="slippers" lemma="slipper" stem="slipper" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="avoided" lemma="avoid" stem="avoid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="touching" lemma="touching" stem="touch" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="anyone" lemma="anyone" stem="anyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="according" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Lennon)) (ADVP (RB rarely)) (VP (VP (VBD wore) (NP (NP (NN clothing)) (, ,) (ADJP (JJ other) (PP (IN than) (NP (NP (DT a) (NN pair)) (PP (IN of) (NP (JJ backless) (NNS slippers)))))) (, ,))) (CC and) (VP (VBD avoided) (NP (JJ touching) (NN anyone))) (, ,) (PP (VBG according) (PP (TO to) (NP (DT the) (NN book))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="wore clothing , other than a pair of backless slippers ," type="VP">
          <tokens>
            <token id="3" string="wore" />
            <token id="4" string="clothing" />
            <token id="5" string="," />
            <token id="6" string="other" />
            <token id="7" string="than" />
            <token id="8" string="a" />
            <token id="9" string="pair" />
            <token id="10" string="of" />
            <token id="11" string="backless" />
            <token id="12" string="slippers" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="clothing , other than a pair of backless slippers ," type="NP">
          <tokens>
            <token id="4" string="clothing" />
            <token id="5" string="," />
            <token id="6" string="other" />
            <token id="7" string="than" />
            <token id="8" string="a" />
            <token id="9" string="pair" />
            <token id="10" string="of" />
            <token id="11" string="backless" />
            <token id="12" string="slippers" />
            <token id="13" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="wore clothing , other than a pair of backless slippers , and avoided touching anyone , according to the book" type="VP">
          <tokens>
            <token id="3" string="wore" />
            <token id="4" string="clothing" />
            <token id="5" string="," />
            <token id="6" string="other" />
            <token id="7" string="than" />
            <token id="8" string="a" />
            <token id="9" string="pair" />
            <token id="10" string="of" />
            <token id="11" string="backless" />
            <token id="12" string="slippers" />
            <token id="13" string="," />
            <token id="14" string="and" />
            <token id="15" string="avoided" />
            <token id="16" string="touching" />
            <token id="17" string="anyone" />
            <token id="18" string="," />
            <token id="19" string="according" />
            <token id="20" string="to" />
            <token id="21" string="the" />
            <token id="22" string="book" />
          </tokens>
        </chunking>
        <chunking id="4" string="Lennon" type="NP">
          <tokens>
            <token id="1" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="5" string="clothing" type="NP">
          <tokens>
            <token id="4" string="clothing" />
          </tokens>
        </chunking>
        <chunking id="6" string="a pair" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="pair" />
          </tokens>
        </chunking>
        <chunking id="7" string="backless slippers" type="NP">
          <tokens>
            <token id="11" string="backless" />
            <token id="12" string="slippers" />
          </tokens>
        </chunking>
        <chunking id="8" string="avoided touching anyone" type="VP">
          <tokens>
            <token id="15" string="avoided" />
            <token id="16" string="touching" />
            <token id="17" string="anyone" />
          </tokens>
        </chunking>
        <chunking id="9" string="a pair of backless slippers" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="pair" />
            <token id="10" string="of" />
            <token id="11" string="backless" />
            <token id="12" string="slippers" />
          </tokens>
        </chunking>
        <chunking id="10" string="the book" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="book" />
          </tokens>
        </chunking>
        <chunking id="11" string="other than a pair of backless slippers" type="ADJP">
          <tokens>
            <token id="6" string="other" />
            <token id="7" string="than" />
            <token id="8" string="a" />
            <token id="9" string="pair" />
            <token id="10" string="of" />
            <token id="11" string="backless" />
            <token id="12" string="slippers" />
          </tokens>
        </chunking>
        <chunking id="12" string="touching anyone" type="NP">
          <tokens>
            <token id="16" string="touching" />
            <token id="17" string="anyone" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">wore</governor>
          <dependent id="1">Lennon</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">wore</governor>
          <dependent id="2">rarely</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">wore</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">wore</governor>
          <dependent id="4">clothing</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="4">clothing</governor>
          <dependent id="6">other</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">pair</governor>
          <dependent id="7">than</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">pair</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">other</governor>
          <dependent id="9">pair</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">slippers</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">slippers</governor>
          <dependent id="11">backless</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">pair</governor>
          <dependent id="12">slippers</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="3">wore</governor>
          <dependent id="14">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">wore</governor>
          <dependent id="15">avoided</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">anyone</governor>
          <dependent id="16">touching</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">avoided</governor>
          <dependent id="17">anyone</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">book</governor>
          <dependent id="19">according</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="19">according</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">book</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">wore</governor>
          <dependent id="22">book</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>The 719-page biography also details Yoko Ono&amp;apost;s $5,000-a-week heroin habit in 1979.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="719-page" lemma="719-page" stem="719-page" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="biography" lemma="biography" stem="biographi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="details" lemma="detail" stem="detail" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="Yoko" lemma="Yoko" stem="yoko" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="Ono" lemma="Ono" stem="ono" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="10" string="5,000-a-week" lemma="5,000-a-week" stem="5,000-a-week" pos="JJ" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="11" string="heroin" lemma="heroin" stem="heroin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="habit" lemma="habit" stem="habit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="1979" lemma="1979" stem="1979" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (DT The) (JJ 719-page) (NN biography)) (RRC (ADVP (RB also)) (NP (NNS details)))) (NP (NP (NP (NNP Yoko) (NNP Ono) (POS 's)) (ADJP ($ $) (JJ 5,000-a-week)) (NN heroin) (NN habit)) (PP (IN in) (NP (CD 1979)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="The 719-page biography also details Yoko Ono 's $ 5,000-a-week heroin habit in 1979 ." type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="719-page" />
            <token id="3" string="biography" />
            <token id="4" string="also" />
            <token id="5" string="details" />
            <token id="6" string="Yoko" />
            <token id="7" string="Ono" />
            <token id="8" string="'s" />
            <token id="9" string="$" />
            <token id="10" string="5,000-a-week" />
            <token id="11" string="heroin" />
            <token id="12" string="habit" />
            <token id="13" string="in" />
            <token id="14" string="1979" />
            <token id="15" string="." />
          </tokens>
        </chunking>
        <chunking id="2" string="The 719-page biography also details" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="719-page" />
            <token id="3" string="biography" />
            <token id="4" string="also" />
            <token id="5" string="details" />
          </tokens>
        </chunking>
        <chunking id="3" string="The 719-page biography" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="719-page" />
            <token id="3" string="biography" />
          </tokens>
        </chunking>
        <chunking id="4" string="$ 5,000-a-week" type="ADJP">
          <tokens>
            <token id="9" string="$" />
            <token id="10" string="5,000-a-week" />
          </tokens>
        </chunking>
        <chunking id="5" string="details" type="NP">
          <tokens>
            <token id="5" string="details" />
          </tokens>
        </chunking>
        <chunking id="6" string="Yoko Ono 's $ 5,000-a-week heroin habit" type="NP">
          <tokens>
            <token id="6" string="Yoko" />
            <token id="7" string="Ono" />
            <token id="8" string="'s" />
            <token id="9" string="$" />
            <token id="10" string="5,000-a-week" />
            <token id="11" string="heroin" />
            <token id="12" string="habit" />
          </tokens>
        </chunking>
        <chunking id="7" string="1979" type="NP">
          <tokens>
            <token id="14" string="1979" />
          </tokens>
        </chunking>
        <chunking id="8" string="Yoko Ono 's $ 5,000-a-week heroin habit in 1979" type="NP">
          <tokens>
            <token id="6" string="Yoko" />
            <token id="7" string="Ono" />
            <token id="8" string="'s" />
            <token id="9" string="$" />
            <token id="10" string="5,000-a-week" />
            <token id="11" string="heroin" />
            <token id="12" string="habit" />
            <token id="13" string="in" />
            <token id="14" string="1979" />
          </tokens>
        </chunking>
        <chunking id="9" string="Yoko Ono 's" type="NP">
          <tokens>
            <token id="6" string="Yoko" />
            <token id="7" string="Ono" />
            <token id="8" string="'s" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">biography</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">biography</governor>
          <dependent id="2">719-page</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">biography</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">details</governor>
          <dependent id="4">also</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">biography</governor>
          <dependent id="5">details</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Ono</governor>
          <dependent id="6">Yoko</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">habit</governor>
          <dependent id="7">Ono</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Ono</governor>
          <dependent id="8">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">habit</governor>
          <dependent id="9">$</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">$</governor>
          <dependent id="10">5,000-a-week</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">habit</governor>
          <dependent id="11">heroin</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">biography</governor>
          <dependent id="12">habit</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">1979</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">habit</governor>
          <dependent id="14">1979</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="$ 5,000-a-week" type="MONEY" score="0.0">
          <tokens>
            <token id="9" string="$" />
            <token id="10" string="5,000-a-week" />
          </tokens>
        </entity>
        <entity id="2" string="Yoko Ono" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Yoko" />
            <token id="7" string="Ono" />
          </tokens>
        </entity>
        <entity id="3" string="1979" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="1979" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>She reportedly snorted the drug.</content>
      <tokens>
        <token id="1" string="She" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="reportedly" lemma="reportedly" stem="reportedli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="snorted" lemma="snort" stem="snort" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="drug" lemma="drug" stem="drug" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP She)) (ADVP (RB reportedly)) (VP (VBD snorted) (NP (DT the) (NN drug))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the drug" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="drug" />
          </tokens>
        </chunking>
        <chunking id="2" string="snorted the drug" type="VP">
          <tokens>
            <token id="3" string="snorted" />
            <token id="4" string="the" />
            <token id="5" string="drug" />
          </tokens>
        </chunking>
        <chunking id="3" string="She" type="NP">
          <tokens>
            <token id="1" string="She" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">snorted</governor>
          <dependent id="1">She</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">snorted</governor>
          <dependent id="2">reportedly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">snorted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">drug</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">snorted</governor>
          <dependent id="5">drug</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>According to the book, Lennon also took heroin and consumed a great deal of LSD.</content>
      <tokens>
        <token id="1" string="According" lemma="accord" stem="accord" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="heroin" lemma="heroin" stem="heroin" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="consumed" lemma="consume" stem="consum" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="deal" lemma="deal" stem="deal" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="LSD" lemma="LSD" stem="lsd" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (VBG According) (PP (TO to) (NP (DT the) (NN book)))) (, ,) (NP (NNP Lennon)) (VP (VP (ADVP (RB also)) (VBD took) (NP (NN heroin))) (CC and) (VP (VBN consumed) (NP (NP (DT a) (JJ great) (NN deal)) (PP (IN of) (NP (NNP LSD)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="also took heroin and consumed a great deal of LSD" type="VP">
          <tokens>
            <token id="7" string="also" />
            <token id="8" string="took" />
            <token id="9" string="heroin" />
            <token id="10" string="and" />
            <token id="11" string="consumed" />
            <token id="12" string="a" />
            <token id="13" string="great" />
            <token id="14" string="deal" />
            <token id="15" string="of" />
            <token id="16" string="LSD" />
          </tokens>
        </chunking>
        <chunking id="2" string="heroin" type="NP">
          <tokens>
            <token id="9" string="heroin" />
          </tokens>
        </chunking>
        <chunking id="3" string="Lennon" type="NP">
          <tokens>
            <token id="6" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="4" string="a great deal of LSD" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="great" />
            <token id="14" string="deal" />
            <token id="15" string="of" />
            <token id="16" string="LSD" />
          </tokens>
        </chunking>
        <chunking id="5" string="the book" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="book" />
          </tokens>
        </chunking>
        <chunking id="6" string="also took heroin" type="VP">
          <tokens>
            <token id="7" string="also" />
            <token id="8" string="took" />
            <token id="9" string="heroin" />
          </tokens>
        </chunking>
        <chunking id="7" string="LSD" type="NP">
          <tokens>
            <token id="16" string="LSD" />
          </tokens>
        </chunking>
        <chunking id="8" string="consumed a great deal of LSD" type="VP">
          <tokens>
            <token id="11" string="consumed" />
            <token id="12" string="a" />
            <token id="13" string="great" />
            <token id="14" string="deal" />
            <token id="15" string="of" />
            <token id="16" string="LSD" />
          </tokens>
        </chunking>
        <chunking id="9" string="a great deal" type="NP">
          <tokens>
            <token id="12" string="a" />
            <token id="13" string="great" />
            <token id="14" string="deal" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">book</governor>
          <dependent id="1">According</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="1">According</governor>
          <dependent id="2">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">book</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">took</governor>
          <dependent id="4">book</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">took</governor>
          <dependent id="6">Lennon</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">took</governor>
          <dependent id="7">also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">took</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">took</governor>
          <dependent id="9">heroin</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">took</governor>
          <dependent id="10">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">took</governor>
          <dependent id="11">consumed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">deal</governor>
          <dependent id="12">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">deal</governor>
          <dependent id="13">great</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">consumed</governor>
          <dependent id="14">deal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">LSD</governor>
          <dependent id="15">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">deal</governor>
          <dependent id="16">LSD</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Lennon" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>``I must have taken a thousand trips,&amp;apost;&amp;apost; the book quotes Lennon as saying.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="taken" lemma="take" stem="taken" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="thousand" lemma="thousand" stem="thousand" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string="trips" lemma="trip" stem="trip" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="quotes" lemma="quote" stem="quot" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="saying" lemma="say" stem="sai" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (VP (MD must) (VP (VB have) (VP (VBN taken) (NP (DT a) (CD thousand) (NNS trips)))))) (, ,) ('' '') (NP (DT the) (NN book)) (VP (VBZ quotes) (NP (NNP Lennon)) (PP (IN as) (S (VP (VBG saying))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="have taken a thousand trips" type="VP">
          <tokens>
            <token id="4" string="have" />
            <token id="5" string="taken" />
            <token id="6" string="a" />
            <token id="7" string="thousand" />
            <token id="8" string="trips" />
          </tokens>
        </chunking>
        <chunking id="2" string="a thousand trips" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="thousand" />
            <token id="8" string="trips" />
          </tokens>
        </chunking>
        <chunking id="3" string="Lennon" type="NP">
          <tokens>
            <token id="14" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="4" string="quotes Lennon as saying" type="VP">
          <tokens>
            <token id="13" string="quotes" />
            <token id="14" string="Lennon" />
            <token id="15" string="as" />
            <token id="16" string="saying" />
          </tokens>
        </chunking>
        <chunking id="5" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="6" string="must have taken a thousand trips" type="VP">
          <tokens>
            <token id="3" string="must" />
            <token id="4" string="have" />
            <token id="5" string="taken" />
            <token id="6" string="a" />
            <token id="7" string="thousand" />
            <token id="8" string="trips" />
          </tokens>
        </chunking>
        <chunking id="7" string="saying" type="VP">
          <tokens>
            <token id="16" string="saying" />
          </tokens>
        </chunking>
        <chunking id="8" string="the book" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="book" />
          </tokens>
        </chunking>
        <chunking id="9" string="taken a thousand trips" type="VP">
          <tokens>
            <token id="5" string="taken" />
            <token id="6" string="a" />
            <token id="7" string="thousand" />
            <token id="8" string="trips" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">taken</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">taken</governor>
          <dependent id="3">must</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">taken</governor>
          <dependent id="4">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">quotes</governor>
          <dependent id="5">taken</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">trips</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">trips</governor>
          <dependent id="7">thousand</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">taken</governor>
          <dependent id="8">trips</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">book</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">quotes</governor>
          <dependent id="12">book</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">quotes</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">quotes</governor>
          <dependent id="14">Lennon</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">saying</governor>
          <dependent id="15">as</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">quotes</governor>
          <dependent id="16">saying</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Lennon" />
          </tokens>
        </entity>
        <entity id="2" string="thousand" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="thousand" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>``I just ate it all the time like candy.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="ate" lemma="eat" stem="at" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="like" lemma="like" stem="like" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="candy" lemma="candy" stem="candi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (ADVP (RB just)) (VBD ate) (NP (PRP it)) (NP-TMP (PDT all) (DT the) (NN time)) (PP (IN like) (NP (NN candy)))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="just ate it all the time like candy" type="VP">
          <tokens>
            <token id="3" string="just" />
            <token id="4" string="ate" />
            <token id="5" string="it" />
            <token id="6" string="all" />
            <token id="7" string="the" />
            <token id="8" string="time" />
            <token id="9" string="like" />
            <token id="10" string="candy" />
          </tokens>
        </chunking>
        <chunking id="2" string="candy" type="NP">
          <tokens>
            <token id="10" string="candy" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="5" string="it" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">ate</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">ate</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">ate</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">ate</governor>
          <dependent id="5">it</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="8">time</governor>
          <dependent id="6">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">time</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="4">ate</governor>
          <dependent id="8">time</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">candy</governor>
          <dependent id="9">like</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">ate</governor>
          <dependent id="10">candy</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>Goldman spent more than six years researching the book, interviewing 1,200 friends, relatives and associates of Lennon, who was murdered eight years ago in New York.</content>
      <tokens>
        <token id="1" string="Goldman" lemma="Goldman" stem="goldman" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="spent" lemma="spend" stem="spent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="4" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="5" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="6" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="researching" lemma="research" stem="research" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="book" lemma="book" stem="book" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="interviewing" lemma="interview" stem="interview" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="1,200" lemma="1,200" stem="1,200" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="13" string="friends" lemma="friend" stem="friend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="relatives" lemma="relative" stem="rel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="associates" lemma="associate" stem="associ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Lennon" lemma="Lennon" stem="lennon" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="murdered" lemma="murder" stem="murder" pos="VBN" type="Word" isStopWord="false" ner="CAUSE_OF_DEATH" is_referenced="false" is_refers="false" />
        <token id="24" string="eight" lemma="eight" stem="eight" pos="CD" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="25" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="26" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="New" lemma="New" stem="new" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="29" string="York" lemma="York" stem="york" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Goldman)) (VP (VBD spent) (NP (NP (QP (JJR more) (IN than) (CD six)) (NNS years)) (VP (VBG researching) (NP (DT the) (NN book)))) (, ,) (S (VP (VBG interviewing) (NP (NP (CD 1,200) (NNS friends)) (, ,) (NP (NP (NNS relatives) (CC and) (NNS associates)) (PP (IN of) (NP (NNP Lennon)))) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD was) (VP (VBN murdered) (PP (ADVP (NP (CD eight) (NNS years)) (RB ago)) (IN in) (NP (NNP New) (NNP York))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="New York" type="NP">
          <tokens>
            <token id="28" string="New" />
            <token id="29" string="York" />
          </tokens>
        </chunking>
        <chunking id="2" string="more than six years" type="NP">
          <tokens>
            <token id="3" string="more" />
            <token id="4" string="than" />
            <token id="5" string="six" />
            <token id="6" string="years" />
          </tokens>
        </chunking>
        <chunking id="3" string="Lennon" type="NP">
          <tokens>
            <token id="19" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="4" string="relatives and associates" type="NP">
          <tokens>
            <token id="15" string="relatives" />
            <token id="16" string="and" />
            <token id="17" string="associates" />
          </tokens>
        </chunking>
        <chunking id="5" string="spent more than six years researching the book , interviewing 1,200 friends , relatives and associates of Lennon , who was murdered eight years ago in New York" type="VP">
          <tokens>
            <token id="2" string="spent" />
            <token id="3" string="more" />
            <token id="4" string="than" />
            <token id="5" string="six" />
            <token id="6" string="years" />
            <token id="7" string="researching" />
            <token id="8" string="the" />
            <token id="9" string="book" />
            <token id="10" string="," />
            <token id="11" string="interviewing" />
            <token id="12" string="1,200" />
            <token id="13" string="friends" />
            <token id="14" string="," />
            <token id="15" string="relatives" />
            <token id="16" string="and" />
            <token id="17" string="associates" />
            <token id="18" string="of" />
            <token id="19" string="Lennon" />
            <token id="20" string="," />
            <token id="21" string="who" />
            <token id="22" string="was" />
            <token id="23" string="murdered" />
            <token id="24" string="eight" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
            <token id="27" string="in" />
            <token id="28" string="New" />
            <token id="29" string="York" />
          </tokens>
        </chunking>
        <chunking id="6" string="relatives and associates of Lennon" type="NP">
          <tokens>
            <token id="15" string="relatives" />
            <token id="16" string="and" />
            <token id="17" string="associates" />
            <token id="18" string="of" />
            <token id="19" string="Lennon" />
          </tokens>
        </chunking>
        <chunking id="7" string="eight years" type="NP">
          <tokens>
            <token id="24" string="eight" />
            <token id="25" string="years" />
          </tokens>
        </chunking>
        <chunking id="8" string="more than six years researching the book" type="NP">
          <tokens>
            <token id="3" string="more" />
            <token id="4" string="than" />
            <token id="5" string="six" />
            <token id="6" string="years" />
            <token id="7" string="researching" />
            <token id="8" string="the" />
            <token id="9" string="book" />
          </tokens>
        </chunking>
        <chunking id="9" string="1,200 friends" type="NP">
          <tokens>
            <token id="12" string="1,200" />
            <token id="13" string="friends" />
          </tokens>
        </chunking>
        <chunking id="10" string="was murdered eight years ago in New York" type="VP">
          <tokens>
            <token id="22" string="was" />
            <token id="23" string="murdered" />
            <token id="24" string="eight" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
            <token id="27" string="in" />
            <token id="28" string="New" />
            <token id="29" string="York" />
          </tokens>
        </chunking>
        <chunking id="11" string="the book" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="book" />
          </tokens>
        </chunking>
        <chunking id="12" string="interviewing 1,200 friends , relatives and associates of Lennon , who was murdered eight years ago in New York" type="VP">
          <tokens>
            <token id="11" string="interviewing" />
            <token id="12" string="1,200" />
            <token id="13" string="friends" />
            <token id="14" string="," />
            <token id="15" string="relatives" />
            <token id="16" string="and" />
            <token id="17" string="associates" />
            <token id="18" string="of" />
            <token id="19" string="Lennon" />
            <token id="20" string="," />
            <token id="21" string="who" />
            <token id="22" string="was" />
            <token id="23" string="murdered" />
            <token id="24" string="eight" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
            <token id="27" string="in" />
            <token id="28" string="New" />
            <token id="29" string="York" />
          </tokens>
        </chunking>
        <chunking id="13" string="who was murdered eight years ago in New York" type="SBAR">
          <tokens>
            <token id="21" string="who" />
            <token id="22" string="was" />
            <token id="23" string="murdered" />
            <token id="24" string="eight" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
            <token id="27" string="in" />
            <token id="28" string="New" />
            <token id="29" string="York" />
          </tokens>
        </chunking>
        <chunking id="14" string="researching the book" type="VP">
          <tokens>
            <token id="7" string="researching" />
            <token id="8" string="the" />
            <token id="9" string="book" />
          </tokens>
        </chunking>
        <chunking id="15" string="1,200 friends , relatives and associates of Lennon , who was murdered eight years ago in New York" type="NP">
          <tokens>
            <token id="12" string="1,200" />
            <token id="13" string="friends" />
            <token id="14" string="," />
            <token id="15" string="relatives" />
            <token id="16" string="and" />
            <token id="17" string="associates" />
            <token id="18" string="of" />
            <token id="19" string="Lennon" />
            <token id="20" string="," />
            <token id="21" string="who" />
            <token id="22" string="was" />
            <token id="23" string="murdered" />
            <token id="24" string="eight" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
            <token id="27" string="in" />
            <token id="28" string="New" />
            <token id="29" string="York" />
          </tokens>
        </chunking>
        <chunking id="16" string="Goldman" type="NP">
          <tokens>
            <token id="1" string="Goldman" />
          </tokens>
        </chunking>
        <chunking id="17" string="murdered eight years ago in New York" type="VP">
          <tokens>
            <token id="23" string="murdered" />
            <token id="24" string="eight" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
            <token id="27" string="in" />
            <token id="28" string="New" />
            <token id="29" string="York" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">spent</governor>
          <dependent id="1">Goldman</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">spent</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">six</governor>
          <dependent id="3">more</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="3">more</governor>
          <dependent id="4">than</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">years</governor>
          <dependent id="5">six</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">spent</governor>
          <dependent id="6">years</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="6">years</governor>
          <dependent id="7">researching</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">book</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">researching</governor>
          <dependent id="9">book</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">spent</governor>
          <dependent id="11">interviewing</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="13">friends</governor>
          <dependent id="12">1,200</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">interviewing</governor>
          <dependent id="13">friends</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="13">friends</governor>
          <dependent id="15">relatives</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="15">relatives</governor>
          <dependent id="16">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="15">relatives</governor>
          <dependent id="17">associates</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">Lennon</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">relatives</governor>
          <dependent id="19">Lennon</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="23">murdered</governor>
          <dependent id="21">who</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="23">murdered</governor>
          <dependent id="22">was</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">friends</governor>
          <dependent id="23">murdered</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="25">years</governor>
          <dependent id="24">eight</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="26">ago</governor>
          <dependent id="25">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="29">York</governor>
          <dependent id="26">ago</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">York</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="29">York</governor>
          <dependent id="28">New</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">murdered</governor>
          <dependent id="29">York</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="New York" type="LOCATION" score="0.0">
          <tokens>
            <token id="28" string="New" />
            <token id="29" string="York" />
          </tokens>
        </entity>
        <entity id="2" string="1,200" type="NUMBER" score="0.0">
          <tokens>
            <token id="12" string="1,200" />
          </tokens>
        </entity>
        <entity id="3" string="more than six years" type="DURATION" score="0.0">
          <tokens>
            <token id="3" string="more" />
            <token id="4" string="than" />
            <token id="5" string="six" />
            <token id="6" string="years" />
          </tokens>
        </entity>
        <entity id="4" string="Lennon" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Lennon" />
          </tokens>
        </entity>
        <entity id="5" string="murdered" type="CAUSE_OF_DEATH" score="0.0">
          <tokens>
            <token id="23" string="murdered" />
          </tokens>
        </entity>
        <entity id="6" string="Goldman" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Goldman" />
          </tokens>
        </entity>
        <entity id="7" string="eight years ago" type="DATE" score="0.0">
          <tokens>
            <token id="24" string="eight" />
            <token id="25" string="years" />
            <token id="26" string="ago" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="1-2" string="John Lennon" id_sentence="1" />
      <mentions>
        <mention ids_tokens="38" string="Lennon" id_sentence="2" />
        <mention ids_tokens="40" string="his" id_sentence="2" />
        <mention ids_tokens="9" string="Lennon" id_sentence="5" />
        <mention ids_tokens="22" string="Lennon" id_sentence="6" />
        <mention ids_tokens="1" string="Lennon" id_sentence="10" />
        <mention ids_tokens="6" string="Lennon" id_sentence="13" />
        <mention ids_tokens="2" string="I" id_sentence="14" />
        <mention ids_tokens="14" string="Lennon" id_sentence="14" />
        <mention ids_tokens="2" string="I" id_sentence="15" />
        <mention ids_tokens="19" string="Lennon" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="37-38-39" string="the slain Beatle" id_sentence="1" />
      <mentions>
        <mention ids_tokens="6" string="Beatle" id_sentence="7" />
        <mention ids_tokens="10" string="his" id_sentence="7" />
        <mention ids_tokens="18" string="himself" id_sentence="7" />
        <mention ids_tokens="21" string="he" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="18-19" string="Albert Goldman" id_sentence="2" />
      <mentions>
        <mention ids_tokens="6" string="Goldman" id_sentence="5" />
        <mention ids_tokens="16" string="his" id_sentence="6" />
        <mention ids_tokens="13" string="Goldman" id_sentence="8" />
        <mention ids_tokens="9" string="his" id_sentence="9" />
        <mention ids_tokens="1" string="Goldman" id_sentence="16" />
      </mentions>
    </coreference>
    <coreference id="5" type="PROPER">
      <referenced ids_tokens="44-45" string="Yoko Ono" id_sentence="2" />
      <mentions>
        <mention ids_tokens="6-8" string="Yoko Ono's" id_sentence="11" />
        <mention ids_tokens="1" string="She" id_sentence="12" />
      </mentions>
    </coreference>
    <coreference id="9" type="PROPER">
      <referenced ids_tokens="7" string="thousand" id_sentence="14" />
      <mentions>
        <mention ids_tokens="5" string="it" id_sentence="15" />
      </mentions>
    </coreference>
  </coreferences>
</document>
