<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="AP900118-0183">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Thursday&amp;apost;s acquittals in the McMartin Pre-School molestation case outraged parents who said prosecutors botched it, while those on the defense side proclaimed a triumph of justice over hysteria and hype.</content>
      <tokens>
        <token id="1" string="Thursday" lemma="Thursday" stem="thursdai" pos="NNP" type="Word" isStopWord="false" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="acquittals" lemma="acquittal" stem="acquitt" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="8" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="outraged" lemma="outraged" stem="outrag" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="prosecutors" lemma="prosecutor" stem="prosecutor" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="botched" lemma="botch" stem="botch" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="while" lemma="while" stem="while" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="defense" lemma="defense" stem="defens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="side" lemma="side" stem="side" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="proclaimed" lemma="proclaim" stem="proclaim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="triumph" lemma="triumph" stem="triumph" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="hysteria" lemma="hysteria" stem="hysteria" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="hype" lemma="hype" stem="hype" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Thursday) (POS 's)) (NNS acquittals)) (PP (IN in) (NP (DT the) (NNP McMartin) (NNP Pre-School) (NN molestation) (NN case)))) (VP (JJ outraged) (NP (NP (NNS parents)) (SBAR (WHNP (WP who)) (S (VP (VBD said) (SBAR (S (NP (NNS prosecutors)) (VP (VBD botched) (NP (PRP it)) (, ,) (SBAR (IN while) (S (NP (NP (DT those)) (PP (IN on) (NP (DT the) (NN defense) (NN side)))) (VP (VBD proclaimed) (NP (NP (DT a) (NN triumph)) (PP (IN of) (NP (NN justice)))))))))))))) (PP (IN over) (NP (NN hysteria) (CC and) (NN hype)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="outraged parents who said prosecutors botched it , while those on the defense side proclaimed a triumph of justice over hysteria and hype" type="VP">
          <tokens>
            <token id="10" string="outraged" />
            <token id="11" string="parents" />
            <token id="12" string="who" />
            <token id="13" string="said" />
            <token id="14" string="prosecutors" />
            <token id="15" string="botched" />
            <token id="16" string="it" />
            <token id="17" string="," />
            <token id="18" string="while" />
            <token id="19" string="those" />
            <token id="20" string="on" />
            <token id="21" string="the" />
            <token id="22" string="defense" />
            <token id="23" string="side" />
            <token id="24" string="proclaimed" />
            <token id="25" string="a" />
            <token id="26" string="triumph" />
            <token id="27" string="of" />
            <token id="28" string="justice" />
            <token id="29" string="over" />
            <token id="30" string="hysteria" />
            <token id="31" string="and" />
            <token id="32" string="hype" />
          </tokens>
        </chunking>
        <chunking id="2" string="those on the defense side" type="NP">
          <tokens>
            <token id="19" string="those" />
            <token id="20" string="on" />
            <token id="21" string="the" />
            <token id="22" string="defense" />
            <token id="23" string="side" />
          </tokens>
        </chunking>
        <chunking id="3" string="proclaimed a triumph of justice" type="VP">
          <tokens>
            <token id="24" string="proclaimed" />
            <token id="25" string="a" />
            <token id="26" string="triumph" />
            <token id="27" string="of" />
            <token id="28" string="justice" />
          </tokens>
        </chunking>
        <chunking id="4" string="Thursday 's acquittals" type="NP">
          <tokens>
            <token id="1" string="Thursday" />
            <token id="2" string="'s" />
            <token id="3" string="acquittals" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="prosecutors botched it , while those on the defense side proclaimed a triumph of justice" type="SBAR">
          <tokens>
            <token id="14" string="prosecutors" />
            <token id="15" string="botched" />
            <token id="16" string="it" />
            <token id="17" string="," />
            <token id="18" string="while" />
            <token id="19" string="those" />
            <token id="20" string="on" />
            <token id="21" string="the" />
            <token id="22" string="defense" />
            <token id="23" string="side" />
            <token id="24" string="proclaimed" />
            <token id="25" string="a" />
            <token id="26" string="triumph" />
            <token id="27" string="of" />
            <token id="28" string="justice" />
          </tokens>
        </chunking>
        <chunking id="7" string="prosecutors" type="NP">
          <tokens>
            <token id="14" string="prosecutors" />
          </tokens>
        </chunking>
        <chunking id="8" string="the McMartin Pre-School molestation case" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="McMartin" />
            <token id="7" string="Pre-School" />
            <token id="8" string="molestation" />
            <token id="9" string="case" />
          </tokens>
        </chunking>
        <chunking id="9" string="hysteria and hype" type="NP">
          <tokens>
            <token id="30" string="hysteria" />
            <token id="31" string="and" />
            <token id="32" string="hype" />
          </tokens>
        </chunking>
        <chunking id="10" string="botched it , while those on the defense side proclaimed a triumph of justice" type="VP">
          <tokens>
            <token id="15" string="botched" />
            <token id="16" string="it" />
            <token id="17" string="," />
            <token id="18" string="while" />
            <token id="19" string="those" />
            <token id="20" string="on" />
            <token id="21" string="the" />
            <token id="22" string="defense" />
            <token id="23" string="side" />
            <token id="24" string="proclaimed" />
            <token id="25" string="a" />
            <token id="26" string="triumph" />
            <token id="27" string="of" />
            <token id="28" string="justice" />
          </tokens>
        </chunking>
        <chunking id="11" string="a triumph" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="triumph" />
          </tokens>
        </chunking>
        <chunking id="12" string="parents who said prosecutors botched it , while those on the defense side proclaimed a triumph of justice" type="NP">
          <tokens>
            <token id="11" string="parents" />
            <token id="12" string="who" />
            <token id="13" string="said" />
            <token id="14" string="prosecutors" />
            <token id="15" string="botched" />
            <token id="16" string="it" />
            <token id="17" string="," />
            <token id="18" string="while" />
            <token id="19" string="those" />
            <token id="20" string="on" />
            <token id="21" string="the" />
            <token id="22" string="defense" />
            <token id="23" string="side" />
            <token id="24" string="proclaimed" />
            <token id="25" string="a" />
            <token id="26" string="triumph" />
            <token id="27" string="of" />
            <token id="28" string="justice" />
          </tokens>
        </chunking>
        <chunking id="13" string="while those on the defense side proclaimed a triumph of justice" type="SBAR">
          <tokens>
            <token id="18" string="while" />
            <token id="19" string="those" />
            <token id="20" string="on" />
            <token id="21" string="the" />
            <token id="22" string="defense" />
            <token id="23" string="side" />
            <token id="24" string="proclaimed" />
            <token id="25" string="a" />
            <token id="26" string="triumph" />
            <token id="27" string="of" />
            <token id="28" string="justice" />
          </tokens>
        </chunking>
        <chunking id="14" string="justice" type="NP">
          <tokens>
            <token id="28" string="justice" />
          </tokens>
        </chunking>
        <chunking id="15" string="said prosecutors botched it , while those on the defense side proclaimed a triumph of justice" type="VP">
          <tokens>
            <token id="13" string="said" />
            <token id="14" string="prosecutors" />
            <token id="15" string="botched" />
            <token id="16" string="it" />
            <token id="17" string="," />
            <token id="18" string="while" />
            <token id="19" string="those" />
            <token id="20" string="on" />
            <token id="21" string="the" />
            <token id="22" string="defense" />
            <token id="23" string="side" />
            <token id="24" string="proclaimed" />
            <token id="25" string="a" />
            <token id="26" string="triumph" />
            <token id="27" string="of" />
            <token id="28" string="justice" />
          </tokens>
        </chunking>
        <chunking id="16" string="the defense side" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="defense" />
            <token id="23" string="side" />
          </tokens>
        </chunking>
        <chunking id="17" string="Thursday 's acquittals in the McMartin Pre-School molestation case" type="NP">
          <tokens>
            <token id="1" string="Thursday" />
            <token id="2" string="'s" />
            <token id="3" string="acquittals" />
            <token id="4" string="in" />
            <token id="5" string="the" />
            <token id="6" string="McMartin" />
            <token id="7" string="Pre-School" />
            <token id="8" string="molestation" />
            <token id="9" string="case" />
          </tokens>
        </chunking>
        <chunking id="18" string="Thursday 's" type="NP">
          <tokens>
            <token id="1" string="Thursday" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="19" string="a triumph of justice" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="triumph" />
            <token id="27" string="of" />
            <token id="28" string="justice" />
          </tokens>
        </chunking>
        <chunking id="20" string="parents" type="NP">
          <tokens>
            <token id="11" string="parents" />
          </tokens>
        </chunking>
        <chunking id="21" string="who said prosecutors botched it , while those on the defense side proclaimed a triumph of justice" type="SBAR">
          <tokens>
            <token id="12" string="who" />
            <token id="13" string="said" />
            <token id="14" string="prosecutors" />
            <token id="15" string="botched" />
            <token id="16" string="it" />
            <token id="17" string="," />
            <token id="18" string="while" />
            <token id="19" string="those" />
            <token id="20" string="on" />
            <token id="21" string="the" />
            <token id="22" string="defense" />
            <token id="23" string="side" />
            <token id="24" string="proclaimed" />
            <token id="25" string="a" />
            <token id="26" string="triumph" />
            <token id="27" string="of" />
            <token id="28" string="justice" />
          </tokens>
        </chunking>
        <chunking id="22" string="those" type="NP">
          <tokens>
            <token id="19" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">acquittals</governor>
          <dependent id="1">Thursday</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Thursday</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">outraged</governor>
          <dependent id="3">acquittals</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">case</governor>
          <dependent id="4">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">case</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">case</governor>
          <dependent id="6">McMartin</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">case</governor>
          <dependent id="7">Pre-School</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">case</governor>
          <dependent id="8">molestation</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">acquittals</governor>
          <dependent id="9">case</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">outraged</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">outraged</governor>
          <dependent id="11">parents</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">said</governor>
          <dependent id="12">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">parents</governor>
          <dependent id="13">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">botched</governor>
          <dependent id="14">prosecutors</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">said</governor>
          <dependent id="15">botched</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">botched</governor>
          <dependent id="16">it</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">proclaimed</governor>
          <dependent id="18">while</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">proclaimed</governor>
          <dependent id="19">those</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">side</governor>
          <dependent id="20">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">side</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">side</governor>
          <dependent id="22">defense</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">those</governor>
          <dependent id="23">side</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">botched</governor>
          <dependent id="24">proclaimed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">triumph</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">proclaimed</governor>
          <dependent id="26">triumph</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">justice</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">triumph</governor>
          <dependent id="28">justice</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">hysteria</governor>
          <dependent id="29">over</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">outraged</governor>
          <dependent id="30">hysteria</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="30">hysteria</governor>
          <dependent id="31">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="30">hysteria</governor>
          <dependent id="32">hype</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Thursday" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Thursday" />
          </tokens>
        </entity>
        <entity id="2" string="McMartin Pre-School" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="6" string="McMartin" />
            <token id="7" string="Pre-School" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>Mother-and-son defendants Peggy McMartin Buckey, 63, and Raymond Buckey, 31, wept as the verdicts were announced.</content>
      <tokens>
        <token id="1" string="Mother-and-son" lemma="mother-and-son" stem="mother-and-son" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="63" lemma="63" stem="63" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Raymond" lemma="Raymond" stem="raymond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="11" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="31" lemma="31" stem="31" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="wept" lemma="weep" stem="wept" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="verdicts" lemma="verdict" stem="verdict" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="announced" lemma="announce" stem="announc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (JJ Mother-and-son) (NNS defendants)) (NP (NNP Peggy) (NNP McMartin) (NNP Buckey))) (, ,) (NP (CD 63)) (, ,) (CC and) (NP (NP (NNP Raymond) (NNP Buckey)) (, ,) (NP (CD 31)) (, ,))) (VP (VBD wept) (SBAR (IN as) (S (NP (DT the) (NNS verdicts)) (VP (VBD were) (VP (VBN announced)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="3" string="Peggy" />
            <token id="4" string="McMartin" />
            <token id="5" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="Mother-and-son defendants" type="NP">
          <tokens>
            <token id="1" string="Mother-and-son" />
            <token id="2" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="3" string="the verdicts" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="verdicts" />
          </tokens>
        </chunking>
        <chunking id="4" string="were announced" type="VP">
          <tokens>
            <token id="19" string="were" />
            <token id="20" string="announced" />
          </tokens>
        </chunking>
        <chunking id="5" string="Mother-and-son defendants Peggy McMartin Buckey" type="NP">
          <tokens>
            <token id="1" string="Mother-and-son" />
            <token id="2" string="defendants" />
            <token id="3" string="Peggy" />
            <token id="4" string="McMartin" />
            <token id="5" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="6" string="Mother-and-son defendants Peggy McMartin Buckey , 63 , and Raymond Buckey , 31 ," type="NP">
          <tokens>
            <token id="1" string="Mother-and-son" />
            <token id="2" string="defendants" />
            <token id="3" string="Peggy" />
            <token id="4" string="McMartin" />
            <token id="5" string="Buckey" />
            <token id="6" string="," />
            <token id="7" string="63" />
            <token id="8" string="," />
            <token id="9" string="and" />
            <token id="10" string="Raymond" />
            <token id="11" string="Buckey" />
            <token id="12" string="," />
            <token id="13" string="31" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="7" string="Raymond Buckey , 31 ," type="NP">
          <tokens>
            <token id="10" string="Raymond" />
            <token id="11" string="Buckey" />
            <token id="12" string="," />
            <token id="13" string="31" />
            <token id="14" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="wept as the verdicts were announced" type="VP">
          <tokens>
            <token id="15" string="wept" />
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="verdicts" />
            <token id="19" string="were" />
            <token id="20" string="announced" />
          </tokens>
        </chunking>
        <chunking id="9" string="Raymond Buckey" type="NP">
          <tokens>
            <token id="10" string="Raymond" />
            <token id="11" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="10" string="announced" type="VP">
          <tokens>
            <token id="20" string="announced" />
          </tokens>
        </chunking>
        <chunking id="11" string="as the verdicts were announced" type="SBAR">
          <tokens>
            <token id="16" string="as" />
            <token id="17" string="the" />
            <token id="18" string="verdicts" />
            <token id="19" string="were" />
            <token id="20" string="announced" />
          </tokens>
        </chunking>
        <chunking id="12" string="63" type="NP">
          <tokens>
            <token id="7" string="63" />
          </tokens>
        </chunking>
        <chunking id="13" string="31" type="NP">
          <tokens>
            <token id="13" string="31" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">defendants</governor>
          <dependent id="1">Mother-and-son</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">wept</governor>
          <dependent id="2">defendants</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Buckey</governor>
          <dependent id="3">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Buckey</governor>
          <dependent id="4">McMartin</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">defendants</governor>
          <dependent id="5">Buckey</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">defendants</governor>
          <dependent id="7">63</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">defendants</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Buckey</governor>
          <dependent id="10">Raymond</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">defendants</governor>
          <dependent id="11">Buckey</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">Buckey</governor>
          <dependent id="13">31</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">wept</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">announced</governor>
          <dependent id="16">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">verdicts</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="20">announced</governor>
          <dependent id="18">verdicts</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="20">announced</governor>
          <dependent id="19">were</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="15">wept</governor>
          <dependent id="20">announced</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Peggy McMartin Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="3" string="Peggy" />
            <token id="4" string="McMartin" />
            <token id="5" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="63" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="63" />
          </tokens>
        </entity>
        <entity id="3" string="31" type="NUMBER" score="0.0">
          <tokens>
            <token id="13" string="31" />
          </tokens>
        </entity>
        <entity id="4" string="Raymond Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Raymond" />
            <token id="11" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>Jurors found the pair innocent of 52 charges and couldn&amp;apost;t reach a verdict on 13 other counts.</content>
      <tokens>
        <token id="1" string="Jurors" lemma="Jurors" stem="juror" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="found" lemma="find" stem="found" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="pair" lemma="pair" stem="pair" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="innocent" lemma="innocent" stem="innoc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="52" lemma="52" stem="52" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="reach" lemma="reach" stem="reach" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="verdict" lemma="verdict" stem="verdict" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="13" lemma="13" stem="13" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="17" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="counts" lemma="count" stem="count" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Jurors)) (VP (VP (VBD found) (S (NP (DT the) (NN pair)) (ADJP (JJ innocent) (PP (IN of) (NP (CD 52) (NNS charges)))))) (CC and) (VP (MD could) (RB n't) (VP (VB reach) (NP (DT a) (NN verdict)) (PP (IN on) (NP (CD 13) (JJ other) (NNS counts)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="innocent of 52 charges" type="ADJP">
          <tokens>
            <token id="5" string="innocent" />
            <token id="6" string="of" />
            <token id="7" string="52" />
            <token id="8" string="charges" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jurors" type="NP">
          <tokens>
            <token id="1" string="Jurors" />
          </tokens>
        </chunking>
        <chunking id="3" string="a verdict" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="verdict" />
          </tokens>
        </chunking>
        <chunking id="4" string="the pair" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="pair" />
          </tokens>
        </chunking>
        <chunking id="5" string="found the pair innocent of 52 charges and could n't reach a verdict on 13 other counts" type="VP">
          <tokens>
            <token id="2" string="found" />
            <token id="3" string="the" />
            <token id="4" string="pair" />
            <token id="5" string="innocent" />
            <token id="6" string="of" />
            <token id="7" string="52" />
            <token id="8" string="charges" />
            <token id="9" string="and" />
            <token id="10" string="could" />
            <token id="11" string="n't" />
            <token id="12" string="reach" />
            <token id="13" string="a" />
            <token id="14" string="verdict" />
            <token id="15" string="on" />
            <token id="16" string="13" />
            <token id="17" string="other" />
            <token id="18" string="counts" />
          </tokens>
        </chunking>
        <chunking id="6" string="found the pair innocent of 52 charges" type="VP">
          <tokens>
            <token id="2" string="found" />
            <token id="3" string="the" />
            <token id="4" string="pair" />
            <token id="5" string="innocent" />
            <token id="6" string="of" />
            <token id="7" string="52" />
            <token id="8" string="charges" />
          </tokens>
        </chunking>
        <chunking id="7" string="could n't reach a verdict on 13 other counts" type="VP">
          <tokens>
            <token id="10" string="could" />
            <token id="11" string="n't" />
            <token id="12" string="reach" />
            <token id="13" string="a" />
            <token id="14" string="verdict" />
            <token id="15" string="on" />
            <token id="16" string="13" />
            <token id="17" string="other" />
            <token id="18" string="counts" />
          </tokens>
        </chunking>
        <chunking id="8" string="13 other counts" type="NP">
          <tokens>
            <token id="16" string="13" />
            <token id="17" string="other" />
            <token id="18" string="counts" />
          </tokens>
        </chunking>
        <chunking id="9" string="reach a verdict on 13 other counts" type="VP">
          <tokens>
            <token id="12" string="reach" />
            <token id="13" string="a" />
            <token id="14" string="verdict" />
            <token id="15" string="on" />
            <token id="16" string="13" />
            <token id="17" string="other" />
            <token id="18" string="counts" />
          </tokens>
        </chunking>
        <chunking id="10" string="52 charges" type="NP">
          <tokens>
            <token id="7" string="52" />
            <token id="8" string="charges" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">found</governor>
          <dependent id="1">Jurors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">found</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">pair</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">innocent</governor>
          <dependent id="4">pair</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="2">found</governor>
          <dependent id="5">innocent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">charges</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="8">charges</governor>
          <dependent id="7">52</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">innocent</governor>
          <dependent id="8">charges</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">found</governor>
          <dependent id="9">and</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">reach</governor>
          <dependent id="10">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">reach</governor>
          <dependent id="11">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">found</governor>
          <dependent id="12">reach</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">verdict</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">reach</governor>
          <dependent id="14">verdict</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">counts</governor>
          <dependent id="15">on</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="18">counts</governor>
          <dependent id="16">13</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">counts</governor>
          <dependent id="17">other</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">reach</governor>
          <dependent id="18">counts</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="13" type="NUMBER" score="0.0">
          <tokens>
            <token id="16" string="13" />
          </tokens>
        </entity>
        <entity id="2" string="52" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="52" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Prosecutors must decide whether to try those charges in a new trial.</content>
      <tokens>
        <token id="1" string="Prosecutors" lemma="prosecutor" stem="prosecutor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="decide" lemma="decide" stem="decid" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="whether" lemma="whether" stem="whether" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="try" lemma="try" stem="try" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="new" lemma="new" stem="new" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNS Prosecutors)) (VP (MD must) (VP (VB decide) (SBAR (IN whether) (S (VP (TO to) (VP (VB try) (NP (DT those) (NNS charges)) (PP (IN in) (NP (DT a) (JJ new) (NN trial))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="whether to try those charges in a new trial" type="SBAR">
          <tokens>
            <token id="4" string="whether" />
            <token id="5" string="to" />
            <token id="6" string="try" />
            <token id="7" string="those" />
            <token id="8" string="charges" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="new" />
            <token id="12" string="trial" />
          </tokens>
        </chunking>
        <chunking id="2" string="try those charges in a new trial" type="VP">
          <tokens>
            <token id="6" string="try" />
            <token id="7" string="those" />
            <token id="8" string="charges" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="new" />
            <token id="12" string="trial" />
          </tokens>
        </chunking>
        <chunking id="3" string="Prosecutors" type="NP">
          <tokens>
            <token id="1" string="Prosecutors" />
          </tokens>
        </chunking>
        <chunking id="4" string="decide whether to try those charges in a new trial" type="VP">
          <tokens>
            <token id="3" string="decide" />
            <token id="4" string="whether" />
            <token id="5" string="to" />
            <token id="6" string="try" />
            <token id="7" string="those" />
            <token id="8" string="charges" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="new" />
            <token id="12" string="trial" />
          </tokens>
        </chunking>
        <chunking id="5" string="a new trial" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="new" />
            <token id="12" string="trial" />
          </tokens>
        </chunking>
        <chunking id="6" string="to try those charges in a new trial" type="VP">
          <tokens>
            <token id="5" string="to" />
            <token id="6" string="try" />
            <token id="7" string="those" />
            <token id="8" string="charges" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="new" />
            <token id="12" string="trial" />
          </tokens>
        </chunking>
        <chunking id="7" string="must decide whether to try those charges in a new trial" type="VP">
          <tokens>
            <token id="2" string="must" />
            <token id="3" string="decide" />
            <token id="4" string="whether" />
            <token id="5" string="to" />
            <token id="6" string="try" />
            <token id="7" string="those" />
            <token id="8" string="charges" />
            <token id="9" string="in" />
            <token id="10" string="a" />
            <token id="11" string="new" />
            <token id="12" string="trial" />
          </tokens>
        </chunking>
        <chunking id="8" string="those charges" type="NP">
          <tokens>
            <token id="7" string="those" />
            <token id="8" string="charges" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">decide</governor>
          <dependent id="1">Prosecutors</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="3">decide</governor>
          <dependent id="2">must</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">decide</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">try</governor>
          <dependent id="4">whether</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">try</governor>
          <dependent id="5">to</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">decide</governor>
          <dependent id="6">try</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">charges</governor>
          <dependent id="7">those</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">try</governor>
          <dependent id="8">charges</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">trial</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">trial</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">trial</governor>
          <dependent id="11">new</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">try</governor>
          <dependent id="12">trial</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>``I just said, `I told you Ray,&amp;apost;&amp;apost;&amp;apost; Mrs. Buckey said.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Ray" lemma="Ray" stem="rai" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (PRP I)) (ADVP (RB just)) (VP (VBD said) (, ,) (`` `) (S (NP (PRP I)) (VP (VBD told) (S (NP (PRP you)) (NP (NNP Ray))))))) (, ,) ('' '') ('' ') (NP (NNP Mrs.) (NNP Buckey)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Mrs. Buckey" type="NP">
          <tokens>
            <token id="14" string="Mrs." />
            <token id="15" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="Ray" type="NP">
          <tokens>
            <token id="10" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="4" string="said , ` I told you Ray" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="," />
            <token id="6" string="`" />
            <token id="7" string="I" />
            <token id="8" string="told" />
            <token id="9" string="you" />
            <token id="10" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="5" string="told you Ray" type="VP">
          <tokens>
            <token id="8" string="told" />
            <token id="9" string="you" />
            <token id="10" string="Ray" />
          </tokens>
        </chunking>
        <chunking id="6" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
        <chunking id="7" string="you" type="NP">
          <tokens>
            <token id="9" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">said</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">told</governor>
          <dependent id="7">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="8">told</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">Ray</governor>
          <dependent id="9">you</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">told</governor>
          <dependent id="10">Ray</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="15">Buckey</governor>
          <dependent id="14">Mrs.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="15">Buckey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Ray" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Ray" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>Asked if her son was surprised, she said.</content>
      <tokens>
        <token id="1" string="Asked" lemma="ask" stem="asked" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="4" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="surprised" lemma="surprise" stem="surpris" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (VP (VBN Asked) (SBAR (IN if) (S (NP (PRP$ her) (NN son)) (VP (VBD was) (VP (VBN surprised))))))) (, ,) (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Asked if her son was surprised" type="VP">
          <tokens>
            <token id="1" string="Asked" />
            <token id="2" string="if" />
            <token id="3" string="her" />
            <token id="4" string="son" />
            <token id="5" string="was" />
            <token id="6" string="surprised" />
          </tokens>
        </chunking>
        <chunking id="2" string="was surprised" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="surprised" />
          </tokens>
        </chunking>
        <chunking id="3" string="if her son was surprised" type="SBAR">
          <tokens>
            <token id="2" string="if" />
            <token id="3" string="her" />
            <token id="4" string="son" />
            <token id="5" string="was" />
            <token id="6" string="surprised" />
          </tokens>
        </chunking>
        <chunking id="4" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
        <chunking id="5" string="her son" type="NP">
          <tokens>
            <token id="3" string="her" />
            <token id="4" string="son" />
          </tokens>
        </chunking>
        <chunking id="6" string="surprised" type="VP">
          <tokens>
            <token id="6" string="surprised" />
          </tokens>
        </chunking>
        <chunking id="7" string="she" type="NP">
          <tokens>
            <token id="8" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advcl">
          <governor id="9">said</governor>
          <dependent id="1">Asked</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="6">surprised</governor>
          <dependent id="2">if</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">son</governor>
          <dependent id="3">her</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">surprised</governor>
          <dependent id="4">son</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">surprised</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="1">Asked</governor>
          <dependent id="6">surprised</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="8">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>``He had fear, definitely.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="fear" lemma="fear" stem="fear" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="definitely" lemma="definitely" stem="definit" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP He)) (VP (VBD had) (NP (NN fear)) (, ,) (ADVP (RB definitely))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="had fear , definitely" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="fear" />
            <token id="5" string="," />
            <token id="6" string="definitely" />
          </tokens>
        </chunking>
        <chunking id="2" string="fear" type="NP">
          <tokens>
            <token id="4" string="fear" />
          </tokens>
        </chunking>
        <chunking id="3" string="He" type="NP">
          <tokens>
            <token id="2" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">had</governor>
          <dependent id="2">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">had</governor>
          <dependent id="4">fear</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">had</governor>
          <dependent id="6">definitely</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>Buckey avoided reporters and slipped out the courthouse with his lawyer.</content>
      <tokens>
        <token id="1" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="avoided" lemma="avoid" stem="avoid" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="slipped" lemma="slip" stem="slip" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="courthouse" lemma="courthouse" stem="courthous" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="lawyer" lemma="lawyer" stem="lawyer" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Buckey)) (VP (VP (VBD avoided) (NP (NNS reporters))) (CC and) (VP (VBD slipped) (PRT (RP out)) (NP (NP (DT the) (NN courthouse)) (PP (IN with) (NP (PRP$ his) (NN lawyer)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Buckey" type="NP">
          <tokens>
            <token id="1" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="2" string="reporters" type="NP">
          <tokens>
            <token id="3" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="3" string="slipped out the courthouse with his lawyer" type="VP">
          <tokens>
            <token id="5" string="slipped" />
            <token id="6" string="out" />
            <token id="7" string="the" />
            <token id="8" string="courthouse" />
            <token id="9" string="with" />
            <token id="10" string="his" />
            <token id="11" string="lawyer" />
          </tokens>
        </chunking>
        <chunking id="4" string="his lawyer" type="NP">
          <tokens>
            <token id="10" string="his" />
            <token id="11" string="lawyer" />
          </tokens>
        </chunking>
        <chunking id="5" string="the courthouse with his lawyer" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="courthouse" />
            <token id="9" string="with" />
            <token id="10" string="his" />
            <token id="11" string="lawyer" />
          </tokens>
        </chunking>
        <chunking id="6" string="avoided reporters" type="VP">
          <tokens>
            <token id="2" string="avoided" />
            <token id="3" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="7" string="the courthouse" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="courthouse" />
          </tokens>
        </chunking>
        <chunking id="8" string="avoided reporters and slipped out the courthouse with his lawyer" type="VP">
          <tokens>
            <token id="2" string="avoided" />
            <token id="3" string="reporters" />
            <token id="4" string="and" />
            <token id="5" string="slipped" />
            <token id="6" string="out" />
            <token id="7" string="the" />
            <token id="8" string="courthouse" />
            <token id="9" string="with" />
            <token id="10" string="his" />
            <token id="11" string="lawyer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">avoided</governor>
          <dependent id="1">Buckey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">avoided</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">avoided</governor>
          <dependent id="3">reporters</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">avoided</governor>
          <dependent id="4">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">avoided</governor>
          <dependent id="5">slipped</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="5">slipped</governor>
          <dependent id="6">out</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">courthouse</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">slipped</governor>
          <dependent id="8">courthouse</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">lawyer</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">lawyer</governor>
          <dependent id="10">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">courthouse</governor>
          <dependent id="11">lawyer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>``If it can happen to seven innocent people it can happen to you, too.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string="innocent" lemma="innocent" stem="innoc" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="happen" lemma="happen" stem="happen" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (SBAR (IN If) (S (NP (PRP it)) (VP (MD can) (VP (VB happen) (PP (TO to) (NP (CD seven) (JJ innocent) (NNS people))))))) (NP (PRP it)) (VP (MD can) (VP (VB happen) (PP (TO to) (NP (PRP you))) (, ,) (ADVP (RB too)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="If it can happen to seven innocent people" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="it" />
            <token id="4" string="can" />
            <token id="5" string="happen" />
            <token id="6" string="to" />
            <token id="7" string="seven" />
            <token id="8" string="innocent" />
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="2" string="can happen to seven innocent people" type="VP">
          <tokens>
            <token id="4" string="can" />
            <token id="5" string="happen" />
            <token id="6" string="to" />
            <token id="7" string="seven" />
            <token id="8" string="innocent" />
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="happen to you , too" type="VP">
          <tokens>
            <token id="12" string="happen" />
            <token id="13" string="to" />
            <token id="14" string="you" />
            <token id="15" string="," />
            <token id="16" string="too" />
          </tokens>
        </chunking>
        <chunking id="4" string="can happen to you , too" type="VP">
          <tokens>
            <token id="11" string="can" />
            <token id="12" string="happen" />
            <token id="13" string="to" />
            <token id="14" string="you" />
            <token id="15" string="," />
            <token id="16" string="too" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="3" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="happen to seven innocent people" type="VP">
          <tokens>
            <token id="5" string="happen" />
            <token id="6" string="to" />
            <token id="7" string="seven" />
            <token id="8" string="innocent" />
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="7" string="seven innocent people" type="NP">
          <tokens>
            <token id="7" string="seven" />
            <token id="8" string="innocent" />
            <token id="9" string="people" />
          </tokens>
        </chunking>
        <chunking id="8" string="you" type="NP">
          <tokens>
            <token id="14" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">happen</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">happen</governor>
          <dependent id="3">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">happen</governor>
          <dependent id="4">can</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">happen</governor>
          <dependent id="5">happen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">people</governor>
          <dependent id="6">to</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="9">people</governor>
          <dependent id="7">seven</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">people</governor>
          <dependent id="8">innocent</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">happen</governor>
          <dependent id="9">people</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">happen</governor>
          <dependent id="10">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">happen</governor>
          <dependent id="11">can</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">happen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">you</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">happen</governor>
          <dependent id="14">you</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">happen</governor>
          <dependent id="16">too</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="seven" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>If it had not been in my faith in God I wouldn&amp;apost;t be here today,&amp;apost;&amp;apost; she said.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="faith" lemma="faith" stem="faith" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="God" lemma="God" stem="god" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="here" lemma="here" stem="here" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="today" lemma="today" stem="todai" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="she" lemma="she" stem="she" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (SBAR (IN If) (S (NP (PRP it)) (VP (VBD had) (RB not) (VP (VBN been) (PP (IN in) (NP (PRP$ my) (NN faith))) (PP (IN in) (NP (NNP God))))))) (NP (PRP I)) (VP (MD would) (RB n't) (VP (VB be) (ADVP (RB here)) (NP-TMP (NN today))))) (, ,) ('' '') (NP (PRP she)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="my faith" type="NP">
          <tokens>
            <token id="7" string="my" />
            <token id="8" string="faith" />
          </tokens>
        </chunking>
        <chunking id="2" string="been in my faith in God" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="in" />
            <token id="7" string="my" />
            <token id="8" string="faith" />
            <token id="9" string="in" />
            <token id="10" string="God" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="11" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="God" type="NP">
          <tokens>
            <token id="10" string="God" />
          </tokens>
        </chunking>
        <chunking id="6" string="be here today" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="here" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="7" string="would n't be here today" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="n't" />
            <token id="14" string="be" />
            <token id="15" string="here" />
            <token id="16" string="today" />
          </tokens>
        </chunking>
        <chunking id="8" string="had not been in my faith in God" type="VP">
          <tokens>
            <token id="3" string="had" />
            <token id="4" string="not" />
            <token id="5" string="been" />
            <token id="6" string="in" />
            <token id="7" string="my" />
            <token id="8" string="faith" />
            <token id="9" string="in" />
            <token id="10" string="God" />
          </tokens>
        </chunking>
        <chunking id="9" string="If it had not been in my faith in God" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="it" />
            <token id="3" string="had" />
            <token id="4" string="not" />
            <token id="5" string="been" />
            <token id="6" string="in" />
            <token id="7" string="my" />
            <token id="8" string="faith" />
            <token id="9" string="in" />
            <token id="10" string="God" />
          </tokens>
        </chunking>
        <chunking id="10" string="said" type="VP">
          <tokens>
            <token id="20" string="said" />
          </tokens>
        </chunking>
        <chunking id="11" string="she" type="NP">
          <tokens>
            <token id="19" string="she" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="8">faith</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">faith</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">faith</governor>
          <dependent id="3">had</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">faith</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">faith</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">faith</governor>
          <dependent id="6">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">faith</governor>
          <dependent id="7">my</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="14">be</governor>
          <dependent id="8">faith</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">God</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">faith</governor>
          <dependent id="10">God</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">be</governor>
          <dependent id="11">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="14">be</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="14">be</governor>
          <dependent id="13">n't</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="20">said</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">be</governor>
          <dependent id="15">here</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="14">be</governor>
          <dependent id="16">today</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="20">said</governor>
          <dependent id="19">she</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="20">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="today" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="today" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>But several parents of former students at the school said the Buckeys won because the system lost.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="several" lemma="several" stem="sever" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="former" lemma="former" stem="former" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="students" lemma="student" stem="student" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Buckeys" lemma="Buckeys" stem="buckei" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="13" string="won" lemma="win" stem="won" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="lost" lemma="lose" stem="lost" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (NP (JJ several) (NNS parents)) (PP (IN of) (NP (NP (JJ former) (NNS students)) (PP (IN at) (NP (DT the) (NN school)))))) (VP (VBD said) (SBAR (S (NP (DT the) (NNPS Buckeys)) (VP (VBD won) (SBAR (IN because) (S (NP (DT the) (NN system)) (VP (VBD lost)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the school" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="school" />
          </tokens>
        </chunking>
        <chunking id="2" string="lost" type="VP">
          <tokens>
            <token id="17" string="lost" />
          </tokens>
        </chunking>
        <chunking id="3" string="the system" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="system" />
          </tokens>
        </chunking>
        <chunking id="4" string="several parents" type="NP">
          <tokens>
            <token id="2" string="several" />
            <token id="3" string="parents" />
          </tokens>
        </chunking>
        <chunking id="5" string="former students at the school" type="NP">
          <tokens>
            <token id="5" string="former" />
            <token id="6" string="students" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="school" />
          </tokens>
        </chunking>
        <chunking id="6" string="several parents of former students at the school" type="NP">
          <tokens>
            <token id="2" string="several" />
            <token id="3" string="parents" />
            <token id="4" string="of" />
            <token id="5" string="former" />
            <token id="6" string="students" />
            <token id="7" string="at" />
            <token id="8" string="the" />
            <token id="9" string="school" />
          </tokens>
        </chunking>
        <chunking id="7" string="former students" type="NP">
          <tokens>
            <token id="5" string="former" />
            <token id="6" string="students" />
          </tokens>
        </chunking>
        <chunking id="8" string="the Buckeys won because the system lost" type="SBAR">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Buckeys" />
            <token id="13" string="won" />
            <token id="14" string="because" />
            <token id="15" string="the" />
            <token id="16" string="system" />
            <token id="17" string="lost" />
          </tokens>
        </chunking>
        <chunking id="9" string="the Buckeys" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="Buckeys" />
          </tokens>
        </chunking>
        <chunking id="10" string="because the system lost" type="SBAR">
          <tokens>
            <token id="14" string="because" />
            <token id="15" string="the" />
            <token id="16" string="system" />
            <token id="17" string="lost" />
          </tokens>
        </chunking>
        <chunking id="11" string="won because the system lost" type="VP">
          <tokens>
            <token id="13" string="won" />
            <token id="14" string="because" />
            <token id="15" string="the" />
            <token id="16" string="system" />
            <token id="17" string="lost" />
          </tokens>
        </chunking>
        <chunking id="12" string="said the Buckeys won because the system lost" type="VP">
          <tokens>
            <token id="10" string="said" />
            <token id="11" string="the" />
            <token id="12" string="Buckeys" />
            <token id="13" string="won" />
            <token id="14" string="because" />
            <token id="15" string="the" />
            <token id="16" string="system" />
            <token id="17" string="lost" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="10">said</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">parents</governor>
          <dependent id="2">several</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">said</governor>
          <dependent id="3">parents</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">students</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">students</governor>
          <dependent id="5">former</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">parents</governor>
          <dependent id="6">students</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">school</governor>
          <dependent id="7">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">school</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">students</governor>
          <dependent id="9">school</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">Buckeys</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">won</governor>
          <dependent id="12">Buckeys</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">said</governor>
          <dependent id="13">won</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">lost</governor>
          <dependent id="14">because</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">system</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">lost</governor>
          <dependent id="16">system</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">won</governor>
          <dependent id="17">lost</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckeys" type="MISC" score="0.0">
          <tokens>
            <token id="12" string="Buckeys" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>``It was never done properly,&amp;apost;&amp;apost; said parent Alan Lagunoff, who moved to Central California from suburban Manhattan Beach.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="done" lemma="do" stem="done" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="properly" lemma="properly" stem="properli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="parent" lemma="parent" stem="parent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="Alan" lemma="Alan" stem="alan" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="12" string="Lagunoff" lemma="Lagunoff" stem="lagunoff" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="moved" lemma="move" stem="move" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="Central" lemma="Central" stem="central" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="18" string="California" lemma="California" stem="california" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="19" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="suburban" lemma="suburban" stem="suburban" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="Manhattan" lemma="Manhattan" stem="manhattan" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="22" string="Beach" lemma="Beach" stem="beach" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="23" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBD was) (ADVP (RB never)) (VP (VBN done) (ADVP (RB properly))))) (, ,) ('' '') (VP (VBD said) (NP (NN parent))) (NP (NP (NNP Alan) (NNP Lagunoff)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD moved) (PP (TO to) (NP (NNP Central) (NNP California))) (PP (IN from) (NP (JJ suburban) (NNP Manhattan) (NNP Beach))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="parent" type="NP">
          <tokens>
            <token id="10" string="parent" />
          </tokens>
        </chunking>
        <chunking id="2" string="who moved to Central California from suburban Manhattan Beach" type="SBAR">
          <tokens>
            <token id="14" string="who" />
            <token id="15" string="moved" />
            <token id="16" string="to" />
            <token id="17" string="Central" />
            <token id="18" string="California" />
            <token id="19" string="from" />
            <token id="20" string="suburban" />
            <token id="21" string="Manhattan" />
            <token id="22" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="3" string="Central California" type="NP">
          <tokens>
            <token id="17" string="Central" />
            <token id="18" string="California" />
          </tokens>
        </chunking>
        <chunking id="4" string="suburban Manhattan Beach" type="NP">
          <tokens>
            <token id="20" string="suburban" />
            <token id="21" string="Manhattan" />
            <token id="22" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="5" string="done properly" type="VP">
          <tokens>
            <token id="5" string="done" />
            <token id="6" string="properly" />
          </tokens>
        </chunking>
        <chunking id="6" string="moved to Central California from suburban Manhattan Beach" type="VP">
          <tokens>
            <token id="15" string="moved" />
            <token id="16" string="to" />
            <token id="17" string="Central" />
            <token id="18" string="California" />
            <token id="19" string="from" />
            <token id="20" string="suburban" />
            <token id="21" string="Manhattan" />
            <token id="22" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="7" string="was never done properly" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="never" />
            <token id="5" string="done" />
            <token id="6" string="properly" />
          </tokens>
        </chunking>
        <chunking id="8" string="said parent" type="VP">
          <tokens>
            <token id="9" string="said" />
            <token id="10" string="parent" />
          </tokens>
        </chunking>
        <chunking id="9" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="10" string="Alan Lagunoff , who moved to Central California from suburban Manhattan Beach" type="NP">
          <tokens>
            <token id="11" string="Alan" />
            <token id="12" string="Lagunoff" />
            <token id="13" string="," />
            <token id="14" string="who" />
            <token id="15" string="moved" />
            <token id="16" string="to" />
            <token id="17" string="Central" />
            <token id="18" string="California" />
            <token id="19" string="from" />
            <token id="20" string="suburban" />
            <token id="21" string="Manhattan" />
            <token id="22" string="Beach" />
          </tokens>
        </chunking>
        <chunking id="11" string="Alan Lagunoff" type="NP">
          <tokens>
            <token id="11" string="Alan" />
            <token id="12" string="Lagunoff" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="5">done</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">done</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">done</governor>
          <dependent id="4">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="5">done</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">done</governor>
          <dependent id="6">properly</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">said</governor>
          <dependent id="10">parent</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="12">Lagunoff</governor>
          <dependent id="11">Alan</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="12">Lagunoff</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">moved</governor>
          <dependent id="14">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="12">Lagunoff</governor>
          <dependent id="15">moved</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">California</governor>
          <dependent id="16">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">California</governor>
          <dependent id="17">Central</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">moved</governor>
          <dependent id="18">California</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">Beach</governor>
          <dependent id="19">from</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">Beach</governor>
          <dependent id="20">suburban</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="22">Beach</governor>
          <dependent id="21">Manhattan</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">moved</governor>
          <dependent id="22">Beach</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Central California" type="LOCATION" score="0.0">
          <tokens>
            <token id="17" string="Central" />
            <token id="18" string="California" />
          </tokens>
        </entity>
        <entity id="2" string="Alan Lagunoff" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Alan" />
            <token id="12" string="Lagunoff" />
          </tokens>
        </entity>
        <entity id="3" string="Manhattan Beach" type="LOCATION" score="0.0">
          <tokens>
            <token id="21" string="Manhattan" />
            <token id="22" string="Beach" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>``I have to sit back and figure out what to do with my son.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="sit" lemma="sit" stem="sit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="figure" lemma="figure" stem="figur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="do" lemma="do" stem="do" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP have) (S (VP (TO to) (VP (VP (VB sit) (ADVP (RB back))) (CC and) (VP (VB figure) (PRT (RP out)) (SBAR (WHNP (WP what)) (S (VP (TO to) (VP (VB do) (PP (IN with) (NP (PRP$ my) (NN son)))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="sit back" type="VP">
          <tokens>
            <token id="5" string="sit" />
            <token id="6" string="back" />
          </tokens>
        </chunking>
        <chunking id="2" string="do with my son" type="VP">
          <tokens>
            <token id="12" string="do" />
            <token id="13" string="with" />
            <token id="14" string="my" />
            <token id="15" string="son" />
          </tokens>
        </chunking>
        <chunking id="3" string="have to sit back and figure out what to do with my son" type="VP">
          <tokens>
            <token id="3" string="have" />
            <token id="4" string="to" />
            <token id="5" string="sit" />
            <token id="6" string="back" />
            <token id="7" string="and" />
            <token id="8" string="figure" />
            <token id="9" string="out" />
            <token id="10" string="what" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="with" />
            <token id="14" string="my" />
            <token id="15" string="son" />
          </tokens>
        </chunking>
        <chunking id="4" string="to sit back and figure out what to do with my son" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="sit" />
            <token id="6" string="back" />
            <token id="7" string="and" />
            <token id="8" string="figure" />
            <token id="9" string="out" />
            <token id="10" string="what" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="with" />
            <token id="14" string="my" />
            <token id="15" string="son" />
          </tokens>
        </chunking>
        <chunking id="5" string="what to do with my son" type="SBAR">
          <tokens>
            <token id="10" string="what" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="with" />
            <token id="14" string="my" />
            <token id="15" string="son" />
          </tokens>
        </chunking>
        <chunking id="6" string="my son" type="NP">
          <tokens>
            <token id="14" string="my" />
            <token id="15" string="son" />
          </tokens>
        </chunking>
        <chunking id="7" string="figure out what to do with my son" type="VP">
          <tokens>
            <token id="8" string="figure" />
            <token id="9" string="out" />
            <token id="10" string="what" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="with" />
            <token id="14" string="my" />
            <token id="15" string="son" />
          </tokens>
        </chunking>
        <chunking id="8" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="9" string="sit back and figure out what to do with my son" type="VP">
          <tokens>
            <token id="5" string="sit" />
            <token id="6" string="back" />
            <token id="7" string="and" />
            <token id="8" string="figure" />
            <token id="9" string="out" />
            <token id="10" string="what" />
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="with" />
            <token id="14" string="my" />
            <token id="15" string="son" />
          </tokens>
        </chunking>
        <chunking id="10" string="to do with my son" type="VP">
          <tokens>
            <token id="11" string="to" />
            <token id="12" string="do" />
            <token id="13" string="with" />
            <token id="14" string="my" />
            <token id="15" string="son" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">have</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">have</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">sit</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">have</governor>
          <dependent id="5">sit</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">sit</governor>
          <dependent id="6">back</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">sit</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">sit</governor>
          <dependent id="8">figure</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="8">figure</governor>
          <dependent id="9">out</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">do</governor>
          <dependent id="10">what</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">do</governor>
          <dependent id="11">to</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">figure</governor>
          <dependent id="12">do</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">son</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">son</governor>
          <dependent id="14">my</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">do</governor>
          <dependent id="15">son</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>I fear that because of this verdict, no child will be seen as a credible witness from now on.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="fear" lemma="fear" stem="fear" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="because" lemma="because" stem="becaus" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="verdict" lemma="verdict" stem="verdict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="seen" lemma="see" stem="seen" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="credible" lemma="credible" stem="credibl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="witness" lemma="witness" stem="wit" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="true" is_refers="false" />
        <token id="20" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP fear) (SBAR (IN that) (IN because) (S (PP (IN of) (NP (DT this) (NN verdict))) (, ,) (NP (DT no) (NN child)) (VP (MD will) (VP (VB be) (VP (VBN seen) (PP (IN as) (NP (NP (DT a) (JJ credible) (NN witness)) (PP (IN from) (NP (RB now))))) (PP (IN on)))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="now" type="NP">
          <tokens>
            <token id="19" string="now" />
          </tokens>
        </chunking>
        <chunking id="2" string="a credible witness" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="credible" />
            <token id="17" string="witness" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="no child" type="NP">
          <tokens>
            <token id="9" string="no" />
            <token id="10" string="child" />
          </tokens>
        </chunking>
        <chunking id="5" string="seen as a credible witness from now on" type="VP">
          <tokens>
            <token id="13" string="seen" />
            <token id="14" string="as" />
            <token id="15" string="a" />
            <token id="16" string="credible" />
            <token id="17" string="witness" />
            <token id="18" string="from" />
            <token id="19" string="now" />
            <token id="20" string="on" />
          </tokens>
        </chunking>
        <chunking id="6" string="fear that because of this verdict , no child will be seen as a credible witness from now on" type="VP">
          <tokens>
            <token id="2" string="fear" />
            <token id="3" string="that" />
            <token id="4" string="because" />
            <token id="5" string="of" />
            <token id="6" string="this" />
            <token id="7" string="verdict" />
            <token id="8" string="," />
            <token id="9" string="no" />
            <token id="10" string="child" />
            <token id="11" string="will" />
            <token id="12" string="be" />
            <token id="13" string="seen" />
            <token id="14" string="as" />
            <token id="15" string="a" />
            <token id="16" string="credible" />
            <token id="17" string="witness" />
            <token id="18" string="from" />
            <token id="19" string="now" />
            <token id="20" string="on" />
          </tokens>
        </chunking>
        <chunking id="7" string="will be seen as a credible witness from now on" type="VP">
          <tokens>
            <token id="11" string="will" />
            <token id="12" string="be" />
            <token id="13" string="seen" />
            <token id="14" string="as" />
            <token id="15" string="a" />
            <token id="16" string="credible" />
            <token id="17" string="witness" />
            <token id="18" string="from" />
            <token id="19" string="now" />
            <token id="20" string="on" />
          </tokens>
        </chunking>
        <chunking id="8" string="be seen as a credible witness from now on" type="VP">
          <tokens>
            <token id="12" string="be" />
            <token id="13" string="seen" />
            <token id="14" string="as" />
            <token id="15" string="a" />
            <token id="16" string="credible" />
            <token id="17" string="witness" />
            <token id="18" string="from" />
            <token id="19" string="now" />
            <token id="20" string="on" />
          </tokens>
        </chunking>
        <chunking id="9" string="that because of this verdict , no child will be seen as a credible witness from now on" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="because" />
            <token id="5" string="of" />
            <token id="6" string="this" />
            <token id="7" string="verdict" />
            <token id="8" string="," />
            <token id="9" string="no" />
            <token id="10" string="child" />
            <token id="11" string="will" />
            <token id="12" string="be" />
            <token id="13" string="seen" />
            <token id="14" string="as" />
            <token id="15" string="a" />
            <token id="16" string="credible" />
            <token id="17" string="witness" />
            <token id="18" string="from" />
            <token id="19" string="now" />
            <token id="20" string="on" />
          </tokens>
        </chunking>
        <chunking id="10" string="a credible witness from now" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="credible" />
            <token id="17" string="witness" />
            <token id="18" string="from" />
            <token id="19" string="now" />
          </tokens>
        </chunking>
        <chunking id="11" string="this verdict" type="NP">
          <tokens>
            <token id="6" string="this" />
            <token id="7" string="verdict" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">fear</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">fear</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">seen</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">seen</governor>
          <dependent id="4">because</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">verdict</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">verdict</governor>
          <dependent id="6">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">seen</governor>
          <dependent id="7">verdict</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">child</governor>
          <dependent id="9">no</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="13">seen</governor>
          <dependent id="10">child</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="13">seen</governor>
          <dependent id="11">will</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="13">seen</governor>
          <dependent id="12">be</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="2">fear</governor>
          <dependent id="13">seen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">witness</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">witness</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">witness</governor>
          <dependent id="16">credible</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">seen</governor>
          <dependent id="17">witness</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">now</governor>
          <dependent id="18">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">witness</governor>
          <dependent id="19">now</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">verdict</governor>
          <dependent id="20">on</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="19" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>His son, now 10, attended the school for 1{ years but wasn&amp;apost;t a witness at the trial.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="5" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="attended" lemma="attend" stem="attend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="1" lemma="1" stem="1" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="12" string="{" lemma="-lcb-" stem="{" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="14" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="witness" lemma="witness" stem="wit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ His) (NN son)) (, ,) (ADVP (RB now) (NP (CD 10))) (, ,)) (VP (VBD attended) (SBAR (S (NP (NP (DT the) (NN school)) (PP (IN for) (NP (NP (CD 1)) (-LRB- -LCB-) (NP (NNS years)) (ADVP (CC but))))) (VP (VBD was) (RB n't) (NP (DT a) (NN witness)) (PP (IN at) (NP (DT the) (NN trial))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was n't a witness at the trial" type="VP">
          <tokens>
            <token id="15" string="was" />
            <token id="16" string="n't" />
            <token id="17" string="a" />
            <token id="18" string="witness" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="trial" />
          </tokens>
        </chunking>
        <chunking id="2" string="the trial" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="trial" />
          </tokens>
        </chunking>
        <chunking id="3" string="a witness" type="NP">
          <tokens>
            <token id="17" string="a" />
            <token id="18" string="witness" />
          </tokens>
        </chunking>
        <chunking id="4" string="the school for 1 -LCB- years but" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="school" />
            <token id="10" string="for" />
            <token id="11" string="1" />
            <token id="12" string="{" />
            <token id="13" string="years" />
            <token id="14" string="but" />
          </tokens>
        </chunking>
        <chunking id="5" string="1 -LCB- years but" type="NP">
          <tokens>
            <token id="11" string="1" />
            <token id="12" string="{" />
            <token id="13" string="years" />
            <token id="14" string="but" />
          </tokens>
        </chunking>
        <chunking id="6" string="years" type="NP">
          <tokens>
            <token id="13" string="years" />
          </tokens>
        </chunking>
        <chunking id="7" string="1" type="NP">
          <tokens>
            <token id="11" string="1" />
          </tokens>
        </chunking>
        <chunking id="8" string="His son" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="son" />
          </tokens>
        </chunking>
        <chunking id="9" string="the school" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="school" />
          </tokens>
        </chunking>
        <chunking id="10" string="attended the school for 1 -LCB- years but was n't a witness at the trial" type="VP">
          <tokens>
            <token id="7" string="attended" />
            <token id="8" string="the" />
            <token id="9" string="school" />
            <token id="10" string="for" />
            <token id="11" string="1" />
            <token id="12" string="{" />
            <token id="13" string="years" />
            <token id="14" string="but" />
            <token id="15" string="was" />
            <token id="16" string="n't" />
            <token id="17" string="a" />
            <token id="18" string="witness" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="trial" />
          </tokens>
        </chunking>
        <chunking id="11" string="His son , now 10 ," type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="son" />
            <token id="3" string="," />
            <token id="4" string="now" />
            <token id="5" string="10" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="the school for 1 -LCB- years but was n't a witness at the trial" type="SBAR">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="school" />
            <token id="10" string="for" />
            <token id="11" string="1" />
            <token id="12" string="{" />
            <token id="13" string="years" />
            <token id="14" string="but" />
            <token id="15" string="was" />
            <token id="16" string="n't" />
            <token id="17" string="a" />
            <token id="18" string="witness" />
            <token id="19" string="at" />
            <token id="20" string="the" />
            <token id="21" string="trial" />
          </tokens>
        </chunking>
        <chunking id="13" string="10" type="NP">
          <tokens>
            <token id="5" string="10" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">son</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">attended</governor>
          <dependent id="2">son</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="2">son</governor>
          <dependent id="4">now</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="4">now</governor>
          <dependent id="5">10</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">attended</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">school</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">witness</governor>
          <dependent id="9">school</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">1</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">school</governor>
          <dependent id="11">1</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">1</governor>
          <dependent id="13">years</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">1</governor>
          <dependent id="14">but</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">witness</governor>
          <dependent id="15">was</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">witness</governor>
          <dependent id="16">n't</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">witness</governor>
          <dependent id="17">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">attended</governor>
          <dependent id="18">witness</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">trial</governor>
          <dependent id="19">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">trial</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">witness</governor>
          <dependent id="21">trial</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="1" type="NUMBER" score="0.0">
          <tokens>
            <token id="11" string="1" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="4" string="now" />
          </tokens>
        </entity>
        <entity id="3" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="13" string="years" />
          </tokens>
        </entity>
        <entity id="4" string="10" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="10" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>``I don&amp;apost;t think it&amp;apost;s worth it to bring this thing back into the courts.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="think" lemma="think" stem="think" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="worth" lemma="worth" stem="worth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="bring" lemma="bring" stem="bring" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="into" lemma="into" stem="into" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="courts" lemma="court" stem="court" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB think) (SBAR (S (NP (PRP it)) (VP (VBZ 's) (ADJP (JJ worth) (SBAR (S (NP (PRP it)) (VP (TO to) (VP (VB bring) (NP (DT this) (NN thing)) (ADVP (RB back)) (PP (IN into) (NP (DT the) (NNS courts))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="bring this thing back into the courts" type="VP">
          <tokens>
            <token id="11" string="bring" />
            <token id="12" string="this" />
            <token id="13" string="thing" />
            <token id="14" string="back" />
            <token id="15" string="into" />
            <token id="16" string="the" />
            <token id="17" string="courts" />
          </tokens>
        </chunking>
        <chunking id="2" string="this thing" type="NP">
          <tokens>
            <token id="12" string="this" />
            <token id="13" string="thing" />
          </tokens>
        </chunking>
        <chunking id="3" string="it 's worth it to bring this thing back into the courts" type="SBAR">
          <tokens>
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="worth" />
            <token id="9" string="it" />
            <token id="10" string="to" />
            <token id="11" string="bring" />
            <token id="12" string="this" />
            <token id="13" string="thing" />
            <token id="14" string="back" />
            <token id="15" string="into" />
            <token id="16" string="the" />
            <token id="17" string="courts" />
          </tokens>
        </chunking>
        <chunking id="4" string="'s worth it to bring this thing back into the courts" type="VP">
          <tokens>
            <token id="7" string="'s" />
            <token id="8" string="worth" />
            <token id="9" string="it" />
            <token id="10" string="to" />
            <token id="11" string="bring" />
            <token id="12" string="this" />
            <token id="13" string="thing" />
            <token id="14" string="back" />
            <token id="15" string="into" />
            <token id="16" string="the" />
            <token id="17" string="courts" />
          </tokens>
        </chunking>
        <chunking id="5" string="the courts" type="NP">
          <tokens>
            <token id="16" string="the" />
            <token id="17" string="courts" />
          </tokens>
        </chunking>
        <chunking id="6" string="think it 's worth it to bring this thing back into the courts" type="VP">
          <tokens>
            <token id="5" string="think" />
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="worth" />
            <token id="9" string="it" />
            <token id="10" string="to" />
            <token id="11" string="bring" />
            <token id="12" string="this" />
            <token id="13" string="thing" />
            <token id="14" string="back" />
            <token id="15" string="into" />
            <token id="16" string="the" />
            <token id="17" string="courts" />
          </tokens>
        </chunking>
        <chunking id="7" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="8" string="do n't think it 's worth it to bring this thing back into the courts" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="think" />
            <token id="6" string="it" />
            <token id="7" string="'s" />
            <token id="8" string="worth" />
            <token id="9" string="it" />
            <token id="10" string="to" />
            <token id="11" string="bring" />
            <token id="12" string="this" />
            <token id="13" string="thing" />
            <token id="14" string="back" />
            <token id="15" string="into" />
            <token id="16" string="the" />
            <token id="17" string="courts" />
          </tokens>
        </chunking>
        <chunking id="9" string="it to bring this thing back into the courts" type="SBAR">
          <tokens>
            <token id="9" string="it" />
            <token id="10" string="to" />
            <token id="11" string="bring" />
            <token id="12" string="this" />
            <token id="13" string="thing" />
            <token id="14" string="back" />
            <token id="15" string="into" />
            <token id="16" string="the" />
            <token id="17" string="courts" />
          </tokens>
        </chunking>
        <chunking id="10" string="it" type="NP">
          <tokens>
            <token id="6" string="it" />
          </tokens>
        </chunking>
        <chunking id="11" string="worth it to bring this thing back into the courts" type="ADJP">
          <tokens>
            <token id="8" string="worth" />
            <token id="9" string="it" />
            <token id="10" string="to" />
            <token id="11" string="bring" />
            <token id="12" string="this" />
            <token id="13" string="thing" />
            <token id="14" string="back" />
            <token id="15" string="into" />
            <token id="16" string="the" />
            <token id="17" string="courts" />
          </tokens>
        </chunking>
        <chunking id="12" string="to bring this thing back into the courts" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="bring" />
            <token id="12" string="this" />
            <token id="13" string="thing" />
            <token id="14" string="back" />
            <token id="15" string="into" />
            <token id="16" string="the" />
            <token id="17" string="courts" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">think</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">think</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">think</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">think</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">worth</governor>
          <dependent id="6">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">worth</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">think</governor>
          <dependent id="8">worth</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">bring</governor>
          <dependent id="9">it</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">bring</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">worth</governor>
          <dependent id="11">bring</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">thing</governor>
          <dependent id="12">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">bring</governor>
          <dependent id="13">thing</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">bring</governor>
          <dependent id="14">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">courts</governor>
          <dependent id="15">into</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">courts</governor>
          <dependent id="16">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">bring</governor>
          <dependent id="17">courts</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>It will just be another six-year travesty,&amp;apost;&amp;apost; Lagunoff said.</content>
      <tokens>
        <token id="1" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="another" lemma="another" stem="anoth" pos="DT" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="six-year" lemma="six-year" stem="six-year" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="7" string="travesty" lemma="travesty" stem="travesti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Lagunoff" lemma="Lagunoff" stem="lagunoff" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP It)) (VP (MD will) (ADVP (RB just)) (VP (VB be) (NP (DT another) (JJ six-year) (NN travesty))))) (, ,) ('' '') (NP (NNP Lagunoff)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be another six-year travesty" type="VP">
          <tokens>
            <token id="4" string="be" />
            <token id="5" string="another" />
            <token id="6" string="six-year" />
            <token id="7" string="travesty" />
          </tokens>
        </chunking>
        <chunking id="2" string="another six-year travesty" type="NP">
          <tokens>
            <token id="5" string="another" />
            <token id="6" string="six-year" />
            <token id="7" string="travesty" />
          </tokens>
        </chunking>
        <chunking id="3" string="will just be another six-year travesty" type="VP">
          <tokens>
            <token id="2" string="will" />
            <token id="3" string="just" />
            <token id="4" string="be" />
            <token id="5" string="another" />
            <token id="6" string="six-year" />
            <token id="7" string="travesty" />
          </tokens>
        </chunking>
        <chunking id="4" string="It" type="NP">
          <tokens>
            <token id="1" string="It" />
          </tokens>
        </chunking>
        <chunking id="5" string="said" type="VP">
          <tokens>
            <token id="11" string="said" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lagunoff" type="NP">
          <tokens>
            <token id="10" string="Lagunoff" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="7">travesty</governor>
          <dependent id="1">It</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">travesty</governor>
          <dependent id="2">will</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">travesty</governor>
          <dependent id="3">just</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">travesty</governor>
          <dependent id="4">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">travesty</governor>
          <dependent id="5">another</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">travesty</governor>
          <dependent id="6">six-year</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="11">said</governor>
          <dependent id="7">travesty</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">said</governor>
          <dependent id="10">Lagunoff</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">said</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="six-year" type="DURATION" score="0.0">
          <tokens>
            <token id="6" string="six-year" />
          </tokens>
        </entity>
        <entity id="2" string="Lagunoff" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Lagunoff" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>``The system is not going to protect children,&amp;apost;&amp;apost; said Jackie McGauley, a parent who believes her child had been molested but didn&amp;apost;t testify in the case.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="protect" lemma="protect" stem="protect" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="Jackie" lemma="Jackie" stem="jacki" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="14" string="McGauley" lemma="McGauley" stem="mcgaulei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="parent" lemma="parent" stem="parent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="believes" lemma="believe" stem="believ" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="her" lemma="she" stem="her" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="testify" lemma="testify" stem="testifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="31" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (DT The) (NN system)) (VP (VBZ is) (RB not) (VP (VBG going) (S (VP (TO to) (VP (VB protect) (NP (NNS children)))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Jackie) (NNP McGauley)) (, ,) (NP (NP (DT a) (NN parent)) (SBAR (WHNP (WP who)) (S (VP (VP (VBZ believes) (SBAR (S (NP (PRP$ her) (NN child)) (VP (VBD had) (VP (VBN been) (VP (VBN molested))))))) (CC but) (VP (VBD did) (RB n't) (VP (VB testify) (PP (IN in) (NP (DT the) (NN case)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="who believes her child had been molested but did n't testify in the case" type="SBAR">
          <tokens>
            <token id="18" string="who" />
            <token id="19" string="believes" />
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
            <token id="25" string="but" />
            <token id="26" string="did" />
            <token id="27" string="n't" />
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="the case" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="had been molested" type="VP">
          <tokens>
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
          </tokens>
        </chunking>
        <chunking id="4" string="her child had been molested" type="SBAR">
          <tokens>
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
          </tokens>
        </chunking>
        <chunking id="5" string="Jackie McGauley , a parent who believes her child had been molested but did n't testify in the case" type="NP">
          <tokens>
            <token id="13" string="Jackie" />
            <token id="14" string="McGauley" />
            <token id="15" string="," />
            <token id="16" string="a" />
            <token id="17" string="parent" />
            <token id="18" string="who" />
            <token id="19" string="believes" />
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
            <token id="25" string="but" />
            <token id="26" string="did" />
            <token id="27" string="n't" />
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="a parent" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="parent" />
          </tokens>
        </chunking>
        <chunking id="7" string="testify in the case" type="VP">
          <tokens>
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="is not going to protect children" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="not" />
            <token id="6" string="going" />
            <token id="7" string="to" />
            <token id="8" string="protect" />
            <token id="9" string="children" />
          </tokens>
        </chunking>
        <chunking id="9" string="Jackie McGauley" type="NP">
          <tokens>
            <token id="13" string="Jackie" />
            <token id="14" string="McGauley" />
          </tokens>
        </chunking>
        <chunking id="10" string="a parent who believes her child had been molested but did n't testify in the case" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="parent" />
            <token id="18" string="who" />
            <token id="19" string="believes" />
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
            <token id="25" string="but" />
            <token id="26" string="did" />
            <token id="27" string="n't" />
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="11" string="to protect children" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="protect" />
            <token id="9" string="children" />
          </tokens>
        </chunking>
        <chunking id="12" string="children" type="NP">
          <tokens>
            <token id="9" string="children" />
          </tokens>
        </chunking>
        <chunking id="13" string="been molested" type="VP">
          <tokens>
            <token id="23" string="been" />
            <token id="24" string="molested" />
          </tokens>
        </chunking>
        <chunking id="14" string="did n't testify in the case" type="VP">
          <tokens>
            <token id="26" string="did" />
            <token id="27" string="n't" />
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="15" string="going to protect children" type="VP">
          <tokens>
            <token id="6" string="going" />
            <token id="7" string="to" />
            <token id="8" string="protect" />
            <token id="9" string="children" />
          </tokens>
        </chunking>
        <chunking id="16" string="protect children" type="VP">
          <tokens>
            <token id="8" string="protect" />
            <token id="9" string="children" />
          </tokens>
        </chunking>
        <chunking id="17" string="her child" type="NP">
          <tokens>
            <token id="20" string="her" />
            <token id="21" string="child" />
          </tokens>
        </chunking>
        <chunking id="18" string="believes her child had been molested but did n't testify in the case" type="VP">
          <tokens>
            <token id="19" string="believes" />
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
            <token id="25" string="but" />
            <token id="26" string="did" />
            <token id="27" string="n't" />
            <token id="28" string="testify" />
            <token id="29" string="in" />
            <token id="30" string="the" />
            <token id="31" string="case" />
          </tokens>
        </chunking>
        <chunking id="19" string="The system" type="NP">
          <tokens>
            <token id="2" string="The" />
            <token id="3" string="system" />
          </tokens>
        </chunking>
        <chunking id="20" string="said" type="VP">
          <tokens>
            <token id="12" string="said" />
          </tokens>
        </chunking>
        <chunking id="21" string="believes her child had been molested" type="VP">
          <tokens>
            <token id="19" string="believes" />
            <token id="20" string="her" />
            <token id="21" string="child" />
            <token id="22" string="had" />
            <token id="23" string="been" />
            <token id="24" string="molested" />
          </tokens>
        </chunking>
        <chunking id="22" string="molested" type="VP">
          <tokens>
            <token id="24" string="molested" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">system</governor>
          <dependent id="2">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">going</governor>
          <dependent id="3">system</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">going</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">going</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="12">said</governor>
          <dependent id="6">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">protect</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">going</governor>
          <dependent id="8">protect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">protect</governor>
          <dependent id="9">children</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">McGauley</governor>
          <dependent id="13">Jackie</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">said</governor>
          <dependent id="14">McGauley</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">parent</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">McGauley</governor>
          <dependent id="17">parent</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="19">believes</governor>
          <dependent id="18">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="17">parent</governor>
          <dependent id="19">believes</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">child</governor>
          <dependent id="20">her</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="24">molested</governor>
          <dependent id="21">child</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="24">molested</governor>
          <dependent id="22">had</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="24">molested</governor>
          <dependent id="23">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="19">believes</governor>
          <dependent id="24">molested</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="19">believes</governor>
          <dependent id="25">but</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="28">testify</governor>
          <dependent id="26">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="28">testify</governor>
          <dependent id="27">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="19">believes</governor>
          <dependent id="28">testify</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">case</governor>
          <dependent id="29">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">case</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">testify</governor>
          <dependent id="31">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Jackie McGauley" type="PERSON" score="0.0">
          <tokens>
            <token id="13" string="Jackie" />
            <token id="14" string="McGauley" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>``I don&amp;apost;t know what the message is that the jury wanted to get out.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="know" lemma="know" stem="know" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="message" lemma="message" stem="messag" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="wanted" lemma="want" stem="want" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP I)) (VP (VBP do) (RB n't) (VP (VB know) (SBAR (WHNP (WP what)) (S (NP (DT the) (NN message)) (VP (VBZ is) (SBAR (IN that) (S (NP (DT the) (NN jury)) (VP (VBD wanted) (S (VP (TO to) (VP (VB get) (PRT (RP out))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the message" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="message" />
          </tokens>
        </chunking>
        <chunking id="2" string="do n't know what the message is that the jury wanted to get out" type="VP">
          <tokens>
            <token id="3" string="do" />
            <token id="4" string="n't" />
            <token id="5" string="know" />
            <token id="6" string="what" />
            <token id="7" string="the" />
            <token id="8" string="message" />
            <token id="9" string="is" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="jury" />
            <token id="13" string="wanted" />
            <token id="14" string="to" />
            <token id="15" string="get" />
            <token id="16" string="out" />
          </tokens>
        </chunking>
        <chunking id="3" string="that the jury wanted to get out" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="jury" />
            <token id="13" string="wanted" />
            <token id="14" string="to" />
            <token id="15" string="get" />
            <token id="16" string="out" />
          </tokens>
        </chunking>
        <chunking id="4" string="know what the message is that the jury wanted to get out" type="VP">
          <tokens>
            <token id="5" string="know" />
            <token id="6" string="what" />
            <token id="7" string="the" />
            <token id="8" string="message" />
            <token id="9" string="is" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="jury" />
            <token id="13" string="wanted" />
            <token id="14" string="to" />
            <token id="15" string="get" />
            <token id="16" string="out" />
          </tokens>
        </chunking>
        <chunking id="5" string="is that the jury wanted to get out" type="VP">
          <tokens>
            <token id="9" string="is" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="jury" />
            <token id="13" string="wanted" />
            <token id="14" string="to" />
            <token id="15" string="get" />
            <token id="16" string="out" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="2" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="to get out" type="VP">
          <tokens>
            <token id="14" string="to" />
            <token id="15" string="get" />
            <token id="16" string="out" />
          </tokens>
        </chunking>
        <chunking id="8" string="wanted to get out" type="VP">
          <tokens>
            <token id="13" string="wanted" />
            <token id="14" string="to" />
            <token id="15" string="get" />
            <token id="16" string="out" />
          </tokens>
        </chunking>
        <chunking id="9" string="what the message is that the jury wanted to get out" type="SBAR">
          <tokens>
            <token id="6" string="what" />
            <token id="7" string="the" />
            <token id="8" string="message" />
            <token id="9" string="is" />
            <token id="10" string="that" />
            <token id="11" string="the" />
            <token id="12" string="jury" />
            <token id="13" string="wanted" />
            <token id="14" string="to" />
            <token id="15" string="get" />
            <token id="16" string="out" />
          </tokens>
        </chunking>
        <chunking id="10" string="get out" type="VP">
          <tokens>
            <token id="15" string="get" />
            <token id="16" string="out" />
          </tokens>
        </chunking>
        <chunking id="11" string="the jury" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="jury" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">know</governor>
          <dependent id="2">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">know</governor>
          <dependent id="3">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">know</governor>
          <dependent id="4">n't</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">know</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">is</governor>
          <dependent id="6">what</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">message</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">is</governor>
          <dependent id="8">message</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">know</governor>
          <dependent id="9">is</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">wanted</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">jury</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">wanted</governor>
          <dependent id="12">jury</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">is</governor>
          <dependent id="13">wanted</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="15">get</governor>
          <dependent id="14">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="13">wanted</governor>
          <dependent id="15">get</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="15">get</governor>
          <dependent id="16">out</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="true">
      <content>I&amp;apost;m anxious to hear that.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="'m" lemma="be" stem="'m" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="anxious" lemma="anxious" stem="anxiou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="hear" lemma="hear" stem="hear" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP 'm) (ADJP (JJ anxious) (S (VP (TO to) (VP (VB hear) (NP (DT that))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="6" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="anxious to hear that" type="ADJP">
          <tokens>
            <token id="3" string="anxious" />
            <token id="4" string="to" />
            <token id="5" string="hear" />
            <token id="6" string="that" />
          </tokens>
        </chunking>
        <chunking id="3" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="4" string="hear that" type="VP">
          <tokens>
            <token id="5" string="hear" />
            <token id="6" string="that" />
          </tokens>
        </chunking>
        <chunking id="5" string="'m anxious to hear that" type="VP">
          <tokens>
            <token id="2" string="'m" />
            <token id="3" string="anxious" />
            <token id="4" string="to" />
            <token id="5" string="hear" />
            <token id="6" string="that" />
          </tokens>
        </chunking>
        <chunking id="6" string="to hear that" type="VP">
          <tokens>
            <token id="4" string="to" />
            <token id="5" string="hear" />
            <token id="6" string="that" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">anxious</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="3">anxious</governor>
          <dependent id="2">'m</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">anxious</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">hear</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">anxious</governor>
          <dependent id="5">hear</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">hear</governor>
          <dependent id="6">that</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Charles Buckey, father of Raymond and husband of Mrs. Buckey, suggested Deputy District Attorney Lael Rubin, who prosecuted the case for its entire six years, was motivated by personal ambition.</content>
      <tokens>
        <token id="1" string="Charles" lemma="Charles" stem="charl" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="Raymond" lemma="Raymond" stem="raymond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="husband" lemma="husband" stem="husband" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="suggested" lemma="suggest" stem="suggest" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="Deputy" lemma="Deputy" stem="deputi" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="District" lemma="District" stem="district" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="Attorney" lemma="Attorney" stem="attornei" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="17" string="Lael" lemma="Lael" stem="lael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="18" string="Rubin" lemma="Rubin" stem="rubin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="prosecuted" lemma="prosecute" stem="prosecut" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="entire" lemma="entire" stem="entir" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="six" lemma="six" stem="six" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="28" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="29" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="motivated" lemma="motivate" stem="motiv" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="personal" lemma="personal" stem="person" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="ambition" lemma="ambition" stem="ambit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Charles) (NNP Buckey)) (, ,) (NP (NP (NP (NN father)) (PP (IN of) (NP (NNP Raymond)))) (CC and) (NP (NP (NN husband)) (PP (IN of) (NP (NNP Mrs.) (NNP Buckey))))) (, ,)) (VP (VBD suggested) (SBAR (S (NP (NP (NNP Deputy) (NNP District) (NNP Attorney) (NNP Lael) (NNP Rubin)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBD prosecuted) (NP (DT the) (NN case)) (PP (IN for) (NP (PRP$ its) (JJ entire) (CD six) (NNS years)))))) (, ,)) (VP (VBD was) (VP (VBN motivated) (PP (IN by) (NP (JJ personal) (NN ambition)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="father" type="NP">
          <tokens>
            <token id="4" string="father" />
          </tokens>
        </chunking>
        <chunking id="2" string="Raymond" type="NP">
          <tokens>
            <token id="6" string="Raymond" />
          </tokens>
        </chunking>
        <chunking id="3" string="who prosecuted the case for its entire six years" type="SBAR">
          <tokens>
            <token id="20" string="who" />
            <token id="21" string="prosecuted" />
            <token id="22" string="the" />
            <token id="23" string="case" />
            <token id="24" string="for" />
            <token id="25" string="its" />
            <token id="26" string="entire" />
            <token id="27" string="six" />
            <token id="28" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="Deputy District Attorney Lael Rubin , who prosecuted the case for its entire six years ," type="NP">
          <tokens>
            <token id="14" string="Deputy" />
            <token id="15" string="District" />
            <token id="16" string="Attorney" />
            <token id="17" string="Lael" />
            <token id="18" string="Rubin" />
            <token id="19" string="," />
            <token id="20" string="who" />
            <token id="21" string="prosecuted" />
            <token id="22" string="the" />
            <token id="23" string="case" />
            <token id="24" string="for" />
            <token id="25" string="its" />
            <token id="26" string="entire" />
            <token id="27" string="six" />
            <token id="28" string="years" />
            <token id="29" string="," />
          </tokens>
        </chunking>
        <chunking id="5" string="prosecuted the case for its entire six years" type="VP">
          <tokens>
            <token id="21" string="prosecuted" />
            <token id="22" string="the" />
            <token id="23" string="case" />
            <token id="24" string="for" />
            <token id="25" string="its" />
            <token id="26" string="entire" />
            <token id="27" string="six" />
            <token id="28" string="years" />
          </tokens>
        </chunking>
        <chunking id="6" string="the case" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="suggested Deputy District Attorney Lael Rubin , who prosecuted the case for its entire six years , was motivated by personal ambition" type="VP">
          <tokens>
            <token id="13" string="suggested" />
            <token id="14" string="Deputy" />
            <token id="15" string="District" />
            <token id="16" string="Attorney" />
            <token id="17" string="Lael" />
            <token id="18" string="Rubin" />
            <token id="19" string="," />
            <token id="20" string="who" />
            <token id="21" string="prosecuted" />
            <token id="22" string="the" />
            <token id="23" string="case" />
            <token id="24" string="for" />
            <token id="25" string="its" />
            <token id="26" string="entire" />
            <token id="27" string="six" />
            <token id="28" string="years" />
            <token id="29" string="," />
            <token id="30" string="was" />
            <token id="31" string="motivated" />
            <token id="32" string="by" />
            <token id="33" string="personal" />
            <token id="34" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="8" string="its entire six years" type="NP">
          <tokens>
            <token id="25" string="its" />
            <token id="26" string="entire" />
            <token id="27" string="six" />
            <token id="28" string="years" />
          </tokens>
        </chunking>
        <chunking id="9" string="husband of Mrs. Buckey" type="NP">
          <tokens>
            <token id="8" string="husband" />
            <token id="9" string="of" />
            <token id="10" string="Mrs." />
            <token id="11" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="10" string="husband" type="NP">
          <tokens>
            <token id="8" string="husband" />
          </tokens>
        </chunking>
        <chunking id="11" string="Charles Buckey , father of Raymond and husband of Mrs. Buckey ," type="NP">
          <tokens>
            <token id="1" string="Charles" />
            <token id="2" string="Buckey" />
            <token id="3" string="," />
            <token id="4" string="father" />
            <token id="5" string="of" />
            <token id="6" string="Raymond" />
            <token id="7" string="and" />
            <token id="8" string="husband" />
            <token id="9" string="of" />
            <token id="10" string="Mrs." />
            <token id="11" string="Buckey" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="12" string="father of Raymond and husband of Mrs. Buckey" type="NP">
          <tokens>
            <token id="4" string="father" />
            <token id="5" string="of" />
            <token id="6" string="Raymond" />
            <token id="7" string="and" />
            <token id="8" string="husband" />
            <token id="9" string="of" />
            <token id="10" string="Mrs." />
            <token id="11" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="13" string="Deputy District Attorney Lael Rubin , who prosecuted the case for its entire six years , was motivated by personal ambition" type="SBAR">
          <tokens>
            <token id="14" string="Deputy" />
            <token id="15" string="District" />
            <token id="16" string="Attorney" />
            <token id="17" string="Lael" />
            <token id="18" string="Rubin" />
            <token id="19" string="," />
            <token id="20" string="who" />
            <token id="21" string="prosecuted" />
            <token id="22" string="the" />
            <token id="23" string="case" />
            <token id="24" string="for" />
            <token id="25" string="its" />
            <token id="26" string="entire" />
            <token id="27" string="six" />
            <token id="28" string="years" />
            <token id="29" string="," />
            <token id="30" string="was" />
            <token id="31" string="motivated" />
            <token id="32" string="by" />
            <token id="33" string="personal" />
            <token id="34" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="14" string="Deputy District Attorney Lael Rubin" type="NP">
          <tokens>
            <token id="14" string="Deputy" />
            <token id="15" string="District" />
            <token id="16" string="Attorney" />
            <token id="17" string="Lael" />
            <token id="18" string="Rubin" />
          </tokens>
        </chunking>
        <chunking id="15" string="Mrs. Buckey" type="NP">
          <tokens>
            <token id="10" string="Mrs." />
            <token id="11" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="16" string="was motivated by personal ambition" type="VP">
          <tokens>
            <token id="30" string="was" />
            <token id="31" string="motivated" />
            <token id="32" string="by" />
            <token id="33" string="personal" />
            <token id="34" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="17" string="personal ambition" type="NP">
          <tokens>
            <token id="33" string="personal" />
            <token id="34" string="ambition" />
          </tokens>
        </chunking>
        <chunking id="18" string="Charles Buckey" type="NP">
          <tokens>
            <token id="1" string="Charles" />
            <token id="2" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="19" string="father of Raymond" type="NP">
          <tokens>
            <token id="4" string="father" />
            <token id="5" string="of" />
            <token id="6" string="Raymond" />
          </tokens>
        </chunking>
        <chunking id="20" string="motivated by personal ambition" type="VP">
          <tokens>
            <token id="31" string="motivated" />
            <token id="32" string="by" />
            <token id="33" string="personal" />
            <token id="34" string="ambition" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Buckey</governor>
          <dependent id="1">Charles</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">suggested</governor>
          <dependent id="2">Buckey</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Buckey</governor>
          <dependent id="4">father</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Raymond</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">father</governor>
          <dependent id="6">Raymond</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="4">father</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="4">father</governor>
          <dependent id="8">husband</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Buckey</governor>
          <dependent id="9">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="11">Buckey</governor>
          <dependent id="10">Mrs.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">husband</governor>
          <dependent id="11">Buckey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">suggested</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Rubin</governor>
          <dependent id="14">Deputy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Rubin</governor>
          <dependent id="15">District</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Rubin</governor>
          <dependent id="16">Attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Rubin</governor>
          <dependent id="17">Lael</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="31">motivated</governor>
          <dependent id="18">Rubin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="21">prosecuted</governor>
          <dependent id="20">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="18">Rubin</governor>
          <dependent id="21">prosecuted</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">case</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">prosecuted</governor>
          <dependent id="23">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">years</governor>
          <dependent id="24">for</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">years</governor>
          <dependent id="25">its</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">years</governor>
          <dependent id="26">entire</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="28">years</governor>
          <dependent id="27">six</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">prosecuted</governor>
          <dependent id="28">years</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="31">motivated</governor>
          <dependent id="30">was</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="13">suggested</governor>
          <dependent id="31">motivated</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">ambition</governor>
          <dependent id="32">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="34">ambition</governor>
          <dependent id="33">personal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="31">motivated</governor>
          <dependent id="34">ambition</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Raymond" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Raymond" />
          </tokens>
        </entity>
        <entity id="2" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="11" string="Buckey" />
          </tokens>
        </entity>
        <entity id="3" string="Lael Rubin" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="Lael" />
            <token id="18" string="Rubin" />
          </tokens>
        </entity>
        <entity id="4" string="Charles Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Charles" />
            <token id="2" string="Buckey" />
          </tokens>
        </entity>
        <entity id="5" string="Attorney" type="TITLE" score="0.0">
          <tokens>
            <token id="16" string="Attorney" />
          </tokens>
        </entity>
        <entity id="6" string="six years" type="DURATION" score="0.0">
          <tokens>
            <token id="27" string="six" />
            <token id="28" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>``My concern primarily was Lael Rubin, who is `anything goes&amp;apost; in order to secure a conviction.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="concern" lemma="concern" stem="concern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="primarily" lemma="primarily" stem="primarili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Lael" lemma="Lael" stem="lael" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="Rubin" lemma="Rubin" stem="rubin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="`" lemma="`" stem="`" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="13" string="goes" lemma="go" stem="goe" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="order" lemma="order" stem="order" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="secure" lemma="secure" stem="secur" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="conviction" lemma="conviction" stem="convict" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP$ My) (NN concern)) (ADVP (RB primarily)) (VP (VBD was) (NP (NP (NNP Lael) (NNP Rubin)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VBZ is) (S (`` `) (NP (NN anything)) (VP (VBZ goes)) ('' ')))))) (SBAR (IN in) (NN order) (S (VP (TO to) (VP (VB secure) (NP (DT a) (NN conviction))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="secure a conviction" type="VP">
          <tokens>
            <token id="18" string="secure" />
            <token id="19" string="a" />
            <token id="20" string="conviction" />
          </tokens>
        </chunking>
        <chunking id="2" string="was Lael Rubin , who is ` anything goes ' in order to secure a conviction" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="Lael" />
            <token id="7" string="Rubin" />
            <token id="8" string="," />
            <token id="9" string="who" />
            <token id="10" string="is" />
            <token id="11" string="`" />
            <token id="12" string="anything" />
            <token id="13" string="goes" />
            <token id="14" string="'" />
            <token id="15" string="in" />
            <token id="16" string="order" />
            <token id="17" string="to" />
            <token id="18" string="secure" />
            <token id="19" string="a" />
            <token id="20" string="conviction" />
          </tokens>
        </chunking>
        <chunking id="3" string="goes" type="VP">
          <tokens>
            <token id="13" string="goes" />
          </tokens>
        </chunking>
        <chunking id="4" string="is ` anything goes '" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="`" />
            <token id="12" string="anything" />
            <token id="13" string="goes" />
            <token id="14" string="'" />
          </tokens>
        </chunking>
        <chunking id="5" string="Lael Rubin" type="NP">
          <tokens>
            <token id="6" string="Lael" />
            <token id="7" string="Rubin" />
          </tokens>
        </chunking>
        <chunking id="6" string="Lael Rubin , who is ` anything goes '" type="NP">
          <tokens>
            <token id="6" string="Lael" />
            <token id="7" string="Rubin" />
            <token id="8" string="," />
            <token id="9" string="who" />
            <token id="10" string="is" />
            <token id="11" string="`" />
            <token id="12" string="anything" />
            <token id="13" string="goes" />
            <token id="14" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="who is ` anything goes '" type="SBAR">
          <tokens>
            <token id="9" string="who" />
            <token id="10" string="is" />
            <token id="11" string="`" />
            <token id="12" string="anything" />
            <token id="13" string="goes" />
            <token id="14" string="'" />
          </tokens>
        </chunking>
        <chunking id="8" string="in order to secure a conviction" type="SBAR">
          <tokens>
            <token id="15" string="in" />
            <token id="16" string="order" />
            <token id="17" string="to" />
            <token id="18" string="secure" />
            <token id="19" string="a" />
            <token id="20" string="conviction" />
          </tokens>
        </chunking>
        <chunking id="9" string="to secure a conviction" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="secure" />
            <token id="19" string="a" />
            <token id="20" string="conviction" />
          </tokens>
        </chunking>
        <chunking id="10" string="anything" type="NP">
          <tokens>
            <token id="12" string="anything" />
          </tokens>
        </chunking>
        <chunking id="11" string="My concern" type="NP">
          <tokens>
            <token id="2" string="My" />
            <token id="3" string="concern" />
          </tokens>
        </chunking>
        <chunking id="12" string="a conviction" type="NP">
          <tokens>
            <token id="19" string="a" />
            <token id="20" string="conviction" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">concern</governor>
          <dependent id="2">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">Rubin</governor>
          <dependent id="3">concern</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">Rubin</governor>
          <dependent id="4">primarily</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">Rubin</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Rubin</governor>
          <dependent id="6">Lael</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">Rubin</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">is</governor>
          <dependent id="9">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="7">Rubin</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">goes</governor>
          <dependent id="12">anything</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">is</governor>
          <dependent id="13">goes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">secure</governor>
          <dependent id="15">in</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="15">in</governor>
          <dependent id="16">order</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">secure</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">Rubin</governor>
          <dependent id="18">secure</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">conviction</governor>
          <dependent id="19">a</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">secure</governor>
          <dependent id="20">conviction</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Lael Rubin" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Lael" />
            <token id="7" string="Rubin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>... If you don&amp;apost;t win, you don&amp;apost;t get promoted,&amp;apost;&amp;apost; he said.</content>
      <tokens>
        <token id="1" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="win" lemma="win" stem="win" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="get" lemma="get" stem="get" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="promoted" lemma="promote" stem="promot" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (: ...) (SBAR (IN If) (S (NP (PRP you)) (VP (VBP do) (RB n't) (VP (VB win))))) (, ,) (S (NP (PRP you)) (VP (VBP do) (RB n't) (VP (VB get) (VP (VBN promoted))))) (, ,) ('' '') (NP (PRP he)) (VP (VBD said)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="do n't get promoted" type="VP">
          <tokens>
            <token id="9" string="do" />
            <token id="10" string="n't" />
            <token id="11" string="get" />
            <token id="12" string="promoted" />
          </tokens>
        </chunking>
        <chunking id="2" string="If you do n't win" type="SBAR">
          <tokens>
            <token id="2" string="If" />
            <token id="3" string="you" />
            <token id="4" string="do" />
            <token id="5" string="n't" />
            <token id="6" string="win" />
          </tokens>
        </chunking>
        <chunking id="3" string="win" type="VP">
          <tokens>
            <token id="6" string="win" />
          </tokens>
        </chunking>
        <chunking id="4" string="promoted" type="VP">
          <tokens>
            <token id="12" string="promoted" />
          </tokens>
        </chunking>
        <chunking id="5" string="get promoted" type="VP">
          <tokens>
            <token id="11" string="get" />
            <token id="12" string="promoted" />
          </tokens>
        </chunking>
        <chunking id="6" string="he" type="NP">
          <tokens>
            <token id="15" string="he" />
          </tokens>
        </chunking>
        <chunking id="7" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
        <chunking id="8" string="do n't win" type="VP">
          <tokens>
            <token id="4" string="do" />
            <token id="5" string="n't" />
            <token id="6" string="win" />
          </tokens>
        </chunking>
        <chunking id="9" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="6">win</governor>
          <dependent id="2">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">win</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">win</governor>
          <dependent id="4">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">win</governor>
          <dependent id="5">n't</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">said</governor>
          <dependent id="6">win</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="12">promoted</governor>
          <dependent id="8">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">promoted</governor>
          <dependent id="9">do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">promoted</governor>
          <dependent id="10">n't</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="12">promoted</governor>
          <dependent id="11">get</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="12">promoted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="15">he</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Juror Brenda Williams said the evidence failed to convince the jury beyond a reasonable doubt in 52 of the charges.</content>
      <tokens>
        <token id="1" string="Juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="2" string="Brenda" lemma="Brenda" stem="brenda" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="4" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="evidence" lemma="evidence" stem="evid" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="failed" lemma="fail" stem="fail" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="convince" lemma="convince" stem="convinc" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="jury" lemma="jury" stem="juri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="beyond" lemma="beyond" stem="beyond" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="reasonable" lemma="reasonable" stem="reason" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="doubt" lemma="doubt" stem="doubt" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="52" lemma="52" stem="52" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NN Juror) (NNP Brenda) (NNP Williams)) (VP (VBD said) (SBAR (S (NP (DT the) (NN evidence)) (VP (VBD failed) (S (VP (TO to) (VP (VB convince) (NP (DT the) (NN jury)) (PP (IN beyond) (NP (NP (DT a) (JJ reasonable) (NN doubt)) (PP (IN in) (NP (NP (CD 52)) (PP (IN of) (NP (DT the) (NNS charges)))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="failed to convince the jury beyond a reasonable doubt in 52 of the charges" type="VP">
          <tokens>
            <token id="7" string="failed" />
            <token id="8" string="to" />
            <token id="9" string="convince" />
            <token id="10" string="the" />
            <token id="11" string="jury" />
            <token id="12" string="beyond" />
            <token id="13" string="a" />
            <token id="14" string="reasonable" />
            <token id="15" string="doubt" />
            <token id="16" string="in" />
            <token id="17" string="52" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="charges" />
          </tokens>
        </chunking>
        <chunking id="2" string="said the evidence failed to convince the jury beyond a reasonable doubt in 52 of the charges" type="VP">
          <tokens>
            <token id="4" string="said" />
            <token id="5" string="the" />
            <token id="6" string="evidence" />
            <token id="7" string="failed" />
            <token id="8" string="to" />
            <token id="9" string="convince" />
            <token id="10" string="the" />
            <token id="11" string="jury" />
            <token id="12" string="beyond" />
            <token id="13" string="a" />
            <token id="14" string="reasonable" />
            <token id="15" string="doubt" />
            <token id="16" string="in" />
            <token id="17" string="52" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="charges" />
          </tokens>
        </chunking>
        <chunking id="3" string="Juror Brenda Williams" type="NP">
          <tokens>
            <token id="1" string="Juror" />
            <token id="2" string="Brenda" />
            <token id="3" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="4" string="the charges" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="charges" />
          </tokens>
        </chunking>
        <chunking id="5" string="the evidence" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="evidence" />
          </tokens>
        </chunking>
        <chunking id="6" string="to convince the jury beyond a reasonable doubt in 52 of the charges" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="convince" />
            <token id="10" string="the" />
            <token id="11" string="jury" />
            <token id="12" string="beyond" />
            <token id="13" string="a" />
            <token id="14" string="reasonable" />
            <token id="15" string="doubt" />
            <token id="16" string="in" />
            <token id="17" string="52" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="charges" />
          </tokens>
        </chunking>
        <chunking id="7" string="convince the jury beyond a reasonable doubt in 52 of the charges" type="VP">
          <tokens>
            <token id="9" string="convince" />
            <token id="10" string="the" />
            <token id="11" string="jury" />
            <token id="12" string="beyond" />
            <token id="13" string="a" />
            <token id="14" string="reasonable" />
            <token id="15" string="doubt" />
            <token id="16" string="in" />
            <token id="17" string="52" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="charges" />
          </tokens>
        </chunking>
        <chunking id="8" string="a reasonable doubt in 52 of the charges" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="reasonable" />
            <token id="15" string="doubt" />
            <token id="16" string="in" />
            <token id="17" string="52" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="charges" />
          </tokens>
        </chunking>
        <chunking id="9" string="the evidence failed to convince the jury beyond a reasonable doubt in 52 of the charges" type="SBAR">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="evidence" />
            <token id="7" string="failed" />
            <token id="8" string="to" />
            <token id="9" string="convince" />
            <token id="10" string="the" />
            <token id="11" string="jury" />
            <token id="12" string="beyond" />
            <token id="13" string="a" />
            <token id="14" string="reasonable" />
            <token id="15" string="doubt" />
            <token id="16" string="in" />
            <token id="17" string="52" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="charges" />
          </tokens>
        </chunking>
        <chunking id="10" string="52 of the charges" type="NP">
          <tokens>
            <token id="17" string="52" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="charges" />
          </tokens>
        </chunking>
        <chunking id="11" string="a reasonable doubt" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="reasonable" />
            <token id="15" string="doubt" />
          </tokens>
        </chunking>
        <chunking id="12" string="52" type="NP">
          <tokens>
            <token id="17" string="52" />
          </tokens>
        </chunking>
        <chunking id="13" string="the jury" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="jury" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Williams</governor>
          <dependent id="1">Juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Williams</governor>
          <dependent id="2">Brenda</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">said</governor>
          <dependent id="3">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">evidence</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">failed</governor>
          <dependent id="6">evidence</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="4">said</governor>
          <dependent id="7">failed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">convince</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">failed</governor>
          <dependent id="9">convince</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">jury</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">convince</governor>
          <dependent id="11">jury</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">doubt</governor>
          <dependent id="12">beyond</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">doubt</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">doubt</governor>
          <dependent id="14">reasonable</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">convince</governor>
          <dependent id="15">doubt</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">52</governor>
          <dependent id="16">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">doubt</governor>
          <dependent id="17">52</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">charges</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">charges</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">52</governor>
          <dependent id="20">charges</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="52" type="NUMBER" score="0.0">
          <tokens>
            <token id="17" string="52" />
          </tokens>
        </entity>
        <entity id="2" string="Brenda Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Brenda" />
            <token id="3" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>``Even if you accept that the children were molested, it didn&amp;apost;t necessarily mean they were molested at the McMartin Pre-School,&amp;apost;&amp;apost; Ms. Williams told reporters.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="accept" lemma="accept" stem="accept" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="necessarily" lemma="necessarily" stem="necessarili" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="mean" lemma="mean" stem="mean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="molested" lemma="molest" stem="molest" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="23" string="Pre-School" lemma="Pre-School" stem="pre-school" pos="NNP" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="true" />
        <token id="24" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="27" string="Williams" lemma="Williams" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="28" string="told" lemma="tell" stem="told" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="reporters" lemma="reporter" stem="report" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (SBAR (RB Even) (IN if) (S (NP (PRP you)) (VP (VBP accept) (SBAR (IN that) (S (NP (DT the) (NNS children)) (VP (VBD were) (VP (VBN molested)))))))) (, ,) (NP (PRP it)) (VP (VBD did) (RB n't) (ADVP (RB necessarily)) (VP (VB mean) (SBAR (S (NP (PRP they)) (VP (VBD were) (VP (VBN molested) (PP (IN at) (NP (DT the) (NNP McMartin) (NNP Pre-School)))))))))) (, ,) ('' '') (NP (NNP Ms.) (NNP Williams)) (VP (VBD told) (NP (NNS reporters))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="reporters" type="NP">
          <tokens>
            <token id="29" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="2" string="did n't necessarily mean they were molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="13" string="did" />
            <token id="14" string="n't" />
            <token id="15" string="necessarily" />
            <token id="16" string="mean" />
            <token id="17" string="they" />
            <token id="18" string="were" />
            <token id="19" string="molested" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="3" string="Ms. Williams" type="NP">
          <tokens>
            <token id="26" string="Ms." />
            <token id="27" string="Williams" />
          </tokens>
        </chunking>
        <chunking id="4" string="it" type="NP">
          <tokens>
            <token id="12" string="it" />
          </tokens>
        </chunking>
        <chunking id="5" string="they" type="NP">
          <tokens>
            <token id="17" string="they" />
          </tokens>
        </chunking>
        <chunking id="6" string="told reporters" type="VP">
          <tokens>
            <token id="28" string="told" />
            <token id="29" string="reporters" />
          </tokens>
        </chunking>
        <chunking id="7" string="the children" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="children" />
          </tokens>
        </chunking>
        <chunking id="8" string="were molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="18" string="were" />
            <token id="19" string="molested" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="9" string="that the children were molested" type="SBAR">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="children" />
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="10" string="accept that the children were molested" type="VP">
          <tokens>
            <token id="5" string="accept" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="children" />
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="11" string="were molested" type="VP">
          <tokens>
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="12" string="the McMartin Pre-School" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="13" string="Even if you accept that the children were molested" type="SBAR">
          <tokens>
            <token id="2" string="Even" />
            <token id="3" string="if" />
            <token id="4" string="you" />
            <token id="5" string="accept" />
            <token id="6" string="that" />
            <token id="7" string="the" />
            <token id="8" string="children" />
            <token id="9" string="were" />
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="14" string="molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="19" string="molested" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="15" string="molested" type="VP">
          <tokens>
            <token id="10" string="molested" />
          </tokens>
        </chunking>
        <chunking id="16" string="you" type="NP">
          <tokens>
            <token id="4" string="you" />
          </tokens>
        </chunking>
        <chunking id="17" string="mean they were molested at the McMartin Pre-School" type="VP">
          <tokens>
            <token id="16" string="mean" />
            <token id="17" string="they" />
            <token id="18" string="were" />
            <token id="19" string="molested" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
        <chunking id="18" string="they were molested at the McMartin Pre-School" type="SBAR">
          <tokens>
            <token id="17" string="they" />
            <token id="18" string="were" />
            <token id="19" string="molested" />
            <token id="20" string="at" />
            <token id="21" string="the" />
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="5">accept</governor>
          <dependent id="2">Even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">accept</governor>
          <dependent id="3">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">accept</governor>
          <dependent id="4">you</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="16">mean</governor>
          <dependent id="5">accept</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">molested</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">children</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="10">molested</governor>
          <dependent id="8">children</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="10">molested</governor>
          <dependent id="9">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">accept</governor>
          <dependent id="10">molested</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">mean</governor>
          <dependent id="12">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">mean</governor>
          <dependent id="13">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">mean</governor>
          <dependent id="14">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">mean</governor>
          <dependent id="15">necessarily</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="28">told</governor>
          <dependent id="16">mean</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="19">molested</governor>
          <dependent id="17">they</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="19">molested</governor>
          <dependent id="18">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">mean</governor>
          <dependent id="19">molested</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">Pre-School</governor>
          <dependent id="20">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">Pre-School</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="23">Pre-School</governor>
          <dependent id="22">McMartin</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">molested</governor>
          <dependent id="23">Pre-School</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="27">Williams</governor>
          <dependent id="26">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">told</governor>
          <dependent id="27">Williams</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="28">told</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">told</governor>
          <dependent id="29">reporters</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="McMartin Pre-School" type="MISC" score="0.0">
          <tokens>
            <token id="22" string="McMartin" />
            <token id="23" string="Pre-School" />
          </tokens>
        </entity>
        <entity id="2" string="Williams" type="PERSON" score="0.0">
          <tokens>
            <token id="27" string="Williams" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>Raymond Buckey spent nearly five years in jail without bail during the case, which defense attorneys said was the result of community hysteria sparked by bizarre allegations by the alcoholic mother of one child at the preschool.</content>
      <tokens>
        <token id="1" string="Raymond" lemma="Raymond" stem="raymond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="spent" lemma="spend" stem="spent" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="nearly" lemma="nearly" stem="nearli" pos="RB" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="5" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="6" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="7" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="jail" lemma="jail" stem="jail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="bail" lemma="bail" stem="bail" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="during" lemma="during" stem="dure" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="defense" lemma="defense" stem="defens" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="17" string="attorneys" lemma="attorney" stem="attornei" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="result" lemma="result" stem="result" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="23" string="community" lemma="community" stem="commun" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="24" string="hysteria" lemma="hysteria" stem="hysteria" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="25" string="sparked" lemma="spark" stem="spark" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="bizarre" lemma="bizarre" stem="bizarr" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="30" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="31" string="alcoholic" lemma="alcoholic" stem="alcohol" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="32" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="34" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="true" />
        <token id="35" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="36" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="38" string="preschool" lemma="preschool" stem="preschool" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Raymond) (NNP Buckey)) (VP (VBD spent) (NP (QP (RB nearly) (CD five)) (NNS years)) (PP (IN in) (NP (NN jail))) (PP (IN without) (NP (NN bail))) (PP (IN during) (NP (NP (DT the) (NN case)) (, ,) (SBAR (WHNP (WDT which)) (S (NP (NN defense) (NNS attorneys)) (VP (VBD said) (SBAR (S (VP (VBD was) (NP (NP (DT the) (NN result)) (PP (IN of) (NP (NP (NN community) (NN hysteria)) (VP (VBN sparked) (PP (IN by) (NP (JJ bizarre) (NNS allegations))) (PP (IN by) (NP (NP (DT the) (JJ alcoholic) (NN mother)) (PP (IN of) (NP (NP (CD one) (NN child)) (PP (IN at) (NP (DT the) (JJ preschool)))))))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="one child" type="NP">
          <tokens>
            <token id="34" string="one" />
            <token id="35" string="child" />
          </tokens>
        </chunking>
        <chunking id="2" string="sparked by bizarre allegations by the alcoholic mother of one child at the preschool" type="VP">
          <tokens>
            <token id="25" string="sparked" />
            <token id="26" string="by" />
            <token id="27" string="bizarre" />
            <token id="28" string="allegations" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="alcoholic" />
            <token id="32" string="mother" />
            <token id="33" string="of" />
            <token id="34" string="one" />
            <token id="35" string="child" />
            <token id="36" string="at" />
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="3" string="the case" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="said was the result of community hysteria sparked by bizarre allegations by the alcoholic mother of one child at the preschool" type="VP">
          <tokens>
            <token id="18" string="said" />
            <token id="19" string="was" />
            <token id="20" string="the" />
            <token id="21" string="result" />
            <token id="22" string="of" />
            <token id="23" string="community" />
            <token id="24" string="hysteria" />
            <token id="25" string="sparked" />
            <token id="26" string="by" />
            <token id="27" string="bizarre" />
            <token id="28" string="allegations" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="alcoholic" />
            <token id="32" string="mother" />
            <token id="33" string="of" />
            <token id="34" string="one" />
            <token id="35" string="child" />
            <token id="36" string="at" />
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="5" string="the preschool" type="NP">
          <tokens>
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="6" string="jail" type="NP">
          <tokens>
            <token id="8" string="jail" />
          </tokens>
        </chunking>
        <chunking id="7" string="which defense attorneys said was the result of community hysteria sparked by bizarre allegations by the alcoholic mother of one child at the preschool" type="SBAR">
          <tokens>
            <token id="15" string="which" />
            <token id="16" string="defense" />
            <token id="17" string="attorneys" />
            <token id="18" string="said" />
            <token id="19" string="was" />
            <token id="20" string="the" />
            <token id="21" string="result" />
            <token id="22" string="of" />
            <token id="23" string="community" />
            <token id="24" string="hysteria" />
            <token id="25" string="sparked" />
            <token id="26" string="by" />
            <token id="27" string="bizarre" />
            <token id="28" string="allegations" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="alcoholic" />
            <token id="32" string="mother" />
            <token id="33" string="of" />
            <token id="34" string="one" />
            <token id="35" string="child" />
            <token id="36" string="at" />
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="8" string="community hysteria sparked by bizarre allegations by the alcoholic mother of one child at the preschool" type="NP">
          <tokens>
            <token id="23" string="community" />
            <token id="24" string="hysteria" />
            <token id="25" string="sparked" />
            <token id="26" string="by" />
            <token id="27" string="bizarre" />
            <token id="28" string="allegations" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="alcoholic" />
            <token id="32" string="mother" />
            <token id="33" string="of" />
            <token id="34" string="one" />
            <token id="35" string="child" />
            <token id="36" string="at" />
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="9" string="the result" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="result" />
          </tokens>
        </chunking>
        <chunking id="10" string="bizarre allegations" type="NP">
          <tokens>
            <token id="27" string="bizarre" />
            <token id="28" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="11" string="community hysteria" type="NP">
          <tokens>
            <token id="23" string="community" />
            <token id="24" string="hysteria" />
          </tokens>
        </chunking>
        <chunking id="12" string="Raymond Buckey" type="NP">
          <tokens>
            <token id="1" string="Raymond" />
            <token id="2" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="13" string="bail" type="NP">
          <tokens>
            <token id="10" string="bail" />
          </tokens>
        </chunking>
        <chunking id="14" string="defense attorneys" type="NP">
          <tokens>
            <token id="16" string="defense" />
            <token id="17" string="attorneys" />
          </tokens>
        </chunking>
        <chunking id="15" string="one child at the preschool" type="NP">
          <tokens>
            <token id="34" string="one" />
            <token id="35" string="child" />
            <token id="36" string="at" />
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="16" string="the alcoholic mother of one child at the preschool" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="alcoholic" />
            <token id="32" string="mother" />
            <token id="33" string="of" />
            <token id="34" string="one" />
            <token id="35" string="child" />
            <token id="36" string="at" />
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="17" string="the result of community hysteria sparked by bizarre allegations by the alcoholic mother of one child at the preschool" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="result" />
            <token id="22" string="of" />
            <token id="23" string="community" />
            <token id="24" string="hysteria" />
            <token id="25" string="sparked" />
            <token id="26" string="by" />
            <token id="27" string="bizarre" />
            <token id="28" string="allegations" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="alcoholic" />
            <token id="32" string="mother" />
            <token id="33" string="of" />
            <token id="34" string="one" />
            <token id="35" string="child" />
            <token id="36" string="at" />
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="18" string="spent nearly five years in jail without bail during the case , which defense attorneys said was the result of community hysteria sparked by bizarre allegations by the alcoholic mother of one child at the preschool" type="VP">
          <tokens>
            <token id="3" string="spent" />
            <token id="4" string="nearly" />
            <token id="5" string="five" />
            <token id="6" string="years" />
            <token id="7" string="in" />
            <token id="8" string="jail" />
            <token id="9" string="without" />
            <token id="10" string="bail" />
            <token id="11" string="during" />
            <token id="12" string="the" />
            <token id="13" string="case" />
            <token id="14" string="," />
            <token id="15" string="which" />
            <token id="16" string="defense" />
            <token id="17" string="attorneys" />
            <token id="18" string="said" />
            <token id="19" string="was" />
            <token id="20" string="the" />
            <token id="21" string="result" />
            <token id="22" string="of" />
            <token id="23" string="community" />
            <token id="24" string="hysteria" />
            <token id="25" string="sparked" />
            <token id="26" string="by" />
            <token id="27" string="bizarre" />
            <token id="28" string="allegations" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="alcoholic" />
            <token id="32" string="mother" />
            <token id="33" string="of" />
            <token id="34" string="one" />
            <token id="35" string="child" />
            <token id="36" string="at" />
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="19" string="the alcoholic mother" type="NP">
          <tokens>
            <token id="30" string="the" />
            <token id="31" string="alcoholic" />
            <token id="32" string="mother" />
          </tokens>
        </chunking>
        <chunking id="20" string="the case , which defense attorneys said was the result of community hysteria sparked by bizarre allegations by the alcoholic mother of one child at the preschool" type="NP">
          <tokens>
            <token id="12" string="the" />
            <token id="13" string="case" />
            <token id="14" string="," />
            <token id="15" string="which" />
            <token id="16" string="defense" />
            <token id="17" string="attorneys" />
            <token id="18" string="said" />
            <token id="19" string="was" />
            <token id="20" string="the" />
            <token id="21" string="result" />
            <token id="22" string="of" />
            <token id="23" string="community" />
            <token id="24" string="hysteria" />
            <token id="25" string="sparked" />
            <token id="26" string="by" />
            <token id="27" string="bizarre" />
            <token id="28" string="allegations" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="alcoholic" />
            <token id="32" string="mother" />
            <token id="33" string="of" />
            <token id="34" string="one" />
            <token id="35" string="child" />
            <token id="36" string="at" />
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="21" string="was the result of community hysteria sparked by bizarre allegations by the alcoholic mother of one child at the preschool" type="SBAR">
          <tokens>
            <token id="19" string="was" />
            <token id="20" string="the" />
            <token id="21" string="result" />
            <token id="22" string="of" />
            <token id="23" string="community" />
            <token id="24" string="hysteria" />
            <token id="25" string="sparked" />
            <token id="26" string="by" />
            <token id="27" string="bizarre" />
            <token id="28" string="allegations" />
            <token id="29" string="by" />
            <token id="30" string="the" />
            <token id="31" string="alcoholic" />
            <token id="32" string="mother" />
            <token id="33" string="of" />
            <token id="34" string="one" />
            <token id="35" string="child" />
            <token id="36" string="at" />
            <token id="37" string="the" />
            <token id="38" string="preschool" />
          </tokens>
        </chunking>
        <chunking id="22" string="nearly five years" type="NP">
          <tokens>
            <token id="4" string="nearly" />
            <token id="5" string="five" />
            <token id="6" string="years" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Buckey</governor>
          <dependent id="1">Raymond</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">spent</governor>
          <dependent id="2">Buckey</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">spent</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">five</governor>
          <dependent id="4">nearly</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">years</governor>
          <dependent id="5">five</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="3">spent</governor>
          <dependent id="6">years</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">jail</governor>
          <dependent id="7">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">spent</governor>
          <dependent id="8">jail</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">bail</governor>
          <dependent id="9">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">spent</governor>
          <dependent id="10">bail</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">case</governor>
          <dependent id="11">during</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">case</governor>
          <dependent id="12">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">spent</governor>
          <dependent id="13">case</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">said</governor>
          <dependent id="15">which</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="17">attorneys</governor>
          <dependent id="16">defense</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="17">attorneys</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="13">case</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="21">result</governor>
          <dependent id="19">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">result</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="21">result</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">hysteria</governor>
          <dependent id="22">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">hysteria</governor>
          <dependent id="23">community</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="21">result</governor>
          <dependent id="24">hysteria</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="24">hysteria</governor>
          <dependent id="25">sparked</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">allegations</governor>
          <dependent id="26">by</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">allegations</governor>
          <dependent id="27">bizarre</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">sparked</governor>
          <dependent id="28">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">mother</governor>
          <dependent id="29">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">mother</governor>
          <dependent id="30">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="32">mother</governor>
          <dependent id="31">alcoholic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">sparked</governor>
          <dependent id="32">mother</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">child</governor>
          <dependent id="33">of</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="35">child</governor>
          <dependent id="34">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="32">mother</governor>
          <dependent id="35">child</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">preschool</governor>
          <dependent id="36">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="38">preschool</governor>
          <dependent id="37">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="35">child</governor>
          <dependent id="38">preschool</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="34" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="Raymond Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Raymond" />
            <token id="2" string="Buckey" />
          </tokens>
        </entity>
        <entity id="3" string="nearly five years" type="DURATION" score="0.0">
          <tokens>
            <token id="4" string="nearly" />
            <token id="5" string="five" />
            <token id="6" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>Some observers accused then-District Attorney Robert Philibosian of using the spectacular charges to boost his failing re-election campaign against Ira Reiner, who beat him and now runs the district attorney&amp;apost;s office.</content>
      <tokens>
        <token id="1" string="Some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="observers" lemma="observer" stem="observ" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="accused" lemma="accuse" stem="accus" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="then-District" lemma="then-district" stem="then-district" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="Attorney" lemma="Attorney" stem="attornei" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="false" is_refers="false" />
        <token id="6" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="7" string="Philibosian" lemma="Philibosian" stem="philibosian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="using" lemma="use" stem="us" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="spectacular" lemma="spectacular" stem="spectacular" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="boost" lemma="boost" stem="boost" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="failing" lemma="fail" stem="fail" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="re-election" lemma="re-election" stem="re-elect" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="campaign" lemma="campaign" stem="campaign" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="against" lemma="against" stem="against" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="Ira" lemma="Ira" stem="ira" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="beat" lemma="beat" stem="beat" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="28" string="runs" lemma="run" stem="run" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="30" string="district" lemma="district" stem="district" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="attorney" lemma="attorney" stem="attornei" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="office" lemma="office" stem="offic" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT Some) (NNS observers)) (VP (VBD accused) (NP (NP (JJ then-District) (NNP Attorney) (NNP Robert) (NNP Philibosian)) (PP (IN of) (S (VP (VBG using) (NP (DT the) (JJ spectacular) (NNS charges)) (S (VP (TO to) (VP (VB boost) (NP (PRP$ his) (VBG failing) (NN re-election) (NN campaign)) (PP (IN against) (NP (NP (NNP Ira) (NNP Reiner)) (, ,) (SBAR (WHNP (WP who)) (S (VP (VP (VBD beat) (NP (PRP him))) (CC and) (VP (ADVP (RB now)) (VBZ runs) (NP (NP (DT the) (NN district) (NN attorney) (POS 's)) (NN office)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="beat him" type="VP">
          <tokens>
            <token id="24" string="beat" />
            <token id="25" string="him" />
          </tokens>
        </chunking>
        <chunking id="2" string="his failing re-election campaign" type="NP">
          <tokens>
            <token id="15" string="his" />
            <token id="16" string="failing" />
            <token id="17" string="re-election" />
            <token id="18" string="campaign" />
          </tokens>
        </chunking>
        <chunking id="3" string="now runs the district attorney 's office" type="VP">
          <tokens>
            <token id="27" string="now" />
            <token id="28" string="runs" />
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
            <token id="33" string="office" />
          </tokens>
        </chunking>
        <chunking id="4" string="the spectacular charges" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="spectacular" />
            <token id="12" string="charges" />
          </tokens>
        </chunking>
        <chunking id="5" string="him" type="NP">
          <tokens>
            <token id="25" string="him" />
          </tokens>
        </chunking>
        <chunking id="6" string="Ira Reiner , who beat him and now runs the district attorney 's office" type="NP">
          <tokens>
            <token id="20" string="Ira" />
            <token id="21" string="Reiner" />
            <token id="22" string="," />
            <token id="23" string="who" />
            <token id="24" string="beat" />
            <token id="25" string="him" />
            <token id="26" string="and" />
            <token id="27" string="now" />
            <token id="28" string="runs" />
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
            <token id="33" string="office" />
          </tokens>
        </chunking>
        <chunking id="7" string="who beat him and now runs the district attorney 's office" type="SBAR">
          <tokens>
            <token id="23" string="who" />
            <token id="24" string="beat" />
            <token id="25" string="him" />
            <token id="26" string="and" />
            <token id="27" string="now" />
            <token id="28" string="runs" />
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
            <token id="33" string="office" />
          </tokens>
        </chunking>
        <chunking id="8" string="beat him and now runs the district attorney 's office" type="VP">
          <tokens>
            <token id="24" string="beat" />
            <token id="25" string="him" />
            <token id="26" string="and" />
            <token id="27" string="now" />
            <token id="28" string="runs" />
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
            <token id="33" string="office" />
          </tokens>
        </chunking>
        <chunking id="9" string="then-District Attorney Robert Philibosian" type="NP">
          <tokens>
            <token id="4" string="then-District" />
            <token id="5" string="Attorney" />
            <token id="6" string="Robert" />
            <token id="7" string="Philibosian" />
          </tokens>
        </chunking>
        <chunking id="10" string="boost his failing re-election campaign against Ira Reiner , who beat him and now runs the district attorney 's office" type="VP">
          <tokens>
            <token id="14" string="boost" />
            <token id="15" string="his" />
            <token id="16" string="failing" />
            <token id="17" string="re-election" />
            <token id="18" string="campaign" />
            <token id="19" string="against" />
            <token id="20" string="Ira" />
            <token id="21" string="Reiner" />
            <token id="22" string="," />
            <token id="23" string="who" />
            <token id="24" string="beat" />
            <token id="25" string="him" />
            <token id="26" string="and" />
            <token id="27" string="now" />
            <token id="28" string="runs" />
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
            <token id="33" string="office" />
          </tokens>
        </chunking>
        <chunking id="11" string="to boost his failing re-election campaign against Ira Reiner , who beat him and now runs the district attorney 's office" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="boost" />
            <token id="15" string="his" />
            <token id="16" string="failing" />
            <token id="17" string="re-election" />
            <token id="18" string="campaign" />
            <token id="19" string="against" />
            <token id="20" string="Ira" />
            <token id="21" string="Reiner" />
            <token id="22" string="," />
            <token id="23" string="who" />
            <token id="24" string="beat" />
            <token id="25" string="him" />
            <token id="26" string="and" />
            <token id="27" string="now" />
            <token id="28" string="runs" />
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
            <token id="33" string="office" />
          </tokens>
        </chunking>
        <chunking id="12" string="the district attorney 's" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="Some observers" type="NP">
          <tokens>
            <token id="1" string="Some" />
            <token id="2" string="observers" />
          </tokens>
        </chunking>
        <chunking id="14" string="using the spectacular charges to boost his failing re-election campaign against Ira Reiner , who beat him and now runs the district attorney 's office" type="VP">
          <tokens>
            <token id="9" string="using" />
            <token id="10" string="the" />
            <token id="11" string="spectacular" />
            <token id="12" string="charges" />
            <token id="13" string="to" />
            <token id="14" string="boost" />
            <token id="15" string="his" />
            <token id="16" string="failing" />
            <token id="17" string="re-election" />
            <token id="18" string="campaign" />
            <token id="19" string="against" />
            <token id="20" string="Ira" />
            <token id="21" string="Reiner" />
            <token id="22" string="," />
            <token id="23" string="who" />
            <token id="24" string="beat" />
            <token id="25" string="him" />
            <token id="26" string="and" />
            <token id="27" string="now" />
            <token id="28" string="runs" />
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
            <token id="33" string="office" />
          </tokens>
        </chunking>
        <chunking id="15" string="then-District Attorney Robert Philibosian of using the spectacular charges to boost his failing re-election campaign against Ira Reiner , who beat him and now runs the district attorney 's office" type="NP">
          <tokens>
            <token id="4" string="then-District" />
            <token id="5" string="Attorney" />
            <token id="6" string="Robert" />
            <token id="7" string="Philibosian" />
            <token id="8" string="of" />
            <token id="9" string="using" />
            <token id="10" string="the" />
            <token id="11" string="spectacular" />
            <token id="12" string="charges" />
            <token id="13" string="to" />
            <token id="14" string="boost" />
            <token id="15" string="his" />
            <token id="16" string="failing" />
            <token id="17" string="re-election" />
            <token id="18" string="campaign" />
            <token id="19" string="against" />
            <token id="20" string="Ira" />
            <token id="21" string="Reiner" />
            <token id="22" string="," />
            <token id="23" string="who" />
            <token id="24" string="beat" />
            <token id="25" string="him" />
            <token id="26" string="and" />
            <token id="27" string="now" />
            <token id="28" string="runs" />
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
            <token id="33" string="office" />
          </tokens>
        </chunking>
        <chunking id="16" string="accused then-District Attorney Robert Philibosian of using the spectacular charges to boost his failing re-election campaign against Ira Reiner , who beat him and now runs the district attorney 's office" type="VP">
          <tokens>
            <token id="3" string="accused" />
            <token id="4" string="then-District" />
            <token id="5" string="Attorney" />
            <token id="6" string="Robert" />
            <token id="7" string="Philibosian" />
            <token id="8" string="of" />
            <token id="9" string="using" />
            <token id="10" string="the" />
            <token id="11" string="spectacular" />
            <token id="12" string="charges" />
            <token id="13" string="to" />
            <token id="14" string="boost" />
            <token id="15" string="his" />
            <token id="16" string="failing" />
            <token id="17" string="re-election" />
            <token id="18" string="campaign" />
            <token id="19" string="against" />
            <token id="20" string="Ira" />
            <token id="21" string="Reiner" />
            <token id="22" string="," />
            <token id="23" string="who" />
            <token id="24" string="beat" />
            <token id="25" string="him" />
            <token id="26" string="and" />
            <token id="27" string="now" />
            <token id="28" string="runs" />
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
            <token id="33" string="office" />
          </tokens>
        </chunking>
        <chunking id="17" string="Ira Reiner" type="NP">
          <tokens>
            <token id="20" string="Ira" />
            <token id="21" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="18" string="the district attorney 's office" type="NP">
          <tokens>
            <token id="29" string="the" />
            <token id="30" string="district" />
            <token id="31" string="attorney" />
            <token id="32" string="'s" />
            <token id="33" string="office" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">observers</governor>
          <dependent id="1">Some</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">accused</governor>
          <dependent id="2">observers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">accused</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">Philibosian</governor>
          <dependent id="4">then-District</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Philibosian</governor>
          <dependent id="5">Attorney</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="7">Philibosian</governor>
          <dependent id="6">Robert</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="3">accused</governor>
          <dependent id="7">Philibosian</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">using</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="7">Philibosian</governor>
          <dependent id="9">using</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">charges</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">charges</governor>
          <dependent id="11">spectacular</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">using</governor>
          <dependent id="12">charges</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">boost</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="9">using</governor>
          <dependent id="14">boost</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="18">campaign</governor>
          <dependent id="15">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">campaign</governor>
          <dependent id="16">failing</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">campaign</governor>
          <dependent id="17">re-election</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">boost</governor>
          <dependent id="18">campaign</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">Reiner</governor>
          <dependent id="19">against</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="21">Reiner</governor>
          <dependent id="20">Ira</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">boost</governor>
          <dependent id="21">Reiner</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">beat</governor>
          <dependent id="23">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">Reiner</governor>
          <dependent id="24">beat</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">beat</governor>
          <dependent id="25">him</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">beat</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="28">runs</governor>
          <dependent id="27">now</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">beat</governor>
          <dependent id="28">runs</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">attorney</governor>
          <dependent id="29">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">attorney</governor>
          <dependent id="30">district</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="33">office</governor>
          <dependent id="31">attorney</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">attorney</governor>
          <dependent id="32">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="28">runs</governor>
          <dependent id="33">office</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="27" string="now" />
          </tokens>
        </entity>
        <entity id="2" string="Robert Philibosian" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Robert" />
            <token id="7" string="Philibosian" />
          </tokens>
        </entity>
        <entity id="3" string="Attorney" type="TITLE" score="0.0">
          <tokens>
            <token id="5" string="Attorney" />
          </tokens>
        </entity>
        <entity id="4" string="Ira Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="20" string="Ira" />
            <token id="21" string="Reiner" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>Philibosian, however, insisted he would not have handled the matter differently.</content>
      <tokens>
        <token id="1" string="Philibosian" lemma="Philibosian" stem="philibosian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="however" lemma="however" stem="howev" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="insisted" lemma="insist" stem="insist" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="handled" lemma="handle" stem="handl" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="differently" lemma="differently" stem="differ" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Philibosian)) (, ,) (ADVP (RB however)) (, ,) (VP (VBD insisted) (SBAR (S (NP (PRP he)) (VP (MD would) (RB not) (VP (VB have) (VP (VBN handled) (NP (DT the) (NN matter)) (ADVP (RB differently)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="he would not have handled the matter differently" type="SBAR">
          <tokens>
            <token id="6" string="he" />
            <token id="7" string="would" />
            <token id="8" string="not" />
            <token id="9" string="have" />
            <token id="10" string="handled" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
            <token id="13" string="differently" />
          </tokens>
        </chunking>
        <chunking id="2" string="Philibosian" type="NP">
          <tokens>
            <token id="1" string="Philibosian" />
          </tokens>
        </chunking>
        <chunking id="3" string="insisted he would not have handled the matter differently" type="VP">
          <tokens>
            <token id="5" string="insisted" />
            <token id="6" string="he" />
            <token id="7" string="would" />
            <token id="8" string="not" />
            <token id="9" string="have" />
            <token id="10" string="handled" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
            <token id="13" string="differently" />
          </tokens>
        </chunking>
        <chunking id="4" string="would not have handled the matter differently" type="VP">
          <tokens>
            <token id="7" string="would" />
            <token id="8" string="not" />
            <token id="9" string="have" />
            <token id="10" string="handled" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
            <token id="13" string="differently" />
          </tokens>
        </chunking>
        <chunking id="5" string="he" type="NP">
          <tokens>
            <token id="6" string="he" />
          </tokens>
        </chunking>
        <chunking id="6" string="handled the matter differently" type="VP">
          <tokens>
            <token id="10" string="handled" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
            <token id="13" string="differently" />
          </tokens>
        </chunking>
        <chunking id="7" string="have handled the matter differently" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="handled" />
            <token id="11" string="the" />
            <token id="12" string="matter" />
            <token id="13" string="differently" />
          </tokens>
        </chunking>
        <chunking id="8" string="the matter" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="matter" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">insisted</governor>
          <dependent id="1">Philibosian</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">insisted</governor>
          <dependent id="3">however</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">insisted</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">handled</governor>
          <dependent id="6">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">handled</governor>
          <dependent id="7">would</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="10">handled</governor>
          <dependent id="8">not</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">handled</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">insisted</governor>
          <dependent id="10">handled</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">matter</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="10">handled</governor>
          <dependent id="12">matter</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">handled</governor>
          <dependent id="13">differently</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Philibosian" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Philibosian" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>``Ira Reiner has had that case for five years, and I am not going to take any public criticism directed at me.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Ira" lemma="Ira" stem="ira" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="4" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="had" lemma="have" stem="had" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="10" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="am" lemma="be" stem="am" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="going" lemma="go" stem="go" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="criticism" lemma="criticism" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="directed" lemma="direct" stem="direct" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="me" lemma="I" stem="me" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NNP Ira) (NNP Reiner)) (VP (VBZ has) (VP (VBN had) (NP (NP (DT that) (NN case)) (PP (IN for) (NP (CD five) (NNS years))))))) (, ,) (CC and) (S (NP (PRP I)) (VP (VBP am) (RB not) (VP (VBG going) (S (VP (TO to) (VP (VB take) (NP (NP (DT any) (JJ public) (NN criticism)) (VP (VBN directed) (PP (IN at) (NP (PRP me))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="directed at me" type="VP">
          <tokens>
            <token id="22" string="directed" />
            <token id="23" string="at" />
            <token id="24" string="me" />
          </tokens>
        </chunking>
        <chunking id="2" string="any public criticism" type="NP">
          <tokens>
            <token id="19" string="any" />
            <token id="20" string="public" />
            <token id="21" string="criticism" />
          </tokens>
        </chunking>
        <chunking id="3" string="has had that case for five years" type="VP">
          <tokens>
            <token id="4" string="has" />
            <token id="5" string="had" />
            <token id="6" string="that" />
            <token id="7" string="case" />
            <token id="8" string="for" />
            <token id="9" string="five" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="13" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="take any public criticism directed at me" type="VP">
          <tokens>
            <token id="18" string="take" />
            <token id="19" string="any" />
            <token id="20" string="public" />
            <token id="21" string="criticism" />
            <token id="22" string="directed" />
            <token id="23" string="at" />
            <token id="24" string="me" />
          </tokens>
        </chunking>
        <chunking id="6" string="going to take any public criticism directed at me" type="VP">
          <tokens>
            <token id="16" string="going" />
            <token id="17" string="to" />
            <token id="18" string="take" />
            <token id="19" string="any" />
            <token id="20" string="public" />
            <token id="21" string="criticism" />
            <token id="22" string="directed" />
            <token id="23" string="at" />
            <token id="24" string="me" />
          </tokens>
        </chunking>
        <chunking id="7" string="five years" type="NP">
          <tokens>
            <token id="9" string="five" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="8" string="am not going to take any public criticism directed at me" type="VP">
          <tokens>
            <token id="14" string="am" />
            <token id="15" string="not" />
            <token id="16" string="going" />
            <token id="17" string="to" />
            <token id="18" string="take" />
            <token id="19" string="any" />
            <token id="20" string="public" />
            <token id="21" string="criticism" />
            <token id="22" string="directed" />
            <token id="23" string="at" />
            <token id="24" string="me" />
          </tokens>
        </chunking>
        <chunking id="9" string="that case" type="NP">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="had that case for five years" type="VP">
          <tokens>
            <token id="5" string="had" />
            <token id="6" string="that" />
            <token id="7" string="case" />
            <token id="8" string="for" />
            <token id="9" string="five" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="11" string="to take any public criticism directed at me" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="take" />
            <token id="19" string="any" />
            <token id="20" string="public" />
            <token id="21" string="criticism" />
            <token id="22" string="directed" />
            <token id="23" string="at" />
            <token id="24" string="me" />
          </tokens>
        </chunking>
        <chunking id="12" string="me" type="NP">
          <tokens>
            <token id="24" string="me" />
          </tokens>
        </chunking>
        <chunking id="13" string="that case for five years" type="NP">
          <tokens>
            <token id="6" string="that" />
            <token id="7" string="case" />
            <token id="8" string="for" />
            <token id="9" string="five" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="14" string="any public criticism directed at me" type="NP">
          <tokens>
            <token id="19" string="any" />
            <token id="20" string="public" />
            <token id="21" string="criticism" />
            <token id="22" string="directed" />
            <token id="23" string="at" />
            <token id="24" string="me" />
          </tokens>
        </chunking>
        <chunking id="15" string="Ira Reiner" type="NP">
          <tokens>
            <token id="2" string="Ira" />
            <token id="3" string="Reiner" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="3">Reiner</governor>
          <dependent id="2">Ira</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">had</governor>
          <dependent id="3">Reiner</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">had</governor>
          <dependent id="4">has</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">had</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">case</governor>
          <dependent id="6">that</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">had</governor>
          <dependent id="7">case</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">years</governor>
          <dependent id="8">for</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="10">years</governor>
          <dependent id="9">five</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">case</governor>
          <dependent id="10">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">had</governor>
          <dependent id="12">and</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">going</governor>
          <dependent id="13">I</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">going</governor>
          <dependent id="14">am</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="16">going</governor>
          <dependent id="15">not</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">had</governor>
          <dependent id="16">going</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">take</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">going</governor>
          <dependent id="18">take</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">criticism</governor>
          <dependent id="19">any</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">criticism</governor>
          <dependent id="20">public</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">take</governor>
          <dependent id="21">criticism</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="21">criticism</governor>
          <dependent id="22">directed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">me</governor>
          <dependent id="23">at</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">directed</governor>
          <dependent id="24">me</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Ira Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Ira" />
            <token id="3" string="Reiner" />
          </tokens>
        </entity>
        <entity id="2" string="five years" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="five" />
            <token id="10" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>Let him respond to the criticism,&amp;apost;&amp;apost; said Philibosian, now in private law practice.</content>
      <tokens>
        <token id="1" string="Let" lemma="let" stem="let" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="him" lemma="he" stem="him" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="respond" lemma="respond" stem="respond" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="criticism" lemma="criticism" stem="critic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="Philibosian" lemma="Philibosian" stem="philibosian" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="now" lemma="now" stem="now" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="true" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="law" lemma="law" stem="law" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="practice" lemma="practice" stem="practic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (VP (VB Let) (S (NP (PRP him)) (VP (VB respond) (PP (TO to) (NP (DT the) (NN criticism))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Philibosian)) (, ,) (NP (NP (RB now)) (PP (IN in) (NP (JJ private) (NN law) (NN practice))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="respond to the criticism" type="VP">
          <tokens>
            <token id="3" string="respond" />
            <token id="4" string="to" />
            <token id="5" string="the" />
            <token id="6" string="criticism" />
          </tokens>
        </chunking>
        <chunking id="2" string="private law practice" type="NP">
          <tokens>
            <token id="14" string="private" />
            <token id="15" string="law" />
            <token id="16" string="practice" />
          </tokens>
        </chunking>
        <chunking id="3" string="Philibosian" type="NP">
          <tokens>
            <token id="10" string="Philibosian" />
          </tokens>
        </chunking>
        <chunking id="4" string="now" type="NP">
          <tokens>
            <token id="12" string="now" />
          </tokens>
        </chunking>
        <chunking id="5" string="Philibosian , now in private law practice" type="NP">
          <tokens>
            <token id="10" string="Philibosian" />
            <token id="11" string="," />
            <token id="12" string="now" />
            <token id="13" string="in" />
            <token id="14" string="private" />
            <token id="15" string="law" />
            <token id="16" string="practice" />
          </tokens>
        </chunking>
        <chunking id="6" string="Let him respond to the criticism" type="VP">
          <tokens>
            <token id="1" string="Let" />
            <token id="2" string="him" />
            <token id="3" string="respond" />
            <token id="4" string="to" />
            <token id="5" string="the" />
            <token id="6" string="criticism" />
          </tokens>
        </chunking>
        <chunking id="7" string="the criticism" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="criticism" />
          </tokens>
        </chunking>
        <chunking id="8" string="him" type="NP">
          <tokens>
            <token id="2" string="him" />
          </tokens>
        </chunking>
        <chunking id="9" string="said" type="VP">
          <tokens>
            <token id="9" string="said" />
          </tokens>
        </chunking>
        <chunking id="10" string="now in private law practice" type="NP">
          <tokens>
            <token id="12" string="now" />
            <token id="13" string="in" />
            <token id="14" string="private" />
            <token id="15" string="law" />
            <token id="16" string="practice" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="ccomp">
          <governor id="9">said</governor>
          <dependent id="1">Let</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">respond</governor>
          <dependent id="2">him</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="1">Let</governor>
          <dependent id="3">respond</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">criticism</governor>
          <dependent id="4">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">criticism</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">respond</governor>
          <dependent id="6">criticism</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="9">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="9">said</governor>
          <dependent id="10">Philibosian</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="10">Philibosian</governor>
          <dependent id="12">now</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">practice</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">practice</governor>
          <dependent id="14">private</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">practice</governor>
          <dependent id="15">law</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">now</governor>
          <dependent id="16">practice</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Philibosian" type="PERSON" score="0.0">
          <tokens>
            <token id="10" string="Philibosian" />
          </tokens>
        </entity>
        <entity id="2" string="now" type="DATE" score="0.0">
          <tokens>
            <token id="12" string="now" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="true">
      <content>Also criticized was the decision by investigators to use a private child therapy group, Children&amp;apost;s Institute International, to conduct the original interviews with the children.</content>
      <tokens>
        <token id="1" string="Also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="criticized" lemma="criticize" stem="critic" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="decision" lemma="decision" stem="decis" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="investigators" lemma="investigator" stem="investig" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="use" lemma="use" stem="us" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="private" lemma="private" stem="privat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="therapy" lemma="therapy" stem="therapi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="group" lemma="group" stem="group" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="Children" lemma="Children" stem="children" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="17" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="18" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="19" string="International" lemma="International" stem="internat" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="conduct" lemma="conduct" stem="conduct" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="original" lemma="original" stem="origin" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="interviews" lemma="interview" stem="interview" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (RB Also) (VP (VBN criticized)) (VP (VBD was) (NP (DT the) (NN decision)) (PP (IN by) (NP (NNS investigators))) (S (VP (TO to) (VP (VB use) (S (NP (NP (DT a) (JJ private) (NN child) (NN therapy) (NN group)) (, ,) (NP (NP (NNP Children) (POS 's)) (NNP Institute) (NNP International)) (, ,)) (VP (TO to) (VP (VB conduct)))))))) (NP (NP (DT the) (JJ original) (NNS interviews)) (PP (IN with) (NP (DT the) (NNS children)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="a private child therapy group , Children 's Institute International ," type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="private" />
            <token id="12" string="child" />
            <token id="13" string="therapy" />
            <token id="14" string="group" />
            <token id="15" string="," />
            <token id="16" string="Children" />
            <token id="17" string="'s" />
            <token id="18" string="Institute" />
            <token id="19" string="International" />
            <token id="20" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="the original interviews with the children" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="original" />
            <token id="25" string="interviews" />
            <token id="26" string="with" />
            <token id="27" string="the" />
            <token id="28" string="children" />
          </tokens>
        </chunking>
        <chunking id="3" string="the decision" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="decision" />
          </tokens>
        </chunking>
        <chunking id="4" string="use a private child therapy group , Children 's Institute International , to conduct" type="VP">
          <tokens>
            <token id="9" string="use" />
            <token id="10" string="a" />
            <token id="11" string="private" />
            <token id="12" string="child" />
            <token id="13" string="therapy" />
            <token id="14" string="group" />
            <token id="15" string="," />
            <token id="16" string="Children" />
            <token id="17" string="'s" />
            <token id="18" string="Institute" />
            <token id="19" string="International" />
            <token id="20" string="," />
            <token id="21" string="to" />
            <token id="22" string="conduct" />
          </tokens>
        </chunking>
        <chunking id="5" string="a private child therapy group" type="NP">
          <tokens>
            <token id="10" string="a" />
            <token id="11" string="private" />
            <token id="12" string="child" />
            <token id="13" string="therapy" />
            <token id="14" string="group" />
          </tokens>
        </chunking>
        <chunking id="6" string="investigators" type="NP">
          <tokens>
            <token id="7" string="investigators" />
          </tokens>
        </chunking>
        <chunking id="7" string="Children 's Institute International" type="NP">
          <tokens>
            <token id="16" string="Children" />
            <token id="17" string="'s" />
            <token id="18" string="Institute" />
            <token id="19" string="International" />
          </tokens>
        </chunking>
        <chunking id="8" string="was the decision by investigators to use a private child therapy group , Children 's Institute International , to conduct" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="decision" />
            <token id="6" string="by" />
            <token id="7" string="investigators" />
            <token id="8" string="to" />
            <token id="9" string="use" />
            <token id="10" string="a" />
            <token id="11" string="private" />
            <token id="12" string="child" />
            <token id="13" string="therapy" />
            <token id="14" string="group" />
            <token id="15" string="," />
            <token id="16" string="Children" />
            <token id="17" string="'s" />
            <token id="18" string="Institute" />
            <token id="19" string="International" />
            <token id="20" string="," />
            <token id="21" string="to" />
            <token id="22" string="conduct" />
          </tokens>
        </chunking>
        <chunking id="9" string="conduct" type="VP">
          <tokens>
            <token id="22" string="conduct" />
          </tokens>
        </chunking>
        <chunking id="10" string="the children" type="NP">
          <tokens>
            <token id="27" string="the" />
            <token id="28" string="children" />
          </tokens>
        </chunking>
        <chunking id="11" string="Children 's" type="NP">
          <tokens>
            <token id="16" string="Children" />
            <token id="17" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="to conduct" type="VP">
          <tokens>
            <token id="21" string="to" />
            <token id="22" string="conduct" />
          </tokens>
        </chunking>
        <chunking id="13" string="to use a private child therapy group , Children 's Institute International , to conduct" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="use" />
            <token id="10" string="a" />
            <token id="11" string="private" />
            <token id="12" string="child" />
            <token id="13" string="therapy" />
            <token id="14" string="group" />
            <token id="15" string="," />
            <token id="16" string="Children" />
            <token id="17" string="'s" />
            <token id="18" string="Institute" />
            <token id="19" string="International" />
            <token id="20" string="," />
            <token id="21" string="to" />
            <token id="22" string="conduct" />
          </tokens>
        </chunking>
        <chunking id="14" string="the original interviews" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="original" />
            <token id="25" string="interviews" />
          </tokens>
        </chunking>
        <chunking id="15" string="criticized" type="VP">
          <tokens>
            <token id="2" string="criticized" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="2">criticized</governor>
          <dependent id="1">Also</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">criticized</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">decision</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">decision</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="2">criticized</governor>
          <dependent id="5">decision</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">investigators</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">decision</governor>
          <dependent id="7">investigators</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">use</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">decision</governor>
          <dependent id="9">use</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">group</governor>
          <dependent id="10">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">group</governor>
          <dependent id="11">private</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">group</governor>
          <dependent id="12">child</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="14">group</governor>
          <dependent id="13">therapy</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="9">use</governor>
          <dependent id="14">group</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">International</governor>
          <dependent id="16">Children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">Children</governor>
          <dependent id="17">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="19">International</governor>
          <dependent id="18">Institute</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="14">group</governor>
          <dependent id="19">International</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">conduct</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="9">use</governor>
          <dependent id="22">conduct</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">interviews</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="25">interviews</governor>
          <dependent id="24">original</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="2">criticized</governor>
          <dependent id="25">interviews</dependent>
        </dependency>
        <dependency type="case">
          <governor id="28">children</governor>
          <dependent id="26">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">children</governor>
          <dependent id="27">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">interviews</governor>
          <dependent id="28">children</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Children 's Institute International" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="16" string="Children" />
            <token id="17" string="'s" />
            <token id="18" string="Institute" />
            <token id="19" string="International" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="false">
      <content>Defense attorneys maintained that questions by the institute&amp;apost;s researchers were leading and prejudicial.</content>
      <tokens>
        <token id="1" string="Defense" lemma="Defense" stem="defens" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="attorneys" lemma="attorney" stem="attornei" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="maintained" lemma="maintain" stem="maintain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="institute" lemma="institute" stem="institut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="researchers" lemma="researcher" stem="research" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="leading" lemma="lead" stem="lead" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="prejudicial" lemma="prejudicial" stem="prejudici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Defense) (NNS attorneys)) (VP (VBD maintained) (SBAR (IN that) (S (NP (NP (NNS questions)) (PP (IN by) (NP (NP (DT the) (NN institute) (POS 's)) (NNS researchers)))) (VP (VBD were) (UCP (VP (VBG leading)) (CC and) (ADJP (JJ prejudicial))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the institute 's" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="institute" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="prejudicial" type="ADJP">
          <tokens>
            <token id="14" string="prejudicial" />
          </tokens>
        </chunking>
        <chunking id="3" string="questions by the institute 's researchers" type="NP">
          <tokens>
            <token id="5" string="questions" />
            <token id="6" string="by" />
            <token id="7" string="the" />
            <token id="8" string="institute" />
            <token id="9" string="'s" />
            <token id="10" string="researchers" />
          </tokens>
        </chunking>
        <chunking id="4" string="were leading and prejudicial" type="VP">
          <tokens>
            <token id="11" string="were" />
            <token id="12" string="leading" />
            <token id="13" string="and" />
            <token id="14" string="prejudicial" />
          </tokens>
        </chunking>
        <chunking id="5" string="leading" type="VP">
          <tokens>
            <token id="12" string="leading" />
          </tokens>
        </chunking>
        <chunking id="6" string="maintained that questions by the institute 's researchers were leading and prejudicial" type="VP">
          <tokens>
            <token id="3" string="maintained" />
            <token id="4" string="that" />
            <token id="5" string="questions" />
            <token id="6" string="by" />
            <token id="7" string="the" />
            <token id="8" string="institute" />
            <token id="9" string="'s" />
            <token id="10" string="researchers" />
            <token id="11" string="were" />
            <token id="12" string="leading" />
            <token id="13" string="and" />
            <token id="14" string="prejudicial" />
          </tokens>
        </chunking>
        <chunking id="7" string="questions" type="NP">
          <tokens>
            <token id="5" string="questions" />
          </tokens>
        </chunking>
        <chunking id="8" string="that questions by the institute 's researchers were leading and prejudicial" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="questions" />
            <token id="6" string="by" />
            <token id="7" string="the" />
            <token id="8" string="institute" />
            <token id="9" string="'s" />
            <token id="10" string="researchers" />
            <token id="11" string="were" />
            <token id="12" string="leading" />
            <token id="13" string="and" />
            <token id="14" string="prejudicial" />
          </tokens>
        </chunking>
        <chunking id="9" string="Defense attorneys" type="NP">
          <tokens>
            <token id="1" string="Defense" />
            <token id="2" string="attorneys" />
          </tokens>
        </chunking>
        <chunking id="10" string="the institute 's researchers" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="institute" />
            <token id="9" string="'s" />
            <token id="10" string="researchers" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">attorneys</governor>
          <dependent id="1">Defense</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">maintained</governor>
          <dependent id="2">attorneys</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">maintained</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">leading</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">leading</governor>
          <dependent id="5">questions</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">researchers</governor>
          <dependent id="6">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">institute</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="10">researchers</governor>
          <dependent id="8">institute</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">institute</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">questions</governor>
          <dependent id="10">researchers</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">leading</governor>
          <dependent id="11">were</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">maintained</governor>
          <dependent id="12">leading</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">leading</governor>
          <dependent id="13">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">leading</governor>
          <dependent id="14">prejudicial</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="false">
      <content>Jurors agreed.</content>
      <tokens>
        <token id="1" string="Jurors" lemma="Jurors" stem="juror" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="agreed" lemma="agree" stem="agre" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Jurors)) (VP (VBD agreed)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="agreed" type="VP">
          <tokens>
            <token id="2" string="agreed" />
          </tokens>
        </chunking>
        <chunking id="2" string="Jurors" type="NP">
          <tokens>
            <token id="1" string="Jurors" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">agreed</governor>
          <dependent id="1">Jurors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">agreed</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>``We never got the children&amp;apost;s stories in their own words,&amp;apost;&amp;apost; said juror John Breese.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="got" lemma="get" stem="got" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="stories" lemma="story" stem="stori" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="words" lemma="word" stem="word" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="juror" lemma="juror" stem="juror" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="18" string="Breese" lemma="Breese" stem="brees" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP We)) (ADVP (RB never)) (VP (VBD got) (NP (NP (DT the) (NNS children) (POS 's)) (NNS stories)) (PP (IN in) (NP (PRP$ their) (JJ own) (NNS words))))) (, ,) ('' '') (VP (VBD said) (NP (NN juror))) (NP (NNP John) (NNP Breese)) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the children 's" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="children" />
            <token id="7" string="'s" />
          </tokens>
        </chunking>
        <chunking id="2" string="their own words" type="NP">
          <tokens>
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
          </tokens>
        </chunking>
        <chunking id="3" string="juror" type="NP">
          <tokens>
            <token id="16" string="juror" />
          </tokens>
        </chunking>
        <chunking id="4" string="the children 's stories" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="children" />
            <token id="7" string="'s" />
            <token id="8" string="stories" />
          </tokens>
        </chunking>
        <chunking id="5" string="John Breese" type="NP">
          <tokens>
            <token id="17" string="John" />
            <token id="18" string="Breese" />
          </tokens>
        </chunking>
        <chunking id="6" string="said juror" type="VP">
          <tokens>
            <token id="15" string="said" />
            <token id="16" string="juror" />
          </tokens>
        </chunking>
        <chunking id="7" string="We" type="NP">
          <tokens>
            <token id="2" string="We" />
          </tokens>
        </chunking>
        <chunking id="8" string="got the children 's stories in their own words" type="VP">
          <tokens>
            <token id="4" string="got" />
            <token id="5" string="the" />
            <token id="6" string="children" />
            <token id="7" string="'s" />
            <token id="8" string="stories" />
            <token id="9" string="in" />
            <token id="10" string="their" />
            <token id="11" string="own" />
            <token id="12" string="words" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="4">got</governor>
          <dependent id="2">We</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="4">got</governor>
          <dependent id="3">never</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="15">said</governor>
          <dependent id="4">got</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">children</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="8">stories</governor>
          <dependent id="6">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">children</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="4">got</governor>
          <dependent id="8">stories</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">words</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">words</governor>
          <dependent id="10">their</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">words</governor>
          <dependent id="11">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">got</governor>
          <dependent id="12">words</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="15">said</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="15">said</governor>
          <dependent id="16">juror</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Breese</governor>
          <dependent id="17">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="15">said</governor>
          <dependent id="18">Breese</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Breese" type="PERSON" score="0.0">
          <tokens>
            <token id="17" string="John" />
            <token id="18" string="Breese" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="true">
      <content>Children&amp;apost;s Institute officials didn&amp;apost;t immediately return telephone calls seeking comment.</content>
      <tokens>
        <token id="1" string="Children" lemma="Children" stem="children" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="3" string="Institute" lemma="Institute" stem="institut" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="4" string="officials" lemma="official" stem="offici" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="immediately" lemma="immediately" stem="immedi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="return" lemma="return" stem="return" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="telephone" lemma="telephone" stem="telephon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="calls" lemma="call" stem="call" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="seeking" lemma="seek" stem="seek" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="comment" lemma="comment" stem="comment" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNP Children) (POS 's)) (NNP Institute) (NNS officials)) (VP (VBD did) (RB n't) (ADVP (RB immediately)) (VP (VB return) (NP (NN telephone) (NNS calls)) (S (VP (VBG seeking) (NP (NN comment)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Children 's Institute officials" type="NP">
          <tokens>
            <token id="1" string="Children" />
            <token id="2" string="'s" />
            <token id="3" string="Institute" />
            <token id="4" string="officials" />
          </tokens>
        </chunking>
        <chunking id="2" string="telephone calls" type="NP">
          <tokens>
            <token id="9" string="telephone" />
            <token id="10" string="calls" />
          </tokens>
        </chunking>
        <chunking id="3" string="Children 's" type="NP">
          <tokens>
            <token id="1" string="Children" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="did n't immediately return telephone calls seeking comment" type="VP">
          <tokens>
            <token id="5" string="did" />
            <token id="6" string="n't" />
            <token id="7" string="immediately" />
            <token id="8" string="return" />
            <token id="9" string="telephone" />
            <token id="10" string="calls" />
            <token id="11" string="seeking" />
            <token id="12" string="comment" />
          </tokens>
        </chunking>
        <chunking id="5" string="return telephone calls seeking comment" type="VP">
          <tokens>
            <token id="8" string="return" />
            <token id="9" string="telephone" />
            <token id="10" string="calls" />
            <token id="11" string="seeking" />
            <token id="12" string="comment" />
          </tokens>
        </chunking>
        <chunking id="6" string="seeking comment" type="VP">
          <tokens>
            <token id="11" string="seeking" />
            <token id="12" string="comment" />
          </tokens>
        </chunking>
        <chunking id="7" string="comment" type="NP">
          <tokens>
            <token id="12" string="comment" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="4">officials</governor>
          <dependent id="1">Children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Children</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="4">officials</governor>
          <dependent id="3">Institute</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">return</governor>
          <dependent id="4">officials</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">return</governor>
          <dependent id="5">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">return</governor>
          <dependent id="6">n't</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">return</governor>
          <dependent id="7">immediately</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">return</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">calls</governor>
          <dependent id="9">telephone</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">return</governor>
          <dependent id="10">calls</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="8">return</governor>
          <dependent id="11">seeking</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">seeking</governor>
          <dependent id="12">comment</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Children 's Institute" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Children" />
            <token id="2" string="'s" />
            <token id="3" string="Institute" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="true">
      <content>Originally, there were seven defendants, including Raymond Buckey&amp;apost;s sister, Peggy Ann Buckey, and Virginia McMartin, the founder of the school, mother of Mrs. Buckey and grandmother of Raymond Buckey.</content>
      <tokens>
        <token id="1" string="Originally" lemma="originally" stem="origin" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="seven" lemma="seven" stem="seven" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="6" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Raymond" lemma="Raymond" stem="raymond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="sister" lemma="sister" stem="sister" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="Peggy" lemma="Peggy" stem="peggi" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="15" string="Ann" lemma="Ann" stem="ann" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="16" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Virginia" lemma="Virginia" stem="virginia" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="20" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="founder" lemma="founder" stem="founder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="mother" lemma="mother" stem="mother" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Mrs." lemma="Mrs." stem="mrs." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="32" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="grandmother" lemma="grandmother" stem="grandmoth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="35" string="Raymond" lemma="Raymond" stem="raymond" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="36" string="Buckey" lemma="Buckey" stem="buckei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="37" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (ADVP (RB Originally)) (, ,) (NP (EX there)) (VP (VBD were) (NP (NP (CD seven) (NNS defendants)) (, ,) (PP (VBG including) (NP (NP (NP (NP (NP (NNP Raymond) (NNP Buckey) (POS 's)) (NN sister)) (, ,) (NP (NNP Peggy) (NNP Ann) (NNP Buckey)) (, ,)) (CC and) (NP (NP (NNP Virginia) (NNP McMartin)) (, ,) (NP (NP (DT the) (NN founder)) (PP (IN of) (NP (DT the) (NN school)))))) (, ,) (NP (NP (NN mother)) (PP (IN of) (NP (NNP Mrs.) (NNP Buckey)))) (CC and) (NP (NP (NN grandmother)) (PP (IN of) (NP (NNP Raymond) (NNP Buckey)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Raymond Buckey 's sister , Peggy Ann Buckey , and Virginia McMartin , the founder of the school" type="NP">
          <tokens>
            <token id="9" string="Raymond" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
            <token id="12" string="sister" />
            <token id="13" string="," />
            <token id="14" string="Peggy" />
            <token id="15" string="Ann" />
            <token id="16" string="Buckey" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="Virginia" />
            <token id="20" string="McMartin" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="founder" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="school" />
          </tokens>
        </chunking>
        <chunking id="2" string="grandmother of Raymond Buckey" type="NP">
          <tokens>
            <token id="33" string="grandmother" />
            <token id="34" string="of" />
            <token id="35" string="Raymond" />
            <token id="36" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="3" string="Raymond Buckey 's sister , Peggy Ann Buckey , and Virginia McMartin , the founder of the school , mother of Mrs. Buckey and grandmother of Raymond Buckey" type="NP">
          <tokens>
            <token id="9" string="Raymond" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
            <token id="12" string="sister" />
            <token id="13" string="," />
            <token id="14" string="Peggy" />
            <token id="15" string="Ann" />
            <token id="16" string="Buckey" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="Virginia" />
            <token id="20" string="McMartin" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="founder" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="school" />
            <token id="27" string="," />
            <token id="28" string="mother" />
            <token id="29" string="of" />
            <token id="30" string="Mrs." />
            <token id="31" string="Buckey" />
            <token id="32" string="and" />
            <token id="33" string="grandmother" />
            <token id="34" string="of" />
            <token id="35" string="Raymond" />
            <token id="36" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="4" string="seven defendants" type="NP">
          <tokens>
            <token id="5" string="seven" />
            <token id="6" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="5" string="Virginia McMartin" type="NP">
          <tokens>
            <token id="19" string="Virginia" />
            <token id="20" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="6" string="grandmother" type="NP">
          <tokens>
            <token id="33" string="grandmother" />
          </tokens>
        </chunking>
        <chunking id="7" string="were seven defendants , including Raymond Buckey 's sister , Peggy Ann Buckey , and Virginia McMartin , the founder of the school , mother of Mrs. Buckey and grandmother of Raymond Buckey" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="seven" />
            <token id="6" string="defendants" />
            <token id="7" string="," />
            <token id="8" string="including" />
            <token id="9" string="Raymond" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
            <token id="12" string="sister" />
            <token id="13" string="," />
            <token id="14" string="Peggy" />
            <token id="15" string="Ann" />
            <token id="16" string="Buckey" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="Virginia" />
            <token id="20" string="McMartin" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="founder" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="school" />
            <token id="27" string="," />
            <token id="28" string="mother" />
            <token id="29" string="of" />
            <token id="30" string="Mrs." />
            <token id="31" string="Buckey" />
            <token id="32" string="and" />
            <token id="33" string="grandmother" />
            <token id="34" string="of" />
            <token id="35" string="Raymond" />
            <token id="36" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="8" string="Raymond Buckey" type="NP">
          <tokens>
            <token id="35" string="Raymond" />
            <token id="36" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="9" string="there" type="NP">
          <tokens>
            <token id="3" string="there" />
          </tokens>
        </chunking>
        <chunking id="10" string="mother" type="NP">
          <tokens>
            <token id="28" string="mother" />
          </tokens>
        </chunking>
        <chunking id="11" string="Raymond Buckey 's" type="NP">
          <tokens>
            <token id="9" string="Raymond" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="12" string="the school" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="school" />
          </tokens>
        </chunking>
        <chunking id="13" string="Peggy Ann Buckey" type="NP">
          <tokens>
            <token id="14" string="Peggy" />
            <token id="15" string="Ann" />
            <token id="16" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="14" string="mother of Mrs. Buckey" type="NP">
          <tokens>
            <token id="28" string="mother" />
            <token id="29" string="of" />
            <token id="30" string="Mrs." />
            <token id="31" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="15" string="Raymond Buckey 's sister , Peggy Ann Buckey ," type="NP">
          <tokens>
            <token id="9" string="Raymond" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
            <token id="12" string="sister" />
            <token id="13" string="," />
            <token id="14" string="Peggy" />
            <token id="15" string="Ann" />
            <token id="16" string="Buckey" />
            <token id="17" string="," />
          </tokens>
        </chunking>
        <chunking id="16" string="Mrs. Buckey" type="NP">
          <tokens>
            <token id="30" string="Mrs." />
            <token id="31" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="17" string="seven defendants , including Raymond Buckey 's sister , Peggy Ann Buckey , and Virginia McMartin , the founder of the school , mother of Mrs. Buckey and grandmother of Raymond Buckey" type="NP">
          <tokens>
            <token id="5" string="seven" />
            <token id="6" string="defendants" />
            <token id="7" string="," />
            <token id="8" string="including" />
            <token id="9" string="Raymond" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
            <token id="12" string="sister" />
            <token id="13" string="," />
            <token id="14" string="Peggy" />
            <token id="15" string="Ann" />
            <token id="16" string="Buckey" />
            <token id="17" string="," />
            <token id="18" string="and" />
            <token id="19" string="Virginia" />
            <token id="20" string="McMartin" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="founder" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="school" />
            <token id="27" string="," />
            <token id="28" string="mother" />
            <token id="29" string="of" />
            <token id="30" string="Mrs." />
            <token id="31" string="Buckey" />
            <token id="32" string="and" />
            <token id="33" string="grandmother" />
            <token id="34" string="of" />
            <token id="35" string="Raymond" />
            <token id="36" string="Buckey" />
          </tokens>
        </chunking>
        <chunking id="18" string="Virginia McMartin , the founder of the school" type="NP">
          <tokens>
            <token id="19" string="Virginia" />
            <token id="20" string="McMartin" />
            <token id="21" string="," />
            <token id="22" string="the" />
            <token id="23" string="founder" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="school" />
          </tokens>
        </chunking>
        <chunking id="19" string="the founder" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="founder" />
          </tokens>
        </chunking>
        <chunking id="20" string="the founder of the school" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="founder" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="school" />
          </tokens>
        </chunking>
        <chunking id="21" string="Raymond Buckey 's sister" type="NP">
          <tokens>
            <token id="9" string="Raymond" />
            <token id="10" string="Buckey" />
            <token id="11" string="'s" />
            <token id="12" string="sister" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="4">were</governor>
          <dependent id="1">Originally</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="4">were</governor>
          <dependent id="3">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="6">defendants</governor>
          <dependent id="5">seven</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">were</governor>
          <dependent id="6">defendants</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">sister</governor>
          <dependent id="8">including</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Buckey</governor>
          <dependent id="9">Raymond</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">sister</governor>
          <dependent id="10">Buckey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Buckey</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">defendants</governor>
          <dependent id="12">sister</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Buckey</governor>
          <dependent id="14">Peggy</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Buckey</governor>
          <dependent id="15">Ann</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="12">sister</governor>
          <dependent id="16">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">sister</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">McMartin</governor>
          <dependent id="19">Virginia</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">sister</governor>
          <dependent id="20">McMartin</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">founder</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="20">McMartin</governor>
          <dependent id="23">founder</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">school</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">school</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">founder</governor>
          <dependent id="26">school</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">sister</governor>
          <dependent id="28">mother</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">Buckey</governor>
          <dependent id="29">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">Buckey</governor>
          <dependent id="30">Mrs.</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">mother</governor>
          <dependent id="31">Buckey</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">sister</governor>
          <dependent id="32">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">sister</governor>
          <dependent id="33">grandmother</dependent>
        </dependency>
        <dependency type="case">
          <governor id="36">Buckey</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="36">Buckey</governor>
          <dependent id="35">Raymond</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">grandmother</governor>
          <dependent id="36">Buckey</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Buckey" />
          </tokens>
        </entity>
        <entity id="2" string="Peggy Ann Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="14" string="Peggy" />
            <token id="15" string="Ann" />
            <token id="16" string="Buckey" />
          </tokens>
        </entity>
        <entity id="3" string="Virginia McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Virginia" />
            <token id="20" string="McMartin" />
          </tokens>
        </entity>
        <entity id="4" string="seven" type="NUMBER" score="0.0">
          <tokens>
            <token id="5" string="seven" />
          </tokens>
        </entity>
        <entity id="5" string="Raymond Buckey" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="Raymond" />
            <token id="10" string="Buckey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="37" has_coreference="true">
      <content>Hundreds of allegations of child molestation were filed in the case, which gained worldwide attention with its tales of underground tunnels at the school and Satanic rituals.</content>
      <tokens>
        <token id="1" string="Hundreds" lemma="hundred" stem="hundr" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="allegations" lemma="allegation" stem="alleg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="child" lemma="child" stem="child" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="molestation" lemma="molestation" stem="molest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="filed" lemma="file" stem="file" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="gained" lemma="gain" stem="gain" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="15" string="worldwide" lemma="worldwide" stem="worldwid" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="attention" lemma="attention" stem="attent" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="tales" lemma="tale" stem="tale" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="underground" lemma="underground" stem="underground" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="tunnels" lemma="tunnel" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="25" string="school" lemma="school" stem="school" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="26" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="Satanic" lemma="satanic" stem="satan" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="28" string="rituals" lemma="ritual" stem="ritual" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="29" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NNS Hundreds)) (PP (IN of) (NP (NP (NNS allegations)) (PP (IN of) (NP (NN child) (NN molestation)))))) (VP (VBD were) (VP (VBN filed) (PP (IN in) (NP (NP (DT the) (NN case)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD gained) (NP (JJ worldwide) (NN attention)) (PP (IN with) (NP (NP (PRP$ its) (NNS tales)) (PP (IN of) (NP (JJ underground) (NNS tunnels))))) (PP (IN at) (NP (NP (DT the) (NN school)) (CC and) (NP (JJ Satanic) (NNS rituals))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="worldwide attention" type="NP">
          <tokens>
            <token id="15" string="worldwide" />
            <token id="16" string="attention" />
          </tokens>
        </chunking>
        <chunking id="2" string="the case , which gained worldwide attention with its tales of underground tunnels at the school and Satanic rituals" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="case" />
            <token id="12" string="," />
            <token id="13" string="which" />
            <token id="14" string="gained" />
            <token id="15" string="worldwide" />
            <token id="16" string="attention" />
            <token id="17" string="with" />
            <token id="18" string="its" />
            <token id="19" string="tales" />
            <token id="20" string="of" />
            <token id="21" string="underground" />
            <token id="22" string="tunnels" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
            <token id="26" string="and" />
            <token id="27" string="Satanic" />
            <token id="28" string="rituals" />
          </tokens>
        </chunking>
        <chunking id="3" string="the case" type="NP">
          <tokens>
            <token id="10" string="the" />
            <token id="11" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="its tales" type="NP">
          <tokens>
            <token id="18" string="its" />
            <token id="19" string="tales" />
          </tokens>
        </chunking>
        <chunking id="5" string="allegations of child molestation" type="NP">
          <tokens>
            <token id="3" string="allegations" />
            <token id="4" string="of" />
            <token id="5" string="child" />
            <token id="6" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="6" string="child molestation" type="NP">
          <tokens>
            <token id="5" string="child" />
            <token id="6" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="7" string="which gained worldwide attention with its tales of underground tunnels at the school and Satanic rituals" type="SBAR">
          <tokens>
            <token id="13" string="which" />
            <token id="14" string="gained" />
            <token id="15" string="worldwide" />
            <token id="16" string="attention" />
            <token id="17" string="with" />
            <token id="18" string="its" />
            <token id="19" string="tales" />
            <token id="20" string="of" />
            <token id="21" string="underground" />
            <token id="22" string="tunnels" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
            <token id="26" string="and" />
            <token id="27" string="Satanic" />
            <token id="28" string="rituals" />
          </tokens>
        </chunking>
        <chunking id="8" string="filed in the case , which gained worldwide attention with its tales of underground tunnels at the school and Satanic rituals" type="VP">
          <tokens>
            <token id="8" string="filed" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="case" />
            <token id="12" string="," />
            <token id="13" string="which" />
            <token id="14" string="gained" />
            <token id="15" string="worldwide" />
            <token id="16" string="attention" />
            <token id="17" string="with" />
            <token id="18" string="its" />
            <token id="19" string="tales" />
            <token id="20" string="of" />
            <token id="21" string="underground" />
            <token id="22" string="tunnels" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
            <token id="26" string="and" />
            <token id="27" string="Satanic" />
            <token id="28" string="rituals" />
          </tokens>
        </chunking>
        <chunking id="9" string="its tales of underground tunnels" type="NP">
          <tokens>
            <token id="18" string="its" />
            <token id="19" string="tales" />
            <token id="20" string="of" />
            <token id="21" string="underground" />
            <token id="22" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="10" string="the school and Satanic rituals" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="school" />
            <token id="26" string="and" />
            <token id="27" string="Satanic" />
            <token id="28" string="rituals" />
          </tokens>
        </chunking>
        <chunking id="11" string="the school" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="school" />
          </tokens>
        </chunking>
        <chunking id="12" string="gained worldwide attention with its tales of underground tunnels at the school and Satanic rituals" type="VP">
          <tokens>
            <token id="14" string="gained" />
            <token id="15" string="worldwide" />
            <token id="16" string="attention" />
            <token id="17" string="with" />
            <token id="18" string="its" />
            <token id="19" string="tales" />
            <token id="20" string="of" />
            <token id="21" string="underground" />
            <token id="22" string="tunnels" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
            <token id="26" string="and" />
            <token id="27" string="Satanic" />
            <token id="28" string="rituals" />
          </tokens>
        </chunking>
        <chunking id="13" string="allegations" type="NP">
          <tokens>
            <token id="3" string="allegations" />
          </tokens>
        </chunking>
        <chunking id="14" string="Satanic rituals" type="NP">
          <tokens>
            <token id="27" string="Satanic" />
            <token id="28" string="rituals" />
          </tokens>
        </chunking>
        <chunking id="15" string="Hundreds of allegations of child molestation" type="NP">
          <tokens>
            <token id="1" string="Hundreds" />
            <token id="2" string="of" />
            <token id="3" string="allegations" />
            <token id="4" string="of" />
            <token id="5" string="child" />
            <token id="6" string="molestation" />
          </tokens>
        </chunking>
        <chunking id="16" string="were filed in the case , which gained worldwide attention with its tales of underground tunnels at the school and Satanic rituals" type="VP">
          <tokens>
            <token id="7" string="were" />
            <token id="8" string="filed" />
            <token id="9" string="in" />
            <token id="10" string="the" />
            <token id="11" string="case" />
            <token id="12" string="," />
            <token id="13" string="which" />
            <token id="14" string="gained" />
            <token id="15" string="worldwide" />
            <token id="16" string="attention" />
            <token id="17" string="with" />
            <token id="18" string="its" />
            <token id="19" string="tales" />
            <token id="20" string="of" />
            <token id="21" string="underground" />
            <token id="22" string="tunnels" />
            <token id="23" string="at" />
            <token id="24" string="the" />
            <token id="25" string="school" />
            <token id="26" string="and" />
            <token id="27" string="Satanic" />
            <token id="28" string="rituals" />
          </tokens>
        </chunking>
        <chunking id="17" string="Hundreds" type="NP">
          <tokens>
            <token id="1" string="Hundreds" />
          </tokens>
        </chunking>
        <chunking id="18" string="underground tunnels" type="NP">
          <tokens>
            <token id="21" string="underground" />
            <token id="22" string="tunnels" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubjpass">
          <governor id="8">filed</governor>
          <dependent id="1">Hundreds</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">allegations</governor>
          <dependent id="2">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">Hundreds</governor>
          <dependent id="3">allegations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">molestation</governor>
          <dependent id="4">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">molestation</governor>
          <dependent id="5">child</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">allegations</governor>
          <dependent id="6">molestation</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="8">filed</governor>
          <dependent id="7">were</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">filed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">case</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="11">case</governor>
          <dependent id="10">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">filed</governor>
          <dependent id="11">case</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">gained</governor>
          <dependent id="13">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="11">case</governor>
          <dependent id="14">gained</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">attention</governor>
          <dependent id="15">worldwide</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">gained</governor>
          <dependent id="16">attention</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">tales</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="19">tales</governor>
          <dependent id="18">its</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">gained</governor>
          <dependent id="19">tales</dependent>
        </dependency>
        <dependency type="case">
          <governor id="22">tunnels</governor>
          <dependent id="20">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">tunnels</governor>
          <dependent id="21">underground</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="19">tales</governor>
          <dependent id="22">tunnels</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">school</governor>
          <dependent id="23">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">school</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">gained</governor>
          <dependent id="25">school</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="25">school</governor>
          <dependent id="26">and</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">rituals</governor>
          <dependent id="27">Satanic</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="25">school</governor>
          <dependent id="28">rituals</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="38" has_coreference="true">
      <content>The focus of the case shifted dramatically over the years as Reiner reduced the number of charges and dropped five defendants after reviewing the case.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="focus" lemma="focus" stem="focu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="shifted" lemma="shift" stem="shift" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="dramatically" lemma="dramatically" stem="dramat" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="over" lemma="over" stem="over" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="10" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="true" />
        <token id="11" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="13" string="reduced" lemma="reduce" stem="reduc" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="charges" lemma="charge" stem="charg" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="dropped" lemma="drop" stem="drop" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="five" lemma="five" stem="five" pos="CD" type="Word" isStopWord="false" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="21" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="after" lemma="after" stem="after" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="reviewing" lemma="review" stem="review" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT The) (NN focus)) (PP (IN of) (NP (DT the) (NN case)))) (VP (VBD shifted) (ADVP (RB dramatically)) (PP (IN over) (NP (DT the) (NNS years))) (SBAR (IN as) (S (NP (NNP Reiner)) (VP (VP (VBD reduced) (NP (NP (DT the) (NN number)) (PP (IN of) (NP (NNS charges))))) (CC and) (VP (VBD dropped) (NP (CD five) (NNS defendants)) (PP (IN after) (S (VP (VBG reviewing) (NP (DT the) (NN case)))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="as Reiner reduced the number of charges and dropped five defendants after reviewing the case" type="SBAR">
          <tokens>
            <token id="11" string="as" />
            <token id="12" string="Reiner" />
            <token id="13" string="reduced" />
            <token id="14" string="the" />
            <token id="15" string="number" />
            <token id="16" string="of" />
            <token id="17" string="charges" />
            <token id="18" string="and" />
            <token id="19" string="dropped" />
            <token id="20" string="five" />
            <token id="21" string="defendants" />
            <token id="22" string="after" />
            <token id="23" string="reviewing" />
            <token id="24" string="the" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="reduced the number of charges and dropped five defendants after reviewing the case" type="VP">
          <tokens>
            <token id="13" string="reduced" />
            <token id="14" string="the" />
            <token id="15" string="number" />
            <token id="16" string="of" />
            <token id="17" string="charges" />
            <token id="18" string="and" />
            <token id="19" string="dropped" />
            <token id="20" string="five" />
            <token id="21" string="defendants" />
            <token id="22" string="after" />
            <token id="23" string="reviewing" />
            <token id="24" string="the" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="reviewing the case" type="VP">
          <tokens>
            <token id="23" string="reviewing" />
            <token id="24" string="the" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="the years" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="years" />
          </tokens>
        </chunking>
        <chunking id="5" string="the case" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="case" />
          </tokens>
        </chunking>
        <chunking id="6" string="reduced the number of charges" type="VP">
          <tokens>
            <token id="13" string="reduced" />
            <token id="14" string="the" />
            <token id="15" string="number" />
            <token id="16" string="of" />
            <token id="17" string="charges" />
          </tokens>
        </chunking>
        <chunking id="7" string="dropped five defendants after reviewing the case" type="VP">
          <tokens>
            <token id="19" string="dropped" />
            <token id="20" string="five" />
            <token id="21" string="defendants" />
            <token id="22" string="after" />
            <token id="23" string="reviewing" />
            <token id="24" string="the" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="8" string="Reiner" type="NP">
          <tokens>
            <token id="12" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="9" string="the number of charges" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="number" />
            <token id="16" string="of" />
            <token id="17" string="charges" />
          </tokens>
        </chunking>
        <chunking id="10" string="shifted dramatically over the years as Reiner reduced the number of charges and dropped five defendants after reviewing the case" type="VP">
          <tokens>
            <token id="6" string="shifted" />
            <token id="7" string="dramatically" />
            <token id="8" string="over" />
            <token id="9" string="the" />
            <token id="10" string="years" />
            <token id="11" string="as" />
            <token id="12" string="Reiner" />
            <token id="13" string="reduced" />
            <token id="14" string="the" />
            <token id="15" string="number" />
            <token id="16" string="of" />
            <token id="17" string="charges" />
            <token id="18" string="and" />
            <token id="19" string="dropped" />
            <token id="20" string="five" />
            <token id="21" string="defendants" />
            <token id="22" string="after" />
            <token id="23" string="reviewing" />
            <token id="24" string="the" />
            <token id="25" string="case" />
          </tokens>
        </chunking>
        <chunking id="11" string="charges" type="NP">
          <tokens>
            <token id="17" string="charges" />
          </tokens>
        </chunking>
        <chunking id="12" string="The focus" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="focus" />
          </tokens>
        </chunking>
        <chunking id="13" string="five defendants" type="NP">
          <tokens>
            <token id="20" string="five" />
            <token id="21" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="14" string="the number" type="NP">
          <tokens>
            <token id="14" string="the" />
            <token id="15" string="number" />
          </tokens>
        </chunking>
        <chunking id="15" string="The focus of the case" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="focus" />
            <token id="3" string="of" />
            <token id="4" string="the" />
            <token id="5" string="case" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">focus</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">shifted</governor>
          <dependent id="2">focus</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">case</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">case</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">focus</governor>
          <dependent id="5">case</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">shifted</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">shifted</governor>
          <dependent id="7">dramatically</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">years</governor>
          <dependent id="8">over</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">years</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">shifted</governor>
          <dependent id="10">years</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">reduced</governor>
          <dependent id="11">as</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">reduced</governor>
          <dependent id="12">Reiner</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">shifted</governor>
          <dependent id="13">reduced</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">number</governor>
          <dependent id="14">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">reduced</governor>
          <dependent id="15">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="17">charges</governor>
          <dependent id="16">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="15">number</governor>
          <dependent id="17">charges</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="13">reduced</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="13">reduced</governor>
          <dependent id="19">dropped</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">defendants</governor>
          <dependent id="20">five</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="19">dropped</governor>
          <dependent id="21">defendants</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="23">reviewing</governor>
          <dependent id="22">after</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="19">dropped</governor>
          <dependent id="23">reviewing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">case</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="23">reviewing</governor>
          <dependent id="25">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="the years" type="DURATION" score="0.0">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="years" />
          </tokens>
        </entity>
        <entity id="2" string="Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="12" string="Reiner" />
          </tokens>
        </entity>
        <entity id="3" string="five" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="five" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="39" has_coreference="true">
      <content>The underground tunnels were never found.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="underground" lemma="underground" stem="underground" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="3" string="tunnels" lemma="tunnel" stem="tunnel" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="never" lemma="never" stem="never" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="found" lemma="find" stem="found" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (JJ underground) (NNS tunnels)) (VP (VBD were) (VP (ADVP (RB never)) (VBN found))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were never found" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="never" />
            <token id="6" string="found" />
          </tokens>
        </chunking>
        <chunking id="2" string="The underground tunnels" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="underground" />
            <token id="3" string="tunnels" />
          </tokens>
        </chunking>
        <chunking id="3" string="never found" type="VP">
          <tokens>
            <token id="5" string="never" />
            <token id="6" string="found" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">tunnels</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">tunnels</governor>
          <dependent id="2">underground</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="6">found</governor>
          <dependent id="3">tunnels</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="6">found</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">found</governor>
          <dependent id="5">never</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">found</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="40" has_coreference="false">
      <content>No proof was ever produced of Satanic rituals.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="proof" lemma="proof" stem="proof" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="ever" lemma="ever" stem="ever" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="produced" lemma="produce" stem="produc" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Satanic" lemma="satanic" stem="satan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="rituals" lemma="ritual" stem="ritual" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT No) (NN proof)) (VP (VBD was) (ADVP (RB ever)) (VP (VBN produced) (PP (IN of) (NP (JJ Satanic) (NNS rituals))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="produced of Satanic rituals" type="VP">
          <tokens>
            <token id="5" string="produced" />
            <token id="6" string="of" />
            <token id="7" string="Satanic" />
            <token id="8" string="rituals" />
          </tokens>
        </chunking>
        <chunking id="2" string="Satanic rituals" type="NP">
          <tokens>
            <token id="7" string="Satanic" />
            <token id="8" string="rituals" />
          </tokens>
        </chunking>
        <chunking id="3" string="was ever produced of Satanic rituals" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="ever" />
            <token id="5" string="produced" />
            <token id="6" string="of" />
            <token id="7" string="Satanic" />
            <token id="8" string="rituals" />
          </tokens>
        </chunking>
        <chunking id="4" string="No proof" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="proof" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">proof</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="5">produced</governor>
          <dependent id="2">proof</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="5">produced</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">produced</governor>
          <dependent id="4">ever</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">produced</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">rituals</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">rituals</governor>
          <dependent id="7">Satanic</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">produced</governor>
          <dependent id="8">rituals</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="41" has_coreference="true">
      <content>Reiner said the system must be changed to prevent such long, expensive prosecution.</content>
      <tokens>
        <token id="1" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="system" lemma="system" stem="system" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="changed" lemma="change" stem="chang" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="prevent" lemma="prevent" stem="prevent" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="expensive" lemma="expensive" stem="expens" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="prosecution" lemma="prosecution" stem="prosecut" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Reiner)) (VP (VBD said) (SBAR (S (NP (DT the) (NN system)) (VP (MD must) (VP (VB be) (VP (VBN changed) (S (VP (TO to) (VP (VB prevent) (PP (JJ such) (NP (NP (RB long)) (, ,) (NP (JJ expensive) (NN prosecution))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="changed to prevent such long , expensive prosecution" type="VP">
          <tokens>
            <token id="7" string="changed" />
            <token id="8" string="to" />
            <token id="9" string="prevent" />
            <token id="10" string="such" />
            <token id="11" string="long" />
            <token id="12" string="," />
            <token id="13" string="expensive" />
            <token id="14" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="2" string="the system" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="system" />
          </tokens>
        </chunking>
        <chunking id="3" string="the system must be changed to prevent such long , expensive prosecution" type="SBAR">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="system" />
            <token id="5" string="must" />
            <token id="6" string="be" />
            <token id="7" string="changed" />
            <token id="8" string="to" />
            <token id="9" string="prevent" />
            <token id="10" string="such" />
            <token id="11" string="long" />
            <token id="12" string="," />
            <token id="13" string="expensive" />
            <token id="14" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="4" string="to prevent such long , expensive prosecution" type="VP">
          <tokens>
            <token id="8" string="to" />
            <token id="9" string="prevent" />
            <token id="10" string="such" />
            <token id="11" string="long" />
            <token id="12" string="," />
            <token id="13" string="expensive" />
            <token id="14" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="5" string="long" type="NP">
          <tokens>
            <token id="11" string="long" />
          </tokens>
        </chunking>
        <chunking id="6" string="Reiner" type="NP">
          <tokens>
            <token id="1" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="7" string="said the system must be changed to prevent such long , expensive prosecution" type="VP">
          <tokens>
            <token id="2" string="said" />
            <token id="3" string="the" />
            <token id="4" string="system" />
            <token id="5" string="must" />
            <token id="6" string="be" />
            <token id="7" string="changed" />
            <token id="8" string="to" />
            <token id="9" string="prevent" />
            <token id="10" string="such" />
            <token id="11" string="long" />
            <token id="12" string="," />
            <token id="13" string="expensive" />
            <token id="14" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="8" string="be changed to prevent such long , expensive prosecution" type="VP">
          <tokens>
            <token id="6" string="be" />
            <token id="7" string="changed" />
            <token id="8" string="to" />
            <token id="9" string="prevent" />
            <token id="10" string="such" />
            <token id="11" string="long" />
            <token id="12" string="," />
            <token id="13" string="expensive" />
            <token id="14" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="9" string="expensive prosecution" type="NP">
          <tokens>
            <token id="13" string="expensive" />
            <token id="14" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="10" string="must be changed to prevent such long , expensive prosecution" type="VP">
          <tokens>
            <token id="5" string="must" />
            <token id="6" string="be" />
            <token id="7" string="changed" />
            <token id="8" string="to" />
            <token id="9" string="prevent" />
            <token id="10" string="such" />
            <token id="11" string="long" />
            <token id="12" string="," />
            <token id="13" string="expensive" />
            <token id="14" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="11" string="prevent such long , expensive prosecution" type="VP">
          <tokens>
            <token id="9" string="prevent" />
            <token id="10" string="such" />
            <token id="11" string="long" />
            <token id="12" string="," />
            <token id="13" string="expensive" />
            <token id="14" string="prosecution" />
          </tokens>
        </chunking>
        <chunking id="12" string="long , expensive prosecution" type="NP">
          <tokens>
            <token id="11" string="long" />
            <token id="12" string="," />
            <token id="13" string="expensive" />
            <token id="14" string="prosecution" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">said</governor>
          <dependent id="1">Reiner</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">said</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">system</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="7">changed</governor>
          <dependent id="4">system</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">changed</governor>
          <dependent id="5">must</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="7">changed</governor>
          <dependent id="6">be</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">said</governor>
          <dependent id="7">changed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="9">prevent</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">changed</governor>
          <dependent id="9">prevent</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">long</governor>
          <dependent id="10">such</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">prevent</governor>
          <dependent id="11">long</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">prosecution</governor>
          <dependent id="13">expensive</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="11">long</governor>
          <dependent id="14">prosecution</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Reiner" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="42" has_coreference="true">
      <content>``It took far too long and cost far too much money to have what has been called perfect justice.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="took" lemma="take" stem="took" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="long" lemma="long" stem="long" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="cost" lemma="cost" stem="cost" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="far" lemma="far" stem="far" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="money" lemma="money" stem="monei" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="have" lemma="have" stem="have" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="perfect" lemma="perfect" stem="perfect" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="justice" lemma="justice" stem="justic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (PRP It)) (VP (VBD took) (UCP (ADJP (RB far) (RB too) (JJ long)) (CC and) (NP (NP (NN cost)) (ADVP (RB far))) (NP (ADJP (RB too) (JJ much)) (NN money))) (S (VP (TO to) (VP (VB have) (SBAR (WHNP (WP what)) (S (VP (VBZ has) (VP (VBN been) (VP (VBN called) (NP (JJ perfect) (NN justice))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="cost" type="NP">
          <tokens>
            <token id="8" string="cost" />
          </tokens>
        </chunking>
        <chunking id="2" string="too much" type="ADJP">
          <tokens>
            <token id="10" string="too" />
            <token id="11" string="much" />
          </tokens>
        </chunking>
        <chunking id="3" string="perfect justice" type="NP">
          <tokens>
            <token id="19" string="perfect" />
            <token id="20" string="justice" />
          </tokens>
        </chunking>
        <chunking id="4" string="been called perfect justice" type="VP">
          <tokens>
            <token id="17" string="been" />
            <token id="18" string="called" />
            <token id="19" string="perfect" />
            <token id="20" string="justice" />
          </tokens>
        </chunking>
        <chunking id="5" string="has been called perfect justice" type="VP">
          <tokens>
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="called" />
            <token id="19" string="perfect" />
            <token id="20" string="justice" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="called perfect justice" type="VP">
          <tokens>
            <token id="18" string="called" />
            <token id="19" string="perfect" />
            <token id="20" string="justice" />
          </tokens>
        </chunking>
        <chunking id="8" string="to have what has been called perfect justice" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="have" />
            <token id="15" string="what" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="called" />
            <token id="19" string="perfect" />
            <token id="20" string="justice" />
          </tokens>
        </chunking>
        <chunking id="9" string="cost far" type="NP">
          <tokens>
            <token id="8" string="cost" />
            <token id="9" string="far" />
          </tokens>
        </chunking>
        <chunking id="10" string="too much money" type="NP">
          <tokens>
            <token id="10" string="too" />
            <token id="11" string="much" />
            <token id="12" string="money" />
          </tokens>
        </chunking>
        <chunking id="11" string="what has been called perfect justice" type="SBAR">
          <tokens>
            <token id="15" string="what" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="called" />
            <token id="19" string="perfect" />
            <token id="20" string="justice" />
          </tokens>
        </chunking>
        <chunking id="12" string="far too long" type="ADJP">
          <tokens>
            <token id="4" string="far" />
            <token id="5" string="too" />
            <token id="6" string="long" />
          </tokens>
        </chunking>
        <chunking id="13" string="have what has been called perfect justice" type="VP">
          <tokens>
            <token id="14" string="have" />
            <token id="15" string="what" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="called" />
            <token id="19" string="perfect" />
            <token id="20" string="justice" />
          </tokens>
        </chunking>
        <chunking id="14" string="took far too long and cost far too much money to have what has been called perfect justice" type="VP">
          <tokens>
            <token id="3" string="took" />
            <token id="4" string="far" />
            <token id="5" string="too" />
            <token id="6" string="long" />
            <token id="7" string="and" />
            <token id="8" string="cost" />
            <token id="9" string="far" />
            <token id="10" string="too" />
            <token id="11" string="much" />
            <token id="12" string="money" />
            <token id="13" string="to" />
            <token id="14" string="have" />
            <token id="15" string="what" />
            <token id="16" string="has" />
            <token id="17" string="been" />
            <token id="18" string="called" />
            <token id="19" string="perfect" />
            <token id="20" string="justice" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">took</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">took</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">long</governor>
          <dependent id="4">far</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">long</governor>
          <dependent id="5">too</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">took</governor>
          <dependent id="6">long</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="6">long</governor>
          <dependent id="7">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="6">long</governor>
          <dependent id="8">cost</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="8">cost</governor>
          <dependent id="9">far</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">much</governor>
          <dependent id="10">too</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">money</governor>
          <dependent id="11">much</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="6">long</governor>
          <dependent id="12">money</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">have</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="3">took</governor>
          <dependent id="14">have</dependent>
        </dependency>
        <dependency type="nsubjpass">
          <governor id="18">called</governor>
          <dependent id="15">what</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="18">called</governor>
          <dependent id="16">has</dependent>
        </dependency>
        <dependency type="auxpass">
          <governor id="18">called</governor>
          <dependent id="17">been</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="14">have</governor>
          <dependent id="18">called</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="20">justice</governor>
          <dependent id="19">perfect</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">called</governor>
          <dependent id="20">justice</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="43" has_coreference="true">
      <content>We need reform,&amp;apost;&amp;apost; Reiner said, adding that in trying to describe the case, ``Insane is the word that comes to mind.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="We" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="need" lemma="need" stem="need" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="reform" lemma="reform" stem="reform" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Reiner" lemma="Reiner" stem="reiner" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="adding" lemma="add" stem="ad" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="describe" lemma="describe" stem="describ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="Insane" lemma="Insane" stem="insane" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="20" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="word" lemma="word" stem="word" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="comes" lemma="come" stem="come" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="mind" lemma="mind" stem="mind" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (PRP We)) (VP (VBP need) (NP (NN reform)))) (, ,) ('' '') (NP (NNP Reiner)) (VP (VBD said) (, ,) (S (VP (VBG adding) (SBAR (IN that) (S (PP (IN in) (S (VP (VBG trying) (S (VP (TO to) (VP (VB describe) (NP (DT the) (NN case)))))))) (, ,) (`` ``) (NP (NNP Insane)) (VP (VBZ is) (NP (NP (DT the) (NN word)) (SBAR (WHNP (WDT that)) (S (VP (VBZ comes) (S (VP (TO to) (VP (VB mind)))))))))))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="need reform" type="VP">
          <tokens>
            <token id="2" string="need" />
            <token id="3" string="reform" />
          </tokens>
        </chunking>
        <chunking id="2" string="mind" type="VP">
          <tokens>
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="3" string="to mind" type="VP">
          <tokens>
            <token id="25" string="to" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="4" string="the case" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="that comes to mind" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="comes" />
            <token id="25" string="to" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="6" string="comes to mind" type="VP">
          <tokens>
            <token id="24" string="comes" />
            <token id="25" string="to" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="7" string="the word that comes to mind" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="word" />
            <token id="23" string="that" />
            <token id="24" string="comes" />
            <token id="25" string="to" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="8" string="Reiner" type="NP">
          <tokens>
            <token id="6" string="Reiner" />
          </tokens>
        </chunking>
        <chunking id="9" string="that in trying to describe the case , `` Insane is the word that comes to mind" type="SBAR">
          <tokens>
            <token id="10" string="that" />
            <token id="11" string="in" />
            <token id="12" string="trying" />
            <token id="13" string="to" />
            <token id="14" string="describe" />
            <token id="15" string="the" />
            <token id="16" string="case" />
            <token id="17" string="," />
            <token id="18" string="``" />
            <token id="19" string="Insane" />
            <token id="20" string="is" />
            <token id="21" string="the" />
            <token id="22" string="word" />
            <token id="23" string="that" />
            <token id="24" string="comes" />
            <token id="25" string="to" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="10" string="said , adding that in trying to describe the case , `` Insane is the word that comes to mind" type="VP">
          <tokens>
            <token id="7" string="said" />
            <token id="8" string="," />
            <token id="9" string="adding" />
            <token id="10" string="that" />
            <token id="11" string="in" />
            <token id="12" string="trying" />
            <token id="13" string="to" />
            <token id="14" string="describe" />
            <token id="15" string="the" />
            <token id="16" string="case" />
            <token id="17" string="," />
            <token id="18" string="``" />
            <token id="19" string="Insane" />
            <token id="20" string="is" />
            <token id="21" string="the" />
            <token id="22" string="word" />
            <token id="23" string="that" />
            <token id="24" string="comes" />
            <token id="25" string="to" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="11" string="is the word that comes to mind" type="VP">
          <tokens>
            <token id="20" string="is" />
            <token id="21" string="the" />
            <token id="22" string="word" />
            <token id="23" string="that" />
            <token id="24" string="comes" />
            <token id="25" string="to" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="12" string="We" type="NP">
          <tokens>
            <token id="1" string="We" />
          </tokens>
        </chunking>
        <chunking id="13" string="trying to describe the case" type="VP">
          <tokens>
            <token id="12" string="trying" />
            <token id="13" string="to" />
            <token id="14" string="describe" />
            <token id="15" string="the" />
            <token id="16" string="case" />
          </tokens>
        </chunking>
        <chunking id="14" string="reform" type="NP">
          <tokens>
            <token id="3" string="reform" />
          </tokens>
        </chunking>
        <chunking id="15" string="describe the case" type="VP">
          <tokens>
            <token id="14" string="describe" />
            <token id="15" string="the" />
            <token id="16" string="case" />
          </tokens>
        </chunking>
        <chunking id="16" string="adding that in trying to describe the case , `` Insane is the word that comes to mind" type="VP">
          <tokens>
            <token id="9" string="adding" />
            <token id="10" string="that" />
            <token id="11" string="in" />
            <token id="12" string="trying" />
            <token id="13" string="to" />
            <token id="14" string="describe" />
            <token id="15" string="the" />
            <token id="16" string="case" />
            <token id="17" string="," />
            <token id="18" string="``" />
            <token id="19" string="Insane" />
            <token id="20" string="is" />
            <token id="21" string="the" />
            <token id="22" string="word" />
            <token id="23" string="that" />
            <token id="24" string="comes" />
            <token id="25" string="to" />
            <token id="26" string="mind" />
          </tokens>
        </chunking>
        <chunking id="17" string="Insane" type="NP">
          <tokens>
            <token id="19" string="Insane" />
          </tokens>
        </chunking>
        <chunking id="18" string="the word" type="NP">
          <tokens>
            <token id="21" string="the" />
            <token id="22" string="word" />
          </tokens>
        </chunking>
        <chunking id="19" string="to describe the case" type="VP">
          <tokens>
            <token id="13" string="to" />
            <token id="14" string="describe" />
            <token id="15" string="the" />
            <token id="16" string="case" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">need</governor>
          <dependent id="1">We</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="7">said</governor>
          <dependent id="2">need</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">need</governor>
          <dependent id="3">reform</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">said</governor>
          <dependent id="6">Reiner</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">said</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">said</governor>
          <dependent id="9">adding</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">word</governor>
          <dependent id="10">that</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="12">trying</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="22">word</governor>
          <dependent id="12">trying</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="14">describe</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="12">trying</governor>
          <dependent id="14">describe</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">case</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">describe</governor>
          <dependent id="16">case</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">word</governor>
          <dependent id="19">Insane</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="22">word</governor>
          <dependent id="20">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">word</governor>
          <dependent id="21">the</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="9">adding</governor>
          <dependent id="22">word</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">comes</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="22">word</governor>
          <dependent id="24">comes</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="26">mind</governor>
          <dependent id="25">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">comes</governor>
          <dependent id="26">mind</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Reiner" type="PERSON" score="0.0">
          <tokens>
            <token id="6" string="Reiner" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="44" has_coreference="false">
      <content>The case was the longest and the costliest in American judicial history, at 2{ years and $15 million.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="longest" lemma="longest" stem="longest" pos="JJS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="costliest" lemma="costliest" stem="costliest" pos="JJS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="11" string="judicial" lemma="judicial" stem="judici" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="history" lemma="history" stem="histori" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="2" lemma="2" stem="2" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="16" string="{" lemma="-lcb-" stem="{" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="$" lemma="$" stem="$" pos="$" type="Symbol" isStopWord="true" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="20" string="15" lemma="15" stem="15" pos="CD" type="Number" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="21" string="million" lemma="million" stem="million" pos="CD" type="Word" isStopWord="false" ner="MONEY" is_referenced="false" is_refers="false" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (DT The) (NN case)) (VP (VBD was) (NP (DT the) (NP (NP (JJS longest)) (CC and) (NP (DT the) (JJS costliest))) (PP (IN in) (NP (JJ American) (JJ judicial) (NN history))) (, ,) (ADVP (IN at)) (NP (NP (CD 2)) (-LRB- -LCB-) (NP (NP (NNS years)) (CC and) (NP ($ $) (CD 15) (CD million)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="longest" type="NP">
          <tokens>
            <token id="5" string="longest" />
          </tokens>
        </chunking>
        <chunking id="2" string="2" type="NP">
          <tokens>
            <token id="15" string="2" />
          </tokens>
        </chunking>
        <chunking id="3" string="was the longest and the costliest in American judicial history , at 2 -LCB- years and $ 15 million" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="the" />
            <token id="5" string="longest" />
            <token id="6" string="and" />
            <token id="7" string="the" />
            <token id="8" string="costliest" />
            <token id="9" string="in" />
            <token id="10" string="American" />
            <token id="11" string="judicial" />
            <token id="12" string="history" />
            <token id="13" string="," />
            <token id="14" string="at" />
            <token id="15" string="2" />
            <token id="16" string="{" />
            <token id="17" string="years" />
            <token id="18" string="and" />
            <token id="19" string="$" />
            <token id="20" string="15" />
            <token id="21" string="million" />
          </tokens>
        </chunking>
        <chunking id="4" string="longest and the costliest" type="NP">
          <tokens>
            <token id="5" string="longest" />
            <token id="6" string="and" />
            <token id="7" string="the" />
            <token id="8" string="costliest" />
          </tokens>
        </chunking>
        <chunking id="5" string="the costliest" type="NP">
          <tokens>
            <token id="7" string="the" />
            <token id="8" string="costliest" />
          </tokens>
        </chunking>
        <chunking id="6" string="$ 15 million" type="NP">
          <tokens>
            <token id="19" string="$" />
            <token id="20" string="15" />
            <token id="21" string="million" />
          </tokens>
        </chunking>
        <chunking id="7" string="years and $ 15 million" type="NP">
          <tokens>
            <token id="17" string="years" />
            <token id="18" string="and" />
            <token id="19" string="$" />
            <token id="20" string="15" />
            <token id="21" string="million" />
          </tokens>
        </chunking>
        <chunking id="8" string="American judicial history" type="NP">
          <tokens>
            <token id="10" string="American" />
            <token id="11" string="judicial" />
            <token id="12" string="history" />
          </tokens>
        </chunking>
        <chunking id="9" string="The case" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="2 -LCB- years and $ 15 million" type="NP">
          <tokens>
            <token id="15" string="2" />
            <token id="16" string="{" />
            <token id="17" string="years" />
            <token id="18" string="and" />
            <token id="19" string="$" />
            <token id="20" string="15" />
            <token id="21" string="million" />
          </tokens>
        </chunking>
        <chunking id="11" string="years" type="NP">
          <tokens>
            <token id="17" string="years" />
          </tokens>
        </chunking>
        <chunking id="12" string="the longest and the costliest in American judicial history , at 2 -LCB- years and $ 15 million" type="NP">
          <tokens>
            <token id="4" string="the" />
            <token id="5" string="longest" />
            <token id="6" string="and" />
            <token id="7" string="the" />
            <token id="8" string="costliest" />
            <token id="9" string="in" />
            <token id="10" string="American" />
            <token id="11" string="judicial" />
            <token id="12" string="history" />
            <token id="13" string="," />
            <token id="14" string="at" />
            <token id="15" string="2" />
            <token id="16" string="{" />
            <token id="17" string="years" />
            <token id="18" string="and" />
            <token id="19" string="$" />
            <token id="20" string="15" />
            <token id="21" string="million" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">case</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">longest</governor>
          <dependent id="2">case</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">longest</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">longest</governor>
          <dependent id="4">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">longest</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="5">longest</governor>
          <dependent id="6">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">costliest</governor>
          <dependent id="7">the</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="5">longest</governor>
          <dependent id="8">costliest</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">history</governor>
          <dependent id="9">in</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">history</governor>
          <dependent id="10">American</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">history</governor>
          <dependent id="11">judicial</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">longest</governor>
          <dependent id="12">history</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">longest</governor>
          <dependent id="14">at</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">longest</governor>
          <dependent id="15">2</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="15">2</governor>
          <dependent id="17">years</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">years</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="21">million</governor>
          <dependent id="19">$</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="21">million</governor>
          <dependent id="20">15</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">years</governor>
          <dependent id="21">million</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="2" type="NUMBER" score="0.0">
          <tokens>
            <token id="15" string="2" />
          </tokens>
        </entity>
        <entity id="2" string="$ 15 million" type="MONEY" score="0.0">
          <tokens>
            <token id="19" string="$" />
            <token id="20" string="15" />
            <token id="21" string="million" />
          </tokens>
        </entity>
        <entity id="3" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="10" string="American" />
          </tokens>
        </entity>
        <entity id="4" string="years" type="DURATION" score="0.0">
          <tokens>
            <token id="17" string="years" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="45" has_coreference="true">
      <content>Superior Court Judge William Pounders said he did what he could to limit its length, cutting 50 witnesses and narrowing the scope of the case.</content>
      <tokens>
        <token id="1" string="Superior" lemma="Superior" stem="superior" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="2" string="Court" lemma="Court" stem="court" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="3" string="Judge" lemma="Judge" stem="judg" pos="NNP" type="Word" isStopWord="false" ner="TITLE" is_referenced="true" is_refers="false" />
        <token id="4" string="William" lemma="William" stem="william" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Pounders" lemma="Pounders" stem="pounder" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="limit" lemma="limit" stem="limit" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="its" lemma="its" stem="it" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="length" lemma="length" stem="length" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="cutting" lemma="cut" stem="cut" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="50" lemma="50" stem="50" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="witnesses" lemma="witness" stem="wit" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="narrowing" lemma="narrow" stem="narrow" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="scope" lemma="scope" stem="scope" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Superior) (NNP Court) (NNP Judge) (NNP William) (NNP Pounders)) (VP (VBD said) (SBAR (S (NP (PRP he)) (VP (VBD did) (SBAR (WHNP (WP what)) (S (NP (PRP he)) (VP (MD could) (S (VP (TO to) (VP (VB limit) (NP (PRP$ its) (NN length)))))))) (, ,) (S (VP (VP (VBG cutting) (NP (CD 50) (NNS witnesses))) (CC and) (VP (VBG narrowing) (NP (NP (DT the) (NN scope)) (PP (IN of) (NP (DT the) (NN case))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="said he did what he could to limit its length , cutting 50 witnesses and narrowing the scope of the case" type="VP">
          <tokens>
            <token id="6" string="said" />
            <token id="7" string="he" />
            <token id="8" string="did" />
            <token id="9" string="what" />
            <token id="10" string="he" />
            <token id="11" string="could" />
            <token id="12" string="to" />
            <token id="13" string="limit" />
            <token id="14" string="its" />
            <token id="15" string="length" />
            <token id="16" string="," />
            <token id="17" string="cutting" />
            <token id="18" string="50" />
            <token id="19" string="witnesses" />
            <token id="20" string="and" />
            <token id="21" string="narrowing" />
            <token id="22" string="the" />
            <token id="23" string="scope" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="case" />
          </tokens>
        </chunking>
        <chunking id="2" string="its length" type="NP">
          <tokens>
            <token id="14" string="its" />
            <token id="15" string="length" />
          </tokens>
        </chunking>
        <chunking id="3" string="narrowing the scope of the case" type="VP">
          <tokens>
            <token id="21" string="narrowing" />
            <token id="22" string="the" />
            <token id="23" string="scope" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="case" />
          </tokens>
        </chunking>
        <chunking id="4" string="the case" type="NP">
          <tokens>
            <token id="25" string="the" />
            <token id="26" string="case" />
          </tokens>
        </chunking>
        <chunking id="5" string="Superior Court Judge William Pounders" type="NP">
          <tokens>
            <token id="1" string="Superior" />
            <token id="2" string="Court" />
            <token id="3" string="Judge" />
            <token id="4" string="William" />
            <token id="5" string="Pounders" />
          </tokens>
        </chunking>
        <chunking id="6" string="what he could to limit its length" type="SBAR">
          <tokens>
            <token id="9" string="what" />
            <token id="10" string="he" />
            <token id="11" string="could" />
            <token id="12" string="to" />
            <token id="13" string="limit" />
            <token id="14" string="its" />
            <token id="15" string="length" />
          </tokens>
        </chunking>
        <chunking id="7" string="limit its length" type="VP">
          <tokens>
            <token id="13" string="limit" />
            <token id="14" string="its" />
            <token id="15" string="length" />
          </tokens>
        </chunking>
        <chunking id="8" string="could to limit its length" type="VP">
          <tokens>
            <token id="11" string="could" />
            <token id="12" string="to" />
            <token id="13" string="limit" />
            <token id="14" string="its" />
            <token id="15" string="length" />
          </tokens>
        </chunking>
        <chunking id="9" string="the scope of the case" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="scope" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="case" />
          </tokens>
        </chunking>
        <chunking id="10" string="50 witnesses" type="NP">
          <tokens>
            <token id="18" string="50" />
            <token id="19" string="witnesses" />
          </tokens>
        </chunking>
        <chunking id="11" string="the scope" type="NP">
          <tokens>
            <token id="22" string="the" />
            <token id="23" string="scope" />
          </tokens>
        </chunking>
        <chunking id="12" string="cutting 50 witnesses and narrowing the scope of the case" type="VP">
          <tokens>
            <token id="17" string="cutting" />
            <token id="18" string="50" />
            <token id="19" string="witnesses" />
            <token id="20" string="and" />
            <token id="21" string="narrowing" />
            <token id="22" string="the" />
            <token id="23" string="scope" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="case" />
          </tokens>
        </chunking>
        <chunking id="13" string="did what he could to limit its length , cutting 50 witnesses and narrowing the scope of the case" type="VP">
          <tokens>
            <token id="8" string="did" />
            <token id="9" string="what" />
            <token id="10" string="he" />
            <token id="11" string="could" />
            <token id="12" string="to" />
            <token id="13" string="limit" />
            <token id="14" string="its" />
            <token id="15" string="length" />
            <token id="16" string="," />
            <token id="17" string="cutting" />
            <token id="18" string="50" />
            <token id="19" string="witnesses" />
            <token id="20" string="and" />
            <token id="21" string="narrowing" />
            <token id="22" string="the" />
            <token id="23" string="scope" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="case" />
          </tokens>
        </chunking>
        <chunking id="14" string="he did what he could to limit its length , cutting 50 witnesses and narrowing the scope of the case" type="SBAR">
          <tokens>
            <token id="7" string="he" />
            <token id="8" string="did" />
            <token id="9" string="what" />
            <token id="10" string="he" />
            <token id="11" string="could" />
            <token id="12" string="to" />
            <token id="13" string="limit" />
            <token id="14" string="its" />
            <token id="15" string="length" />
            <token id="16" string="," />
            <token id="17" string="cutting" />
            <token id="18" string="50" />
            <token id="19" string="witnesses" />
            <token id="20" string="and" />
            <token id="21" string="narrowing" />
            <token id="22" string="the" />
            <token id="23" string="scope" />
            <token id="24" string="of" />
            <token id="25" string="the" />
            <token id="26" string="case" />
          </tokens>
        </chunking>
        <chunking id="15" string="he" type="NP">
          <tokens>
            <token id="7" string="he" />
          </tokens>
        </chunking>
        <chunking id="16" string="to limit its length" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="limit" />
            <token id="14" string="its" />
            <token id="15" string="length" />
          </tokens>
        </chunking>
        <chunking id="17" string="cutting 50 witnesses" type="VP">
          <tokens>
            <token id="17" string="cutting" />
            <token id="18" string="50" />
            <token id="19" string="witnesses" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="5">Pounders</governor>
          <dependent id="1">Superior</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Pounders</governor>
          <dependent id="2">Court</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Pounders</governor>
          <dependent id="3">Judge</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Pounders</governor>
          <dependent id="4">William</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">said</governor>
          <dependent id="5">Pounders</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">said</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">did</governor>
          <dependent id="7">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">said</governor>
          <dependent id="8">did</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">could</governor>
          <dependent id="9">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">could</governor>
          <dependent id="10">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">did</governor>
          <dependent id="11">could</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">limit</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">could</governor>
          <dependent id="13">limit</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">length</governor>
          <dependent id="14">its</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="13">limit</governor>
          <dependent id="15">length</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">did</governor>
          <dependent id="17">cutting</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="19">witnesses</governor>
          <dependent id="18">50</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">cutting</governor>
          <dependent id="19">witnesses</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="17">cutting</governor>
          <dependent id="20">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="17">cutting</governor>
          <dependent id="21">narrowing</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">scope</governor>
          <dependent id="22">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="21">narrowing</governor>
          <dependent id="23">scope</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">case</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="26">case</governor>
          <dependent id="25">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">scope</governor>
          <dependent id="26">case</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Superior Court" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Superior" />
            <token id="2" string="Court" />
          </tokens>
        </entity>
        <entity id="2" string="William Pounders" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="William" />
            <token id="5" string="Pounders" />
          </tokens>
        </entity>
        <entity id="3" string="50" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="50" />
          </tokens>
        </entity>
        <entity id="4" string="Judge" type="TITLE" score="0.0">
          <tokens>
            <token id="3" string="Judge" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="46" has_coreference="false">
      <content>For parents and others, there was more to ponder than legal questions.</content>
      <tokens>
        <token id="1" string="For" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="parents" lemma="parent" stem="parent" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="others" lemma="other" stem="other" pos="NNS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="more" lemma="more" stem="more" pos="JJR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="ponder" lemma="ponder" stem="ponder" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="than" lemma="than" stem="than" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="legal" lemma="legal" stem="legal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="questions" lemma="question" stem="question" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN For) (NP (NNS parents) (CC and) (NNS others))) (, ,) (NP (EX there)) (VP (VBD was) (ADJP (JJR more)) (S (VP (TO to) (VP (VB ponder) (PP (IN than) (NP (JJ legal) (NNS questions))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="there" type="NP">
          <tokens>
            <token id="6" string="there" />
          </tokens>
        </chunking>
        <chunking id="2" string="was more to ponder than legal questions" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="more" />
            <token id="9" string="to" />
            <token id="10" string="ponder" />
            <token id="11" string="than" />
            <token id="12" string="legal" />
            <token id="13" string="questions" />
          </tokens>
        </chunking>
        <chunking id="3" string="legal questions" type="NP">
          <tokens>
            <token id="12" string="legal" />
            <token id="13" string="questions" />
          </tokens>
        </chunking>
        <chunking id="4" string="ponder than legal questions" type="VP">
          <tokens>
            <token id="10" string="ponder" />
            <token id="11" string="than" />
            <token id="12" string="legal" />
            <token id="13" string="questions" />
          </tokens>
        </chunking>
        <chunking id="5" string="more" type="ADJP">
          <tokens>
            <token id="8" string="more" />
          </tokens>
        </chunking>
        <chunking id="6" string="parents and others" type="NP">
          <tokens>
            <token id="2" string="parents" />
            <token id="3" string="and" />
            <token id="4" string="others" />
          </tokens>
        </chunking>
        <chunking id="7" string="to ponder than legal questions" type="VP">
          <tokens>
            <token id="9" string="to" />
            <token id="10" string="ponder" />
            <token id="11" string="than" />
            <token id="12" string="legal" />
            <token id="13" string="questions" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">parents</governor>
          <dependent id="1">For</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">was</governor>
          <dependent id="2">parents</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="2">parents</governor>
          <dependent id="3">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="2">parents</governor>
          <dependent id="4">others</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="7">was</governor>
          <dependent id="6">there</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">was</governor>
          <dependent id="8">more</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">ponder</governor>
          <dependent id="9">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="7">was</governor>
          <dependent id="10">ponder</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">questions</governor>
          <dependent id="11">than</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">questions</governor>
          <dependent id="12">legal</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">ponder</governor>
          <dependent id="13">questions</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="47" has_coreference="false">
      <content>``Life is not fair.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Life" lemma="Life" stem="life" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (NP (NNP Life)) (VP (VBZ is) (RB not) (ADJP (JJ fair))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="is not fair" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="not" />
            <token id="5" string="fair" />
          </tokens>
        </chunking>
        <chunking id="2" string="fair" type="ADJP">
          <tokens>
            <token id="5" string="fair" />
          </tokens>
        </chunking>
        <chunking id="3" string="Life" type="NP">
          <tokens>
            <token id="2" string="Life" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="5">fair</governor>
          <dependent id="2">Life</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">fair</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">fair</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">fair</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="48" has_coreference="true">
      <content>I tell my children all the time ... there is no such thing as fair,&amp;apost;&amp;apost; said Robert Currie, whose son attended McMartin but didn&amp;apost;t testify at the trial.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="tell" lemma="tell" stem="tell" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="all" lemma="all" stem="all" pos="PDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="there" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="14" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="fair" lemma="fair" stem="fair" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Robert" lemma="Robert" stem="robert" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="20" string="Currie" lemma="Currie" stem="curri" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="whose" lemma="whose" stem="whose" pos="WP$" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="son" lemma="son" stem="son" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="attended" lemma="attend" stem="attend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="McMartin" lemma="McMartin" stem="mcmartin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="26" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="n't" lemma="not" stem="n't" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="testify" lemma="testify" stem="testifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="32" string="trial" lemma="trial" stem="trial" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (S (S (NP (PRP I)) (VP (VBP tell) (NP (PRP$ my) (NNS children)) (NP-TMP (PDT all) (DT the) (NN time)))) (: ...) (S (NP (EX there)) (VP (VBZ is) (NP (NP (DT no) (JJ such) (NN thing)) (PP (IN as) (ADJP (JJ fair))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Robert) (NNP Currie)) (, ,) (SBAR (WHNP (WP$ whose) (NN son)) (S (VP (VP (VBD attended) (NP (NNP McMartin))) (CC but) (VP (VBD did) (RB n't) (VP (VB testify) (PP (IN at) (NP (DT the) (NN trial))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Robert Currie" type="NP">
          <tokens>
            <token id="19" string="Robert" />
            <token id="20" string="Currie" />
          </tokens>
        </chunking>
        <chunking id="2" string="the trial" type="NP">
          <tokens>
            <token id="31" string="the" />
            <token id="32" string="trial" />
          </tokens>
        </chunking>
        <chunking id="3" string="McMartin" type="NP">
          <tokens>
            <token id="25" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="4" string="no such thing as fair" type="NP">
          <tokens>
            <token id="11" string="no" />
            <token id="12" string="such" />
            <token id="13" string="thing" />
            <token id="14" string="as" />
            <token id="15" string="fair" />
          </tokens>
        </chunking>
        <chunking id="5" string="testify at the trial" type="VP">
          <tokens>
            <token id="29" string="testify" />
            <token id="30" string="at" />
            <token id="31" string="the" />
            <token id="32" string="trial" />
          </tokens>
        </chunking>
        <chunking id="6" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="7" string="is no such thing as fair" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="no" />
            <token id="12" string="such" />
            <token id="13" string="thing" />
            <token id="14" string="as" />
            <token id="15" string="fair" />
          </tokens>
        </chunking>
        <chunking id="8" string="no such thing" type="NP">
          <tokens>
            <token id="11" string="no" />
            <token id="12" string="such" />
            <token id="13" string="thing" />
          </tokens>
        </chunking>
        <chunking id="9" string="fair" type="ADJP">
          <tokens>
            <token id="15" string="fair" />
          </tokens>
        </chunking>
        <chunking id="10" string="whose son attended McMartin but did n't testify at the trial" type="SBAR">
          <tokens>
            <token id="22" string="whose" />
            <token id="23" string="son" />
            <token id="24" string="attended" />
            <token id="25" string="McMartin" />
            <token id="26" string="but" />
            <token id="27" string="did" />
            <token id="28" string="n't" />
            <token id="29" string="testify" />
            <token id="30" string="at" />
            <token id="31" string="the" />
            <token id="32" string="trial" />
          </tokens>
        </chunking>
        <chunking id="11" string="there" type="NP">
          <tokens>
            <token id="9" string="there" />
          </tokens>
        </chunking>
        <chunking id="12" string="attended McMartin but did n't testify at the trial" type="VP">
          <tokens>
            <token id="24" string="attended" />
            <token id="25" string="McMartin" />
            <token id="26" string="but" />
            <token id="27" string="did" />
            <token id="28" string="n't" />
            <token id="29" string="testify" />
            <token id="30" string="at" />
            <token id="31" string="the" />
            <token id="32" string="trial" />
          </tokens>
        </chunking>
        <chunking id="13" string="tell my children all the time" type="VP">
          <tokens>
            <token id="2" string="tell" />
            <token id="3" string="my" />
            <token id="4" string="children" />
            <token id="5" string="all" />
            <token id="6" string="the" />
            <token id="7" string="time" />
          </tokens>
        </chunking>
        <chunking id="14" string="attended McMartin" type="VP">
          <tokens>
            <token id="24" string="attended" />
            <token id="25" string="McMartin" />
          </tokens>
        </chunking>
        <chunking id="15" string="Robert Currie , whose son attended McMartin but did n't testify at the trial" type="NP">
          <tokens>
            <token id="19" string="Robert" />
            <token id="20" string="Currie" />
            <token id="21" string="," />
            <token id="22" string="whose" />
            <token id="23" string="son" />
            <token id="24" string="attended" />
            <token id="25" string="McMartin" />
            <token id="26" string="but" />
            <token id="27" string="did" />
            <token id="28" string="n't" />
            <token id="29" string="testify" />
            <token id="30" string="at" />
            <token id="31" string="the" />
            <token id="32" string="trial" />
          </tokens>
        </chunking>
        <chunking id="16" string="did n't testify at the trial" type="VP">
          <tokens>
            <token id="27" string="did" />
            <token id="28" string="n't" />
            <token id="29" string="testify" />
            <token id="30" string="at" />
            <token id="31" string="the" />
            <token id="32" string="trial" />
          </tokens>
        </chunking>
        <chunking id="17" string="my children" type="NP">
          <tokens>
            <token id="3" string="my" />
            <token id="4" string="children" />
          </tokens>
        </chunking>
        <chunking id="18" string="said" type="VP">
          <tokens>
            <token id="18" string="said" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">tell</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">said</governor>
          <dependent id="2">tell</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">children</governor>
          <dependent id="3">my</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">tell</governor>
          <dependent id="4">children</dependent>
        </dependency>
        <dependency type="det:predet">
          <governor id="7">time</governor>
          <dependent id="5">all</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">time</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="2">tell</governor>
          <dependent id="7">time</dependent>
        </dependency>
        <dependency type="expl">
          <governor id="10">is</governor>
          <dependent id="9">there</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="2">tell</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="13">thing</governor>
          <dependent id="11">no</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">thing</governor>
          <dependent id="12">such</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">is</governor>
          <dependent id="13">thing</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">fair</governor>
          <dependent id="14">as</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="13">thing</governor>
          <dependent id="15">fair</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Currie</governor>
          <dependent id="19">Robert</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">said</governor>
          <dependent id="20">Currie</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="23">son</governor>
          <dependent id="22">whose</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">attended</governor>
          <dependent id="23">son</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">Currie</governor>
          <dependent id="24">attended</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="24">attended</governor>
          <dependent id="25">McMartin</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="24">attended</governor>
          <dependent id="26">but</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="29">testify</governor>
          <dependent id="27">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="29">testify</governor>
          <dependent id="28">n't</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="24">attended</governor>
          <dependent id="29">testify</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">trial</governor>
          <dependent id="30">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="32">trial</governor>
          <dependent id="31">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="29">testify</governor>
          <dependent id="32">trial</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Robert Currie" type="PERSON" score="0.0">
          <tokens>
            <token id="19" string="Robert" />
            <token id="20" string="Currie" />
          </tokens>
        </entity>
        <entity id="2" string="McMartin" type="PERSON" score="0.0">
          <tokens>
            <token id="25" string="McMartin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="49" has_coreference="true">
      <content>``It&amp;apost;s really a travesty for a case to take this long,&amp;apost;&amp;apost; said Ms. Rubin, the prosecutor.</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="really" lemma="really" stem="realli" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="travesty" lemma="travesty" stem="travesti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="9" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="11" string="take" lemma="take" stem="take" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="12" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="13" string="long" lemma="long" stem="long" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="said" lemma="say" stem="said" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="Ms." lemma="Ms." stem="ms." pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="Rubin" lemma="Rubin" stem="rubin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="prosecutor" lemma="prosecutor" stem="prosecutor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (SINV (`` ``) (S (NP (PRP It)) (VP (VBZ 's) (ADVP (RB really)) (NP (NP (DT a) (NN travesty)) (PP (IN for) (NP (DT a) (NN case) (S (VP (TO to) (VP (VB take) (NP (DT this)) (ADVP (RB long)))))))))) (, ,) ('' '') (VP (VBD said)) (NP (NP (NNP Ms.) (NNP Rubin)) (, ,) (NP (DT the) (NN prosecutor))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the prosecutor" type="NP">
          <tokens>
            <token id="20" string="the" />
            <token id="21" string="prosecutor" />
          </tokens>
        </chunking>
        <chunking id="2" string="a travesty" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="travesty" />
          </tokens>
        </chunking>
        <chunking id="3" string="Ms. Rubin , the prosecutor" type="NP">
          <tokens>
            <token id="17" string="Ms." />
            <token id="18" string="Rubin" />
            <token id="19" string="," />
            <token id="20" string="the" />
            <token id="21" string="prosecutor" />
          </tokens>
        </chunking>
        <chunking id="4" string="a case to take this long" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="case" />
            <token id="10" string="to" />
            <token id="11" string="take" />
            <token id="12" string="this" />
            <token id="13" string="long" />
          </tokens>
        </chunking>
        <chunking id="5" string="to take this long" type="VP">
          <tokens>
            <token id="10" string="to" />
            <token id="11" string="take" />
            <token id="12" string="this" />
            <token id="13" string="long" />
          </tokens>
        </chunking>
        <chunking id="6" string="It" type="NP">
          <tokens>
            <token id="2" string="It" />
          </tokens>
        </chunking>
        <chunking id="7" string="this" type="NP">
          <tokens>
            <token id="12" string="this" />
          </tokens>
        </chunking>
        <chunking id="8" string="Ms. Rubin" type="NP">
          <tokens>
            <token id="17" string="Ms." />
            <token id="18" string="Rubin" />
          </tokens>
        </chunking>
        <chunking id="9" string="'s really a travesty for a case to take this long" type="VP">
          <tokens>
            <token id="3" string="'s" />
            <token id="4" string="really" />
            <token id="5" string="a" />
            <token id="6" string="travesty" />
            <token id="7" string="for" />
            <token id="8" string="a" />
            <token id="9" string="case" />
            <token id="10" string="to" />
            <token id="11" string="take" />
            <token id="12" string="this" />
            <token id="13" string="long" />
          </tokens>
        </chunking>
        <chunking id="10" string="a travesty for a case to take this long" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="travesty" />
            <token id="7" string="for" />
            <token id="8" string="a" />
            <token id="9" string="case" />
            <token id="10" string="to" />
            <token id="11" string="take" />
            <token id="12" string="this" />
            <token id="13" string="long" />
          </tokens>
        </chunking>
        <chunking id="11" string="said" type="VP">
          <tokens>
            <token id="16" string="said" />
          </tokens>
        </chunking>
        <chunking id="12" string="take this long" type="VP">
          <tokens>
            <token id="11" string="take" />
            <token id="12" string="this" />
            <token id="13" string="long" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="6">travesty</governor>
          <dependent id="2">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">travesty</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">travesty</governor>
          <dependent id="4">really</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">travesty</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="16">said</governor>
          <dependent id="6">travesty</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">case</governor>
          <dependent id="7">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">case</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">travesty</governor>
          <dependent id="9">case</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">take</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">case</governor>
          <dependent id="11">take</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">take</governor>
          <dependent id="12">this</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">take</governor>
          <dependent id="13">long</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">said</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="18">Rubin</governor>
          <dependent id="17">Ms.</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">said</governor>
          <dependent id="18">Rubin</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">prosecutor</governor>
          <dependent id="20">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="18">Rubin</governor>
          <dependent id="21">prosecutor</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Rubin" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Rubin" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="50" has_coreference="true">
      <content>``...Not only for the families, the children in this case, but also for the defendants as well.&amp;apost;&amp;apost;</content>
      <tokens>
        <token id="1" string="``" lemma="``" stem="``" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="..." lemma="..." stem="..." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="Not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="7" string="families" lemma="family" stem="famili" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="children" lemma="child" stem="children" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="also" lemma="also" stem="also" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="defendants" lemma="defendant" stem="defend" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="20" string="as" lemma="as" stem="a" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="21" string="well" lemma="well" stem="well" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="22" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="''" lemma="''" stem="''" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (`` ``) (S (NP (NP (: ...) (NP (RB Not) (RB only)) (PP (IN for) (NP (NP (DT the) (NNS families)) (, ,) (NP (NP (DT the) (NNS children)) (PP (IN in) (NP (DT this) (NN case)))) (, ,) (ADVP (CC but))))) (ADVP (RB also))) (PP (IN for) (NP (NP (DT the) (NNS defendants)) (ADVP (RB as) (RB well))))) (. .) ('' '')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Not only" type="NP">
          <tokens>
            <token id="3" string="Not" />
            <token id="4" string="only" />
          </tokens>
        </chunking>
        <chunking id="2" string="the children in this case" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="children" />
            <token id="11" string="in" />
            <token id="12" string="this" />
            <token id="13" string="case" />
          </tokens>
        </chunking>
        <chunking id="3" string="the children" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="children" />
          </tokens>
        </chunking>
        <chunking id="4" string="the families , the children in this case , but" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="families" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="children" />
            <token id="11" string="in" />
            <token id="12" string="this" />
            <token id="13" string="case" />
            <token id="14" string="," />
            <token id="15" string="but" />
          </tokens>
        </chunking>
        <chunking id="5" string="the defendants" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="defendants" />
          </tokens>
        </chunking>
        <chunking id="6" string="this case" type="NP">
          <tokens>
            <token id="12" string="this" />
            <token id="13" string="case" />
          </tokens>
        </chunking>
        <chunking id="7" string="... Not only for the families , the children in this case , but also" type="NP">
          <tokens>
            <token id="2" string="..." />
            <token id="3" string="Not" />
            <token id="4" string="only" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="families" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="children" />
            <token id="11" string="in" />
            <token id="12" string="this" />
            <token id="13" string="case" />
            <token id="14" string="," />
            <token id="15" string="but" />
            <token id="16" string="also" />
          </tokens>
        </chunking>
        <chunking id="8" string="the families" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="families" />
          </tokens>
        </chunking>
        <chunking id="9" string="the defendants as well" type="NP">
          <tokens>
            <token id="18" string="the" />
            <token id="19" string="defendants" />
            <token id="20" string="as" />
            <token id="21" string="well" />
          </tokens>
        </chunking>
        <chunking id="10" string="... Not only for the families , the children in this case , but" type="NP">
          <tokens>
            <token id="2" string="..." />
            <token id="3" string="Not" />
            <token id="4" string="only" />
            <token id="5" string="for" />
            <token id="6" string="the" />
            <token id="7" string="families" />
            <token id="8" string="," />
            <token id="9" string="the" />
            <token id="10" string="children" />
            <token id="11" string="in" />
            <token id="12" string="this" />
            <token id="13" string="case" />
            <token id="14" string="," />
            <token id="15" string="but" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="4">only</governor>
          <dependent id="3">Not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">only</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">families</governor>
          <dependent id="5">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">families</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">only</governor>
          <dependent id="7">families</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">children</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="7">families</governor>
          <dependent id="10">children</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">case</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">case</governor>
          <dependent id="12">this</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">children</governor>
          <dependent id="13">case</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">families</governor>
          <dependent id="15">but</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">only</governor>
          <dependent id="16">also</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">defendants</governor>
          <dependent id="17">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">defendants</governor>
          <dependent id="18">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="4">only</governor>
          <dependent id="19">defendants</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="19">defendants</governor>
          <dependent id="20">as</dependent>
        </dependency>
        <dependency type="mwe">
          <governor id="20">as</governor>
          <dependent id="21">well</dependent>
        </dependency>
      </dependencies>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="6-7" string="McMartin Pre-School" id_sentence="1" />
      <mentions>
        <mention ids_tokens="21-23" string="the McMartin Pre-School" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5" string="Superior Court Judge William Pounders" id_sentence="45" />
      <mentions>
        <mention ids_tokens="1" string="I" id_sentence="48" />
        <mention ids_tokens="3" string="my" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="6" type="PROPER">
      <referenced ids_tokens="3-4-5" string="Peggy McMartin Buckey" id_sentence="2" />
      <mentions>
        <mention ids_tokens="14-15" string="Mrs. Buckey" id_sentence="5" />
        <mention ids_tokens="1" string="Buckey" id_sentence="8" />
        <mention ids_tokens="10" string="his" id_sentence="8" />
        <mention ids_tokens="7" string="my" id_sentence="10" />
        <mention ids_tokens="11" string="I" id_sentence="10" />
        <mention ids_tokens="1-11" string="Charles Buckey , father of Raymond and husband of Mrs. Buckey" id_sentence="21" />
        <mention ids_tokens="1-2" string="Charles Buckey" id_sentence="21" />
        <mention ids_tokens="4-6" string="father of Raymond" id_sentence="21" />
        <mention ids_tokens="10-11" string="Mrs. Buckey" id_sentence="21" />
        <mention ids_tokens="11" string="Buckey" id_sentence="21" />
        <mention ids_tokens="14-16" string="Peggy Ann Buckey" id_sentence="36" />
        <mention ids_tokens="30-31" string="Mrs. Buckey" id_sentence="36" />
        <mention ids_tokens="31" string="Buckey" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="7" type="PROPER">
      <referenced ids_tokens="10-11-12-13-14" string="Raymond Buckey , 31 ," id_sentence="2" />
      <mentions>
        <mention ids_tokens="10" string="Ray" id_sentence="5" />
        <mention ids_tokens="6" string="Raymond" id_sentence="21" />
        <mention ids_tokens="1-2" string="Raymond Buckey" id_sentence="26" />
        <mention ids_tokens="9-11" string="Raymond Buckey's" id_sentence="36" />
        <mention ids_tokens="35-36" string="Raymond Buckey" id_sentence="36" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15" string="no such thing as fair" id_sentence="48" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="49" />
        <mention ids_tokens="5-13" string="a travesty for a case to take this long" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="10" type="NOMINAL">
      <referenced ids_tokens="7-8" string="52 charges" id_sentence="3" />
      <mentions>
        <mention ids_tokens="7-8" string="those charges" id_sentence="4" />
        <mention ids_tokens="19-20" string="the charges" id_sentence="24" />
      </mentions>
    </coreference>
    <coreference id="11" type="NOMINAL">
      <referenced ids_tokens="13-14" string="a verdict" id_sentence="3" />
      <mentions>
        <mention ids_tokens="6-7" string="this verdict" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="8-9-10-11-12-13" string="a case to take this long" id_sentence="49" />
      <mentions>
        <mention ids_tokens="12-13" string="this case" id_sentence="50" />
      </mentions>
    </coreference>
    <coreference id="13" type="NOMINAL">
      <referenced ids_tokens="10-11-12" string="a new trial" id_sentence="4" />
      <mentions>
        <mention ids_tokens="20-21" string="the trial" id_sentence="15" />
        <mention ids_tokens="31-32" string="the trial" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="14" type="PRONOMINAL">
      <referenced ids_tokens="2" string="I" id_sentence="5" />
      <mentions>
        <mention ids_tokens="3" string="her" id_sentence="6" />
        <mention ids_tokens="8" string="she" id_sentence="6" />
        <mention ids_tokens="14" string="you" id_sentence="9" />
        <mention ids_tokens="19" string="she" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="3-4" string="her son" id_sentence="6" />
      <mentions>
        <mention ids_tokens="2" string="He" id_sentence="7" />
        <mention ids_tokens="14-15" string="my son" id_sentence="13" />
        <mention ids_tokens="1-2" string="His son" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="18" type="NOMINAL">
      <referenced ids_tokens="7-8-9-10-11" string="the courthouse with his lawyer" id_sentence="8" />
      <mentions>
        <mention ids_tokens="3" string="it" id_sentence="9" />
        <mention ids_tokens="10" string="it" id_sentence="9" />
        <mention ids_tokens="2" string="it" id_sentence="10" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="8-9" string="the school" id_sentence="11" />
      <mentions>
        <mention ids_tokens="2" string="It" id_sentence="12" />
        <mention ids_tokens="2" string="I" id_sentence="13" />
        <mention ids_tokens="14" string="my" id_sentence="13" />
        <mention ids_tokens="1" string="I" id_sentence="14" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="15-16" string="the system" id_sentence="11" />
      <mentions>
        <mention ids_tokens="2" string="I" id_sentence="19" />
        <mention ids_tokens="1" string="I" id_sentence="20" />
        <mention ids_tokens="2" string="My" id_sentence="22" />
        <mention ids_tokens="3" string="you" id_sentence="23" />
        <mention ids_tokens="8" string="you" id_sentence="23" />
        <mention ids_tokens="4" string="you" id_sentence="25" />
        <mention ids_tokens="2" string="It" id_sentence="42" />
      </mentions>
    </coreference>
    <coreference id="22" type="PROPER">
      <referenced ids_tokens="11-12" string="Alan Lagunoff" id_sentence="12" />
      <mentions>
        <mention ids_tokens="10" string="Lagunoff" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="23" type="NOMINAL">
      <referenced ids_tokens="9-10" string="no child" id_sentence="14" />
      <mentions>
        <mention ids_tokens="1" string="His" id_sentence="15" />
        <mention ids_tokens="20-21" string="her child" id_sentence="18" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="15-16-17-18-19" string="a credible witness from now" id_sentence="14" />
      <mentions>
        <mention ids_tokens="17-18" string="a witness" id_sentence="15" />
      </mentions>
    </coreference>
    <coreference id="25" type="PROPER">
      <referenced ids_tokens="5" string="10" id_sentence="15" />
      <mentions>
        <mention ids_tokens="6" string="it" id_sentence="16" />
        <mention ids_tokens="9" string="it" id_sentence="16" />
        <mention ids_tokens="1" string="It" id_sentence="17" />
      </mentions>
    </coreference>
    <coreference id="29" type="NOMINAL">
      <referenced ids_tokens="7-8" string="the children" id_sentence="25" />
      <mentions>
        <mention ids_tokens="9" string="children" id_sentence="18" />
        <mention ids_tokens="5-7" string="the children's" id_sentence="34" />
        <mention ids_tokens="10" string="their" id_sentence="34" />
        <mention ids_tokens="3-4" string="my children" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="30" type="NOMINAL">
      <referenced ids_tokens="30-31" string="the case" id_sentence="18" />
      <mentions>
        <mention ids_tokens="25" string="its" id_sentence="21" />
        <mention ids_tokens="12-38" string="the case , which defense attorneys said was the result of community hysteria sparked by bizarre allegations by the alcoholic mother of one child at the preschool" id_sentence="26" />
        <mention ids_tokens="10-28" string="the case , which gained worldwide attention with its tales of underground tunnels at the school and Satanic rituals" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="31" type="NOMINAL">
      <referenced ids_tokens="7-8" string="the message" id_sentence="19" />
      <mentions>
        <mention ids_tokens="6" string="that" id_sentence="20" />
      </mentions>
    </coreference>
    <coreference id="33" type="PROPER">
      <referenced ids_tokens="16" string="Attorney" id_sentence="21" />
      <mentions>
        <mention ids_tokens="15" string="his" id_sentence="27" />
        <mention ids_tokens="25" string="him" id_sentence="27" />
      </mentions>
    </coreference>
    <coreference id="34" type="PROPER">
      <referenced ids_tokens="17-18" string="Lael Rubin" id_sentence="21" />
      <mentions>
        <mention ids_tokens="6-14" string="Lael Rubin , who is ` anything goes'" id_sentence="22" />
        <mention ids_tokens="15" string="he" id_sentence="23" />
        <mention ids_tokens="17-21" string="Ms. Rubin , the prosecutor" id_sentence="49" />
        <mention ids_tokens="17-18" string="Ms. Rubin" id_sentence="49" />
        <mention ids_tokens="18" string="Rubin" id_sentence="49" />
        <mention ids_tokens="20-21" string="the prosecutor" id_sentence="49" />
      </mentions>
    </coreference>
    <coreference id="35" type="PROPER">
      <referenced ids_tokens="1-2-3" string="Juror Brenda Williams" id_sentence="24" />
      <mentions>
        <mention ids_tokens="26-27" string="Ms. Williams" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="36" type="NOMINAL">
      <referenced ids_tokens="5-6" string="the evidence" id_sentence="24" />
      <mentions>
        <mention ids_tokens="12" string="it" id_sentence="25" />
      </mentions>
    </coreference>
    <coreference id="37" type="PROPER">
      <referenced ids_tokens="4-5-6" string="nearly five years" id_sentence="26" />
      <mentions>
        <mention ids_tokens="9-10" string="five years" id_sentence="29" />
        <mention ids_tokens="9-10" string="the years" id_sentence="38" />
      </mentions>
    </coreference>
    <coreference id="38" type="NOMINAL">
      <referenced ids_tokens="16-17" string="defense attorneys" id_sentence="26" />
      <mentions>
        <mention ids_tokens="2" string="We" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="39" type="PROPER">
      <referenced ids_tokens="20-21" string="Ira Reiner" id_sentence="27" />
      <mentions>
        <mention ids_tokens="2" string="him" id_sentence="30" />
        <mention ids_tokens="12" string="Reiner" id_sentence="38" />
        <mention ids_tokens="1" string="Reiner" id_sentence="41" />
        <mention ids_tokens="6" string="Reiner" id_sentence="43" />
      </mentions>
    </coreference>
    <coreference id="40" type="NOMINAL">
      <referenced ids_tokens="29-30-31-32-33" string="the district attorney 's office" id_sentence="27" />
      <mentions>
        <mention ids_tokens="13" string="I" id_sentence="29" />
        <mention ids_tokens="24" string="me" id_sentence="29" />
      </mentions>
    </coreference>
    <coreference id="41" type="PROPER">
      <referenced ids_tokens="1" string="Philibosian" id_sentence="28" />
      <mentions>
        <mention ids_tokens="10-16" string="Philibosian , now in private law practice" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="42" type="PROPER">
      <referenced ids_tokens="16-17-18-19" string="Children 's Institute International" id_sentence="31" />
      <mentions>
        <mention ids_tokens="1-3" string="Children's Institute" id_sentence="35" />
      </mentions>
    </coreference>
    <coreference id="43" type="PROPER">
      <referenced ids_tokens="19-20" string="Virginia McMartin" id_sentence="36" />
      <mentions>
        <mention ids_tokens="25" string="McMartin" id_sentence="48" />
      </mentions>
    </coreference>
    <coreference id="45" type="NOMINAL">
      <referenced ids_tokens="1-2-3" string="The underground tunnels" id_sentence="39" />
      <mentions>
        <mention ids_tokens="21-22" string="underground tunnels" id_sentence="37" />
      </mentions>
    </coreference>
    <coreference id="47" type="NOMINAL">
      <referenced ids_tokens="20-21" string="five defendants" id_sentence="38" />
      <mentions>
        <mention ids_tokens="18-21" string="the defendants as well" id_sentence="50" />
      </mentions>
    </coreference>
  </coreferences>
</document>
