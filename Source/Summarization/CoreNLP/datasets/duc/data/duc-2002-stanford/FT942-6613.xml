<?xml version="1.0" encoding="UTF-8"?>
<document id="0" name="FT942-6613">
  <sentences>
    <sentence id="1" has_coreference="true">
      <content>Last year a biography of Mrs Norma Major - or, if we are being old-fashioned, Mrs John Major - claimed that the Majors&amp;apost; favourite film was Being There.</content>
      <tokens>
        <token id="1" string="Last" lemma="last" stem="last" pos="JJ" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="2" string="year" lemma="year" stem="year" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="biography" lemma="biography" stem="biographi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Mrs" lemma="Mrs" stem="mr" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="7" string="Norma" lemma="Norma" stem="norma" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="or" lemma="or" stem="or" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="if" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="we" lemma="we" stem="we" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="16" string="old-fashioned" lemma="old-fashioned" stem="old-fashion" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="Mrs" lemma="Mrs" stem="mr" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="19" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="20" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="21" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="22" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="24" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="25" string="Majors" lemma="Majors" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="'" lemma="'" stem="'" pos="POS" type="Symbol" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="favourite" lemma="favourite" stem="favourit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="28" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="29" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="Being" lemma="be" stem="be" pos="VBG" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="31" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP-TMP (JJ Last) (NN year)) (NP (NP (DT a) (NN biography)) (PP (IN of) (NP (NP (NP (NNP Mrs) (NNP Norma) (NNP Major)) (: -) (CC or) (PRN (, ,) (SBAR (IN if) (S (NP (PRP we)) (VP (VBP are) (VP (VBG being) (ADJP (JJ old-fashioned)))))) (, ,)) (NP (NNP Mrs) (NNP John) (NNP Major)) (: -)) (VP (VBD claimed) (SBAR (IN that) (S (NP (NP (DT the) (NNP Majors) (POS ')) (JJ favourite) (NN film)))))))) (VP (VBD was) (S (VP (VBG Being) (NP (EX There))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was Being There" type="VP">
          <tokens>
            <token id="29" string="was" />
            <token id="30" string="Being" />
            <token id="31" string="There" />
          </tokens>
        </chunking>
        <chunking id="2" string="old-fashioned" type="ADJP">
          <tokens>
            <token id="16" string="old-fashioned" />
          </tokens>
        </chunking>
        <chunking id="3" string="are being old-fashioned" type="VP">
          <tokens>
            <token id="14" string="are" />
            <token id="15" string="being" />
            <token id="16" string="old-fashioned" />
          </tokens>
        </chunking>
        <chunking id="4" string="claimed that the Majors ' favourite film" type="VP">
          <tokens>
            <token id="22" string="claimed" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="Majors" />
            <token id="26" string="'" />
            <token id="27" string="favourite" />
            <token id="28" string="film" />
          </tokens>
        </chunking>
        <chunking id="5" string="we" type="NP">
          <tokens>
            <token id="13" string="we" />
          </tokens>
        </chunking>
        <chunking id="6" string="Being There" type="VP">
          <tokens>
            <token id="30" string="Being" />
            <token id="31" string="There" />
          </tokens>
        </chunking>
        <chunking id="7" string="if we are being old-fashioned" type="SBAR">
          <tokens>
            <token id="12" string="if" />
            <token id="13" string="we" />
            <token id="14" string="are" />
            <token id="15" string="being" />
            <token id="16" string="old-fashioned" />
          </tokens>
        </chunking>
        <chunking id="8" string="Mrs Norma Major - or , if we are being old-fashioned , Mrs John Major -" type="NP">
          <tokens>
            <token id="6" string="Mrs" />
            <token id="7" string="Norma" />
            <token id="8" string="Major" />
            <token id="9" string="-" />
            <token id="10" string="or" />
            <token id="11" string="," />
            <token id="12" string="if" />
            <token id="13" string="we" />
            <token id="14" string="are" />
            <token id="15" string="being" />
            <token id="16" string="old-fashioned" />
            <token id="17" string="," />
            <token id="18" string="Mrs" />
            <token id="19" string="John" />
            <token id="20" string="Major" />
            <token id="21" string="-" />
          </tokens>
        </chunking>
        <chunking id="9" string="a biography of Mrs Norma Major - or , if we are being old-fashioned , Mrs John Major - claimed that the Majors ' favourite film" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="biography" />
            <token id="5" string="of" />
            <token id="6" string="Mrs" />
            <token id="7" string="Norma" />
            <token id="8" string="Major" />
            <token id="9" string="-" />
            <token id="10" string="or" />
            <token id="11" string="," />
            <token id="12" string="if" />
            <token id="13" string="we" />
            <token id="14" string="are" />
            <token id="15" string="being" />
            <token id="16" string="old-fashioned" />
            <token id="17" string="," />
            <token id="18" string="Mrs" />
            <token id="19" string="John" />
            <token id="20" string="Major" />
            <token id="21" string="-" />
            <token id="22" string="claimed" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="Majors" />
            <token id="26" string="'" />
            <token id="27" string="favourite" />
            <token id="28" string="film" />
          </tokens>
        </chunking>
        <chunking id="10" string="Mrs John Major" type="NP">
          <tokens>
            <token id="18" string="Mrs" />
            <token id="19" string="John" />
            <token id="20" string="Major" />
          </tokens>
        </chunking>
        <chunking id="11" string="There" type="NP">
          <tokens>
            <token id="31" string="There" />
          </tokens>
        </chunking>
        <chunking id="12" string="the Majors ' favourite film" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Majors" />
            <token id="26" string="'" />
            <token id="27" string="favourite" />
            <token id="28" string="film" />
          </tokens>
        </chunking>
        <chunking id="13" string="the Majors '" type="NP">
          <tokens>
            <token id="24" string="the" />
            <token id="25" string="Majors" />
            <token id="26" string="'" />
          </tokens>
        </chunking>
        <chunking id="14" string="being old-fashioned" type="VP">
          <tokens>
            <token id="15" string="being" />
            <token id="16" string="old-fashioned" />
          </tokens>
        </chunking>
        <chunking id="15" string="a biography" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="biography" />
          </tokens>
        </chunking>
        <chunking id="16" string="Mrs Norma Major - or , if we are being old-fashioned , Mrs John Major - claimed that the Majors ' favourite film" type="NP">
          <tokens>
            <token id="6" string="Mrs" />
            <token id="7" string="Norma" />
            <token id="8" string="Major" />
            <token id="9" string="-" />
            <token id="10" string="or" />
            <token id="11" string="," />
            <token id="12" string="if" />
            <token id="13" string="we" />
            <token id="14" string="are" />
            <token id="15" string="being" />
            <token id="16" string="old-fashioned" />
            <token id="17" string="," />
            <token id="18" string="Mrs" />
            <token id="19" string="John" />
            <token id="20" string="Major" />
            <token id="21" string="-" />
            <token id="22" string="claimed" />
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="Majors" />
            <token id="26" string="'" />
            <token id="27" string="favourite" />
            <token id="28" string="film" />
          </tokens>
        </chunking>
        <chunking id="17" string="that the Majors ' favourite film" type="SBAR">
          <tokens>
            <token id="23" string="that" />
            <token id="24" string="the" />
            <token id="25" string="Majors" />
            <token id="26" string="'" />
            <token id="27" string="favourite" />
            <token id="28" string="film" />
          </tokens>
        </chunking>
        <chunking id="18" string="Mrs Norma Major" type="NP">
          <tokens>
            <token id="6" string="Mrs" />
            <token id="7" string="Norma" />
            <token id="8" string="Major" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="amod">
          <governor id="2">year</governor>
          <dependent id="1">Last</dependent>
        </dependency>
        <dependency type="nmod:tmod">
          <governor id="29">was</governor>
          <dependent id="2">year</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">biography</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">was</governor>
          <dependent id="4">biography</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Major</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Major</governor>
          <dependent id="6">Mrs</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Major</governor>
          <dependent id="7">Norma</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">biography</governor>
          <dependent id="8">Major</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">Major</governor>
          <dependent id="10">or</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">old-fashioned</governor>
          <dependent id="12">if</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">old-fashioned</governor>
          <dependent id="13">we</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">old-fashioned</governor>
          <dependent id="14">are</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">old-fashioned</governor>
          <dependent id="15">being</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="8">Major</governor>
          <dependent id="16">old-fashioned</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Major</governor>
          <dependent id="18">Mrs</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Major</governor>
          <dependent id="19">John</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">Major</governor>
          <dependent id="20">Major</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="8">Major</governor>
          <dependent id="22">claimed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">film</governor>
          <dependent id="23">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">Majors</governor>
          <dependent id="24">the</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="28">film</governor>
          <dependent id="25">Majors</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Majors</governor>
          <dependent id="26">'</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="28">film</governor>
          <dependent id="27">favourite</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">claimed</governor>
          <dependent id="28">film</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="29">was</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="31">There</governor>
          <dependent id="30">Being</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="29">was</governor>
          <dependent id="31">There</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Mrs John Major" type="PERSON" score="0.0">
          <tokens>
            <token id="18" string="Mrs" />
            <token id="19" string="John" />
            <token id="20" string="Major" />
          </tokens>
        </entity>
        <entity id="2" string="Last year" type="DATE" score="0.0">
          <tokens>
            <token id="1" string="Last" />
            <token id="2" string="year" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="2" has_coreference="true">
      <content>I entirely concur with their choice.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="entirely" lemma="entirely" stem="entir" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="concur" lemma="concur" stem="concur" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="their" lemma="they" stem="their" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="choice" lemma="choice" stem="choic" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (ADVP (RB entirely)) (VP (VBP concur) (PP (IN with) (NP (PRP$ their) (NN choice)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="concur with their choice" type="VP">
          <tokens>
            <token id="3" string="concur" />
            <token id="4" string="with" />
            <token id="5" string="their" />
            <token id="6" string="choice" />
          </tokens>
        </chunking>
        <chunking id="2" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="3" string="their choice" type="NP">
          <tokens>
            <token id="5" string="their" />
            <token id="6" string="choice" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="3">concur</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="3">concur</governor>
          <dependent id="2">entirely</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">concur</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">choice</governor>
          <dependent id="4">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="6">choice</governor>
          <dependent id="5">their</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">concur</governor>
          <dependent id="6">choice</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="3" has_coreference="true">
      <content>In case you did not see that marvellous film, this, in essence, was the plot: a man no one knows anything about, a gardener called Chauncey, rises without trace to become, by the end of the film, a serious candidate for the US presidency.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="case" lemma="case" stem="case" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="marvellous" lemma="marvellous" stem="marvel" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="essence" lemma="essence" stem="essenc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="plot" lemma="plot" stem="plot" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="19" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="21" string="man" lemma="man" stem="man" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="one" lemma="one" stem="on" pos="NN" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="24" string="knows" lemma="know" stem="know" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="anything" lemma="anything" stem="anyth" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="about" lemma="about" stem="about" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="gardener" lemma="gardener" stem="garden" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="called" lemma="call" stem="call" pos="VBN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="Chauncey" lemma="Chauncey" stem="chauncei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="33" string="rises" lemma="rise" stem="rise" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="without" lemma="without" stem="without" pos="IN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="35" string="trace" lemma="trace" stem="trace" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="37" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="38" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="40" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="41" string="end" lemma="end" stem="end" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="42" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="43" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="44" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="45" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="46" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="47" string="serious" lemma="serious" stem="seriou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="48" string="candidate" lemma="candidate" stem="candid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="49" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="50" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="51" string="US" lemma="US" stem="us" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="52" string="presidency" lemma="presidency" stem="presid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="53" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (PP (IN In) (NP (NN case))) (NP (PRP you)) (VP (VBD did) (RB not) (VP (VB see) (NP (DT that) (JJ marvellous) (NN film))))) (, ,) (NP (NP (DT this)) (, ,) (PP (IN in) (NP (NN essence))) (, ,)) (VP (VBD was) (NP (NP (DT the) (NN plot)) (: :) (NP (NP (DT a) (NN man)) (SBAR (S (NP (DT no) (NN one)) (VP (VBZ knows) (SBAR (S (NP (NP (NN anything) (RB about)) (, ,) (NP (NP (DT a) (NN gardener)) (VP (VBN called) (NP (NNP Chauncey)))) (, ,)) (VP (VBZ rises) (PP (IN without) (NP (NN trace))) (S (VP (TO to) (VP (VB become)))))))))))) (, ,) (PP (IN by) (NP (NP (DT the) (NN end)) (PP (IN of) (NP (NP (DT the) (NN film)) (, ,) (NP (NP (DT a) (JJ serious) (NN candidate)) (PP (IN for) (NP (DT the) (NNP US) (NN presidency))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="anything about , a gardener called Chauncey ," type="NP">
          <tokens>
            <token id="25" string="anything" />
            <token id="26" string="about" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="gardener" />
            <token id="30" string="called" />
            <token id="31" string="Chauncey" />
            <token id="32" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="no one" type="NP">
          <tokens>
            <token id="22" string="no" />
            <token id="23" string="one" />
          </tokens>
        </chunking>
        <chunking id="3" string="the end of the film , a serious candidate for the US presidency" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="end" />
            <token id="42" string="of" />
            <token id="43" string="the" />
            <token id="44" string="film" />
            <token id="45" string="," />
            <token id="46" string="a" />
            <token id="47" string="serious" />
            <token id="48" string="candidate" />
            <token id="49" string="for" />
            <token id="50" string="the" />
            <token id="51" string="US" />
            <token id="52" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="4" string="this" type="NP">
          <tokens>
            <token id="11" string="this" />
          </tokens>
        </chunking>
        <chunking id="5" string="rises without trace to become" type="VP">
          <tokens>
            <token id="33" string="rises" />
            <token id="34" string="without" />
            <token id="35" string="trace" />
            <token id="36" string="to" />
            <token id="37" string="become" />
          </tokens>
        </chunking>
        <chunking id="6" string="to become" type="VP">
          <tokens>
            <token id="36" string="to" />
            <token id="37" string="become" />
          </tokens>
        </chunking>
        <chunking id="7" string="a man no one knows anything about , a gardener called Chauncey , rises without trace to become" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="man" />
            <token id="22" string="no" />
            <token id="23" string="one" />
            <token id="24" string="knows" />
            <token id="25" string="anything" />
            <token id="26" string="about" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="gardener" />
            <token id="30" string="called" />
            <token id="31" string="Chauncey" />
            <token id="32" string="," />
            <token id="33" string="rises" />
            <token id="34" string="without" />
            <token id="35" string="trace" />
            <token id="36" string="to" />
            <token id="37" string="become" />
          </tokens>
        </chunking>
        <chunking id="8" string="a gardener" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="gardener" />
          </tokens>
        </chunking>
        <chunking id="9" string="anything about" type="NP">
          <tokens>
            <token id="25" string="anything" />
            <token id="26" string="about" />
          </tokens>
        </chunking>
        <chunking id="10" string="a man" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="man" />
          </tokens>
        </chunking>
        <chunking id="11" string="become" type="VP">
          <tokens>
            <token id="37" string="become" />
          </tokens>
        </chunking>
        <chunking id="12" string="Chauncey" type="NP">
          <tokens>
            <token id="31" string="Chauncey" />
          </tokens>
        </chunking>
        <chunking id="13" string="case" type="NP">
          <tokens>
            <token id="2" string="case" />
          </tokens>
        </chunking>
        <chunking id="14" string="the end" type="NP">
          <tokens>
            <token id="40" string="the" />
            <token id="41" string="end" />
          </tokens>
        </chunking>
        <chunking id="15" string="the film , a serious candidate for the US presidency" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="film" />
            <token id="45" string="," />
            <token id="46" string="a" />
            <token id="47" string="serious" />
            <token id="48" string="candidate" />
            <token id="49" string="for" />
            <token id="50" string="the" />
            <token id="51" string="US" />
            <token id="52" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="16" string="this , in essence ," type="NP">
          <tokens>
            <token id="11" string="this" />
            <token id="12" string="," />
            <token id="13" string="in" />
            <token id="14" string="essence" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="17" string="see that marvellous film" type="VP">
          <tokens>
            <token id="6" string="see" />
            <token id="7" string="that" />
            <token id="8" string="marvellous" />
            <token id="9" string="film" />
          </tokens>
        </chunking>
        <chunking id="18" string="a gardener called Chauncey" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="gardener" />
            <token id="30" string="called" />
            <token id="31" string="Chauncey" />
          </tokens>
        </chunking>
        <chunking id="19" string="the US presidency" type="NP">
          <tokens>
            <token id="50" string="the" />
            <token id="51" string="US" />
            <token id="52" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="20" string="the plot" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="plot" />
          </tokens>
        </chunking>
        <chunking id="21" string="the film" type="NP">
          <tokens>
            <token id="43" string="the" />
            <token id="44" string="film" />
          </tokens>
        </chunking>
        <chunking id="22" string="called Chauncey" type="VP">
          <tokens>
            <token id="30" string="called" />
            <token id="31" string="Chauncey" />
          </tokens>
        </chunking>
        <chunking id="23" string="that marvellous film" type="NP">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="marvellous" />
            <token id="9" string="film" />
          </tokens>
        </chunking>
        <chunking id="24" string="trace" type="NP">
          <tokens>
            <token id="35" string="trace" />
          </tokens>
        </chunking>
        <chunking id="25" string="anything about , a gardener called Chauncey , rises without trace to become" type="SBAR">
          <tokens>
            <token id="25" string="anything" />
            <token id="26" string="about" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="gardener" />
            <token id="30" string="called" />
            <token id="31" string="Chauncey" />
            <token id="32" string="," />
            <token id="33" string="rises" />
            <token id="34" string="without" />
            <token id="35" string="trace" />
            <token id="36" string="to" />
            <token id="37" string="become" />
          </tokens>
        </chunking>
        <chunking id="26" string="no one knows anything about , a gardener called Chauncey , rises without trace to become" type="SBAR">
          <tokens>
            <token id="22" string="no" />
            <token id="23" string="one" />
            <token id="24" string="knows" />
            <token id="25" string="anything" />
            <token id="26" string="about" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="gardener" />
            <token id="30" string="called" />
            <token id="31" string="Chauncey" />
            <token id="32" string="," />
            <token id="33" string="rises" />
            <token id="34" string="without" />
            <token id="35" string="trace" />
            <token id="36" string="to" />
            <token id="37" string="become" />
          </tokens>
        </chunking>
        <chunking id="27" string="was the plot : a man no one knows anything about , a gardener called Chauncey , rises without trace to become , by the end of the film , a serious candidate for the US presidency" type="VP">
          <tokens>
            <token id="16" string="was" />
            <token id="17" string="the" />
            <token id="18" string="plot" />
            <token id="19" string=":" />
            <token id="20" string="a" />
            <token id="21" string="man" />
            <token id="22" string="no" />
            <token id="23" string="one" />
            <token id="24" string="knows" />
            <token id="25" string="anything" />
            <token id="26" string="about" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="gardener" />
            <token id="30" string="called" />
            <token id="31" string="Chauncey" />
            <token id="32" string="," />
            <token id="33" string="rises" />
            <token id="34" string="without" />
            <token id="35" string="trace" />
            <token id="36" string="to" />
            <token id="37" string="become" />
            <token id="38" string="," />
            <token id="39" string="by" />
            <token id="40" string="the" />
            <token id="41" string="end" />
            <token id="42" string="of" />
            <token id="43" string="the" />
            <token id="44" string="film" />
            <token id="45" string="," />
            <token id="46" string="a" />
            <token id="47" string="serious" />
            <token id="48" string="candidate" />
            <token id="49" string="for" />
            <token id="50" string="the" />
            <token id="51" string="US" />
            <token id="52" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="28" string="a serious candidate" type="NP">
          <tokens>
            <token id="46" string="a" />
            <token id="47" string="serious" />
            <token id="48" string="candidate" />
          </tokens>
        </chunking>
        <chunking id="29" string="knows anything about , a gardener called Chauncey , rises without trace to become" type="VP">
          <tokens>
            <token id="24" string="knows" />
            <token id="25" string="anything" />
            <token id="26" string="about" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="gardener" />
            <token id="30" string="called" />
            <token id="31" string="Chauncey" />
            <token id="32" string="," />
            <token id="33" string="rises" />
            <token id="34" string="without" />
            <token id="35" string="trace" />
            <token id="36" string="to" />
            <token id="37" string="become" />
          </tokens>
        </chunking>
        <chunking id="30" string="did not see that marvellous film" type="VP">
          <tokens>
            <token id="4" string="did" />
            <token id="5" string="not" />
            <token id="6" string="see" />
            <token id="7" string="that" />
            <token id="8" string="marvellous" />
            <token id="9" string="film" />
          </tokens>
        </chunking>
        <chunking id="31" string="essence" type="NP">
          <tokens>
            <token id="14" string="essence" />
          </tokens>
        </chunking>
        <chunking id="32" string="a serious candidate for the US presidency" type="NP">
          <tokens>
            <token id="46" string="a" />
            <token id="47" string="serious" />
            <token id="48" string="candidate" />
            <token id="49" string="for" />
            <token id="50" string="the" />
            <token id="51" string="US" />
            <token id="52" string="presidency" />
          </tokens>
        </chunking>
        <chunking id="33" string="the plot : a man no one knows anything about , a gardener called Chauncey , rises without trace to become" type="NP">
          <tokens>
            <token id="17" string="the" />
            <token id="18" string="plot" />
            <token id="19" string=":" />
            <token id="20" string="a" />
            <token id="21" string="man" />
            <token id="22" string="no" />
            <token id="23" string="one" />
            <token id="24" string="knows" />
            <token id="25" string="anything" />
            <token id="26" string="about" />
            <token id="27" string="," />
            <token id="28" string="a" />
            <token id="29" string="gardener" />
            <token id="30" string="called" />
            <token id="31" string="Chauncey" />
            <token id="32" string="," />
            <token id="33" string="rises" />
            <token id="34" string="without" />
            <token id="35" string="trace" />
            <token id="36" string="to" />
            <token id="37" string="become" />
          </tokens>
        </chunking>
        <chunking id="34" string="you" type="NP">
          <tokens>
            <token id="3" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="2">case</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">see</governor>
          <dependent id="2">case</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">see</governor>
          <dependent id="3">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">see</governor>
          <dependent id="4">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">see</governor>
          <dependent id="5">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">plot</governor>
          <dependent id="6">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">film</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">film</governor>
          <dependent id="8">marvellous</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="6">see</governor>
          <dependent id="9">film</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">plot</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">essence</governor>
          <dependent id="13">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">this</governor>
          <dependent id="14">essence</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">plot</governor>
          <dependent id="16">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">plot</governor>
          <dependent id="17">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="18">plot</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">man</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">plot</governor>
          <dependent id="21">man</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="23">one</governor>
          <dependent id="22">no</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">knows</governor>
          <dependent id="23">one</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="21">man</governor>
          <dependent id="24">knows</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="33">rises</governor>
          <dependent id="25">anything</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="25">anything</governor>
          <dependent id="26">about</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">gardener</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="25">anything</governor>
          <dependent id="29">gardener</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="29">gardener</governor>
          <dependent id="30">called</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="30">called</governor>
          <dependent id="31">Chauncey</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="24">knows</governor>
          <dependent id="33">rises</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">trace</governor>
          <dependent id="34">without</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">rises</governor>
          <dependent id="35">trace</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="37">become</governor>
          <dependent id="36">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="33">rises</governor>
          <dependent id="37">become</dependent>
        </dependency>
        <dependency type="case">
          <governor id="41">end</governor>
          <dependent id="39">by</dependent>
        </dependency>
        <dependency type="det">
          <governor id="41">end</governor>
          <dependent id="40">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">plot</governor>
          <dependent id="41">end</dependent>
        </dependency>
        <dependency type="case">
          <governor id="44">film</governor>
          <dependent id="42">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="44">film</governor>
          <dependent id="43">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="41">end</governor>
          <dependent id="44">film</dependent>
        </dependency>
        <dependency type="det">
          <governor id="48">candidate</governor>
          <dependent id="46">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="48">candidate</governor>
          <dependent id="47">serious</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="44">film</governor>
          <dependent id="48">candidate</dependent>
        </dependency>
        <dependency type="case">
          <governor id="52">presidency</governor>
          <dependent id="49">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="52">presidency</governor>
          <dependent id="50">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="52">presidency</governor>
          <dependent id="51">US</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="48">candidate</governor>
          <dependent id="52">presidency</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chauncey" type="PERSON" score="0.0">
          <tokens>
            <token id="31" string="Chauncey" />
          </tokens>
        </entity>
        <entity id="2" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="23" string="one" />
          </tokens>
        </entity>
        <entity id="3" string="US" type="LOCATION" score="0.0">
          <tokens>
            <token id="51" string="US" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="4" has_coreference="true">
      <content>Chauncey, played by Peter Sellers, utters only mundane sentiments in a halting monotone but this convinces the Republican party&amp;apost;s power brokers that he is a sure-fire winner.</content>
      <tokens>
        <token id="1" string="Chauncey" lemma="Chauncey" stem="chauncei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="played" lemma="play" stem="plai" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="4" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="Peter" lemma="Peter" stem="peter" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="Sellers" lemma="Sellers" stem="seller" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="utters" lemma="utter" stem="utter" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="only" lemma="only" stem="onli" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="mundane" lemma="mundane" stem="mundan" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="sentiments" lemma="sentiment" stem="sentiment" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="halting" lemma="halt" stem="halt" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="monotone" lemma="monotone" stem="monoton" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="but" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="convinces" lemma="convince" stem="convinc" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="Republican" lemma="republican" stem="republican" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="21" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="power" lemma="power" stem="power" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="24" string="brokers" lemma="broker" stem="broker" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="27" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="29" string="sure-fire" lemma="sure-fire" stem="sure-fir" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="30" string="winner" lemma="winner" stem="winner" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (NP (NNP Chauncey)) (, ,) (VP (VBN played) (PP (IN by) (NP (NNP Peter) (NNP Sellers)))) (, ,)) (VP (VBZ utters) (NP (NP (RB only) (JJ mundane) (NNS sentiments)) (PP (IN in) (NP (DT a) (VBG halting) (NN monotone)))))) (CC but) (S (NP (DT this)) (VP (VBZ convinces) (NP (NP (DT the) (JJ Republican) (NN party) (POS 's)) (NN power) (NNS brokers)) (SBAR (IN that) (S (NP (PRP he)) (VP (VBZ is) (NP (DT a) (JJ sure-fire) (NN winner))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Chauncey" type="NP">
          <tokens>
            <token id="1" string="Chauncey" />
          </tokens>
        </chunking>
        <chunking id="2" string="only mundane sentiments" type="NP">
          <tokens>
            <token id="9" string="only" />
            <token id="10" string="mundane" />
            <token id="11" string="sentiments" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Republican party 's" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Republican" />
            <token id="21" string="party" />
            <token id="22" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="this" type="NP">
          <tokens>
            <token id="17" string="this" />
          </tokens>
        </chunking>
        <chunking id="5" string="utters only mundane sentiments in a halting monotone" type="VP">
          <tokens>
            <token id="8" string="utters" />
            <token id="9" string="only" />
            <token id="10" string="mundane" />
            <token id="11" string="sentiments" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="halting" />
            <token id="15" string="monotone" />
          </tokens>
        </chunking>
        <chunking id="6" string="the Republican party 's power brokers" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="Republican" />
            <token id="21" string="party" />
            <token id="22" string="'s" />
            <token id="23" string="power" />
            <token id="24" string="brokers" />
          </tokens>
        </chunking>
        <chunking id="7" string="a sure-fire winner" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="sure-fire" />
            <token id="30" string="winner" />
          </tokens>
        </chunking>
        <chunking id="8" string="played by Peter Sellers" type="VP">
          <tokens>
            <token id="3" string="played" />
            <token id="4" string="by" />
            <token id="5" string="Peter" />
            <token id="6" string="Sellers" />
          </tokens>
        </chunking>
        <chunking id="9" string="only mundane sentiments in a halting monotone" type="NP">
          <tokens>
            <token id="9" string="only" />
            <token id="10" string="mundane" />
            <token id="11" string="sentiments" />
            <token id="12" string="in" />
            <token id="13" string="a" />
            <token id="14" string="halting" />
            <token id="15" string="monotone" />
          </tokens>
        </chunking>
        <chunking id="10" string="that he is a sure-fire winner" type="SBAR">
          <tokens>
            <token id="25" string="that" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="a" />
            <token id="29" string="sure-fire" />
            <token id="30" string="winner" />
          </tokens>
        </chunking>
        <chunking id="11" string="Peter Sellers" type="NP">
          <tokens>
            <token id="5" string="Peter" />
            <token id="6" string="Sellers" />
          </tokens>
        </chunking>
        <chunking id="12" string="convinces the Republican party 's power brokers that he is a sure-fire winner" type="VP">
          <tokens>
            <token id="18" string="convinces" />
            <token id="19" string="the" />
            <token id="20" string="Republican" />
            <token id="21" string="party" />
            <token id="22" string="'s" />
            <token id="23" string="power" />
            <token id="24" string="brokers" />
            <token id="25" string="that" />
            <token id="26" string="he" />
            <token id="27" string="is" />
            <token id="28" string="a" />
            <token id="29" string="sure-fire" />
            <token id="30" string="winner" />
          </tokens>
        </chunking>
        <chunking id="13" string="is a sure-fire winner" type="VP">
          <tokens>
            <token id="27" string="is" />
            <token id="28" string="a" />
            <token id="29" string="sure-fire" />
            <token id="30" string="winner" />
          </tokens>
        </chunking>
        <chunking id="14" string="he" type="NP">
          <tokens>
            <token id="26" string="he" />
          </tokens>
        </chunking>
        <chunking id="15" string="a halting monotone" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="halting" />
            <token id="15" string="monotone" />
          </tokens>
        </chunking>
        <chunking id="16" string="Chauncey , played by Peter Sellers ," type="NP">
          <tokens>
            <token id="1" string="Chauncey" />
            <token id="2" string="," />
            <token id="3" string="played" />
            <token id="4" string="by" />
            <token id="5" string="Peter" />
            <token id="6" string="Sellers" />
            <token id="7" string="," />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">utters</governor>
          <dependent id="1">Chauncey</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="1">Chauncey</governor>
          <dependent id="3">played</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Sellers</governor>
          <dependent id="4">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Sellers</governor>
          <dependent id="5">Peter</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">played</governor>
          <dependent id="6">Sellers</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">utters</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">sentiments</governor>
          <dependent id="9">only</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">sentiments</governor>
          <dependent id="10">mundane</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">utters</governor>
          <dependent id="11">sentiments</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">monotone</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">monotone</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">monotone</governor>
          <dependent id="14">halting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">sentiments</governor>
          <dependent id="15">monotone</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="8">utters</governor>
          <dependent id="16">but</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">convinces</governor>
          <dependent id="17">this</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="8">utters</governor>
          <dependent id="18">convinces</dependent>
        </dependency>
        <dependency type="det">
          <governor id="21">party</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">party</governor>
          <dependent id="20">Republican</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="24">brokers</governor>
          <dependent id="21">party</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">party</governor>
          <dependent id="22">'s</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="24">brokers</governor>
          <dependent id="23">power</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">convinces</governor>
          <dependent id="24">brokers</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="30">winner</governor>
          <dependent id="25">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="30">winner</governor>
          <dependent id="26">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="30">winner</governor>
          <dependent id="27">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="30">winner</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">winner</governor>
          <dependent id="29">sure-fire</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="18">convinces</governor>
          <dependent id="30">winner</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chauncey" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Chauncey" />
          </tokens>
        </entity>
        <entity id="2" string="Republican" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="20" string="Republican" />
          </tokens>
        </entity>
        <entity id="3" string="Peter Sellers" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="Peter" />
            <token id="6" string="Sellers" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="5" has_coreference="true">
      <content>In Chauncey&amp;apost;s bromides everyone seems to hear what they want to believe.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Chauncey" lemma="Chauncey" stem="chauncei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="bromides" lemma="bromide" stem="bromid" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="everyone" lemma="everyone" stem="everyon" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="seems" lemma="seem" stem="seem" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="hear" lemma="hear" stem="hear" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="what" lemma="what" stem="what" pos="WP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="they" lemma="they" stem="thei" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="want" lemma="want" stem="want" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="believe" lemma="believe" stem="believ" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (NNP Chauncey) (POS 's)) (NNS bromides))) (NP (NN everyone)) (VP (VBZ seems) (S (VP (TO to) (VP (VB hear) (SBAR (WHNP (WP what)) (S (NP (PRP they)) (VP (VBP want) (S (VP (TO to) (VP (VB believe))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="they" type="NP">
          <tokens>
            <token id="10" string="they" />
          </tokens>
        </chunking>
        <chunking id="2" string="Chauncey 's bromides" type="NP">
          <tokens>
            <token id="2" string="Chauncey" />
            <token id="3" string="'s" />
            <token id="4" string="bromides" />
          </tokens>
        </chunking>
        <chunking id="3" string="everyone" type="NP">
          <tokens>
            <token id="5" string="everyone" />
          </tokens>
        </chunking>
        <chunking id="4" string="Chauncey 's" type="NP">
          <tokens>
            <token id="2" string="Chauncey" />
            <token id="3" string="'s" />
          </tokens>
        </chunking>
        <chunking id="5" string="to hear what they want to believe" type="VP">
          <tokens>
            <token id="7" string="to" />
            <token id="8" string="hear" />
            <token id="9" string="what" />
            <token id="10" string="they" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="believe" />
          </tokens>
        </chunking>
        <chunking id="6" string="to believe" type="VP">
          <tokens>
            <token id="12" string="to" />
            <token id="13" string="believe" />
          </tokens>
        </chunking>
        <chunking id="7" string="what they want to believe" type="SBAR">
          <tokens>
            <token id="9" string="what" />
            <token id="10" string="they" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="believe" />
          </tokens>
        </chunking>
        <chunking id="8" string="seems to hear what they want to believe" type="VP">
          <tokens>
            <token id="6" string="seems" />
            <token id="7" string="to" />
            <token id="8" string="hear" />
            <token id="9" string="what" />
            <token id="10" string="they" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="believe" />
          </tokens>
        </chunking>
        <chunking id="9" string="want to believe" type="VP">
          <tokens>
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="believe" />
          </tokens>
        </chunking>
        <chunking id="10" string="believe" type="VP">
          <tokens>
            <token id="13" string="believe" />
          </tokens>
        </chunking>
        <chunking id="11" string="hear what they want to believe" type="VP">
          <tokens>
            <token id="8" string="hear" />
            <token id="9" string="what" />
            <token id="10" string="they" />
            <token id="11" string="want" />
            <token id="12" string="to" />
            <token id="13" string="believe" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">bromides</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="4">bromides</governor>
          <dependent id="2">Chauncey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="2">Chauncey</governor>
          <dependent id="3">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">seems</governor>
          <dependent id="4">bromides</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">seems</governor>
          <dependent id="5">everyone</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">seems</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="8">hear</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="6">seems</governor>
          <dependent id="8">hear</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">want</governor>
          <dependent id="9">what</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">want</governor>
          <dependent id="10">they</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">hear</governor>
          <dependent id="11">want</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="13">believe</governor>
          <dependent id="12">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="11">want</governor>
          <dependent id="13">believe</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chauncey" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Chauncey" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="6" has_coreference="true">
      <content>He has a deadly innocence.</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="deadly" lemma="deadly" stem="deadli" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="innocence" lemma="innocence" stem="innoc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBZ has) (NP (DT a) (JJ deadly) (NN innocence))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
        <chunking id="2" string="a deadly innocence" type="NP">
          <tokens>
            <token id="3" string="a" />
            <token id="4" string="deadly" />
            <token id="5" string="innocence" />
          </tokens>
        </chunking>
        <chunking id="3" string="has a deadly innocence" type="VP">
          <tokens>
            <token id="2" string="has" />
            <token id="3" string="a" />
            <token id="4" string="deadly" />
            <token id="5" string="innocence" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">has</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">has</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">innocence</governor>
          <dependent id="3">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="5">innocence</governor>
          <dependent id="4">deadly</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="2">has</governor>
          <dependent id="5">innocence</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="7" has_coreference="true">
      <content>No wonder the Majors liked this film.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="wonder" lemma="wonder" stem="wonder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="Majors" lemma="Majors" stem="major" pos="NNPS" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="liked" lemma="like" stem="like" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="film" lemma="film" stem="film" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT No) (NN wonder)) (NP (DT the) (NNPS Majors))) (VP (VBD liked) (NP (DT this) (NN film))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="No wonder the Majors" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="wonder" />
            <token id="3" string="the" />
            <token id="4" string="Majors" />
          </tokens>
        </chunking>
        <chunking id="2" string="liked this film" type="VP">
          <tokens>
            <token id="5" string="liked" />
            <token id="6" string="this" />
            <token id="7" string="film" />
          </tokens>
        </chunking>
        <chunking id="3" string="the Majors" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="Majors" />
          </tokens>
        </chunking>
        <chunking id="4" string="No wonder" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="wonder" />
          </tokens>
        </chunking>
        <chunking id="5" string="this film" type="NP">
          <tokens>
            <token id="6" string="this" />
            <token id="7" string="film" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">wonder</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">liked</governor>
          <dependent id="2">wonder</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">Majors</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">wonder</governor>
          <dependent id="4">Majors</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">liked</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">film</governor>
          <dependent id="6">this</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">liked</governor>
          <dependent id="7">film</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="8" has_coreference="true">
      <content>John Major must, at some level, have appreciated the similarity between his own, strangely intangible, rise and that of Chauncey&amp;apost;s.</content>
      <tokens>
        <token id="1" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="2" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="some" lemma="some" stem="some" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="level" lemma="level" stem="level" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="have" lemma="have" stem="have" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="appreciated" lemma="appreciate" stem="appreci" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="similarity" lemma="similarity" stem="similar" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="13" string="between" lemma="between" stem="between" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="15" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="strangely" lemma="strangely" stem="strang" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="intangible" lemma="intangible" stem="intang" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="rise" lemma="rise" stem="rise" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="Chauncey" lemma="Chauncey" stem="chauncei" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="25" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP John) (NNP Major)) (VP (MD must) (, ,) (PP (IN at) (NP (DT some) (NN level))) (, ,) (VP (VBP have) (VP (VBN appreciated) (S (NP (NP (DT the) (NN similarity)) (PP (IN between) (NP (PRP$ his) (JJ own))))) (, ,) (UCP (ADJP (RB strangely) (JJ intangible)) (, ,) (NP (NN rise)) (CC and) (ADVP (IN that) (PP (IN of) (NP (NNP Chauncey) (POS 's)))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="strangely intangible" type="ADJP">
          <tokens>
            <token id="17" string="strangely" />
            <token id="18" string="intangible" />
          </tokens>
        </chunking>
        <chunking id="2" string="Chauncey 's" type="NP">
          <tokens>
            <token id="24" string="Chauncey" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="3" string="appreciated the similarity between his own , strangely intangible , rise and that of Chauncey 's" type="VP">
          <tokens>
            <token id="10" string="appreciated" />
            <token id="11" string="the" />
            <token id="12" string="similarity" />
            <token id="13" string="between" />
            <token id="14" string="his" />
            <token id="15" string="own" />
            <token id="16" string="," />
            <token id="17" string="strangely" />
            <token id="18" string="intangible" />
            <token id="19" string="," />
            <token id="20" string="rise" />
            <token id="21" string="and" />
            <token id="22" string="that" />
            <token id="23" string="of" />
            <token id="24" string="Chauncey" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="4" string="John Major" type="NP">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Major" />
          </tokens>
        </chunking>
        <chunking id="5" string="must , at some level , have appreciated the similarity between his own , strangely intangible , rise and that of Chauncey 's" type="VP">
          <tokens>
            <token id="3" string="must" />
            <token id="4" string="," />
            <token id="5" string="at" />
            <token id="6" string="some" />
            <token id="7" string="level" />
            <token id="8" string="," />
            <token id="9" string="have" />
            <token id="10" string="appreciated" />
            <token id="11" string="the" />
            <token id="12" string="similarity" />
            <token id="13" string="between" />
            <token id="14" string="his" />
            <token id="15" string="own" />
            <token id="16" string="," />
            <token id="17" string="strangely" />
            <token id="18" string="intangible" />
            <token id="19" string="," />
            <token id="20" string="rise" />
            <token id="21" string="and" />
            <token id="22" string="that" />
            <token id="23" string="of" />
            <token id="24" string="Chauncey" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="6" string="some level" type="NP">
          <tokens>
            <token id="6" string="some" />
            <token id="7" string="level" />
          </tokens>
        </chunking>
        <chunking id="7" string="have appreciated the similarity between his own , strangely intangible , rise and that of Chauncey 's" type="VP">
          <tokens>
            <token id="9" string="have" />
            <token id="10" string="appreciated" />
            <token id="11" string="the" />
            <token id="12" string="similarity" />
            <token id="13" string="between" />
            <token id="14" string="his" />
            <token id="15" string="own" />
            <token id="16" string="," />
            <token id="17" string="strangely" />
            <token id="18" string="intangible" />
            <token id="19" string="," />
            <token id="20" string="rise" />
            <token id="21" string="and" />
            <token id="22" string="that" />
            <token id="23" string="of" />
            <token id="24" string="Chauncey" />
            <token id="25" string="'s" />
          </tokens>
        </chunking>
        <chunking id="8" string="the similarity" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="similarity" />
          </tokens>
        </chunking>
        <chunking id="9" string="rise" type="NP">
          <tokens>
            <token id="20" string="rise" />
          </tokens>
        </chunking>
        <chunking id="10" string="his own" type="NP">
          <tokens>
            <token id="14" string="his" />
            <token id="15" string="own" />
          </tokens>
        </chunking>
        <chunking id="11" string="the similarity between his own" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="similarity" />
            <token id="13" string="between" />
            <token id="14" string="his" />
            <token id="15" string="own" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Major</governor>
          <dependent id="1">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">appreciated</governor>
          <dependent id="2">Major</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">appreciated</governor>
          <dependent id="3">must</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">level</governor>
          <dependent id="5">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">level</governor>
          <dependent id="6">some</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">appreciated</governor>
          <dependent id="7">level</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="10">appreciated</governor>
          <dependent id="9">have</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">appreciated</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">similarity</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">appreciated</governor>
          <dependent id="12">similarity</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">own</governor>
          <dependent id="13">between</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="15">own</governor>
          <dependent id="14">his</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">similarity</governor>
          <dependent id="15">own</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">intangible</governor>
          <dependent id="17">strangely</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="10">appreciated</governor>
          <dependent id="18">intangible</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="18">intangible</governor>
          <dependent id="20">rise</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="18">intangible</governor>
          <dependent id="21">and</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">intangible</governor>
          <dependent id="22">that</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Chauncey</governor>
          <dependent id="23">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="22">that</governor>
          <dependent id="24">Chauncey</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">Chauncey</governor>
          <dependent id="25">'s</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Chauncey" type="PERSON" score="0.0">
          <tokens>
            <token id="24" string="Chauncey" />
          </tokens>
        </entity>
        <entity id="2" string="John Major" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="John" />
            <token id="2" string="Major" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="9" has_coreference="true">
      <content>If he did not see the similarity, that is still more revealing.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="did" lemma="do" stem="did" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="see" lemma="see" stem="see" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="similarity" lemma="similarity" stem="similar" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="8" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="still" lemma="still" stem="still" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="more" lemma="more" stem="more" pos="RBR" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="revealing" lemma="revealing" stem="reveal" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (PRP he)) (VP (VBD did) (RB not) (VP (VB see) (NP (DT the) (NN similarity)))))) (, ,) (NP (WDT that)) (VP (VBZ is) (ADVP (RB still)) (ADJP (RBR more) (JJ revealing))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="9" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="If he did not see the similarity" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="he" />
            <token id="3" string="did" />
            <token id="4" string="not" />
            <token id="5" string="see" />
            <token id="6" string="the" />
            <token id="7" string="similarity" />
          </tokens>
        </chunking>
        <chunking id="3" string="is still more revealing" type="VP">
          <tokens>
            <token id="10" string="is" />
            <token id="11" string="still" />
            <token id="12" string="more" />
            <token id="13" string="revealing" />
          </tokens>
        </chunking>
        <chunking id="4" string="he" type="NP">
          <tokens>
            <token id="2" string="he" />
          </tokens>
        </chunking>
        <chunking id="5" string="did not see the similarity" type="VP">
          <tokens>
            <token id="3" string="did" />
            <token id="4" string="not" />
            <token id="5" string="see" />
            <token id="6" string="the" />
            <token id="7" string="similarity" />
          </tokens>
        </chunking>
        <chunking id="6" string="more revealing" type="ADJP">
          <tokens>
            <token id="12" string="more" />
            <token id="13" string="revealing" />
          </tokens>
        </chunking>
        <chunking id="7" string="see the similarity" type="VP">
          <tokens>
            <token id="5" string="see" />
            <token id="6" string="the" />
            <token id="7" string="similarity" />
          </tokens>
        </chunking>
        <chunking id="8" string="the similarity" type="NP">
          <tokens>
            <token id="6" string="the" />
            <token id="7" string="similarity" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="5">see</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">see</governor>
          <dependent id="2">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="5">see</governor>
          <dependent id="3">did</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="5">see</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="13">revealing</governor>
          <dependent id="5">see</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">similarity</governor>
          <dependent id="6">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">see</governor>
          <dependent id="7">similarity</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="13">revealing</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="13">revealing</governor>
          <dependent id="10">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">revealing</governor>
          <dependent id="11">still</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="13">revealing</governor>
          <dependent id="12">more</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="13">revealing</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="10" has_coreference="true">
      <content>Do not protest that the urban John Major could not identify with a gardener.</content>
      <tokens>
        <token id="1" string="Do" lemma="do" stem="do" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="protest" lemma="protest" stem="protest" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="urban" lemma="urban" stem="urban" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="8" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="9" string="could" lemma="could" stem="could" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="identify" lemma="identify" stem="identifi" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="gardener" lemma="gardener" stem="garden" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (VP (VBP Do) (RB not) (VP (VB protest) (SBAR (IN that) (S (NP (DT the) (JJ urban) (NNP John) (NNP Major)) (VP (MD could) (RB not) (VP (VB identify) (PP (IN with) (NP (DT a) (NN gardener))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="could not identify with a gardener" type="VP">
          <tokens>
            <token id="9" string="could" />
            <token id="10" string="not" />
            <token id="11" string="identify" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string="gardener" />
          </tokens>
        </chunking>
        <chunking id="2" string="a gardener" type="NP">
          <tokens>
            <token id="13" string="a" />
            <token id="14" string="gardener" />
          </tokens>
        </chunking>
        <chunking id="3" string="the urban John Major" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="urban" />
            <token id="7" string="John" />
            <token id="8" string="Major" />
          </tokens>
        </chunking>
        <chunking id="4" string="identify with a gardener" type="VP">
          <tokens>
            <token id="11" string="identify" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string="gardener" />
          </tokens>
        </chunking>
        <chunking id="5" string="Do not protest that the urban John Major could not identify with a gardener" type="VP">
          <tokens>
            <token id="1" string="Do" />
            <token id="2" string="not" />
            <token id="3" string="protest" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="urban" />
            <token id="7" string="John" />
            <token id="8" string="Major" />
            <token id="9" string="could" />
            <token id="10" string="not" />
            <token id="11" string="identify" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string="gardener" />
          </tokens>
        </chunking>
        <chunking id="6" string="that the urban John Major could not identify with a gardener" type="SBAR">
          <tokens>
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="urban" />
            <token id="7" string="John" />
            <token id="8" string="Major" />
            <token id="9" string="could" />
            <token id="10" string="not" />
            <token id="11" string="identify" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string="gardener" />
          </tokens>
        </chunking>
        <chunking id="7" string="protest that the urban John Major could not identify with a gardener" type="VP">
          <tokens>
            <token id="3" string="protest" />
            <token id="4" string="that" />
            <token id="5" string="the" />
            <token id="6" string="urban" />
            <token id="7" string="John" />
            <token id="8" string="Major" />
            <token id="9" string="could" />
            <token id="10" string="not" />
            <token id="11" string="identify" />
            <token id="12" string="with" />
            <token id="13" string="a" />
            <token id="14" string="gardener" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="aux">
          <governor id="3">protest</governor>
          <dependent id="1">Do</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="3">protest</governor>
          <dependent id="2">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">protest</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">identify</governor>
          <dependent id="4">that</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">Major</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">Major</governor>
          <dependent id="6">urban</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="8">Major</governor>
          <dependent id="7">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">identify</governor>
          <dependent id="8">Major</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="11">identify</governor>
          <dependent id="9">could</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="11">identify</governor>
          <dependent id="10">not</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">protest</governor>
          <dependent id="11">identify</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">gardener</governor>
          <dependent id="12">with</dependent>
        </dependency>
        <dependency type="det">
          <governor id="14">gardener</governor>
          <dependent id="13">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">identify</governor>
          <dependent id="14">gardener</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Major" type="PERSON" score="0.0">
          <tokens>
            <token id="7" string="John" />
            <token id="8" string="Major" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="11" has_coreference="true">
      <content>In an interview with Farmers Weekly, a few days ago, Major disclosed an unknown fact: his father was once a farmer.</content>
      <tokens>
        <token id="1" string="In" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="interview" lemma="interview" stem="interview" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="Farmers" lemma="Farmers" stem="farmer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="6" string="Weekly" lemma="Weekly" stem="weekli" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="true" is_refers="false" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" ner="SET" is_referenced="false" is_refers="false" />
        <token id="8" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="SET" is_referenced="false" is_refers="false" />
        <token id="9" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="SET" is_referenced="false" is_refers="false" />
        <token id="10" string="days" lemma="day" stem="dai" pos="NNS" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="11" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="SET" is_referenced="false" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="Major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string="disclosed" lemma="disclose" stem="disclos" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="unknown" lemma="unknown" stem="unknown" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="fact" lemma="fact" stem="fact" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="20" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="once" lemma="once" stem="onc" pos="RB" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="23" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="farmer" lemma="farmer" stem="farmer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN In) (NP (NP (DT an) (NN interview)) (PP (IN with) (NP (NNP Farmers) (NNP Weekly))))) (, ,) (S (ADVP (NP (DT a) (JJ few) (NNS days)) (RB ago)) (, ,) (NP (JJ Major)) (VP (VBD disclosed) (NP (DT an) (JJ unknown) (NN fact)))) (: :) (S (NP (PRP$ his) (NN father)) (VP (VBD was) (ADVP (RB once)) (NP (DT a) (NN farmer)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="an interview with Farmers Weekly" type="NP">
          <tokens>
            <token id="2" string="an" />
            <token id="3" string="interview" />
            <token id="4" string="with" />
            <token id="5" string="Farmers" />
            <token id="6" string="Weekly" />
          </tokens>
        </chunking>
        <chunking id="2" string="an interview" type="NP">
          <tokens>
            <token id="2" string="an" />
            <token id="3" string="interview" />
          </tokens>
        </chunking>
        <chunking id="3" string="Major" type="NP">
          <tokens>
            <token id="13" string="Major" />
          </tokens>
        </chunking>
        <chunking id="4" string="a farmer" type="NP">
          <tokens>
            <token id="23" string="a" />
            <token id="24" string="farmer" />
          </tokens>
        </chunking>
        <chunking id="5" string="his father" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="father" />
          </tokens>
        </chunking>
        <chunking id="6" string="an unknown fact" type="NP">
          <tokens>
            <token id="15" string="an" />
            <token id="16" string="unknown" />
            <token id="17" string="fact" />
          </tokens>
        </chunking>
        <chunking id="7" string="Farmers Weekly" type="NP">
          <tokens>
            <token id="5" string="Farmers" />
            <token id="6" string="Weekly" />
          </tokens>
        </chunking>
        <chunking id="8" string="a few days" type="NP">
          <tokens>
            <token id="8" string="a" />
            <token id="9" string="few" />
            <token id="10" string="days" />
          </tokens>
        </chunking>
        <chunking id="9" string="disclosed an unknown fact" type="VP">
          <tokens>
            <token id="14" string="disclosed" />
            <token id="15" string="an" />
            <token id="16" string="unknown" />
            <token id="17" string="fact" />
          </tokens>
        </chunking>
        <chunking id="10" string="was once a farmer" type="VP">
          <tokens>
            <token id="21" string="was" />
            <token id="22" string="once" />
            <token id="23" string="a" />
            <token id="24" string="farmer" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">interview</governor>
          <dependent id="1">In</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">interview</governor>
          <dependent id="2">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="14">disclosed</governor>
          <dependent id="3">interview</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">Weekly</governor>
          <dependent id="4">with</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Weekly</governor>
          <dependent id="5">Farmers</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="3">interview</governor>
          <dependent id="6">Weekly</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">days</governor>
          <dependent id="8">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">days</governor>
          <dependent id="9">few</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="11">ago</governor>
          <dependent id="10">days</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="14">disclosed</governor>
          <dependent id="11">ago</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="14">disclosed</governor>
          <dependent id="13">Major</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="14">disclosed</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">fact</governor>
          <dependent id="15">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">fact</governor>
          <dependent id="16">unknown</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="14">disclosed</governor>
          <dependent id="17">fact</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">father</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="24">farmer</governor>
          <dependent id="20">father</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">farmer</governor>
          <dependent id="21">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="24">farmer</governor>
          <dependent id="22">once</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">farmer</governor>
          <dependent id="23">a</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="14">disclosed</governor>
          <dependent id="24">farmer</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string=", a few days ago" type="SET" score="0.0">
          <tokens>
            <token id="7" string="," />
            <token id="8" string="a" />
            <token id="9" string="few" />
            <token id="10" string="days" />
            <token id="11" string="ago" />
          </tokens>
        </entity>
        <entity id="2" string="once" type="DATE" score="0.0">
          <tokens>
            <token id="22" string="once" />
          </tokens>
        </entity>
        <entity id="3" string="Farmers Weekly" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="5" string="Farmers" />
            <token id="6" string="Weekly" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="12" has_coreference="true">
      <content>Farmers Weekly, you see, had asked Major how he had &amp;apost;such obvious empathy with agriculture&amp;apost;.</content>
      <tokens>
        <token id="1" string="Farmers" lemma="Farmers" stem="farmer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="2" string="Weekly" lemma="Weekly" stem="weekli" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="see" lemma="see" stem="see" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="asked" lemma="ask" stem="ask" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="14" string="such" lemma="such" stem="such" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="15" string="obvious" lemma="obvious" stem="obviou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="16" string="empathy" lemma="empathy" stem="empathi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="17" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="18" string="agriculture" lemma="agriculture" stem="agricultur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="19" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Farmers) (NNP Weekly)) (PRN (, ,) (S (NP (PRP you)) (VP (VBP see))) (, ,)) (VP (VBD had) (VP (VBN asked) (NP (NP (NNP Major)) (SBAR (WHADVP (WRB how)) (S (NP (PRP he)) (VP (VBD had) (NP (`` `) (NP (JJ such) (JJ obvious) (NN empathy)) (PP (IN with) (NP (NN agriculture))) ('' ')))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="such obvious empathy" type="NP">
          <tokens>
            <token id="14" string="such" />
            <token id="15" string="obvious" />
            <token id="16" string="empathy" />
          </tokens>
        </chunking>
        <chunking id="2" string="asked Major how he had ` such obvious empathy with agriculture '" type="VP">
          <tokens>
            <token id="8" string="asked" />
            <token id="9" string="Major" />
            <token id="10" string="how" />
            <token id="11" string="he" />
            <token id="12" string="had" />
            <token id="13" string="'" />
            <token id="14" string="such" />
            <token id="15" string="obvious" />
            <token id="16" string="empathy" />
            <token id="17" string="with" />
            <token id="18" string="agriculture" />
            <token id="19" string="'" />
          </tokens>
        </chunking>
        <chunking id="3" string="Farmers Weekly" type="NP">
          <tokens>
            <token id="1" string="Farmers" />
            <token id="2" string="Weekly" />
          </tokens>
        </chunking>
        <chunking id="4" string="how" type="WHADVP">
          <tokens>
            <token id="10" string="how" />
          </tokens>
        </chunking>
        <chunking id="5" string="Major how he had ` such obvious empathy with agriculture '" type="NP">
          <tokens>
            <token id="9" string="Major" />
            <token id="10" string="how" />
            <token id="11" string="he" />
            <token id="12" string="had" />
            <token id="13" string="'" />
            <token id="14" string="such" />
            <token id="15" string="obvious" />
            <token id="16" string="empathy" />
            <token id="17" string="with" />
            <token id="18" string="agriculture" />
            <token id="19" string="'" />
          </tokens>
        </chunking>
        <chunking id="6" string="agriculture" type="NP">
          <tokens>
            <token id="18" string="agriculture" />
          </tokens>
        </chunking>
        <chunking id="7" string="Major" type="NP">
          <tokens>
            <token id="9" string="Major" />
          </tokens>
        </chunking>
        <chunking id="8" string="see" type="VP">
          <tokens>
            <token id="5" string="see" />
          </tokens>
        </chunking>
        <chunking id="9" string="` such obvious empathy with agriculture '" type="NP">
          <tokens>
            <token id="13" string="'" />
            <token id="14" string="such" />
            <token id="15" string="obvious" />
            <token id="16" string="empathy" />
            <token id="17" string="with" />
            <token id="18" string="agriculture" />
            <token id="19" string="'" />
          </tokens>
        </chunking>
        <chunking id="10" string="how he had ` such obvious empathy with agriculture '" type="SBAR">
          <tokens>
            <token id="10" string="how" />
            <token id="11" string="he" />
            <token id="12" string="had" />
            <token id="13" string="'" />
            <token id="14" string="such" />
            <token id="15" string="obvious" />
            <token id="16" string="empathy" />
            <token id="17" string="with" />
            <token id="18" string="agriculture" />
            <token id="19" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="he" type="NP">
          <tokens>
            <token id="11" string="he" />
          </tokens>
        </chunking>
        <chunking id="12" string="had ` such obvious empathy with agriculture '" type="VP">
          <tokens>
            <token id="12" string="had" />
            <token id="13" string="'" />
            <token id="14" string="such" />
            <token id="15" string="obvious" />
            <token id="16" string="empathy" />
            <token id="17" string="with" />
            <token id="18" string="agriculture" />
            <token id="19" string="'" />
          </tokens>
        </chunking>
        <chunking id="13" string="had asked Major how he had ` such obvious empathy with agriculture '" type="VP">
          <tokens>
            <token id="7" string="had" />
            <token id="8" string="asked" />
            <token id="9" string="Major" />
            <token id="10" string="how" />
            <token id="11" string="he" />
            <token id="12" string="had" />
            <token id="13" string="'" />
            <token id="14" string="such" />
            <token id="15" string="obvious" />
            <token id="16" string="empathy" />
            <token id="17" string="with" />
            <token id="18" string="agriculture" />
            <token id="19" string="'" />
          </tokens>
        </chunking>
        <chunking id="14" string="you" type="NP">
          <tokens>
            <token id="4" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Weekly</governor>
          <dependent id="1">Farmers</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">asked</governor>
          <dependent id="2">Weekly</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">see</governor>
          <dependent id="4">you</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="8">asked</governor>
          <dependent id="5">see</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">asked</governor>
          <dependent id="7">had</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">asked</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="8">asked</governor>
          <dependent id="9">Major</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="12">had</governor>
          <dependent id="10">how</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">had</governor>
          <dependent id="11">he</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">Major</governor>
          <dependent id="12">had</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">empathy</governor>
          <dependent id="14">such</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">empathy</governor>
          <dependent id="15">obvious</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">had</governor>
          <dependent id="16">empathy</dependent>
        </dependency>
        <dependency type="case">
          <governor id="18">agriculture</governor>
          <dependent id="17">with</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">empathy</governor>
          <dependent id="18">agriculture</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Farmers Weekly" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="1" string="Farmers" />
            <token id="2" string="Weekly" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="13" has_coreference="true">
      <content>(Well, it was obvious to Farmers Weekly, anyway.)</content>
      <tokens>
        <token id="1" string="(" lemma="-lrb-" stem="(" pos="-LRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Well" lemma="well" stem="well" pos="UH" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="obvious" lemma="obvious" stem="obviou" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Farmers" lemma="Farmers" stem="farmer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="9" string="Weekly" lemma="Weekly" stem="weekli" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="anyway" lemma="anyway" stem="anywai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string=")" lemma="-rrb-" stem=")" pos="-RRB-" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (-LRB- -LRB-) (ADVP (UH Well)) (, ,) (NP (PRP it)) (VP (VBD was) (ADJP (JJ obvious)) (PP (TO to) (NP (NNP Farmers) (NNP Weekly))) (, ,) (ADVP (RB anyway))) (. .) (-RRB- -RRB-)))</syntactictree>
      <chunkings>
        <chunking id="1" string="obvious" type="ADJP">
          <tokens>
            <token id="6" string="obvious" />
          </tokens>
        </chunking>
        <chunking id="2" string="it" type="NP">
          <tokens>
            <token id="4" string="it" />
          </tokens>
        </chunking>
        <chunking id="3" string="Farmers Weekly" type="NP">
          <tokens>
            <token id="8" string="Farmers" />
            <token id="9" string="Weekly" />
          </tokens>
        </chunking>
        <chunking id="4" string="was obvious to Farmers Weekly , anyway" type="VP">
          <tokens>
            <token id="5" string="was" />
            <token id="6" string="obvious" />
            <token id="7" string="to" />
            <token id="8" string="Farmers" />
            <token id="9" string="Weekly" />
            <token id="10" string="," />
            <token id="11" string="anyway" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="6">obvious</governor>
          <dependent id="2">Well</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">obvious</governor>
          <dependent id="4">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">obvious</governor>
          <dependent id="5">was</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">obvious</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Weekly</governor>
          <dependent id="7">to</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">Weekly</governor>
          <dependent id="8">Farmers</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">obvious</governor>
          <dependent id="9">Weekly</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="6">obvious</governor>
          <dependent id="11">anyway</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Farmers Weekly" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="8" string="Farmers" />
            <token id="9" string="Weekly" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="14" has_coreference="true">
      <content>And Major replied: &amp;apost;It&amp;apost;s simple.</content>
      <tokens>
        <token id="1" string="And" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="replied" lemma="reply" stem="repli" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="It" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="'s" lemma="be" stem="'" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="simple" lemma="simple" stem="simpl" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC And) (NP (JJ Major)) (VP (VBD replied) (: :) (`` `) (S (NP (PRP It)) (VP (VBZ 's) (ADJP (JJ simple))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Major" type="NP">
          <tokens>
            <token id="2" string="Major" />
          </tokens>
        </chunking>
        <chunking id="2" string="replied : ` It 's simple" type="VP">
          <tokens>
            <token id="3" string="replied" />
            <token id="4" string=":" />
            <token id="5" string="'" />
            <token id="6" string="It" />
            <token id="7" string="'s" />
            <token id="8" string="simple" />
          </tokens>
        </chunking>
        <chunking id="3" string="'s simple" type="VP">
          <tokens>
            <token id="7" string="'s" />
            <token id="8" string="simple" />
          </tokens>
        </chunking>
        <chunking id="4" string="simple" type="ADJP">
          <tokens>
            <token id="8" string="simple" />
          </tokens>
        </chunking>
        <chunking id="5" string="It" type="NP">
          <tokens>
            <token id="6" string="It" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="3">replied</governor>
          <dependent id="1">And</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">replied</governor>
          <dependent id="2">Major</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="3">replied</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="8">simple</governor>
          <dependent id="6">It</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="8">simple</governor>
          <dependent id="7">'s</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="3">replied</governor>
          <dependent id="8">simple</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="15" has_coreference="true">
      <content>My father was a farmer.</content>
      <tokens>
        <token id="1" string="My" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="farmer" lemma="farmer" stem="farmer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="6" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP$ My) (NN father)) (VP (VBD was) (NP (DT a) (NN farmer))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="was a farmer" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="a" />
            <token id="5" string="farmer" />
          </tokens>
        </chunking>
        <chunking id="2" string="a farmer" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="farmer" />
          </tokens>
        </chunking>
        <chunking id="3" string="My father" type="NP">
          <tokens>
            <token id="1" string="My" />
            <token id="2" string="father" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">father</governor>
          <dependent id="1">My</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">farmer</governor>
          <dependent id="2">father</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">farmer</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">farmer</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">farmer</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="16" has_coreference="true">
      <content>He lived on a small farm somewhere in Shropshire.&amp;apost;</content>
      <tokens>
        <token id="1" string="He" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="lived" lemma="live" stem="live" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="on" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="small" lemma="small" stem="small" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="farm" lemma="farm" stem="farm" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="somewhere" lemma="somewhere" stem="somewher" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="Shropshire" lemma="Shropshire" stem="shropshir" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="10" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP He)) (VP (VBD lived) (PP (IN on) (NP (DT a) (JJ small) (NN farm))) (PP (RB somewhere) (IN in) (NP (NNP Shropshire)))) (. .) ('' ')))</syntactictree>
      <chunkings>
        <chunking id="1" string="Shropshire" type="NP">
          <tokens>
            <token id="9" string="Shropshire" />
          </tokens>
        </chunking>
        <chunking id="2" string="lived on a small farm somewhere in Shropshire" type="VP">
          <tokens>
            <token id="2" string="lived" />
            <token id="3" string="on" />
            <token id="4" string="a" />
            <token id="5" string="small" />
            <token id="6" string="farm" />
            <token id="7" string="somewhere" />
            <token id="8" string="in" />
            <token id="9" string="Shropshire" />
          </tokens>
        </chunking>
        <chunking id="3" string="a small farm" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="small" />
            <token id="6" string="farm" />
          </tokens>
        </chunking>
        <chunking id="4" string="He" type="NP">
          <tokens>
            <token id="1" string="He" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">lived</governor>
          <dependent id="1">He</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">lived</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">farm</governor>
          <dependent id="3">on</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">farm</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">farm</governor>
          <dependent id="5">small</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">lived</governor>
          <dependent id="6">farm</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="9">Shropshire</governor>
          <dependent id="7">somewhere</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">Shropshire</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">lived</governor>
          <dependent id="9">Shropshire</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Shropshire" type="LOCATION" score="0.0">
          <tokens>
            <token id="9" string="Shropshire" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="17" has_coreference="true">
      <content>Francis Wheen of The Guardian, a keen student of Major&amp;apost;s mysterious past, immediately rang 10 Downing Street, which claimed that Major&amp;apost;s father farmed near Bromsgrove in 1910.</content>
      <tokens>
        <token id="1" string="Francis" lemma="Francis" stem="franci" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Wheen" lemma="Wheen" stem="wheen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="Guardian" lemma="Guardian" stem="guardian" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="keen" lemma="keen" stem="keen" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="student" lemma="student" stem="student" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="12" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="mysterious" lemma="mysterious" stem="mysteri" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="past" lemma="past" stem="past" pos="NN" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="15" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="immediately" lemma="immediately" stem="immedi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="rang" lemma="ring" stem="rang" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="10" lemma="10" stem="10" pos="CD" type="Number" isStopWord="false" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="19" string="Downing" lemma="Downing" stem="down" pos="NNP" type="Word" isStopWord="true" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="20" string="Street" lemma="Street" stem="street" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="21" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="which" lemma="which" stem="which" pos="WDT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="claimed" lemma="claim" stem="claim" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="26" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="27" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="28" string="farmed" lemma="farm" stem="farm" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="near" lemma="near" stem="near" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="Bromsgrove" lemma="Bromsgrove" stem="bromsgrov" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="31" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="32" string="1910" lemma="1910" stem="1910" pos="CD" type="Number" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="33" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Francis) (NNP Wheen)) (PP (IN of) (NP (DT The) (NNP Guardian)))) (, ,) (NP (NP (DT a) (JJ keen) (NN student)) (PP (IN of) (NP (NP (NNP Major) (POS 's)) (JJ mysterious) (NN past)))) (, ,)) (ADVP (RB immediately)) (VP (VBD rang) (NP (NP (CD 10) (NNP Downing) (NNP Street)) (, ,) (SBAR (WHNP (WDT which)) (S (VP (VBD claimed) (SBAR (IN that) (S (NP (NP (NNP Major) (POS 's)) (NN father)) (VP (VBD farmed) (PP (IN near) (NP (NNP Bromsgrove))) (PP (IN in) (NP (CD 1910))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Major 's mysterious past" type="NP">
          <tokens>
            <token id="11" string="Major" />
            <token id="12" string="'s" />
            <token id="13" string="mysterious" />
            <token id="14" string="past" />
          </tokens>
        </chunking>
        <chunking id="2" string="Major 's father" type="NP">
          <tokens>
            <token id="25" string="Major" />
            <token id="26" string="'s" />
            <token id="27" string="father" />
          </tokens>
        </chunking>
        <chunking id="3" string="Francis Wheen" type="NP">
          <tokens>
            <token id="1" string="Francis" />
            <token id="2" string="Wheen" />
          </tokens>
        </chunking>
        <chunking id="4" string="which claimed that Major 's father farmed near Bromsgrove in 1910" type="SBAR">
          <tokens>
            <token id="22" string="which" />
            <token id="23" string="claimed" />
            <token id="24" string="that" />
            <token id="25" string="Major" />
            <token id="26" string="'s" />
            <token id="27" string="father" />
            <token id="28" string="farmed" />
            <token id="29" string="near" />
            <token id="30" string="Bromsgrove" />
            <token id="31" string="in" />
            <token id="32" string="1910" />
          </tokens>
        </chunking>
        <chunking id="5" string="Francis Wheen of The Guardian" type="NP">
          <tokens>
            <token id="1" string="Francis" />
            <token id="2" string="Wheen" />
            <token id="3" string="of" />
            <token id="4" string="The" />
            <token id="5" string="Guardian" />
          </tokens>
        </chunking>
        <chunking id="6" string="that Major 's father farmed near Bromsgrove in 1910" type="SBAR">
          <tokens>
            <token id="24" string="that" />
            <token id="25" string="Major" />
            <token id="26" string="'s" />
            <token id="27" string="father" />
            <token id="28" string="farmed" />
            <token id="29" string="near" />
            <token id="30" string="Bromsgrove" />
            <token id="31" string="in" />
            <token id="32" string="1910" />
          </tokens>
        </chunking>
        <chunking id="7" string="1910" type="NP">
          <tokens>
            <token id="32" string="1910" />
          </tokens>
        </chunking>
        <chunking id="8" string="Francis Wheen of The Guardian , a keen student of Major 's mysterious past ," type="NP">
          <tokens>
            <token id="1" string="Francis" />
            <token id="2" string="Wheen" />
            <token id="3" string="of" />
            <token id="4" string="The" />
            <token id="5" string="Guardian" />
            <token id="6" string="," />
            <token id="7" string="a" />
            <token id="8" string="keen" />
            <token id="9" string="student" />
            <token id="10" string="of" />
            <token id="11" string="Major" />
            <token id="12" string="'s" />
            <token id="13" string="mysterious" />
            <token id="14" string="past" />
            <token id="15" string="," />
          </tokens>
        </chunking>
        <chunking id="9" string="a keen student of Major 's mysterious past" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="keen" />
            <token id="9" string="student" />
            <token id="10" string="of" />
            <token id="11" string="Major" />
            <token id="12" string="'s" />
            <token id="13" string="mysterious" />
            <token id="14" string="past" />
          </tokens>
        </chunking>
        <chunking id="10" string="a keen student" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="keen" />
            <token id="9" string="student" />
          </tokens>
        </chunking>
        <chunking id="11" string="farmed near Bromsgrove in 1910" type="VP">
          <tokens>
            <token id="28" string="farmed" />
            <token id="29" string="near" />
            <token id="30" string="Bromsgrove" />
            <token id="31" string="in" />
            <token id="32" string="1910" />
          </tokens>
        </chunking>
        <chunking id="12" string="Major 's" type="NP">
          <tokens>
            <token id="11" string="Major" />
            <token id="12" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="The Guardian" type="NP">
          <tokens>
            <token id="4" string="The" />
            <token id="5" string="Guardian" />
          </tokens>
        </chunking>
        <chunking id="14" string="rang 10 Downing Street , which claimed that Major 's father farmed near Bromsgrove in 1910" type="VP">
          <tokens>
            <token id="17" string="rang" />
            <token id="18" string="10" />
            <token id="19" string="Downing" />
            <token id="20" string="Street" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="claimed" />
            <token id="24" string="that" />
            <token id="25" string="Major" />
            <token id="26" string="'s" />
            <token id="27" string="father" />
            <token id="28" string="farmed" />
            <token id="29" string="near" />
            <token id="30" string="Bromsgrove" />
            <token id="31" string="in" />
            <token id="32" string="1910" />
          </tokens>
        </chunking>
        <chunking id="15" string="10 Downing Street" type="NP">
          <tokens>
            <token id="18" string="10" />
            <token id="19" string="Downing" />
            <token id="20" string="Street" />
          </tokens>
        </chunking>
        <chunking id="16" string="Bromsgrove" type="NP">
          <tokens>
            <token id="30" string="Bromsgrove" />
          </tokens>
        </chunking>
        <chunking id="17" string="10 Downing Street , which claimed that Major 's father farmed near Bromsgrove in 1910" type="NP">
          <tokens>
            <token id="18" string="10" />
            <token id="19" string="Downing" />
            <token id="20" string="Street" />
            <token id="21" string="," />
            <token id="22" string="which" />
            <token id="23" string="claimed" />
            <token id="24" string="that" />
            <token id="25" string="Major" />
            <token id="26" string="'s" />
            <token id="27" string="father" />
            <token id="28" string="farmed" />
            <token id="29" string="near" />
            <token id="30" string="Bromsgrove" />
            <token id="31" string="in" />
            <token id="32" string="1910" />
          </tokens>
        </chunking>
        <chunking id="18" string="claimed that Major 's father farmed near Bromsgrove in 1910" type="VP">
          <tokens>
            <token id="23" string="claimed" />
            <token id="24" string="that" />
            <token id="25" string="Major" />
            <token id="26" string="'s" />
            <token id="27" string="father" />
            <token id="28" string="farmed" />
            <token id="29" string="near" />
            <token id="30" string="Bromsgrove" />
            <token id="31" string="in" />
            <token id="32" string="1910" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Wheen</governor>
          <dependent id="1">Francis</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">rang</governor>
          <dependent id="2">Wheen</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Guardian</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="5">Guardian</governor>
          <dependent id="4">The</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">Wheen</governor>
          <dependent id="5">Guardian</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">student</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">student</governor>
          <dependent id="8">keen</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">Wheen</governor>
          <dependent id="9">student</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">past</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">past</governor>
          <dependent id="11">Major</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">Major</governor>
          <dependent id="12">'s</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">past</governor>
          <dependent id="13">mysterious</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">student</governor>
          <dependent id="14">past</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">rang</governor>
          <dependent id="16">immediately</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">rang</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="20">Street</governor>
          <dependent id="18">10</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="20">Street</governor>
          <dependent id="19">Downing</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="17">rang</governor>
          <dependent id="20">Street</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">claimed</governor>
          <dependent id="22">which</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">Street</governor>
          <dependent id="23">claimed</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">farmed</governor>
          <dependent id="24">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="27">father</governor>
          <dependent id="25">Major</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Major</governor>
          <dependent id="26">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="28">farmed</governor>
          <dependent id="27">father</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="23">claimed</governor>
          <dependent id="28">farmed</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">Bromsgrove</governor>
          <dependent id="29">near</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">farmed</governor>
          <dependent id="30">Bromsgrove</dependent>
        </dependency>
        <dependency type="case">
          <governor id="32">1910</governor>
          <dependent id="31">in</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="28">farmed</governor>
          <dependent id="32">1910</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Downing Street" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="19" string="Downing" />
            <token id="20" string="Street" />
          </tokens>
        </entity>
        <entity id="2" string="1910" type="DATE" score="0.0">
          <tokens>
            <token id="32" string="1910" />
          </tokens>
        </entity>
        <entity id="3" string="past" type="DATE" score="0.0">
          <tokens>
            <token id="14" string="past" />
          </tokens>
        </entity>
        <entity id="4" string="Francis Wheen" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Francis" />
            <token id="2" string="Wheen" />
          </tokens>
        </entity>
        <entity id="5" string="Bromsgrove" type="LOCATION" score="0.0">
          <tokens>
            <token id="30" string="Bromsgrove" />
          </tokens>
        </entity>
        <entity id="6" string="10" type="NUMBER" score="0.0">
          <tokens>
            <token id="18" string="10" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="18" has_coreference="true">
      <content>As Wheen pointed out, Major was an unresponsive minus 33 years old at that time, and - a minor point this - Bromsgrove is not in Shropshire.</content>
      <tokens>
        <token id="1" string="As" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="Wheen" lemma="Wheen" stem="wheen" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="pointed" lemma="point" stem="point" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="out" lemma="out" stem="out" pos="RP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="unresponsive" lemma="unresponsive" stem="unrespons" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="minus" lemma="minus" stem="minu" pos="CC" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="33" lemma="33" stem="33" pos="CD" type="Number" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="12" string="years" lemma="year" stem="year" pos="NNS" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="13" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" ner="DURATION" is_referenced="true" is_refers="false" />
        <token id="14" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="minor" lemma="minor" stem="minor" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="-" lemma="-" stem="-" pos=":" type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="Bromsgrove" lemma="Bromsgrove" stem="bromsgrov" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="26" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="Shropshire" lemma="Shropshire" stem="shropshir" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (SBAR (IN As) (S (NP (NNP Wheen)) (VP (VBD pointed) (PRT (RP out))))) (, ,) (NP (NNP Major)) (VP (VBD was) (NP (NP (DT an) (ADJP (JJ unresponsive) (NP (QP (CC minus) (CD 33)))) (NNS years)) (ADJP (JJ old) (PP (IN at) (NP (DT that) (NN time))))))) (, ,) (CC and) (S (NP (PRN (: -) (FRAG (NP (DT a) (JJ minor) (NN point)) (NP (NP (DT this)) (: -) (NP (NNP Bromsgrove)))))) (VP (VBZ is) (RB not) (PP (IN in) (NP (NNP Shropshire))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="unresponsive minus 33" type="ADJP">
          <tokens>
            <token id="9" string="unresponsive" />
            <token id="10" string="minus" />
            <token id="11" string="33" />
          </tokens>
        </chunking>
        <chunking id="2" string="that time" type="NP">
          <tokens>
            <token id="15" string="that" />
            <token id="16" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="an unresponsive minus 33 years old at that time" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="unresponsive" />
            <token id="10" string="minus" />
            <token id="11" string="33" />
            <token id="12" string="years" />
            <token id="13" string="old" />
            <token id="14" string="at" />
            <token id="15" string="that" />
            <token id="16" string="time" />
          </tokens>
        </chunking>
        <chunking id="4" string="Wheen" type="NP">
          <tokens>
            <token id="2" string="Wheen" />
          </tokens>
        </chunking>
        <chunking id="5" string="minus 33" type="NP">
          <tokens>
            <token id="10" string="minus" />
            <token id="11" string="33" />
          </tokens>
        </chunking>
        <chunking id="6" string="a minor point" type="NP">
          <tokens>
            <token id="20" string="a" />
            <token id="21" string="minor" />
            <token id="22" string="point" />
          </tokens>
        </chunking>
        <chunking id="7" string="old at that time" type="ADJP">
          <tokens>
            <token id="13" string="old" />
            <token id="14" string="at" />
            <token id="15" string="that" />
            <token id="16" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="As Wheen pointed out" type="SBAR">
          <tokens>
            <token id="1" string="As" />
            <token id="2" string="Wheen" />
            <token id="3" string="pointed" />
            <token id="4" string="out" />
          </tokens>
        </chunking>
        <chunking id="9" string="pointed out" type="VP">
          <tokens>
            <token id="3" string="pointed" />
            <token id="4" string="out" />
          </tokens>
        </chunking>
        <chunking id="10" string="this" type="NP">
          <tokens>
            <token id="23" string="this" />
          </tokens>
        </chunking>
        <chunking id="11" string="is not in Shropshire" type="VP">
          <tokens>
            <token id="26" string="is" />
            <token id="27" string="not" />
            <token id="28" string="in" />
            <token id="29" string="Shropshire" />
          </tokens>
        </chunking>
        <chunking id="12" string="- a minor point this - Bromsgrove" type="NP">
          <tokens>
            <token id="19" string="-" />
            <token id="20" string="a" />
            <token id="21" string="minor" />
            <token id="22" string="point" />
            <token id="23" string="this" />
            <token id="24" string="-" />
            <token id="25" string="Bromsgrove" />
          </tokens>
        </chunking>
        <chunking id="13" string="was an unresponsive minus 33 years old at that time" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="an" />
            <token id="9" string="unresponsive" />
            <token id="10" string="minus" />
            <token id="11" string="33" />
            <token id="12" string="years" />
            <token id="13" string="old" />
            <token id="14" string="at" />
            <token id="15" string="that" />
            <token id="16" string="time" />
          </tokens>
        </chunking>
        <chunking id="14" string="Major" type="NP">
          <tokens>
            <token id="6" string="Major" />
          </tokens>
        </chunking>
        <chunking id="15" string="Shropshire" type="NP">
          <tokens>
            <token id="29" string="Shropshire" />
          </tokens>
        </chunking>
        <chunking id="16" string="an unresponsive minus 33 years" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="unresponsive" />
            <token id="10" string="minus" />
            <token id="11" string="33" />
            <token id="12" string="years" />
          </tokens>
        </chunking>
        <chunking id="17" string="Bromsgrove" type="NP">
          <tokens>
            <token id="25" string="Bromsgrove" />
          </tokens>
        </chunking>
        <chunking id="18" string="this - Bromsgrove" type="NP">
          <tokens>
            <token id="23" string="this" />
            <token id="24" string="-" />
            <token id="25" string="Bromsgrove" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="3">pointed</governor>
          <dependent id="1">As</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="3">pointed</governor>
          <dependent id="2">Wheen</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">years</governor>
          <dependent id="3">pointed</dependent>
        </dependency>
        <dependency type="compound:prt">
          <governor id="3">pointed</governor>
          <dependent id="4">out</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">years</governor>
          <dependent id="6">Major</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="12">years</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="12">years</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">years</governor>
          <dependent id="9">unresponsive</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">33</governor>
          <dependent id="10">minus</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="9">unresponsive</governor>
          <dependent id="11">33</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="12">years</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="12">years</governor>
          <dependent id="13">old</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">time</governor>
          <dependent id="14">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">time</governor>
          <dependent id="15">that</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">old</governor>
          <dependent id="16">time</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="12">years</governor>
          <dependent id="18">and</dependent>
        </dependency>
        <dependency type="det">
          <governor id="22">point</governor>
          <dependent id="20">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="22">point</governor>
          <dependent id="21">minor</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="29">Shropshire</governor>
          <dependent id="22">point</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="22">point</governor>
          <dependent id="23">this</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="23">this</governor>
          <dependent id="25">Bromsgrove</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="29">Shropshire</governor>
          <dependent id="26">is</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="29">Shropshire</governor>
          <dependent id="27">not</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">Shropshire</governor>
          <dependent id="28">in</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="12">years</governor>
          <dependent id="29">Shropshire</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Shropshire" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="Shropshire" />
          </tokens>
        </entity>
        <entity id="2" string="Wheen" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="Wheen" />
          </tokens>
        </entity>
        <entity id="3" string="33 years old" type="DURATION" score="0.0">
          <tokens>
            <token id="11" string="33" />
            <token id="12" string="years" />
            <token id="13" string="old" />
          </tokens>
        </entity>
        <entity id="4" string="Bromsgrove" type="LOCATION" score="0.0">
          <tokens>
            <token id="25" string="Bromsgrove" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="19" has_coreference="true">
      <content>This, of course, does not mean that Major made everything up.</content>
      <tokens>
        <token id="1" string="This" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="course" lemma="course" stem="cours" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="mean" lemma="mean" stem="mean" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="everything" lemma="everything" stem="everyth" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="up" lemma="up" stem="up" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT This)) (, ,) (PP (IN of) (NP (NN course))) (, ,)) (VP (VBZ does) (RB not) (VP (VB mean) (SBAR (IN that) (S (NP (NNP Major)) (VP (VBD made) (NP (NN everything)) (ADVP (RB up))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Major" type="NP">
          <tokens>
            <token id="10" string="Major" />
          </tokens>
        </chunking>
        <chunking id="2" string="This , of course ," type="NP">
          <tokens>
            <token id="1" string="This" />
            <token id="2" string="," />
            <token id="3" string="of" />
            <token id="4" string="course" />
            <token id="5" string="," />
          </tokens>
        </chunking>
        <chunking id="3" string="course" type="NP">
          <tokens>
            <token id="4" string="course" />
          </tokens>
        </chunking>
        <chunking id="4" string="does not mean that Major made everything up" type="VP">
          <tokens>
            <token id="6" string="does" />
            <token id="7" string="not" />
            <token id="8" string="mean" />
            <token id="9" string="that" />
            <token id="10" string="Major" />
            <token id="11" string="made" />
            <token id="12" string="everything" />
            <token id="13" string="up" />
          </tokens>
        </chunking>
        <chunking id="5" string="mean that Major made everything up" type="VP">
          <tokens>
            <token id="8" string="mean" />
            <token id="9" string="that" />
            <token id="10" string="Major" />
            <token id="11" string="made" />
            <token id="12" string="everything" />
            <token id="13" string="up" />
          </tokens>
        </chunking>
        <chunking id="6" string="made everything up" type="VP">
          <tokens>
            <token id="11" string="made" />
            <token id="12" string="everything" />
            <token id="13" string="up" />
          </tokens>
        </chunking>
        <chunking id="7" string="This" type="NP">
          <tokens>
            <token id="1" string="This" />
          </tokens>
        </chunking>
        <chunking id="8" string="that Major made everything up" type="SBAR">
          <tokens>
            <token id="9" string="that" />
            <token id="10" string="Major" />
            <token id="11" string="made" />
            <token id="12" string="everything" />
            <token id="13" string="up" />
          </tokens>
        </chunking>
        <chunking id="9" string="everything" type="NP">
          <tokens>
            <token id="12" string="everything" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="8">mean</governor>
          <dependent id="1">This</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">course</governor>
          <dependent id="3">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="1">This</governor>
          <dependent id="4">course</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="8">mean</governor>
          <dependent id="6">does</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="8">mean</governor>
          <dependent id="7">not</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="8">mean</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="11">made</governor>
          <dependent id="9">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">made</governor>
          <dependent id="10">Major</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="8">mean</governor>
          <dependent id="11">made</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="11">made</governor>
          <dependent id="12">everything</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">made</governor>
          <dependent id="13">up</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="20" has_coreference="false">
      <content>Family folklore is a peculiar thing.</content>
      <tokens>
        <token id="1" string="Family" lemma="Family" stem="famili" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="folklore" lemma="folklore" stem="folklor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="peculiar" lemma="peculiar" stem="peculiar" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="thing" lemma="thing" stem="thing" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Family) (NN folklore)) (VP (VBZ is) (NP (DT a) (JJ peculiar) (NN thing))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Family folklore" type="NP">
          <tokens>
            <token id="1" string="Family" />
            <token id="2" string="folklore" />
          </tokens>
        </chunking>
        <chunking id="2" string="is a peculiar thing" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="a" />
            <token id="5" string="peculiar" />
            <token id="6" string="thing" />
          </tokens>
        </chunking>
        <chunking id="3" string="a peculiar thing" type="NP">
          <tokens>
            <token id="4" string="a" />
            <token id="5" string="peculiar" />
            <token id="6" string="thing" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">folklore</governor>
          <dependent id="1">Family</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">thing</governor>
          <dependent id="2">folklore</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">thing</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">thing</governor>
          <dependent id="4">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">thing</governor>
          <dependent id="5">peculiar</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">thing</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="21" has_coreference="true">
      <content>Yet when I heard about this, my mind immediately went back to an incident a few months ago, when Major visited Pittsburgh, centre of the US steel industry, as part of his American tour.</content>
      <tokens>
        <token id="1" string="Yet" lemma="yet" stem="yet" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="heard" lemma="hear" stem="heard" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="about" lemma="about" stem="about" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="my" lemma="my" stem="my" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="9" string="mind" lemma="mind" stem="mind" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="immediately" lemma="immediately" stem="immedi" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="went" lemma="go" stem="went" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="back" lemma="back" stem="back" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="incident" lemma="incident" stem="incid" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="17" string="few" lemma="few" stem="few" pos="JJ" type="Word" isStopWord="true" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="18" string="months" lemma="month" stem="month" pos="NNS" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="19" string="ago" lemma="ago" stem="ago" pos="RB" type="Word" isStopWord="false" ner="DATE" is_referenced="false" is_refers="false" />
        <token id="20" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="when" lemma="when" stem="when" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="Major" lemma="major" stem="major" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="23" string="visited" lemma="visit" stem="visit" pos="VBN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="Pittsburgh" lemma="Pittsburgh" stem="pittsburgh" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="true" is_refers="false" />
        <token id="25" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="centre" lemma="centre" stem="centr" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="27" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="US" lemma="US" stem="us" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="30" string="steel" lemma="steel" stem="steel" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="31" string="industry" lemma="industry" stem="industri" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="32" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="33" string="as" lemma="as" stem="a" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="34" string="part" lemma="part" stem="part" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="35" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="36" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="37" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="false" />
        <token id="38" string="tour" lemma="tour" stem="tour" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="39" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (RB Yet) (SBAR (WHADVP (WRB when)) (S (NP (PRP I)) (VP (VBD heard) (PP (IN about) (NP (DT this)))))) (, ,) (NP (PRP$ my) (NN mind)) (ADVP (RB immediately)) (VP (VBD went) (ADVP (RB back)) (PP (TO to) (NP (NP (DT an) (NN incident)) (ADVP (NP (DT a) (JJ few) (NNS months)) (RB ago)))) (, ,) (SBAR (WHADVP (WRB when)) (S (NP (JJ Major)) (VP (VBN visited) (S (NP (NP (NNP Pittsburgh)) (, ,) (NP (NP (NN centre)) (PP (IN of) (NP (DT the) (NNP US) (NN steel) (NN industry)))) (, ,))) (PP (IN as) (NP (NP (NN part)) (PP (IN of) (NP (PRP$ his) (JJ American) (NN tour))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="went back to an incident a few months ago , when Major visited Pittsburgh , centre of the US steel industry , as part of his American tour" type="VP">
          <tokens>
            <token id="11" string="went" />
            <token id="12" string="back" />
            <token id="13" string="to" />
            <token id="14" string="an" />
            <token id="15" string="incident" />
            <token id="16" string="a" />
            <token id="17" string="few" />
            <token id="18" string="months" />
            <token id="19" string="ago" />
            <token id="20" string="," />
            <token id="21" string="when" />
            <token id="22" string="Major" />
            <token id="23" string="visited" />
            <token id="24" string="Pittsburgh" />
            <token id="25" string="," />
            <token id="26" string="centre" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="US" />
            <token id="30" string="steel" />
            <token id="31" string="industry" />
            <token id="32" string="," />
            <token id="33" string="as" />
            <token id="34" string="part" />
            <token id="35" string="of" />
            <token id="36" string="his" />
            <token id="37" string="American" />
            <token id="38" string="tour" />
          </tokens>
        </chunking>
        <chunking id="2" string="part" type="NP">
          <tokens>
            <token id="34" string="part" />
          </tokens>
        </chunking>
        <chunking id="3" string="heard about this" type="VP">
          <tokens>
            <token id="4" string="heard" />
            <token id="5" string="about" />
            <token id="6" string="this" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="3" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="visited Pittsburgh , centre of the US steel industry , as part of his American tour" type="VP">
          <tokens>
            <token id="23" string="visited" />
            <token id="24" string="Pittsburgh" />
            <token id="25" string="," />
            <token id="26" string="centre" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="US" />
            <token id="30" string="steel" />
            <token id="31" string="industry" />
            <token id="32" string="," />
            <token id="33" string="as" />
            <token id="34" string="part" />
            <token id="35" string="of" />
            <token id="36" string="his" />
            <token id="37" string="American" />
            <token id="38" string="tour" />
          </tokens>
        </chunking>
        <chunking id="6" string="centre" type="NP">
          <tokens>
            <token id="26" string="centre" />
          </tokens>
        </chunking>
        <chunking id="7" string="this" type="NP">
          <tokens>
            <token id="6" string="this" />
          </tokens>
        </chunking>
        <chunking id="8" string="when Major visited Pittsburgh , centre of the US steel industry , as part of his American tour" type="SBAR">
          <tokens>
            <token id="21" string="when" />
            <token id="22" string="Major" />
            <token id="23" string="visited" />
            <token id="24" string="Pittsburgh" />
            <token id="25" string="," />
            <token id="26" string="centre" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="US" />
            <token id="30" string="steel" />
            <token id="31" string="industry" />
            <token id="32" string="," />
            <token id="33" string="as" />
            <token id="34" string="part" />
            <token id="35" string="of" />
            <token id="36" string="his" />
            <token id="37" string="American" />
            <token id="38" string="tour" />
          </tokens>
        </chunking>
        <chunking id="9" string="centre of the US steel industry" type="NP">
          <tokens>
            <token id="26" string="centre" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="US" />
            <token id="30" string="steel" />
            <token id="31" string="industry" />
          </tokens>
        </chunking>
        <chunking id="10" string="when" type="WHADVP">
          <tokens>
            <token id="2" string="when" />
          </tokens>
        </chunking>
        <chunking id="11" string="his American tour" type="NP">
          <tokens>
            <token id="36" string="his" />
            <token id="37" string="American" />
            <token id="38" string="tour" />
          </tokens>
        </chunking>
        <chunking id="12" string="my mind" type="NP">
          <tokens>
            <token id="8" string="my" />
            <token id="9" string="mind" />
          </tokens>
        </chunking>
        <chunking id="13" string="Major" type="NP">
          <tokens>
            <token id="22" string="Major" />
          </tokens>
        </chunking>
        <chunking id="14" string="when I heard about this" type="SBAR">
          <tokens>
            <token id="2" string="when" />
            <token id="3" string="I" />
            <token id="4" string="heard" />
            <token id="5" string="about" />
            <token id="6" string="this" />
          </tokens>
        </chunking>
        <chunking id="15" string="the US steel industry" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="US" />
            <token id="30" string="steel" />
            <token id="31" string="industry" />
          </tokens>
        </chunking>
        <chunking id="16" string="part of his American tour" type="NP">
          <tokens>
            <token id="34" string="part" />
            <token id="35" string="of" />
            <token id="36" string="his" />
            <token id="37" string="American" />
            <token id="38" string="tour" />
          </tokens>
        </chunking>
        <chunking id="17" string="a few months" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="few" />
            <token id="18" string="months" />
          </tokens>
        </chunking>
        <chunking id="18" string="Pittsburgh , centre of the US steel industry ," type="NP">
          <tokens>
            <token id="24" string="Pittsburgh" />
            <token id="25" string="," />
            <token id="26" string="centre" />
            <token id="27" string="of" />
            <token id="28" string="the" />
            <token id="29" string="US" />
            <token id="30" string="steel" />
            <token id="31" string="industry" />
            <token id="32" string="," />
          </tokens>
        </chunking>
        <chunking id="19" string="an incident a few months ago" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="incident" />
            <token id="16" string="a" />
            <token id="17" string="few" />
            <token id="18" string="months" />
            <token id="19" string="ago" />
          </tokens>
        </chunking>
        <chunking id="20" string="an incident" type="NP">
          <tokens>
            <token id="14" string="an" />
            <token id="15" string="incident" />
          </tokens>
        </chunking>
        <chunking id="21" string="Pittsburgh" type="NP">
          <tokens>
            <token id="24" string="Pittsburgh" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="advmod">
          <governor id="11">went</governor>
          <dependent id="1">Yet</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="4">heard</governor>
          <dependent id="2">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">heard</governor>
          <dependent id="3">I</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">went</governor>
          <dependent id="4">heard</dependent>
        </dependency>
        <dependency type="case">
          <governor id="6">this</governor>
          <dependent id="5">about</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">heard</governor>
          <dependent id="6">this</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="9">mind</governor>
          <dependent id="8">my</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="11">went</governor>
          <dependent id="9">mind</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">went</governor>
          <dependent id="10">immediately</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">went</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">went</governor>
          <dependent id="12">back</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">incident</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">incident</governor>
          <dependent id="14">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">went</governor>
          <dependent id="15">incident</dependent>
        </dependency>
        <dependency type="det">
          <governor id="18">months</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="18">months</governor>
          <dependent id="17">few</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="19">ago</governor>
          <dependent id="18">months</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="15">incident</governor>
          <dependent id="19">ago</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="23">visited</governor>
          <dependent id="21">when</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="23">visited</governor>
          <dependent id="22">Major</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="11">went</governor>
          <dependent id="23">visited</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="23">visited</governor>
          <dependent id="24">Pittsburgh</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="24">Pittsburgh</governor>
          <dependent id="26">centre</dependent>
        </dependency>
        <dependency type="case">
          <governor id="31">industry</governor>
          <dependent id="27">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="31">industry</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">industry</governor>
          <dependent id="29">US</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="31">industry</governor>
          <dependent id="30">steel</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="26">centre</governor>
          <dependent id="31">industry</dependent>
        </dependency>
        <dependency type="case">
          <governor id="34">part</governor>
          <dependent id="33">as</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">visited</governor>
          <dependent id="34">part</dependent>
        </dependency>
        <dependency type="case">
          <governor id="38">tour</governor>
          <dependent id="35">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="38">tour</governor>
          <dependent id="36">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="38">tour</governor>
          <dependent id="37">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="34">part</governor>
          <dependent id="38">tour</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="centre" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="26" string="centre" />
          </tokens>
        </entity>
        <entity id="2" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="37" string="American" />
          </tokens>
        </entity>
        <entity id="3" string="a few months ago" type="DATE" score="0.0">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="few" />
            <token id="18" string="months" />
            <token id="19" string="ago" />
          </tokens>
        </entity>
        <entity id="4" string="Pittsburgh" type="LOCATION" score="0.0">
          <tokens>
            <token id="24" string="Pittsburgh" />
          </tokens>
        </entity>
        <entity id="5" string="US" type="LOCATION" score="0.0">
          <tokens>
            <token id="29" string="US" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="22" has_coreference="true">
      <content>I recall that he made a great hit by recounting that his father had been a steelworker in the city.</content>
      <tokens>
        <token id="1" string="I" lemma="I" stem="i" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="recall" lemma="recall" stem="recal" pos="VBP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="made" lemma="make" stem="made" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="great" lemma="great" stem="great" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="hit" lemma="hit" stem="hit" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="recounting" lemma="recount" stem="recount" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="had" lemma="have" stem="had" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="17" string="steelworker" lemma="steelworker" stem="steelwork" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="18" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="city" lemma="city" stem="citi" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (PRP I)) (VP (VBP recall) (SBAR (IN that) (S (NP (PRP he)) (VP (VBD made) (NP (DT a) (JJ great) (NN hit)) (PP (IN by) (S (VP (VBG recounting) (SBAR (IN that) (S (NP (PRP$ his) (NN father)) (VP (VBD had) (VP (VBN been) (NP (NP (DT a) (NN steelworker)) (PP (IN in) (NP (DT the) (NN city))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that his father had been a steelworker in the city" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="his" />
            <token id="13" string="father" />
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="a" />
            <token id="17" string="steelworker" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="2" string="the city" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="3" string="recall that he made a great hit by recounting that his father had been a steelworker in the city" type="VP">
          <tokens>
            <token id="2" string="recall" />
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="made" />
            <token id="6" string="a" />
            <token id="7" string="great" />
            <token id="8" string="hit" />
            <token id="9" string="by" />
            <token id="10" string="recounting" />
            <token id="11" string="that" />
            <token id="12" string="his" />
            <token id="13" string="father" />
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="a" />
            <token id="17" string="steelworker" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="4" string="I" type="NP">
          <tokens>
            <token id="1" string="I" />
          </tokens>
        </chunking>
        <chunking id="5" string="that he made a great hit by recounting that his father had been a steelworker in the city" type="SBAR">
          <tokens>
            <token id="3" string="that" />
            <token id="4" string="he" />
            <token id="5" string="made" />
            <token id="6" string="a" />
            <token id="7" string="great" />
            <token id="8" string="hit" />
            <token id="9" string="by" />
            <token id="10" string="recounting" />
            <token id="11" string="that" />
            <token id="12" string="his" />
            <token id="13" string="father" />
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="a" />
            <token id="17" string="steelworker" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="6" string="had been a steelworker in the city" type="VP">
          <tokens>
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="a" />
            <token id="17" string="steelworker" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="7" string="recounting that his father had been a steelworker in the city" type="VP">
          <tokens>
            <token id="10" string="recounting" />
            <token id="11" string="that" />
            <token id="12" string="his" />
            <token id="13" string="father" />
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="a" />
            <token id="17" string="steelworker" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="8" string="a great hit" type="NP">
          <tokens>
            <token id="6" string="a" />
            <token id="7" string="great" />
            <token id="8" string="hit" />
          </tokens>
        </chunking>
        <chunking id="9" string="been a steelworker in the city" type="VP">
          <tokens>
            <token id="15" string="been" />
            <token id="16" string="a" />
            <token id="17" string="steelworker" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="10" string="a steelworker in the city" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="steelworker" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="11" string="his father" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="father" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="made a great hit by recounting that his father had been a steelworker in the city" type="VP">
          <tokens>
            <token id="5" string="made" />
            <token id="6" string="a" />
            <token id="7" string="great" />
            <token id="8" string="hit" />
            <token id="9" string="by" />
            <token id="10" string="recounting" />
            <token id="11" string="that" />
            <token id="12" string="his" />
            <token id="13" string="father" />
            <token id="14" string="had" />
            <token id="15" string="been" />
            <token id="16" string="a" />
            <token id="17" string="steelworker" />
            <token id="18" string="in" />
            <token id="19" string="the" />
            <token id="20" string="city" />
          </tokens>
        </chunking>
        <chunking id="14" string="a steelworker" type="NP">
          <tokens>
            <token id="16" string="a" />
            <token id="17" string="steelworker" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="2">recall</governor>
          <dependent id="1">I</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">recall</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="5">made</governor>
          <dependent id="3">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">made</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="2">recall</governor>
          <dependent id="5">made</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">hit</governor>
          <dependent id="6">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="8">hit</governor>
          <dependent id="7">great</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="5">made</governor>
          <dependent id="8">hit</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">recounting</governor>
          <dependent id="9">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="5">made</governor>
          <dependent id="10">recounting</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">steelworker</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">father</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">steelworker</governor>
          <dependent id="13">father</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">steelworker</governor>
          <dependent id="14">had</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">steelworker</governor>
          <dependent id="15">been</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">steelworker</governor>
          <dependent id="16">a</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">recounting</governor>
          <dependent id="17">steelworker</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">city</governor>
          <dependent id="18">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">city</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="17">steelworker</governor>
          <dependent id="20">city</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="23" has_coreference="true">
      <content>A farmer for Farmers Weekly, a Pittsburgh steelworker for the American audience . . . a pattern emerges.</content>
      <tokens>
        <token id="1" string="A" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="farmer" lemma="farmer" stem="farmer" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Farmers" lemma="Farmers" stem="farmer" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="5" string="Weekly" lemma="Weekly" stem="weekli" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="true" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="8" string="Pittsburgh" lemma="Pittsburgh" stem="pittsburgh" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="true" />
        <token id="9" string="steelworker" lemma="steelworker" stem="steelwork" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="10" string="for" lemma="for" stem="for" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="American" lemma="american" stem="american" pos="JJ" type="Word" isStopWord="false" ner="NATIONALITY" is_referenced="false" is_refers="true" />
        <token id="13" string="audience" lemma="audience" stem="audienc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="14" string=". . ." lemma="..." stem=". . ." pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="pattern" lemma="pattern" stem="pattern" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="emerges" lemma="emerge" stem="emerg" pos="VBZ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (NP (NP (NP (DT A) (NN farmer)) (PP (IN for) (NP (NP (NNP Farmers) (NNP Weekly)) (, ,) (NP (NP (DT a) (NNP Pittsburgh) (NN steelworker)) (PP (IN for) (NP (DT the) (JJ American) (NN audience))))))) (: ...) (NP (NP (DT a) (NN pattern)) (VP (VBZ emerges))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="A farmer for Farmers Weekly , a Pittsburgh steelworker for the American audience" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="farmer" />
            <token id="3" string="for" />
            <token id="4" string="Farmers" />
            <token id="5" string="Weekly" />
            <token id="6" string="," />
            <token id="7" string="a" />
            <token id="8" string="Pittsburgh" />
            <token id="9" string="steelworker" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="American" />
            <token id="13" string="audience" />
          </tokens>
        </chunking>
        <chunking id="2" string="the American audience" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="American" />
            <token id="13" string="audience" />
          </tokens>
        </chunking>
        <chunking id="3" string="a pattern emerges" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="pattern" />
            <token id="17" string="emerges" />
          </tokens>
        </chunking>
        <chunking id="4" string="emerges" type="VP">
          <tokens>
            <token id="17" string="emerges" />
          </tokens>
        </chunking>
        <chunking id="5" string="A farmer for Farmers Weekly , a Pittsburgh steelworker for the American audience ... a pattern emerges ." type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="farmer" />
            <token id="3" string="for" />
            <token id="4" string="Farmers" />
            <token id="5" string="Weekly" />
            <token id="6" string="," />
            <token id="7" string="a" />
            <token id="8" string="Pittsburgh" />
            <token id="9" string="steelworker" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="American" />
            <token id="13" string="audience" />
            <token id="14" string=". . ." />
            <token id="15" string="a" />
            <token id="16" string="pattern" />
            <token id="17" string="emerges" />
            <token id="18" string="." />
          </tokens>
        </chunking>
        <chunking id="6" string="Farmers Weekly , a Pittsburgh steelworker for the American audience" type="NP">
          <tokens>
            <token id="4" string="Farmers" />
            <token id="5" string="Weekly" />
            <token id="6" string="," />
            <token id="7" string="a" />
            <token id="8" string="Pittsburgh" />
            <token id="9" string="steelworker" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="American" />
            <token id="13" string="audience" />
          </tokens>
        </chunking>
        <chunking id="7" string="Farmers Weekly" type="NP">
          <tokens>
            <token id="4" string="Farmers" />
            <token id="5" string="Weekly" />
          </tokens>
        </chunking>
        <chunking id="8" string="a Pittsburgh steelworker for the American audience" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="Pittsburgh" />
            <token id="9" string="steelworker" />
            <token id="10" string="for" />
            <token id="11" string="the" />
            <token id="12" string="American" />
            <token id="13" string="audience" />
          </tokens>
        </chunking>
        <chunking id="9" string="a pattern" type="NP">
          <tokens>
            <token id="15" string="a" />
            <token id="16" string="pattern" />
          </tokens>
        </chunking>
        <chunking id="10" string="A farmer" type="NP">
          <tokens>
            <token id="1" string="A" />
            <token id="2" string="farmer" />
          </tokens>
        </chunking>
        <chunking id="11" string="a Pittsburgh steelworker" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="Pittsburgh" />
            <token id="9" string="steelworker" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="2">farmer</governor>
          <dependent id="1">A</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">farmer</dependent>
        </dependency>
        <dependency type="case">
          <governor id="5">Weekly</governor>
          <dependent id="3">for</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Weekly</governor>
          <dependent id="4">Farmers</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="2">farmer</governor>
          <dependent id="5">Weekly</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">steelworker</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="9">steelworker</governor>
          <dependent id="8">Pittsburgh</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="5">Weekly</governor>
          <dependent id="9">steelworker</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">audience</governor>
          <dependent id="10">for</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">audience</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">audience</governor>
          <dependent id="12">American</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="9">steelworker</governor>
          <dependent id="13">audience</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">pattern</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">farmer</governor>
          <dependent id="16">pattern</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">pattern</governor>
          <dependent id="17">emerges</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="American" type="NATIONALITY" score="0.0">
          <tokens>
            <token id="12" string="American" />
          </tokens>
        </entity>
        <entity id="2" string="Farmers Weekly" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="4" string="Farmers" />
            <token id="5" string="Weekly" />
          </tokens>
        </entity>
        <entity id="3" string="Pittsburgh" type="LOCATION" score="0.0">
          <tokens>
            <token id="8" string="Pittsburgh" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="24" has_coreference="true">
      <content>Major&amp;apost;s father, and therefore by extension John Major himself, can be all things to all people.</content>
      <tokens>
        <token id="1" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="2" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="therefore" lemma="therefore" stem="therefor" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="extension" lemma="extension" stem="extens" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="10" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="11" string="himself" lemma="himself" stem="himself" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="things" lemma="thing" stem="thing" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (NP (NNP Major) (POS 's)) (NN father)) (PRN (, ,) (CC and) (ADVP (ADVP (RB therefore)) (PP (IN by) (NP (NN extension) (NNP John) (NNP Major)))) (NP (PRP himself)) (, ,))) (VP (MD can) (VP (VB be) (NP (NP (DT all) (NNS things)) (PP (TO to) (NP (DT all) (NNS people)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="Major 's father" type="NP">
          <tokens>
            <token id="1" string="Major" />
            <token id="2" string="'s" />
            <token id="3" string="father" />
          </tokens>
        </chunking>
        <chunking id="2" string="can be all things to all people" type="VP">
          <tokens>
            <token id="13" string="can" />
            <token id="14" string="be" />
            <token id="15" string="all" />
            <token id="16" string="things" />
            <token id="17" string="to" />
            <token id="18" string="all" />
            <token id="19" string="people" />
          </tokens>
        </chunking>
        <chunking id="3" string="all things" type="NP">
          <tokens>
            <token id="15" string="all" />
            <token id="16" string="things" />
          </tokens>
        </chunking>
        <chunking id="4" string="all people" type="NP">
          <tokens>
            <token id="18" string="all" />
            <token id="19" string="people" />
          </tokens>
        </chunking>
        <chunking id="5" string="all things to all people" type="NP">
          <tokens>
            <token id="15" string="all" />
            <token id="16" string="things" />
            <token id="17" string="to" />
            <token id="18" string="all" />
            <token id="19" string="people" />
          </tokens>
        </chunking>
        <chunking id="6" string="Major 's" type="NP">
          <tokens>
            <token id="1" string="Major" />
            <token id="2" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="Major 's father , and therefore by extension John Major himself ," type="NP">
          <tokens>
            <token id="1" string="Major" />
            <token id="2" string="'s" />
            <token id="3" string="father" />
            <token id="4" string="," />
            <token id="5" string="and" />
            <token id="6" string="therefore" />
            <token id="7" string="by" />
            <token id="8" string="extension" />
            <token id="9" string="John" />
            <token id="10" string="Major" />
            <token id="11" string="himself" />
            <token id="12" string="," />
          </tokens>
        </chunking>
        <chunking id="8" string="himself" type="NP">
          <tokens>
            <token id="11" string="himself" />
          </tokens>
        </chunking>
        <chunking id="9" string="be all things to all people" type="VP">
          <tokens>
            <token id="14" string="be" />
            <token id="15" string="all" />
            <token id="16" string="things" />
            <token id="17" string="to" />
            <token id="18" string="all" />
            <token id="19" string="people" />
          </tokens>
        </chunking>
        <chunking id="10" string="extension John Major" type="NP">
          <tokens>
            <token id="8" string="extension" />
            <token id="9" string="John" />
            <token id="10" string="Major" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="3">father</governor>
          <dependent id="1">Major</dependent>
        </dependency>
        <dependency type="case">
          <governor id="1">Major</governor>
          <dependent id="2">'s</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="16">things</governor>
          <dependent id="3">father</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="11">himself</governor>
          <dependent id="5">and</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">himself</governor>
          <dependent id="6">therefore</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Major</governor>
          <dependent id="7">by</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Major</governor>
          <dependent id="8">extension</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="10">Major</governor>
          <dependent id="9">John</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">therefore</governor>
          <dependent id="10">Major</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">father</governor>
          <dependent id="11">himself</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="16">things</governor>
          <dependent id="13">can</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="16">things</governor>
          <dependent id="14">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">things</governor>
          <dependent id="15">all</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="16">things</dependent>
        </dependency>
        <dependency type="case">
          <governor id="19">people</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="19">people</governor>
          <dependent id="18">all</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">things</governor>
          <dependent id="19">people</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Major" type="PERSON" score="0.0">
          <tokens>
            <token id="9" string="John" />
            <token id="10" string="Major" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="25" has_coreference="true">
      <content>If John Major were a different sort of politician, this would be a point barely worth making.</content>
      <tokens>
        <token id="1" string="If" lemma="if" stem="if" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="3" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="4" string="were" lemma="be" stem="were" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="different" lemma="different" stem="differ" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="sort" lemma="sort" stem="sort" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="8" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="politician" lemma="politician" stem="politician" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="would" lemma="would" stem="would" pos="MD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="point" lemma="point" stem="point" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="barely" lemma="barely" stem="bare" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="worth" lemma="worth" stem="worth" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="18" string="making" lemma="make" stem="make" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (SBAR (IN If) (S (NP (NNP John) (NNP Major)) (VP (VBD were) (NP (NP (DT a) (JJ different) (NN sort)) (PP (IN of) (NP (NN politician))))))) (, ,) (NP (DT this)) (VP (MD would) (VP (VB be) (ADJP (NP (DT a) (NN point)) (RB barely) (JJ worth)) (S (VP (VBG making))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="were a different sort of politician" type="VP">
          <tokens>
            <token id="4" string="were" />
            <token id="5" string="a" />
            <token id="6" string="different" />
            <token id="7" string="sort" />
            <token id="8" string="of" />
            <token id="9" string="politician" />
          </tokens>
        </chunking>
        <chunking id="2" string="politician" type="NP">
          <tokens>
            <token id="9" string="politician" />
          </tokens>
        </chunking>
        <chunking id="3" string="a different sort of politician" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="different" />
            <token id="7" string="sort" />
            <token id="8" string="of" />
            <token id="9" string="politician" />
          </tokens>
        </chunking>
        <chunking id="4" string="making" type="VP">
          <tokens>
            <token id="18" string="making" />
          </tokens>
        </chunking>
        <chunking id="5" string="a point barely worth" type="ADJP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="point" />
            <token id="16" string="barely" />
            <token id="17" string="worth" />
          </tokens>
        </chunking>
        <chunking id="6" string="a point" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="point" />
          </tokens>
        </chunking>
        <chunking id="7" string="If John Major were a different sort of politician" type="SBAR">
          <tokens>
            <token id="1" string="If" />
            <token id="2" string="John" />
            <token id="3" string="Major" />
            <token id="4" string="were" />
            <token id="5" string="a" />
            <token id="6" string="different" />
            <token id="7" string="sort" />
            <token id="8" string="of" />
            <token id="9" string="politician" />
          </tokens>
        </chunking>
        <chunking id="8" string="John Major" type="NP">
          <tokens>
            <token id="2" string="John" />
            <token id="3" string="Major" />
          </tokens>
        </chunking>
        <chunking id="9" string="this" type="NP">
          <tokens>
            <token id="11" string="this" />
          </tokens>
        </chunking>
        <chunking id="10" string="would be a point barely worth making" type="VP">
          <tokens>
            <token id="12" string="would" />
            <token id="13" string="be" />
            <token id="14" string="a" />
            <token id="15" string="point" />
            <token id="16" string="barely" />
            <token id="17" string="worth" />
            <token id="18" string="making" />
          </tokens>
        </chunking>
        <chunking id="11" string="a different sort" type="NP">
          <tokens>
            <token id="5" string="a" />
            <token id="6" string="different" />
            <token id="7" string="sort" />
          </tokens>
        </chunking>
        <chunking id="12" string="be a point barely worth making" type="VP">
          <tokens>
            <token id="13" string="be" />
            <token id="14" string="a" />
            <token id="15" string="point" />
            <token id="16" string="barely" />
            <token id="17" string="worth" />
            <token id="18" string="making" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="mark">
          <governor id="7">sort</governor>
          <dependent id="1">If</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="3">Major</governor>
          <dependent id="2">John</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">sort</governor>
          <dependent id="3">Major</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">sort</governor>
          <dependent id="4">were</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">sort</governor>
          <dependent id="5">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">sort</governor>
          <dependent id="6">different</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="17">worth</governor>
          <dependent id="7">sort</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">politician</governor>
          <dependent id="8">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">sort</governor>
          <dependent id="9">politician</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">worth</governor>
          <dependent id="11">this</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="17">worth</governor>
          <dependent id="12">would</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">worth</governor>
          <dependent id="13">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="15">point</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="17">worth</governor>
          <dependent id="15">point</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="17">worth</governor>
          <dependent id="16">barely</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="17">worth</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="17">worth</governor>
          <dependent id="18">making</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Major" type="PERSON" score="0.0">
          <tokens>
            <token id="2" string="John" />
            <token id="3" string="Major" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="26" has_coreference="true">
      <content>But it does seem all of a piece with Major&amp;apost;s approach to wider political issues.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="does" lemma="do" stem="doe" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="seem" lemma="seem" stem="seem" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="piece" lemma="piece" stem="piec" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="11" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="12" string="approach" lemma="approach" stem="approach" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="wider" lemma="wider" stem="wider" pos="JJR" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="political" lemma="political" stem="polit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="issues" lemma="issue" stem="issu" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (PRP it)) (VP (VBZ does) (VP (VB seem) (NP (NP (DT all)) (PP (IN of) (NP (NP (DT a) (NN piece)) (PP (IN with) (NP (NP (NNP Major) (POS 's)) (NN approach)))))) (PP (TO to) (NP (JJR wider) (JJ political) (NNS issues))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="all" type="NP">
          <tokens>
            <token id="5" string="all" />
          </tokens>
        </chunking>
        <chunking id="2" string="Major 's approach" type="NP">
          <tokens>
            <token id="10" string="Major" />
            <token id="11" string="'s" />
            <token id="12" string="approach" />
          </tokens>
        </chunking>
        <chunking id="3" string="a piece with Major 's approach" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="piece" />
            <token id="9" string="with" />
            <token id="10" string="Major" />
            <token id="11" string="'s" />
            <token id="12" string="approach" />
          </tokens>
        </chunking>
        <chunking id="4" string="wider political issues" type="NP">
          <tokens>
            <token id="14" string="wider" />
            <token id="15" string="political" />
            <token id="16" string="issues" />
          </tokens>
        </chunking>
        <chunking id="5" string="does seem all of a piece with Major 's approach to wider political issues" type="VP">
          <tokens>
            <token id="3" string="does" />
            <token id="4" string="seem" />
            <token id="5" string="all" />
            <token id="6" string="of" />
            <token id="7" string="a" />
            <token id="8" string="piece" />
            <token id="9" string="with" />
            <token id="10" string="Major" />
            <token id="11" string="'s" />
            <token id="12" string="approach" />
            <token id="13" string="to" />
            <token id="14" string="wider" />
            <token id="15" string="political" />
            <token id="16" string="issues" />
          </tokens>
        </chunking>
        <chunking id="6" string="seem all of a piece with Major 's approach to wider political issues" type="VP">
          <tokens>
            <token id="4" string="seem" />
            <token id="5" string="all" />
            <token id="6" string="of" />
            <token id="7" string="a" />
            <token id="8" string="piece" />
            <token id="9" string="with" />
            <token id="10" string="Major" />
            <token id="11" string="'s" />
            <token id="12" string="approach" />
            <token id="13" string="to" />
            <token id="14" string="wider" />
            <token id="15" string="political" />
            <token id="16" string="issues" />
          </tokens>
        </chunking>
        <chunking id="7" string="it" type="NP">
          <tokens>
            <token id="2" string="it" />
          </tokens>
        </chunking>
        <chunking id="8" string="Major 's" type="NP">
          <tokens>
            <token id="10" string="Major" />
            <token id="11" string="'s" />
          </tokens>
        </chunking>
        <chunking id="9" string="all of a piece with Major 's approach" type="NP">
          <tokens>
            <token id="5" string="all" />
            <token id="6" string="of" />
            <token id="7" string="a" />
            <token id="8" string="piece" />
            <token id="9" string="with" />
            <token id="10" string="Major" />
            <token id="11" string="'s" />
            <token id="12" string="approach" />
          </tokens>
        </chunking>
        <chunking id="10" string="a piece" type="NP">
          <tokens>
            <token id="7" string="a" />
            <token id="8" string="piece" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="4">seem</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">seem</governor>
          <dependent id="2">it</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="4">seem</governor>
          <dependent id="3">does</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">seem</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="4">seem</governor>
          <dependent id="5">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">piece</governor>
          <dependent id="6">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="8">piece</governor>
          <dependent id="7">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="5">all</governor>
          <dependent id="8">piece</dependent>
        </dependency>
        <dependency type="case">
          <governor id="12">approach</governor>
          <dependent id="9">with</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="12">approach</governor>
          <dependent id="10">Major</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">Major</governor>
          <dependent id="11">'s</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="8">piece</governor>
          <dependent id="12">approach</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">issues</governor>
          <dependent id="13">to</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">issues</governor>
          <dependent id="14">wider</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="16">issues</governor>
          <dependent id="15">political</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">seem</governor>
          <dependent id="16">issues</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="27" has_coreference="true">
      <content>On the one hand he will appeal to the pro-Europeans in his own party by claiming to want Britain to be at the heart of Europe.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="4" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="5" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="6" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="appeal" lemma="appeal" stem="appeal" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="pro-Europeans" lemma="pro-Europeans" stem="pro-european" pos="NNPS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="11" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="13" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="party" lemma="party" stem="parti" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="by" lemma="by" stem="by" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="claiming" lemma="claim" stem="claim" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="want" lemma="want" stem="want" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="Britain" lemma="Britain" stem="britain" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="20" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="heart" lemma="heart" stem="heart" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="25" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="Europe" lemma="Europe" stem="europ" pos="NNP" type="Word" isStopWord="false" ner="LOCATION" is_referenced="false" is_refers="false" />
        <token id="27" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (DT the) (CD one) (NN hand))) (NP (PRP he)) (VP (MD will) (VP (VB appeal) (PP (TO to) (NP (NP (DT the) (NNPS pro-Europeans)) (PP (IN in) (NP (PRP$ his) (JJ own) (NN party))))) (PP (IN by) (S (VP (VBG claiming) (S (VP (TO to) (VP (VB want) (S (NP (NNP Britain)) (VP (TO to) (VP (VB be) (PP (IN at) (NP (NP (DT the) (NN heart)) (PP (IN of) (NP (NNP Europe)))))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="want Britain to be at the heart of Europe" type="VP">
          <tokens>
            <token id="18" string="want" />
            <token id="19" string="Britain" />
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="heart" />
            <token id="25" string="of" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="2" string="the heart" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="heart" />
          </tokens>
        </chunking>
        <chunking id="3" string="to be at the heart of Europe" type="VP">
          <tokens>
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="heart" />
            <token id="25" string="of" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="4" string="Europe" type="NP">
          <tokens>
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="5" string="his own party" type="NP">
          <tokens>
            <token id="12" string="his" />
            <token id="13" string="own" />
            <token id="14" string="party" />
          </tokens>
        </chunking>
        <chunking id="6" string="Britain" type="NP">
          <tokens>
            <token id="19" string="Britain" />
          </tokens>
        </chunking>
        <chunking id="7" string="the pro-Europeans in his own party" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="pro-Europeans" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="own" />
            <token id="14" string="party" />
          </tokens>
        </chunking>
        <chunking id="8" string="be at the heart of Europe" type="VP">
          <tokens>
            <token id="21" string="be" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="heart" />
            <token id="25" string="of" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="9" string="to want Britain to be at the heart of Europe" type="VP">
          <tokens>
            <token id="17" string="to" />
            <token id="18" string="want" />
            <token id="19" string="Britain" />
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="heart" />
            <token id="25" string="of" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="10" string="the one hand" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="one" />
            <token id="4" string="hand" />
          </tokens>
        </chunking>
        <chunking id="11" string="appeal to the pro-Europeans in his own party by claiming to want Britain to be at the heart of Europe" type="VP">
          <tokens>
            <token id="7" string="appeal" />
            <token id="8" string="to" />
            <token id="9" string="the" />
            <token id="10" string="pro-Europeans" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="own" />
            <token id="14" string="party" />
            <token id="15" string="by" />
            <token id="16" string="claiming" />
            <token id="17" string="to" />
            <token id="18" string="want" />
            <token id="19" string="Britain" />
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="heart" />
            <token id="25" string="of" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="12" string="he" type="NP">
          <tokens>
            <token id="5" string="he" />
          </tokens>
        </chunking>
        <chunking id="13" string="will appeal to the pro-Europeans in his own party by claiming to want Britain to be at the heart of Europe" type="VP">
          <tokens>
            <token id="6" string="will" />
            <token id="7" string="appeal" />
            <token id="8" string="to" />
            <token id="9" string="the" />
            <token id="10" string="pro-Europeans" />
            <token id="11" string="in" />
            <token id="12" string="his" />
            <token id="13" string="own" />
            <token id="14" string="party" />
            <token id="15" string="by" />
            <token id="16" string="claiming" />
            <token id="17" string="to" />
            <token id="18" string="want" />
            <token id="19" string="Britain" />
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="heart" />
            <token id="25" string="of" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="14" string="the heart of Europe" type="NP">
          <tokens>
            <token id="23" string="the" />
            <token id="24" string="heart" />
            <token id="25" string="of" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
        <chunking id="15" string="the pro-Europeans" type="NP">
          <tokens>
            <token id="9" string="the" />
            <token id="10" string="pro-Europeans" />
          </tokens>
        </chunking>
        <chunking id="16" string="claiming to want Britain to be at the heart of Europe" type="VP">
          <tokens>
            <token id="16" string="claiming" />
            <token id="17" string="to" />
            <token id="18" string="want" />
            <token id="19" string="Britain" />
            <token id="20" string="to" />
            <token id="21" string="be" />
            <token id="22" string="at" />
            <token id="23" string="the" />
            <token id="24" string="heart" />
            <token id="25" string="of" />
            <token id="26" string="Europe" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">hand</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">hand</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nummod">
          <governor id="4">hand</governor>
          <dependent id="3">one</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">appeal</governor>
          <dependent id="4">hand</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">appeal</governor>
          <dependent id="5">he</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="7">appeal</governor>
          <dependent id="6">will</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">appeal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="10">pro-Europeans</governor>
          <dependent id="8">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">pro-Europeans</governor>
          <dependent id="9">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">appeal</governor>
          <dependent id="10">pro-Europeans</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">party</governor>
          <dependent id="11">in</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="14">party</governor>
          <dependent id="12">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="14">party</governor>
          <dependent id="13">own</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">pro-Europeans</governor>
          <dependent id="14">party</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="16">claiming</governor>
          <dependent id="15">by</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">appeal</governor>
          <dependent id="16">claiming</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="18">want</governor>
          <dependent id="17">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="16">claiming</governor>
          <dependent id="18">want</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">want</governor>
          <dependent id="19">Britain</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">heart</governor>
          <dependent id="20">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="24">heart</governor>
          <dependent id="21">be</dependent>
        </dependency>
        <dependency type="case">
          <governor id="24">heart</governor>
          <dependent id="22">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="24">heart</governor>
          <dependent id="23">the</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">want</governor>
          <dependent id="24">heart</dependent>
        </dependency>
        <dependency type="case">
          <governor id="26">Europe</governor>
          <dependent id="25">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">heart</governor>
          <dependent id="26">Europe</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="3" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="pro-Europeans" type="MISC" score="0.0">
          <tokens>
            <token id="10" string="pro-Europeans" />
          </tokens>
        </entity>
        <entity id="3" string="Europe" type="LOCATION" score="0.0">
          <tokens>
            <token id="26" string="Europe" />
          </tokens>
        </entity>
        <entity id="4" string="Britain" type="LOCATION" score="0.0">
          <tokens>
            <token id="19" string="Britain" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="28" has_coreference="true">
      <content>On the other he is free with insulting references to the European Commission, whenever it is necessary to appeal to an audience of Euro-sceptics.</content>
      <tokens>
        <token id="1" string="On" lemma="on" stem="on" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="other" lemma="other" stem="other" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="5" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="free" lemma="free" stem="free" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="insulting" lemma="insulting" stem="insult" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="9" string="references" lemma="reference" stem="refer" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="European" lemma="european" stem="european" pos="JJ" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="13" string="Commission" lemma="Commission" stem="commiss" pos="NNP" type="Word" isStopWord="false" ner="ORGANIZATION" is_referenced="false" is_refers="false" />
        <token id="14" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="whenever" lemma="whenever" stem="whenev" pos="WRB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="it" lemma="it" stem="it" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="necessary" lemma="necessary" stem="necessari" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="appeal" lemma="appeal" stem="appeal" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="audience" lemma="audience" stem="audienc" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="Euro-sceptics" lemma="euro-sceptic" stem="euro-scept" pos="NNS" type="Word" isStopWord="false" ner="MISC" is_referenced="false" is_refers="false" />
        <token id="26" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (PP (IN On) (NP (DT the) (JJ other))) (NP (PRP he)) (VP (VBZ is) (ADJP (JJ free) (PP (IN with) (NP (JJ insulting) (NNS references)))) (PP (TO to) (NP (DT the) (JJ European) (NNP Commission))) (, ,) (SBAR (WHADVP (WRB whenever)) (S (NP (PRP it)) (VP (VBZ is) (ADJP (JJ necessary) (S (VP (TO to) (VP (VB appeal) (PP (TO to) (NP (NP (DT an) (NN audience)) (PP (IN of) (NP (NNS Euro-sceptics))))))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="free with insulting references" type="ADJP">
          <tokens>
            <token id="6" string="free" />
            <token id="7" string="with" />
            <token id="8" string="insulting" />
            <token id="9" string="references" />
          </tokens>
        </chunking>
        <chunking id="2" string="is necessary to appeal to an audience of Euro-sceptics" type="VP">
          <tokens>
            <token id="17" string="is" />
            <token id="18" string="necessary" />
            <token id="19" string="to" />
            <token id="20" string="appeal" />
            <token id="21" string="to" />
            <token id="22" string="an" />
            <token id="23" string="audience" />
            <token id="24" string="of" />
            <token id="25" string="Euro-sceptics" />
          </tokens>
        </chunking>
        <chunking id="3" string="whenever it is necessary to appeal to an audience of Euro-sceptics" type="SBAR">
          <tokens>
            <token id="15" string="whenever" />
            <token id="16" string="it" />
            <token id="17" string="is" />
            <token id="18" string="necessary" />
            <token id="19" string="to" />
            <token id="20" string="appeal" />
            <token id="21" string="to" />
            <token id="22" string="an" />
            <token id="23" string="audience" />
            <token id="24" string="of" />
            <token id="25" string="Euro-sceptics" />
          </tokens>
        </chunking>
        <chunking id="4" string="is free with insulting references to the European Commission , whenever it is necessary to appeal to an audience of Euro-sceptics" type="VP">
          <tokens>
            <token id="5" string="is" />
            <token id="6" string="free" />
            <token id="7" string="with" />
            <token id="8" string="insulting" />
            <token id="9" string="references" />
            <token id="10" string="to" />
            <token id="11" string="the" />
            <token id="12" string="European" />
            <token id="13" string="Commission" />
            <token id="14" string="," />
            <token id="15" string="whenever" />
            <token id="16" string="it" />
            <token id="17" string="is" />
            <token id="18" string="necessary" />
            <token id="19" string="to" />
            <token id="20" string="appeal" />
            <token id="21" string="to" />
            <token id="22" string="an" />
            <token id="23" string="audience" />
            <token id="24" string="of" />
            <token id="25" string="Euro-sceptics" />
          </tokens>
        </chunking>
        <chunking id="5" string="it" type="NP">
          <tokens>
            <token id="16" string="it" />
          </tokens>
        </chunking>
        <chunking id="6" string="appeal to an audience of Euro-sceptics" type="VP">
          <tokens>
            <token id="20" string="appeal" />
            <token id="21" string="to" />
            <token id="22" string="an" />
            <token id="23" string="audience" />
            <token id="24" string="of" />
            <token id="25" string="Euro-sceptics" />
          </tokens>
        </chunking>
        <chunking id="7" string="insulting references" type="NP">
          <tokens>
            <token id="8" string="insulting" />
            <token id="9" string="references" />
          </tokens>
        </chunking>
        <chunking id="8" string="an audience of Euro-sceptics" type="NP">
          <tokens>
            <token id="22" string="an" />
            <token id="23" string="audience" />
            <token id="24" string="of" />
            <token id="25" string="Euro-sceptics" />
          </tokens>
        </chunking>
        <chunking id="9" string="necessary to appeal to an audience of Euro-sceptics" type="ADJP">
          <tokens>
            <token id="18" string="necessary" />
            <token id="19" string="to" />
            <token id="20" string="appeal" />
            <token id="21" string="to" />
            <token id="22" string="an" />
            <token id="23" string="audience" />
            <token id="24" string="of" />
            <token id="25" string="Euro-sceptics" />
          </tokens>
        </chunking>
        <chunking id="10" string="he" type="NP">
          <tokens>
            <token id="4" string="he" />
          </tokens>
        </chunking>
        <chunking id="11" string="the European Commission" type="NP">
          <tokens>
            <token id="11" string="the" />
            <token id="12" string="European" />
            <token id="13" string="Commission" />
          </tokens>
        </chunking>
        <chunking id="12" string="whenever" type="WHADVP">
          <tokens>
            <token id="15" string="whenever" />
          </tokens>
        </chunking>
        <chunking id="13" string="an audience" type="NP">
          <tokens>
            <token id="22" string="an" />
            <token id="23" string="audience" />
          </tokens>
        </chunking>
        <chunking id="14" string="Euro-sceptics" type="NP">
          <tokens>
            <token id="25" string="Euro-sceptics" />
          </tokens>
        </chunking>
        <chunking id="15" string="to appeal to an audience of Euro-sceptics" type="VP">
          <tokens>
            <token id="19" string="to" />
            <token id="20" string="appeal" />
            <token id="21" string="to" />
            <token id="22" string="an" />
            <token id="23" string="audience" />
            <token id="24" string="of" />
            <token id="25" string="Euro-sceptics" />
          </tokens>
        </chunking>
        <chunking id="16" string="the other" type="NP">
          <tokens>
            <token id="2" string="the" />
            <token id="3" string="other" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="3">other</governor>
          <dependent id="1">On</dependent>
        </dependency>
        <dependency type="det">
          <governor id="3">other</governor>
          <dependent id="2">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">free</governor>
          <dependent id="3">other</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">free</governor>
          <dependent id="4">he</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">free</governor>
          <dependent id="5">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">free</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">references</governor>
          <dependent id="7">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="9">references</governor>
          <dependent id="8">insulting</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">free</governor>
          <dependent id="9">references</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">Commission</governor>
          <dependent id="10">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="13">Commission</governor>
          <dependent id="11">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">Commission</governor>
          <dependent id="12">European</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">free</governor>
          <dependent id="13">Commission</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="18">necessary</governor>
          <dependent id="15">whenever</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="18">necessary</governor>
          <dependent id="16">it</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="18">necessary</governor>
          <dependent id="17">is</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="6">free</governor>
          <dependent id="18">necessary</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="20">appeal</governor>
          <dependent id="19">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="18">necessary</governor>
          <dependent id="20">appeal</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">audience</governor>
          <dependent id="21">to</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">audience</governor>
          <dependent id="22">an</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="20">appeal</governor>
          <dependent id="23">audience</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">Euro-sceptics</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">audience</governor>
          <dependent id="25">Euro-sceptics</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="European Commission" type="ORGANIZATION" score="0.0">
          <tokens>
            <token id="12" string="European" />
            <token id="13" string="Commission" />
          </tokens>
        </entity>
        <entity id="2" string="Euro-sceptics" type="MISC" score="0.0">
          <tokens>
            <token id="25" string="Euro-sceptics" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="29" has_coreference="true">
      <content>There are those who will argue that this merely means that Major is a typical democratic politician, that one who wants to become prime minister in a democracy must recognise many constituencies of interest, not just one.</content>
      <tokens>
        <token id="1" string="There" lemma="there" stem="there" pos="EX" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="are" lemma="be" stem="ar" pos="VBP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="those" lemma="those" stem="those" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="4" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="5" string="will" lemma="will" stem="will" pos="MD" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="argue" lemma="argue" stem="argu" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="this" lemma="this" stem="thi" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="9" string="merely" lemma="merely" stem="mere" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="10" string="means" lemma="mean" stem="mean" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="11" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="12" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="13" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="15" string="typical" lemma="typical" stem="typic" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="16" string="democratic" lemma="democratic" stem="democrat" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="politician" lemma="politician" stem="politician" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="18" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="that" lemma="that" stem="that" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="21" string="who" lemma="who" stem="who" pos="WP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="22" string="wants" lemma="want" stem="want" pos="VBZ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="become" lemma="become" stem="becom" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="25" string="prime" lemma="prime" stem="prime" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="minister" lemma="minister" stem="minist" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="27" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="29" string="democracy" lemma="democracy" stem="democraci" pos="NN" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="true" is_refers="false" />
        <token id="30" string="must" lemma="must" stem="must" pos="MD" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="recognise" lemma="recognise" stem="recognis" pos="VB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="32" string="many" lemma="many" stem="mani" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="33" string="constituencies" lemma="constituency" stem="constitu" pos="NNS" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="34" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="35" string="interest" lemma="interest" stem="interest" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="36" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="37" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="38" string="just" lemma="just" stem="just" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="39" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="false" is_refers="false" />
        <token id="40" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (EX There)) (VP (VBP are) (NP (NP (NP (DT those)) (SBAR (WHNP (WP who)) (S (VP (MD will) (VP (VB argue) (SBAR (IN that) (S (NP (DT this)) (ADVP (RB merely)) (VP (VBZ means) (SBAR (IN that) (S (NP (NNP Major)) (VP (VBZ is) (NP (DT a) (JJ typical) (JJ democratic) (NN politician)) (, ,) (SBAR (IN that) (S (NP (NP (CD one)) (SBAR (WHNP (WP who)) (S (VP (VBZ wants) (S (VP (TO to) (VP (VB become) (NP (JJ prime) (NN minister)) (PP (IN in) (NP (DT a) (NN democracy)))))))))) (VP (MD must) (VP (VB recognise) (NP (NP (JJ many) (NNS constituencies)) (PP (IN of) (NP (NN interest))))))))))))))))))) (, ,) (CONJP (RB not) (RB just)) (NP (CD one)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="those who will argue that this merely means that Major is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest , not just one" type="NP">
          <tokens>
            <token id="3" string="those" />
            <token id="4" string="who" />
            <token id="5" string="will" />
            <token id="6" string="argue" />
            <token id="7" string="that" />
            <token id="8" string="this" />
            <token id="9" string="merely" />
            <token id="10" string="means" />
            <token id="11" string="that" />
            <token id="12" string="Major" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
            <token id="36" string="," />
            <token id="37" string="not" />
            <token id="38" string="just" />
            <token id="39" string="one" />
          </tokens>
        </chunking>
        <chunking id="2" string="those who will argue that this merely means that Major is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest" type="NP">
          <tokens>
            <token id="3" string="those" />
            <token id="4" string="who" />
            <token id="5" string="will" />
            <token id="6" string="argue" />
            <token id="7" string="that" />
            <token id="8" string="this" />
            <token id="9" string="merely" />
            <token id="10" string="means" />
            <token id="11" string="that" />
            <token id="12" string="Major" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="3" string="one" type="NP">
          <tokens>
            <token id="20" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="who will argue that this merely means that Major is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest" type="SBAR">
          <tokens>
            <token id="4" string="who" />
            <token id="5" string="will" />
            <token id="6" string="argue" />
            <token id="7" string="that" />
            <token id="8" string="this" />
            <token id="9" string="merely" />
            <token id="10" string="means" />
            <token id="11" string="that" />
            <token id="12" string="Major" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="5" string="this" type="NP">
          <tokens>
            <token id="8" string="this" />
          </tokens>
        </chunking>
        <chunking id="6" string="means that Major is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest" type="VP">
          <tokens>
            <token id="10" string="means" />
            <token id="11" string="that" />
            <token id="12" string="Major" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="7" string="a typical democratic politician" type="NP">
          <tokens>
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
          </tokens>
        </chunking>
        <chunking id="8" string="Major" type="NP">
          <tokens>
            <token id="12" string="Major" />
          </tokens>
        </chunking>
        <chunking id="9" string="that one who wants to become prime minister in a democracy must recognise many constituencies of interest" type="SBAR">
          <tokens>
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="10" string="many constituencies of interest" type="NP">
          <tokens>
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="11" string="that this merely means that Major is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest" type="SBAR">
          <tokens>
            <token id="7" string="that" />
            <token id="8" string="this" />
            <token id="9" string="merely" />
            <token id="10" string="means" />
            <token id="11" string="that" />
            <token id="12" string="Major" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="12" string="argue that this merely means that Major is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest" type="VP">
          <tokens>
            <token id="6" string="argue" />
            <token id="7" string="that" />
            <token id="8" string="this" />
            <token id="9" string="merely" />
            <token id="10" string="means" />
            <token id="11" string="that" />
            <token id="12" string="Major" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="13" string="one who wants to become prime minister in a democracy" type="NP">
          <tokens>
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
          </tokens>
        </chunking>
        <chunking id="14" string="will argue that this merely means that Major is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest" type="VP">
          <tokens>
            <token id="5" string="will" />
            <token id="6" string="argue" />
            <token id="7" string="that" />
            <token id="8" string="this" />
            <token id="9" string="merely" />
            <token id="10" string="means" />
            <token id="11" string="that" />
            <token id="12" string="Major" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="15" string="become prime minister in a democracy" type="VP">
          <tokens>
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
          </tokens>
        </chunking>
        <chunking id="16" string="many constituencies" type="NP">
          <tokens>
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
          </tokens>
        </chunking>
        <chunking id="17" string="who wants to become prime minister in a democracy" type="SBAR">
          <tokens>
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
          </tokens>
        </chunking>
        <chunking id="18" string="prime minister" type="NP">
          <tokens>
            <token id="25" string="prime" />
            <token id="26" string="minister" />
          </tokens>
        </chunking>
        <chunking id="19" string="a democracy" type="NP">
          <tokens>
            <token id="28" string="a" />
            <token id="29" string="democracy" />
          </tokens>
        </chunking>
        <chunking id="20" string="is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest" type="VP">
          <tokens>
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="21" string="must recognise many constituencies of interest" type="VP">
          <tokens>
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="22" string="wants to become prime minister in a democracy" type="VP">
          <tokens>
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
          </tokens>
        </chunking>
        <chunking id="23" string="There" type="NP">
          <tokens>
            <token id="1" string="There" />
          </tokens>
        </chunking>
        <chunking id="24" string="recognise many constituencies of interest" type="VP">
          <tokens>
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="25" string="interest" type="NP">
          <tokens>
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="26" string="are those who will argue that this merely means that Major is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest , not just one" type="VP">
          <tokens>
            <token id="2" string="are" />
            <token id="3" string="those" />
            <token id="4" string="who" />
            <token id="5" string="will" />
            <token id="6" string="argue" />
            <token id="7" string="that" />
            <token id="8" string="this" />
            <token id="9" string="merely" />
            <token id="10" string="means" />
            <token id="11" string="that" />
            <token id="12" string="Major" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
            <token id="36" string="," />
            <token id="37" string="not" />
            <token id="38" string="just" />
            <token id="39" string="one" />
          </tokens>
        </chunking>
        <chunking id="27" string="to become prime minister in a democracy" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
          </tokens>
        </chunking>
        <chunking id="28" string="that Major is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest" type="SBAR">
          <tokens>
            <token id="11" string="that" />
            <token id="12" string="Major" />
            <token id="13" string="is" />
            <token id="14" string="a" />
            <token id="15" string="typical" />
            <token id="16" string="democratic" />
            <token id="17" string="politician" />
            <token id="18" string="," />
            <token id="19" string="that" />
            <token id="20" string="one" />
            <token id="21" string="who" />
            <token id="22" string="wants" />
            <token id="23" string="to" />
            <token id="24" string="become" />
            <token id="25" string="prime" />
            <token id="26" string="minister" />
            <token id="27" string="in" />
            <token id="28" string="a" />
            <token id="29" string="democracy" />
            <token id="30" string="must" />
            <token id="31" string="recognise" />
            <token id="32" string="many" />
            <token id="33" string="constituencies" />
            <token id="34" string="of" />
            <token id="35" string="interest" />
          </tokens>
        </chunking>
        <chunking id="29" string="those" type="NP">
          <tokens>
            <token id="3" string="those" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="expl">
          <governor id="2">are</governor>
          <dependent id="1">There</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="2">are</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="2">are</governor>
          <dependent id="3">those</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">argue</governor>
          <dependent id="4">who</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">argue</governor>
          <dependent id="5">will</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="3">those</governor>
          <dependent id="6">argue</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="10">means</governor>
          <dependent id="7">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">means</governor>
          <dependent id="8">this</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="10">means</governor>
          <dependent id="9">merely</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="6">argue</governor>
          <dependent id="10">means</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="17">politician</governor>
          <dependent id="11">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="17">politician</governor>
          <dependent id="12">Major</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="17">politician</governor>
          <dependent id="13">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="17">politician</governor>
          <dependent id="14">a</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">politician</governor>
          <dependent id="15">typical</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="17">politician</governor>
          <dependent id="16">democratic</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="10">means</governor>
          <dependent id="17">politician</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="31">recognise</governor>
          <dependent id="19">that</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="31">recognise</governor>
          <dependent id="20">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">wants</governor>
          <dependent id="21">who</dependent>
        </dependency>
        <dependency type="acl:relcl">
          <governor id="20">one</governor>
          <dependent id="22">wants</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="24">become</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">wants</governor>
          <dependent id="24">become</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="26">minister</governor>
          <dependent id="25">prime</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="24">become</governor>
          <dependent id="26">minister</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">democracy</governor>
          <dependent id="27">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">democracy</governor>
          <dependent id="28">a</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="24">become</governor>
          <dependent id="29">democracy</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="31">recognise</governor>
          <dependent id="30">must</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="17">politician</governor>
          <dependent id="31">recognise</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="33">constituencies</governor>
          <dependent id="32">many</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="31">recognise</governor>
          <dependent id="33">constituencies</dependent>
        </dependency>
        <dependency type="case">
          <governor id="35">interest</governor>
          <dependent id="34">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="33">constituencies</governor>
          <dependent id="35">interest</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="38">just</governor>
          <dependent id="37">not</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="3">those</governor>
          <dependent id="38">just</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="3">those</governor>
          <dependent id="39">one</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="20" string="one" />
          </tokens>
        </entity>
        <entity id="2" string="democracy" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="29" string="democracy" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="30" has_coreference="true">
      <content>But that has not been true of Major&amp;apost;s most recent Conservative predecessors.</content>
      <tokens>
        <token id="1" string="But" lemma="but" stem="but" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="that" lemma="that" stem="that" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="3" string="has" lemma="have" stem="ha" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="been" lemma="be" stem="been" pos="VBN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="true" lemma="true" stem="true" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="7" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="9" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="10" string="most" lemma="most" stem="most" pos="RBS" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="recent" lemma="recent" stem="recent" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="Conservative" lemma="conservative" stem="conserv" pos="JJ" type="Word" isStopWord="false" ner="IDEOLOGY" is_referenced="false" is_refers="false" />
        <token id="13" string="predecessors" lemma="predecessor" stem="predecessor" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="14" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (CC But) (NP (DT that)) (VP (VBZ has) (RB not) (VP (VBN been) (ADJP (JJ true)) (PP (IN of) (NP (NP (NNP Major) (POS 's)) (ADJP (RBS most) (JJ recent)) (JJ Conservative) (NNS predecessors))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="that" type="NP">
          <tokens>
            <token id="2" string="that" />
          </tokens>
        </chunking>
        <chunking id="2" string="has not been true of Major 's most recent Conservative predecessors" type="VP">
          <tokens>
            <token id="3" string="has" />
            <token id="4" string="not" />
            <token id="5" string="been" />
            <token id="6" string="true" />
            <token id="7" string="of" />
            <token id="8" string="Major" />
            <token id="9" string="'s" />
            <token id="10" string="most" />
            <token id="11" string="recent" />
            <token id="12" string="Conservative" />
            <token id="13" string="predecessors" />
          </tokens>
        </chunking>
        <chunking id="3" string="been true of Major 's most recent Conservative predecessors" type="VP">
          <tokens>
            <token id="5" string="been" />
            <token id="6" string="true" />
            <token id="7" string="of" />
            <token id="8" string="Major" />
            <token id="9" string="'s" />
            <token id="10" string="most" />
            <token id="11" string="recent" />
            <token id="12" string="Conservative" />
            <token id="13" string="predecessors" />
          </tokens>
        </chunking>
        <chunking id="4" string="Major 's most recent Conservative predecessors" type="NP">
          <tokens>
            <token id="8" string="Major" />
            <token id="9" string="'s" />
            <token id="10" string="most" />
            <token id="11" string="recent" />
            <token id="12" string="Conservative" />
            <token id="13" string="predecessors" />
          </tokens>
        </chunking>
        <chunking id="5" string="true" type="ADJP">
          <tokens>
            <token id="6" string="true" />
          </tokens>
        </chunking>
        <chunking id="6" string="Major 's" type="NP">
          <tokens>
            <token id="8" string="Major" />
            <token id="9" string="'s" />
          </tokens>
        </chunking>
        <chunking id="7" string="most recent" type="ADJP">
          <tokens>
            <token id="10" string="most" />
            <token id="11" string="recent" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="cc">
          <governor id="6">true</governor>
          <dependent id="1">But</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="6">true</governor>
          <dependent id="2">that</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="6">true</governor>
          <dependent id="3">has</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="6">true</governor>
          <dependent id="4">not</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="6">true</governor>
          <dependent id="5">been</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="6">true</dependent>
        </dependency>
        <dependency type="case">
          <governor id="13">predecessors</governor>
          <dependent id="7">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="13">predecessors</governor>
          <dependent id="8">Major</dependent>
        </dependency>
        <dependency type="case">
          <governor id="8">Major</governor>
          <dependent id="9">'s</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">recent</governor>
          <dependent id="10">most</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">predecessors</governor>
          <dependent id="11">recent</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="13">predecessors</governor>
          <dependent id="12">Conservative</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="6">true</governor>
          <dependent id="13">predecessors</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Conservative" type="IDEOLOGY" score="0.0">
          <tokens>
            <token id="12" string="Conservative" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="31" has_coreference="false">
      <content>Margaret Thatcher was notoriously dogmatic, even in public, and so too was Edward Heath, even though he always pretended to be a &amp;apost;consensus politician&amp;apost;.</content>
      <tokens>
        <token id="1" string="Margaret" lemma="Margaret" stem="margaret" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="2" string="Thatcher" lemma="Thatcher" stem="thatcher" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="false" />
        <token id="3" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="notoriously" lemma="notoriously" stem="notori" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="dogmatic" lemma="dogmatic" stem="dogmat" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="public" lemma="public" stem="public" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="and" lemma="and" stem="and" pos="CC" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="so" lemma="so" stem="so" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="too" lemma="too" stem="too" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="Edward" lemma="Edward" stem="edward" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="16" string="Heath" lemma="Heath" stem="heath" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="even" lemma="even" stem="even" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="though" lemma="though" stem="though" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="20" string="he" lemma="he" stem="he" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="21" string="always" lemma="always" stem="alwai" pos="RB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="22" string="pretended" lemma="pretend" stem="pretend" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="23" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="24" string="be" lemma="be" stem="be" pos="VB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="26" string="'" lemma="`" stem="'" pos="``" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="consensus" lemma="consensus" stem="consensu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="politician" lemma="politician" stem="politician" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="29" string="'" lemma="'" stem="'" pos="''" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Margaret) (NNP Thatcher)) (VP (VBD was) (ADJP (RB notoriously) (JJ dogmatic) (PRN (, ,) (SINV (ADVP (ADVP (RB even) (PP (IN in) (ADJP (JJ public)))) (, ,) (CC and) (RB so) (ADVP (RB too))) (VBD was) (NP (NNP Edward) (NNP Heath))) (, ,)) (SBAR (RB even) (IN though) (S (NP (PRP he)) (ADVP (RB always)) (VP (VBD pretended) (S (VP (TO to) (VP (VB be) (NP (DT a) (`` `) (NN consensus) (NN politician) ('' ')))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="be a ` consensus politician '" type="VP">
          <tokens>
            <token id="24" string="be" />
            <token id="25" string="a" />
            <token id="26" string="'" />
            <token id="27" string="consensus" />
            <token id="28" string="politician" />
            <token id="29" string="'" />
          </tokens>
        </chunking>
        <chunking id="2" string="pretended to be a ` consensus politician '" type="VP">
          <tokens>
            <token id="22" string="pretended" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="a" />
            <token id="26" string="'" />
            <token id="27" string="consensus" />
            <token id="28" string="politician" />
            <token id="29" string="'" />
          </tokens>
        </chunking>
        <chunking id="3" string="was notoriously dogmatic , even in public , and so too was Edward Heath , even though he always pretended to be a ` consensus politician '" type="VP">
          <tokens>
            <token id="3" string="was" />
            <token id="4" string="notoriously" />
            <token id="5" string="dogmatic" />
            <token id="6" string="," />
            <token id="7" string="even" />
            <token id="8" string="in" />
            <token id="9" string="public" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="so" />
            <token id="13" string="too" />
            <token id="14" string="was" />
            <token id="15" string="Edward" />
            <token id="16" string="Heath" />
            <token id="17" string="," />
            <token id="18" string="even" />
            <token id="19" string="though" />
            <token id="20" string="he" />
            <token id="21" string="always" />
            <token id="22" string="pretended" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="a" />
            <token id="26" string="'" />
            <token id="27" string="consensus" />
            <token id="28" string="politician" />
            <token id="29" string="'" />
          </tokens>
        </chunking>
        <chunking id="4" string="public" type="ADJP">
          <tokens>
            <token id="9" string="public" />
          </tokens>
        </chunking>
        <chunking id="5" string="notoriously dogmatic , even in public , and so too was Edward Heath , even though he always pretended to be a ` consensus politician '" type="ADJP">
          <tokens>
            <token id="4" string="notoriously" />
            <token id="5" string="dogmatic" />
            <token id="6" string="," />
            <token id="7" string="even" />
            <token id="8" string="in" />
            <token id="9" string="public" />
            <token id="10" string="," />
            <token id="11" string="and" />
            <token id="12" string="so" />
            <token id="13" string="too" />
            <token id="14" string="was" />
            <token id="15" string="Edward" />
            <token id="16" string="Heath" />
            <token id="17" string="," />
            <token id="18" string="even" />
            <token id="19" string="though" />
            <token id="20" string="he" />
            <token id="21" string="always" />
            <token id="22" string="pretended" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="a" />
            <token id="26" string="'" />
            <token id="27" string="consensus" />
            <token id="28" string="politician" />
            <token id="29" string="'" />
          </tokens>
        </chunking>
        <chunking id="6" string="even though he always pretended to be a ` consensus politician '" type="SBAR">
          <tokens>
            <token id="18" string="even" />
            <token id="19" string="though" />
            <token id="20" string="he" />
            <token id="21" string="always" />
            <token id="22" string="pretended" />
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="a" />
            <token id="26" string="'" />
            <token id="27" string="consensus" />
            <token id="28" string="politician" />
            <token id="29" string="'" />
          </tokens>
        </chunking>
        <chunking id="7" string="to be a ` consensus politician '" type="VP">
          <tokens>
            <token id="23" string="to" />
            <token id="24" string="be" />
            <token id="25" string="a" />
            <token id="26" string="'" />
            <token id="27" string="consensus" />
            <token id="28" string="politician" />
            <token id="29" string="'" />
          </tokens>
        </chunking>
        <chunking id="8" string="he" type="NP">
          <tokens>
            <token id="20" string="he" />
          </tokens>
        </chunking>
        <chunking id="9" string="Edward Heath" type="NP">
          <tokens>
            <token id="15" string="Edward" />
            <token id="16" string="Heath" />
          </tokens>
        </chunking>
        <chunking id="10" string="a ` consensus politician '" type="NP">
          <tokens>
            <token id="25" string="a" />
            <token id="26" string="'" />
            <token id="27" string="consensus" />
            <token id="28" string="politician" />
            <token id="29" string="'" />
          </tokens>
        </chunking>
        <chunking id="11" string="Margaret Thatcher" type="NP">
          <tokens>
            <token id="1" string="Margaret" />
            <token id="2" string="Thatcher" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Thatcher</governor>
          <dependent id="1">Margaret</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="5">dogmatic</governor>
          <dependent id="2">Thatcher</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="5">dogmatic</governor>
          <dependent id="3">was</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="5">dogmatic</governor>
          <dependent id="4">notoriously</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="5">dogmatic</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">Heath</governor>
          <dependent id="7">even</dependent>
        </dependency>
        <dependency type="case">
          <governor id="9">public</governor>
          <dependent id="8">in</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="7">even</governor>
          <dependent id="9">public</dependent>
        </dependency>
        <dependency type="cc">
          <governor id="7">even</governor>
          <dependent id="11">and</dependent>
        </dependency>
        <dependency type="conj">
          <governor id="7">even</governor>
          <dependent id="12">so</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="7">even</governor>
          <dependent id="13">too</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="16">Heath</governor>
          <dependent id="14">was</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="16">Heath</governor>
          <dependent id="15">Edward</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="5">dogmatic</governor>
          <dependent id="16">Heath</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">pretended</governor>
          <dependent id="18">even</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="22">pretended</governor>
          <dependent id="19">though</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="22">pretended</governor>
          <dependent id="20">he</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="22">pretended</governor>
          <dependent id="21">always</dependent>
        </dependency>
        <dependency type="ccomp">
          <governor id="5">dogmatic</governor>
          <dependent id="22">pretended</dependent>
        </dependency>
        <dependency type="mark">
          <governor id="28">politician</governor>
          <dependent id="23">to</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="28">politician</governor>
          <dependent id="24">be</dependent>
        </dependency>
        <dependency type="det">
          <governor id="28">politician</governor>
          <dependent id="25">a</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="28">politician</governor>
          <dependent id="27">consensus</dependent>
        </dependency>
        <dependency type="xcomp">
          <governor id="22">pretended</governor>
          <dependent id="28">politician</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Edward Heath" type="PERSON" score="0.0">
          <tokens>
            <token id="15" string="Edward" />
            <token id="16" string="Heath" />
          </tokens>
        </entity>
        <entity id="2" string="Margaret Thatcher" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Margaret" />
            <token id="2" string="Thatcher" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="32" has_coreference="true">
      <content>No, Major&amp;apost;s technique is very much his own invention, very much a reflection of his own particular character, itself a product of his unsettled family background.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="2" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="3" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" is_referenced="true" is_refers="true" />
        <token id="4" string="'s" lemma="'s" stem="'" pos="POS" type="Word" isStopWord="true" is_referenced="true" is_refers="true" />
        <token id="5" string="technique" lemma="technique" stem="techniqu" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="6" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="8" string="much" lemma="much" stem="much" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="9" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="10" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="11" string="invention" lemma="invention" stem="invent" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="12" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="13" string="very" lemma="very" stem="veri" pos="RB" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="14" string="much" lemma="much" stem="much" pos="RB" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="15" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="16" string="reflection" lemma="reflection" stem="reflect" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="17" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="18" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="19" string="own" lemma="own" stem="own" pos="JJ" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="20" string="particular" lemma="particular" stem="particular" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="21" string="character" lemma="character" stem="charact" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="22" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="23" string="itself" lemma="itself" stem="itself" pos="PRP" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="24" string="a" lemma="a" stem="a" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="25" string="product" lemma="product" stem="product" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="26" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="27" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="28" string="unsettled" lemma="unsettled" stem="unsettl" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="29" string="family" lemma="family" stem="famili" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="30" string="background" lemma="background" stem="background" pos="NN" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="31" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT No)) (, ,) (NP (NP (NNP Major) (POS 's)) (NN technique))) (VP (VBZ is) (NP (RB very) (ADVP (JJ much)) (NP (NP (PRP$ his) (JJ own) (NN invention)) (, ,) (ADVP (RB very) (NP (RB much) (DT a) (NN reflection)))) (PP (IN of) (NP (PRP$ his) (JJ own) (JJ particular) (NN character))) (, ,) (ADVP (PRP itself)) (NP (NP (DT a) (NN product)) (PP (IN of) (NP (PRP$ his) (JJ unsettled) (NN family) (NN background)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="No" type="NP">
          <tokens>
            <token id="1" string="No" />
          </tokens>
        </chunking>
        <chunking id="2" string="No , Major 's technique" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="," />
            <token id="3" string="Major" />
            <token id="4" string="'s" />
            <token id="5" string="technique" />
          </tokens>
        </chunking>
        <chunking id="3" string="his own invention" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="own" />
            <token id="11" string="invention" />
          </tokens>
        </chunking>
        <chunking id="4" string="very much his own invention , very much a reflection of his own particular character , itself a product of his unsettled family background" type="NP">
          <tokens>
            <token id="7" string="very" />
            <token id="8" string="much" />
            <token id="9" string="his" />
            <token id="10" string="own" />
            <token id="11" string="invention" />
            <token id="12" string="," />
            <token id="13" string="very" />
            <token id="14" string="much" />
            <token id="15" string="a" />
            <token id="16" string="reflection" />
            <token id="17" string="of" />
            <token id="18" string="his" />
            <token id="19" string="own" />
            <token id="20" string="particular" />
            <token id="21" string="character" />
            <token id="22" string="," />
            <token id="23" string="itself" />
            <token id="24" string="a" />
            <token id="25" string="product" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="unsettled" />
            <token id="29" string="family" />
            <token id="30" string="background" />
          </tokens>
        </chunking>
        <chunking id="5" string="a product of his unsettled family background" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="product" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="unsettled" />
            <token id="29" string="family" />
            <token id="30" string="background" />
          </tokens>
        </chunking>
        <chunking id="6" string="his own invention , very much a reflection" type="NP">
          <tokens>
            <token id="9" string="his" />
            <token id="10" string="own" />
            <token id="11" string="invention" />
            <token id="12" string="," />
            <token id="13" string="very" />
            <token id="14" string="much" />
            <token id="15" string="a" />
            <token id="16" string="reflection" />
          </tokens>
        </chunking>
        <chunking id="7" string="a product" type="NP">
          <tokens>
            <token id="24" string="a" />
            <token id="25" string="product" />
          </tokens>
        </chunking>
        <chunking id="8" string="is very much his own invention , very much a reflection of his own particular character , itself a product of his unsettled family background" type="VP">
          <tokens>
            <token id="6" string="is" />
            <token id="7" string="very" />
            <token id="8" string="much" />
            <token id="9" string="his" />
            <token id="10" string="own" />
            <token id="11" string="invention" />
            <token id="12" string="," />
            <token id="13" string="very" />
            <token id="14" string="much" />
            <token id="15" string="a" />
            <token id="16" string="reflection" />
            <token id="17" string="of" />
            <token id="18" string="his" />
            <token id="19" string="own" />
            <token id="20" string="particular" />
            <token id="21" string="character" />
            <token id="22" string="," />
            <token id="23" string="itself" />
            <token id="24" string="a" />
            <token id="25" string="product" />
            <token id="26" string="of" />
            <token id="27" string="his" />
            <token id="28" string="unsettled" />
            <token id="29" string="family" />
            <token id="30" string="background" />
          </tokens>
        </chunking>
        <chunking id="9" string="his own particular character" type="NP">
          <tokens>
            <token id="18" string="his" />
            <token id="19" string="own" />
            <token id="20" string="particular" />
            <token id="21" string="character" />
          </tokens>
        </chunking>
        <chunking id="10" string="his unsettled family background" type="NP">
          <tokens>
            <token id="27" string="his" />
            <token id="28" string="unsettled" />
            <token id="29" string="family" />
            <token id="30" string="background" />
          </tokens>
        </chunking>
        <chunking id="11" string="much a reflection" type="NP">
          <tokens>
            <token id="14" string="much" />
            <token id="15" string="a" />
            <token id="16" string="reflection" />
          </tokens>
        </chunking>
        <chunking id="12" string="Major 's" type="NP">
          <tokens>
            <token id="3" string="Major" />
            <token id="4" string="'s" />
          </tokens>
        </chunking>
        <chunking id="13" string="Major 's technique" type="NP">
          <tokens>
            <token id="3" string="Major" />
            <token id="4" string="'s" />
            <token id="5" string="technique" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nsubj">
          <governor id="11">invention</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="5">technique</governor>
          <dependent id="3">Major</dependent>
        </dependency>
        <dependency type="case">
          <governor id="3">Major</governor>
          <dependent id="4">'s</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="1">No</governor>
          <dependent id="5">technique</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="11">invention</governor>
          <dependent id="6">is</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">invention</governor>
          <dependent id="7">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">invention</governor>
          <dependent id="8">much</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="11">invention</governor>
          <dependent id="9">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="11">invention</governor>
          <dependent id="10">own</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="11">invention</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">invention</governor>
          <dependent id="13">very</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="16">reflection</governor>
          <dependent id="14">much</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">reflection</governor>
          <dependent id="15">a</dependent>
        </dependency>
        <dependency type="nmod:npmod">
          <governor id="13">very</governor>
          <dependent id="16">reflection</dependent>
        </dependency>
        <dependency type="case">
          <governor id="21">character</governor>
          <dependent id="17">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="21">character</governor>
          <dependent id="18">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">character</governor>
          <dependent id="19">own</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="21">character</governor>
          <dependent id="20">particular</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="11">invention</governor>
          <dependent id="21">character</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="11">invention</governor>
          <dependent id="23">itself</dependent>
        </dependency>
        <dependency type="det">
          <governor id="25">product</governor>
          <dependent id="24">a</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="11">invention</governor>
          <dependent id="25">product</dependent>
        </dependency>
        <dependency type="case">
          <governor id="30">background</governor>
          <dependent id="26">of</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="30">background</governor>
          <dependent id="27">his</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="30">background</governor>
          <dependent id="28">unsettled</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="30">background</governor>
          <dependent id="29">family</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="25">product</governor>
          <dependent id="30">background</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="33" has_coreference="true">
      <content>His father, Tom Major-Ball, was an itinerant figure, moving from place to place, trying his hand at any number of occupations, including the circus.</content>
      <tokens>
        <token id="1" string="His" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="2" string="father" lemma="father" stem="father" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="Tom" lemma="Tom" stem="tom" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="5" string="Major-Ball" lemma="Major-Ball" stem="major-bal" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="6" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="was" lemma="be" stem="wa" pos="VBD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="8" string="an" lemma="a" stem="an" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="itinerant" lemma="itinerant" stem="itiner" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="figure" lemma="figure" stem="figur" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="11" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="moving" lemma="move" stem="move" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="from" lemma="from" stem="from" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="to" lemma="to" stem="to" pos="TO" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="place" lemma="place" stem="place" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="trying" lemma="try" stem="try" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="his" lemma="he" stem="hi" pos="PRP$" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="20" string="hand" lemma="hand" stem="hand" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="21" string="at" lemma="at" stem="at" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="22" string="any" lemma="any" stem="ani" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="23" string="number" lemma="number" stem="number" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="24" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="25" string="occupations" lemma="occupation" stem="occup" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="26" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="27" string="including" lemma="include" stem="includ" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="28" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="29" string="circus" lemma="circus" stem="circu" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="30" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (PRP$ His) (NN father)) (, ,) (NP (NNP Tom) (NNP Major-Ball)) (, ,)) (VP (VBD was) (NP (NP (DT an) (JJ itinerant) (NN figure)) (, ,) (VP (VBG moving) (PP (IN from) (NP (NN place))) (PP (TO to) (NP (NN place))) (, ,) (S (VP (VBG trying) (NP (PRP$ his) (NN hand)) (PP (IN at) (NP (NP (DT any) (NN number)) (PP (IN of) (NP (NNS occupations)))))))) (, ,) (PP (VBG including) (NP (DT the) (NN circus))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="His father , Tom Major-Ball ," type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="father" />
            <token id="3" string="," />
            <token id="4" string="Tom" />
            <token id="5" string="Major-Ball" />
            <token id="6" string="," />
          </tokens>
        </chunking>
        <chunking id="2" string="occupations" type="NP">
          <tokens>
            <token id="25" string="occupations" />
          </tokens>
        </chunking>
        <chunking id="3" string="his hand" type="NP">
          <tokens>
            <token id="19" string="his" />
            <token id="20" string="hand" />
          </tokens>
        </chunking>
        <chunking id="4" string="Tom Major-Ball" type="NP">
          <tokens>
            <token id="4" string="Tom" />
            <token id="5" string="Major-Ball" />
          </tokens>
        </chunking>
        <chunking id="5" string="His father" type="NP">
          <tokens>
            <token id="1" string="His" />
            <token id="2" string="father" />
          </tokens>
        </chunking>
        <chunking id="6" string="an itinerant figure , moving from place to place , trying his hand at any number of occupations , including the circus" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="itinerant" />
            <token id="10" string="figure" />
            <token id="11" string="," />
            <token id="12" string="moving" />
            <token id="13" string="from" />
            <token id="14" string="place" />
            <token id="15" string="to" />
            <token id="16" string="place" />
            <token id="17" string="," />
            <token id="18" string="trying" />
            <token id="19" string="his" />
            <token id="20" string="hand" />
            <token id="21" string="at" />
            <token id="22" string="any" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="occupations" />
            <token id="26" string="," />
            <token id="27" string="including" />
            <token id="28" string="the" />
            <token id="29" string="circus" />
          </tokens>
        </chunking>
        <chunking id="7" string="an itinerant figure" type="NP">
          <tokens>
            <token id="8" string="an" />
            <token id="9" string="itinerant" />
            <token id="10" string="figure" />
          </tokens>
        </chunking>
        <chunking id="8" string="any number of occupations" type="NP">
          <tokens>
            <token id="22" string="any" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="occupations" />
          </tokens>
        </chunking>
        <chunking id="9" string="was an itinerant figure , moving from place to place , trying his hand at any number of occupations , including the circus" type="VP">
          <tokens>
            <token id="7" string="was" />
            <token id="8" string="an" />
            <token id="9" string="itinerant" />
            <token id="10" string="figure" />
            <token id="11" string="," />
            <token id="12" string="moving" />
            <token id="13" string="from" />
            <token id="14" string="place" />
            <token id="15" string="to" />
            <token id="16" string="place" />
            <token id="17" string="," />
            <token id="18" string="trying" />
            <token id="19" string="his" />
            <token id="20" string="hand" />
            <token id="21" string="at" />
            <token id="22" string="any" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="occupations" />
            <token id="26" string="," />
            <token id="27" string="including" />
            <token id="28" string="the" />
            <token id="29" string="circus" />
          </tokens>
        </chunking>
        <chunking id="10" string="any number" type="NP">
          <tokens>
            <token id="22" string="any" />
            <token id="23" string="number" />
          </tokens>
        </chunking>
        <chunking id="11" string="moving from place to place , trying his hand at any number of occupations" type="VP">
          <tokens>
            <token id="12" string="moving" />
            <token id="13" string="from" />
            <token id="14" string="place" />
            <token id="15" string="to" />
            <token id="16" string="place" />
            <token id="17" string="," />
            <token id="18" string="trying" />
            <token id="19" string="his" />
            <token id="20" string="hand" />
            <token id="21" string="at" />
            <token id="22" string="any" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="occupations" />
          </tokens>
        </chunking>
        <chunking id="12" string="place" type="NP">
          <tokens>
            <token id="14" string="place" />
          </tokens>
        </chunking>
        <chunking id="13" string="the circus" type="NP">
          <tokens>
            <token id="28" string="the" />
            <token id="29" string="circus" />
          </tokens>
        </chunking>
        <chunking id="14" string="trying his hand at any number of occupations" type="VP">
          <tokens>
            <token id="18" string="trying" />
            <token id="19" string="his" />
            <token id="20" string="hand" />
            <token id="21" string="at" />
            <token id="22" string="any" />
            <token id="23" string="number" />
            <token id="24" string="of" />
            <token id="25" string="occupations" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="nmod:poss">
          <governor id="2">father</governor>
          <dependent id="1">His</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="10">figure</governor>
          <dependent id="2">father</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="5">Major-Ball</governor>
          <dependent id="4">Tom</dependent>
        </dependency>
        <dependency type="appos">
          <governor id="2">father</governor>
          <dependent id="5">Major-Ball</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="10">figure</governor>
          <dependent id="7">was</dependent>
        </dependency>
        <dependency type="det">
          <governor id="10">figure</governor>
          <dependent id="8">an</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="10">figure</governor>
          <dependent id="9">itinerant</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="10">figure</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="10">figure</governor>
          <dependent id="12">moving</dependent>
        </dependency>
        <dependency type="case">
          <governor id="14">place</governor>
          <dependent id="13">from</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">moving</governor>
          <dependent id="14">place</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">place</governor>
          <dependent id="15">to</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="12">moving</governor>
          <dependent id="16">place</dependent>
        </dependency>
        <dependency type="advcl">
          <governor id="12">moving</governor>
          <dependent id="18">trying</dependent>
        </dependency>
        <dependency type="nmod:poss">
          <governor id="20">hand</governor>
          <dependent id="19">his</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="18">trying</governor>
          <dependent id="20">hand</dependent>
        </dependency>
        <dependency type="case">
          <governor id="23">number</governor>
          <dependent id="21">at</dependent>
        </dependency>
        <dependency type="det">
          <governor id="23">number</governor>
          <dependent id="22">any</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="18">trying</governor>
          <dependent id="23">number</dependent>
        </dependency>
        <dependency type="case">
          <governor id="25">occupations</governor>
          <dependent id="24">of</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="23">number</governor>
          <dependent id="25">occupations</dependent>
        </dependency>
        <dependency type="case">
          <governor id="29">circus</governor>
          <dependent id="27">including</dependent>
        </dependency>
        <dependency type="det">
          <governor id="29">circus</governor>
          <dependent id="28">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="10">figure</governor>
          <dependent id="29">circus</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Tom Major-Ball" type="PERSON" score="0.0">
          <tokens>
            <token id="4" string="Tom" />
            <token id="5" string="Major-Ball" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="34" has_coreference="true">
      <content>No wonder the young John Major learned the skill of fitting in with prevailing circumstances, no matter how fluctuating.</content>
      <tokens>
        <token id="1" string="No" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="wonder" lemma="wonder" stem="wonder" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="true" />
        <token id="4" string="young" lemma="young" stem="young" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="true" />
        <token id="5" string="John" lemma="John" stem="john" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="6" string="Major" lemma="Major" stem="major" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="false" is_refers="true" />
        <token id="7" string="learned" lemma="learn" stem="learn" pos="VBD" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="8" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="skill" lemma="skill" stem="skill" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="10" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="fitting" lemma="fitting" stem="fit" pos="JJ" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="12" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="13" string="with" lemma="with" stem="with" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="prevailing" lemma="prevail" stem="prevail" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="15" string="circumstances" lemma="circumstance" stem="circumst" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="16" string="," lemma="," stem="," pos="," type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="17" string="no" lemma="no" stem="no" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="matter" lemma="matter" stem="matter" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="19" string="how" lemma="how" stem="how" pos="WRB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="fluctuating" lemma="fluctuate" stem="fluctuat" pos="VBG" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NP (DT No) (NN wonder)) (NP (DT the) (JJ young) (NNP John) (NNP Major))) (VP (VBD learned) (NP (NP (DT the) (NN skill)) (PP (IN of) (ADJP (JJ fitting)))) (PP (IN in) (IN with) (NP (VBG prevailing) (NNS circumstances))) (, ,) (ADVP (DT no) (NN matter) (SBAR (WHADVP (WRB how)) (S (VP (VBG fluctuating)))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the skill" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="skill" />
          </tokens>
        </chunking>
        <chunking id="2" string="the young John Major" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="young" />
            <token id="5" string="John" />
            <token id="6" string="Major" />
          </tokens>
        </chunking>
        <chunking id="3" string="fluctuating" type="VP">
          <tokens>
            <token id="20" string="fluctuating" />
          </tokens>
        </chunking>
        <chunking id="4" string="No wonder" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="wonder" />
          </tokens>
        </chunking>
        <chunking id="5" string="prevailing circumstances" type="NP">
          <tokens>
            <token id="14" string="prevailing" />
            <token id="15" string="circumstances" />
          </tokens>
        </chunking>
        <chunking id="6" string="learned the skill of fitting in with prevailing circumstances , no matter how fluctuating" type="VP">
          <tokens>
            <token id="7" string="learned" />
            <token id="8" string="the" />
            <token id="9" string="skill" />
            <token id="10" string="of" />
            <token id="11" string="fitting" />
            <token id="12" string="in" />
            <token id="13" string="with" />
            <token id="14" string="prevailing" />
            <token id="15" string="circumstances" />
            <token id="16" string="," />
            <token id="17" string="no" />
            <token id="18" string="matter" />
            <token id="19" string="how" />
            <token id="20" string="fluctuating" />
          </tokens>
        </chunking>
        <chunking id="7" string="how fluctuating" type="SBAR">
          <tokens>
            <token id="19" string="how" />
            <token id="20" string="fluctuating" />
          </tokens>
        </chunking>
        <chunking id="8" string="how" type="WHADVP">
          <tokens>
            <token id="19" string="how" />
          </tokens>
        </chunking>
        <chunking id="9" string="No wonder the young John Major" type="NP">
          <tokens>
            <token id="1" string="No" />
            <token id="2" string="wonder" />
            <token id="3" string="the" />
            <token id="4" string="young" />
            <token id="5" string="John" />
            <token id="6" string="Major" />
          </tokens>
        </chunking>
        <chunking id="10" string="the skill of fitting" type="NP">
          <tokens>
            <token id="8" string="the" />
            <token id="9" string="skill" />
            <token id="10" string="of" />
            <token id="11" string="fitting" />
          </tokens>
        </chunking>
        <chunking id="11" string="fitting" type="ADJP">
          <tokens>
            <token id="11" string="fitting" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="neg">
          <governor id="2">wonder</governor>
          <dependent id="1">No</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">learned</governor>
          <dependent id="2">wonder</dependent>
        </dependency>
        <dependency type="det">
          <governor id="6">Major</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="6">Major</governor>
          <dependent id="4">young</dependent>
        </dependency>
        <dependency type="compound">
          <governor id="6">Major</governor>
          <dependent id="5">John</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="2">wonder</governor>
          <dependent id="6">Major</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">learned</dependent>
        </dependency>
        <dependency type="det">
          <governor id="9">skill</governor>
          <dependent id="8">the</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="7">learned</governor>
          <dependent id="9">skill</dependent>
        </dependency>
        <dependency type="case">
          <governor id="11">fitting</governor>
          <dependent id="10">of</dependent>
        </dependency>
        <dependency type="acl">
          <governor id="9">skill</governor>
          <dependent id="11">fitting</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">circumstances</governor>
          <dependent id="12">in</dependent>
        </dependency>
        <dependency type="case">
          <governor id="15">circumstances</governor>
          <dependent id="13">with</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="15">circumstances</governor>
          <dependent id="14">prevailing</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="7">learned</governor>
          <dependent id="15">circumstances</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="18">matter</governor>
          <dependent id="17">no</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="7">learned</governor>
          <dependent id="18">matter</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">fluctuating</governor>
          <dependent id="19">how</dependent>
        </dependency>
        <dependency type="dep">
          <governor id="18">matter</governor>
          <dependent id="20">fluctuating</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="John Major" type="PERSON" score="0.0">
          <tokens>
            <token id="5" string="John" />
            <token id="6" string="Major" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="35" has_coreference="false">
      <content>The only problem is the old one: you cannot fool all of the people all of the time.</content>
      <tokens>
        <token id="1" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="2" string="only" lemma="only" stem="onli" pos="JJ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="problem" lemma="problem" stem="problem" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="4" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="5" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="true" is_refers="false" />
        <token id="6" string="old" lemma="old" stem="old" pos="JJ" type="Word" isStopWord="false" is_referenced="true" is_refers="false" />
        <token id="7" string="one" lemma="one" stem="on" pos="CD" type="Word" isStopWord="true" ner="NUMBER" is_referenced="true" is_refers="false" />
        <token id="8" string=":" lemma=":" stem=":" pos=":" type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="9" string="you" lemma="you" stem="you" pos="PRP" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="10" string="can" lemma="can" stem="can" pos="MD" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="11" string="not" lemma="not" stem="not" pos="RB" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="12" string="fool" lemma="fool" stem="fool" pos="VB" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="13" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="14" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="15" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="16" string="people" lemma="people" stem="peopl" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="17" string="all" lemma="all" stem="all" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="18" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="19" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="20" string="time" lemma="time" stem="time" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="21" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (S (NP (DT The) (JJ only) (NN problem)) (VP (VBZ is) (NP (DT the) (JJ old) (CD one)))) (: :) (S (NP (PRP you)) (VP (MD can) (RB not) (VP (VB fool) (NP (NP (DT all)) (PP (IN of) (NP (NP (DT the) (NNS people)) (PP (ADVP (DT all)) (IN of) (NP (DT the) (NN time))))))))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="can not fool all of the people all of the time" type="VP">
          <tokens>
            <token id="10" string="can" />
            <token id="11" string="not" />
            <token id="12" string="fool" />
            <token id="13" string="all" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="people" />
            <token id="17" string="all" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="time" />
          </tokens>
        </chunking>
        <chunking id="2" string="the people all of the time" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="people" />
            <token id="17" string="all" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="time" />
          </tokens>
        </chunking>
        <chunking id="3" string="the old one" type="NP">
          <tokens>
            <token id="5" string="the" />
            <token id="6" string="old" />
            <token id="7" string="one" />
          </tokens>
        </chunking>
        <chunking id="4" string="all" type="NP">
          <tokens>
            <token id="13" string="all" />
          </tokens>
        </chunking>
        <chunking id="5" string="is the old one" type="VP">
          <tokens>
            <token id="4" string="is" />
            <token id="5" string="the" />
            <token id="6" string="old" />
            <token id="7" string="one" />
          </tokens>
        </chunking>
        <chunking id="6" string="fool all of the people all of the time" type="VP">
          <tokens>
            <token id="12" string="fool" />
            <token id="13" string="all" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="people" />
            <token id="17" string="all" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="time" />
          </tokens>
        </chunking>
        <chunking id="7" string="all of the people all of the time" type="NP">
          <tokens>
            <token id="13" string="all" />
            <token id="14" string="of" />
            <token id="15" string="the" />
            <token id="16" string="people" />
            <token id="17" string="all" />
            <token id="18" string="of" />
            <token id="19" string="the" />
            <token id="20" string="time" />
          </tokens>
        </chunking>
        <chunking id="8" string="the time" type="NP">
          <tokens>
            <token id="19" string="the" />
            <token id="20" string="time" />
          </tokens>
        </chunking>
        <chunking id="9" string="the people" type="NP">
          <tokens>
            <token id="15" string="the" />
            <token id="16" string="people" />
          </tokens>
        </chunking>
        <chunking id="10" string="The only problem" type="NP">
          <tokens>
            <token id="1" string="The" />
            <token id="2" string="only" />
            <token id="3" string="problem" />
          </tokens>
        </chunking>
        <chunking id="11" string="you" type="NP">
          <tokens>
            <token id="9" string="you" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="det">
          <governor id="3">problem</governor>
          <dependent id="1">The</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="3">problem</governor>
          <dependent id="2">only</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="7">one</governor>
          <dependent id="3">problem</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="7">one</governor>
          <dependent id="4">is</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">one</governor>
          <dependent id="5">the</dependent>
        </dependency>
        <dependency type="amod">
          <governor id="7">one</governor>
          <dependent id="6">old</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="7">one</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="12">fool</governor>
          <dependent id="9">you</dependent>
        </dependency>
        <dependency type="aux">
          <governor id="12">fool</governor>
          <dependent id="10">can</dependent>
        </dependency>
        <dependency type="neg">
          <governor id="12">fool</governor>
          <dependent id="11">not</dependent>
        </dependency>
        <dependency type="parataxis">
          <governor id="7">one</governor>
          <dependent id="12">fool</dependent>
        </dependency>
        <dependency type="dobj">
          <governor id="12">fool</governor>
          <dependent id="13">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="16">people</governor>
          <dependent id="14">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="16">people</governor>
          <dependent id="15">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="13">all</governor>
          <dependent id="16">people</dependent>
        </dependency>
        <dependency type="advmod">
          <governor id="20">time</governor>
          <dependent id="17">all</dependent>
        </dependency>
        <dependency type="case">
          <governor id="20">time</governor>
          <dependent id="18">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="20">time</governor>
          <dependent id="19">the</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="16">people</governor>
          <dependent id="20">time</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="one" type="NUMBER" score="0.0">
          <tokens>
            <token id="7" string="one" />
          </tokens>
        </entity>
      </entities>
    </sentence>
    <sentence id="36" has_coreference="false">
      <content>Except in the movies.</content>
      <tokens>
        <token id="1" string="Except" lemma="except" stem="except" pos="IN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="2" string="in" lemma="in" stem="in" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="3" string="the" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="movies" lemma="movie" stem="movi" pos="NNS" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="." lemma="." stem="." pos="." type="Symbol" isStopWord="true" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (FRAG (PP (IN Except) (PP (IN in) (NP (DT the) (NNS movies)))) (. .)))</syntactictree>
      <chunkings>
        <chunking id="1" string="the movies" type="NP">
          <tokens>
            <token id="3" string="the" />
            <token id="4" string="movies" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="case">
          <governor id="4">movies</governor>
          <dependent id="1">Except</dependent>
        </dependency>
        <dependency type="case">
          <governor id="4">movies</governor>
          <dependent id="2">in</dependent>
        </dependency>
        <dependency type="det">
          <governor id="4">movies</governor>
          <dependent id="3">the</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">movies</dependent>
        </dependency>
      </dependencies>
    </sentence>
    <sentence id="37" has_coreference="false">
      <content>Dominic Lawson is editor of The Spectator</content>
      <tokens>
        <token id="1" string="Dominic" lemma="Dominic" stem="domin" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="2" string="Lawson" lemma="Lawson" stem="lawson" pos="NNP" type="Word" isStopWord="false" ner="PERSON" is_referenced="true" is_refers="false" />
        <token id="3" string="is" lemma="be" stem="i" pos="VBZ" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="4" string="editor" lemma="editor" stem="editor" pos="NN" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
        <token id="5" string="of" lemma="of" stem="of" pos="IN" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="6" string="The" lemma="the" stem="the" pos="DT" type="Word" isStopWord="true" is_referenced="false" is_refers="false" />
        <token id="7" string="Spectator" lemma="Spectator" stem="spectat" pos="NNP" type="Word" isStopWord="false" is_referenced="false" is_refers="false" />
      </tokens>
      <syntactictree>(ROOT (S (NP (NNP Dominic) (NNP Lawson)) (VP (VBZ is) (NP (NP (NN editor)) (PP (IN of) (NP (DT The) (NNP Spectator)))))))</syntactictree>
      <chunkings>
        <chunking id="1" string="editor" type="NP">
          <tokens>
            <token id="4" string="editor" />
          </tokens>
        </chunking>
        <chunking id="2" string="The Spectator" type="NP">
          <tokens>
            <token id="6" string="The" />
            <token id="7" string="Spectator" />
          </tokens>
        </chunking>
        <chunking id="3" string="is editor of The Spectator" type="VP">
          <tokens>
            <token id="3" string="is" />
            <token id="4" string="editor" />
            <token id="5" string="of" />
            <token id="6" string="The" />
            <token id="7" string="Spectator" />
          </tokens>
        </chunking>
        <chunking id="4" string="editor of The Spectator" type="NP">
          <tokens>
            <token id="4" string="editor" />
            <token id="5" string="of" />
            <token id="6" string="The" />
            <token id="7" string="Spectator" />
          </tokens>
        </chunking>
        <chunking id="5" string="Dominic Lawson" type="NP">
          <tokens>
            <token id="1" string="Dominic" />
            <token id="2" string="Lawson" />
          </tokens>
        </chunking>
      </chunkings>
      <dependencies>
        <dependency type="compound">
          <governor id="2">Lawson</governor>
          <dependent id="1">Dominic</dependent>
        </dependency>
        <dependency type="nsubj">
          <governor id="4">editor</governor>
          <dependent id="2">Lawson</dependent>
        </dependency>
        <dependency type="cop">
          <governor id="4">editor</governor>
          <dependent id="3">is</dependent>
        </dependency>
        <dependency type="root">
          <governor id="0">ROOT</governor>
          <dependent id="4">editor</dependent>
        </dependency>
        <dependency type="case">
          <governor id="7">Spectator</governor>
          <dependent id="5">of</dependent>
        </dependency>
        <dependency type="det">
          <governor id="7">Spectator</governor>
          <dependent id="6">The</dependent>
        </dependency>
        <dependency type="nmod">
          <governor id="4">editor</governor>
          <dependent id="7">Spectator</dependent>
        </dependency>
      </dependencies>
      <entities>
        <entity id="1" string="Dominic Lawson" type="PERSON" score="0.0">
          <tokens>
            <token id="1" string="Dominic" />
            <token id="2" string="Lawson" />
          </tokens>
        </entity>
      </entities>
    </sentence>
  </sentences>
  <coreferences>
    <coreference id="1" type="PROPER">
      <referenced ids_tokens="5-6-7-8" string="the urban John Major" id_sentence="10" />
      <mentions>
        <mention ids_tokens="6-28" string="Mrs Norma Major - or , if we are being old-fashioned , Mrs John Major - claimed that the Majors' favourite film" id_sentence="1" />
        <mention ids_tokens="5" string="their" id_sentence="2" />
        <mention ids_tokens="1-2" string="John Major" id_sentence="8" />
        <mention ids_tokens="8-10" string="extension John Major" id_sentence="24" />
        <mention ids_tokens="2-3" string="John Major" id_sentence="25" />
        <mention ids_tokens="3-6" string="the young John Major" id_sentence="34" />
      </mentions>
    </coreference>
    <coreference id="2" type="PROPER">
      <referenced ids_tokens="24-25-26" string="the Majors '" id_sentence="1" />
      <mentions>
        <mention ids_tokens="3-4" string="the Majors" id_sentence="7" />
        <mention ids_tokens="14" string="his" id_sentence="8" />
        <mention ids_tokens="2" string="he" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="3" type="PROPER">
      <referenced ids_tokens="51" string="US" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1" string="I" id_sentence="2" />
        <mention ids_tokens="1" string="My" id_sentence="15" />
        <mention ids_tokens="3" string="I" id_sentence="21" />
        <mention ids_tokens="8" string="my" id_sentence="21" />
        <mention ids_tokens="1" string="I" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="4" type="PROPER">
      <referenced ids_tokens="31" string="Chauncey" id_sentence="3" />
      <mentions>
        <mention ids_tokens="1-6" string="Chauncey , played by Peter Sellers" id_sentence="4" />
        <mention ids_tokens="26" string="he" id_sentence="4" />
        <mention ids_tokens="28-30" string="a sure-fire winner" id_sentence="4" />
        <mention ids_tokens="2-3" string="Chauncey's" id_sentence="5" />
        <mention ids_tokens="1" string="He" id_sentence="6" />
        <mention ids_tokens="24-25" string="Chauncey's" id_sentence="8" />
      </mentions>
    </coreference>
    <coreference id="5" type="NOMINAL">
      <referenced ids_tokens="7-8-9" string="that marvellous film" id_sentence="3" />
      <mentions>
        <mention ids_tokens="6-7" string="this film" id_sentence="7" />
      </mentions>
    </coreference>
    <coreference id="6" type="NOMINAL">
      <referenced ids_tokens="17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35-36-37" string="the plot : a man no one knows anything about , a gardener called Chauncey , rises without trace to become" id_sentence="3" />
      <mentions>
        <mention ids_tokens="17" string="this" id_sentence="4" />
      </mentions>
    </coreference>
    <coreference id="7" type="NOMINAL">
      <referenced ids_tokens="19-20-21-22-23-24" string="the Republican party 's power brokers" id_sentence="4" />
      <mentions>
        <mention ids_tokens="10" string="they" id_sentence="5" />
      </mentions>
    </coreference>
    <coreference id="8" type="NOMINAL">
      <referenced ids_tokens="11-12-13-14-15" string="the similarity between his own" id_sentence="8" />
      <mentions>
        <mention ids_tokens="6-7" string="the similarity" id_sentence="9" />
        <mention ids_tokens="9" string="that" id_sentence="9" />
      </mentions>
    </coreference>
    <coreference id="9" type="NOMINAL">
      <referenced ids_tokens="13-14" string="a gardener" id_sentence="10" />
      <mentions>
        <mention ids_tokens="19" string="his" id_sentence="11" />
      </mentions>
    </coreference>
    <coreference id="10" type="PROPER">
      <referenced ids_tokens="5-6" string="Farmers Weekly" id_sentence="11" />
      <mentions>
        <mention ids_tokens="4" string="it" id_sentence="13" />
        <mention ids_tokens="4-13" string="Farmers Weekly , a Pittsburgh steelworker for the American audience" id_sentence="23" />
      </mentions>
    </coreference>
    <coreference id="11" type="PROPER">
      <referenced ids_tokens="8-9-10-11-12-13-14-15-16" string="an unresponsive minus 33 years old at that time" id_sentence="18" />
      <mentions>
        <mention ids_tokens="13" string="Major" id_sentence="11" />
        <mention ids_tokens="9-19" string="Major how he had' such obvious empathy with agriculture'" id_sentence="12" />
        <mention ids_tokens="2" string="Major" id_sentence="14" />
        <mention ids_tokens="6" string="It" id_sentence="14" />
        <mention ids_tokens="11-12" string="Major's" id_sentence="17" />
        <mention ids_tokens="25-26" string="Major's" id_sentence="17" />
        <mention ids_tokens="10" string="Major" id_sentence="19" />
        <mention ids_tokens="22" string="Major" id_sentence="21" />
        <mention ids_tokens="1-2" string="Major's" id_sentence="24" />
        <mention ids_tokens="10-11" string="Major's" id_sentence="26" />
        <mention ids_tokens="12" string="Major" id_sentence="29" />
        <mention ids_tokens="8-9" string="Major's" id_sentence="30" />
        <mention ids_tokens="3-4" string="Major's" id_sentence="32" />
      </mentions>
    </coreference>
    <coreference id="12" type="NOMINAL">
      <referenced ids_tokens="19-20" string="his father" id_sentence="11" />
      <mentions>
        <mention ids_tokens="11" string="he" id_sentence="12" />
        <mention ids_tokens="1-2" string="My father" id_sentence="15" />
        <mention ids_tokens="4-5" string="a farmer" id_sentence="15" />
        <mention ids_tokens="1" string="He" id_sentence="16" />
        <mention ids_tokens="16-20" string="a steelworker in the city" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="15" type="PROPER">
      <referenced ids_tokens="1-2-3-4-5" string="Francis Wheen of The Guardian" id_sentence="17" />
      <mentions>
        <mention ids_tokens="2" string="Wheen" id_sentence="18" />
        <mention ids_tokens="36" string="his" id_sentence="21" />
        <mention ids_tokens="4" string="he" id_sentence="22" />
        <mention ids_tokens="12" string="his" id_sentence="22" />
      </mentions>
    </coreference>
    <coreference id="16" type="NOMINAL">
      <referenced ids_tokens="25-26-27" string="Major 's father" id_sentence="17" />
      <mentions>
        <mention ids_tokens="11" string="himself" id_sentence="24" />
        <mention ids_tokens="5" string="he" id_sentence="27" />
        <mention ids_tokens="12" string="his" id_sentence="27" />
        <mention ids_tokens="4" string="he" id_sentence="28" />
      </mentions>
    </coreference>
    <coreference id="17" type="NOMINAL">
      <referenced ids_tokens="23-24-25" string="this - Bromsgrove" id_sentence="18" />
      <mentions>
        <mention ids_tokens="1" string="This" id_sentence="19" />
        <mention ids_tokens="6" string="this" id_sentence="21" />
      </mentions>
    </coreference>
    <coreference id="20" type="NOMINAL">
      <referenced ids_tokens="5-6-7-8-9" string="a different sort of politician" id_sentence="25" />
      <mentions>
        <mention ids_tokens="2" string="it" id_sentence="26" />
      </mentions>
    </coreference>
    <coreference id="21" type="NOMINAL">
      <referenced ids_tokens="2-3-4" string="the one hand" id_sentence="27" />
      <mentions>
        <mention ids_tokens="19-20" string="his hand" id_sentence="33" />
      </mentions>
    </coreference>
    <coreference id="22" type="NOMINAL">
      <referenced ids_tokens="3-4-5-6-7-8-9-10-11-12-13-14-15-16-17-18-19-20-21-22-23-24-25-26-27-28-29-30-31-32-33-34-35" string="those who will argue that this merely means that Major is a typical democratic politician , that one who wants to become prime minister in a democracy must recognise many constituencies of interest" id_sentence="29" />
      <mentions>
        <mention ids_tokens="2" string="that" id_sentence="30" />
      </mentions>
    </coreference>
    <coreference id="24" type="NOMINAL">
      <referenced ids_tokens="1-2-3-4-5" string="No , Major 's technique" id_sentence="32" />
      <mentions>
        <mention ids_tokens="1" string="His" id_sentence="33" />
      </mentions>
    </coreference>
  </coreferences>
</document>
